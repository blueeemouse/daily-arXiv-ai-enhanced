{"id": "2602.23598", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23598", "abs": "https://arxiv.org/abs/2602.23598", "authors": ["Md Hasanur Rashid", "Jesun Firoz", "Nathan R. Tallent", "Luanzheng Guo", "Meng Tang", "Dong Dai"], "title": "QoSFlow: Ensuring Service Quality of Distributed Workflows Using Interpretable Sensitivity Models", "comment": "to be published in 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS), 2026", "summary": "With the increasing importance of distributed scientific workflows, there is a critical need to ensure Quality of Service (QoS) constraints, such as minimizing time or limiting execution to resource subsets. However, the unpredictable nature of workflow behavior, even with similar configurations, makes it difficult to provide QoS guarantees. For effective reasoning about QoS scheduling, we introduce QoSFlow, a performance modeling method that partitions a workflow's execution configuration space into regions with similar behavior. Each region groups configurations with comparable execution times according to a given statistical sensitivity, enabling efficient QoS-driven scheduling through analytical reasoning rather than exhaustive testing. Evaluation on three diverse workflows shows that QoSFlow's execution recommendations outperform the best-performing standard heuristic by 27.38%. Empirical validation confirms that QoSFlow's recommended configurations consistently match measured execution outcomes across different QoS constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQoSFlow\u7684\u6027\u80fd\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u5de5\u4f5c\u6d41\u7684\u6267\u884c\u914d\u7f6e\u7a7a\u95f4\u5212\u5206\u4e3a\u5177\u6709\u76f8\u4f3c\u884c\u4e3a\u7684\u533a\u57df\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684QoS\u9a71\u52a8\u8c03\u5ea6\u3002\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u5de5\u4f5c\u6d41\u7684\u8bc4\u4f30\u8868\u660e\uff0cQoSFlow\u63d0\u4f9b\u7684\u6267\u884c\u5efa\u8bae\u6bd4\u6700\u4f73\u6807\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u9ad8\u51fa27.38%\u3002", "motivation": "\u968f\u7740\u5206\u5e03\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u786e\u4fdd\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u7ea6\u675f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u6bd4\u5982\u6700\u5c0f\u5316\u65f6\u95f4\u6216\u9650\u5236\u5728\u8d44\u6e90\u5b50\u96c6\u5185\u6267\u884c\u3002\u7136\u800c\uff0c\u5373\u4f7f\u662f\u5728\u7c7b\u4f3c\u914d\u7f6e\u4e0b\uff0c\u5de5\u4f5c\u6d41\u884c\u4e3a\u4e5f\u96be\u4ee5\u9884\u6d4b\uff0c\u8fd9\u4f7f\u5f97\u63d0\u4f9bQoS\u4fdd\u8bc1\u53d8\u5f97\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5e76\u6709\u6548\u5904\u7406QoS\u8c03\u5ea6\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e86QoSFlow\uff0c\u4e00\u79cd\u6027\u80fd\u5efa\u6a21\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u5c06\u5de5\u4f5c\u6d41\u7684\u6267\u884c\u914d\u7f6e\u7a7a\u95f4\u5206\u5272\u6210\u62e5\u6709\u76f8\u4f3c\u884c\u4e3a\u7279\u6027\u7684\u533a\u57df\u3002\u6bcf\u4e2a\u533a\u57df\u6839\u636e\u7ed9\u5b9a\u7684\u7edf\u8ba1\u654f\u611f\u5ea6\u5bf9\u5177\u6709\u53ef\u6bd4\u6267\u884c\u65f6\u95f4\u7684\u914d\u7f6e\u8fdb\u884c\u5206\u7ec4\uff0c\u4ece\u800c\u5141\u8bb8\u901a\u8fc7\u5206\u6790\u63a8\u7406\u800c\u4e0d\u662f\u8be6\u5c3d\u6d4b\u8bd5\u6765\u5b9e\u73b0\u9ad8\u6548\u7684QoS\u9a71\u52a8\u8c03\u5ea6\u3002", "result": "\u901a\u8fc7\u5bf9\u4e09\u4e2a\u4e0d\u540c\u5de5\u4f5c\u6d41\u7684\u8bc4\u4f30\u663e\u793a\uff0cQoSFlow\u7ed9\u51fa\u7684\u6267\u884c\u63a8\u8350\u6bd4\u8868\u73b0\u6700\u597d\u7684\u6807\u51c6\u542f\u53d1\u5f0f\u7b97\u6cd5\u63d0\u9ad8\u4e8627.38%\u3002\u5b9e\u8bc1\u9a8c\u8bc1\u8fd8\u8bc1\u5b9e\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684QoS\u7ea6\u675f\u6761\u4ef6\uff0cQoSFlow\u63a8\u8350\u7684\u914d\u7f6e\u59cb\u7ec8\u4e0e\u6d4b\u91cf\u5230\u7684\u6267\u884c\u7ed3\u679c\u76f8\u5339\u914d\u3002", "conclusion": "QoSFlow\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u4e00\u79cd\u65b0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8QoS\u9a71\u52a8\u8c03\u5ea6\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5176\u63a8\u8350\u7684\u914d\u7f6e\u80fd\u591f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u51c6\u786e\u5730\u53cd\u6620\u9884\u671f\u7684\u884c\u4e3a\u7279\u6027\u3002"}}
{"id": "2602.23935", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23935", "abs": "https://arxiv.org/abs/2602.23935", "authors": ["Bowen Sun", "Christos D. Antonopoulos", "Evgenia Smirni", "Bin Ren", "Nikolaos Bellas", "Spyros Lalis"], "title": "Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing", "comment": null, "summary": "Serverless computing simplifies cloud deployment but introduces new challenges in managing service latency and carbon emissions. Reducing cold-start latency requires retaining warm function instances, while minimizing carbon emissions favors reclaiming idle resources. This balance is further complicated by time-varying grid carbon intensity and varying workload patterns, under which static keep-alive policies are inefficient. We present LACE-RL, a latency-aware and carbon-efficient management framework that formulates serverless pod retention as a sequential decision problem. LACE-RL uses deep reinforcement learning to dynamically tune keep-alive durations, jointly modeling cold-start probability, function-specific latency costs, and real-time carbon intensity. Using the Huawei Public Cloud Trace, we show that LACE-RL reduces cold starts by 51.69% and idle keep-alive carbon emissions by 77.08% compared to Huawei's static policy, while achieving better latency-carbon trade-offs than state-of-the-art heuristic and single-objective baselines, approaching Oracle performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLACE-RL\u7684\u7ba1\u7406\u6846\u67b6\uff0c\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u4e2d\u51fd\u6570\u5b9e\u4f8b\u7684\u4fdd\u6301\u6d3b\u52a8\u65f6\u95f4\uff0c\u4ee5\u5e73\u8861\u670d\u52a1\u5ef6\u8fdf\u548c\u78b3\u6392\u653e\u3002\u57fa\u4e8e\u534e\u4e3a\u516c\u5171\u4e91\u8ddf\u8e2a\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u51b7\u542f\u52a8\u6b21\u6570\u548c\u7a7a\u95f2\u65f6\u4fdd\u6301\u6d3b\u52a8\u72b6\u6001\u7684\u78b3\u6392\u653e\u65b9\u9762\u4f18\u4e8e\u9759\u6001\u7b56\u7565\u548c\u5176\u4ed6\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7b80\u5316\u4e86\u4e91\u90e8\u7f72\u8fc7\u7a0b\uff0c\u4f46\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u5982\u5982\u4f55\u6709\u6548\u7ba1\u7406\u670d\u52a1\u5ef6\u8fdf\u548c\u964d\u4f4e\u78b3\u6392\u653e\u3002\u5f53\u524d\u5b58\u5728\u7684\u95ee\u9898\u5305\u62ec\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u9700\u8981\u4fdd\u7559\u70ed\u51fd\u6570\u5b9e\u4f8b\uff0c\u800c\u51cf\u5c11\u78b3\u6392\u653e\u5219\u504f\u597d\u56de\u6536\u95f2\u7f6e\u8d44\u6e90\u3002\u6b64\u5916\uff0c\u7535\u7f51\u78b3\u5f3a\u5ea6\u968f\u65f6\u95f4\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u5f0f\u53d8\u5316\uff0c\u4f7f\u5f97\u56fa\u5b9a\u7684\u4fdd\u6301\u6d3b\u52a8\u7b56\u7565\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86LACE-RL\u6846\u67b6\uff0c\u5c06\u65e0\u670d\u52a1\u5668\u5bb9\u5668\u4fdd\u7559\u95ee\u9898\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u6765\u52a8\u6001\u8c03\u6574\u4fdd\u6301\u6d3b\u52a8\u7684\u65f6\u95f4\u957f\u5ea6\u3002\u6b64\u65b9\u6cd5\u540c\u65f6\u8003\u8651\u4e86\u51b7\u542f\u52a8\u6982\u7387\u3001\u7279\u5b9a\u4e8e\u51fd\u6570\u7684\u5ef6\u8fdf\u6210\u672c\u4ee5\u53ca\u5b9e\u65f6\u78b3\u5f3a\u5ea6\u7b49\u56e0\u7d20\u3002", "result": "\u901a\u8fc7\u534e\u4e3a\u516c\u5171\u4e91\u8ffd\u8e2a\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u7684\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u534e\u4e3a\u91c7\u7528\u7684\u9759\u6001\u7b56\u7565\u76f8\u6bd4\uff0cLACE-RL\u80fd\u591f\u51cf\u5c1151.69%\u7684\u51b7\u542f\u52a8\u6b21\u6570\u53ca77.08%\u56e0\u7a7a\u95f2\u4fdd\u6301\u6d3b\u52a8\u5bfc\u81f4\u7684\u78b3\u6392\u653e\u3002\u6b64\u5916\uff0c\u5728\u6743\u8861\u5ef6\u8fdf\u4e0e\u78b3\u6392\u653e\u65b9\u9762\uff0cLACE-RL\u4e5f\u5c55\u73b0\u51fa\u4e86\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u5355\u4e00\u76ee\u6807\u57fa\u7ebf\u65b9\u6848\u7684\u8868\u73b0\uff0c\u63a5\u8fd1\u7406\u60f3\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86LACE-RL\u80fd\u591f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u5730\u5e73\u8861\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e0b\u7684\u670d\u52a1\u5ef6\u8fdf\u4e0e\u78b3\u6392\u653e\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u4e91\u8ba1\u7b97\u5e73\u53f0\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2602.23969", "categories": ["cs.MM", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23969", "abs": "https://arxiv.org/abs/2602.23969", "authors": ["Haoyuan Shi", "Yunxin Li", "Nanhao Deng", "Zhenran Xu", "Xinyu Chen", "Longyue Wang", "Baotian Hu", "Min Zhang"], "title": "MSVBench: Towards Human-Level Evaluation of Multi-Shot Video Generation", "comment": null, "summary": "The evolution of video generation toward complex, multi-shot narratives has exposed a critical deficit in current evaluation methods. Existing benchmarks remain anchored to single-shot paradigms, lacking the comprehensive story assets and cross-shot metrics required to assess long-form coherence and appeal. To bridge this gap, we introduce MSVBench, the first comprehensive benchmark featuring hierarchical scripts and reference images tailored for Multi-Shot Video generation. We propose a hybrid evaluation framework that synergizes the high-level semantic reasoning of Large Multimodal Models (LMMs) with the fine-grained perceptual rigor of domain-specific expert models. Evaluating 20 video generation methods across diverse paradigms, we find that current models--despite strong visual fidelity--primarily behave as visual interpolators rather than true world models. We further validate the reliability of our benchmark by demonstrating a state-of-the-art Spearman's rank correlation of 94.4% with human judgments. Finally, MSVBench extends beyond evaluation by providing a scalable supervisory signal. Fine-tuning a lightweight model on its pipeline-refined reasoning traces yields human-aligned performance comparable to commercial models like Gemini-2.5-Flash.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MSVBench\uff0c\u8fd9\u662f\u9996\u4e2a\u4e13\u4e3a\u591a\u955c\u5934\u89c6\u9891\u751f\u6210\u8bbe\u8ba1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u7ed3\u5408\u4e86\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u9ad8\u7ea7\u8bed\u4e49\u63a8\u7406\u4e0e\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u6a21\u578b\u7684\u7cbe\u7ec6\u611f\u77e5\u4e25\u8c28\u6027\uff0c\u4ee5\u8bc4\u4f30\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u4f5c\u4e3a\u89c6\u89c9\u63d2\u503c\u5668\u800c\u975e\u771f\u5b9e\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u4e14\u901a\u8fc7\u5fae\u8c03\u8f7b\u91cf\u7ea7\u6a21\u578b\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5546\u4e1a\u6a21\u578b\u76f8\u5f53\u7684\u4eba\u7c7b\u5bf9\u9f50\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u9891\u751f\u6210\u8bc4\u4ef7\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u3001\u591a\u955c\u5934\u53d9\u4e8b\u7684\u9700\u6c42\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u6545\u4e8b\u8d44\u6e90\u548c\u8de8\u955c\u5934\u5ea6\u91cf\u6765\u8bc4\u4f30\u957f\u7bc7\u8fde\u8d2f\u6027\u548c\u5438\u5f15\u529b\u3002", "method": "\u63d0\u51fa\u4e86MSVBench\uff0c\u4e00\u4e2a\u5305\u542b\u5206\u5c42\u811a\u672c\u548c\u53c2\u8003\u56fe\u50cf\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u591a\u955c\u5934\u89c6\u9891\u751f\u6210\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u79cd\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u9ad8\u7ea7\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u4e0e\u9886\u57df\u7279\u5b9a\u4e13\u5bb6\u6a21\u578b\u7684\u7ec6\u81f4\u611f\u77e5\u4e25\u8c28\u6027\u76f8\u7ed3\u5408\u3002", "result": "\u901a\u8fc7\u5bf920\u79cd\u4e0d\u540c\u8303\u5f0f\u7684\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u867d\u7136\u5177\u6709\u5f88\u5f3a\u7684\u89c6\u89c9\u903c\u771f\u5ea6\uff0c\u4f46\u4e3b\u8981\u8868\u73b0\u4e3a\u89c6\u89c9\u63d2\u503c\u5668\u800c\u4e0d\u662f\u771f\u6b63\u610f\u4e49\u4e0a\u7684\u4e16\u754c\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e4b\u95f4\u8fbe\u5230\u4e8694.4%\u7684\u76f8\u5173\u6027\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u901a\u8fc7\u5728MSVBench\u63d0\u4f9b\u7684\u7cbe\u70bc\u63a8\u7406\u8f68\u8ff9\u4e0a\u5fae\u8c03\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u53ef\u4ee5\u83b7\u5f97\u4e0e\u5546\u4e1a\u6a21\u578b\u5982Gemini-2.5-Flash\u76f8\u5ab2\u7f8e\u7684\u4eba\u7c7b\u5bf9\u9f50\u8868\u73b0\u3002", "conclusion": "MSVBench\u4e0d\u4ec5\u586b\u8865\u4e86\u591a\u955c\u5934\u89c6\u9891\u751f\u6210\u9886\u57df\u5185\u7efc\u5408\u6027\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u89c6\u9891\u751f\u6210\u6280\u672f\u7684\u6574\u4f53\u6c34\u5e73\u3002"}}
{"id": "2602.23469", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.23469", "abs": "https://arxiv.org/abs/2602.23469", "authors": ["Lixi Zhou", "Kanchan Chowdhury", "Lulu Xie", "Jaykumar Tandel", "Hong Guan", "Zhiwei Fan", "Xinwei Fu", "Jia Zou"], "title": "CACTUSDB: Unlock Co-Optimization Opportunities for SQL and AI/ML Inferences", "comment": "Accepted to ICDE 2026 as a full research paper", "summary": "There is a growing demand for supporting inference queries that combine Structured Query Language (SQL) and Artificial Intelligence / Machine Learning (AI/ML) model inferences in database systems, to avoid data denormalization and transfer, facilitate management, and alleviate privacy concerns. Co-optimization techniques for executing inference queries in database systems without accuracy loss fall into four categories: (O1) Relational algebra optimization treating AI/ML models as black-box user-defined functions (UDFs); (O2) Factorized AI/ML inferences; (O3) Tensor-relational transformation; and (O4) General cross-optimization techniques. However, we found none of the existing database systems support all these techniques simultaneously, resulting in suboptimal performance. In this work, we identify two key challenges to address the above problem: (1) the difficulty of unifying all co-optimization techniques that involve disparate data and computation abstractions in one system; and (2) the lack of an optimizer that can effectively explore the exponential search space. To address these challenges, we present CactusDB, a novel system built atop Velox - a high-performance, UDF-centric database engine, open-sourced by Meta. CactusDB features a three-level Intermediate Representations (IR) that supports relational operators, expression operators, and ML functions to enable flexible optimization of arbitrary sub-computations. Additionally, we propose a novel Monte-Carlo Tree Search (MCTS)-based optimizer with query embedding, co-designed with our unique three-level IR, enabling shared and reusable optimization knowledge across different queries. Evaluation of 12 representative inference workloads and 2,000 randomly generated inference queries on well-known datasets, such as MovieLens and TPCx-AI, shows that CactusDB achieves up to 441 times speedup compared to alternative systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u5e93\u7cfb\u7edfCactusDB\uff0c\u5b83\u57fa\u4e8eVelox\u6784\u5efa\uff0c\u5e76\u91c7\u7528\u4e09\u5c42\u4e2d\u95f4\u8868\u793a(IR)\u652f\u6301\u5173\u7cfb\u8fd0\u7b97\u7b26\u3001\u8868\u8fbe\u5f0f\u8fd0\u7b97\u7b26\u548cML\u51fd\u6570\uff0c\u4ee5\u53ca\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22(MCTS)\u7684\u4f18\u5316\u5668\uff0c\u4ee5\u89e3\u51b3SQL\u4e0eAI/ML\u6a21\u578b\u63a8\u7406\u67e5\u8be2\u7ed3\u5408\u6267\u884c\u65f6\u7684\u534f\u540c\u4f18\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u5904\u7406\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u76f8\u6bd4\u5176\u4ed6\u7cfb\u7edf\u53ef\u8fbe\u5230\u6700\u9ad8441\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u5bf9SQL\u4e0eAI/ML\u6a21\u578b\u63a8\u7406\u67e5\u8be2\u7ed3\u5408\u6267\u884c\u7684\u6709\u6548\u652f\u6301\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u540c\u65f6\u652f\u6301\u6240\u6709\u534f\u540c\u4f18\u5316\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u7edf\u4e00\u4e0d\u540c\u6570\u636e\u548c\u8ba1\u7b97\u62bd\u8c61\u7684\u7cfb\u7edf\uff0c\u5e76\u4e14\u8bbe\u8ba1\u51fa\u80fd\u6709\u6548\u63a2\u7d22\u6307\u6570\u7ea7\u641c\u7d22\u7a7a\u95f4\u7684\u4f18\u5316\u5668\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aCactusDB\u7684\u65b0\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5efa\u7acb\u5728\u9ad8\u6027\u80fd\u7684UDF\u4e2d\u5fc3\u6570\u636e\u5e93\u5f15\u64ceVelox\u4e4b\u4e0a\u3002CactusDB\u5f15\u5165\u4e86\u4e09\u5c42IR\u7ed3\u6784\u6765\u7075\u6d3b\u5730\u4f18\u5316\u4efb\u610f\u5b50\u8ba1\u7b97\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eMCTS\u7684\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u67e5\u8be2\u5d4c\u5165\u6280\u672f\u4f7f\u4e0d\u540c\u67e5\u8be2\u95f4\u53ef\u4ee5\u5171\u4eab\u548c\u91cd\u7528\u4f18\u5316\u77e5\u8bc6\u3002", "result": "\u901a\u8fc7\u5bf912\u4e2a\u4ee3\u8868\u6027\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u53ca2000\u4e2a\u968f\u673a\u751f\u6210\u7684\u63a8\u7406\u67e5\u8be2\u8fdb\u884c\u8bc4\u4f30\uff0c\u5728\u5982MovieLens\u548cTPCx-AI\u7b49\u77e5\u540d\u6570\u636e\u96c6\u4e0a\uff0cCactusDB\u76f8\u5bf9\u4e8e\u5176\u4ed6\u7cfb\u7edf\u5b9e\u73b0\u4e86\u9ad8\u8fbe441\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "CactusDB\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u5c06SQL\u4e0eAI/ML\u6a21\u578b\u63a8\u7406\u76f8\u7ed3\u5408\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u7edf\u4e00\u591a\u79cd\u6570\u636e\u548c\u8ba1\u7b97\u62bd\u8c61\u7684\u80fd\u529b\u4ee5\u53ca\u5229\u7528\u57fa\u4e8eMCTS\u7684\u4f18\u5316\u5668\u9ad8\u6548\u63a2\u7d22\u5927\u641c\u7d22\u7a7a\u95f4\u7684\u80fd\u529b\u3002\u5176\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u9ad8\u63a8\u7406\u67e5\u8be2\u6027\u80fd\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.23391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23391", "abs": "https://arxiv.org/abs/2602.23391", "authors": ["Nazanin Mohammadi Sepahvand", "Eleni Triantafillou", "Hugo Larochelle", "Doina Precup", "Daniel M. Roy", "Gintare Karolina Dziugaite"], "title": "Detoxifying LLMs via Representation Erasure-Based Preference Optimization", "comment": null, "summary": "Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful \"directions\" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREPO\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6709\u5bb3\u5185\u5bb9\u7684\u8868\u793a\u6536\u655b\u5230\u65e0\u5bb3\u5185\u5bb9\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u6709\u6bd2\u8f93\u51fa\u7684\u95ee\u9898\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u6df1\u5ea6\u4e14\u5c40\u90e8\u7684\u7f16\u8f91\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u4e00\u822c\u5b9e\u7528\u6027\uff0c\u5e76\u5bf9\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u7684\u590d\u6742\u5a01\u80c1\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u9632\u5fa1\u63aa\u65bd\u867d\u7136\u51cf\u5c11\u4e86\u6709\u5bb3\u5ef6\u7eed\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u63d0\u793a\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u5fae\u8c03\u7684\u91cd\u65b0\u5b66\u4e60\u653b\u51fb\u8f7b\u6613\u88ab\u9006\u8f6c\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e9b\u5bf9\u6a21\u578b\u7684\u4fee\u6539\u662f\u8868\u9762\u7684\uff0c\u7ebf\u6027\u63a2\u6d4b\u663e\u793a\u6709\u5bb3\u7684\u201c\u65b9\u5411\u201d\u4ecd\u7136\u5b58\u5728\u4e8e\u8868\u793a\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8868\u793a\u64e6\u9664\u7684\u504f\u597d\u4f18\u5316\uff08REPO\uff09\uff0c\u5c06\u53bb\u6bd2\u5316\u91cd\u6784\u6210\u4e00\u4e2a\u4ee4\u724c\u7ea7\u522b\u7684\u504f\u597d\u95ee\u9898\u3002\u5229\u7528\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u548c\u504f\u597d\u6570\u636e\uff0c\u5f3a\u5236\u6709\u6bd2\u5ef6\u7eed\u7684\u8868\u793a\u5411\u5176\u826f\u6027\u5bf9\u5e94\u7269\u9760\u62e2\u3002", "result": "REPO\u5b9e\u73b0\u4e86\u6700\u524d\u6cbf\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u963b\u6b62\u5305\u62ec\u91cd\u65b0\u5b66\u4e60\u653b\u51fb\u548c\u589e\u5f3a\u578bGCG\u8d8a\u72f1\u5728\u5185\u7684\u590d\u6742\u5a01\u80c1\uff0c\u5728\u8fd9\u4e00\u70b9\u4e0a\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u8868\u793a\u548c\u8f93\u51fa\u7684\u65b9\u6cd5\u5931\u8d25\u4e86\u3002", "conclusion": "REPO\u4e0d\u4ec5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6709\u6bd2\u8f93\u51fa\u7684\u95ee\u9898\uff0c\u800c\u4e14\u5728\u9762\u5bf9\u590d\u6742\u7684\u653b\u51fb\u65b9\u5f0f\u65f6\u4e5f\u5c55\u73b0\u51fa\u4e86\u524d\u6240\u672a\u6709\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5b89\u5168\u90e8\u7f72\u8fd9\u7c7b\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2602.24044", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24044", "abs": "https://arxiv.org/abs/2602.24044", "authors": ["Ferran Agullo", "Joan Oliveras", "Chen Wang", "Alberto Gutierrez-Torre", "Olivier Tardieu", "Alaa Youssef", "Jordi Torres", "Josep Ll. Berral"], "title": "Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving", "comment": "journal extension of the workshop paper titled as \"A data-driven ml approach for maximizing performance in llm-adapter serving\"", "summary": "Large Language Model (LLM) adapters enable low-cost model specialization, but introduce complex caching and scheduling challenges in distributed serving systems where hundreds of adapters must be hosted concurrently. While prior work has largely focused on latency minimization, resource efficiency through throughput maximization remains underexplored. This paper presents a data-driven pipeline that, for a given workload, computes an adapter placement that serves the workload with the minimum number of GPUs while avoiding request starvation and GPU memory errors. To that end, the approach identifies the maximum feasible throughput attainable on each GPU by leveraging accurate performance predictions learned from real serving behavior. The proposed pipeline integrates three components: (i) a Digital Twin (DT) tailored to LLM-adapter serving, (ii) a distilled machine learning (ML) model trained on DT-generated data, and (iii) a greedy placement algorithm that exploits ML-based performance estimates to maximize GPU efficiency. The DT emulates real system dynamics with high fidelity, achieving below 5% throughput estimation error while executing up to 90 times faster than full LLM benchmarking across both predictable and unpredictable workloads. The learned ML models further accelerate performance estimation with marginal accuracy degradation, enabling scalable optimization. Experimental results demonstrate that the pipeline substantially improves GPU efficiency by reducing the number of GPUs required to sustain target workloads. Beyond GPU efficiency, the pipeline can be adapted to alternative objectives, such as latency minimization, highlighting its versatility for future large-scale LLM serving infrastructures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u8ba1\u7b97\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5668\u7684\u653e\u7f6e\u65b9\u6848\uff0c\u4ee5\u6700\u5c11\u6570\u91cf\u7684GPU\u670d\u52a1\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u540c\u65f6\u907f\u514d\u8bf7\u6c42\u9965\u997f\u548cGPU\u5185\u5b58\u9519\u8bef\u3002\u8be5\u6d41\u6c34\u7ebf\u96c6\u6210\u4e86\u6570\u5b57\u5b6a\u751f\u3001\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u53ca\u8d2a\u5a6a\u653e\u7f6e\u7b97\u6cd5\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u80fd\u591f\u5927\u5e45\u63d0\u9ad8GPU\u6548\u7387\uff0c\u5e76\u4e14\u53ef\u4ee5\u9002\u5e94\u5176\u4ed6\u4f18\u5316\u76ee\u6807\u5982\u5ef6\u8fdf\u6700\u5c0f\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5668\u5728\u5206\u5e03\u5f0f\u670d\u52a1\u7cfb\u7edf\u4e2d\u5f15\u5165\u4e86\u590d\u6742\u7684\u7f13\u5b58\u548c\u8c03\u5ea6\u6311\u6218\uff0c\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u51cf\u5c11\u5ef6\u8fdf\u4e0a\uff0c\u4f46\u901a\u8fc7\u6700\u5927\u5316\u541e\u5410\u91cf\u6765\u63d0\u9ad8\u8d44\u6e90\u6548\u7387\u4ecd\u5f85\u63a2\u7d22\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u62ec\u7279\u5b9a\u4e8eLLM-\u9002\u914d\u5668\u670d\u52a1\u7684\u6570\u5b57\u5b6a\u751f\u3001\u57fa\u4e8eDT\u751f\u6210\u6570\u636e\u8bad\u7ec3\u7684\u7b80\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u53ca\u5229\u7528\u57fa\u4e8eML\u6027\u80fd\u4f30\u8ba1\u7684\u8d2a\u5a6a\u653e\u7f6e\u7b97\u6cd5\u5728\u5185\u7684\u6570\u636e\u9a71\u52a8\u6d41\u6c34\u7ebf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6d41\u6c34\u7ebf\u80fd\u663e\u8457\u63d0\u9ad8GPU\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u652f\u6301\u76ee\u6807\u5de5\u4f5c\u8d1f\u8f7d\u6240\u9700\u7684GPU\u6570\u91cf\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u53ef\u4ee5\u8c03\u6574\u4ee5\u9002\u5e94\u5176\u4ed6\u76ee\u6807\uff0c\u6bd4\u5982\u6700\u5c0f\u5316\u5ef6\u8fdf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u6d41\u6c34\u7ebf\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9002\u914d\u5668\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u9762\u4e34\u7684\u8d44\u6e90\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7684\u5927\u89c4\u6a21LLM\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u591a\u529f\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23369", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23369", "abs": "https://arxiv.org/abs/2602.23369", "authors": ["Xuanming Cui", "Hong-You Chen", "Hao Yu", "Hao Yuan", "Zihao Wang", "Shlok Kumar Mishra", "Hanchao Yu", "Yonghuan Yang", "Jun Xiao", "Ser-Nam Lim", "Jianpeng Cheng", "Qi Guo", "Xiangjun Fan"], "title": "Reason to Contrast: A Cascaded Multimodal Retrieval Framework", "comment": null, "summary": "Traditional multimodal retrieval systems rely primarily on bi-encoder architectures, where performance is closely tied to embedding dimensionality. Recent work, Think-Then-Embed (TTE), shows that incorporating multimodal reasoning to elicit additional informative tokens before embedding can further improve retrieval. In this paper, we extend this paradigm with TTE-v2, a hybrid multimodal retrieval framework that introduces reasoning-driven performance scaling based on additional input token budget rather than model or embedding size. Our approach augments the initial multimodal retrieval with additional reasoning steps for reranking, enabling more expressive query-candidate interactions at test time. The reranking stage further provides fine-grained supervision for hard negative mining and false negative filtering, creating a feedback loop that effectively strengthens the upstream retriever. This cascaded design delivers substantial test-time improvements based on intermediate reasoning token scaling. Experiments on the MMEB-V2 benchmark demonstrate that TTE-v2-7B achieves a new state-of-the-art accuracy of 75.7%, and that TTE-v2-2B matches or surpasses leading 7B models trained with significantly larger external data. Our results highlight the promise of token-wise scaling as an alternative scaling paradigm for multimodal retrieval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TTE-v2\uff0c\u4e00\u79cd\u57fa\u4e8e\u989d\u5916\u8f93\u5165\u4ee4\u724c\u9884\u7b97\u800c\u975e\u6a21\u578b\u6216\u5d4c\u5165\u5927\u5c0f\u8fdb\u884c\u63a8\u7406\u9a71\u52a8\u6027\u80fd\u6269\u5c55\u7684\u6df7\u5408\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6\u3002\u901a\u8fc7\u589e\u52a0\u91cd\u6392\u5e8f\u9636\u6bb5\u6765\u589e\u5f3a\u67e5\u8be2-\u5019\u9009\u4ea4\u4e92\uff0c\u5e76\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u76d1\u7763\u4ee5\u6316\u6398\u96be\u8d1f\u6837\u672c\u548c\u8fc7\u6ee4\u5047\u8d1f\u6837\u672c\uff0c\u5f62\u6210\u4e00\u4e2a\u53cd\u9988\u5faa\u73af\u52a0\u5f3a\u4e0a\u6e38\u68c0\u7d22\u5668\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTTE-v2\u5728MMEB-V2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u51c6\u786e\u738775.7%\u3002", "motivation": "\u4f20\u7edf\u591a\u6a21\u6001\u68c0\u7d22\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u4e8e\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5176\u6027\u80fd\u4e0e\u5d4c\u5165\u7ef4\u5ea6\u7d27\u5bc6\u76f8\u5173\u3002\u6700\u8fd1\u7684\u5de5\u4f5cThink-Then-Embed (TTE)\u8868\u660e\uff0c\u5728\u5d4c\u5165\u4e4b\u524d\u5f15\u5165\u591a\u6a21\u6001\u63a8\u7406\u4ee5\u6fc0\u53d1\u66f4\u591a\u4fe1\u606f\u4ee4\u724c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u68c0\u7d22\u6548\u679c\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u6539\u8fdb\u8fd9\u79cd\u65b9\u6cd5\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6TTE-v2\uff0c\u65e8\u5728\u901a\u8fc7\u589e\u52a0\u989d\u5916\u7684\u63a8\u7406\u6b65\u9aa4\u6765\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u67e5\u8be2-\u5019\u9009\u4e92\u52a8\u3002", "method": "TTE-v2\u662f\u4e00\u79cd\u7ed3\u5408\u4e86\u521d\u59cb\u591a\u6a21\u6001\u68c0\u7d22\u548c\u9644\u52a0\u63a8\u7406\u6b65\u9aa4\u7528\u4e8e\u91cd\u65b0\u6392\u5e8f\u7684\u6df7\u5408\u591a\u6a21\u6001\u68c0\u7d22\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u9760\u6269\u5927\u6a21\u578b\u6216\u5d4c\u5165\u5c3a\u5bf8\u800c\u662f\u5229\u7528\u989d\u5916\u7684\u8f93\u5165\u4ee4\u724c\u9884\u7b97\u6765\u63d0\u5347\u6027\u80fd\u3002\u91cd\u6392\u5e8f\u9636\u6bb5\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u96be\u8d1f\u6837\u672c\u6316\u6398\u548c\u5047\u8d1f\u6837\u672c\u8fc7\u6ee4\u7684\u7ec6\u7c92\u5ea6\u76d1\u7ba1\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u80fd\u6709\u6548\u5f3a\u5316\u4e0a\u6e38\u68c0\u7d22\u5668\u7684\u53cd\u9988\u5faa\u73af\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTTE-v2-7B\u5728MMEB-V2\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e8675.7%\u7684\u65b0\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u800cTTE-v2-2B\u5219\u80fd\u591f\u5339\u654c\u751a\u81f3\u8d85\u8d8a\u4f7f\u7528\u663e\u8457\u66f4\u5927\u5916\u90e8\u6570\u636e\u8bad\u7ec3\u7684\u4e3b\u89817B\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u6309\u4ee4\u724c\u6269\u5c55\u4f5c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u53e6\u4e00\u79cd\u6269\u5c55\u8303\u5f0f\u6240\u5177\u6709\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.23736", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23736", "abs": "https://arxiv.org/abs/2602.23736", "authors": ["Ruixiang Qian", "Chunrong Fang", "Zengxu Chen", "Youxin Fu", "Zhenyu Chen"], "title": "Peeling Off the Cocoon: Unveiling Suppressed Golden Seeds for Mutational Greybox Fuzzing", "comment": "Accepted by OOPSLA 2026", "summary": "PoCo is a technique that aims to enhance modern coverage-based seed selection (CSS) techniques (such as afl-cmin) by gradually removing obstacle conditional statements and conducting deeper seed selection.", "AI": {"tldr": "PoCo\u6280\u672f\u65e8\u5728\u901a\u8fc7\u9010\u6b65\u79fb\u9664\u969c\u788d\u6761\u4ef6\u8bed\u53e5\u5e76\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u79cd\u5b50\u9009\u62e9\u6765\u6539\u8fdb\u73b0\u4ee3\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\uff08CSS\uff09\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u73b0\u6709\u7684\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\u6280\u672f\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u89e3\u51b3\u7531\u4e8e\u969c\u788d\u6761\u4ef6\u8bed\u53e5\u5bfc\u81f4\u7684\u9009\u62e9\u6df1\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9010\u6b65\u79fb\u9664\u969c\u788d\u6761\u4ef6\u8bed\u53e5\u7684\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u66f4\u6df1\u5c42\u6b21\u7684\u79cd\u5b50\u9009\u62e9\u8fc7\u7a0b\u3002", "result": "\u589e\u5f3a\u4e86\u73b0\u6709CSS\u6280\u672f\u7684\u80fd\u529b\uff0c\u5141\u8bb8\u66f4\u6df1\u5c42\u6b21\u5730\u63a2\u7d22\u7a0b\u5e8f\u8def\u5f84\u3002", "conclusion": "PoCo\u4e3a\u6539\u5584\u57fa\u4e8e\u8986\u76d6\u7387\u7684\u79cd\u5b50\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u7a0b\u5e8f\u903b\u8f91\u65f6\u3002"}}
{"id": "2602.23400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23400", "abs": "https://arxiv.org/abs/2602.23400", "authors": ["Zezheng Wu", "Rui Wang", "Xinghe Cheng", "Yang Shao", "Qing Yang", "Jiapu Wang", "Jingwei Zhang"], "title": "U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aU-CAN\u7684\u7cbe\u51c6\u9057\u5fd8\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5bf9\u6bd4\u6fc0\u6d3b\u6765\u91cf\u5316\u98ce\u9669\uff0c\u5e76\u5bf9\u654f\u611f\u6570\u636e\u8fdb\u884c\u9009\u62e9\u6027\u964d\u7ea7\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u7535\u8def\u7684\u62d3\u6251\u8fde\u901a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cU-CAN\u5728\u9690\u79c1\u9057\u5fd8\u3001\u6548\u7528\u4fdd\u7559\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\uff08GenRec\uff09\u901a\u5e38\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u4e2a\u6027\u5316\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6307\u4ee4\u9a71\u52a8\u7684\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u3002\u4f46\u662f\uff0c\u5728\u7528\u6237\u65e5\u5fd7\u4e0a\u5fae\u8c03\u65f6\u4f1a\u65e0\u610f\u4e2d\u5c06\u654f\u611f\u5c5e\u6027\u7f16\u7801\u5230\u6a21\u578b\u53c2\u6570\u4e2d\uff0c\u5f15\u53d1\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u95ee\u9898\u3002\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u6280\u672f\u56e0\u591a\u4e49\u56f0\u5883\u800c\u96be\u4ee5\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\uff0c\u5bfc\u81f4\u5728\u4f7f\u7528\u4f20\u7edf\u68af\u5ea6\u6216\u526a\u679d\u65b9\u6cd5\u65f6\u51fa\u73b0\u707e\u96be\u6027\u7684\u6548\u7528\u635f\u5931\u3002", "method": "\u63d0\u51fa\u4e86Utility-aware Contrastive AttenuatioN (U-CAN)\u6846\u67b6\uff0c\u4e00\u79cd\u57fa\u4e8e\u4f4e\u79e9\u9002\u914d\u5668\u7684\u7cbe\u51c6\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\u3002U-CAN\u901a\u8fc7\u5bf9\u6fc0\u6d3b\u60c5\u51b5\u8fdb\u884c\u5bf9\u6bd4\u6765\u8861\u91cf\u98ce\u9669\uff0c\u4e13\u6ce8\u4e8e\u90a3\u4e9b\u5bf9\u4e8e\u9057\u5fd8\u96c6\u5408\u9ad8\u5ea6\u654f\u611f\u4f46\u88ab\u6291\u5236\u5728\u4fdd\u7559\u96c6\u5408\u4e2d\u7684\u795e\u7ecf\u5143\u3002\u4e3a\u4e86\u4fdd\u62a4\u6027\u80fd\uff0c\u5f15\u5165\u4e86\u7ed3\u5408\u6743\u91cd\u5927\u5c0f\u4e0e\u4fdd\u7559\u96c6\u5408\u6fc0\u6d3b\u8303\u6570\u7684\u6548\u7528\u611f\u77e5\u6821\u51c6\u673a\u5236\uff0c\u7ed9\u5bf9\u4fdd\u7559\u6027\u80fd\u8d21\u732e\u5927\u7684\u7ef4\u5ea6\u5206\u914d\u66f4\u9ad8\u7684\u6548\u7528\u5206\u6570\u3002\u4e0d\u540c\u4e8e\u4e8c\u8fdb\u5236\u526a\u679d\uff0cU-CAN\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u8f6f\u8870\u51cf\uff0c\u91c7\u7528\u53ef\u5fae\u8870\u51cf\u51fd\u6570\u6709\u9009\u62e9\u5730\u4e0b\u8c03LoRA\u9002\u914d\u5668\u4e0a\u7684\u9ad8\u98ce\u9669\u53c2\u6570\uff0c\u6291\u5236\u654f\u611f\u68c0\u7d22\u8def\u5f84\u5e76\u7ef4\u6301\u63a8\u7406\u7535\u8def\u7684\u62d3\u6251\u8fde\u63a5\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u5c55\u793a\u4e86U-CAN\u5728\u4e03\u4e2a\u6307\u6807\u4e0a\u7684\u4f18\u8d8a\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u73b0\u5f3a\u5927\u9690\u79c1\u9057\u5fd8\u7684\u540c\u65f6\u8fd8\u80fd\u6709\u6548\u4fdd\u7559\u6a21\u578b\u6548\u7528\uff0c\u5e76\u4e14\u5177\u5907\u826f\u597d\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "U-CAN\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u663e\u8457\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5904\u7406\u7531\u4e2a\u4eba\u5316\u63a8\u8350\u7cfb\u7edf\u5e26\u6765\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002\u5b83\u4e0d\u4ec5\u80fd\u591f\u7cbe\u786e\u5730\u5220\u9664\u654f\u611f\u4fe1\u606f\uff0c\u540c\u65f6\u4e5f\u6210\u529f\u5730\u7ef4\u62a4\u4e86\u6a21\u578b\u7684\u6838\u5fc3\u529f\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002"}}
{"id": "2602.23999", "categories": ["cs.DB", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23999", "abs": "https://arxiv.org/abs/2602.23999", "authors": ["Jifan Shi", "Jianyang Gao", "James Xia", "Tam\u00e1s B\u00e9la Feh\u00e9r", "Cheng Long"], "title": "GPU-Native Approximate Nearest Neighbor Search with IVF-RaBitQ: Fast Index Build and Search", "comment": null, "summary": "Approximate nearest neighbor search (ANNS) on GPUs is gaining increasing popularity for modern retrieval and recommendation workloads that operate over massive high-dimensional vectors. Graph-based indexes deliver high recall and throughput but incur heavy build-time and storage costs. In contrast, cluster-based methods build and scale efficiently yet often need many probes for high recall, straining memory bandwidth and compute. Aiming to simultaneously achieve fast index build, high-throughput search, high recall, and low storage requirement for GPUs, we present IVF-RaBitQ (GPU), a GPU-native ANNS solution that integrates the cluster-based method IVF with RaBitQ quantization into an efficient GPU index build/search pipeline. Specifically, for index build, we develop a scalable GPU-native RaBitQ quantization method that enables fast and accurate low-bit encoding at scale. For search, we develop GPU-native distance computation schemes for RaBitQ codes and a fused search kernel to achieve high throughput with high recall. With IVF-RaBitQ implemented and integrated into the NVIDIA cuVS Library, experiments on cuVS Bench across multiple datasets show that IVF-RaBitQ offers a strong performance frontier in recall, throughput, index build time, and storage footprint. For Recall approximately equal to 0.95, IVF-RaBitQ achieves 2.2x higher QPS than the state-of-the-art graph-based method CAGRA, while also constructing indices 7.7x faster on average. Compared to the cluster-based method IVF-PQ, IVF-RaBitQ delivers on average over 2.7x higher throughput while avoiding accessing the raw vectors for reranking.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GPU\u539f\u751f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u89e3\u51b3\u65b9\u6848IVF-RaBitQ\uff0c\u5b83\u7ed3\u5408\u4e86\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5IVF\u548cRaBitQ\u91cf\u5316\u65b9\u6cd5\uff0c\u65e8\u5728\u540c\u65f6\u5b9e\u73b0\u5feb\u901f\u7d22\u5f15\u6784\u5efa\u3001\u9ad8\u541e\u5410\u91cf\u641c\u7d22\u3001\u9ad8\u53ec\u56de\u7387\u548c\u4f4e\u5b58\u50a8\u9700\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4fdd\u8bc1\u7ea60.95\u7684\u53ec\u56de\u7387\u65f6\uff0cIVF-RaBitQ\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5CAGRA\u5177\u67092.2\u500d\u7684\u66f4\u9ad8\u67e5\u8be2\u6bcf\u79d2(QPS)\uff0c\u5e76\u4e14\u5e73\u5747\u6784\u5efa\u7d22\u5f15\u901f\u5ea6\u63d0\u9ad8\u4e867.7\u500d\u3002", "motivation": "\u4e3a\u4e86\u5728GPU\u4e0a\u540c\u65f6\u8fbe\u5230\u5feb\u901f\u7d22\u5f15\u6784\u5efa\u3001\u9ad8\u541e\u5410\u91cf\u641c\u7d22\u3001\u9ad8\u53ec\u56de\u7387\u4ee5\u53ca\u4f4e\u5b58\u50a8\u8981\u6c42\u7684\u76ee\u6807\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u4e86\u8f83\u9ad8\u7684\u53ec\u56de\u7387\u548c\u541e\u5410\u91cf\u4f46\u6784\u5efa\u65f6\u95f4\u548c\u5b58\u50a8\u6210\u672c\u8f83\u9ad8\uff1b\u800c\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5\u867d\u7136\u5728\u6784\u5efa\u6548\u7387\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u9ad8\u53ec\u56de\u7387\u65f6\u5f80\u5f80\u56e0\u5927\u91cf\u67e5\u8be2\u64cd\u4f5c\u800c\u5bf9\u5185\u5b58\u5e26\u5bbd\u548c\u8ba1\u7b97\u80fd\u529b\u9020\u6210\u538b\u529b\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86IVF-RaBitQ (GPU)\u8fd9\u4e00GPU\u539f\u751fANNS\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5c06\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5IVF\u4e0eRaBitQ\u91cf\u5316\u76f8\u7ed3\u5408\u3002\u5bf9\u4e8e\u7d22\u5f15\u6784\u5efa\u8fc7\u7a0b\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684GPU\u539f\u751fRaBitQ\u91cf\u5316\u65b9\u6cd5\u6765\u652f\u6301\u5927\u89c4\u6a21\u4e0b\u7684\u5feb\u901f\u51c6\u786e\u4f4e\u4f4d\u7f16\u7801\uff1b\u800c\u5728\u641c\u7d22\u9636\u6bb5\uff0c\u5219\u8bbe\u8ba1\u4e86\u9488\u5bf9RaBitQ\u7801\u7684\u8ddd\u79bb\u8ba1\u7b97\u65b9\u6848\u53ca\u878d\u5408\u641c\u7d22\u5185\u6838\u4ee5\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u3002", "result": "\u901a\u8fc7\u5c06IVF-RaBitQ\u96c6\u6210\u5230NVIDIA cuVS\u5e93\u4e2d\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u540e\u53d1\u73b0\uff0c\u8be5\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u3001\u541e\u5410\u91cf\u3001\u7d22\u5f15\u6784\u5efa\u65f6\u95f4\u548c\u5b58\u50a8\u5360\u7528\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002\u7279\u522b\u662f\u5f53\u53ec\u56de\u7387\u7ea6\u4e3a0.95\u65f6\uff0c\u76f8\u6bd4\u6700\u65b0\u7684\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5CAGRA\uff0cIVF-RaBitQ\u5b9e\u73b0\u4e862.2\u500d\u66f4\u9ad8\u7684QPS\uff0c\u5e76\u4e14\u5e73\u5747\u800c\u8a00\u80fd\u591f\u5c06\u7d22\u5f15\u6784\u5efa\u901f\u5ea6\u52a0\u5feb7.7\u500d\u3002", "conclusion": "IVF-RaBitQ\u4f5c\u4e3a\u4e00\u9879\u521b\u65b0\u6027\u7684GPU\u539f\u751fANNS\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u5730\u5728\u591a\u79cd\u5173\u952e\u6027\u80fd\u6307\u6807\u4e4b\u95f4\u627e\u5230\u4e86\u5e73\u8861\u70b9\uff0c\u4e3a\u73b0\u4ee3\u68c0\u7d22\u548c\u63a8\u8350\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u5411\u91cf\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.23409", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.23409", "abs": "https://arxiv.org/abs/2602.23409", "authors": ["Michael Poppel", "Jonas Stein", "Sebastian W\u00f6lckert", "Markus Baumann", "Claudia Linnhoff-Popien"], "title": "Long Range Frequency Tuning for QML", "comment": null, "summary": "Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u9891\u7387\u53ef\u8c03\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u8fdb\u5236\u7f16\u7801\u7684\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4ece\u800c\u5728\u5408\u6210\u76ee\u6807\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u9891\u7387\u53ef\u8c03\u65b9\u6cd5\u7684\u5b9e\u9645\u6709\u6548\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u68af\u5ea6\u4f18\u5316\u65e0\u6cd5\u5c06\u7cfb\u6570\u9a71\u52a8\u5230\u4efb\u610f\u76ee\u6807\u503c\u65f6\u9047\u5230\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u63ed\u793a\u9891\u7387\u7cfb\u6570\u7684\u6709\u9650\u53ef\u8bad\u7ec3\u6027\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u8fdb\u5236\u7f16\u7801\u7684\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u5bc6\u96c6\u6574\u6570\u9891\u7387\u8c31\uff0c\u786e\u4fdd\u76ee\u6807\u9891\u7387\u4f4d\u4e8e\u5c40\u90e8\u53ef\u8fbe\u8303\u56f4\u5185\u3002", "result": "\u5bf9\u4e8e\u5305\u542b\u4e09\u4e2a\u504f\u79fb\u9ad8\u9891\u7684\u5408\u6210\u76ee\u6807\uff0c\u4e09\u8fdb\u5236\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\u8fbe\u5230\u4e860.9969\u7684R^2\u5206\u6570\uff0c\u800c\u9891\u7387\u53ef\u8c03\u57fa\u7ebf\u4ec5\u4e3a0.1841\uff1b\u5728Flight Passengers\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u9891\u7387\u53ef\u8c03\u521d\u59cb\u5316\u63d0\u9ad8\u4e8622.8%\u7684R^2\u5206\u6570\uff08\u4ece0.7876\u63d0\u9ad8\u5230\u4e860.9671\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u8fdb\u5236\u7f51\u683c\u521d\u59cb\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u9891\u7387\u53ef\u8c03\u65b9\u6cd5\u4e2d\u7684\u9891\u7387\u53ef\u8fbe\u6027\u9650\u5236\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6a21\u62df\u4e0e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2602.23504", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23504", "abs": "https://arxiv.org/abs/2602.23504", "authors": ["Anik Pramanik", "Murat Kantarcioglu", "Vincent Oria", "Shantanu Sharma"], "title": "FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments", "comment": "This paper has been accepted in ICLR 2026", "summary": "Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.", "AI": {"tldr": "FedDAG\u662f\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u548c\u68af\u5ea6\u4fe1\u606f\u6765\u8861\u91cf\u5ba2\u6237\u7aef\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\u4fc3\u8fdb\u8de8\u96c6\u7fa4\u7279\u5f81\u8fc1\u79fb\uff0c\u4ece\u800c\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u4e8e\u6570\u636e\u76f8\u4f3c\u6027\u6216\u68af\u5ea6\u76f8\u4f3c\u6027\u6765\u8bc4\u4f30\u5ba2\u6237\u7aef\u76f8\u4f3c\u6027\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u591f\u5168\u9762\uff1b\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u9650\u5236\u4e86\u77e5\u8bc6\u4e0e\u8868\u793a\u5171\u4eab\u7ed9\u540c\u4e00\u96c6\u7fa4\u5185\u7684\u5ba2\u6237\u7aef\uff0c\u963b\u788d\u4e86\u6a21\u578b\u4ece\u4e0d\u540c\u96c6\u7fa4\u95f4\u7684\u591a\u6837\u5316\u5ba2\u6237\u7aef\u7fa4\u4f53\u4e2d\u83b7\u76ca\u3002", "method": "FedDAG\u63d0\u51fa\u4e86\u4e00\u79cd\u52a0\u6743\u7684\u3001\u57fa\u4e8e\u7c7b\u522b\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u6807\u51c6\uff0c\u8be5\u6807\u51c6\u6574\u5408\u4e86\u6570\u636e\u4e0e\u68af\u5ea6\u4fe1\u606f\uff0c\u4ee5\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u7528\u4e8e\u805a\u7c7b\u8fc7\u7a0b\u3002\u540c\u65f6\uff0cFedDAG\u5229\u7528\u4e86\u4e00\u4e2a\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5176\u4e2d\u4e00\u4e2a\u4e3b\u7f16\u7801\u5668\u4f7f\u7528\u81ea\u5df1\u5ba2\u6237\u7aef\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u6b21\u7ea7\u7f16\u7801\u5668\u5219\u901a\u8fc7\u6765\u81ea\u4e92\u8865\u96c6\u7fa4\u7684\u68af\u5ea6\u4fe1\u606f\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u6b64\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7684\u7279\u5f81\u8f6c\u79fb\u540c\u65f6\u4e5f\u4fdd\u6301\u4e86\u96c6\u7fa4\u7279\u5b9a\u7684\u4e13\u4e1a\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u591a\u6837\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u6570\u636e\u5f02\u8d28\u6027\u8bbe\u7f6e\u4e0b\uff0cFedDAG\u5728\u51c6\u786e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedDAG\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u5f0f\u53ca\u521b\u65b0\u6027\u7684\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e3a\u5904\u7406\u975e\u540c\u6784\u5ba2\u6237\u6570\u636e\u63d0\u4f9b\u4e86\u66f4\u4f18\u89e3\u3002"}}
{"id": "2602.24271", "categories": ["cs.DB", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.24271", "abs": "https://arxiv.org/abs/2602.24271", "authors": ["Boram Jung", "Yuliang Li", "Hung-Wei Tseng"], "title": "NSHEDB: Noise-Sensitive Homomorphic Encrypted Database Query Engine", "comment": null, "summary": "Homomorphic encryption (HE) enables computations directly on encrypted data, offering strong cryptographic guarantees for secure and privacy-preserving data storage and query execution. However, despite its theoretical power, practical adoption of HE in database systems remains limited due to extreme cipher-text expansion, memory overhead, and the computational cost of bootstrapping, which resets noise levels for correctness.\n  This paper presents NSHEDB, a secure query processing engine designed to address these challenges at the system architecture level. NSHEDB uses word-level leveled HE (LHE) based on the BFV scheme to minimize ciphertext expansion and avoid costly bootstrapping. It introduces novel techniques for executing equality, range, and aggregation operations using purely homomorphic computation, without transciphering between different HE schemes (e.g., CKKS/BFV/TFHE) or relying on trusted hardware. Additionally, it incorporates a noise-aware query planner to extend computation depth while preserving security guarantees.\n  We implement and evaluate NSHEDB on real-world database workloads (TPC-H) and show that it achieves 20x-V1370x speedup and a 73x storage reduction compared to state-of-the-art HE-based systems, while upholding 128-bit security in a semi-honest model with no key release or trusted components.", "AI": {"tldr": "NSHEDB, a secure query processing engine, utilizes word-level leveled homomorphic encryption (LHE) to reduce ciphertext expansion and avoid bootstrapping, enabling efficient equality, range, and aggregation operations on encrypted data with 20x-1370x speedup and 73x storage reduction over current HE-based systems.", "motivation": "\u5c3d\u7ba1\u540c\u6001\u52a0\u5bc6(HE)\u7406\u8bba\u4e0a\u80fd\u591f\u76f4\u63a5\u5bf9\u52a0\u5bc6\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\uff0c\u4ece\u800c\u63d0\u4f9b\u5f3a\u5927\u7684\u52a0\u5bc6\u4fdd\u8bc1\u4ee5\u5b9e\u73b0\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u6570\u636e\u5b58\u50a8\u4e0e\u67e5\u8be2\u6267\u884c\uff0c\u4f46\u5176\u5728\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ecd\u53d7\u5230\u6781\u5927\u7684\u9650\u5236\uff0c\u4e3b\u8981\u7531\u4e8e\u5bc6\u6587\u6269\u5c55\u3001\u5185\u5b58\u5f00\u9500\u4ee5\u53ca\u91cd\u7f6e\u566a\u58f0\u6c34\u5e73\u4ee5\u786e\u4fdd\u6b63\u786e\u6027\u7684\u81ea\u4e3e\u8fd0\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "NSHEDB\u91c7\u7528\u57fa\u4e8eBFV\u65b9\u6848\u7684\u5b57\u7ea7\u5206\u5c42HE\uff08LHE\uff09\u6765\u6700\u5c0f\u5316\u5bc6\u6587\u6269\u5c55\u5e76\u907f\u514d\u6602\u8d35\u7684\u81ea\u4e3e\u8fc7\u7a0b\u3002\u5b83\u5f15\u5165\u4e86\u5168\u65b0\u7684\u6280\u672f\u7528\u4e8e\u7eaf\u540c\u6001\u8ba1\u7b97\u4e0b\u7684\u7b49\u503c\u3001\u8303\u56f4\u53ca\u805a\u5408\u64cd\u4f5c\u6267\u884c\uff0c\u65e0\u9700\u5728\u4e0d\u540cHE\u65b9\u6848\u95f4\u8f6c\u6362\u5bc6\u6587\u6216\u4f9d\u8d56\u53ef\u4fe1\u786c\u4ef6\u3002\u6b64\u5916\uff0c\u8fd8\u6574\u5408\u4e86\u4e00\u4e2a\u566a\u58f0\u611f\u77e5\u67e5\u8be2\u89c4\u5212\u5668\uff0c\u65e8\u5728\u589e\u52a0\u8ba1\u7b97\u6df1\u5ea6\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5e93\u5de5\u4f5c\u8d1f\u8f7d(TPC-H)\u4e0a\u7684\u5b9e\u73b0\u4e0e\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u4e8eHE\u7684\u7cfb\u7edf\uff0cNSHEDB\u8fbe\u5230\u4e8620\u500d\u81f31370\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c73\u500d\u7684\u5b58\u50a8\u51cf\u5c11\uff0c\u5e76\u4e14\u5728\u534a\u8bda\u5b9e\u6a21\u578b\u4e0b\u7ef4\u6301\u4e86128\u4f4d\u7684\u5b89\u5168\u6027\uff0c\u6ca1\u6709\u5bc6\u94a5\u91ca\u653e\u6216\u4fe1\u4efb\u7ec4\u4ef6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\u67b6\u6784\u5c42\u9762\u89e3\u51b3\u65b9\u6cd5\u2014\u2014NSHEDB\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u540c\u6001\u52a0\u5bc6\u5e94\u7528\u4e8e\u6570\u636e\u5e93\u65f6\u9762\u4e34\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u901f\u5ea6\u548c\u51cf\u5c11\u4e86\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u4e5f\u4fdd\u8bc1\u4e86\u9ad8\u6c34\u5e73\u7684\u6570\u636e\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2602.23372", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23372", "abs": "https://arxiv.org/abs/2602.23372", "authors": ["Qizhi Wang"], "title": "Democratizing GraphRAG: Linear, CPU-Only Graph Retrieval for Multi-Hop QA", "comment": "13 pages, 14 figures, 26 tables", "summary": "GraphRAG systems improve multi-hop retrieval by modeling structure, but many approaches rely on expensive LLM-based graph construction and GPU-heavy inference. We present SPRIG (Seeded Propagation for Retrieval In Graphs), a CPU-only, linear-time, token-free GraphRAG pipeline that replaces LLM graph building with lightweight NER-driven co-occurrence graphs and uses Personalized PageRank (PPR) for 28% with negligible Recall@10 changes. The results characterize when CPU-friendly graph retrieval helps multi-hop recall and when strong lexical hybrids (RRF) are sufficient, outlining a realistic path to democratizing GraphRAG without token costs or GPU requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPRIG\u7684\u4ec5\u4f7f\u7528CPU\u3001\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u4e14\u65e0\u9700token\u7684GraphRAG\u6d41\u7a0b\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u7ea7NER\u9a71\u52a8\u7684\u5171\u73b0\u56fe\u66ff\u4ee3\u4e86\u57fa\u4e8eLLM\u7684\u56fe\u6784\u5efa\uff0c\u5e76\u5229\u7528\u4e2a\u6027\u5316PageRank\u7b97\u6cd5\u63d0\u9ad8\u4e86\u591a\u8df3\u68c0\u7d22\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u8fd1\u7684\u53ec\u56de\u7387\u3002", "motivation": "\u5f53\u524d\u8bb8\u591aGraphRAG\u7cfb\u7edf\u867d\u7136\u80fd\u591f\u6539\u5584\u591a\u8df3\u68c0\u7d22\u6027\u80fd\uff0c\u4f46\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6210\u672c\u9ad8\u6602\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u56fe\u6784\u5efa\u4ee5\u53ca\u9700\u8981\u5927\u91cfGPU\u8d44\u6e90\u8fdb\u884c\u63a8\u7406\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4f7f\u5f97GraphRAG\u6280\u672f\u66f4\u52a0\u666e\u53ca\u5316\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u4e3a\u9ad8\u6548\u4e14\u6613\u4e8e\u5b9e\u73b0\u7684\u65b0\u65b9\u6848\u3002", "method": "\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u4e86\u4e00\u4e2a\u88ab\u79f0\u4e3aSPRIG\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5b8c\u5168\u57fa\u4e8eCPU\u8fd0\u884c\uff0c\u5177\u6709\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u4efb\u4f55token\u3002SPRIG\u91c7\u7528\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u6280\u672f\u751f\u6210\u8f7b\u91cf\u7ea7\u7684\u5171\u73b0\u56fe\u6765\u4ee3\u66ff\u590d\u6742\u7684\u57fa\u4e8eLLM\u7684\u56fe\u6784\u9020\u8fc7\u7a0b\uff1b\u63a5\u7740\uff0c\u8fd0\u7528\u4e2a\u6027\u5316PageRank\u7b97\u6cd5\u5b8c\u6210\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4e0d\u663e\u8457\u5f71\u54cdRecall@10\u7684\u60c5\u51b5\u4e0b\uff0cSPRIG\u80fd\u591f\u5c06\u591a\u8df3\u68c0\u7d22\u6027\u80fd\u63d0\u9ad828%\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u5728\u4f55\u79cd\u60c5\u51b5\u4e0bCPU\u53cb\u597d\u7684\u56fe\u5f62\u68c0\u7d22\u5bf9\u589e\u5f3a\u591a\u8df3\u53ec\u56de\u7387\u7279\u522b\u6709\u6548\uff0c\u4ee5\u53ca\u4f55\u65f6\u5f3a\u5927\u7684\u8bcd\u6c47\u6df7\u5408\u7b56\u7565\u5df2\u7ecf\u8db3\u591f\u597d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u65e0\u9700\u9ad8\u6602\u8ba1\u7b97\u6210\u672c\u6216GPU\u652f\u6301\u6761\u4ef6\u4e0b\u63a8\u5e7fGraphRAG\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u8def\u5f84\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u521b\u65b0\u6027\u7684\u975eLLM\u4f9d\u8d56\u578b\u56fe\u6784\u5efa\u53ca\u68c0\u7d22\u673a\u5236\u2014\u2014SPRIG\uff0c\u4e0d\u4ec5\u964d\u4f4e\u4e86\u786c\u4ef6\u8981\u6c42\uff0c\u540c\u65f6\u4e5f\u4fdd\u8bc1\u4e86\u8f83\u9ad8\u7684\u68c0\u7d22\u8d28\u91cf\u3002"}}
{"id": "2602.23410", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.23410", "abs": "https://arxiv.org/abs/2602.23410", "authors": ["Hanning Guo", "Farah Abdellatif", "Hanwen Bi", "Andrei Galbenus", "Jon. N. Shah", "Abigail Morrison", "J\u00fcrgen Dammers"], "title": "Brain-OF: An Omnifunctional Foundation Model for fMRI, EEG and MEG", "comment": null, "summary": "Brain foundation models have achieved remarkable advances across a wide range of neuroscience tasks. However, most existing models are limited to a single functional modality, restricting their ability to exploit complementary spatiotemporal dynamics and the collective data scale across imaging techniques. To address this limitation, we propose Brain-OF, the first omnifunctional brain foundation model jointly pretrained on fMRI, EEG and MEG, capable of handling both unimodal and multimodal inputs within a unified framework. To reconcile heterogeneous spatiotemporal resolutions, we introduce the Any-Resolution Neural Signal Sampler, which projects diverse brain signals into a shared semantic space.To further manage semantic shifts, the Brain-OF backbone integrates DINT attention with a Sparse Mixture of Experts, where shared experts capture modality-invariant representations and routed experts specialize in modality-specific semantics. Furthermore, we propose Masked Temporal-Frequency Modeling, a dual-domain pretraining objective that jointly reconstructs brain signals in both the time and frequency domains. Brain-OF is pretrained on a large-scale corpus comprising around 40 datasets and demonstrates superior performance across diverse downstream tasks, highlighting the benefits of joint multimodal integration and dual-domain pretraining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Brain-OF\uff0c\u9996\u4e2a\u80fd\u591f\u5904\u7406fMRI\u3001EEG\u548cMEG\u6570\u636e\u7684\u5168\u529f\u80fd\u8111\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u4efb\u610f\u5206\u8fa8\u7387\u795e\u7ecf\u4fe1\u53f7\u91c7\u6837\u5668\u3001DINT\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u4f53\u4ee5\u53ca\u63a9\u7801\u65f6\u9891\u5efa\u6a21\u65b9\u6cd5\u6765\u5b9e\u73b0\u8de8\u6a21\u6001\u7684\u6570\u636e\u6574\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u591a\u6570\u8111\u57fa\u7840\u6a21\u578b\u4ec5\u9650\u4e8e\u5355\u4e00\u529f\u80fd\u6a21\u6001\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5229\u7528\u8de8\u6210\u50cf\u6280\u672f\u4e92\u8865\u7684\u7a7a\u95f4\u65f6\u95f4\u52a8\u6001\u548c\u96c6\u4f53\u6570\u636e\u89c4\u6a21\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u5904\u7406\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u8f93\u5165\u7684\u5168\u529f\u80fd\u8111\u57fa\u7840\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBrain-OF\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u8054\u5408\u9884\u8bad\u7ec3\u4e86fMRI\u3001EEG\u548cMEG\u7b49\u4e0d\u540c\u7c7b\u578b\u7684\u8111\u4fe1\u53f7\uff1b\u5f15\u5165\u4e86Any-Resolution Neural Signal Sampler\u7528\u4e8e\u5c06\u4e0d\u540c\u7684\u8111\u4fe1\u53f7\u6295\u5f71\u5230\u4e00\u4e2a\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\u4e2d\uff1b\u91c7\u7528\u4e86\u7ed3\u5408DINT\u6ce8\u610f\u529b\u673a\u5236\u4e0eSparse Mixture of Experts\u7684\u8bbe\u8ba1\u6765\u7ba1\u7406\u8bed\u4e49\u504f\u79fb\uff1b\u8fd8\u63d0\u51fa\u4e86Masked Temporal-Frequency Modeling\u4f5c\u4e3a\u53cc\u57df\u9884\u8bad\u7ec3\u76ee\u6807\u3002", "result": "Brain-OF\u5728\u5927\u7ea640\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9884\u8bad\u7ec3\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8054\u5408\u591a\u6a21\u6001\u96c6\u6210\u548c\u53cc\u57df\u9884\u8bad\u7ec3\u7684\u4f18\u52bf\u3002", "conclusion": "Brain-OF\u4ee3\u8868\u4e86\u671d\u5411\u66f4\u5f3a\u5927\u3001\u7075\u6d3b\u7684\u8111\u79d1\u5b66\u5e94\u7528\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u5b83\u80fd\u591f\u6709\u6548\u878d\u5408\u591a\u79cd\u7c7b\u578b\u7684\u8111\u6d3b\u52a8\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u521b\u65b0\u6027\u7684\u67b6\u6784\u8bbe\u8ba1\u514b\u670d\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u9650\u5236\u3002"}}
{"id": "2602.23374", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23374", "abs": "https://arxiv.org/abs/2602.23374", "authors": ["Weixi Lin"], "title": "Higress-RAG: A Holistic Optimization Framework for Enterprise Retrieval-Augmented Generation via Dual Hybrid Retrieval, Adaptive Routing, and CRAG", "comment": "7 pages,5 figures, our submissions are not yet published", "summary": "The integration of Large Language Models (LLMs) into enterprise knowledge management systems has been catalyzed by the Retrieval-Augmented Generation (RAG) paradigm, which augments parametric memory with non-parametric external data. However, the transition from proof-of-concept to production-grade RAG systems is hindered by three persistent challenges: low retrieval precision for complex queries, high rates of hallucination in the generation phase, and unacceptable latency for real-time applications. This paper presents a comprehensive analysis of the Higress RAG MCP Server, a novel, enterprise-centric architecture designed to resolve these bottlenecks through a \"Full-Link Optimization\" strategy. Built upon the Model Context Protocol (MCP), the system introduces a layered architecture that orchestrates a sophisticated pipeline of Adaptive Routing, Semantic Caching, Hybrid Retrieval, and Corrective RAG (CRAG). We detail the technical implementation of key innovations, including the Higress-Native Splitter for structure-aware data ingestion, the application of Reciprocal Rank Fusion (RRF) for merging dense and sparse retrieval signals, and a 50ms-latency Semantic Caching mechanism with dynamic thresholding. Experimental evaluations on domain-specific Higress technical documentation and blogs verify the system's architectural robustness. The results demonstrate that by optimizing the entire retrieval lifecycle - from pre-retrieval query rewriting to post-retrieval corrective evaluation - the Higress RAG system offers a scalable, hallucination-resistant solution for enterprise AI deployment.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Higress RAG MCP\u670d\u52a1\u5668\uff0c\u8fd9\u662f\u4e00\u79cd\u65e8\u5728\u901a\u8fc7\"\u5168\u94fe\u8def\u4f18\u5316\"\u7b56\u7565\u89e3\u51b3\u4ece\u6982\u5ff5\u9a8c\u8bc1\u5230\u751f\u4ea7\u7ea7RAG\u7cfb\u7edf\u8fc7\u6e21\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u4e3b\u8981\u6311\u6218\uff08\u68c0\u7d22\u7cbe\u5ea6\u4f4e\u3001\u751f\u6210\u9636\u6bb5\u5e7b\u89c9\u7387\u9ad8\u548c\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u4e0d\u53ef\u63a5\u53d7\uff09\u7684\u4f01\u4e1a\u7ea7\u67b6\u6784\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4f01\u4e1a\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u96c6\u6210\u9762\u4e34\u7684\u95ee\u9898\u5305\u62ec\uff1a\u590d\u6742\u67e5\u8be2\u7684\u68c0\u7d22\u7cbe\u5ea6\u4f4e\u3001\u751f\u6210\u9636\u6bb5\u51fa\u73b0\u5927\u91cf\u5e7b\u89c9\u4ee5\u53ca\u5bf9\u4e8e\u5b9e\u65f6\u5e94\u7528\u800c\u8a00\u5ef6\u8fdf\u8fc7\u9ad8\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHigress RAG MCP Server\u7684\u65b0\u67b6\u6784\uff0c\u5b83\u57fa\u4e8eModel Context Protocol\u5e76\u901a\u8fc7\u4e00\u7cfb\u5217\u521b\u65b0\u6280\u672f\u5982\u81ea\u9002\u5e94\u8def\u7531\u3001\u8bed\u4e49\u7f13\u5b58\u3001\u6df7\u5408\u68c0\u7d22\u53ca\u7ea0\u6b63\u6027RAG\u7b49\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u6b64\u5916\u8fd8\u8be6\u7ec6\u63cf\u8ff0\u4e86\u51e0\u4e2a\u5173\u952e\u6280\u672f\u5b9e\u73b0\uff0c\u6bd4\u5982Higress-Native Splitter\u7528\u4e8e\u7ed3\u6784\u611f\u77e5\u7684\u6570\u636e\u6444\u5165\u3001Reciprocal Rank Fusion (RRF)\u7528\u4e8e\u5408\u5e76\u5bc6\u96c6\u578b\u548c\u7a00\u758f\u578b\u68c0\u7d22\u4fe1\u53f7\u4ee5\u53ca\u4e00\u4e2a\u5177\u6709\u52a8\u6001\u9608\u503c\u8bbe\u7f6e\u768450\u6beb\u79d2\u5ef6\u8fdf\u8bed\u4e49\u7f13\u5b58\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u6574\u4e2a\u68c0\u7d22\u751f\u547d\u5468\u671f\u8fdb\u884c\u4f18\u5316\u2014\u2014\u4ece\u524d\u68c0\u7d22\u67e5\u8be2\u91cd\u5199\u5230\u540e\u68c0\u7d22\u7ea0\u6b63\u8bc4\u4ef7\u2014\u2014Higress RAG\u7cfb\u7edf\u4e3a\u4f01\u4e1aAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6297\u5e7b\u89c9\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Higress RAG MCP\u670d\u52a1\u5668\u901a\u8fc7\u5176\u72ec\u7279\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6574\u5408\u8fdb\u4f01\u4e1a\u73af\u5883\u65f6\u9762\u4e34\u7684\u51e0\u5927\u96be\u9898\uff0c\u4e3a\u5b9e\u73b0\u66f4\u9ad8\u6548\u51c6\u786e\u7684\u77e5\u8bc6\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2602.23413", "categories": ["cs.LG", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.23413", "abs": "https://arxiv.org/abs/2602.23413", "authors": ["Shu Liu", "Shubham Agarwal", "Monishwaran Maheswaran", "Mert Cemri", "Zhifei Li", "Qiuyang Mang", "Ashwin Naren", "Ethan Boneh", "Audrey Cheng", "Melissa Z. Pan", "Alexander Du", "Kurt Keutzer", "Alexandros G. Dimakis", "Koushik Sen", "Matei Zaharia", "Ion Stoica"], "title": "EvoX: Meta-Evolution for Automated Discovery", "comment": null, "summary": "Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u8fdb\u5316\u65b9\u6cd5EvoX\uff0c\u5b83\u80fd\u591f\u4f18\u5316\u81ea\u8eab\u7684\u8fdb\u5316\u8fc7\u7a0b\uff0c\u5e76\u5728\u8fd1200\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684AI\u9a71\u52a8\u7684\u8fdb\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4f18\u5316\u4e0e\u8fdb\u5316\u641c\u7d22\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9759\u6001\u7684\u641c\u7d22\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u65e0\u6cd5\u5f88\u597d\u5730\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u6216\u540c\u4e00\u4efb\u52a1\u4e2d\u7684\u53d8\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86EvoX\uff0c\u4e00\u79cd\u53ef\u4ee5\u81ea\u6211\u4f18\u5316\u5176\u8fdb\u5316\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "EvoX\u540c\u65f6\u8fdb\u5316\u5019\u9009\u89e3\u51b3\u65b9\u6848\u548c\u7528\u4e8e\u751f\u6210\u8fd9\u4e9b\u65b9\u6848\u7684\u641c\u7d22\u7b56\u7565\uff0c\u57fa\u4e8e\u8fdb\u5c55\u6301\u7eed\u66f4\u65b0\u5148\u524d\u89e3\u7684\u9009\u62e9\u548c\u53d8\u5f02\u65b9\u5f0f\u3002\u8fd9\u6837\u7684\u8bbe\u8ba1\u5141\u8bb8\u7cfb\u7edf\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u52a8\u6001\u5730\u5207\u6362\u4e0d\u540c\u7684\u641c\u7d22\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728\u63a5\u8fd1200\u4e2a\u5b9e\u9645\u4f18\u5316\u4efb\u52a1\u4e0a\u7684\u6d4b\u8bd5\uff0cEvoX\u5728\u5927\u90e8\u5206\u4efb\u52a1\u4e0a\u8d85\u8fc7\u4e86\u5305\u62ecAlphaEvolve\u3001OpenEvolve\u3001GEPA\u53caShinkaEvolve\u5728\u5185\u7684\u73b0\u6709AI\u9a71\u52a8\u8fdb\u5316\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "EvoX\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u52a0\u7075\u6d3b\u4e14\u6709\u6548\u7684\u9014\u5f84\u6765\u6267\u884cAI\u9a71\u52a8\u7684\u8fdb\u5316\u641c\u7d22\uff0c\u5bf9\u4e8e\u9700\u8981\u4e0d\u65ad\u8c03\u6574\u641c\u7d22\u7b56\u7565\u4ee5\u5e94\u5bf9\u590d\u6742\u591a\u53d8\u60c5\u51b5\u7684\u4efb\u52a1\u5c24\u5176\u6709\u7528\u3002"}}
{"id": "2602.23798", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23798", "abs": "https://arxiv.org/abs/2602.23798", "authors": ["Tiantong Wang", "Xinyu Yan", "Tiantong Wu", "Yurong Hao", "Yong Jiang", "Fei Huang", "Wei Yang Bryan Lim"], "title": "MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models", "comment": null, "summary": "Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMPU\u7684\u9690\u79c1\u4fdd\u62a4\u591a\u6270\u52a8\u526f\u672c\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u670d\u52a1\u5668\u7aef\u5f15\u5165\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u6a21\u5757\uff0c\u5141\u8bb8\u5ba2\u6237\u7aef\u5728\u5176\u79c1\u6709\u7684\u9057\u5fd8\u96c6\u4e0a\u672c\u5730\u6267\u884c\u9057\u5fd8\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u65e0\u566a\u58f0\u57fa\u7ebf\u76f8\u5f53\u7684\u9057\u5fd8\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u9057\u5fd8\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u9690\u79c1\u56f0\u5883\uff0c\u5373\u4e25\u683c\u7684\u7ea6\u675f\u7981\u6b62\u5171\u4eab\u670d\u52a1\u5668\u53c2\u6570\u6216\u5ba2\u6237\u7aef\u7684\u9057\u5fd8\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b97\u6cd5\u65e0\u5173\u7684\u9690\u79c1\u4fdd\u62a4\u591a\u6270\u52a8\u526f\u672c\u9057\u5fd8\u6846\u67b6MPU\uff0c\u8be5\u6846\u67b6\u4e3b\u8981\u5f15\u5165\u4e86\u4e24\u4e2a\u670d\u52a1\u5668\u7aef\u6a21\u5757\uff1a\u9884\u5904\u7406\u7528\u4e8e\u751f\u6210\u968f\u673a\u5316\u7684\u526f\u672c\uff0c\u540e\u5904\u7406\u7528\u4e8e\u901a\u8fc7\u8c03\u548c\u53bb\u566a\u7a0b\u5e8f\u805a\u5408\u66f4\u65b0\u4ee5\u51cf\u8f7b\u6270\u52a8\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMPU\u80fd\u591f\u5b9e\u73b0\u4e0e\u65e0\u566a\u58f0\u57fa\u7ebf\u76f8\u5ab2\u7f8e\u7684\u9057\u5fd8\u6027\u80fd\uff0c\u5bf9\u4e8e\u5927\u591a\u6570\u7b97\u6cd5\u800c\u8a00\uff0c\u572810%\u566a\u58f0\u4e0b\u5e73\u5747\u9000\u5316\u8fdc\u4f4e\u4e8e1%\uff0c\u751a\u81f3\u57281%\u566a\u58f0\u6761\u4ef6\u4e0b\u5bf9\u67d0\u4e9b\u7b97\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u65e0\u566a\u58f0\u57fa\u7ebf\u3002", "conclusion": "MPU\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u673a\u5668\u9057\u5fd8\u4e2d\u7684\u9690\u79c1\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u9057\u5fd8\u6548\u679c\u3002"}}
{"id": "2602.23957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23957", "abs": "https://arxiv.org/abs/2602.23957", "authors": ["Alexander Berndt", "Zolt\u00e1n Nochta", "Thomas Bach"], "title": "The Vocabulary of Flaky Tests in the Context of SAP HANA", "comment": "Accepted to ESEM IGC 2023", "summary": "Background. Automated test execution is an important activity to gather information about the quality of a software project. So-called flaky tests, however, negatively affect this process. Such tests fail seemingly at random without changes to the code and thus do not provide a clear signal. Previous work proposed to identify flaky tests based on the source code identifiers in the test code. So far, these approaches have not been evaluated in a large-scale industrial setting. Aims. We evaluate approaches to identify flaky tests and their root causes based on source code identifiers in the test code in a large-scale industrial project. Method. First, we replicate previous work by Pinto et al. in the context of SAP HANA. Second, we assess different feature extraction techniques, namely TF-IDF and TF-IDFC-RF. Third, we evaluate CodeBERT and XGBoost as classification models. For a sound comparison, we utilize both the data set from previous work and two data sets from SAP HANA. Results. Our replication shows similar results on the original data set and on one of the SAP HANA data sets. While the original approach yielded an F1-Score of 0.94 on the original data set and 0.92 on the SAP HANA data set, our extensions achieve F1-Scores of 0.96 and 0.99, respectively. The reliance on external data sources is a common root cause for test flakiness in the context of SAP HANA. Conclusions. The vocabulary of a large industrial project seems to be slightly different with respect to the exact terms, but the categories for the terms, such as remote dependencies, are similar to previous empirical findings. However, even with rather large F1-Scores, both finding source code identifiers for flakiness and a black box prediction have limited use in practice as the results are not actionable for developers.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u5927\u578b\u5de5\u4e1a\u9879\u76eeSAP HANA\u4e2d\u8bc4\u4f30\u4e86\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u6765\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u53ca\u5176\u6839\u672c\u539f\u56e0\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u590d\u5236Pinto\u7b49\u4eba\u7684\u5148\u524d\u5de5\u4f5c\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff08TF-IDF\u548cTF-IDFC-RF\uff09\u4ee5\u53ca\u5206\u7c7b\u6a21\u578b\uff08CodeBERT\u548cXGBoost\uff09\uff0c\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u53d6\u5f97\u4e86\u8f83\u9ad8\u7684F1\u5206\u6570\uff08\u6700\u9ad8\u8fbe0.99\uff09\uff0c\u4f46\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u4e8e\u5f00\u53d1\u8005\u6765\u8bf4\u5e76\u4e0d\u5177\u6709\u5b9e\u9645\u64cd\u4f5c\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u96be\u4ee5\u76f4\u63a5\u8f6c\u5316\u4e3a\u53ef\u884c\u52a8\u7684\u5efa\u8bae\u3002", "motivation": "\u81ea\u52a8\u5316\u6d4b\u8bd5\u6267\u884c\u662f\u83b7\u53d6\u8f6f\u4ef6\u9879\u76ee\u8d28\u91cf\u4fe1\u606f\u7684\u91cd\u8981\u6d3b\u52a8\uff0c\u7136\u800c\u6240\u8c13\u7684\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u5bf9\u8fd9\u4e00\u8fc7\u7a0b\u4ea7\u751f\u4e86\u8d1f\u9762\u5f71\u54cd\u3002\u8fd9\u7c7b\u6d4b\u8bd5\u770b\u4f3c\u968f\u673a\u5931\u8d25\u4e14\u4e0e\u4ee3\u7801\u66f4\u6539\u65e0\u5173\uff0c\u56e0\u6b64\u4e0d\u80fd\u63d0\u4f9b\u6e05\u6670\u7684\u8d28\u91cf\u4fe1\u53f7\u3002\u4e4b\u524d\u7684\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u4e2d\u7684\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u6765\u8bc6\u522b\u4e0d\u7a33\u5b9a\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u4f46\u5c1a\u672a\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u73af\u5883\u4e2d\u5f97\u5230\u8bc4\u4f30\u3002", "method": "\u9996\u5148\uff0c\u5728SAP HANA\u7684\u80cc\u666f\u4e0b\u590d\u5236\u4e86Pinto\u7b49\u4eba\u4e4b\u524d\u7684\u7814\u7a76\u6210\u679c\uff1b\u5176\u6b21\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u7684\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u5305\u62ecTF-IDF\u548cTF-IDFC-RF\uff1b\u6700\u540e\uff0c\u4f7f\u7528CodeBERT\u548cXGBoost\u4f5c\u4e3a\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002\u4e3a\u4e86\u786e\u4fdd\u6bd4\u8f83\u7684\u6709\u6548\u6027\uff0c\u7814\u7a76\u91c7\u7528\u4e86\u6765\u81ea\u5148\u524d\u5de5\u4f5c\u7684\u6570\u636e\u96c6\u53ca\u4e24\u4e2a\u6765\u81eaSAP HANA\u7684\u6570\u636e\u96c6\u3002", "result": "\u590d\u5236\u7814\u7a76\u8868\u660e\uff0c\u5728\u539f\u59cb\u6570\u636e\u96c6\u548c\u5176\u4e2d\u4e00\u4e2aSAP HANA\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u4e86\u76f8\u4f3c\u7684\u7ed3\u679c\u3002\u539f\u65b9\u6cd5\u5728\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e860.94\u7684F1-Score\uff0c\u5728SAP HANA\u6570\u636e\u96c6\u4e0a\u4e3a0.92\uff1b\u800c\u65b0\u6269\u5c55\u65b9\u6cd5\u5219\u5206\u522b\u8fbe\u5230\u4e860.96\u548c0.99\u7684F1-Score\u3002\u4f9d\u8d56\u5916\u90e8\u6570\u636e\u6e90\u88ab\u786e\u5b9a\u4e3aSAP HANA\u73af\u5883\u4e0b\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u6027\u7684\u5e38\u89c1\u6839\u6e90\u4e4b\u4e00\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u578b\u5de5\u4e1a\u9879\u76ee\u7684\u8bcd\u6c47\u8868\u53ef\u80fd\u4e0e\u5177\u4f53\u672f\u8bed\u7565\u6709\u4e0d\u540c\uff0c\u4f46\u5728\u8bf8\u5982\u8fdc\u7a0b\u4f9d\u8d56\u8fd9\u6837\u7684\u7c7b\u522b\u65b9\u9762\uff0c\u4e0e\u4e4b\u524d\u7684\u5b9e\u8bc1\u53d1\u73b0\u76f8\u4f3c\u3002\u4e0d\u8fc7\uff0c\u5373\u4f7f\u62e5\u6709\u76f8\u5f53\u9ad8\u7684F1-Score\u503c\uff0c\u65e0\u8bba\u662f\u627e\u5230\u4ee3\u8868\u4e0d\u7a33\u5b9a\u7684\u6e90\u4ee3\u7801\u6807\u8bc6\u7b26\u8fd8\u662f\u8fdb\u884c\u9ed1\u76d2\u9884\u6d4b\uff0c\u5728\u5b9e\u8df5\u4e2d\u90fd\u56e0\u7ed3\u679c\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\u800c\u9650\u5236\u4e86\u5176\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.23446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23446", "abs": "https://arxiv.org/abs/2602.23446", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning", "comment": "Proceedings from IEEE CAI 2026, Conference on Artificial Intelligence, 8-10 May, Granada, Spain. 8 Pages, 3 Figures, 7 Tables", "summary": "Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7406\u8bba\uff0c\u89e3\u91ca\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u4eba\u7c7b\u76d1\u7763\u6e20\u9053\u7684\u5c40\u9650\u6027\u800c\u4ea7\u751f\u7684\u6301\u7eed\u9519\u8bef\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u4ec5\u9760\u6269\u5927\u89c4\u6a21\u65e0\u6cd5\u6d88\u9664\u8fd9\u4e9b\u9519\u8bef\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5f15\u5165\u8f85\u52a9\u7684\u975e\u4eba\u7c7b\u4fe1\u53f7\u53ef\u4ee5\u589e\u52a0\u6709\u6548\u7684\u76d1\u7763\u80fd\u529b\u5e76\u51cf\u5c11\u6216\u6d88\u9664\u989d\u5916\u7684\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u4eba\u7c7b\u751f\u6210\u7684\u6570\u636e\u548c\u53cd\u9988\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5b83\u4eec\u8868\u73b0\u51fa\u7531\u6807\u6ce8\u566a\u58f0\u3001\u4e3b\u89c2\u504f\u597d\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u5e26\u5bbd\u6709\u9650\u5f15\u8d77\u7684\u6301\u7eed\u9519\u8bef\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u9650\u5236\u53cd\u6620\u4e86\u76d1\u7763\u6e20\u9053\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u800c\u975e\u6a21\u578b\u89c4\u6a21\u6216\u4f18\u5316\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5f53\u4eba\u7c7b\u76d1\u7763\u6e20\u9053\u4e0d\u8db3\u4ee5\u8986\u76d6\u6f5c\u5728\u8bc4\u4f30\u76ee\u6807\u65f6\uff0c\u5b83\u4f1a\u6210\u4e3a\u4e00\u4e2a\u4fe1\u606f\u51cf\u5c11\u7684\u6e20\u9053\uff0c\u4e3a\u4efb\u4f55\u53d7\u5176\u652f\u914d\u7684\u5b66\u4e60\u8005\u5e26\u6765\u4e25\u683c\u6b63\u5411\u7684\u8d85\u989d\u98ce\u9669\u4e0b\u9650\u3002\u8fd9\u4e00\u7406\u8bba\u5728\u516d\u4e2a\u4e92\u8865\u6846\u67b6\uff08\u7b97\u5b50\u7406\u8bba\u3001PAC-Bayes\u65b9\u6cd5\u3001\u4fe1\u606f\u8bba\u3001\u56e0\u679c\u63a8\u7406\u3001\u8303\u7574\u8bba\u4ee5\u53ca\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\u7684\u6e38\u620f\u7406\u8bba\u5206\u6790\uff09\u4e2d\u5f97\u5230\u4e86\u5f62\u5f0f\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f9d\u9760\u4eba\u7c7b\u76d1\u7763\u5b58\u5728\u6301\u4e45\u6027\u7684\u6027\u80fd\u4e0b\u9650\uff0c\u800c\u8db3\u591f\u4fe1\u606f\u91cf\u7684\u8f85\u52a9\u6e20\u9053\u80fd\u591f\u663e\u8457\u51cf\u5c11\u6216\u5b8c\u5168\u6d88\u9664\u8fd9\u79cd\u8d85\u989d\u9519\u8bef\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u9760\u6269\u5927\u6a21\u578b\u89c4\u6a21\u4e0d\u80fd\u89e3\u51b3\u56e0\u4eba\u7c7b\u76d1\u7763\u4e0d\u8db3\u5bfc\u81f4\u7684\u56fa\u6709\u9519\u8bef\u95ee\u9898\uff1b\u901a\u8fc7\u7ed3\u5408\u4f7f\u7528\u975e\u4eba\u7c7b\u6765\u6e90\u7684\u4fe1\u606f\uff08\u5982\u68c0\u7d22\u3001\u7a0b\u5e8f\u6267\u884c\u7b49\u5de5\u5177\uff09\uff0c\u53ef\u4ee5\u63d0\u9ad8\u6709\u6548\u76d1\u7763\u80fd\u529b\u5e76\u964d\u4f4e\u9519\u8bef\u7387\u3002"}}
{"id": "2602.23530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23530", "abs": "https://arxiv.org/abs/2602.23530", "authors": ["Aditya Gaydhani", "Guangyue Xu", "Dhanush Kamath", "Ankit Singh", "Alex Li"], "title": "Unified Learning-to-Rank for Multi-Channel Retrieval in Large-Scale E-Commerce Search", "comment": null, "summary": "Large-scale e-commerce search must surface a broad set of items from a vast catalog, ranging from bestselling products to new, trending, or seasonal items. Modern systems therefore rely on multiple specialized retrieval channels to surface products, each designed to satisfy a specific objective. A key challenge is how to effectively merge documents from these heterogeneous channels into a single ranked list under strict latency constraints while optimizing for business KPIs such as user conversion. Rank-based fusion methods such as Reciprocal Rank Fusion (RRF) and Weighted Interleaving rely on fixed global channel weights and treat channels independently, failing to account for query-specific channel utility and cross-channel interactions. We observe that multi-channel fusion can be reformulated as a query-dependent learning-to-rank problem over heterogeneous candidate sources. In this paper, we propose a unified ranking model that learns to merge and rank documents from multiple retrieval channels. We formulate the problem as a channel-aware learning-to-rank task that jointly optimizes clicks, add-to-carts, and purchases while incorporating channel-specific objectives. We further incorporate recent user behavioral signals to capture short-term intent shifts that are critical for improving conversion in multi-channel ranking. Our online A/B experiments show that the proposed approach outperforms rank-based fusion methods, leading to a +2.85\\% improvement in user conversion. The model satisfies production latency requirements, achieving a p95 latency of under 50\\,ms, and is deployed on Target.com.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6392\u5e8f\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u4ece\u591a\u4e2a\u68c0\u7d22\u6e20\u9053\u5408\u5e76\u548c\u6392\u5e8f\u6587\u6863\uff0c\u5e76\u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u4fe1\u53f7\u6355\u6349\u77ed\u671f\u610f\u56fe\u53d8\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u4e8e\u6392\u540d\u7684\u878d\u5408\u65b9\u6cd5\u63d0\u9ad8\u4e862.85%\u7684\u7528\u6237\u8f6c\u5316\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u751f\u4ea7\u5ef6\u8fdf\u8981\u6c42\u3002", "motivation": "\u9488\u5bf9\u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\u5982\u4f55\u5728\u4e25\u683c\u5ef6\u8fdf\u9650\u5236\u4e0b\u6709\u6548\u6574\u5408\u6765\u81ea\u4e0d\u540c\u6e20\u9053\u7684\u6587\u6863\u4ee5\u4f18\u5316\u4e1a\u52a1KPI\uff08\u5982\u7528\u6237\u8f6c\u5316\uff09\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u6392\u540d\u7684\u878d\u5408\u65b9\u6cd5\u7531\u4e8e\u4f7f\u7528\u56fa\u5b9a\u7684\u5168\u5c40\u6e20\u9053\u6743\u91cd\u4e14\u72ec\u7acb\u5904\u7406\u5404\u6e20\u9053\u800c\u65e0\u6cd5\u8003\u8651\u67e5\u8be2\u7279\u5b9a\u7684\u6e20\u9053\u6548\u7528\u53ca\u8de8\u6e20\u9053\u4ea4\u4e92\u4f5c\u7528\u3002", "method": "\u5c06\u591a\u6e20\u9053\u878d\u5408\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u67e5\u8be2\u7684\u5b66\u4e60\u6392\u5e8f\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6392\u5e8f\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u4ece\u591a\u4e2a\u68c0\u7d22\u6e20\u9053\u5408\u5e76\u5e76\u6392\u5e8f\u6587\u6863\u3002\u6b64\u6a21\u578b\u4f5c\u4e3a\u4e00\u4e2a\u6e20\u9053\u611f\u77e5\u7684\u5b66\u4e60\u6392\u5e8f\u4efb\u52a1\u6765\u5171\u540c\u4f18\u5316\u70b9\u51fb\u3001\u52a0\u5165\u8d2d\u7269\u8f66\u548c\u8d2d\u4e70\u7b49\u64cd\u4f5c\uff0c\u540c\u65f6\u7ed3\u5408\u4e86\u6e20\u9053\u7279\u5b9a\u76ee\u6807\u3002\u6b64\u5916\uff0c\u8fd8\u52a0\u5165\u4e86\u6700\u8fd1\u7684\u7528\u6237\u884c\u4e3a\u4fe1\u53f7\u6765\u6355\u6349\u5bf9\u63d0\u9ad8\u591a\u6e20\u9053\u6392\u540d\u8f6c\u5316\u81f3\u5173\u91cd\u8981\u7684\u77ed\u671f\u610f\u56fe\u8f6c\u53d8\u3002", "result": "\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u4e8e\u57fa\u4e8e\u6392\u540d\u7684\u878d\u5408\u65b9\u6cd5\uff0c\u5728\u7528\u6237\u8f6c\u5316\u65b9\u9762\u53d6\u5f97\u4e86+2.85%\u7684\u63d0\u5347\u3002\u8be5\u6a21\u578b\u8fbe\u5230\u4e86\u751f\u4ea7\u73af\u5883\u4e2d\u5bf9\u4e8e\u5ef6\u8fdf\u7684\u8981\u6c42\uff0c\u5b9e\u73b0\u4e8695\u5206\u4f4d\u6570\u4e0b\u7684\u5ef6\u8fdf\u4f4e\u4e8e50\u6beb\u79d2\uff0c\u5e76\u5df2\u5728Target.com\u4e0a\u90e8\u7f72\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6e20\u9053\u611f\u77e5\u5b66\u4e60\u6392\u5e8f\u65b9\u6cd5\uff0c\u7814\u7a76\u6210\u529f\u5730\u89e3\u51b3\u4e86\u591a\u6e20\u9053\u878d\u5408\u4e2d\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u8f6c\u5316\u7387\uff0c\u540c\u65f6\u4e5f\u4fdd\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\u7b26\u5408\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2602.24108", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24108", "abs": "https://arxiv.org/abs/2602.24108", "authors": ["Yakun Zhang", "Zihan Wang", "Xinzhi Peng", "Zihao Xie", "Xiaodong Wang", "Xutao Li", "Dan Hao", "Lu Zhang", "Yunming Ye"], "title": "Context-Aware Functional Test Generation via Business Logic Extraction and Adaptation", "comment": null, "summary": "Functional testing is essential for verifying that the business logic of mobile applications aligns with user requirements, serving as the primary methodology for quality assurance in software development. Despite its importance, functional testing remains heavily dependent on manual effort due to two core challenges. First, acquiring and reusing complex business logic from unstructured requirements remains difficult, which hinders the understanding of specific functionalities. Second, a significant semantic gap exists when adapting business logic to the diverse GUI environments, which hinders the generation of test cases for specific mobile applications. To address the preceding challenges, we propose LogiDroid, a two-stage approach that generates individual functional test cases by extracting business logic and adapting it to target applications. First, in the Knowledge Retrieval and Fusion stage, we construct a dataset to retrieve relevant cases and extract business logic for the target functionality. Second, in the Context-Aware Test Generation stage, LogiDroid jointly analyzes the extracted business logic and the real-time GUI environment to generate functional test cases. This design allows LogiDroid to accurately understand application semantics and use domain expertise to generate complete test cases with verification assertions. We assess the effectiveness of LogiDroid using two widely-used datasets that cover 28 real-world applications and 190 functional requirements. Experimental results show that LogiDroid successfully tested 40% of functional requirements on the FrUITeR dataset (an improvement of over 48% compared to the state-of-the-art approaches) and 65% on the Lin dataset (an improvement of over 55% compared to the state-of-the-art approaches). These results demonstrate the significant effectiveness of LogiDroid in functional test generation.", "AI": {"tldr": "LogiDroid, a two-stage approach for generating functional test cases by extracting business logic and adapting it to the target mobile applications, significantly outperforms state-of-the-art methods in testing functional requirements, with improvements of over 48% and 55% on two different datasets.", "motivation": "Functional testing is crucial for ensuring that mobile applications meet user requirements, but it faces challenges due to the difficulty in acquiring and reusing complex business logic from unstructured requirements and the semantic gap when applying this logic to various GUI environments. This hinders the automatic generation of effective test cases.", "method": "The proposed method, LogiDroid, consists of two stages: Knowledge Retrieval and Fusion, where a dataset is used to retrieve relevant cases and extract business logic; and Context-Aware Test Generation, which analyzes the extracted business logic and the real-time GUI environment to generate functional test cases.", "result": "Experiments on two widely-used datasets covering 28 real-world applications and 190 functional requirements show that LogiDroid successfully tested 40% of the functional requirements on the FrUITeR dataset (an improvement of over 48%) and 65% on the Lin dataset (an improvement of over 55%) compared to existing methods.", "conclusion": "LogiDroid effectively addresses the challenges in functional testing for mobile applications by accurately understanding application semantics and leveraging domain expertise, leading to significant improvements in the success rate of testing functional requirements."}}
{"id": "2602.23459", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23459", "abs": "https://arxiv.org/abs/2602.23459", "authors": ["Eric V. Strobl"], "title": "Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires", "comment": null, "summary": "Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREFINE\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u975e\u7ebf\u6027\u5904\u7406\u9650\u5236\u5728\u57fa\u7ebf\u9884\u5904\u7406\u6a21\u5757\u4e2d\uff0c\u5e76\u4ece\u8fd9\u4e9b\u7a33\u5b9a\u7684\u57fa\u7ebf\u9879\u76ee\u5b66\u4e60\u5230\u672a\u6765\u4e25\u91cd\u7a0b\u5ea6\u7684\u7ebf\u6027\u6620\u5c04\uff0c\u4ece\u800c\u63d0\u9ad8\u7cbe\u795e\u79d1\u95ee\u5377\u6570\u636e\u7684\u9884\u6d4b\u51c6\u786e\u6027\u540c\u65f6\u4fdd\u6301\u4e86\u9884\u6d4b\u5173\u7cfb\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7531\u4e8e\u7cbe\u795e\u79d1\u95ee\u5377\u5bf9\u4e0a\u4e0b\u6587\u9ad8\u5ea6\u654f\u611f\u4e14\u5f80\u5f80\u53ea\u80fd\u5f31\u9884\u6d4b\u540e\u7eed\u75c7\u72b6\u7684\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5bfc\u81f4\u9884\u540e\u5173\u7cfb\u96be\u4ee5\u5b66\u4e60\u3002\u5c3d\u7ba1\u7075\u6d3b\u7684\u975e\u7ebf\u6027\u6a21\u578b\u53ef\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5b83\u4eec\u6709\u9650\u7684\u53ef\u89e3\u91ca\u6027\u53ef\u80fd\u4f1a\u524a\u5f31\u4e34\u5e8a\u4fe1\u4efb\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u65e2\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u53c8\u4fdd\u6301\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528REFINE\uff08\u5229\u7528\u5197\u4f59-\u968f\u8bbf\u4fe1\u606f\u7684\u975e\u7ebf\u6027\u589e\u5f3a\uff09\u4e24\u9636\u6bb5\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u57fa\u7ebf\u9884\u5904\u7406\u6a21\u5757\u4f30\u8ba1\u7a33\u5b9a\u9879\u76ee\u503c\uff0c\u7136\u540e\u4ece\u8fd9\u4e9b\u7a33\u5b9a\u5316\u7684\u57fa\u7ebf\u9879\u76ee\u5b66\u4e60\u5230\u672a\u6765\u4e25\u91cd\u7a0b\u5ea6\u7684\u7ebf\u6027\u6620\u5c04\u3002\u6b64\u65b9\u6cd5\u5c06\u975e\u7ebf\u6027\u80fd\u529b\u96c6\u4e2d\u5728\u9884\u5904\u7406\u9636\u6bb5\uff0c\u800c\u4fdd\u6301\u9884\u540e\u5173\u7cfb\u4e3a\u900f\u660e\u7684\u7ebf\u6027\uff0c\u4ece\u800c\u901a\u8fc7\u7cfb\u6570\u77e9\u9635\u5b9e\u73b0\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cREFINE\u5728\u7cbe\u795e\u79d1\u548c\u975e\u7cbe\u795e\u79d1\u7eb5\u5411\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6e05\u6670\u7684\u9884\u540e\u56e0\u7d20\u5168\u5c40\u5f52\u56e0\u3002", "conclusion": "REFINE\u65b9\u6cd5\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u7cbe\u795e\u79d1\u95ee\u5377\u6570\u636e\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5f97\u4e34\u5e8a\u533b\u751f\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u5e76\u4fe1\u4efb\u6a21\u578b\u7ed3\u679c\u3002"}}
{"id": "2602.23620", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23620", "abs": "https://arxiv.org/abs/2602.23620", "authors": ["Gui Ling", "Weiyuan Li", "Yue Jiang", "Wenjun Peng", "Xingxian Liu", "Dongshuai Li", "Fuyu Lv", "Dan Ou", "Haihong Tang"], "title": "Synthetic Data Powers Product Retrieval for Long-tail Knowledge-Intensive Queries in E-commerce Search", "comment": null, "summary": "Product retrieval is the backbone of e-commerce search: for each user query, it identifies a high-recall candidate set from billions of items, laying the foundation for high-quality ranking and user experience. Despite extensive optimization for mainstream queries, existing systems still struggle with long-tail queries, especially knowledge-intensive ones. These queries exhibit diverse linguistic patterns, often lack explicit purchase intent, and require domain-specific knowledge reasoning for accurate interpretation. They also suffer from a shortage of reliable behavioral logs, which makes such queries a persistent challenge for retrieval optimization. To address these issues, we propose an efficient data synthesis framework tailored to retrieval involving long-tail, knowledge-intensive queries. The key idea is to implicitly distill the capabilities of a powerful offline query-rewriting model into an efficient online retrieval system. Leveraging the strong language understanding of LLMs, we train a multi-candidate query rewriting model with multiple reward signals and capture its rewriting capability in well-curated query-product pairs through a powerful offline retrieval pipeline. This design mitigates distributional shift in rewritten queries, which might otherwise limit incremental recall or introduce irrelevant products. Experiments demonstrate that without any additional tricks, simply incorporating this synthetic data into retrieval model training leads to significant improvements. Online Side-By-Side (SBS) human evaluation results indicate a notable enhancement in user search experience.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u957f\u5c3e\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u7684\u6709\u6548\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5f3a\u5927\u7684\u79bb\u7ebf\u67e5\u8be2\u91cd\u5199\u6a21\u578b\u7684\u80fd\u529b\u9690\u5f0f\u5730\u63d0\u70bc\u5230\u9ad8\u6548\u7684\u5728\u7ebf\u68c0\u7d22\u7cfb\u7edf\u4e2d\uff0c\u4ece\u800c\u6539\u5584\u4e86\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\u7684\u4ea7\u54c1\u68c0\u7d22\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u901a\u8fc7\u5c06\u8fd9\u79cd\u5408\u6210\u6570\u636e\u7eb3\u5165\u68c0\u7d22\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u5c31\u80fd\u663e\u8457\u63d0\u9ad8\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u73b0\u6709\u7684\u4ea7\u54c1\u68c0\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u4e3b\u6d41\u67e5\u8be2\u65f6\u5df2\u7ecf\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u4f18\u5316\uff0c\u4f46\u5bf9\u4e8e\u957f\u5c3e\u67e5\u8be2\u5c24\u5176\u662f\u90a3\u4e9b\u9700\u8981\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u63a8\u7406\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u4ecd\u5b58\u5728\u6311\u6218\u3002\u8fd9\u7c7b\u67e5\u8be2\u5177\u6709\u591a\u6837\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u5f80\u5f80\u7f3a\u4e4f\u660e\u786e\u7684\u8d2d\u4e70\u610f\u56fe\uff0c\u5e76\u4e14\u7531\u4e8e\u53ef\u9760\u7684\u884c\u4e3a\u65e5\u5fd7\u4e0d\u8db3\u800c\u96be\u4ee5\u4f18\u5316\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u5305\u542b\u957f\u5c3e\u53ca\u77e5\u8bc6\u5bc6\u96c6\u578b\u67e5\u8be2\u7684\u6570\u636e\u5408\u6210\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u6765\u8bad\u7ec3\u4e00\u4e2a\u591a\u5019\u9009\u67e5\u8be2\u91cd\u5199\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528\u591a\u79cd\u5956\u52b1\u4fe1\u53f7\u4ee5\u6355\u6349\u5176\u91cd\u5199\u80fd\u529b\u3002\u901a\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u67e5\u8be2-\u4ea7\u54c1\u5bf9\u4ee5\u53ca\u4e00\u4e2a\u5f3a\u5927\u7684\u79bb\u7ebf\u68c0\u7d22\u7ba1\u9053\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6ca1\u6709\u91c7\u7528\u4efb\u4f55\u989d\u5916\u6280\u5de7\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4ec5\u5c06\u4e0a\u8ff0\u5408\u6210\u6570\u636e\u5f15\u5165\u5230\u68c0\u7d22\u6a21\u578b\u8bad\u7ec3\u4e2d\u5c31\u80fd\u591f\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002\u5728\u7ebf\u5e76\u884c\u7684\u4eba\u5de5\u8bc4\u4f30\u7ed3\u679c\u4e5f\u663e\u793a\u51fa\u7528\u6237\u641c\u7d22\u4f53\u9a8c\u5f97\u5230\u4e86\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u9ad8\u6548\u6570\u636e\u5408\u6210\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7535\u5b50\u5546\u52a1\u641c\u7d22\u573a\u666f\u4e0b\u957f\u5c3e\u67e5\u8be2\u6240\u5e26\u6765\u7684\u6311\u6218\uff0c\u8fdb\u800c\u4e3a\u7528\u6237\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u4ea7\u54c1\u68c0\u7d22\u670d\u52a1\u3002"}}
{"id": "2602.23495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23495", "abs": "https://arxiv.org/abs/2602.23495", "authors": ["Yangyi Li", "Mengdi Huai"], "title": "Uncertainty-aware Language Guidance for Concept Bottleneck Models", "comment": null, "summary": "Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5CBM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u6982\u5ff5\u6807\u7b7e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5c06\u6b64\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165CBM\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u540c\u53ef\u9760\u6027\u6c34\u5e73\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u6982\u5ff5\u3002", "motivation": "\u73b0\u6709\u7684\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBMs\uff09\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u77e5\u8bc6\u548c\u52b3\u52a8\u6765\u6ce8\u91ca\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u6982\u5ff5\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\uff1b\u800c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u5efa\u6982\u5ff5\u74f6\u9888\u7684\u5de5\u4f5c\u5219\u5ffd\u7565\u4e86\u4e0eLLMs\u6ce8\u91ca\u6982\u5ff5\u76f8\u5173\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u7f3a\u4e4f\u6709\u6548\u673a\u5236\u6765\u91cf\u5316\u8fd9\u4e9b\u6982\u5ff5\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u589e\u52a0\u4e86\u7531\u4e8eLLMs\u4ea7\u751f\u5e7b\u89c9\u5bfc\u81f4\u9519\u8bef\u7684\u98ce\u9669\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u672a\u80fd\u5c06\u4e0e\u8fd9\u4e9b\u6ce8\u91ca\u76f8\u5173\u7684\u4e0d\u786e\u5b9a\u6027\u878d\u5165\u5230\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5CBM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4e25\u683c\u5730\u7528\u6709\u6548\u4e14\u65e0\u5206\u5e03\u5047\u8bbe\u7684\u65b9\u5f0f\u91cf\u5316\u4e86\u7531LLM\u6ce8\u91ca\u7684\u6982\u5ff5\u6807\u7b7e\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd8\u901a\u8fc7\u5c06\u91cf\u5316\u7684\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165CBM\u8bad\u7ec3\u7a0b\u5e8f\u4e2d\uff0c\u4ee5\u8003\u8651\u5230LLM\u6ce8\u91ca\u6982\u5ff5\u95f4\u4e0d\u540c\u7684\u53ef\u9760\u6027\u7a0b\u5ea6\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u5bf9\u6240\u63d0\u65b9\u6cd5\u7684\u7406\u8bba\u5206\u6790\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5CBM\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u4e2d\u5b58\u5728\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5373\u65e0\u6cd5\u59a5\u5584\u5904\u7406\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u7684\u6982\u5ff5\u6ce8\u91ca\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u63d0\u5347CBM\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.23639", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23639", "abs": "https://arxiv.org/abs/2602.23639", "authors": ["Haibo Xing", "Hao Deng", "Lingyu Mu", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "Learning to Reflect and Correct: Towards Better Decoding Trajectories for Large-Scale Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has become a promising paradigm for large-scale recommendation systems. However, existing GR models typically perform single-pass decoding without explicit refinement, causing early deviations to accumulate and ultimately degrade recommendation quality. To tackle this problem, we propose GRC, which is, to our knowledge, the first structured reflection-correction framework for GR that extends standard decoding into a Generation-Reflection-Correction (GRC) process. Concretely, GRC introduces a supervised reflection-correction template that decomposes the decoding process into initial draft generation, multi-granular reflection, and reflection-guided correction, thereby enabling structured reflection and correction in the semantic token space. To further explore the enlarged refinement space introduced by the GRC process, we optimize the entire GRC trajectory with GRPO-based reinforcement learning, under a carefully designed reward function with token-level and trajectory-level signals. For efficient online serving, we propose an Entropy-Guided Reflection Scheduling (EGRS) strategy that dynamically allocates more correction budget to high-uncertainty decoding trajectories during beam search. Extensive experiments on real-world datasets show that GRC consistently outperforms six state-of-the-art baselines by up to 15.74%, and online A/B tests demonstrate its substantial practical value in large-scale industrial recommendation, delivering a 1.79% lift in advertising revenue with only modest latency overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGRC\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u89e3\u7801\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u751f\u6210-\u53cd\u601d-\u4fee\u6b63\u6d41\u7a0b\u6765\u63d0\u9ad8\u63a8\u8350\u8d28\u91cf\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eGRPO\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4f18\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGRC\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u80fd\u591f\u663e\u8457\u63d0\u5347\u5e7f\u544a\u6536\u5165\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u5ef6\u8fdf\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u901a\u5e38\u91c7\u7528\u5355\u6b21\u89e3\u7801\u65b9\u5f0f\u800c\u7f3a\u4e4f\u660e\u786e\u7684\u7cbe\u70bc\u6b65\u9aa4\uff0c\u5bfc\u81f4\u65e9\u671f\u504f\u5dee\u7d2f\u79ef\u5e76\u6700\u7ec8\u964d\u4f4e\u63a8\u8350\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86GRC\u6846\u67b6\uff0c\u5c06\u6807\u51c6\u89e3\u7801\u6269\u5c55\u4e3a\u751f\u6210-\u53cd\u601d-\u4fee\u6b63\u7684\u8fc7\u7a0b\u3002\u5177\u4f53\u6765\u8bf4\uff0cGRC\u5f15\u5165\u4e86\u76d1\u7763\u4e0b\u7684\u53cd\u601d-\u4fee\u6b63\u6a21\u677f\uff0c\u5c06\u89e3\u7801\u8fc7\u7a0b\u5206\u89e3\u4e3a\u521d\u59cb\u8349\u7a3f\u751f\u6210\u3001\u591a\u7c92\u5ea6\u53cd\u601d\u4ee5\u53ca\u53cd\u601d\u6307\u5bfc\u4e0b\u7684\u4fee\u6b63\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63a2\u7d22GRC\u8fc7\u7a0b\u5e26\u6765\u7684\u66f4\u5927\u8303\u56f4\u7684\u7cbe\u70bc\u7a7a\u95f4\uff0c\u91c7\u7528\u4e86\u57fa\u4e8eGRPO\u7684\u5f3a\u5316\u5b66\u4e60\u5bf9\u6574\u4e2aGRC\u8f68\u8ff9\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u5bf9\u4e8e\u5728\u7ebf\u670d\u52a1\u6548\u7387\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u71b5\u5f15\u5bfc\u7684\u53cd\u601d\u8c03\u5ea6\u7b56\u7565\uff08EGRS\uff09\uff0c\u5728\u6ce2\u675f\u641c\u7d22\u8fc7\u7a0b\u4e2d\u52a8\u6001\u5730\u4e3a\u9ad8\u4e0d\u786e\u5b9a\u6027\u89e3\u7801\u8f68\u8ff9\u5206\u914d\u66f4\u591a\u7684\u4fee\u6b63\u9884\u7b97\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u516d\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cGRC\u6700\u9ad8\u53ef\u63d0\u534715.74%\u7684\u8868\u73b0\u3002\u5728\u7ebfA/B\u6d4b\u8bd5\u4e5f\u8bc1\u660e\u4e86\u5176\u5728\u5927\u89c4\u6a21\u5de5\u4e1a\u63a8\u8350\u573a\u666f\u4e2d\u7684\u5b9e\u8d28\u6027\u5b9e\u7528\u4ef7\u503c\uff0c\u5b9e\u73b0\u4e861.79%\u7684\u5e7f\u544a\u6536\u5165\u589e\u957f\uff0c\u4e14\u4ec5\u4f34\u6709\u9002\u5ea6\u7684\u5ef6\u8fdf\u5f00\u9500\u3002", "conclusion": "GRC\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u5584\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u7684\u63a8\u8350\u8d28\u91cf\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6027\u80fd\u6307\u6807\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u4e5f\u5c55\u793a\u4e86\u826f\u597d\u7684\u5546\u4e1a\u4ef7\u503c\u3002"}}
{"id": "2602.23665", "categories": ["cs.IR", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.23665", "abs": "https://arxiv.org/abs/2602.23665", "authors": ["Brandon Yee", "Lucas Wang", "Kundana Kommini", "Krishna Sharma"], "title": "Geodesic Semantic Search: Learning Local Riemannian Metrics for Citation Graph Retrieval", "comment": null, "summary": "We present Geodesic Semantic Search (GSS), a retrieval system that learns node-specific Riemannian metrics on citation graphs to enable geometry-aware semantic search. Unlike standard embedding-based retrieval that relies on fixed Euclidean distances, \\gss{} learns a low-rank metric tensor $\\mL_i \\in \\R^{d \\times r}$ at each node, inducing a local positive semi-definite metric $\\mG_i = \\mL_i \\mL_i^\\top + \\eps \\mI$. This parameterization guarantees valid metrics while keeping the model tractable. Retrieval proceeds via multi-source Dijkstra on the learned geodesic distances, followed by Maximal Marginal Relevance reranking and path coherence filtering. On citation prediction benchmarks with 169K papers, \\gss{} achieves 23\\% relative improvement in Recall@20 over SPECTER+FAISS baselines while providing interpretable citation paths. Our hierarchical coarse-to-fine search with k-means pooling reduces computational cost by 4$\\times$ compared to flat geodesic search while maintaining 97\\% retrieval quality. We provide theoretical analysis of when geodesic distances outperform direct similarity, characterize the approximation quality of low-rank metrics, and validate predictions empirically. Code and trained models are available at https://github.com/YCRG-Labs/geodesic-search.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGeodesic Semantic Search (GSS)\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u5b66\u4e60\u5f15\u7528\u56fe\u4e0a\u7684\u8282\u70b9\u7279\u5b9a\u9ece\u66fc\u5ea6\u91cf\u6765\u5b9e\u73b0\u51e0\u4f55\u611f\u77e5\u8bed\u4e49\u641c\u7d22\u3002\u4e0e\u4f9d\u8d56\u56fa\u5b9a\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u6807\u51c6\u5d4c\u5165\u5f0f\u68c0\u7d22\u4e0d\u540c\uff0cGSS\u5728\u6bcf\u4e2a\u8282\u70b9\u4e0a\u5b66\u4e60\u4e00\u4e2a\u4f4e\u79e9\u5ea6\u91cf\u5f20\u91cf\uff0c\u4ece\u800c\u8bf1\u5bfc\u51fa\u5c40\u90e8\u6b63\u534a\u5b9a\u5ea6\u91cf\u3002\u901a\u8fc7\u591a\u6e90Dijkstra\u7b97\u6cd5\u3001\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u91cd\u6392\u548c\u8def\u5f84\u4e00\u81f4\u6027\u8fc7\u6ee4\u6765\u8fdb\u884c\u68c0\u7d22\u3002\u5728\u5305\u542b169,000\u7bc7\u8bba\u6587\u7684\u6570\u636e\u96c6\u4e0a\uff0cGSS\u76f8\u6bd4SPECTER+FAISS\u57fa\u51c6\u63d0\u9ad8\u4e8623%\u7684Recall@20\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u5f15\u7528\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\uff0c\u8fd9\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6570\u636e\u5185\u5728\u7684\u590d\u6742\u7ed3\u6784\u3002GSS\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u2014\u2014\u5373\u5728\u5f15\u7528\u56fe\u4e0a\u5b66\u4e60\u8282\u70b9\u7279\u5b9a\u7684\u9ece\u66fc\u5ea6\u91cf\u2014\u2014\u6765\u6539\u5584\u8fd9\u4e00\u70b9\uff0c\u4ee5\u652f\u6301\u66f4\u7cbe\u51c6\u4e14\u5177\u6709\u51e0\u4f55\u610f\u8bc6\u7684\u8bed\u4e49\u641c\u7d22\u3002", "method": "GSS\u4e3a\u6bcf\u4e2a\u8282\u70b9\u5b66\u4e60\u4e00\u4e2a\u4f4e\u79e9\u5ea6\u91cf\u5f20\u91cf$\\mL_i \\in \\R^{d \\times r}$\uff0c\u8fdb\u800c\u8bf1\u5bfc\u51fa\u5c40\u90e8\u6b63\u534a\u5b9a\u5ea6\u91cf$\\mG_i = \\mL_i \\mL_i^\\top + \\eps \\mI$\u3002\u8fd9\u79cd\u53c2\u6570\u5316\u786e\u4fdd\u4e86\u5ea6\u91cf\u7684\u6709\u6548\u6027\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002\u68c0\u7d22\u8fc7\u7a0b\u7ed3\u5408\u4e86\u57fa\u4e8e\u5b66\u5230\u7684\u6d4b\u5730\u7ebf\u8ddd\u79bb\u7684\u591a\u6e90Dijkstra\u7b97\u6cd5\u3001\u6700\u5927\u8fb9\u9645\u76f8\u5173\u6027\u91cd\u6392\u4ee5\u53ca\u8def\u5f84\u4e00\u81f4\u6027\u8fc7\u6ee4\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u7c97\u5230\u7ec6\u7684\u5c42\u6b21\u641c\u7d22\u7b56\u7565\uff0c\u5229\u7528k-means\u6c60\u5316\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728\u5904\u7406\u5305\u542b169,000\u7bc7\u8bba\u6587\u7684\u6570\u636e\u96c6\u65f6\uff0cGSS\u76f8\u5bf9\u4e8eSPECTER+FAISS\u57fa\u7ebf\u5728Recall@20\u6307\u6807\u4e0a\u53d6\u5f97\u4e8623%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u5e76\u80fd\u591f\u63d0\u4f9b\u66f4\u52a0\u76f4\u89c2\u7684\u5f15\u7528\u8def\u5f84\u3002\u91c7\u7528\u5206\u5c42\u641c\u7d22\u7b56\u7565\u540e\uff0c\u5728\u4fdd\u630197%\u68c0\u7d22\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u4e864\u500d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5b66\u4e60\u5f15\u7528\u56fe\u4e2d\u8282\u70b9\u7279\u5b9a\u7684\u9ece\u66fc\u5ea6\u91cf\u6765\u6267\u884c\u51e0\u4f55\u611f\u77e5\u8bed\u4e49\u641c\u7d22\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002GSS\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u68c0\u7d22\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u63d0\u51fa\u7684\u4f4e\u79e9\u5ea6\u91cf\u8fd1\u4f3c\u65b9\u6cd5\u4e5f\u5f97\u5230\u4e86\u7406\u8bba\u5206\u6790\u7684\u652f\u6301\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.23507", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.23507", "abs": "https://arxiv.org/abs/2602.23507", "authors": ["Diana Shamsutdinova", "Felix Zimmer", "Oyebayo Ridwan Olaniran", "Sarah Markham", "Daniel Stahl", "Gordon Forbes", "Ewan Carr"], "title": "Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package", "comment": "26 pages, 4 figures, 1 table, preprint", "summary": "Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6a21\u62df\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u548c\u4fdd\u8bc1\u539f\u5219\u6765\u786e\u5b9a\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u6240\u9700\u7684\u6837\u672c\u91cf\uff0c\u5e76\u5f00\u53d1\u4e86\u5f00\u6e90R\u5305pmsims\u3002\u8be5\u65b9\u6cd5\u4e3a\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u7684\u6837\u672c\u91cf\u4f30\u8ba1\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u533b\u7597\u51b3\u7b56\uff0c\u4f46\u5176\u5f00\u53d1\u6240\u9700\u7684\u6700\u5c0f\u6837\u672c\u91cf\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u4e14\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u800c\u8a00\u3002", "method": "\u7814\u7a76\u8005\u4eec\u56de\u987e\u4e86\u5f53\u524d\u9884\u6d4b\u5efa\u6a21\u4e2d\u6837\u672c\u91cf\u4f30\u7b97\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u533a\u5206\u57fa\u4e8e\u5e73\u5747\u503c\u6807\u51c6\u4e0e\u57fa\u4e8e\u4fdd\u8bc1\u6807\u51c6\u7684\u6982\u5ff5\u6846\u67b6\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u4e8e\u6a21\u62df\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5b66\u4e60\u66f2\u7ebf\u3001\u9ad8\u65af\u8fc7\u7a0b\u4f18\u5316\u4ee5\u53ca\u4fdd\u8bc1\u539f\u5219\u6765\u8bc6\u522b\u80fd\u591f\u4ee5\u9ad8\u6982\u7387\u8fbe\u6210\u76ee\u6807\u8868\u73b0\u7684\u6837\u672c\u91cf\u3002\u8fd9\u4e00\u65b9\u6cd5\u88ab\u5b9e\u73b0\u5728\u540d\u4e3apmsims\u7684\u5f00\u6e90R\u8f6f\u4ef6\u5305\u4e2d\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u4e0d\u540c\u65b9\u6cd5\u3001\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\u53ca\u5efa\u6a21\u7b56\u7565\u4e0b\u5f97\u5230\u7684\u6837\u672c\u91cf\u4f30\u8ba1\u5dee\u5f02\u5f88\u5927\u3002\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u6bd4\uff0cpmsims\u63d0\u4f9b\u4e86\u66f4\u52a0\u7075\u6d3b\u3001\u9ad8\u6548\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u9002\u5e94\u5404\u79cd\u6a21\u578b\u7c7b\u578b\u548c\u7528\u6237\u5b9a\u4e49\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u660e\u786e\u8003\u8651\u5230\u4e86\u6a21\u578b\u6027\u80fd\u4e2d\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u8f6f\u4ef6\u901a\u8fc7\u7ed3\u5408\u7075\u6d3b\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u63a8\u8fdb\u4e86\u4e34\u5e8a\u9884\u6d4b\u5efa\u6a21\u9886\u57df\u5185\u7684\u6837\u672c\u91cf\u65b9\u6cd5\u5b66\u53d1\u5c55\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u6269\u5c55\u5230\u5c42\u6b21\u5316\u548c\u591a\u6a21\u6001\u6570\u636e\u4e0a\uff0c\u7eb3\u5165\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u6307\u6807\uff0c\u5e76\u89e3\u51b3\u5982\u7f3a\u5931\u6570\u636e\u548c\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u7b49\u6311\u6218\u3002"}}
{"id": "2602.23671", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23671", "abs": "https://arxiv.org/abs/2602.23671", "authors": ["Yufei Ye", "Wei Guo", "Hao Wang", "Luankang Zhang", "Heng Chang", "Hong Zhu", "Yuyang Ye", "Yong Liu", "Defu Lian", "Enhong Chen"], "title": "FuXi-Linear: Unleashing the Power of Linear Attention in Long-term Time-aware Sequential Recommendation", "comment": null, "summary": "Modern recommendation systems primarily rely on attention mechanisms with quadratic complexity, which limits their ability to handle long user sequences and slows down inference. While linear attention is a promising alternative, existing research faces three critical challenges: (1) temporal signals are often overlooked or integrated via naive coupling that causes mutual interference between temporal and semantic signals while neglecting behavioral periodicity; (2) insufficient positional information provided by existing linear frameworks; and (3) a primary focus on short sequences and shallow architectures. To address these issues, we propose FuXi-Linear, a linear-complexity model designed for efficient long-sequence recommendation. Our approach introduces two key components: (1) a Temporal Retention Channel that independently computes periodic attention weights using temporal data, preventing crosstalk between temporal and semantic signals; (2) a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. Moreover, we demonstrate that FuXi-Linear exhibits a robust power-law scaling property at a thousand-length scale, a characteristic largely unexplored in prior linear recommendation studies. Extensive experiments on sequences of several thousand tokens demonstrate that FuXi-Linear outperforms state-of-the-art models in recommendation quality, while achieving up to 10$\\times$ speedup in the prefill stage and up to 21$\\times$ speedup in the decode stage compared to competitive baselines. Our code has been released in a public repository https://github.com/USTC-StarTeam/fuxi-linear.", "AI": {"tldr": "FuXi-Linear, a linear-complexity model, addresses the limitations of current recommendation systems by incorporating a Temporal Retention Channel and a Linear Positional Channel, which together improve handling of long sequences, reduce interference between temporal and semantic signals, and provide better positional information. The model demonstrates superior performance in both speed and recommendation quality on long sequences.", "motivation": "Current recommendation systems are limited by their quadratic complexity attention mechanisms, which struggle with long user sequences and slow down inference. While linear attention offers a solution, it faces challenges such as neglecting temporal signals, insufficient positional information, and a focus on short sequences. This paper aims to address these issues with a new model called FuXi-Linear.", "method": "The proposed method, FuXi-Linear, includes two key components: a Temporal Retention Channel that computes periodic attention weights using temporal data, avoiding crosstalk between temporal and semantic signals; and a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. These components work together to enable efficient processing of long sequences while maintaining or improving recommendation quality.", "result": "FuXi-Linear is shown to outperform state-of-the-art models in recommendation quality for long sequences, achieving up to 10x speedup in the prefill stage and up to 21x speedup in the decode stage compared to competitive baselines. Additionally, the model exhibits power-law scaling properties at a thousand-length scale, indicating its robustness for very long sequences.", "conclusion": "FuXi-Linear effectively tackles the shortcomings of existing recommendation systems by introducing a more sophisticated treatment of temporal and positional information, leading to significant improvements in both efficiency and effectiveness for long-sequence recommendations."}}
{"id": "2602.23528", "categories": ["cs.LG", "cs.CE", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23528", "abs": "https://arxiv.org/abs/2602.23528", "authors": ["Yicen Li", "Jose Antonio Lara Benitez", "Ruiyang Hong", "Anastasis Kratsios", "Paul David McNicholas", "Maarten Valentijn de Hoop"], "title": "Neural Operators Can Discover Functional Clusters", "comment": null, "summary": "Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.\n  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u57fa\u4e8e\u6837\u672c\u7684\u795e\u7ecf\u7b97\u5b50\u53ef\u4ee5\u5b66\u4e60\u65e0\u9650\u7ef4\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4efb\u4f55\u6709\u9650\u7c7b\u522b\u7684\u96c6\u5408\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u795e\u7ecf\u7b97\u5b50\u9a71\u52a8\u7684\u805a\u7c7b\u7ba1\u9053\u7528\u4e8e\u51fd\u6570\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u7ecf\u5178\u65b9\u6cd5\u5931\u6548\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684SNO\u80fd\u591f\u6062\u590d\u6f5c\u5728\u7684\u52a8\u529b\u5b66\u7ed3\u6784\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u867d\u7136\u795e\u7ecf\u7b97\u5b50\uff08NOs\uff09\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u88ab\u7406\u89e3\uff0c\u4f46\u5728\u5206\u7c7b\u548c\u5176\u65e0\u76d1\u7763\u7c7b\u4f3c\u7269\uff1a\u805a\u7c7b\u4e2d\u7684\u5e94\u7528\u5374\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u795e\u7ecf\u7b97\u5b50\u5728\u5904\u7406\u65e0\u9650\u7ef4\u7a7a\u95f4\u4e2d\u7684\u805a\u7c7b\u95ee\u9898\u65f6\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u57fa\u4e8e\u6837\u672c\u7684\u795e\u7ecf\u7b97\u5b50\u80fd\u591f\u5728\u6ee1\u8db3\u6e29\u548c\u6838\u91c7\u6837\u5047\u8bbe\u4e0b\u5b66\u4e60\u5230\u975e\u51f8\u6216\u4e0d\u8fde\u901a\u7684\u7c7b\u522b\u96c6\u5408\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u51fd\u6570\u6570\u636e\u7684\u3001\u7531\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u548c\u8f7b\u91cf\u7ea7\u53ef\u8bad\u7ec3\u5934\u90e8\u7ec4\u6210\u7684\u795e\u7ecf\u7b97\u5b50\u9a71\u52a8\u7684\u805a\u7c7b\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u5728\u591a\u79cd\u5408\u6210ODE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u5b9e\u7528SNO\u80fd\u591f\u5728\u4f20\u7edf\u65b9\u6cd5\u5931\u8d25\u7684\u60c5\u5883\u4e0b\u6062\u590d\u51fa\u6f5c\u5728\u7684\u52a8\u529b\u5b66\u7ed3\u6784\uff0c\u8fd9\u4e0e\u63d0\u51fa\u7684\u666e\u904d\u805a\u7c7b\u7406\u8bba\u662f\u4e00\u81f4\u7684\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u795e\u7ecf\u7b97\u5b50\u4e0d\u4ec5\u7406\u8bba\u4e0a\u80fd\u591f\u903c\u8fd1\u4efb\u610f\u95ed\u5408\u7c7b\u522b\u7684\u96c6\u5408\uff0c\u800c\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u529f\u80fd\u6570\u636e\u805a\u7c7b\u95ee\u9898\u4e0a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23717", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23717", "abs": "https://arxiv.org/abs/2602.23717", "authors": ["Hao Li", "Kedar Bellare", "Siyu Yang", "Sherry Chen", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Recommending Search Filters To Improve Conversions At Airbnb", "comment": null, "summary": "Airbnb, a two-sided online marketplace connecting guests and hosts, offers a diverse and unique inventory of accommodations, experiences, and services. Search filters play an important role in helping guests navigate this variety by refining search results to align with their needs. Yet, while search filters are designed to facilitate conversions in online marketplaces, their direct impact on driving conversions remains underexplored in the existing literature.\n  This paper bridges this gap by presenting a novel application of machine learning techniques to recommend search filters aimed at improving booking conversions. We introduce a modeling framework that directly targets lower-funnel conversions (bookings) by recommending intermediate tools, i.e. search filters. Leveraging the framework, we designed and built the filter recommendation system at Airbnb from the ground up, addressing challenges like cold start and stringent serving requirements.\n  The filter recommendation system we developed has been successfully deployed at Airbnb, powering multiple user interfaces and driving incremental booking conversion lifts, as validated through online A/B testing. An ablation study further validates the effectiveness of our approach and key design choices. By focusing on conversion-oriented filter recommendations, our work ensures that search filters serve their ultimate purpose at Airbnb - helping guests find and book their ideal accommodations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u5e94\u7528\uff0c\u7528\u4e8e\u63a8\u8350\u641c\u7d22\u8fc7\u6ee4\u5668\u4ee5\u63d0\u9ad8\u9884\u8ba2\u8f6c\u5316\u7387\u3002\u5f00\u53d1\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\u5728Airbnb\u6210\u529f\u90e8\u7f72\u5e76\u901a\u8fc7\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u867d\u7136\u641c\u7d22\u8fc7\u6ee4\u5668\u65e8\u5728\u4fc3\u8fdb\u5728\u7ebf\u5e02\u573a\u7684\u8f6c\u5316\uff0c\u4f46\u5b83\u4eec\u5bf9\u63a8\u52a8\u8f6c\u5316\u7684\u76f4\u63a5\u5f71\u54cd\u5728\u73b0\u6709\u6587\u732e\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u63a8\u8350\u641c\u7d22\u8fc7\u6ee4\u5668\u6765\u76f4\u63a5\u63d0\u9ad8\u9884\u8ba2\u8f6c\u5316\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5efa\u6a21\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u63a8\u8350\u4e2d\u95f4\u5de5\u5177\uff08\u5373\u641c\u7d22\u8fc7\u6ee4\u5668\uff09\u6765\u76f4\u63a5\u9488\u5bf9\u4e0b\u5c42\u6f0f\u6597\u8f6c\u5316\uff08\u9884\u8ba2\uff09\u3002\u5229\u7528\u6b64\u6846\u67b6\uff0c\u4ece\u96f6\u5f00\u59cb\u8bbe\u8ba1\u5e76\u6784\u5efa\u4e86Airbnb\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\uff0c\u5e76\u89e3\u51b3\u4e86\u51b7\u542f\u52a8\u548c\u670d\u52a1\u8981\u6c42\u4e25\u683c\u7b49\u6311\u6218\u3002", "result": "\u6240\u5f00\u53d1\u7684\u8fc7\u6ee4\u5668\u63a8\u8350\u7cfb\u7edf\u5df2\u5728Airbnb\u6210\u529f\u90e8\u7f72\uff0c\u652f\u6301\u591a\u4e2a\u7528\u6237\u754c\u9762\uff0c\u5e76\u901a\u8fc7\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u5b9e\u73b0\u4e86\u9884\u8ba2\u8f6c\u5316\u7387\u7684\u589e\u91cf\u63d0\u5347\u3002\u6b64\u5916\uff0c\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u53ca\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u5de5\u4f5c\u786e\u4fdd\u4e86\u641c\u7d22\u8fc7\u6ee4\u5668\u5728Airbnb\u4e0a\u670d\u52a1\u4e8e\u5176\u6700\u7ec8\u76ee\u7684\u2014\u2014\u5e2e\u52a9\u5ba2\u4eba\u627e\u5230\u5e76\u9884\u8ba2\u7406\u60f3\u7684\u4f4f\u5bbf\u3002"}}
{"id": "2602.23529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23529", "abs": "https://arxiv.org/abs/2602.23529", "authors": ["Martin \u010cern\u00fd", "David Sychrovsk\u00fd", "Filip \u00daradn\u00edk", "Jakub \u010cern\u00fd"], "title": "Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning", "comment": null, "summary": "Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u52a0\u6027\u8bef\u5dee\u4e0b\u8fd1\u4f3c\u672a\u77e5\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6700\u5c0f\u5316\u548c\u6700\u5927\u5316\u8865\u5168\u4e0d\u540c\u7c7b\u522b\u7684\u7f3a\u5931\u503c\u96c6\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e\u6307\u5b9a\u4e00\u4e2a\u96c6\u51fd\u6570\u901a\u5e38\u9700\u8981\u4e3a\u6307\u6570\u7ea7\u6570\u91cf\u7684\u5b50\u96c6\u5206\u914d\u503c\uff0c\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5f80\u5f80\u662f\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u4efb\u52a1\u3002\u7b80\u5355\u7684\u5ffd\u7565\u67d0\u4e9b\u503c\u4f1a\u5bfc\u81f4\u6a21\u7cca\u6027\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5b8c\u5168\u96c6\u51fd\u6570\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u65f6\u3002\u53d7\u5230\u5173\u4e8e\u4f7f\u7528\u786e\u5b9a\u6027\u503c\u67e5\u8be2\u65e0\u6cd5\u8fd1\u4f3c\u6b21\u53ef\u52a0\u51fd\u6570\u7ed3\u679c\u7684\u542f\u53d1\uff0c\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4ee5\u52a0\u6027\u8bef\u5dee\u65b9\u5f0f\u8fd1\u4f3c\u672a\u77e5\u6b21\u53ef\u52a0\u6216\u5176\u5b50\u7c7b\u96c6\u51fd\u6570\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u9996\u5148\u5168\u9762\u63a2\u8ba8\u4e86\u5177\u6709\u7f3a\u5931\u503c\u7684\u4e0d\u540c\u7c7b\u522b\u96c6\u51fd\u6570\u7684\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u53ca\u5176\u5bfc\u81f4\u7684\u8ddd\u79bb\uff1b\u5176\u6b21\u5f00\u53d1\u4e86\u65b9\u6cd5\u6765\u51cf\u5c11\u5df2\u77e5\u5148\u9a8c\u4fe1\u606f\u7684\u96c6\u51fd\u6570\u7c7b\u522b\u95f4\u7684\u8fd9\u79cd\u8ddd\u79bb\uff0c\u901a\u8fc7\u5728\u7ebf\u548c\u79bb\u7ebf\u4e24\u79cd\u65b9\u5f0f\u62ab\u9732\u989d\u5916\u5b50\u96c6\u7684\u4ef7\u503c\u6765\u5b9e\u73b0\uff1b\u6700\u540e\uff0c\u901a\u8fc7\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u7b97\u6cd5\u6027\u80fd\u5c55\u793a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u522b\u7684\u96c6\u51fd\u6570\uff0c\u5176\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u95f4\u5b58\u5728\u7279\u5b9a\u8ddd\u79bb\uff0c\u5e76\u4e14\u901a\u8fc7\u9009\u62e9\u6027\u5730\u63ed\u793a\u989d\u5916\u5b50\u96c6\u7684\u4ef7\u503c\u53ef\u4ee5\u6709\u6548\u5730\u51cf\u5c0f\u8fd9\u4e2a\u8ddd\u79bb\u3002\u6b64\u5916\uff0c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u7b56\u7565\u9009\u62e9\u6027\u5730\u589e\u52a0\u96c6\u51fd\u6570\u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u4e0d\u5b8c\u5168\u96c6\u51fd\u6570\u7684\u6700\u5c0f\u548c\u6700\u5927\u8865\u5168\u4e4b\u95f4\u7684\u8ddd\u79bb\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u672a\u77e5\u6b21\u53ef\u52a0\u96c6\u51fd\u6570\u7684\u8fd1\u4f3c\u6548\u679c\u3002"}}
{"id": "2602.23766", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23766", "abs": "https://arxiv.org/abs/2602.23766", "authors": ["Zheng Dou", "Zhao Zhang", "Deqing Wang", "Yikun Ban", "Fuzhen Zhuang"], "title": "UniFAR: A Unified Facet-Aware Retrieval Framework for Scientific Documents", "comment": null, "summary": "Existing scientific document retrieval (SDR) methods primarily rely on document-centric representations learned from inter-document relationships for document-document (doc-doc) retrieval. However, the rise of LLMs and RAG has shifted SDR toward question-driven retrieval, where documents are retrieved in response to natural-language questions (q-doc). This change has led to systematic mismatches between document-centric models and question-driven retrieval, including (1) input granularity (long documents vs. short questions), (2) semantic focus (scientific discourse structure vs. specific question intent), and (3) training signals (citation-based similarity vs. question-oriented relevance). To this end, we propose UniFAR, a Unified Facet-Aware Retrieval framework to jointly support doc-doc and q-doc SDR within a single architecture. UniFAR reconciles granularity differences through adaptive multi-granularity aggregation, aligns document structure with question intent via learnable facet anchors, and unifies doc-doc and q-doc supervision through joint training. Experimental results show that UniFAR consistently outperforms prior methods across multiple retrieval tasks and base models, confirming its effectiveness and generality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUniFAR\u7684\u7edf\u4e00\u68c0\u7d22\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u6587\u6863\u4e2d\u5fc3\u6a21\u578b\u4e0e\u95ee\u9898\u9a71\u52a8\u68c0\u7d22\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u7c92\u5ea6\u805a\u5408\u3001\u53ef\u5b66\u4e60\u65b9\u9762\u951a\u70b9\u4ee5\u53ca\u8054\u5408\u8bad\u7ec3\u6765\u540c\u65f6\u652f\u6301\u6587\u6863-\u6587\u6863\u548c\u95ee\u9898-\u6587\u6863\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUniFAR\u5728\u591a\u4e2a\u68c0\u7d22\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u53d1\u5c55\uff0c\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u4ece\u57fa\u4e8e\u6587\u6863\u95f4\u5173\u7cfb\u8f6c\u5411\u4e86\u4ee5\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u4e3a\u5bfc\u5411\u7684\u68c0\u7d22\u65b9\u5f0f\u3002\u8fd9\u79cd\u8f6c\u53d8\u5bfc\u81f4\u4e86\u4f20\u7edf\u6587\u6863\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u4e0e\u65b0\u7684\u95ee\u9898\u9a71\u52a8\u68c0\u7d22\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u914d\uff0c\u5305\u62ec\u8f93\u5165\u7c92\u5ea6\u3001\u8bed\u4e49\u7126\u70b9\u53ca\u8bad\u7ec3\u4fe1\u53f7\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u5f00\u53d1\u4e86UniFAR\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u81ea\u9002\u5e94\u591a\u7c92\u5ea6\u805a\u5408\u6280\u672f\u6765\u5904\u7406\u4e0d\u540c\u957f\u5ea6\u6587\u672c\u95f4\u7684\u5dee\u8ddd\uff1b\u5229\u7528\u53ef\u5b66\u4e60\u7684\u65b9\u9762\u951a\u70b9\u4f7f\u6587\u6863\u7ed3\u6784\u66f4\u597d\u5730\u4e0e\u67e5\u8be2\u610f\u56fe\u76f8\u5339\u914d\uff1b\u5e76\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6574\u5408\u6587\u6863-\u6587\u6863\u548c\u95ee\u9898-\u6587\u6863\u4e24\u79cd\u76d1\u7763\u5f62\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u65e0\u8bba\u662f\u5728\u4e0d\u540c\u7684\u68c0\u7d22\u4efb\u52a1\u8fd8\u662f\u57fa\u51c6\u6a21\u578b\u4e0a\uff0cUniFAR\u7684\u8868\u73b0\u90fd\u4f18\u4e8e\u5148\u524d\u7684\u6280\u672f\u65b9\u6848\u3002", "conclusion": "UniFAR\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u4e14\u901a\u7528\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fc3\u8fdb\u79d1\u5b66\u6587\u732e\u68c0\u7d22\u5411\u66f4\u6709\u6548\u7684\u95ee\u9898\u5bfc\u5411\u578b\u6a21\u5f0f\u8f6c\u53d8\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.23565", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.23565", "abs": "https://arxiv.org/abs/2602.23565", "authors": ["Adhyyan Narang", "Sarah Dean", "Lillian J Ratliff", "Maryam Fazel"], "title": "Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing", "comment": null, "summary": "In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the \"local\" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to \"probe\" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u591a\u4e2a\u5e73\u53f0\u4ece\u540c\u4e00\u7528\u6237\u6c60\u83b7\u53d6\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u7b97\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5b66\u4e60\u8005\u51e0\u4e4e\u80af\u5b9a\u4f1a\u6536\u655b\u5230\u5168\u5c40\u6027\u80fd\u6781\u5dee\u7684\u6a21\u578b\u7684\u95ee\u9898\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u5141\u8bb8\u5b66\u4e60\u8005'\u63a2\u6d4b'\u540c\u884c\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u4ece\u800c\u4e86\u89e3\u90a3\u4e9b\u6ca1\u6709\u9009\u62e9\u4ed6\u4eec\u7684\u7528\u6237\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u63a2\u67e5\u6e90\u8db3\u591f\u6709\u4fe1\u606f\u91cf\u65f6\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u51e0\u4e4e\u80af\u5b9a\u5730\u6536\u655b\u5230\u4e00\u4e2a\u5177\u6709\u6709\u9650\u5168\u4eba\u53e3\u98ce\u9669\u7684\u7a33\u5b9a\u70b9\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e8e\u7ecf\u6d4e\u76f8\u5173\u9886\u57df\u7684\u80cc\u666f\u4e0b\uff0c\u591a\u4e2a\u5e73\u53f0\u4ece\u76f8\u540c\u7684\u7528\u6237\u6c60\u4e2d\u83b7\u53d6\u6570\u636e\uff0c\u6bcf\u4e2a\u7528\u6237\u9009\u62e9\u6700\u80fd\u6ee1\u8db3\u4ed6\u4eec\u9700\u6c42\u7684\u5e73\u53f0\u3002\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5b66\u4e60\u8005\u5728\u5176\u89c2\u5bdf\u5230\u7684\u6570\u636e\u5206\u5e03\u4e0a\u7684'\u5c40\u90e8'\u635f\u5931\u4e0a\u3002\u7136\u800c\uff0c\u5b58\u5728\u8fd9\u6837\u7684\u60c5\u51b5\uff1a\u5373\u4f7f\u5b58\u5728\u4f4e\u5168\u4eba\u53e3\u635f\u5931\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u73b0\u6709\u7b97\u6cd5\u7684\u5b66\u4e60\u8005\u4e5f\u51e0\u4e4e\u80af\u5b9a\u4f1a\u6536\u655b\u5230\u5168\u5c40\u6027\u80fd\u6781\u5dee\u7684\u6a21\u578b\u3002\u8fd9\u79cd\u73b0\u8c61\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3a\u8fc7\u5ea6\u4e13\u4e1a\u5316\u9677\u9631\u7684\u53cd\u9988\u8bf1\u5bfc\u673a\u5236\u53d1\u751f\u3002", "method": "\u53d7\u73b0\u4ee3ML\u4e2d\u77e5\u8bc6\u84b8\u998f\u6700\u8fd1\u4f7f\u7528\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u8ba9\u5b66\u4e60\u8005\u80fd\u591f'\u63a2\u6d4b'\u540c\u884c\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u8fd9\u4f7f\u4ed6\u4eec\u80fd\u591f\u4e86\u89e3\u672a\u9009\u62e9\u4ed6\u4eec\u7684\u7528\u6237\u3002\u5206\u6790\u6307\u51fa\uff0c\u5f53\u63a2\u67e5\u6e90\u8db3\u591f\u6709\u4fe1\u606f\u4ef7\u503c\u65f6\uff08\u4f8b\u5982\uff0c\u5df2\u77e5\u7684\u5e02\u573a\u9886\u5bfc\u8005\u6216\u5927\u591a\u6570\u5177\u6709\u826f\u597d\u5168\u7403\u8868\u73b0\u7684\u540c\u884c\uff09\uff0c\u6b64\u8fc7\u7a0b\u51e0\u4e4e\u80af\u5b9a\u80fd\u6536\u655b\u81f3\u4e00\u4e2a\u5168\u4eba\u7fa4\u98ce\u9669\u6709\u9650\u7684\u9759\u6b62\u70b9\u3002", "result": "\u901a\u8fc7\u5728MovieLens\u3001Census\u548cAmazon Sentiment\u6570\u636e\u96c6\u4e0a\u7684\u534a\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7814\u7a76\u53d1\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u5728\u63a2\u67e5\u6e90\u5177\u5907\u5145\u5206\u4fe1\u606f\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u51e0\u4e4e\u80af\u5b9a\u5730\u6536\u655b\u5230\u4e00\u4e2a\u5177\u6709\u9650\u5b9a\u5168\u4eba\u53e3\u98ce\u9669\u7684\u7a33\u6001\u70b9\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5728\u591a\u5e73\u53f0\u7ade\u4e89\u73af\u5883\u4e0b\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u53ef\u80fd\u9677\u5165\u8fc7\u5ea6\u4e13\u4e1a\u5316\u9677\u9631\u7684\u98ce\u9669\uff0c\u5e76\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u7b97\u6cd5\u6765\u514b\u670d\u8fd9\u4e2a\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u5176\u4ed6\u6a21\u578b\u4f5c\u4e3a\u63a2\u67e5\u6e90\u4ee5\u6539\u5584\u81ea\u8eab\u5bf9\u672a\u670d\u52a1\u7528\u6237\u7684\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2602.23964", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23964", "abs": "https://arxiv.org/abs/2602.23964", "authors": ["Zhiguo Chen", "Guohao Sun", "Yiming Qiu", "Xingzhi Yao", "Mingming Li", "Huimu Wang", "Yangqi Zhang", "Songlin Wang", "Sulong Xu"], "title": "RAD-DPO: Robust Adaptive Denoising Direct Preference Optimization for Generative Retrieval in E-commerce", "comment": null, "summary": "Generative Retrieval (GR) has emerged as a powerful paradigm in e-commerce search, retrieving items via autoregressive decoding of Semantic IDs (SIDs). However, aligning GR with complex user preferences remains challenging. While Direct Preference Optimization (DPO) offers an efficient alignment solution, its direct application to structured SIDs suffers from three limitations: (i) it penalizes shared hierarchical prefixes, causing gradient conflicts; (ii) it is vulnerable to noisy pseudo-negatives from implicit feedback; and (iii) in multi-label queries with multiple relevant items, it exacerbates a probability \"squeezing effect\" among valid candidates. To address these issues, we propose RAD-DPO, which introduces token-level gradient detachment to protect prefix structures, similarity-based dynamic reward weighting to mitigate label noise, and a multi-label global contrastive objective integrated with global SFT loss to explicitly expand positive coverage. Extensive offline experiments and online A/B testing on a large-scale e-commerce platform demonstrate significant improvements in ranking quality and training efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5RAD-DPO\uff0c\u4ee5\u89e3\u51b3\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u5728\u7ed3\u6784\u5316\u8bed\u4e49ID(SIDs)\u5e94\u7528\u4e2d\u7684\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u5171\u4eab\u5c42\u6b21\u524d\u7f00\u7684\u68af\u5ea6\u51b2\u7a81\u3001\u5bf9\u9690\u5f0f\u53cd\u9988\u4e2d\u566a\u58f0\u4f2a\u8d1f\u6837\u672c\u7684\u8106\u5f31\u6027\u4ee5\u53ca\u591a\u6807\u7b7e\u67e5\u8be2\u4e2d\u6709\u6548\u5019\u9009\u4e4b\u95f4\u7684\u6982\u7387\u201c\u6324\u538b\u6548\u5e94\u201d\u3002\u901a\u8fc7\u5f15\u5165token\u7ea7\u522b\u7684\u68af\u5ea6\u5206\u79bb\u3001\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u52a8\u6001\u5956\u52b1\u6743\u91cd\u8c03\u6574\u53ca\u4e0e\u5168\u5c40SFT\u635f\u5931\u7ed3\u5408\u7684\u591a\u6807\u7b7e\u5168\u5c40\u5bf9\u6bd4\u76ee\u6807\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u4e0a\u7684\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u4e86\u663e\u8457\u7684\u6392\u540d\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u6539\u8fdb\u3002", "motivation": "\u751f\u6210\u5f0f\u68c0\u7d22\uff08GR\uff09\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u8303\u5f0f\uff0c\u5728\u7535\u5546\u641c\u7d22\u9886\u57df\u901a\u8fc7\u81ea\u56de\u5f52\u89e3\u7801\u8bed\u4e49ID\uff08SIDs\uff09\u6765\u68c0\u7d22\u5546\u54c1\u3002\u7136\u800c\uff0c\u4f7fGR\u9002\u5e94\u590d\u6742\u7684\u7528\u6237\u504f\u597d\u4ecd\u9762\u4e34\u6311\u6218\u3002\u5c3d\u7ba1\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5bf9\u9f50\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5c06\u5176\u76f4\u63a5\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u7684SIDs\u65f6\u5b58\u5728\u4e09\u65b9\u9762\u7684\u95ee\u9898\uff1a\u4e00\u662f\u60e9\u7f5a\u5171\u4eab\u7684\u5c42\u7ea7\u524d\u7f00\u5bfc\u81f4\u68af\u5ea6\u51b2\u7a81\uff1b\u4e8c\u662f\u5bb9\u6613\u53d7\u5230\u6765\u81ea\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u566a\u58f0\u4f2a\u8d1f\u9762\u6837\u672c\u5f71\u54cd\uff1b\u4e09\u662f\u5bf9\u4e8e\u542b\u6709\u591a\u9879\u76f8\u5173\u7269\u54c1\u7684\u591a\u6807\u7b7e\u67e5\u8be2\uff0c\u52a0\u5267\u4e86\u6709\u6548\u5019\u9009\u8005\u4e4b\u95f4\u7684\u6982\u7387\u2018\u6324\u538b\u6548\u5e94\u2019\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86RAD-DPO\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5305\u62ec\u4ee5\u4e0b\u5173\u952e\u7ec4\u4ef6\uff1a\n- token\u7ea7\u522b\u7684\u68af\u5ea6\u5206\u79bb\uff0c\u7528\u6765\u4fdd\u62a4\u524d\u7f00\u7ed3\u6784\u4e0d\u53d7\u635f\u5bb3\u3002\n- \u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u52a8\u6001\u5956\u52b1\u52a0\u6743\u673a\u5236\uff0c\u65e8\u5728\u51cf\u8f7b\u6807\u7b7e\u566a\u97f3\u7684\u5f71\u54cd\u3002\n- \u4e00\u4e2a\u4e0e\u5168\u5c40SFT\u635f\u5931\u76f8\u7ed3\u5408\u7684\u591a\u6807\u7b7e\u5168\u5c40\u5bf9\u6bd4\u76ee\u6807\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u660e\u786e\u6269\u5927\u6b63\u9762\u8986\u76d6\u8303\u56f4\u3002", "result": "\u5e7f\u6cdb\u7684\u79bb\u7ebf\u5b9e\u9a8c\u7ed3\u679c\u4ee5\u53ca\u5728\u4e00\u4e2a\u5927\u89c4\u6a21\u7535\u5546\u5e73\u53f0\u8fdb\u884c\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5RAD-DPO\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6392\u5e8f\u8d28\u91cf\u5e76\u589e\u5f3a\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0cRAD-DPO\u901a\u8fc7\u5bf9\u73b0\u6709DPO\u6280\u672f\u7684\u6539\u8fdb\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5176\u5728\u5904\u7406\u7ed3\u6784\u5316SID\u6570\u636e\u65f6\u9047\u5230\u7684\u5173\u952e\u96be\u9898\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u4e3a\u751f\u6210\u5f0f\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u52a0\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23978", "abs": "https://arxiv.org/abs/2602.23978", "authors": ["Huimu Wang", "Xingzhi Yao", "Yiming Qiu", "Qinghong Zhang", "Haotian Wang", "Yufan Cui", "Songlin Wang", "Sulong Xu", "Mingming Li"], "title": "Towards Efficient and Generalizable Retrieval: Adaptive Semantic Quantization and Residual Knowledge Transfer", "comment": null, "summary": "While semantic ID-based generative retrieval enables efficient end-to-end modeling in industrial applications, these methods face a persistent trade-off: head items are susceptible to ID collisions that negatively impact downstream tasks, whereas data-sparse tail items, including cold-start items, exhibit limited generalization. To address this issue, we propose the Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ) framework. The framework introduces Sequential Adaptive Residual Quantization (SARQ) to dynamically allocate code lengths based on item path entropy, assigning longer, discriminative IDs to head items and shorter, generalizable IDs to tail items. To mitigate data sparsity, the Anchored Curriculum Residual Quantization (ACRQ) component utilizes a frozen semantic manifold learned from head items to regularize and accelerate the representation learning of tail items. Experimental results from a large-scale industrial search system and multiple public datasets indicate that SA^2CRQ yields consistent improvements over existing baselines, particularly in cold-start retrieval scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSA^2CRQ\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u914d\u7f16\u7801\u957f\u5ea6\u548c\u5229\u7528\u5934\u90e8\u9879\u76ee\u5b66\u4e60\u5230\u7684\u8bed\u4e49\u6d41\u5f62\u6765\u52a0\u901f\u5c3e\u90e8\u9879\u76ee\u7684\u8868\u793a\u5b66\u4e60\uff0c\u4ece\u800c\u6539\u5584\u4e86\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u68c0\u7d22\u5728\u5904\u7406\u5934\u90e8\u548c\u5c3e\u90e8\u9879\u76ee\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u68c0\u7d22\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e00\u4e2a\u6301\u7eed\u7684\u95ee\u9898\uff1a\u5934\u90e8\u9879\u76ee\u5bb9\u6613\u9047\u5230ID\u78b0\u649e\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u800c\u6570\u636e\u7a00\u758f\u7684\u5c3e\u90e8\u9879\u76ee\uff08\u5305\u62ec\u51b7\u542f\u52a8\u9879\u76ee\uff09\u5219\u8868\u73b0\u51fa\u6709\u9650\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e24\u90e8\u5206\uff1a1. Sequential Adaptive Residual Quantization (SARQ)\uff0c\u6839\u636e\u9879\u76ee\u8def\u5f84\u71b5\u52a8\u6001\u8c03\u6574\u7f16\u7801\u957f\u5ea6\uff1b2. Anchored Curriculum Residual Quantization (ACRQ)\uff0c\u4f7f\u7528\u4ece\u5934\u90e8\u9879\u76ee\u5b66\u5230\u7684\u56fa\u5b9a\u8bed\u4e49\u6d41\u5f62\u6765\u89c4\u8303\u5e76\u52a0\u901f\u5c3e\u90e8\u9879\u76ee\u7684\u8868\u793a\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5728\u4e00\u4e2a\u5927\u89c4\u6a21\u5de5\u4e1a\u641c\u7d22\u5f15\u64ce\u53ca\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\uff0cSA^2CRQ\u80fd\u591f\u4e00\u81f4\u5730\u63d0\u9ad8\u6027\u80fd\uff0c\u5c24\u5176\u5728\u51b7\u542f\u52a8\u68c0\u7d22\u60c5\u666f\u4e0b\u6548\u679c\u663e\u8457\u3002", "conclusion": "SA^2CRQ\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u521b\u65b0\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u57fa\u4e8e\u8bed\u4e49ID\u7684\u751f\u6210\u68c0\u7d22\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e3a\u63d0\u9ad8\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u68c0\u7d22\u6548\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.23982", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23982", "abs": "https://arxiv.org/abs/2602.23982", "authors": ["Minh Hieu Nguyen"], "title": "Robust Aggregation for Federated Sequential Recommendation with Sparse and Poisoned Data", "comment": null, "summary": "Federated sequential recommendation distributes model training across user devices so that behavioural data remains local, reducing privacy risks. Yet, this setting introduces two intertwined difficulties. On the one hand, individual clients typically contribute only short and highly sparse interaction sequences, limiting the reliability of learned user representations. On the other hand, the federated optimisation process is vulnerable to malicious or corrupted client updates, where poisoned gradients can significantly distort the global model. These challenges are particularly severe in sequential recommendation, where temporal dynamics further complicate signal aggregation. To address this problem, we propose a robust aggregation framework tailored for federated sequential recommendation under sparse and adversarial conditions. Instead of relying on standard averaging, our method introduces a defence-aware aggregation mechanism that identifies and down-weights unreliable client updates while preserving informative signals from sparse but benign participants. The framework incorporates representation-level constraints to stabilise user and item embeddings, preventing poisoned or anomalous contributions from dominating the global parameter space. In addition, we integrate sequence-aware regularisation to maintain temporal coherence in user modelling despite limited local observations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7a00\u758f\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u7684\u9c81\u68d2\u805a\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u9632\u5fa1\u610f\u8bc6\u7684\u805a\u5408\u673a\u5236\u8bc6\u522b\u5e76\u964d\u4f4e\u4e0d\u53ef\u9760\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u53c2\u4e0e\u8005\u7684\u4fe1\u606f\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u8868\u793a\u7ea7\u7ea6\u675f\u548c\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\u6765\u7a33\u5b9a\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\u4ee5\u53ca\u4fdd\u6301\u7528\u6237\u5efa\u6a21\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "motivation": "\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u867d\u7136\u51cf\u5c11\u4e86\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u4e00\u662f\u5355\u4e2a\u5ba2\u6237\u7aef\u901a\u5e38\u53ea\u8d21\u732e\u77ed\u4e14\u9ad8\u5ea6\u7a00\u758f\u7684\u4ea4\u4e92\u5e8f\u5217\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u5230\u7684\u7528\u6237\u8868\u793a\u7684\u53ef\u9760\u6027\uff1b\u4e8c\u662f\u8054\u90a6\u4f18\u5316\u8fc7\u7a0b\u5bb9\u6613\u53d7\u5230\u6076\u610f\u6216\u635f\u574f\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\uff0c\u5176\u4e2d\u4e2d\u6bd2\u68af\u5ea6\u53ef\u80fd\u4f1a\u4e25\u91cd\u626d\u66f2\u5168\u5c40\u6a21\u578b\u3002\u8fd9\u4e9b\u95ee\u9898\u5728\u5177\u6709\u65f6\u95f4\u52a8\u6001\u6027\u7684\u5e8f\u5217\u63a8\u8350\u4e2d\u5c24\u4e3a\u4e25\u91cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u805a\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u9632\u5fa1\u610f\u8bc6\u7684\u805a\u5408\u673a\u5236\u6765\u8bc6\u522b\u5e76\u51cf\u5c11\u4e0d\u53ef\u9760\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u7559\u6765\u81ea\u7a00\u758f\u4f46\u826f\u6027\u53c2\u4e0e\u8005\u7684\u6709\u7528\u4fe1\u53f7\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5f15\u5165\u4e86\u8868\u793a\u7ea7\u7ea6\u675f\u4ee5\u7a33\u5b9a\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\uff0c\u5e76\u7ed3\u5408\u4e86\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\u4ee5\u5728\u6709\u9650\u672c\u5730\u89c2\u5bdf\u7684\u60c5\u51b5\u4e0b\u7ef4\u6301\u7528\u6237\u5efa\u6a21\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u51cf\u8f7b\u6076\u610f\u5ba2\u6237\u7aef\u5bf9\u5168\u5c40\u6a21\u578b\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u4ece\u7a00\u758f\u6570\u636e\u4e2d\u83b7\u53d6\u7684\u6709\u6548\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u5b83\u6709\u52a9\u4e8e\u7ef4\u62a4\u7528\u6237\u548c\u7269\u54c1\u5d4c\u5165\u7684\u7a33\u5b9a\u6027\uff0c\u5373\u4f7f\u9762\u5bf9\u6f5c\u5728\u7684\u4e2d\u6bd2\u6216\u5f02\u5e38\u8d21\u732e\u65f6\u4e5f\u80fd\u5982\u6b64\u3002\u8fd8\u901a\u8fc7\u5e8f\u5217\u611f\u77e5\u6b63\u5219\u5316\u589e\u5f3a\u4e86\u7528\u6237\u884c\u4e3a\u6a21\u5f0f\u7684\u65f6\u95f4\u8fde\u8d2f\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8054\u90a6\u5e8f\u5217\u63a8\u8350\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u9c81\u68d2\u805a\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u7a00\u758f\u6027\u548c\u5bf9\u6297\u73af\u5883\u4e0b\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.23581", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23581", "abs": "https://arxiv.org/abs/2602.23581", "authors": ["Xiang Ao"], "title": "SDMixer: Sparse Dual-Mixer for Time Series Forecasting", "comment": "12pages,2 figures", "summary": "Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41\u7a00\u758fMixer\u9884\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u65f6\u57df\u548c\u9891\u57df\u5e8f\u5217\u4e2d\u5206\u522b\u63d0\u53d6\u5168\u5c40\u8d8b\u52bf\u548c\u5c40\u90e8\u52a8\u6001\u7279\u5f81\uff0c\u5e76\u91c7\u7528\u7a00\u758f\u673a\u5236\u8fc7\u6ee4\u65e0\u6548\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u8de8\u53d8\u91cf\u4f9d\u8d56\u5efa\u6a21\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6b64\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u573a\u666f\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u9886\u5148\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u4ea4\u901a\u3001\u80fd\u6e90\u548c\u91d1\u878d\u7b49\u9886\u57df\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6570\u636e\u901a\u5e38\u5b58\u5728\u591a\u5c3a\u5ea6\u7279\u6027\u3001\u5f31\u76f8\u5173\u6027\u548c\u566a\u58f0\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u73b0\u6709\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u6d41\u7a00\u758fMixer\u9884\u6d4b\u6846\u67b6\uff0c\u65e8\u5728\u4ece\u65f6\u57df\u548c\u9891\u57df\u4e24\u65b9\u9762\u6355\u6349\u5e8f\u5217\u4e2d\u7684\u5168\u5c40\u8d8b\u52bf\u4e0e\u5c40\u90e8\u52a8\u6001\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u7a00\u758f\u673a\u5236\u53bb\u9664\u4e0d\u76f8\u5173\u4fe1\u606f\u4ee5\u589e\u5f3a\u8de8\u53d8\u91cf\u95f4\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u7684\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u79cd\u5b9e\u9645\u5e94\u7528\u573a\u666f\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u53ca\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u53cc\u6d41\u5904\u7406\u4e0e\u65f6-\u9891\u5206\u6790\u7ed3\u5408\u7684\u65b9\u6cd5\u8bba\uff0c\u4ee5\u53ca\u5229\u7528\u7a00\u758f\u7b56\u7565\u4f18\u5316\u4fe1\u606f\u7b5b\u9009\u8fc7\u7a0b\uff0c\u672c\u7814\u7a76\u4e3a\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u7528\u4ef7\u503c\u548c\u53d1\u5c55\u6f5c\u529b\u3002"}}
{"id": "2602.24067", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24067", "abs": "https://arxiv.org/abs/2602.24067", "authors": ["Thom Vaughan", "Pedro Ortiz Suarez"], "title": "Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains", "comment": "8 pages, 4 tables. Companion website and reproducible analysis code available at https://thunderpoot.github.io/wcag-audit/ and https://github.com/thunderpoot/wcag-audit", "summary": "We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Common Crawl\u7684\u6863\u6848\uff0c\u5bf9500\u4e2a\u6700\u5e38\u8bbf\u95ee\u7684\u7f51\u7ad9\u8fdb\u884c\u4e86WCAG 2.1/2.2 AA\u7ea7\u989c\u8272\u5bf9\u6bd4\u5ea6\u5408\u89c4\u6027\u7684\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u5ba1\u8ba1\u3002\u7ed3\u679c\u663e\u793a40.9%\u7684\u989c\u8272\u914d\u5bf9\u672a\u80fd\u8fbe\u5230\u6b63\u5e38\u6587\u672c\u6240\u9700\u76844.5:1\u5bf9\u6bd4\u5ea6\u9608\u503c\uff0c\u8868\u660e\u5373\u4f7f\u662f\u9ad8\u6d41\u91cf\u7f51\u7ad9\u4e5f\u666e\u904d\u5b58\u5728\u989c\u8272\u5bf9\u6bd4\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u8bc4\u4f30\u548c\u63d0\u9ad8\u4e92\u8054\u7f51\u4e0a\u4e3b\u8981\u7f51\u7ad9\u7684\u989c\u8272\u5bf9\u6bd4\u5ea6\u5408\u89c4\u6027\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e9b\u7f51\u7ad9\u5bf9\u4e8e\u6240\u6709\u7528\u6237\uff08\u5305\u62ec\u89c6\u89c9\u969c\u788d\u8005\uff09\u90fd\u662f\u53ef\u8bbf\u95ee\u7684\u3002\u901a\u8fc7\u5229\u7528\u516c\u5f00\u7684\u6570\u636e\u96c6\u8fdb\u884c\u9759\u6001\u5206\u6790\uff0c\u7814\u7a76\u8fd8\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u76ee\u6807\u7f51\u7ad9\u670d\u52a1\u5668\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u7684\u65b9\u6cd5\u662f\u57fa\u4e8eCommon Crawl CC-MAIN-2026-08\u722c\u866b\u5b58\u6863\u4e2d\u7684\u6570\u636e\uff0c\u800c\u4e0d\u662f\u6267\u884c\u5b9e\u65f6\u7f51\u9875\u6293\u53d6\uff0c\u6765\u5206\u6790\u9009\u5b9a\u7f51\u7ad9\u7684\u9996\u9875\u3002\u7814\u7a76\u7279\u522b\u5173\u6ce8\u4e86CSS\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u989c\u8272\u914d\u5bf9\uff0c\u5e76\u4f9d\u636eWCAG\u6307\u5357\u68c0\u67e5\u8fd9\u4e9b\u914d\u5bf9\u662f\u5426\u7b26\u5408\u6700\u4f4e\u989c\u8272\u5bf9\u6bd4\u5ea6\u6807\u51c6\u3002", "result": "\u5728\u5206\u6790\u4e86240\u4e2a\u4e3b\u9875\u540e\uff0c\u53d1\u73b0\u5171\u67094,327\u79cd\u4e0d\u540c\u7684\u524d\u666f/\u80cc\u666f\u989c\u8272\u7ec4\u5408\uff0c\u5176\u4e2d1,771\u79cd(\u5360\u603b\u6570\u768440.9%)\u4e0d\u7b26\u5408\u6b63\u5e38\u6587\u672c\u8981\u6c42\u76844.5:1\u5bf9\u6bd4\u5ea6\u6bd4\u7387\u3002\u5404\u7ad9\u70b9\u901a\u8fc7\u7387\u7684\u4e2d\u4f4d\u6570\u4e3a62.7%\uff0c\u53ea\u670920.4%\u7684\u7ad9\u70b9\u5728\u5176\u68c0\u6d4b\u5230\u7684\u6240\u6709\u989c\u8272\u7ec4\u5408\u4e0a\u5b8c\u5168\u7b26\u5408\u89c4\u5b9a\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u5373\u4f7f\u662f\u5728\u6700\u53d7\u6b22\u8fce\u7684\u7f51\u7ad9\u4e0a\uff0c\u989c\u8272\u5bf9\u6bd4\u5ea6\u95ee\u9898\u4ecd\u7136\u662f\u4e00\u4e2a\u666e\u904d\u5b58\u5728\u7684\u53ef\u8bbf\u95ee\u6027\u969c\u788d\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u7684\u5408\u89c4\u7a0b\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63d0\u793a\u9700\u8981\u8fdb\u4e00\u6b65\u52aa\u529b\u6765\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\u3002"}}
{"id": "2602.24125", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24125", "abs": "https://arxiv.org/abs/2602.24125", "authors": ["Rohit Chivukula", "T. Jaya Lakshmi", "Hemlata Sharma", "C. H. S. N. P. Sairam Rallabandi"], "title": "Recommendation Algorithms: A Comparative Study in Movie Domain", "comment": null, "summary": "Intelligent recommendation systems have clearly increased the revenue of well-known e-commerce firms. Users receive product recommendations from recommendation systems. Cinematic recommendations are made to users by a movie recommendation system. There have been numerous approaches to the problem of recommendation in the literature. It is viewed as a regression task in this research. A regression model was built using novel properties extracted from the dataset and used as features in the model. For experimentation, the Netflix challenge dataset has been used. Video streaming service Netflix is a popular choice for many. Customers' prior viewing habits are taken into account when Netflix makes movie recommendations to them. An exploratory data analysis on the Netflix dataset was conducted to gain insights into user rating behaviour and movie characteristics. Various kinds of features, including aggregating, Matrix Factorization (MF) based, and user and movie similarity based, have been extracted in the subsequent stages. In addition to a feature in the XGBoost regression algorithm, the K-Nearest Neighbors and MF algorithms from Python's Surprise library are used for recommendations. Based on Root Mean Square Error (RMSE), MF-based algorithms have provided the best recommendations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u63a8\u8350\u95ee\u9898\u89c6\u4e3a\u56de\u5f52\u4efb\u52a1\uff0c\u5229\u7528\u4eceNetflix\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u7684\u65b0\u7279\u5f81\u6784\u5efa\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u7ed3\u5408XGBoost\u3001K-\u6700\u8fd1\u90bb\u548c\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u7b97\u6cd5\u6765\u6539\u8fdb\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\u3002\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u7b97\u6cd5\u5728RMSE\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63d0\u9ad8\u7535\u5b50\u5546\u52a1\u516c\u53f8\u7684\u6536\u5165\uff0c\u6539\u5584\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u7535\u5f71\u63a8\u8350\u3002", "method": "\u4f7f\u7528Netflix\u6311\u6218\u6570\u636e\u96c6\uff0c\u5bf9\u7528\u6237\u8bc4\u5206\u884c\u4e3a\u548c\u7535\u5f71\u7279\u6027\u8fdb\u884c\u4e86\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u3002\u7136\u540e\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u4e86\u805a\u5408\u3001\u57fa\u4e8e\u77e9\u9635\u5206\u89e3(MF)\u4ee5\u53ca\u57fa\u4e8e\u7528\u6237\u548c\u7535\u5f71\u76f8\u4f3c\u6027\u7684\u591a\u79cd\u7279\u5f81\u3002\u6700\u540e\uff0c\u91c7\u7528XGBoost\u56de\u5f52\u7b97\u6cd5\u4e2d\u7684\u4e00\u4e2a\u7279\u5f81\uff0c\u540c\u65f6\u5229\u7528Python\u7684Surprise\u5e93\u4e2d\u7684K-\u6700\u8fd1\u90bb(K-Nearest Neighbors, KNN)\u7b97\u6cd5\u548cMF\u7b97\u6cd5\u8fdb\u884c\u63a8\u8350\u3002", "result": "\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u63a8\u8350\u7b97\u6cd5\u5728\u6839\u5747\u65b9\u8bef\u5dee(RMSE)\u8fd9\u4e00\u8bc4\u4ef7\u6307\u6807\u4e0a\u63d0\u4f9b\u4e86\u6700\u4f73\u7684\u63a8\u8350\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u5bf9Netflix\u6570\u636e\u96c6\u7684\u6df1\u5165\u5206\u6790\u4e0e\u5904\u7406\uff0c\u57fa\u4e8e\u77e9\u9635\u5206\u89e3\u7684\u65b9\u6cd5\u88ab\u8bc1\u660e\u662f\u63d0\u9ad8\u7535\u5f71\u63a8\u8350\u7cfb\u7edf\u51c6\u786e\u6027\u7684\u6709\u6548\u624b\u6bb5\u3002"}}
{"id": "2602.23614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23614", "abs": "https://arxiv.org/abs/2602.23614", "authors": ["Kejing Yin", "Haizhou Xu", "Wenfang Yao", "Chen Liu", "Zijie Chen", "Yui Haang Cheung", "William K. Cheung", "Jing Qin"], "title": "When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion", "comment": null, "summary": "Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u548c\u80f8\u90e8X\u5149\u7247\uff08CXR\uff09\u4e4b\u95f4\u7684\u591a\u6a21\u6001\u878d\u5408\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u878d\u5408\u4f55\u65f6\u80fd\u6539\u5584\u9884\u6d4b\u3001\u4e0d\u540c\u878d\u5408\u7b56\u7565\u7684\u6bd4\u8f83\u3001\u73b0\u6709\u65b9\u6cd5\u5bf9\u7f3a\u5931\u6a21\u6001\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u591a\u6a21\u6001\u6a21\u578b\u662f\u5426\u5b9e\u73b0\u7b97\u6cd5\u516c\u5e73\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6a21\u6001\u5b8c\u6574\u65f6\u591a\u6a21\u6001\u878d\u5408\u786e\u5b9e\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7ed3\u5408EHR\u4e0eCXR\u4fe1\u606f\u7684\u75be\u75c5\u4e0a\u3002\u7136\u800c\uff0c\u5f53\u9762\u4e34\u5b9e\u9645\u4e2d\u5e38\u89c1\u7684\u6570\u636e\u7f3a\u5931\u60c5\u51b5\u65f6\uff0c\u9664\u975e\u6a21\u578b\u7279\u522b\u8bbe\u8ba1\u6765\u5904\u7406\u4e0d\u5b8c\u6574\u8f93\u5165\uff0c\u5426\u5219\u591a\u6a21\u6001\u7684\u4f18\u52bf\u4f1a\u8fc5\u901f\u51cf\u5f31\u3002\u6b64\u5916\uff0c\u591a\u6a21\u6001\u878d\u5408\u672c\u8eab\u5e76\u4e0d\u81ea\u7136\u63d0\u9ad8\u516c\u5e73\u6027\uff0c\u5b50\u7fa4\u4f53\u95f4\u7684\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u7ec4\u95f4\u654f\u611f\u5ea6\u7684\u4e0d\u5e73\u7b49\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u6709\u671b\u63a8\u8fdb\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7684\u53d1\u5c55\uff0c\u4f46\u5728\u5b9e\u8df5\u4e2d\u5c24\u5176\u662f\u5728\u6a21\u6001\u7f3a\u5931\u548c\u516c\u5e73\u6027\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u771f\u6b63\u5e2e\u52a9\u7684\u60c5\u51b5\u5c1a\u4e0d\u6e05\u695a\u3002\u8fd9\u9879\u5de5\u4f5c\u7684\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u56de\u7b54\u56db\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u591a\u6a21\u6001\u878d\u5408\u4f55\u65f6\u80fd\u6539\u5584\u4e34\u5e8a\u9884\u6d4b\uff1b\u4e0d\u540c\u878d\u5408\u7b56\u7565\u4e4b\u95f4\u5982\u4f55\u6bd4\u8f83\uff1b\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e8e\u7f3a\u5931\u6a21\u6001\u6709\u591a\u5f3a\u7684\u9c81\u68d2\u6027\uff1b\u4ee5\u53ca\u591a\u6a21\u6001\u6a21\u578b\u662f\u5426\u5b9e\u73b0\u4e86\u7b97\u6cd5\u4e0a\u7684\u516c\u5e73\u6027\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5229\u7528MIMIC-IV\u548cMIMIC-CXR\u63d0\u4f9b\u7684\u6807\u51c6\u5316\u961f\u5217\u8fdb\u884c\u4e86EHR\u4e0eCXR\u4e4b\u95f4\u591a\u6a21\u6001\u878d\u5408\u7684\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u3002\u4ed6\u4eec\u8003\u5bdf\u4e86\u51e0\u79cd\u4e0d\u540c\u7684\u878d\u5408\u7b56\u7565\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u7b56\u7565\u5728\u6a21\u6001\u5b8c\u6574\u53ca\u7f3a\u5931\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u8fd8\u8bc4\u4f30\u4e86\u591a\u6a21\u6001\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u7fa4\u4e9a\u7ec4\u4e2d\u7684\u516c\u5e73\u6027\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\u65f6\uff0c\u591a\u6a21\u6001\u878d\u5408\u786e\u5b9e\u53ef\u4ee5\u63d0\u9ad8\u67d0\u4e9b\u75be\u75c5\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u9700\u8981\u4eceEHR\u548cCXR\u4e2d\u83b7\u53d6\u4e92\u8865\u4fe1\u606f\u7684\u75be\u75c5\u3002\u4f46\u662f\uff0c\u9762\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7ecf\u5e38\u9047\u5230\u7684\u6570\u636e\u7f3a\u5931\u95ee\u9898\u65f6\uff0c\u9664\u975e\u4e13\u95e8\u8bbe\u8ba1\u4e86\u80fd\u591f\u5e94\u5bf9\u8fd9\u79cd\u60c5\u5f62\u7684\u6a21\u578b\uff0c\u5426\u5219\u591a\u6a21\u6001\u5e26\u6765\u7684\u597d\u5904\u5c06\u5feb\u901f\u6d88\u5931\u3002\u53e6\u5916\uff0c\u5355\u7eaf\u4f9d\u9760\u591a\u6a21\u6001\u878d\u5408\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u7b97\u6cd5\u516c\u5e73\u6027\u7684\u63d0\u5347\uff0c\u8de8\u4eba\u7fa4\u4e9a\u7ec4\u95f4\u7684\u5dee\u5f02\u4e3b\u8981\u7531\u4e0d\u540c\u7fa4\u4f53\u95f4\u654f\u611f\u5ea6\u7684\u4e0d\u5747\u8861\u5f15\u8d77\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u591a\u6a21\u6001\u5b66\u4e60\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u6709\u76ca\u3001\u5728\u54ea\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u5931\u8d25\u53ca\u5176\u80cc\u540e\u539f\u56e0\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u4e3a\u5f00\u53d1\u65e2\u6709\u6548\u53c8\u53ef\u9760\u7684\u4e34\u5e8a\u591a\u6a21\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u6b64\u5916\uff0c\u7814\u7a76\u56e2\u961f\u8fd8\u53d1\u5e03\u4e86\u7075\u6d3b\u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305\uff0c\u652f\u6301\u65b0\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u5373\u63d2\u5373\u7528\u96c6\u6210\uff0c\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u5185\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2602.24229", "categories": ["cs.IR", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.24229", "abs": "https://arxiv.org/abs/2602.24229", "authors": ["W\u0142odzimierz Lewoniewski", "Milena Str\u00f3\u017cyna", "Izabela Czuma\u0142owska", "El\u017cbieta Lewa\u0144ska"], "title": "Science Fiction and Fantasy in Wikipedia: Exploring Structural and Semantic Cues", "comment": "Supplementary materials: https://data.lewoniewski.info/fantasy/", "summary": "Identifying which Wikipedia articles are related to science fiction, fantasy, or their hybrids is challenging because genre boundaries are porous and frequently overlap. Wikipedia nonetheless offers machine-readable structure beyond text, including categories, internal links (wikilinks), and statements if corresponding Wikidata items. However, each of these signals reflects community conventions and can be biased or incomplete. This study examines structural and semantic features of Wikipedia articles that can be used to identify content related to science fiction and fantasy (SF/F).", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\u6765\u8bc6\u522b\u4e0e\u79d1\u5e7b\u548c\u5947\u5e7b\uff08SF/F\uff09\u76f8\u5173\u7684\u5185\u5bb9\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u7c7b\u578b\u7684\u8fb9\u754c\u5f80\u5f80\u662f\u6a21\u7cca\u4e14\u91cd\u53e0\u7684\u3002", "motivation": "\u7531\u4e8e\u79d1\u5e7b\u3001\u5947\u5e7b\u53ca\u5176\u6df7\u5408\u4f53\u7684\u6587\u7ae0\u7c7b\u578b\u754c\u9650\u6a21\u7cca\u4e14\u5e38\u5e38\u91cd\u53e0\uff0c\u5728\u7ef4\u57fa\u767e\u79d1\u4e0a\u8fa8\u8bc6\u5b83\u4eec\u5177\u6709\u6311\u6218\u6027\u3002\u7136\u800c\uff0c\u7ef4\u57fa\u767e\u79d1\u63d0\u4f9b\u4e86\u6587\u672c\u4e4b\u5916\u7684\u673a\u5668\u53ef\u8bfb\u7ed3\u6784\uff0c\u5982\u5206\u7c7b\u3001\u5185\u90e8\u94fe\u63a5\u4ee5\u53ca\u5bf9\u5e94\u7684\u7ef4\u57fa\u6570\u636e\u9879\u58f0\u660e\u3002\u4e0d\u8fc7\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u53cd\u6620\u4e86\u793e\u533a\u60ef\u4f8b\uff0c\u53ef\u80fd\u5e26\u6709\u504f\u89c1\u6216\u4e0d\u5b8c\u6574\u3002", "method": "\u8fd9\u9879\u7814\u7a76\u901a\u8fc7\u68c0\u67e5\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u6765\u8bc6\u522b\u4e0e\u79d1\u5e7b\u548c\u5947\u5e7b\u76f8\u5173\u7684\u6761\u76ee\u3002", "result": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u7ef4\u57fa\u767e\u79d1\u63d0\u4f9b\u7684\u989d\u5916\u7ed3\u6784\u5316\u4fe1\u606f\u6765\u66f4\u597d\u5730\u7406\u89e3\u548c\u5206\u7c7b\u79d1\u5e7b\u53ca\u5947\u5e7b\u5185\u5bb9\uff0c\u5c3d\u7ba1\u5b58\u5728\u793e\u533a\u60ef\u4f8b\u5bfc\u81f4\u7684\u6f5c\u5728\u504f\u5dee\u6216\u4fe1\u606f\u4e0d\u5168\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u7ef4\u57fa\u767e\u79d1\u6587\u7ae0\u4e2d\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8bc6\u522b\u51fa\u4e0e\u79d1\u5e7b\u548c\u5947\u5e7b\u6709\u5173\u7684\u5185\u5bb9\uff0c\u5373\u4f7f\u5728\u9762\u5bf9\u7c7b\u578b\u754c\u9650\u6a21\u7cca\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002"}}
{"id": "2602.23633", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23633", "abs": "https://arxiv.org/abs/2602.23633", "authors": ["Yubo Zhou", "Luo Luo", "Guang Dai", "Haishan Ye"], "title": "On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation", "comment": null, "summary": "Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $\u03ba$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $\u03b5$-stationary point with an oracle complexity of $\\mathcal{O}(\u03ba^7 \u03b5^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\\mathcal{O}(\u03b5^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $\u03ba$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5355\u5faa\u73af\u968f\u673a\u8fd1\u4f3c\u9690\u5f0f\u5fae\u5206\uff08SSAID\uff09\u7b97\u6cd5\u8fdb\u884c\u4e86\u6df1\u5165\u7684\u6536\u655b\u6027\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u4fdd\u6301\u5355\u5faa\u73af\u66f4\u65b0\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u80fd\u591f\u8fbe\u5230\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u591a\u5faa\u73af\u65b9\u6cd5\u76f8\u540c\u7684\u6700\u4f18\u6536\u655b\u7387\uff0c\u5e76\u9996\u6b21\u660e\u786e\u5730\u7ed9\u51fa\u4e86\u03ba\u4f9d\u8d56\u6027\u7684\u7cbe\u7ec6\u8868\u5f81\u3002", "motivation": "\u968f\u673a\u53cc\u5c42\u4f18\u5316\u662f\u5143\u5b66\u4e60\u548c\u8d85\u53c2\u6570\u4f18\u5316\u7684\u57fa\u7840\u6846\u67b6\u3002\u5c3d\u7ba1\u5355\u5faa\u73af\u7b97\u6cd5\u5728\u5b9e\u8df5\u4e2d\u975e\u5e38\u666e\u904d\uff0c\u4f46\u5b83\u4eec\u5728\u968f\u673a\u73af\u5883\u4e0b\u7684\u7406\u8bba\u7406\u89e3\u8fdc\u4e0d\u5982\u591a\u5faa\u73af\u7b97\u6cd5\u6210\u719f\u3002\u73b0\u6709\u7684\u5206\u6790\u5f80\u5f80\u4ea7\u751f\u6b21\u4f18\u7684\u6536\u655b\u901f\u5ea6\u6216\u6a21\u7cca\u4e86\u5bf9\u4e0b\u5c42\u6761\u4ef6\u6570\u03ba\u7684\u5173\u952e\u4f9d\u8d56\u6027\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u4e00\u79cd\u540d\u4e3a\u5355\u5faa\u73af\u968f\u673a\u8fd1\u4f3c\u9690\u5f0f\u5fae\u5206\uff08SSAID\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cSSAID\u7b97\u6cd5\u53ef\u4ee5\u4ee5$\\mathcal{O}(\u03ba^7 \u03b5^{-2})$\u7684\u590d\u6742\u5ea6\u8fbe\u5230\u03b5-\u7a33\u5b9a\u70b9\uff0c\u8fd9\u4e0d\u4ec5\u4e0e\u6700\u5148\u8fdb\u7684\u591a\u5faa\u73af\u65b9\u6cd5\u7684\u6700\u4f73$\\mathcal{O}(\u03b5^{-2})$\u901f\u7387\u76f8\u5339\u914d\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u5355\u5faa\u73af\u66f4\u65b0\u7684\u8ba1\u7b97\u6548\u7387\uff1b\u6b64\u5916\uff0c\u8fd8\u9996\u6b21\u4e3a\u57fa\u4e8e\u968f\u673aAID\u7684\u5355\u5faa\u73af\u65b9\u6cd5\u63d0\u4f9b\u4e86\u03ba\u4f9d\u8d56\u6027\u7684\u660e\u786e\u3001\u7ec6\u7c92\u5ea6\u7279\u5f81\u63cf\u8ff0\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8868\u660e\uff0cSSAID\u4e0d\u4ec5\u4ec5\u662f\u4e00\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5b83\u8fd8\u62e5\u6709\u4e00\u4e2a\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5176\u6536\u655b\u4fdd\u8bc1\u53ef\u4e0e\u4e3b\u6d41\u591a\u5faa\u73af\u6846\u67b6\u7ade\u4e89\u3002"}}
{"id": "2602.24265", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24265", "abs": "https://arxiv.org/abs/2602.24265", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "Beyond the Click: A Framework for Inferring Cognitive Traces in Search", "comment": null, "summary": "User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u884c\u4e3a\u65e5\u5fd7\u4e2d\u63a8\u65ad\u8ba4\u77e5\u75d5\u8ff9\u7684\u6846\u67b6\uff0c\u5229\u7528\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u548c\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u9884\u6d4b\u4f1a\u8bdd\u7ed3\u679c\u548c\u7528\u6237\u6323\u624e\u6062\u590d\u7b49\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u7528\u6237\u6a21\u62df\u5668\u4e3b\u8981\u6a21\u4eff\u7528\u6237\u7684\u884c\u4e3a\u800c\u6ca1\u6709\u7406\u89e3\u80cc\u540e\u7684\u601d\u7ef4\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u65e0\u6cd5\u4e86\u89e3\u7528\u6237\u7684\u611f\u53d7\u6216\u56f0\u60d1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u4ece\u5927\u89c4\u6a21\u4ea4\u4e92\u65e5\u5fd7\u4e2d\u63a8\u65ad\u51fa\u7528\u6237\u7684\u8ba4\u77e5\u8f68\u8ff9\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\uff08IFT\uff09\u548c\u4eba\u7c7b\u4e13\u5bb6\u610f\u89c1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4ece\u7528\u6237\u7684\u884c\u4e3a\u65e5\u5fd7\u4e2d\u63a8\u65ad\u8ba4\u77e5\u8f68\u8ff9\u3002", "result": "\u6240\u63d0\u51fa\u7684\u8ba4\u77e5\u8f68\u8ff9\u80fd\u591f\u6539\u8fdb\u6a21\u578b\u5728\u8bf8\u5982\u9884\u6d4b\u4f1a\u8bdd\u7ed3\u679c\u548c\u5e2e\u52a9\u7528\u6237\u514b\u670d\u56f0\u96be\u7b49\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4f5c\u8005\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e9b\u516c\u5f00\u6570\u636e\u96c6\u7684\u6ce8\u91ca\u4ee5\u53ca\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\uff0c\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u81ea\u5df1\u7684\u6570\u636e\u4e0a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6784\u5efa\u66f4\u52a0\u4eba\u6027\u5316\u7684\u7528\u6237\u6a21\u62df\u5668\u6240\u9700\u7684\u5de5\u5177\u548c\u6570\u636e\uff0c\u540c\u65f6\u4e5f\u4e3a\u68c0\u7d22\u7cfb\u7edf\u5728\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u6027\u80fd\u7ef4\u5ea6\u4e0a\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2602.23636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23636", "abs": "https://arxiv.org/abs/2602.23636", "authors": ["Zhihao Ding", "Jinming Li", "Ze Lu", "Jieming Shi"], "title": "FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation", "comment": null, "summary": "Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFlexGuard\u7684LLM\u8c03\u8282\u5668\uff0c\u5b83\u53ef\u4ee5\u8f93\u51fa\u6821\u51c6\u540e\u7684\u8fde\u7eed\u98ce\u9669\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u9608\u503c\u8c03\u6574\u652f\u6301\u7279\u5b9a\u4e25\u683c\u5ea6\u7684\u51b3\u7b56\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6a21\u578b\u76f8\u6bd4\uff0cFlexGuard\u5728\u4e0d\u540c\u4e25\u683c\u5ea6\u4e0b\u5177\u6709\u66f4\u9ad8\u7684\u8c03\u8282\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u62a4\u680f\u6a21\u578b\u5927\u591a\u5c06\u5185\u5bb9\u5ba1\u6838\u89c6\u4e3a\u4e00\u4e2a\u56fa\u5b9a\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd9\u5047\u8bbe\u4e86\u6709\u5bb3\u6027\u7684\u5b9a\u4e49\u662f\u56fa\u5b9a\u7684\u3002\u4f46\u5b9e\u9645\u4e0a\uff0c\u4e0d\u540c\u5e73\u53f0\u4e4b\u95f4\u4ee5\u53ca\u968f\u7740\u65f6\u95f4\u63a8\u79fb\uff0c\u6267\u884c\u4e25\u683c\u7a0b\u5ea6\u4f1a\u6709\u6240\u4e0d\u540c\u3002\u8fd9\u79cd\u5dee\u5f02\u4f7f\u5f97\u57fa\u4e8e\u4e8c\u5206\u7c7b\u7684\u5ba1\u6838\u6a21\u578b\u96be\u4ee5\u9002\u5e94\u53d8\u5316\u7684\u9700\u6c42\u3002", "method": "\u9996\u5148\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u4e25\u683c\u5ea6\u8981\u6c42\u7684LLM\u5ba1\u6838\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177FlexBench\u3002\u63a5\u7740\u63d0\u51fa\u4e86FlexGuard\uff0c\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u8c03\u8282\u5668\uff0c\u5b83\u80fd\u8f93\u51fa\u53cd\u6620\u98ce\u9669\u4e25\u91cd\u7a0b\u5ea6\u7684\u6807\u51c6\u5316\u8fde\u7eed\u8bc4\u5206\uff0c\u5e76\u5141\u8bb8\u901a\u8fc7\u8bbe\u5b9a\u9608\u503c\u6765\u9002\u5e94\u7279\u5b9a\u7684\u4e25\u683c\u5ea6\u9700\u6c42\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u98ce\u9669\u5bf9\u9f50\u4f18\u5316\u65b9\u6cd5\u8bad\u7ec3FlexGuard\u4ee5\u63d0\u9ad8\u5f97\u5206-\u4e25\u91cd\u6027\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u9608\u503c\u9009\u62e9\u7b56\u7565\u4ee5\u4fbf\u4e8e\u90e8\u7f72\u65f6\u8c03\u6574\u5230\u76ee\u6807\u4e25\u683c\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u9762\u5bf9\u4e0d\u540c\u7684\u4e25\u683c\u5ea6\u6807\u51c6\u65f6\uff0cFlexGuard\u76f8\u8f83\u4e8e\u5176\u4ed6\u73b0\u6709\u8c03\u8282\u5668\u5c55\u73b0\u51fa\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u4e0e\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165FlexGuard\uff0c\u7814\u7a76\u89e3\u51b3\u4e86\u5f53\u524d\u56fa\u5b9a\u4e8c\u5206\u7c7b\u5ba1\u6838\u6a21\u578b\u5728\u5e94\u5bf9\u591a\u53d8\u7684\u6267\u884c\u4e25\u683c\u5ea6\u4e0a\u5b58\u5728\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u52a0\u7075\u6d3b\u9ad8\u6548\u7684\u5185\u5bb9\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.24277", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24277", "abs": "https://arxiv.org/abs/2602.24277", "authors": ["Dake Zhang", "Mark D. Smucker", "Charles L. A. Clarke"], "title": "Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment", "comment": null, "summary": "Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $\u03c4= 0.678$ for Task 1 and $\u03c4= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation.", "AI": {"tldr": "The TREC 2025 DRAGUN Track introduced tasks for developing systems to help readers assess news trustworthiness. The track featured two tasks: Question Generation and Report Generation, with an automated judging process (AutoJudge) that closely matched human-assessed rankings, enabling future research on RAG systems and their evaluation.", "motivation": "\u9274\u4e8e\u5728\u7ebf\u65b0\u95fb\u4e2d\u53ef\u9760\u62a5\u9053\u4e0e\u9519\u8bef\u4fe1\u606f\u5e76\u5b58\uff0c\u8bfb\u8005\u96be\u4ee5\u8bc4\u4f30\u65b0\u95fb\u7684\u53ef\u4fe1\u5ea6\u3002\u4e3a\u6b64\uff0cTREC 2025 DRAGUN \u8f68\u9053\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u53d1\u548c\u8bc4\u4f30\u8f85\u52a9RAG\u7cfb\u7edf\u7684\u673a\u4f1a\uff0c\u65e8\u5728\u901a\u8fc7\u751f\u6210\u9762\u5411\u8bfb\u8005\u3001\u6709\u5145\u5206\u5f15\u7528\u7684\u62a5\u544a\u6765\u652f\u6301\u5bf9\u65b0\u95fb\u53ef\u4fe1\u5ea6\u7684\u8bc4\u4f30\u3002", "method": "\u7ec4\u7ec7\u8005\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u4efb\u52a1\uff1a\uff08\u4efb\u52a11\uff09\u95ee\u9898\u751f\u6210\uff0c\u4ea7\u751f10\u4e2a\u6392\u540d\u8c03\u67e5\u95ee\u9898\uff1b\u4ee5\u53ca\uff08\u4efb\u52a12\uff0c\u4e3b\u8981\u4efb\u52a1\uff09\u62a5\u544a\u751f\u6210\uff0c\u57fa\u4e8eMS MARCO V2.1\u5206\u6bb5\u8bed\u6599\u5e93\u751f\u6210\u4e00\u7bc7250\u5b57\u7684\u62a5\u544a\u3002\u6b64\u5916\uff0c\u8fd8\u521b\u5efa\u4e86\u4e00\u4e2a\u81ea\u52a8\u8bc4\u5224\u8fc7\u7a0b\uff08AutoJudge\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u672a\u53c2\u4e0e\u539f\u59cb\u8bc4\u4f30\u7684\u4efb\u52a1\u63d0\u4ea4\u3002", "result": "AutoJudge\u5728\u4efb\u52a11\u548c\u4efb\u52a12\u4e0a\u7684\u8bc4\u5206\u4e0eTREC\u4eba\u5de5\u8bc4\u4f30\u76f8\u6bd4\u663e\u793a\u51fa\u826f\u597d\u7684\u4e00\u81f4\u6027(Kendall's \u03c4\u5206\u522b\u4e3a0.678\u548c0.872)\uff0c\u8fd9\u8868\u660e\u8be5\u81ea\u52a8\u5316\u8bc4\u5224\u8fc7\u7a0b\u80fd\u591f\u6709\u6548\u5730\u66ff\u4ee3\u4eba\u5de5\u8bc4\u4f30\u3002", "conclusion": "\u8fd9\u4e9b\u8d44\u6e90\u4e0d\u4ec5\u652f\u6301\u4e86\u8f85\u52a9\u6027\u65b0\u95fb\u53ef\u4fe1\u5ea6\u8bc4\u4f30RAG\u7cfb\u7edf\u7684\u8bc4\u6d4b\uff0c\u5e76\u4e14\u4ee5\u4eba\u5de5\u8bc4\u4f30\u4f5c\u4e3a\u57fa\u51c6\uff0c\u4fc3\u8fdb\u4e86\u5173\u4e8e\u6539\u8fdb\u81ea\u52a8\u5316RAG\u8bc4\u4f30\u7684\u7814\u7a76\u3002"}}
{"id": "2602.23638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23638", "abs": "https://arxiv.org/abs/2602.23638", "authors": ["Haoran Zhang", "Dongjun Kim", "Seohyeon Cha", "Haris Vikalo"], "title": "FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA", "comment": "preprint", "summary": "Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.", "AI": {"tldr": "\u63d0\u51fa\u4e86FedRot-LoRA\uff0c\u4e00\u79cd\u8054\u90a6LoRA\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u805a\u5408\u524d\u5bf9\u5ba2\u6237\u7aef\u66f4\u65b0\u8fdb\u884c\u6b63\u4ea4\u53d8\u6362\u6765\u89e3\u51b3\u4f4e\u79e9\u56e0\u5b50\u5316\u4e2d\u7684\u65cb\u8f6c\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u4ece\u800c\u51cf\u5c11\u8de8\u5ba2\u6237\u7aef\u5b50\u7a7a\u95f4\u4e0d\u5339\u914d\u5e76\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6LoRA\u673a\u5236\u5728\u5b9e\u8df5\u4e2d\u9047\u5230\u4e86\u7531\u4e8e\u7ef4\u6301\u4f4e\u79e9\u6240\u4f7f\u7528\u7684\u56e0\u5b50\u5e73\u5747\u4e0e\u6570\u5b66\u4e0a\u6b63\u786e\u7684\u5c40\u90e8\u66f4\u65b0\u805a\u5408\u4e4b\u95f4\u7684\u5dee\u5f02\u5bfc\u81f4\u7684\u663e\u8457\u805a\u5408\u8bef\u5dee\u548c\u4e0d\u7a33\u5b9a\u8bad\u7ec3\u7684\u95ee\u9898\u3002\u4e3b\u8981\u539f\u56e0\u662f\u6765\u81ea\u4e0d\u540c\u5ba2\u6237\u7aef\u7684\u8bed\u4e49\u7b49\u4ef7\u66f4\u65b0\u53ef\u4ee5\u8868\u793a\u5728\u4e0d\u540c\u7684\u6f5c\u5728\u5b50\u7a7a\u95f4\u4e2d\uff0c\u76f4\u63a5\u5e73\u5747\u8fd9\u4e9b\u672a\u5bf9\u9f50\u7684\u56e0\u7d20\u4f1a\u5bfc\u81f4\u5b83\u4eec\u4e92\u76f8\u7834\u574f\u6027\u5e72\u6270\uff0c\u4ece\u800c\u964d\u4f4e\u5168\u5c40\u66f4\u65b0\u7684\u8d28\u91cf\u3002", "method": "\u63d0\u51faFedRot-LoRA\u6846\u67b6\uff0c\u5728\u805a\u5408\u524d\u901a\u8fc7\u6b63\u4ea4\u53d8\u6362\u5bf9\u9f50\u5ba2\u6237\u7aef\u66f4\u65b0\u3002\u8fd9\u6837\u65e2\u4fdd\u6301\u4e86\u8bed\u4e49\u66f4\u65b0\uff0c\u53c8\u51cf\u5c11\u4e86\u8de8\u5ba2\u6237\u7aef\u5b50\u7a7a\u95f4\u4e0d\u5339\u914d\u7684\u60c5\u51b5\uff0c\u540c\u65f6\u6ca1\u6709\u589e\u52a0\u901a\u4fe1\u6210\u672c\u6216\u9650\u5236\u6a21\u578b\u8868\u8fbe\u529b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u65e0\u8bba\u662f\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u8fd8\u662f\u751f\u6210\u4efb\u52a1\u4e0a\uff0cFedRot-LoRA\u76f8\u8f83\u4e8e\u73b0\u6709\u8054\u90a6LoRA\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u5f02\u8d28\u6027\u548cLoRA\u7b49\u7ea7\u6c34\u5e73\u4e0b\u5747\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u5206\u6790\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u65cb\u8f6c\u5bf9\u9f50\u5982\u4f55\u5f97\u5230\u66f4\u7d27\u81f4\u7684\u805a\u5408\u8bef\u5dee\u4e0a\u754c\u3002", "conclusion": "FedRot-LoRA\u901a\u8fc7\u5f15\u5165\u65cb\u8f6c\u5bf9\u9f50\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u4f4e\u79e9\u5206\u89e3\u5f15\u8d77\u7684\u65cb\u8f6c\u4e0d\u53d8\u6027\u95ee\u9898\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2602.23662", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23662", "abs": "https://arxiv.org/abs/2602.23662", "authors": ["Kohei Obata", "Zheng Chen", "Yasuko Matsubara", "Lingwei Zhu", "Yasushi Sakurai"], "title": "Selective Denoising Diffusion Model for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAnomalyFilter\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u9636\u6bb5\u5bf9\u9ad8\u65af\u566a\u58f0\u8fdb\u884c\u63a9\u7801\u5e76\u5728\u4e0d\u5411\u5b9e\u4f8b\u6dfb\u52a0\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u53bb\u566a\u8fc7\u7a0b\uff0c\u4ece\u800c\u9009\u62e9\u6027\u5730\u4ec5\u5bf9\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5f02\u5e38\u90e8\u5206\u8fdb\u884c\u53bb\u566a\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u5e38\u90e8\u5206\u4e0d\u53d8\u3002\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u8f83\u4f4e\u7684\u6b63\u5e38\u90e8\u5206\u91cd\u5efa\u8bef\u5dee\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6761\u4ef6\u7b56\u7565\u6765\u4ece\u767d\u566a\u58f0\u4e2d\u91cd\u5efa\u8f93\u5165\u5b9e\u4f8b\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5728\u51c6\u786e\u91cd\u5efa\u6b63\u5e38\u90e8\u5206\u65f6\u9047\u5230\u6311\u6218\uff0c\u8fdb\u800c\u5f71\u54cd\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "method": "AnomalyFilter\u65b9\u6cd5\u5728\u8bad\u7ec3\u9636\u6bb5\u5bf9\u9ad8\u65af\u566a\u58f0\u8fdb\u884c\u63a9\u853d\uff0c\u5e76\u4e14\u5728\u4e0d\u5411\u5b9e\u4f8b\u6dfb\u52a0\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u53bb\u566a\u8fc7\u7a0b\uff0c\u8fd9\u6837\u53ef\u4ee5\u6784\u5efa\u4e00\u4e2a\u53ea\u9488\u5bf9\u5f02\u5e38\u90e8\u5206\u8fdb\u884c\u53bb\u566a\u7684\u9009\u62e9\u6027\u8fc7\u6ee4\u5668\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAnomalyFilter\u5728\u4e94\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5bf9\u4e8e\u6b63\u5e38\u90e8\u5206\u80fd\u591f\u8fbe\u5230\u663e\u8457\u4f4e\u7684\u91cd\u5efa\u8bef\u5dee\uff0c\u652f\u6301\u4e86\u5176\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "AnomalyFilter\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u8bbe\u8ba1\u7279\u522b\u9002\u5408\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff08TSAD\uff09\u7684\u6269\u6563\u6a21\u578b\u566a\u58f0\u5904\u7406\u65b9\u5f0f\uff0c\u663e\u793a\u51fa\u6bd4\u4f20\u7edf\u6269\u6563\u6a21\u578b\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.23696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23696", "abs": "https://arxiv.org/abs/2602.23696", "authors": ["Yongzhong Xu"], "title": "Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training", "comment": "18 pages, 4 figures", "summary": "We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5c0f\u578bTransformer\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53c2\u6570\u66f4\u65b0\u7684\u51e0\u4f55\u7279\u6027\uff0c\u53d1\u73b0\u53c2\u6570\u66f4\u65b0\u4e3b\u8981\u6cbf\u7740\u4e00\u4e2a\u4e3b\u5bfc\u6f02\u79fb\u65b9\u5411\u8fdb\u884c\uff0c\u5e76\u4f34\u6709\u6a2a\u5411\u7684\u6b8b\u4f59\u52a8\u6001\u3002\u901a\u8fc7\u4f7f\u7528\u672a\u5c45\u4e2d\u3001\u884c\u5f52\u4e00\u5316\u7684\u8f68\u8ff9PCA\u6280\u672f\uff0c\u7814\u7a76\u4eba\u5458\u5c55\u793a\u4e86\u5355\u4e2a\u65b9\u5411\u65e9\u671f\u5373\u53ef\u6355\u6349\u5230\u7d2f\u79ef\u53c2\u6570\u79fb\u52a8\u7684\u4e00\u5927\u6bd4\u4f8b\uff0c\u800c\u5269\u4f59\u6210\u5206\u5219\u7f16\u7801\u4e86\u8f85\u52a9\u63a2\u9488\u6027\u80fd\u4e2d\u7684\u632f\u8361\u884c\u4e3a\u3002\u77ac\u65f6\u68af\u5ea6\u4e0e\u8fd9\u4e2a\u4e3b\u5bfc\u65b9\u5411\u51e0\u4e4e\u6ca1\u6709\u5bf9\u9f50\uff0c\u8868\u660e\u5b83\u662f\u7531\u7d2f\u79ef\u4f18\u5316\u5668\u66f4\u65b0\u800c\u975e\u6bcf\u6279\u68af\u5ea6\u7ed3\u6784\u5f15\u8d77\u7684\u3002\u6bd4\u8f83AdamW\u4e0eSGD\u53d8\u4f53\u5728\u5339\u914d\u635f\u5931\u6c34\u5e73\u4e0b\u7684\u8868\u73b0\u63ed\u793a\u4e86\u8f68\u8ff9\u51e0\u4f55\u5b66\u4e0a\u7684\u663e\u8457\u5dee\u5f02\uff1aAdamW\u53d1\u5c55\u51fa\u591a\u7ef4\u6f02\u79fb\u7ed3\u6784\uff0c\u800cSGD\u5bb6\u65cf\u4f18\u5316\u5668\u4ea7\u751f\u7684\u53c2\u6570\u6f14\u53d8\u51e0\u4e4e\u5171\u7ebf\u4e14\u63a2\u9488\u52a8\u529b\u8f83\u5f31\u3002\u91cd\u52a0\u70ed\u9009\u62e9\u6027\u5730\u6270\u4e71\u6a2a\u5411\u6210\u5206\uff0c\u5bf9\u4e3b\u5bfc\u6f02\u79fb\u5750\u6807\u7684\u5f71\u54cd\u6781\u5c0f\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u9664\u4e86\u4ece\u635f\u5931\u503c\u672c\u8eab\u6240\u89c2\u5bdf\u5230\u7684\u73b0\u8c61\u5916\uff0c\u4f18\u5316\u5668\u7684\u9009\u62e9\u8fd8\u5f71\u54cd\u7740\u5b66\u4e60\u8f68\u8ff9\u7684\u6709\u6548\u7ef4\u5ea6\u548c\u7ed3\u6784\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u7406\u89e3\u4e0d\u540c\u4f18\u5316\u7b97\u6cd5\u5982\u4f55\u5f71\u54cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662f\u5c0f\u578bTransformer\uff09\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\u66f4\u65b0\u8def\u5f84\u53ca\u5176\u51e0\u4f55\u7279\u6027\u3002\u901a\u8fc7\u63a2\u7d22\u8fd9\u4e9b\u8def\u5f84\u7684\u5185\u5728\u7ed3\u6784\uff0c\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u4f18\u5316\u5668\u9009\u62e9\u80cc\u540e\u66f4\u6df1\u5c42\u6b21\u7684\u5b66\u4e60\u673a\u5236\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8bad\u7ec3\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528\u4e86\u672a\u5c45\u4e2d\u3001\u884c\u5f52\u4e00\u5316\u7684\u8f68\u8ff9\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u65b9\u6cd5\u6765\u7814\u7a76\u53c2\u6570\u66f4\u65b0\u7684\u65b9\u5411\u6027\u548c\u6a21\u5f0f\uff1b\u5bf9\u6bd4\u4e86AdamW\u4e0e\u51e0\u79cdSGD\u53d8\u4f53\u5728\u7c7b\u4f3c\u635f\u5931\u6c34\u5e73\u4e0b\u7684\u8bad\u7ec3\u8f68\u8ff9\u7279\u5f81\uff1b\u5e94\u7528\u4e86\u91cd\u65b0\u52a0\u70ed\u6280\u672f\u4ee5\u8bc4\u4f30\u5176\u5bf9\u53c2\u6570\u66f4\u65b0\u8def\u5f84\u7279\u5b9a\u65b9\u9762\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u8bad\u7ec3\u521d\u671f\uff0c\u5927\u90e8\u5206\u53c2\u6570\u53d8\u5316\u53ef\u4ee5\u7531\u5355\u4e00\u65b9\u5411\u89e3\u91ca\uff0c\u8fd9\u8868\u660e\u5b58\u5728\u4e00\u4e2a\u4e3b\u5bfc\u7684\u6f02\u79fb\u65b9\u5411\uff1b\u5269\u4f59\u7684\u53d8\u5316\u53cd\u6620\u4e86\u8f85\u52a9\u4efb\u52a1\u6027\u80fd\u4e2d\u7684\u5468\u671f\u6027\u6ce2\u52a8\uff1bAdamW\u4f18\u5316\u5668\u76f8\u8f83\u4e8eSGD\u7cfb\u5217\u80fd\u591f\u4ea7\u751f\u66f4\u52a0\u590d\u6742\u7684\u591a\u7ef4\u6f02\u79fb\u7ed3\u6784\uff1b\u91cd\u65b0\u52a0\u70ed\u64cd\u4f5c\u4e3b\u8981\u5f71\u54cd\u7684\u662f\u4e0e\u4e3b\u5bfc\u6f02\u79fb\u65b9\u5411\u5782\u76f4\u7684\u90e8\u5206\u3002", "conclusion": "\u4f18\u5316\u5668\u7684\u9009\u62e9\u4e0d\u4ec5\u5f71\u54cd\u6700\u7ec8\u6a21\u578b\u6027\u80fd\uff0c\u4e5f\u6df1\u523b\u5851\u9020\u4e86\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\u66f4\u65b0\u8def\u5f84\u53ca\u5176\u51e0\u4f55\u7279\u6027\u3002\u8fd9\u610f\u5473\u7740\uff0c\u4e3a\u4e86\u83b7\u5f97\u6700\u4f73\u8bad\u7ec3\u6548\u679c\uff0c\u9700\u8981\u8003\u8651\u66f4\u591a\u56e0\u7d20\u800c\u4e0d\u4ec5\u4ec5\u662f\u5173\u6ce8\u635f\u5931\u51fd\u6570\u7684\u8868\u73b0\u3002"}}
{"id": "2602.23737", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23737", "abs": "https://arxiv.org/abs/2602.23737", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Bridging Dynamics Gaps via Diffusion Schr\u00f6dinger Bridge for Cross-Domain Reinforcement Learning", "comment": null, "summary": "Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schr\u00f6dinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u6846\u67b6BDGxRL\uff0c\u901a\u8fc7Diffusion Schr\u00f6dinger Bridge\u8c03\u6574\u6e90\u57df\u8f6c\u79fb\u4ee5\u5339\u914d\u76ee\u6807\u57df\u52a8\u6001\uff0c\u5e76\u5f15\u5165\u5956\u52b1\u8c03\u8282\u673a\u5236\u6765\u786e\u4fdd\u4e0e\u76ee\u6807\u57df\u52a8\u529b\u5b66\u7684\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8de8\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u52a8\u6001\u8f6c\u6362\u4e0b\u8868\u73b0\u51fa\u5f88\u5f3a\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u5728\u7f3a\u4e4f\u76ee\u6807\u9886\u57df\u73af\u5883\u4e92\u52a8\u548c\u5956\u52b1\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0c\u76f4\u63a5\u5b66\u4e60\u7b56\u7565\u53d8\u5f97\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86BDGxRL\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u79bb\u7ebf\u6f14\u793a\u7f16\u7801\u7684\u76ee\u6807\u57df\u52a8\u6001\u5bf9\u9f50\u6e90\u8f6c\u79fb\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u73af\u5883\u6216\u5176\u5956\u52b1\u5c31\u80fd\u8fdb\u884c\u9762\u5411\u76ee\u6807\u7684\u7b56\u7565\u5b66\u4e60\u3002", "method": "BDGxRL\u5229\u7528Diffusion Schr\u00f6dinger Bridge\u6280\u672f\u5c06\u6e90\u57df\u4e2d\u7684\u8f6c\u6362\u4e0e\u76ee\u6807\u57df\u7684\u52a8\u529b\u5b66\u7279\u6027\u5bf9\u9f50\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u72b6\u6001\u8f6c\u6362\u4f30\u8ba1\u5956\u52b1\u7684\u673a\u5236\uff0c\u9002\u7528\u4e8e\u7ecf\u8fc7DSB\u6821\u6b63\u540e\u7684\u6837\u672c\uff0c\u4fdd\u8bc1\u5956\u52b1\u4e0e\u76ee\u6807\u57df\u52a8\u529b\u5b66\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "result": "MuJoCo\u8de8\u57df\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cBDGxRL\u4e0d\u4ec5\u8d85\u8fc7\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u800c\u4e14\u5728\u9762\u5bf9\u8fc7\u6e21\u52a8\u529b\u5b66\u53d8\u5316\u65f6\u4e5f\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7BDGxRL\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u540c\u57df\u95f4\u6709\u6548\u8fc1\u79fb\u7b56\u7565\uff0c\u5373\u4fbf\u5728\u6ca1\u6709\u76ee\u6807\u73af\u5883\u4ea4\u4e92\u6216\u5956\u52b1\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u8de8\u57df\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.23761", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23761", "abs": "https://arxiv.org/abs/2602.23761", "authors": ["Yuyu Geng", "Lei Sun", "Yao Gao", "Xinxin Hu", "Zhonghua Yi", "Xiaolong Qian", "Weijian Hu", "Jian Bai", "Kaiwei Wang"], "title": "OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design", "comment": null, "summary": "Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c1d\u8bd5\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e94\u7528\u4e8e\u5149\u5b66\u8bbe\u8ba1\u9886\u57df\uff0c\u901a\u8fc7\u6784\u5efaOptiDesignQA\u6570\u636e\u96c6\u548c\u5f15\u5165\u57fa\u4e8e\u7269\u7406\u9a71\u52a8\u7684\u7b56\u7565\u5bf9\u9f50\u65b9\u6cd5DrGRPO\uff0c\u4f7f\u5f97\u975e\u4e13\u4e1a\u7528\u6237\u4e5f\u80fd\u6210\u529f\u5f00\u53d1\u51fa\u529f\u80fd\u6027\u900f\u955c\u7cfb\u7edf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u62e5\u6709\u5e7f\u6cdb\u7684\u5149\u5b66\u77e5\u8bc6\uff0c\u4f46\u5728\u8bbe\u8ba1\u900f\u955c\u7cfb\u7edf\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u53d7\u5230\u5f88\u5927\u9650\u5236\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u7684\u77e5\u8bc6\u6765\u7f29\u5c0f\u4e13\u4e1a\u77e5\u8bc6\u5dee\u8ddd\uff0c\u8ba9\u6ca1\u6709\u6b63\u5f0f\u5149\u5b66\u8bad\u7ec3\u80cc\u666f\u7684\u7528\u6237\u4e5f\u80fd\u591f\u8bbe\u8ba1\u51fa\u6709\u6548\u7684\u900f\u955c\u7cfb\u7edf\u3002", "method": "\u521b\u5efa\u4e86\u540d\u4e3aOptiDesignQA\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e86\u6765\u81ea\u6807\u51c6\u5149\u5b66\u6559\u79d1\u4e66\u7684\u7ecf\u5178\u900f\u955c\u7cfb\u7edf\u4ee5\u53ca\u7531\u81ea\u52a8\u5316\u8bbe\u8ba1\u7b97\u6cd5\u751f\u6210\u7684\u65b0\u914d\u7f6e\uff1b\u901a\u8fc7\u5168\u7cfb\u7edf\u5408\u6210\u4e0e\u900f\u955c\u5b8c\u6210\u7684\u6df7\u5408\u76ee\u6807\u5411LLM\u6ce8\u5165\u7279\u5b9a\u9886\u57df\u7684\u5149\u5b66\u4e13\u4e1a\u77e5\u8bc6\uff1b\u4f7f\u7528Group Relative Policy Optimization Done Right (DrGRPO) \u7ed3\u5408\u5149\u5b66\u8bcd\u5178\u5956\u52b1\u673a\u5236\u6765\u8c03\u6574\u6a21\u578b\uff0c\u4f7f\u4e4b\u7b26\u5408\u5149\u5b66\u539f\u7406\uff1b\u6700\u540e\uff0c\u6a21\u578b\u4e0e\u4e13\u95e8\u7684\u5149\u5b66\u4f18\u5316\u7a0b\u5e8f\u96c6\u6210\u4ee5\u8fdb\u884c\u7aef\u5230\u7aef\u5fae\u8c03\u548c\u7cbe\u5ea6\u63d0\u5347\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u4f18\u5316\u7684\u81ea\u52a8\u5316\u8bbe\u8ba1\u7b97\u6cd5\u548c\u5176\u4ed6LLM\u540c\u884c\uff0c\u5728\u6027\u80fd\u4e0a\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u6709\u6548\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4fc3\u8fdb\u5149\u5b66\u8bbe\u8ba1\u7684\u8fdb\u6b65\uff0c\u4e3a\u4e0d\u5177\u5907\u6df1\u539a\u5149\u5b66\u80cc\u666f\u7684\u4eba\u58eb\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u5de5\u5177\u3002"}}
{"id": "2602.23770", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23770", "abs": "https://arxiv.org/abs/2602.23770", "authors": ["Chenxing Lin", "Xinhui Gao", "Haipeng Zhang", "Xinran Li", "Haitao Wang", "Songzhu Mei", "Chenglu Wen", "Weiquan Liu", "Siqi Shen", "Cheng Wang"], "title": "MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning", "comment": "ICLR2026", "summary": "Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5c3a\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5MAGE\uff0c\u5b83\u901a\u8fc7\u6761\u4ef6\u5f15\u5bfc\u7684\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\u548c\u591a\u5c3a\u5ea6\u53d8\u6362\u5668\u6765\u5b66\u4e60\u548c\u751f\u6210\u8f68\u8ff9\u8868\u793a\uff0c\u4ece\u800c\u5728\u957f\u65f6\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u7a00\u758f\u5956\u52b1\u7279\u5f81\u7684\u957f\u65f6\u95f4\u4efb\u52a1\u65f6\u5b58\u5728\u56f0\u96be\u3002\u867d\u7136\u5206\u5c42\u751f\u6210\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u5c06\u539f\u59cb\u95ee\u9898\u5206\u89e3\u4e3a\u8f83\u77ed\u65f6\u95f4\u8303\u56f4\u5185\u7684\u5b50\u95ee\u9898\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u5ffd\u7565\u4e86\u8f68\u8ff9\u5185\u5728\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u7ed3\u6784\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "MAGE\u65b9\u6cd5\u7ed3\u5408\u4e86\u6761\u4ef6\u5f15\u5bfc\u7684\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\u4e0e\u4e00\u4e2a\u591a\u5c3a\u5ea6\u53d8\u6362\u5668\uff0c\u524d\u8005\u7528\u4e8e\u5b66\u4e60\u5c42\u6b21\u5316\u7684\u8f68\u8ff9\u8868\u793a\uff0c\u540e\u8005\u5219\u80fd\u591f\u4ece\u7c97\u5230\u7ec6\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u81ea\u56de\u5f52\u5730\u751f\u6210\u8f68\u8ff9\u8868\u793a\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u4e00\u4e2a\u6761\u4ef6\u5f15\u5bfc\u89e3\u7801\u5668\u6765\u7cbe\u786e\u63a7\u5236\u77ed\u671f\u884c\u4e3a\u3002", "result": "\u5728\u4e94\u4e2a\u79bb\u7ebfRL\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u4e0e\u5176\u4ed6\u5341\u4e94\u79cd\u57fa\u7ebf\u7b97\u6cd5\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0cMAGE\u5c55\u793a\u4e86\u5176\u6210\u529f\u6574\u5408\u591a\u5c3a\u5ea6\u8f68\u8ff9\u5efa\u6a21\u4e0e\u6761\u4ef6\u6307\u5bfc\u7684\u80fd\u529b\uff0c\u5728\u957f\u65f6\u95f4\u7a00\u758f\u5956\u52b1\u573a\u666f\u4e0b\u4ea7\u751f\u8fde\u8d2f\u4e14\u53ef\u63a7\u7684\u8f68\u8ff9\u3002", "conclusion": "MAGE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u957f\u65f6\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u6311\u6218\u7684\u65b0\u9014\u5f84\uff0c\u901a\u8fc7\u5f15\u5165\u591a\u5c3a\u5ea6\u8f68\u8ff9\u5efa\u6a21\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8f68\u8ff9\u7684\u8d28\u91cf\u548c\u53ef\u63a7\u6027\u3002"}}
{"id": "2602.23789", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23789", "abs": "https://arxiv.org/abs/2602.23789", "authors": ["Aleksandr Ananikian", "Daniil Drozdov", "Konstantin Yakovlev"], "title": "UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding", "comment": null, "summary": "The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\\unicode{x2013}$ a milestone reached for the first time by a learnable solver.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u542f\u53d1\u5f0f\u9884\u6d4b\u5668\uff0c\u8be5\u6a21\u578b\u4ec5\u9700\u8bad\u7ec3\u4e00\u6b21\u5373\u53ef\u6cdb\u5316\u5230\u6240\u6709\u672a\u89c1\u4efb\u52a1\u4e0a\uff0c\u663e\u8457\u51cf\u5c11\u4e86A*\u641c\u7d22\u7b97\u6cd5\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff0c\u5e76\u4e14\u5728\u4e0e\u8bad\u7ec3\u4efb\u52a1\u5b8c\u5168\u4e0d\u540c\u7684\u4efb\u52a1\u4e0a\u4ecd\u80fd\u63d0\u4f9b\u63a5\u8fd1\u6700\u4f18\u89e3\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7f51\u683c\u5730\u56fe\u6765\u81ea\u540c\u4e00\u5206\u5e03\uff0c\u5bf9\u4e8e\u4e0d\u540c\u5206\u5e03\u7684\u4efb\u52a1\u8868\u73b0\u8f83\u5dee\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u7684\u5b9e\u9645\u5e94\u7528\u3002\u800c\u5b9e\u9645\u4e2d\u5f80\u5f80\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u9ad8\u6548\u5904\u7406\u4efb\u4f55\u95ee\u9898\u5b9e\u4f8b\u7684\u901a\u7528\u6c42\u89e3\u5668\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u542f\u53d1\u5f0f\u9884\u6d4b\u5668\uff0c\u8be5\u6a21\u578b\u7ecf\u8fc7\u4e00\u6b21\u6027\u8bad\u7ec3\u540e\u80fd\u591f\u5728\u5e7f\u6cdb\u7684\u672a\u89c1\u4efb\u52a1\u8c31\u7cfb\u4e0a\u8fdb\u884c\u6cdb\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6700\u591a\u53ef\u5c06A*\u7684\u8ba1\u7b97\u5de5\u4f5c\u91cf\u51cf\u5c11\u81f3\u539f\u6765\u76841/2.2\uff0c\u540c\u65f6\u5728\u4e0e\u8bad\u7ec3\u65f6\u5b8c\u5168\u4e0d\u540c\u7684\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u4f9b\u504f\u79bb\u6700\u4f18\u6210\u672c3%\u4ee5\u5185\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u901a\u7528\u542f\u53d1\u5f0f\u9884\u6d4b\u5668\u6709\u6548\u63d0\u5347\u4e86A*\u641c\u7d22\u7b97\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u662f\u9996\u6b21\u7531\u53ef\u5b66\u4e60\u6c42\u89e3\u5668\u8fbe\u5230\u8fd9\u4e00\u91cc\u7a0b\u7891\u3002"}}
{"id": "2602.23795", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23795", "abs": "https://arxiv.org/abs/2602.23795", "authors": ["Wenwu Tang", "Dong Wang", "Lothar Thiele", "Olga Saukh"], "title": "GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks", "comment": "Conference on Parsimony and Learning (CPAL)", "summary": "Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGRAIL\u7684\u540e\u5904\u7406\u5757\u8865\u507f\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u5728\u6a21\u578b\u538b\u7f29\u540e\u4e0d\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u6062\u590d\u6bcf\u4e2a\u5757\u7684\u8f93\u5165-\u8f93\u51fa\u884c\u4e3a\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u5c0f\u89c4\u6a21\u6821\u51c6\u96c6\u6765\u603b\u7ed3\u9690\u85cf\u6fc0\u6d3b\uff0c\u5e76\u5e94\u7528\u5cad\u56de\u5f52\u4ece\u51cf\u5c11\u7684\u8868\u793a\u4e2d\u7ebf\u6027\u91cd\u6784\u539f\u59cb\u9690\u85cf\u8868\u793a\u3002\u8fd9\u79cd\u65b9\u6cd5\u72ec\u7acb\u4e8e\u9009\u62e9\u5668\u3001\u6570\u636e\u611f\u77e5\uff08\u4ec5\u9700\u51e0\u6b21\u524d\u5411\u4f20\u9012\u800c\u65e0\u9700\u68af\u5ea6\u6216\u6807\u7b7e\uff09\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u538b\u7f29\u60c5\u51b5\u4e0b\u80fd\u591f\u63d0\u9ad8\u51c6\u786e\u6027\u6216\u964d\u4f4e\u56f0\u60d1\u5ea6\u3002", "motivation": "\u7ed3\u6784\u5316\u7684\u6df1\u5ea6\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u867d\u7136\u5bf9\u786c\u4ef6\u53cb\u597d\u4e14\u80fd\u663e\u8457\u51cf\u5c11\u5185\u5b58\u548c\u63a8\u7406\u6210\u672c\uff0c\u4f46\u5728\u6fc0\u8fdb\u538b\u7f29\u4e0b\u4f1a\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u9700\u8981\u540e\u7eed\u5fae\u8c03\uff0c\u800c\u8fd9\u5f80\u5f80\u7531\u4e8e\u7f3a\u5c11\u6807\u8bb0\u6570\u636e\u6216\u9ad8\u6602\u7684\u8bad\u7ec3\u6210\u672c\u800c\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u9700\u8981\u5fae\u8c03\u5c31\u80fd\u6062\u590d\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u662f\u540d\u4e3aGRAIL\u7684\u540e\u5904\u7406\u5757\u8865\u507f\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e00\u4e2a\u5c0f\u6821\u51c6\u96c6\u6765\u603b\u7ed3\u9690\u85cf\u5c42\u6fc0\u6d3b\u72b6\u6001\uff0c\u5e76\u901a\u8fc7Gram\u77e9\u9635\u5e94\u7528\u5cad\u56de\u5f52\u6280\u672f\u4ece\u88ab\u538b\u7f29\u540e\u7684\u8868\u5f81\u4e2d\u91cd\u5efa\u539f\u59cb\u9690\u85cf\u5c42\u8868\u5f81\u3002\u6b64\u8fc7\u7a0b\u4e0d\u4f9d\u8d56\u7279\u5b9a\u7684\u9009\u62e9\u5668\u7c7b\u578b\uff0c\u4e5f\u4e0d\u9700\u8981\u68af\u5ea6\u6216\u6807\u7b7e\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728ResNets\u3001ViTs\u53ca\u89e3\u7801\u5668\u578b\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u76f8\u8f83\u4e8e\u65e0\u6570\u636e\u548c\u6709\u6570\u636e\u610f\u8bc6\u7684\u526a\u679d\u6216\u6298\u53e0\u57fa\u7ebf\u65b9\u6cd5\uff0cGRAIL\u5728\u5b9e\u9645\u538b\u7f29\u6bd4\u4e0b\u80fd\u591f\u4e00\u81f4\u5730\u63d0\u5347\u51c6\u786e\u7387\u6216\u964d\u4f4e\u56f0\u60d1\u5ea6\uff0c\u540c\u65f6\u5177\u6709\u53ef\u7ba1\u7406\u7684\u5f00\u9500\u4e14\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u3002", "conclusion": "GRAIL\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u96f6\u5fae\u8c03\u6b65\u9aa4\uff0c\u53ef\u4ee5\u5728\u6a21\u578b\u538b\u7f29\u4e4b\u540e\u6539\u5584\u5176\u6027\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u90a3\u4e9b\u56e0\u7f3a\u4e4f\u6807\u8bb0\u6570\u636e\u6216\u9ad8\u8bad\u7ec3\u6210\u672c\u800c\u96be\u4ee5\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u3002"}}
{"id": "2602.23811", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23811", "abs": "https://arxiv.org/abs/2602.23811", "authors": ["Xiang Li", "Nan Jiang", "Yuheng Zhang"], "title": "Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies", "comment": null, "summary": "We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u4e00\u822c\u51fd\u6570\u903c\u8fd1\u6761\u4ef6\u4e0b\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u7406\u8bba\u65b9\u9762\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u7b97\u6cd5\u4ee5\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6216\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u89e3\u51b3\u4e86\u53c2\u6570\u5316\u7b56\u7565\u4e2d\u7684\u4e0a\u4e0b\u6587\u8026\u5408\u96be\u9898\uff0c\u901a\u8fc7\u5c06\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u8054\u7cfb\u8d77\u6765\uff0c\u63ed\u793a\u4e86\u79bb\u7ebfRL\u548c\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u60ca\u4eba\u7684\u7edf\u4e00\u3002", "motivation": "\u73b0\u6709\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u867d\u7136\u5728\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u4ece\u79bb\u7ebf\u6570\u636e\u4e2d\u5b66\u4e60\u826f\u597d\u7b56\u7565\u7684\u57fa\u7840\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u53ea\u5bf9\u6709\u9650\u4e14\u8f83\u5c0f\u7684\u52a8\u4f5c\u7a7a\u95f4\u6709\u6548\uff0c\u5e76\u4e14\u4f9d\u8d56\u4e8e\u72b6\u6001\u7ea7\u955c\u50cf\u4e0b\u964d\uff0c\u65e0\u6cd5\u5f88\u597d\u5730\u652f\u6301\u5b9e\u8df5\u4e2d\u5e38\u89c1\u7684\u72ec\u7acb\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u5c06\u955c\u50cf\u4e0b\u964d\u6cd5\u62d3\u5c55\u5230\u53c2\u6570\u5316\u7b56\u7565\u4e0a\uff0c\u8bc6\u522b\u5e76\u5904\u7406\u4e86\u5176\u4e2d\u7684\u6838\u5fc3\u56f0\u96be\u2014\u2014\u4e0a\u4e0b\u6587\u8026\u5408\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u8fde\u63a5\u955c\u50cf\u4e0b\u964d\u4e0e\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u6765\u63d0\u4f9b\u65b0\u7684\u5206\u6790\u3001\u4fdd\u8bc1\u4ee5\u53ca\u7b97\u6cd5\u89c1\u89e3\u3002", "result": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u89e3\u51b3\u53c2\u6570\u5316\u7b56\u7565\u7c7b\u4e2d\u7684\u4e0a\u4e0b\u6587\u8026\u5408\u95ee\u9898\uff0c\u53ef\u4ee5\u5c06\u7406\u8bba\u4fdd\u8bc1\u6269\u5c55\u5230\u66f4\u5927\u6216\u8fde\u7eed\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u53d1\u73b0\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u514b\u670d\u4e86\u73b0\u6709\u79bb\u7ebfRL\u7b97\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5728\u5927\u89c4\u6a21\u6216\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u4f7f\u7528\u53c2\u6570\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u9014\u5f84\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u79bb\u7ebfRL\u4e0e\u6a21\u4eff\u5b66\u4e60\u4e4b\u95f4\u7684\u4e00\u4e2a\u610f\u5916\u7edf\u4e00\u3002"}}
{"id": "2602.23816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23816", "abs": "https://arxiv.org/abs/2602.23816", "authors": ["George Papadopoulos", "George A. Vouros"], "title": "Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective", "comment": "Accepted for publication at AAMAS 2026", "summary": "Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise\" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdSafe Q Inverse Constrained Reinforcement Learning (SafeQIL)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u6700\u5927\u5316\u6f14\u793a\u8f68\u8ff9\u7684\u53ef\u80fd\u6027\u6765\u5b66\u4e60\u4e00\u4e2a\u7b56\u7565\uff0c\u540c\u65f6\u5e73\u8861\u4fdd\u5b88\u6027\u548c\u9ad8\u5956\u52b1\u8f68\u8ff9\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u627e\u5230\u4e00\u79cd\u7b56\u7565\uff0c\u5728\u53d7\u9650\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff08MDP\uff09\uff0c\u5728\u5df2\u77e5\u5956\u52b1\u4f46\u672a\u77e5\u7ea6\u675f\u548c\u4e0d\u53ef\u89c2\u6d4b\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u5b89\u5168\u5730\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u4fdd\u6301\u4fdd\u5b88\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u9ad8\u56de\u62a5\u8f68\u8ff9\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u79f0\u4e3aSafe Q Inverse Constrained Reinforcement Learning (SafeQIL) \u7684\u7b97\u6cd5\uff0c\u5b83\u5b9a\u4e49\u4e86\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u201c\u627f\u8bfa\u201d\u6982\u5ff5\uff0c\u8fd9\u4e2a\u6982\u5ff5\u57fa\u4e8eQ\u503c\uff0c\u8fd9\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u7279\u5b9a\u4efb\u52a1\u7684\u56de\u62a5\u4e5f\u8003\u8651\u4e86\u72b6\u6001\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5c06\u63d0\u51fa\u7684SafeQIL\u7b97\u6cd5\u4e0e\u73b0\u6709\u7684\u9006\u5411\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u9006\u5411\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7ea6\u675f\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u7ed3\u5408\u5956\u52b1\u548c\u5b89\u5168\u6027\u56e0\u7d20\u6765\u5bfb\u627e\u6700\u6709\u524d\u9014\u7684\u7b56\u7565\u3002"}}
{"id": "2602.23824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23824", "abs": "https://arxiv.org/abs/2602.23824", "authors": ["Pavlin G. Poli\u010dar", "Dalibor Stanimirovi\u0107", "Bla\u017e Zupan"], "title": "Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach", "comment": null, "summary": "Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5904\u65b9\u52a8\u6001\u7684\u6162\u6027\u75c5\u6cbb\u7597\u5f00\u59cb\u65f6\u95f4\u63a8\u65ad\u7684\u6982\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u7535\u5b50\u5904\u65b9\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u6bd4\u7b80\u5355\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u75be\u75c5\u5f00\u59cb\u65f6\u95f4\u3002", "motivation": "\u7531\u4e8e\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u6570\u636e\u7ecf\u5e38\u5b58\u5728\u5de6\u5220\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u8bca\u65ad\u8bb0\u5f55\u4e0d\u5b8c\u6574\u4e14\u4e0d\u53ef\u9760\uff0c\u96be\u4ee5\u51c6\u786e\u5224\u65ad\u75be\u75c5\u7684\u8d77\u59cb\u65f6\u95f4\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u95e8\u8bca\u5904\u65b9\u5f62\u6210\u4e86\u57fa\u4e8e\u7eed\u836f\u7684\u8f68\u8ff9\uff0c\u4e3a\u75be\u75c5\u7ba1\u7406\u63d0\u4f9b\u4e86\u8fde\u7eed\u4fe1\u53f7\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u5229\u7528\u8fd9\u79cd\u8fde\u7eed\u6027\u6765\u6539\u8fdb\u6162\u6027\u75c5\u6cbb\u7597\u5f00\u59cb\u65f6\u95f4\u7684\u63a8\u65ad\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u7387\u6846\u67b6\uff0c\u5c06\u5904\u65b9\u52a8\u6001\u5efa\u6a21\u4e3a\u66f4\u65b0\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u5728\u57fa\u7ebf\u6cca\u677e\uff08\u968f\u673a\u5f00\u836f\uff09\u6a21\u5f0f\u4e0e\u7279\u5b9a\u6a21\u5f0f\u5a01\u5e03\u5c14\uff08\u6301\u7eed\u6cbb\u7597\uff09\u66f4\u65b0\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u53d8\u70b9\u68c0\u6d4b\uff0c\u6765\u8bc6\u522b\u4ece\u5076\u53d1\u6027\u6cbb\u7597\u5230\u6301\u7eed\u6027\u6cbb\u7597\u4e4b\u95f4\u7684\u8f6c\u53d8\u3002", "result": "\u4f7f\u7528\u4e86\u4e00\u4e2a\u5305\u542b240\u4e07\u4e2a\u4f53\u7684\u5168\u56fd\u8303\u56f4\u5185\u7535\u5b50\u5904\u65b9\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u4e8e\u7b80\u5355\u57fa\u4e8e\u89c4\u5219\u7684\u89e6\u53d1\u65b9\u5f0f\uff0c\u5728\u5f3a\u5de6\u5220\u5931\u60c5\u51b5\u4e0b\u80fd\u591f\u663e\u8457\u51cf\u5c11\u4e0d\u5408\u7406\u63d0\u524d\u68c0\u6d4b\u7684\u60c5\u51b5\u53d1\u751f\uff0c\u63d0\u4f9b\u66f4\u52a0\u5408\u7406\u7684\u65f6\u95f4\u4f30\u8ba1\u3002\u4f46\u4e0d\u540c\u75be\u75c5\u95f4\u68c0\u6d4b\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u4e14\u4e0e\u5904\u65b9\u5bc6\u5ea6\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u57fa\u4e8e\u6cbb\u7597\u7684\u8fc7\u7a0b\u6765\u63a8\u65ad\u6162\u6027\u75c5\u6cbb\u7597\u7684\u8d77\u59cb\u65f6\u95f4\u662f\u53ef\u884c\u7684\uff0c\u800c\u4e14\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u63d0\u4f9b\u66f4\u5408\u7406\u7684\u4f30\u8ba1\u3002\u4e0d\u8fc7\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7684\u6548\u679c\u53d7\u5230\u75be\u75c5\u7c7b\u578b\u4ee5\u53ca\u5904\u65b9\u9891\u7387\u7b49\u56e0\u7d20\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.23827", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23827", "abs": "https://arxiv.org/abs/2602.23827", "authors": ["Junkang Liu", "Fanhua Shang", "Yuxuan Tian", "Hongying Liu", "Yuanyuan Liu"], "title": "FedNSAM:Consistency of Local and Global Flatness for Federated Learning", "comment": null, "summary": "In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \\textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \\textbf{flatness distance}, we propose a novel \\textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \\textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \\textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684FedNSAM\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5168\u5c40Nesterov\u52a8\u91cf\u5230\u5c40\u90e8\u66f4\u65b0\u4e2d\uff0c\u6765\u534f\u8c03\u5168\u5c40\u548c\u5e73\u5766\u5ea6\u7684\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u52a0\u901fSAM\u7b97\u6cd5\u3002\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86FedNSAM\u5728\u6536\u655b\u6027\u548c\u6027\u80fd\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u591a\u6b65\u672c\u5730\u66f4\u65b0\u548c\u6570\u636e\u5f02\u8d28\u6027\u901a\u5e38\u4f1a\u5bfc\u81f4\u66f4\u5c16\u9510\u7684\u5168\u5c40\u6781\u5c0f\u503c\uff0c\u8fd9\u4f1a\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u7684\u6027\u80fd\u3002\u5c3d\u7ba1\u73b0\u6709\u7684FL\u7b97\u6cd5\u901a\u8fc7\u5c06\u9510\u5ea6\u611f\u77e5\u6700\u5c0f\u5316(SAM)\u6574\u5408\u5230\u672c\u5730\u8bad\u7ec3\u4e2d\u8bd5\u56fe\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5728\u9ad8\u6570\u636e\u5f02\u8d28\u6027\u7684\u73af\u5883\u4e0b\uff0c\u672c\u5730\u8bad\u7ec3\u4e2d\u7684\u5e73\u5766\u5ea6\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u5168\u5c40\u6a21\u578b\u540c\u6837\u5e73\u5766\u3002\u56e0\u6b64\uff0c\u5355\u7eaf\u51cf\u5c0f\u5ba2\u6237\u7aef\u6570\u636e\u4e0a\u5c40\u90e8\u635f\u5931\u9762\u7684\u9510\u5ea6\u5e76\u4e0d\u80fd\u6709\u6548\u63d0\u5347SAM\u5728FL\u4e2d\u7684\u6548\u80fd\uff0c\u8fdb\u800c\u6539\u5584\u5168\u5c40\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u5b9a\u4e49\u4e86'\u5e73\u5766\u8ddd\u79bb'\u7684\u6982\u5ff5\u6765\u89e3\u91ca\u4e0a\u8ff0\u73b0\u8c61\uff0c\u5e76\u57fa\u4e8e\u6b64\u91cd\u65b0\u601d\u8003\u4e86FL\u4e2d\u7684SAM\u65b9\u6cd5\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790'\u5e73\u5766\u8ddd\u79bb'\uff0c\u63d0\u51fa\u4e86FedNSAM\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5411\u5c40\u90e8\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u52a0\u5165\u5168\u5c40Nesterov\u52a8\u91cf\uff0c\u4ee5\u4fc3\u8fdb\u5168\u5c40\u4e0e\u5c40\u90e8\u5e73\u5766\u5ea6\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u52a0\u901fSAM\u8fc7\u7a0b\u3002FedNSAM\u5229\u7528\u5168\u5c40Nesterov\u52a8\u91cf\u4f5c\u4e3a\u5ba2\u6237\u7aef\u5168\u7403\u6270\u52a8\u4f30\u8ba1\u53ca\u5916\u63a8\u7684\u65b9\u5411\u3002", "result": "\u4ece\u7406\u8bba\u4e0a\u8bb2\uff0c\u7814\u7a76\u8bc1\u660e\u4e86\u501f\u52a9Nesterov\u5916\u63a8\u6cd5\uff0cFedNSAM\u76f8\u6bd4FedSAM\u80fd\u591f\u83b7\u5f97\u66f4\u7d27\u7684\u6536\u655b\u754c\u9650\u3002\u5b9e\u9a8c\u65b9\u9762\uff0c\u5728CNN\u548cTransformer\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86FedNSAM\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u7684\u4f18\u8d8a\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5168\u5c40Nesterov\u52a8\u91cf\u81f3\u5c40\u90e8\u66f4\u65b0\u6b65\u9aa4\uff0cFedNSAM\u7b97\u6cd5\u6210\u529f\u5730\u63d0\u5347\u4e86SAM\u5728\u5904\u7406\u5177\u6709\u9ad8\u5ea6\u6570\u636e\u5f02\u8d28\u6027\u7684\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u8fd8\u589e\u5f3a\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2602.23852", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.23852", "abs": "https://arxiv.org/abs/2602.23852", "authors": ["Zhaowen Wang", "Dongdong Zhou", "Qi Xu", "Fengyu Cong", "Mohammad Al-Sa'd", "Jenni Raitoharju"], "title": "ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring", "comment": "Accepted to ICASSP 2026", "summary": "Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ULW-SleepNet\uff0c\u4e00\u79cd\u8d85\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u7761\u7720\u9636\u6bb5\u8bc4\u5206\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u6709\u6548\u6574\u5408\u591a\u79cd\u751f\u7406\u4fe1\u53f7\u7684\u4fe1\u606f\uff0c\u5e76\u5728\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u7684\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u7684\u51c6\u786e\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5728\u81ea\u52a8\u7761\u7720\u9636\u6bb5\u8bc4\u5206\u9886\u57df\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u591a\u6570\u6a21\u578b\u5bf9\u8ba1\u7b97\u8d44\u6e90\u8981\u6c42\u9ad8\u4e14\u4ec5\u9002\u7528\u4e8e\u5355\u901a\u9053\u8111\u7535\u56fe\uff08EEG\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5904\u7406\u591a\u6a21\u6001\u591a\u5bfc\u7761\u7720\u56fe(PSG)\u6570\u636e\u65f6\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aULW-SleepNet\u7684\u65b0\u578b\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u901a\u8fc7\u5f15\u5165\u53cc\u6d41\u53ef\u5206\u79bb\u5377\u79ef(DSSC)\u6a21\u5757\u3001\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u3001\u901a\u9053\u53c2\u6570\u5171\u4eab\u4ee5\u53ca\u5168\u5c40\u5e73\u5747\u6c60\u5316\u6280\u672f\u6765\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7cbe\u5ea6\u3002", "result": "\u5728Sleep-EDF-20\u548cSleep-EDF-78\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u65f6\uff0cULW-SleepNet\u5206\u522b\u8fbe\u5230\u4e8686.9%\u548c81.4%\u7684\u51c6\u786e\u7387\uff0c\u4ec5\u670913.3K\u4e2a\u53c2\u6570\u548c7.89M FLOPs\u3002\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6a21\u578b\u51cf\u5c11\u4e86\u9ad8\u8fbe98.6%\u7684\u53c2\u6570\u91cf\uff0c\u6027\u80fd\u635f\u5931\u5fae\u4e4e\u5176\u5fae\u3002", "conclusion": "ULW-SleepNet\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6f5c\u529b\uff0c\u7279\u522b\u9002\u5408\u4e8e\u7a7f\u6234\u5f0f\u53ca\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u7761\u7720\u76d1\u6d4b\u5e94\u7528\u3002"}}
{"id": "2602.23880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23880", "abs": "https://arxiv.org/abs/2602.23880", "authors": ["Zhang Wan", "Tingting Mu", "Samuel Kaski"], "title": "A Theory of Random Graph Shift in Truncated-Spectrum vRKHS", "comment": null, "summary": "This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u968f\u673a\u56fe\u751f\u6210\u7684\u89d2\u5ea6\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u9886\u57df\u8fc1\u79fb\u4e0b\u8fdb\u884c\u56fe\u5206\u7c7b\u7684\u7406\u8bba\uff0c\u5176\u4e2d\u5047\u5b9a\u540c\u4e00\u7c7b\u5185\u7684\u56fe\u5171\u4eab\u76f8\u540c\u7684\u968f\u673a\u56fe\u6a21\u578b\uff08RGM\uff09\uff0c\u800c\u9886\u57df\u8fc1\u79fb\u7531RGM\u7ec4\u4ef6\u7684\u53d8\u5316\u5f15\u8d77\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u5047\u8bbeRGM\u4e3a\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7684\u7406\u8bba\uff0c\u5e76\u5229\u7528\u5176\u4e0e\u51fd\u6570\u7a7a\u95f4\u4e2d\u5047\u8bbe\u590d\u6742\u5ea6\u7684\u8054\u7cfb\u6765\u8fdb\u884c\u7ec6\u81f4\u7684\u5206\u6790\u3002\u57fa\u4e8e\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08vRKHS\uff09\u516c\u5f0f\uff0c\u63a8\u5bfc\u51fa\u4e00\u4e2a\u6cdb\u5316\u8fb9\u754c\uff0c\u8be5\u8fb9\u754c\u7684\u8fc1\u79fb\u60e9\u7f5a\u53ef\u4ee5\u5206\u89e3\u4e3a\uff1a(i) \u9886\u57df\u5dee\u5f02\u9879\u3001(ii) \u7531\u53ef\u8bbf\u95ee\u622a\u65ad\u8c31\u603b\u7ed3\u7684\u8c31\u51e0\u4f55\u9879\uff0c\u4ee5\u53ca(iii) \u6c47\u805a\u6536\u655b\u548c\u6784\u5efa\u7a33\u5b9a\u6027\u6548\u5e94\u7684\u5e45\u5ea6\u9879\u3002", "motivation": "\u73b0\u6709\u7684\u9886\u57df\u9002\u5e94\uff08DA\uff09\u7406\u8bba\u867d\u5df2\u5f88\u597d\u5730\u652f\u6301\u4e86\u5904\u7406\u56fe\u5206\u5e03\u8fc1\u79fb\u7684\u6280\u672f\uff0c\u4f46\u5bf9\u4e8e\u56fe\u6837\u672c\u672c\u8eab\u4f5c\u4e3a\u7ed3\u6784\u5316\u5bf9\u8c61\u7684\u4fe1\u606f\u63a2\u7d22\u8f83\u5c11\u3002\u9274\u4e8e\u56fe\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u6027\u8d28\u53ca\u9488\u5bf9\u56fe\u5b66\u4e60\u7684\u4e13\u4e1a\u67b6\u6784\u8fdb\u4e00\u6b65\u590d\u6742\u5316\u4e86\u5bf9\u56fe\u5206\u5e03\u8fc1\u79fb\u7684\u7ec6\u81f4\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7406\u89e3\u548c\u5904\u7406\u8fd9\u79cd\u8fc1\u79fb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u968f\u673a\u56fe\u6a21\u578b\uff08RGM\uff09\u89c6\u4e3a\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u7684\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u4ece\u51fd\u6570\u7a7a\u95f4\u89d2\u5ea6\u63a2\u8ba8\u4e86\u5b83\u4e0e\u5047\u8bbe\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u7814\u7a76\u8005\u4eec\u8fd8\u57fa\u4e8e\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(vRKHS)\u5efa\u7acb\u4e86\u4e00\u4e2a\u6570\u5b66\u516c\u5f0f\uff0c\u7528\u4ee5\u63a8\u5bfc\u51fa\u4e00\u4e2a\u65b0\u7684\u6cdb\u5316\u754c\u9650\uff0c\u8be5\u754c\u9650\u80fd\u66f4\u7ec6\u81f4\u5730\u5206\u6790\u7531\u4e8e\u9886\u57df\u8fc1\u79fb\u5bfc\u81f4\u7684\u56fe\u5206\u5e03\u53d8\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7406\u8bba\u6210\u529f\u5730\u63d0\u4f9b\u4e86\u5bf9\u4e8e\u9886\u57df\u8fc1\u79fb\u6761\u4ef6\u4e0b\u56fe\u5206\u7c7b\u95ee\u9898\u7684\u6df1\u5165\u7406\u89e3\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b0\u5b9a\u4e49\u7684\u5404\u9879\u6307\u6807\uff08\u5982\u9886\u57df\u5dee\u5f02\u3001\u8c31\u51e0\u4f55\u7279\u6027\u53ca\u632f\u5e45\u56e0\u7d20\uff09\u7684\u6709\u6548\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u65e2\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e5f\u9002\u7528\u4e8e\u6a21\u62df\u73af\u5883\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u89e3\u51b3\u9886\u57df\u8fc1\u79fb\u6761\u4ef6\u4e0b\u7684\u56fe\u5206\u7c7b\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165\u968f\u673a\u56fe\u6a21\u578b\u4f5c\u4e3a\u57fa\u7840\u5e76\u7ed3\u5408\u5148\u8fdb\u7684\u6570\u5b66\u5de5\u5177\uff0c\u80fd\u591f\u66f4\u7cbe\u786e\u5730\u8861\u91cf\u548c\u89e3\u91ca\u4e0d\u540c\u7c7b\u578b\u7684\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.23881", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23881", "abs": "https://arxiv.org/abs/2602.23881", "authors": ["Alexander Samarin", "Sergei Krutikov", "Anton Shevtsov", "Sergei Skvortsov", "Filipp Fisin", "Alexander Golubev"], "title": "LK Losses: Direct Acceptance Rate Optimization for Speculative Decoding", "comment": null, "summary": "Speculative decoding accelerates autoregressive large language model (LLM) inference by using a lightweight draft model to propose candidate tokens that are then verified in parallel by the target model. The speedup is significantly determined by the acceptance rate, yet standard training minimizes Kullback-Leibler (KL) divergence as a proxy objective. While KL divergence and acceptance rate share the same global optimum, small draft models, having limited capacity, typically converge to suboptimal solutions where minimizing KL does not guarantee maximizing acceptance rate. To address this issue, we propose LK losses, special training objectives that directly target acceptance rate. Comprehensive experiments across four draft architectures and six target models, ranging from 8B to 685B parameters, demonstrate consistent improvements in acceptance metrics across all configurations compared to the standard KL-based training. We evaluate our approach on general, coding and math domains and report gains of up to 8-10% in average acceptance length. LK losses are easy to implement, introduce no computational overhead and can be directly integrated into any existing speculator training framework, making them a compelling alternative to the existing draft training objectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLK\u635f\u5931\u7684\u7279\u6b8a\u8bad\u7ec3\u76ee\u6807\uff0c\u76f4\u63a5\u9488\u5bf9\u63a5\u53d7\u7387\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u89e3\u51b3\u5728\u4f7f\u7528\u63a8\u6d4b\u89e3\u7801\u52a0\u901f\u81ea\u56de\u5f52\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\uff0c\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u56e0\u5bb9\u91cf\u6709\u9650\u800c\u65e0\u6cd5\u6700\u5927\u5316\u63a5\u53d7\u7387\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u4e8eKL\u6563\u5ea6\u7684\u6807\u51c6\u8bad\u7ec3\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u914d\u7f6e\u4e0b\u90fd\u80fd\u63d0\u9ad8\u63a5\u53d7\u7387\u6307\u6807\u3002", "motivation": "\u6807\u51c6\u8bad\u7ec3\u901a\u8fc7\u6700\u5c0f\u5316Kullback-Leibler (KL) \u6563\u5ea6\u6765\u95f4\u63a5\u5f71\u54cd\u63a5\u53d7\u7387\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u4e8e\u5bb9\u91cf\u6709\u9650\u7684\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u6765\u8bf4\uff0c\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u63a5\u53d7\u7387\u7684\u6700\u5927\u5316\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u65e8\u5728\u627e\u5230\u4e00\u79cd\u53ef\u4ee5\u76f4\u63a5\u63d0\u5347\u63a5\u53d7\u7387\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86LK\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u95e8\u8bbe\u8ba1\u7528\u6765\u76f4\u63a5\u4f18\u5316\u63a5\u53d7\u7387\u7684\u8bad\u7ec3\u76ee\u6807\u3002LK\u635f\u5931\u51fd\u6570\u6613\u4e8e\u5b9e\u73b0\u4e14\u4e0d\u5f15\u5165\u989d\u5916\u8ba1\u7b97\u8d1f\u62c5\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684\u63a8\u6d4b\u5668\u8bad\u7ec3\u6846\u67b6\u4e2d\u3002", "result": "\u901a\u8fc7\u5bf9\u56db\u79cd\u8349\u7a3f\u67b6\u6784\u548c\u516d\u4e2a\u53c2\u6570\u89c4\u6a21\u4ece8\u4ebf\u81f3685\u4ebf\u7684\u76ee\u6807\u6a21\u578b\u8fdb\u884c\u5168\u9762\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u57fa\u4e8eKL\u7684\u65b9\u6cd5\uff0cLK\u635f\u5931\u5728\u5404\u79cd\u8bbe\u5b9a\u4e0b\u5747\u80fd\u663e\u8457\u63d0\u9ad8\u63a5\u53d7\u7387\u6307\u6807\uff0c\u5728\u4e00\u822c\u3001\u7f16\u7801\u53ca\u6570\u5b66\u9886\u57df\u4e0a\u5e73\u5747\u63a5\u53d7\u957f\u5ea6\u589e\u52a0\u4e868-10%\u3002", "conclusion": "LK\u635f\u5931\u4e3a\u63d0\u9ad8\u63a8\u6d4b\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u63a5\u53d7\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u5b9e\u7528\u6027\u5f3a\u7684\u65b0\u65b9\u6848\uff0c\u5b83\u4e0d\u4ec5\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\uff0c\u8fd8\u5177\u5907\u826f\u597d\u7684\u517c\u5bb9\u6027\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u5f53\u524d\u5b58\u5728\u7684\u4efb\u4f55\u63a8\u6d4b\u5668\u8bad\u7ec3\u73af\u5883\u4e2d\u3002"}}
{"id": "2602.23994", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23994", "abs": "https://arxiv.org/abs/2602.23994", "authors": ["Vrushank Ahire", "Yogesh Kumar", "Anouck Girard", "M. A. Ganaie"], "title": "MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening", "comment": null, "summary": "Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMINT\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u5c06MRI\u7684\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u6784\u8f6c\u79fb\u5230\u8bed\u97f3\u7f16\u7801\u5668\u4e2d\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8eMRI\u77e5\u8bc6\u7684\u8bed\u97f3\u5206\u6790\u4ee5\u7b5b\u67e5\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u3002\u8be5\u65b9\u6cd5\u5728\u4e0d\u9700\u8981\u5b9e\u9645\u8fdb\u884c\u795e\u7ecf\u5f71\u50cf\u68c0\u67e5\u7684\u60c5\u51b5\u4e0b\uff0c\u8fbe\u5230\u4e86\u4e0e\u4ec5\u4f7f\u7528\u8bed\u97f3\u57fa\u7ebf\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u901a\u8fc7\u7ed3\u5408MRI\u4fe1\u606f\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u7684\u53d1\u5c55\u8fc7\u7a0b\u4e2d\uff0c\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u662f\u4ece\u6b63\u5e38\u8001\u5316\u5230\u75f4\u5446\u7684\u5173\u952e\u8fc7\u6e21\u9636\u6bb5\u3002\u867d\u7136\u795e\u7ecf\u5f71\u50cf\u5b66\u5982\u7ed3\u6784\u78c1\u5171\u632f\u6210\u50cf\uff08MRI\uff09\u63d0\u4f9b\u4e86\u8fd9\u4e00\u8f6c\u53d8\u7684\u751f\u7269\u6807\u8bb0\u7269\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u6210\u672c\u548c\u57fa\u7840\u8bbe\u65bd\u9700\u6c42\u9650\u5236\u4e86\u5927\u89c4\u6a21\u5e94\u7528\u3002\u800c\u5355\u72ec\u57fa\u4e8e\u8bed\u97f3\u5206\u6790\u7684\u65b9\u6cd5\u867d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u975e\u4fb5\u5165\u6027\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u751f\u7269\u5b66\u57fa\u7840\uff0c\u4f7f\u5f97\u5b83\u5728\u533a\u5206\u6b63\u5e38\u5bf9\u7167\u7ec4\u4e0eMCI\u65f6\u4e0d\u591f\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9636\u6bb5\u8de8\u6a21\u6001\u6846\u67b6MINT\uff0c\u65e8\u5728\u8bad\u7ec3\u671f\u95f4\u5c06MRI\u4e2d\u7684\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u6784\u8f6c\u79fb\u81f3\u8bed\u97f3\u7f16\u7801\u5668\u3002\u9996\u5148\u5229\u75281,228\u540d\u53d7\u8bd5\u8005\u7684\u6570\u636e\u8bad\u7ec3\u4e00\u4e2aMRI\u6559\u5e08\u6a21\u578b\uff0c\u5b9a\u4e49\u51fa\u7528\u4e8e\u533a\u5206\u6b63\u5e38\u5bf9\u7167\u7ec4\u4e0eMCI\u7684\u7d27\u51d1\u795e\u7ecf\u5f71\u50cf\u5d4c\u5165\u7a7a\u95f4\uff1b\u7136\u540e\u901a\u8fc7\u6b8b\u5dee\u6295\u5f71\u5934\u914d\u5408\u51e0\u4f55\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u8bed\u97f3\u8868\u793a\u4e0e\u6b64\u51bb\u7ed3\u7684\u5f71\u50cf\u6d41\u5f62\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u5f71\u50cf\u7f16\u7801\u5668\u7684\u4fdd\u771f\u5ea6\uff1b\u6700\u540e\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u76f4\u63a5\u5e94\u7528\u4ece\u672a\u63a5\u89e6\u8fc7\u8bed\u97f3\u6570\u636e\u7684\u51bb\u7ed3MRI\u5206\u7c7b\u5668\u4e8e\u5df2\u5bf9\u9f50\u7684\u5d4c\u5165\u4e0a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728ADNI-4\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u65f6\uff0c\u5bf9\u9f50\u540e\u7684\u8bed\u97f3\u8868\u73b0\u4e0e\u4ec5\u4f7f\u7528\u8bed\u97f3\u57fa\u7ebf\u7684\u7ed3\u679c\u76f8\u5f53(AUC 0.720 vs 0.711)\uff0c\u5e76\u4e14\u65e0\u9700\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u4efb\u4f55\u5f71\u50cf\u8d44\u6599\u3002\u6b64\u5916\uff0c\u591a\u6a21\u6001\u878d\u5408\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528MRI\u6709\u6240\u6539\u8fdb(0.973 vs 0.958)\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0cdropout\u6b63\u5219\u5316\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u662f\u5173\u952e\u7684\u8bbe\u8ba1\u51b3\u7b56\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c55\u793a\u4eceMRI\u5230\u8bed\u97f3\u7684\u77e5\u8bc6\u8fc1\u79fb\u5e94\u7528\u4e8e\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b5b\u67e5\u7684\u7814\u7a76\uff0c\u4e3a\u65e0\u9700\u795e\u7ecf\u5f71\u50cf\u7684\u5927\u89c4\u6a21\u8ba4\u77e5\u521d\u6b65\u7b5b\u67e5\u5efa\u7acb\u4e86\u4e00\u6761\u5177\u6709\u751f\u7269\u5b66\u57fa\u7840\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.24012", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.24012", "abs": "https://arxiv.org/abs/2602.24012", "authors": ["Roy Betser", "Eyal Gofer", "Meir Yossef Levi", "Guy Gilboa"], "title": "InfoNCE Induces Gaussian Distribution", "comment": "Accepted to ICLR 2026, Oral", "summary": "Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u7684InfoNCE\u76ee\u6807\u5982\u4f55\u8bf1\u5bfc\u8868\u793a\u5411\u91cf\u5448\u73b0\u51fa\u9ad8\u65af\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8fd9\u4e00\u70b9\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u91ca\u4e3a\u4ec0\u4e48\u5728\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u8bad\u7ec3\u51fa\u7684\u8868\u793a\u503e\u5411\u4e8e\u5448\u73b0\u9ad8\u65af\u5206\u5e03\u7279\u6027\uff0c\u63d0\u4f9b\u8fd9\u79cd\u73b0\u8c61\u80cc\u540e\u7684\u539f\u7406\u6027\u7406\u89e3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5728\u7279\u5b9a\u5bf9\u9f50\u548c\u96c6\u4e2d\u5047\u8bbe\u4e0b\u5c55\u793a\u9ad8\u7ef4\u8868\u793a\u6295\u5f71\u63a5\u8fd1\u591a\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\uff0c\u4ee5\u53ca\u901a\u8fc7\u52a0\u5165\u8f7b\u5fae\u6b63\u5219\u5316\u9879\u4fc3\u8fdb\u4f4e\u7279\u5f81\u8303\u6570\u4e0e\u9ad8\u7279\u5f81\u71b5\u6765\u8fbe\u5230\u7c7b\u4f3c\u6e10\u8fd1\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u53caCIFAR-10\u4e0a\u4f7f\u7528\u591a\u79cd\u7f16\u7801\u5668\u67b6\u6784\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u4e00\u81f4\u5730\u8868\u73b0\u51fa\u9ad8\u65af\u884c\u4e3a\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u8be5\u5de5\u4f5c\u4e3a\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u666e\u904d\u89c2\u5bdf\u5230\u7684\u9ad8\u65af\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u89e3\u91ca\uff0c\u5e76\u4e14\u5f97\u5230\u7684\u9ad8\u65af\u6a21\u578b\u6709\u671b\u652f\u6301\u5bf9\u6bd4\u5b66\u4e60\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2602.24040", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24040", "abs": "https://arxiv.org/abs/2602.24040", "authors": ["Daniel Yang", "Samuel Stante", "Florian Redhardt", "Lena Libon", "Parnian Kassraie", "Ido Hakimi", "Barna P\u00e1sztor", "Andreas Krause"], "title": "RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models", "comment": null, "summary": "Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRewardUQ\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6a21\u578b\u5927\u5c0f\u548c\u521d\u59cb\u5316\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u6700\u5927\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u70b9\u4f30\u8ba1\u6765\u786e\u5b9a\u5956\u52b1\u6a21\u578b\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5ffd\u7565\u4e86\u7531\u4e8e\u6709\u9650\u7684\u4eba\u7c7b\u53cd\u9988\u800c\u4ea7\u751f\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002\u8003\u8651\u5230\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u53ef\u4ee5\u51cf\u5c11\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u4e3b\u52a8\u5b66\u4e60\u5e26\u6765\u7684\u4eba\u5de5\u6807\u6ce8\u6210\u672c\uff0c\u5e76\u51cf\u8f7bLLM\u540e\u8bad\u7ec3\u4e2d\u7684\u5956\u52b1\u8fc7\u5ea6\u4f18\u5316\u95ee\u9898\u3002\u7136\u800c\uff0c\u76ee\u524d\u8fd8\u6ca1\u6709\u5bf9\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u5f7b\u5e95\u7684\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u4e00\u4e2a\u79f0\u4e3aRewardUQ\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4ee5\u7cfb\u7edf\u5730\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u6cbf\u7528\u4e86\u8861\u91cf\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u7684\u6807\u51c6\u6307\u6807\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u7684\u65b0\u6392\u540d\u7b56\u7565\uff0c\u4ee5\u4fbf\u66f4\u7b80\u4fbf\u5730\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5927\u5c0f\u4e0e\u521d\u59cb\u5316\u5bf9\u6700\u7ec8\u6027\u80fd\u5f71\u54cd\u6700\u5927\u3002\u6b64\u5916\uff0c\u5148\u524d\u7684\u5f88\u591a\u5de5\u4f5c\u5982\u679c\u91c7\u7528\u4e0d\u540c\u7684\u8bbe\u8ba1\u9009\u62e9\u53ef\u80fd\u4f1a\u53d6\u5f97\u66f4\u597d\u7684\u6548\u679c\u3002\u4e3a\u4e86\u4fc3\u8fdb\u65b0\u65b9\u6cd5\u7684\u53d1\u5c55\u4e0e\u8bc4\u4f30\uff0c\u5e76\u652f\u6301\u4e0b\u6e38\u5e94\u7528\u7684\u90e8\u7f72\uff0c\u4f5c\u8005\u4eec\u5f00\u6e90\u4e86\u4ed6\u4eec\u7684\u6846\u67b6\u4f5c\u4e3a\u4e00\u4e2aPython\u5305\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165RewardUQ\u6846\u67b6\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u9002\u5f53\u8003\u8651\u6a21\u578b\u5927\u5c0f\u53ca\u521d\u59cb\u5316\u7684\u91cd\u8981\u6027\u3002\u540c\u65f6\uff0c\u5b83\u4e5f\u4e3a\u672a\u6765\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\u96c6\u3002"}}
{"id": "2602.24066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24066", "abs": "https://arxiv.org/abs/2602.24066", "authors": ["Tobias Nygaard"], "title": "pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures", "comment": null, "summary": "Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3apathsig\u7684PyTorch\u539f\u751f\u5e93\uff0c\u5b83\u80fd\u9ad8\u6548\u5730\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\uff0c\u5e76\u4e14\u5728GPU\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u91cf\u548c\u51e0\u4e4e\u6700\u5c0f\u7684\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u3002\u4e0e\u5176\u5b83\u5e93\u76f8\u6bd4\uff0cpathsig\u5728\u622a\u65ad\u7b7e\u540d\u8ba1\u7b97\u65b9\u9762\u8fbe\u5230\u4e8610-30\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5728\u9700\u8981\u901a\u8fc7\u7b7e\u540d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u8bad\u7ec3\u4e2d\u5219\u8fbe\u5230\u4e864-10\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0cpathsig\u8fd8\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u8bcd\u96c6\u4e0a\u7684\u7b7e\u540d\u6295\u5f71\u4ee5\u53ca\u57fa\u4e8e\u4e0d\u5747\u5300\u8def\u5f84\u89c4\u5f8b\u6027\u7684\u5404\u5411\u5f02\u6027\u622a\u65ad\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u7ef4\u5ea6\u3001\u5197\u4f59\u6027\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u867d\u7136\u8def\u5f84\u7b7e\u540d\u4f5c\u4e3a\u5e8f\u5217\u6570\u636e\u7684\u4e00\u79cd\u4e30\u5bcc\u8868\u793a\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u5e76\u5177\u6709\u575a\u5b9e\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u4f46\u73b0\u6709\u7684\u5e93\u901a\u5e38\u7f3a\u4e4f\u652f\u6301\u5927\u89c4\u6a21\u57fa\u4e8e\u68af\u5ea6\u5b66\u4e60\u6240\u9700\u7684\u53ef\u6269\u5c55\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6ee1\u8db3\u8fd9\u79cd\u9700\u6c42\u7684\u65b0\u5e93\u3002", "method": "\u5f15\u5165\u4e86\u540d\u4e3apathsig\u7684PyTorch\u539f\u751f\u5e93\uff0c\u8be5\u5e93\u76f4\u63a5\u4ee5\u8bcd\u57fa\u4e3a\u57fa\u7840\u8ba1\u7b97\u8def\u5f84\u7b7e\u540d\u3002\u901a\u8fc7\u5229\u7528CUDA\u5185\u6838\u5e76\u884c\u66f4\u65b0\u524d\u7f00\u95ed\u5408\u8bcd\u96c6\u4e0a\u7684\u7b7e\u540d\u7cfb\u6570\uff0cpathsig\u80fd\u591f\u5728\u4fdd\u6301\u63a5\u8fd1\u6700\u5c0f\u5cf0\u503c\u5185\u5b58\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8GPU\u541e\u5410\u91cf\u3002\u6b64\u5916\uff0c\u9664\u4e86\u5e38\u89c4\u622a\u65ad\u5916\uff0cpathsig\u8fd8\u652f\u6301\u5c06\uff08\u65e0\u9650\u7ef4\uff09\u7b7e\u540d\u6295\u5f71\u5230\u7528\u6237\u6307\u5b9a\u7684\u8bcd\u96c6\u4e0a\uff0c\u5e76\u4e14\u652f\u6301\u7531\u4e0d\u5747\u5300\u8def\u5f84\u89c4\u5f8b\u6027\u6fc0\u53d1\u7684\u5404\u5411\u5f02\u6027\u622a\u65ad\u3002", "result": "\u4e0e\u5176\u4ed6\u5e93\u76f8\u6bd4\uff0cpathsig\u5728\u8ba1\u7b97\u622a\u65ad\u7b7e\u540d\u65f6\u901f\u5ea6\u63d0\u5347\u4e8610-30\u500d\uff1b\u5bf9\u4e8e\u9700\u8981\u901a\u8fc7\u7b7e\u540d\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5176\u901f\u5ea6\u4e5f\u63d0\u9ad8\u4e864-10\u500d\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u652f\u6301\u66f4\u7d27\u51d1\u7684\u6570\u636e\u8868\u793a\u65b9\u5f0f\uff0cpathsig\u8fd8\u6709\u52a9\u4e8e\u51cf\u5c11\u7ef4\u5ea6\u3001\u53bb\u9664\u5197\u4f59\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "pathsig\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u6548\u7684\u8def\u5f84\u7b7e\u540d\u8ba1\u7b97\u5e93\uff0c\u4e0d\u4ec5\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u66f4\u52a0\u7075\u6d3b\u7684\u6570\u636e\u5904\u7406\u9009\u9879\uff0c\u4ece\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.24083", "categories": ["cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24083", "abs": "https://arxiv.org/abs/2602.24083", "authors": ["Xinlong Du", "Harsha Honnappa", "Vinayak Rao"], "title": "Neural Diffusion Intensity Models for Point Process Data", "comment": null, "summary": "Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecfSDE\u7684Cox\u8fc7\u7a0b\u53d8\u5206\u6846\u67b6\uff0c\u5373\u795e\u7ecf\u6269\u6563\u5f3a\u5ea6\u6a21\u578b\u3002\u901a\u8fc7\u663e\u5f0f\u7684\u6f02\u79fb\u4fee\u6b63\u4fdd\u6301\u4e86\u6f5c\u5728\u5f3a\u5ea6\u7684\u6269\u6563\u7ed3\u6784\uff0c\u4ece\u800c\u4fdd\u8bc1\u53d8\u5206\u5bb6\u65cf\u5305\u542b\u771f\u5b9e\u540e\u9a8c\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u6062\u590d\u6f5c\u5728\u5f3a\u5ea6\u52a8\u6001\u548c\u540e\u9a8c\u8def\u5f84\uff0c\u5e76\u4e14\u76f8\u6bd4\u57fa\u4e8eMCMC\u7684\u65b9\u6cd5\u5177\u6709\u663e\u8457\u7684\u901f\u5ea6\u4f18\u52bf\u3002", "motivation": "Cox\u8fc7\u7a0b\u7528\u4e8e\u5efa\u6a21\u8fc7\u5206\u6563\u70b9\u8fc7\u7a0b\u6570\u636e\uff0c\u4f46\u5176\u975e\u53c2\u6570\u4f30\u8ba1\u53ca\u540e\u9a8c\u63a8\u7406\u901a\u5e38\u96be\u4ee5\u5904\u7406\uff0c\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684MCMC\u65b9\u6cd5\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u4ee5\u63d0\u9ad8\u6548\u7387\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u4e86\u795e\u7ecf\u6269\u6563\u5f3a\u5ea6\u6a21\u578b\uff08Neural Diffusion Intensity Models\uff09\uff0c\u4e00\u79cd\u7531\u795e\u7ecfSDE\u9a71\u52a8\u7684Cox\u8fc7\u7a0b\u53d8\u5206\u6846\u67b6\u3002\u5229\u7528\u8fc7\u6ee4\u6269\u589e\u7406\u8bba\u8bc1\u660e\u4e86\u6761\u4ef6\u4e8e\u70b9\u8fc7\u7a0b\u89c2\u5bdf\u4fdd\u7559\u4e86\u6f5c\u5728\u5f3a\u5ea6\u7684\u6269\u6563\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u660e\u786e\u7684\u6f02\u79fb\u4fee\u6b63\u5b9e\u73b0\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53ef\u644a\u9500\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5c06\u4e0d\u540c\u957f\u5ea6\u7684\u4e8b\u4ef6\u5e8f\u5217\u6620\u5c04\u5230\u540e\u9a8c\u5f3a\u5ea6\u8def\u5f84\u4e0a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u5730\u6062\u590d\u6f5c\u5728\u5f3a\u5ea6\u52a8\u6001\u548c\u540e\u9a8c\u8def\u5f84\uff0c\u76f8\u8f83\u4e8e\u57fa\u4e8eMCMC\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u6570\u91cf\u7ea7\u4e0a\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u795e\u7ecf\u6269\u6563\u5f3a\u5ea6\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u66ff\u4ee3\u4f20\u7edfMCMC\u65b9\u6cd5\u7684\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u8f83\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u5ea6\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2602.24146", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24146", "abs": "https://arxiv.org/abs/2602.24146", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Learning with a Budget: Identifying the Best Arm with Resource Constraints", "comment": "A preliminary version of this work, titled 'Best Arm Identification with Resource Constraints,' was presented at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024). This manuscript extends the original conference paper by providing improved theoretical results and more generalized conclusions, aiming for future journal submission. arXiv admin note: substantial text overlap with arXiv:2402.19090", "summary": "In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \\textit{effective consumption measure", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSH-RR\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5728\u8d44\u6e90\u9650\u5236\u6761\u4ef6\u4e0b\u7684\u6700\u4f73\u9009\u62e9\u95ee\u9898\u3002\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u5bf9\u8d44\u6e90\u6d88\u8017\u7684\u8ba4\u77e5\uff0c\u5e76\u80fd\u591f\u7edf\u4e00\u5904\u7406\u968f\u673a\u548c\u786e\u5b9a\u6027\u6d88\u8d39\u573a\u666f\u3002", "motivation": "\u5728\u5f88\u591a\u5e94\u7528\u4e2d\uff0c\u8bc4\u4f30\u4e0d\u540c\u9009\u9879\u7684\u6709\u6548\u6027\u4f34\u968f\u7740\u4e0d\u540c\u7684\u6210\u672c\u6216\u8d44\u6e90\u4f7f\u7528\u3002\u53d7\u8fd9\u79cd\u5f02\u8d28\u6027\u7684\u9a71\u52a8\uff0c\u4f5c\u8005\u7814\u7a76\u4e86\u5b58\u5728\u8d44\u6e90\u7ea6\u675f\u65f6\u5982\u4f55\u8bc6\u522b\u6700\u4f73\u9009\u9879\u7684\u95ee\u9898\u3002\u6bcf\u6b21\u9009\u62e9\u90fd\u4f1a\u6d88\u8017\u4e00\u79cd\u6216\u591a\u79cd\u6709\u9650\u7684\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u2014\u2014Successive Halving with Resource Rationing (SH-RR)\uff0c\u5b83\u5c06\u8d44\u6e90\u610f\u8bc6\u5206\u914d\u6574\u5408\u5230\u6700\u4f73\u9009\u62e9\u8bc6\u522b\u7684\u7ecf\u5178\u8fde\u7eed\u51cf\u534a\u6846\u67b6\u4e2d\u3002", "result": "SH-RR\u7b97\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u968f\u673a\u6d88\u8d39\u73af\u5883\u4e5f\u9002\u7528\u4e8e\u786e\u5b9a\u6027\u6d88\u8d39\u73af\u5883\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6709\u6548\u6d88\u8d39\u5ea6\u91cf\u6807\u51c6\u6765\u7edf\u4e00\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165SH-RR\u7b97\u6cd5\u53ca\u65b0\u7684\u6709\u6548\u6d88\u8d39\u8861\u91cf\u65b9\u5f0f\uff0c\u4e3a\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u6700\u4f73\u9009\u62e9\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u521b\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.24178", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.24178", "abs": "https://arxiv.org/abs/2602.24178", "authors": ["Adam R. Klivans", "Konstantinos Stavropoulos", "Arsen Vasilyan"], "title": "Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension", "comment": "30 pages", "summary": "Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.\n  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u4f4e\u5ea6\u5939\u5c42\u591a\u9879\u5f0f\uff0c\u5bf9\u4e8e\u4e00\u4e9b\u57fa\u672c\u51fd\u6570\u7c7b\u548c\u8fb9\u9645\u5206\u5e03\uff0c\u8be5\u65b9\u6cd5\u5728\u5ea6\u6570\u754c\u9650\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u9ad8\u65af\u5206\u5e03\u4e0b\u7684k\u4e2a\u534a\u7a7a\u95f4\u51fd\u6570\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u5ea6\u6570\u4e3apoly(k)\u7684\u5939\u5c42\u591a\u9879\u5f0f\uff0c\u76f8\u6bd4\u4e4b\u524d\u76842^O(k)\u754c\u9650\u6709\u4e86\u6307\u6570\u7ea7\u7684\u63d0\u5347\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u8fd8\u9002\u7528\u4e8e\u4f4e\u7ef4\u4e14\u8fb9\u754c\u5e73\u6ed1\u7684\u51fd\u6570\u7c7b\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u5c55\u793a\u4e86\u4f4e\u5ea6\u5939\u5c42\u591a\u9879\u5f0f\u8fd1\u4f3c\u5668\u5728\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u5982\u5177\u6709\u5206\u5e03\u504f\u79fb\u7684\u5b66\u4e60\u3001\u53ef\u6d4b\u8bd5\u5b66\u4e60\u4ee5\u53ca\u6c61\u67d3\u5b66\u4e60\u3002\u4f46\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u67d0\u4e9b\u51fd\u6570\u7c7b\u65f6\u5b58\u5728\u5ea6\u6570\u754c\u9650\u8fc7\u9ad8\u7684\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u65b0\u7684\u6784\u9020\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ee5\u83b7\u5f97\u66f4\u4f4e\u5ea6\u6570\u7684\u5939\u5c42\u591a\u9879\u5f0f\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u7684\u65b0\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u76ee\u6807\u51fd\u6570\u8fb9\u754c\u7684\u5e73\u6ed1\u6027\u6765\u76f4\u63a5\u6784\u9020\u5939\u5c42Lipschitz\u51fd\u6570\uff0c\u5e76\u501f\u52a9\u9ad8\u7ef4\u903c\u8fd1\u7406\u8bba\u7684\u7ed3\u679c\u3002\u6b64\u65b9\u6cd5\u907f\u514d\u4e86\u4f7f\u7528\u5148\u524d\u6700\u4f73\u7ed3\u679c\u4e2d\u6240\u91c7\u7528\u7684FT-\u8f6f\u5316\u6280\u672f\uff0c\u4ece\u800c\u5bf9\u4f4e\u7ef4\u591a\u9879\u5f0f\u9608\u503c\u51fd\u6570\uff08PTFs\uff09\u5173\u4e8e\u9ad8\u65af\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u53cc\u91cd\u6307\u6570\u7ea7\u522b\u7684\u6539\u8fdb\u3002", "result": "\u65b0\u65b9\u6cd5\u6210\u529f\u5730\u964d\u4f4e\u4e86\u591a\u4e2a\u91cd\u8981\u51fd\u6570\u7c7b\u53ca\u7279\u5b9a\u8fb9\u9645\u5206\u5e03\u6761\u4ef6\u4e0b\u6240\u9700\u7684\u591a\u9879\u5f0f\u5ea6\u6570\u3002\u7279\u522b\u5730\uff0c\u5728\u9ad8\u65af\u5206\u5e03\u4e0b\u9488\u5bf9k\u4e2a\u534a\u7a7a\u95f4\u51fd\u6570\u7684\u60c5\u51b5\uff0c\u6240\u5f97\u5939\u5c42\u591a\u9879\u5f0f\u7684\u5ea6\u6570\u964d\u4f4e\u81f3poly(k)\uff0c\u8f83\u4e4b\u524d\u7684\u7814\u7a76\u6210\u679c\u6709\u7740\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u6784\u9020\u4f4e\u5ea6\u5939\u5c42\u591a\u9879\u5f0f\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5177\u6709\u5e73\u6ed1\u8fb9\u754c\u7684\u4f4e\u7ef4\u51fd\u6570\u7c7b\u65f6\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u3002\u8fd9\u4e0d\u4ec5\u7b80\u5316\u4e86\u8bc1\u660e\u8fc7\u7a0b\uff0c\u800c\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5e26\u6765\u4e86\u6307\u6570\u4e43\u81f3\u53cc\u6307\u6570\u7ea7\u522b\u7684\u6539\u8fdb\u3002"}}
{"id": "2602.24182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24182", "abs": "https://arxiv.org/abs/2602.24182", "authors": ["Sikata Sengupta", "Guangyi Liu", "Omer Gottesman", "Joseph W Durham", "Michael Kearns", "Aaron Roth", "Michael Caldara"], "title": "Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers", "comment": null, "summary": "Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u57fa\u4e8e\u5bb9\u5668\u7684\u914d\u9001\u4e2d\u5fc3\u7684\u6574\u5408\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5728\u96f6\u548c\u535a\u5f08\u4e2d\u8fd0\u7528\u6700\u4f73\u54cd\u5e94\u548c\u65e0\u6094\u52a8\u6001\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u53d7\u9650\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u73b0\u5b9e\u4ed3\u5e93\u6a21\u62df\u4e2d\u6709\u6548\u5e73\u8861\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u5b66\u4e60\u5230\u4e00\u4e2a\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\u6761\u4ef6\u7684\u5355\u4e00\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u5904\u7406\u8bef\u5dee\u62b5\u6d88\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u4f18\u5316\u57fa\u4e8e\u5bb9\u5668\u7684\u914d\u9001\u4e2d\u5fc3\u4e2d\u7684\u6574\u5408\u6d41\u7a0b\uff0c\u9700\u8981\u5728\u5904\u7406\u901f\u5ea6\u3001\u8d44\u6e90\u4f7f\u7528\u7387\u4ee5\u53ca\u7a7a\u95f4\u5229\u7528\u7387\u7b49\u7ade\u4e89\u6027\u76ee\u6807\u4e4b\u95f4\u505a\u51fa\u6743\u8861\uff0c\u540c\u65f6\u9075\u5b88\u4e00\u7cfb\u5217\u5b9e\u9645\u64cd\u4f5c\u9650\u5236\u3002", "method": "\u5c06\u6b64\u95ee\u9898\u5b9a\u4e49\u4e3a\u5177\u6709\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e0e\u52a8\u6001\u7cfb\u7edf\u884c\u4e3a\u7684\u5927\u89c4\u6a21\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u3002\u57fa\u4e8e\u6700\u8fd1\u5728\u89e3\u51b3\u53d7\u9650RL\u95ee\u9898\u4e0a\u53d6\u5f97\u7684\u7406\u8bba\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u901a\u8fc7\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u6700\u4f73\u54cd\u5e94\u53ca\u65e0\u6094\u52a8\u6001\u5b9e\u73b0\u539f\u5219\u6027\u7684\u6700\u5c0f\u6700\u5927\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5728\u4e0d\u540c\u76ee\u6807\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u5e76\u4e14\u89c2\u5bdf\u5230\u5373\u4f7f\u7406\u8bba\u4e0a\u672a\u4fdd\u8bc1\u4e5f\u80fd\u5b66\u5230\u4e00\u4e2a\u5355\u72ec\u7b56\u7565\u4ee5\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\u6761\u4ef6\u3002\u5bf9\u4e8e\u8bef\u5dee\u62b5\u6d88\u95ee\u9898\uff08\u65f6\u95f4\u5e73\u5747\u89e3\u663e\u793a\u51fa\u632f\u8361\u884c\u4e3a\uff09\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u8fd4\u56de\u4e86\u4e00\u4e2a\u8fed\u4ee3\u7ed3\u679c\uff0c\u5176\u62c9\u683c\u6717\u65e5\u503c\u63a5\u8fd1\u6e38\u620f\u7684\u6700\u5c0f\u6700\u5927\u503c\u3002", "conclusion": "\u8fd9\u4e9b\u6210\u679c\u5c55\u793a\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u590d\u6742\u800c\u91cd\u8981\u7684\u51b3\u7b56\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.24201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24201", "abs": "https://arxiv.org/abs/2602.24201", "authors": ["Egor Antipov", "Alessandro Palma", "Lorenzo Consoli", "Stephan G\u00fcnnemann", "Andrea Dittadi", "Fabian J. Theis"], "title": "Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics", "comment": null, "summary": "Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u96be\u4ee5\u5904\u7406\u7684\u6570\u636e\u5206\u5e03\u5bf9\u4e4b\u95f4\u7684\u5bc6\u5ea6\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u5728\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u6570\u636e\u5206\u6790\u4e2d\u5c55\u793a\u4e86\u5176\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4f30\u8ba1\u6210\u5bf9\u96be\u4ee5\u5904\u7406\u7684\u6570\u636e\u5206\u5e03\u4e4b\u95f4\u7684\u5bc6\u5ea6\u6bd4\u662f\u6982\u7387\u5efa\u6a21\u4e2d\u7684\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\u3002\u867d\u7136\u6b63\u5219\u5316\u6d41\u7b49\u7cbe\u786e\u4f3c\u7136\u6a21\u578b\u4e3a\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u4f46\u57fa\u4e8e\u6d41\u7684\u76f4\u63a5\u8bc4\u4f30\u65b9\u6cd5\u7531\u4e8e\u9700\u8981\u5206\u522b\u4e3a\u6bcf\u4e2a\u5206\u5e03\u6a21\u62df\u6602\u8d35\u7684\u4f3c\u7136\u79ef\u5206\u800c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u4f5c\u8005\u4eec\u5229\u7528\u4e86\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u6280\u672f\uff0c\u63a8\u5bfc\u51fa\u4e00\u79cd\u5355\u4e00\u7684\u52a8\u529b\u5b66\u516c\u5f0f\uff0c\u7528\u4e8e\u6cbf\u751f\u6210\u8f68\u8ff9\u8ddf\u8e2a\u5bc6\u5ea6\u6bd4\u7684\u53d8\u5316\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u5728\u5c01\u95ed\u5f62\u5f0f\u6bd4\u7387\u4f30\u8ba1\u7684\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u51fa\u4e86\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u652f\u6301\u5355\u7ec6\u80de\u57fa\u56e0omics\u6570\u636e\u5206\u6790\u4e2d\u7684\u591a\u79cd\u4efb\u52a1\uff0c\u5982\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u7ec6\u80de\u72b6\u6001\u7684\u53ef\u80fd\u6027\u6765\u8fdb\u884c\u6cbb\u7597\u6548\u679c\u8bc4\u4f30\u548c\u6279\u6b21\u6821\u6b63\u8bc4\u4ef7\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u6761\u4ef6\u611f\u77e5\u6d41\u5339\u914d\u7684\u65b0\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6570\u636e\u5206\u5e03\u95f4\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\uff08\u7279\u522b\u662f\u5355\u7ec6\u80de\u57fa\u56e0\u7ec4\u5b66\uff09\u5c55\u73b0\u4e86\u5176\u4ef7\u503c\u3002"}}
{"id": "2602.24207", "categories": ["cs.LG", "cs.CY", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24207", "abs": "https://arxiv.org/abs/2602.24207", "authors": ["Gabriele Farina", "Juan Carlos Perdomo"], "title": "The Stability of Online Algorithms in Performative Prediction", "comment": null, "summary": "The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7b97\u6cd5\u9884\u6d4b\u5728\u51b3\u7b56\u4e2d\u7684\u4f7f\u7528\u5982\u4f55\u5bfc\u81f4\u53cd\u9988\u5faa\u73af\uff0c\u5e76\u8bc1\u660e\u4e86\u4efb\u4f55\u65e0\u6094\u7b97\u6cd5\u5728\u8fd9\u79cd\u8868\u73b0\u6027\u8bbe\u7f6e\u4e2d\u90fd\u4f1a\u6536\u655b\u5230\u4e00\u4e2a\uff08\u6df7\u5408\uff09\u8868\u73b0\u7a33\u5b9a\u5747\u8861\uff0c\u63ed\u793a\u4e86\u5982\u68af\u5ea6\u4e0b\u964d\u7b49\u5e38\u89c1\u7b97\u6cd5\u4e3a\u4f55\u81ea\u7136\u5177\u6709\u7a33\u5b9a\u6027\u5e76\u9632\u6b62\u5931\u63a7\u53cd\u9988\u5faa\u73af\u3002", "motivation": "\u968f\u7740\u7b97\u6cd5\u9884\u6d4b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u51b3\u7b56\uff0c\u8fd9\u4e9b\u6a21\u578b\u5f00\u59cb\u4e3b\u52a8\u5f71\u54cd\u6211\u4eec\u770b\u5230\u7684\u6570\u636e\u5206\u5e03\uff0c\u8fdb\u800c\u5f71\u54cd\u540e\u7eed\u7684\u518d\u8bad\u7ec3\u8fc7\u7a0b\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4f5c\u8868\u73b0\u6027\u9884\u6d4b\u3002\u5148\u524d\u7684\u7814\u7a76\u5bf9\u6a21\u578b\u5982\u4f55\u5f71\u54cd\u6570\u636e\u5206\u5e03\u505a\u51fa\u4e86\u8f83\u5f3a\u7684\u9650\u5236\u6761\u4ef6\uff0c\u800c\u672c\u6587\u8bd5\u56fe\u5728\u4e0d\u8bbe\u6b64\u7c7b\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u63a2\u8ba8\u8be5\u95ee\u9898\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u4e00\u79cd\u9785\u8bba\u70b9\uff0c\u5e76\u5141\u8bb8\u968f\u673a\u5316\u5904\u7406\uff0c\u4ece\u800c\u907f\u514d\u4e86\u4ee5\u5f80\u7814\u7a76\u4e2d\u5bf9\u6a21\u578b\u5f71\u54cd\u6570\u636e\u5206\u5e03\u65b9\u5f0f\u6240\u4f5c\u7684\u5f3a\u5047\u8bbe\uff0c\u7ed5\u8fc7\u4e86\u5bfb\u627e\u7a33\u5b9a\u6a21\u578b\u7684\u6700\u65b0\u96be\u5ea6\u7ed3\u679c\u3002", "result": "\u7814\u7a76\u8bc1\u660e\u4e86\uff0c\u5728\u8868\u73b0\u6027\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u4efb\u4f55\u65e0\u6094\u7b97\u6cd5\u6700\u7ec8\u90fd\u5c06\u6536\u655b\u81f3\u4e00\u4e2a\uff08\u53ef\u80fd\u662f\u6df7\u5408\u7b56\u7565\u4e0b\u7684\uff09\u8868\u73b0\u7a33\u5b9a\u5747\u8861\u72b6\u6001\u3002\u6b64\u5916\uff0c\u8fd8\u9610\u660e\u4e86\u50cf\u68af\u5ea6\u4e0b\u964d\u8fd9\u6837\u7684\u5e38\u7528\u7b97\u6cd5\u4e4b\u6240\u4ee5\u80fd\u591f\u81ea\u7136\u7a33\u5b9a\u3001\u9632\u6b62\u51fa\u73b0\u5931\u63a7\u53cd\u9988\u5faa\u73af\u7684\u539f\u56e0\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u7ebf\u4f18\u5316\u4e0e\u8868\u73b0\u6027\u4e4b\u95f4\u672a\u6765\u7684\u6280\u672f\u7406\u5ff5\u8f6c\u79fb\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u540c\u65f6\u4e5f\u4e3a\u7406\u89e3\u53ca\u8bbe\u8ba1\u66f4\u7a33\u5065\u7684\u8868\u73b0\u6027\u9884\u6d4b\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.24209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24209", "abs": "https://arxiv.org/abs/2602.24209", "authors": ["Mohsen Tajgardan", "Atena Shiranzaei", "Mahdi Rabbani", "Reza Khoshkangini", "Mahtab Jamali"], "title": "An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks", "comment": null, "summary": "Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u4e24\u4e2a\u4e0d\u540c\u7269\u8054\u7f51\u6570\u636e\u96c6\u7684\u5171\u4eab\u7279\u5f81\u6765\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u96c6\u7279\u5b9a\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7531\u4e8e\u8bbe\u5907\u80fd\u529b\u3001\u6570\u636e\u683c\u5f0f\u548c\u901a\u4fe1\u9650\u5236\u7684\u4e0d\u540c\u5bfc\u81f4\u7684\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5f02\u6784\u6027\u5bf9\u7ef4\u62a4\u5168\u5c40\u6a21\u578b\u6027\u80fd\u548c\u9690\u79c1\u6784\u6210\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u5f02\u5e38\u68c0\u6d4b\u573a\u666f\u4e2d\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u5229\u7528\u6765\u81ea\u4e13\u6ce8\u4e8e\u5f02\u5e38\u68c0\u6d4b\u4e0e\u8bbe\u5907\u8bc6\u522b\u4e24\u5927\u6570\u636e\u96c6\u4e4b\u95f4\u5171\u4eab\u7279\u5f81\u7684\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u53ef\u89e3\u91caAI\u6280\u672f\u5982SHAP\u503c\u6765\u589e\u5f3a\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u786e\u5b9a\u5f71\u54cd\u5c40\u90e8\u6a21\u578b\u51b3\u7b56\u7684\u5173\u952e\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u7684\u7269\u8054\u7f51\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u51c6\u786e\u7387\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u901a\u8fc7\u4f7f\u7528\u4e92\u8865\u6570\u636e\u96c6\u4e2d\u7684\u5171\u4eab\u7279\u5f81\u4f18\u5316\u65e0\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u4ee5\u5b9e\u73b0\u5728\u53bb\u4e2d\u5fc3\u5316\u7684\u7269\u8054\u7f51\u73af\u5883\u4e2d\u53d6\u5f97\u66f4\u4f18\u5f02\u5e38\u68c0\u6d4b\u7ed3\u679c\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2602.24231", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24231", "abs": "https://arxiv.org/abs/2602.24231", "authors": ["Hongrui Xie", "Junyu Cao", "Kan Xu"], "title": "Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference", "comment": "30 pages, 3 figure, AISTATS 2026 accepted paper", "summary": "In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63a2\u8ba8\u4e86\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u5728\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09\u4e2d\u6743\u8861\u9057\u61be\u6700\u5c0f\u5316\u4e0e\u7edf\u8ba1\u529f\u6548\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5b9a\u4e49\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u6765\u5f62\u5f0f\u5316\u8fd9\u4e00\u6743\u8861\uff0c\u5e76\u4e3a\u5168\u8001\u864e\u673a\u53cd\u9988\u548c\u534a\u8001\u864e\u673a\u53cd\u9988\u4e24\u79cd\u60c5\u51b5\u5206\u522b\u63d0\u51fa\u4e86MixCombKL\u548cMixCombUCB\u7b97\u6cd5\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e24\u79cd\u7b97\u6cd5\u90fd\u80fd\u8fbe\u5230\u5e15\u7d2f\u6258\u6700\u4f18\uff0c\u5e76\u4e14\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u4ece\u800c\u7f29\u5c0f\u53ef\u5b9e\u73b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u5728\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u4e2d\uff0c\u4e3a\u4e86\u540c\u65f6\u8fbe\u6210\u9057\u61be\u6700\u5c0f\u5316\u548c\u5bf9\u5956\u52b1\u5dee\u8ddd\u8fdb\u884c\u51c6\u786e\u63a8\u65ad\u8fd9\u4e24\u4e2a\u76ee\u6807\uff0c\u9700\u8981\u89e3\u51b3\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u4e3a\u6b64\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6982\u5ff5\u6765\u6b63\u5f0f\u5b9a\u4e49\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u8fd9\u79cd\u6743\u8861\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u7684\u4fe1\u606f\u7ed3\u6784\uff08\u5373\u5168\u8001\u864e\u673a\u53cd\u9988\u548c\u534a\u8001\u864e\u673a\u53cd\u9988\uff09\uff0c\u5206\u522b\u4e3a\u8fd9\u4e24\u79cd\u60c5\u51b5\u8bbe\u8ba1\u4e86\u540d\u4e3aMixCombKL\u548cMixCombUCB\u7684\u7b97\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4e24\u79cd\u7b97\u6cd5\u90fd\u80fd\u591f\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\uff0c\u5728\u6709\u9650\u65f6\u95f4\u5185\u4fdd\u8bc1\u4e86\u4f4e\u9057\u61be\u503c\u4ee5\u53ca\u8f83\u5c0f\u7684\u624b\u81c2\u95f4\u5dee\u8ddd\u4f30\u8ba1\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u53d1\u73b0\u66f4\u4e30\u5bcc\u7684\u53cd\u9988\u7c7b\u578b\u80fd\u591f\u663e\u8457\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u8fdb\u800c\u7f29\u5c0f\u4e86\u53ef\u8fbe\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u76ee\u6807\u51b3\u7b56\u5236\u5b9a\u4e2d\u7684\u81ea\u9002\u5e94\u7ec4\u5408\u5b9e\u9a8c\u786e\u7acb\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u4fe1\u606f\u7ed3\u6784\u4e0b\u6709\u6548\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u91cd\u8981\u6027\u3002"}}
