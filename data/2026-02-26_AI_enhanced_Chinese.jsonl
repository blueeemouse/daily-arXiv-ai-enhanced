{"id": "2602.22011", "categories": ["cs.MM", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.22011", "abs": "https://arxiv.org/abs/2602.22011", "authors": ["Kundan Singh"], "title": "A Generic Web Component for WebRTC Pub-Sub", "comment": "11 pages, 12 figures, 6 tables", "summary": "We present video-io, a generic web component to publish or subscribe to a media stream in WebRTC (web real-time communication) applications. Unlike a call or conference room abstraction of existing video conferencing services, it uses a named stream abstraction, which is useful in many scenarios beyond just a call or conference. It keeps most of the application logic in the endpoint using the extensive application interface of this component, and keeps any vendor specific access control or signaling negotiation in a service-specific connector implementation. This allows an app developer to write once, and be able to run the web app on different servers or services. We also demonstrate its flexibility by implementing the connector for ten different existing systems and services. Decoupling the app from the hosted vendor service promotes innovation in the endpoint beyond what a single vendor locked client app can offer.", "AI": {"tldr": "\u89c6\u9891-io\u662f\u4e00\u4e2a\u901a\u7528\u7684Web\u7ec4\u4ef6\uff0c\u7528\u4e8e\u5728WebRTC\u5e94\u7528\u4e2d\u53d1\u5e03\u6216\u8ba2\u9605\u5a92\u4f53\u6d41\u3002\u5b83\u4f7f\u7528\u547d\u540d\u6d41\u62bd\u8c61\u800c\u975e\u901a\u8bdd\u6216\u4f1a\u8bae\u5ba4\u62bd\u8c61\uff0c\u4f7f\u5f97\u5e94\u7528\u7a0b\u5e8f\u903b\u8f91\u4fdd\u7559\u5728\u7aef\u70b9\u5904\uff0c\u5e76\u5141\u8bb8\u5f00\u53d1\u8005\u7f16\u5199\u4e00\u6b21\u4ee3\u7801\u5373\u53ef\u5728\u4e0d\u540c\u670d\u52a1\u5668\u6216\u670d\u52a1\u4e0a\u8fd0\u884cweb\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7684\u89c6\u9891\u4f1a\u8bae\u670d\u52a1\u4e3b\u8981\u91c7\u7528\u901a\u8bdd\u6216\u4f1a\u8bae\u5ba4\u62bd\u8c61\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5e94\u7528\u573a\u666f\u3002\u4e3a\u4e86\u8d85\u8d8a\u8fd9\u4e9b\u9650\u5236\u5e76\u4fc3\u8fdb\u7aef\u70b9\u5904\u7684\u521b\u65b0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u89c6\u9891-io\u7ec4\u4ef6\u3002", "method": "\u89c6\u9891-io\u901a\u8fc7\u4f7f\u7528\u547d\u540d\u6d41\u62bd\u8c61\u6765\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002\u5927\u90e8\u5206\u5e94\u7528\u7a0b\u5e8f\u903b\u8f91\u88ab\u4fdd\u6301\u5728\u7aef\u70b9\u5904\uff0c\u800c\u7279\u5b9a\u4e8e\u4f9b\u5e94\u5546\u7684\u8bbf\u95ee\u63a7\u5236\u6216\u4fe1\u53f7\u534f\u5546\u5219\u7531\u670d\u52a1\u7279\u5b9a\u8fde\u63a5\u5668\u5b9e\u73b0\u8d1f\u8d23\u5904\u7406\u3002", "result": "\u5c55\u793a\u4e86\u89c6\u9891-io\u7ec4\u4ef6\u7684\u7075\u6d3b\u6027\uff0c\u901a\u8fc7\u4e3a\u5341\u4e2a\u4e0d\u540c\u7684\u73b0\u6709\u7cfb\u7edf\u548c\u670d\u52a1\u5b9e\u73b0\u8fde\u63a5\u5668\u3002\u8fd9\u79cd\u65b9\u5f0f\u8ba9web\u5e94\u7528\u80fd\u591f\u8131\u79bb\u7279\u5b9a\u4f9b\u5e94\u5546\u7684\u670d\u52a1\uff0c\u4ece\u800c\u4fc3\u8fdb\u7ec8\u7aef\u7528\u6237\u5c42\u9762\u7684\u66f4\u591a\u521b\u65b0\u3002", "conclusion": "\u89c6\u9891-io\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6784\u5efaWebRTC\u5e94\u7528\uff0c\u5b83\u4e0d\u4ec5\u9650\u4e8e\u4f20\u7edf\u7684\u901a\u8bdd\u6216\u4f1a\u8bae\u573a\u666f\uff0c\u800c\u4e14\u652f\u6301\u8de8\u5e73\u53f0\u548c\u8de8\u670d\u52a1\u90e8\u7f72\uff0c\u9f13\u52b1\u4e86\u66f4\u591a\u7684\u6280\u672f\u521b\u65b0\u3002"}}
{"id": "2602.21213", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21213", "abs": "https://arxiv.org/abs/2602.21213", "authors": ["Bilge Senturk", "Faruk Alpay"], "title": "Topological Relational Theory: A Simplicial-Complex View of Functional Dependencies, Lossless Decomposition, and Acyclicity", "comment": "8 pages, 2 figures", "summary": "We develop a topological lens on relational schema design by encoding functional dependencies (FDs) as simplices of an abstract simplicial complex. This dependency complex exposes multi-attribute interactions and enables homological invariants (Betti numbers) to diagnose cyclic dependency structure. We define Simplicial Normal Form (SNF) as homological acyclicity of the dependency complex in positive dimensions, i.e., vanishing reduced homology for all $n \\ge 1$. SNF is intentionally weaker than contractibility and does not identify homology with homotopy. For decompositions, we give a topological reformulation of the classical binary lossless-join criterion: assuming dependency preservation, a decomposition is lossless exactly when the intersection attributes form a key for at least one component. Topologically, this yields a strong deformation retraction that trivializes the relevant Mayer--Vietoris boundary map. For multiway decompositions, we show how the nerve of a cover by induced subcomplexes provides a computable certificate: a 1-cycle in the nerve (detected by $H_1$) obstructs join-tree structure and aligns with cyclic join behavior in acyclic-scheme theory. Finally, we discuss an algorithmic consequence: Betti numbers of the dependency complex (or of a decomposition nerve) can be computed from boundary matrices and used as a lightweight schema diagnostic to localize \"unexplained\" dependency cycles, complementing standard FD-chase tests.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u51fd\u6570\u4f9d\u8d56\u7f16\u7801\u4e3a\u62bd\u8c61\u5355\u7eaf\u590d\u5f62\u7684\u5355\u7eaf\u5f62\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u62d3\u6251\u89c6\u89d2\u6765\u7814\u7a76\u5173\u7cfb\u6a21\u5f0f\u8bbe\u8ba1\u3002\u5b9a\u4e49\u4e86\u5355\u7eaf\u6b63\u5219\u5f62\u5f0f\uff08SNF\uff09\uff0c\u5e76\u91cd\u65b0\u8868\u8ff0\u4e86\u7ecf\u5178\u7684\u65e0\u635f\u8fde\u63a5\u5206\u89e3\u51c6\u5219\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u8bf1\u5bfc\u5b50\u590d\u5f62\u8986\u76d6\u7684\u795e\u7ecf\u6765\u63d0\u4f9b\u53ef\u8ba1\u7b97\u8bc1\u660e\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fb9\u754c\u77e9\u9635\u8ba1\u7b97Betti\u6570\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u6a21\u5f0f\u8bca\u65ad\u7684\u5e94\u7528\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u62d3\u6251\u5b66\u6982\u5ff5\u5230\u5173\u7cfb\u6570\u636e\u5e93\u6a21\u5f0f\u8bbe\u8ba1\u4e2d\uff0c\u4ee5\u65b0\u7684\u65b9\u5f0f\u7406\u89e3\u548c\u5904\u7406\u51fd\u6570\u4f9d\u8d56\u53ca\u6a21\u5f0f\u5206\u89e3\u95ee\u9898\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8bca\u65ad\u548c\u89e3\u51b3\u5faa\u73af\u4f9d\u8d56\u7ed3\u6784\u7b49\u95ee\u9898\u3002", "method": "1. \u5c06\u51fd\u6570\u4f9d\u8d56\u7f16\u7801\u4e3a\u62bd\u8c61\u5355\u7eaf\u590d\u5f62\u7684\u5355\u7eaf\u5f62\u3002\n2. \u5b9a\u4e49\u5355\u7eaf\u6b63\u5219\u5f62\u5f0f\uff08SNF\uff09\u4f5c\u4e3a\u6b63\u7ef4\u5ea6\u4e0a\u4f9d\u8d56\u590d\u5f62\u7684\u540c\u8c03\u975e\u5faa\u73af\u6027\u3002\n3. \u7528\u62d3\u6251\u65b9\u6cd5\u91cd\u65b0\u8868\u8ff0\u4e86\u65e0\u635f\u8fde\u63a5\u5206\u89e3\u7684\u6807\u51c6\u3002\n4. \u5c55\u793a\u4e86\u5229\u7528\u8bf1\u5bfc\u5b50\u590d\u5f62\u8986\u76d6\u7684\u795e\u7ecf\u6765\u68c0\u6d4b\u963b\u788d\u8fde\u63a5\u6811\u7ed3\u6784\u7684\u4e00\u9636\u5faa\u73af\u3002\n5. \u63d0\u51fa\u4e86\u901a\u8fc7\u8fb9\u754c\u77e9\u9635\u8ba1\u7b97Betti\u6570\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u672a\u89e3\u91ca\u7684\u4f9d\u8d56\u5faa\u73af\u3002", "result": "1. \u6210\u529f\u5730\u5c06\u62d3\u6251\u5b66\u6982\u5ff5\u5e94\u7528\u4e8e\u5173\u7cfb\u6a21\u5f0f\u8bbe\u8ba1\u4e2d\uff0c\u63d0\u4f9b\u4e86\u8bca\u65ad\u5faa\u73af\u4f9d\u8d56\u7ed3\u6784\u7684\u65b0\u5de5\u5177\u3002\n2. \u7ed9\u51fa\u4e86\u65e0\u635f\u8fde\u63a5\u5206\u89e3\u7684\u4e00\u4e2a\u65b0\u7684\u62d3\u6251\u89e3\u91ca\u3002\n3. \u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u795e\u7ecf\u4e2d\u76841-\u5faa\u73af\u6765\u8bc6\u522b\u591a\u8def\u5206\u89e3\u4e2d\u7684\u8fde\u63a5\u884c\u4e3a\u95ee\u9898\u3002\n4. \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBetti\u6570\u8ba1\u7b97\u7684\u8f7b\u91cf\u7ea7\u6a21\u5f0f\u8bca\u65ad\u65b9\u6cd5\uff0c\u80fd\u591f\u8865\u5145\u6807\u51c6FD-chase\u6d4b\u8bd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u62d3\u6251\u5b66\u7684\u6982\u5ff5\u548c\u6280\u672f\uff0c\u672c\u6587\u4e3a\u5173\u7cfb\u6a21\u5f0f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u4e14\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7406\u89e3\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u4ee5\u53ca\u8fdb\u884c\u6709\u6548\u7684\u6a21\u5f0f\u5206\u89e3\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86\u5bf9\u73b0\u6709\u95ee\u9898\u7684\u7406\u89e3\uff0c\u4e5f\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.21221", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.21221", "abs": "https://arxiv.org/abs/2602.21221", "authors": ["Zeju Li", "Yizhou Zhou", "Qiang Xu"], "title": "Latent Context Compilation: Distilling Long Context into Compact Portable Memory", "comment": null, "summary": "Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that complicate concurrent serving. We propose Latent Context Compilation, a framework that fundamentally shifts context processing from adaptation to compilation. By utilizing a disposable LoRA module as a compiler, we distill long contexts into compact buffer tokens -- stateless, portable memory artifacts that are plug-and-play compatible with frozen base models. Crucially, we introduce a self-aligned optimization strategy that eliminates the need for synthetic context-relevant QA pairs. By regularizing context reconstruction task with context-agnostic random queries, we force compressed tokens to reside within the model's existing instruction-following manifold. Experiments with Llama-3.1-8B demonstrate that Latent Context Compilation preserves fine-grained details and reasoning capabilities where prior methods falter, effectively decoupling memory density from model parameters even at a 16x compression ratio.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6f5c\u4e0a\u4e0b\u6587\u7f16\u8bd1\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e00\u6b21\u6027LoRA\u6a21\u5757\u5c06\u957f\u4e0a\u4e0b\u6587\u63d0\u70bc\u6210\u7d27\u51d1\u7684\u7f13\u51b2\u4ee4\u724c\uff0c\u8fd9\u4e9b\u4ee4\u724c\u4e0e\u51bb\u7ed3\u7684\u57fa\u7840\u6a21\u578b\u517c\u5bb9\u3002\u901a\u8fc7\u81ea\u5bf9\u9f50\u4f18\u5316\u7b56\u7565\u6d88\u9664\u4e86\u5bf9\u5408\u6210\u4e0a\u4e0b\u6587\u76f8\u5173QA\u5bf9\u7684\u9700\u6c42\uff0c\u5e76\u4e14\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u5373\u4f7f\u572816\u500d\u538b\u7f29\u6bd4\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7ec6\u8282\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u9762\u4e34\u4e24\u4e2a\u95ee\u9898\uff1a\u644a\u9500\u538b\u7f29\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5206\u5e03\u5916\u6cdb\u5316\uff1b\u800c\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u5219\u5e26\u6765\u4e86\u9ad8\u6602\u7684\u5408\u6210\u6570\u636e\u6210\u672c\u5e76\u9700\u8981\u4fee\u6539\u6a21\u578b\u6743\u91cd\uff0c\u5bfc\u81f4\u72b6\u6001\u53c2\u6570\u590d\u6742\u5316\uff0c\u4e0d\u5229\u4e8e\u540c\u65f6\u670d\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u6f5c\u4e0a\u4e0b\u6587\u7f16\u8bd1\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u4e00\u6b21\u6027\u7684LoRA\u6a21\u5757\u4f5c\u4e3a\u7f16\u8bd1\u5668\uff0c\u5c06\u957f\u4e0a\u4e0b\u6587\u63d0\u70bc\u4e3a\u7d27\u51d1\u7684\u7f13\u51b2\u4ee4\u724c\u2014\u2014\u65e0\u72b6\u6001\u3001\u53ef\u79fb\u690d\u7684\u8bb0\u5fc6\u5236\u54c1\uff0c\u80fd\u591f\u4e0e\u51bb\u7ed3\u7684\u57fa\u7840\u6a21\u578b\u5373\u63d2\u5373\u7528\u3002\u8fd8\u5f15\u5165\u4e86\u81ea\u5bf9\u9f50\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u4f7f\u7528\u4e0e\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u968f\u673a\u67e5\u8be2\u6765\u89c4\u8303\u4e0a\u4e0b\u6587\u91cd\u5efa\u4efb\u52a1\uff0c\u8feb\u4f7f\u538b\u7f29\u540e\u7684\u4ee4\u724c\u4f4d\u4e8e\u6a21\u578b\u73b0\u6709\u7684\u6307\u4ee4\u8ddf\u968f\u6d41\u5f62\u5185\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6f5c\u4e0a\u4e0b\u6587\u7f16\u8bd1\u80fd\u591f\u5728\u4fdd\u7559\u7ec6\u7c92\u5ea6\u7ec6\u8282\u548c\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u9ad8\u8fbe16\u500d\u7684\u538b\u7f29\u6bd4\u7387\uff0c\u8fd9\u8868\u660e\u5b83\u6210\u529f\u5730\u5c06\u8bb0\u5fc6\u5bc6\u5ea6\u4e0e\u6a21\u578b\u53c2\u6570\u89e3\u8026\u3002", "conclusion": "\u6f5c\u4e0a\u4e0b\u6587\u7f16\u8bd1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6bd4\u4f8b\u538b\u7f29\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.21411", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21411", "abs": "https://arxiv.org/abs/2602.21411", "authors": ["Marc Dufay", "Diana Ghinea", "Anton Paramonov"], "title": "General Convex Agreement with Near-Optimal Communication", "comment": "Working paper", "summary": "Convex Agreement (CA) strengthens Byzantine Agreement (BA) by requiring the output agreed upon to lie in the convex hull of the honest parties' inputs. This validity condition is motivated by practical aggregation tasks (e.g., robust learning or sensor fusion) where honest inputs need not coincide but should still constrain the decision. CA inherits BA lower bounds, and optimal synchronous round complexity is easy to obtain (e.g., via Byzantine Broadcast). The main challenge is \\emph{communication}: standard approaches for CA have a communication complexity of $\u0398(Ln^2)$ for large $L$-bit inputs, leaving a gap in contrast to BA's lower bound of $\u03a9(Ln)$ bits. While recent work achieves optimal communication complexity of $O(Ln)$ for sufficiently large $L$ [GLW,PODC'25], translating this result to general convexity spaces remained an open problem.\n  We investigate this gap for abstract convexity spaces, and we present deterministic synchronous CA protocols with near-optimal communication complexity: when $L = \u03a9(n \\cdot \u03ba)$, where $\u03ba$ is a security parameter, we achieve $O(L\\cdot n\\log n)$ communication for finite convexity spaces and $O(L\\cdot n^{1+o(1)})$ communication for Euclidean spaces $\\mathbb{R}^d$. Our protocols have asymptotically optimal round complexity $O(n)$ and, when a bound on the inputs' lengths $L$ is fixed a priori, we achieve near-optimal resilience $t < n/(\u03c9+\\varepsilon)$ for any constant $\\varepsilon>0$, where $\u03c9$ is the Helly number of the convexity space. If $L$ is unknown, we still achieve resilience $t<n/(\u03c9+\\varepsilon+1)$ for any constant $\\varepsilon > 0$. We further note that our protocols can be leveraged to efficiently solve parallel BA.\n  Our main technical contribution is the use of extractor graphs to obtain a deterministic assignment of parties to committees, which is resilient against adaptive adversaries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u51f8\u534f\u8bae\uff08CA\uff09\u5728\u62bd\u8c61\u51f8\u6027\u7a7a\u95f4\u4e2d\u7684\u901a\u4fe1\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5177\u6709\u63a5\u8fd1\u6700\u4f18\u901a\u4fe1\u590d\u6742\u5ea6\u7684\u786e\u5b9a\u6027\u540c\u6b65CA\u534f\u8bae\uff0c\u5e76\u5229\u7528\u63d0\u53d6\u5668\u56fe\u5b9e\u73b0\u4e86\u5bf9\u9002\u5e94\u6027\u5bf9\u624b\u6709\u5f39\u6027\u7684\u53c2\u4e0e\u8005\u5230\u59d4\u5458\u4f1a\u7684\u786e\u5b9a\u6027\u5206\u914d\u3002", "motivation": "\u51f8\u534f\u8bae\uff08CA\uff09\u662f\u62dc\u5360\u5ead\u534f\u8bae\uff08BA\uff09\u7684\u4e00\u79cd\u5f3a\u5316\u5f62\u5f0f\uff0c\u8981\u6c42\u8fbe\u6210\u4e00\u81f4\u7684\u8f93\u51fa\u4f4d\u4e8e\u8bda\u5b9e\u53c2\u4e0e\u8005\u7684\u8f93\u5165\u7684\u51f8\u5305\u5185\u3002\u8fd9\u79cd\u6709\u6548\u6027\u6761\u4ef6\u53d7\u5230\u5b9e\u9645\u805a\u5408\u4efb\u52a1\uff08\u5982\u9c81\u68d2\u5b66\u4e60\u6216\u4f20\u611f\u5668\u878d\u5408\uff09\u7684\u9a71\u52a8\uff0c\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\uff0c\u8bda\u5b9e\u8f93\u5165\u4e0d\u5fc5\u5b8c\u5168\u76f8\u540c\uff0c\u4f46\u5e94\u8be5\u4ecd\u7136\u7ea6\u675f\u51b3\u7b56\u3002\u867d\u7136\u6807\u51c6\u65b9\u6cd5\u5bf9\u4e8e\u5927L\u4f4d\u8f93\u5165\u7684CA\u5177\u6709\u0398(Ln^2)\u7684\u901a\u4fe1\u590d\u6742\u5ea6\uff0c\u4f46\u4e0eBA\u7684\u4e0b\u754c\u03a9(Ln)\u6bd4\u7279\u76f8\u6bd4\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u4f5c\u8005\u4eec\u63a2\u8ba8\u4e86\u62bd\u8c61\u51f8\u6027\u7a7a\u95f4\u4e2d\u7684\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u5177\u6709\u8fd1\u4f3c\u6700\u4f18\u901a\u4fe1\u590d\u6742\u5ea6\u7684\u786e\u5b9a\u6027\u540c\u6b65CA\u534f\u8bae\u3002\u5f53L = \u03a9(n \u00b7 \u03ba)\uff0c\u5176\u4e2d\u03ba\u4e3a\u5b89\u5168\u53c2\u6570\u65f6\uff0c\u5bf9\u4e8e\u6709\u9650\u7684\u51f8\u6027\u7a7a\u95f4\uff0c\u4ed6\u4eec\u5b9e\u73b0\u4e86O(L\u00b7 nlog n)\u7684\u901a\u4fe1\u91cf\uff1b\u5bf9\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4R^d\uff0c\u5219\u5b9e\u73b0\u4e86O(L\u00b7 n^(1+o(1)))\u7684\u901a\u4fe1\u91cf\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u63d0\u53d6\u5668\u56fe\u6765\u5b9e\u73b0\u5bf9\u9002\u5e94\u6027\u5bf9\u624b\u6709\u5f39\u6027\u7684\u53c2\u4e0e\u8005\u5230\u59d4\u5458\u4f1a\u7684\u786e\u5b9a\u6027\u5206\u914d\u662f\u4ed6\u4eec\u7684\u4e3b\u8981\u6280\u672f\u8d21\u732e\u3002", "result": "\u6240\u63d0\u51fa\u7684\u534f\u8bae\u5177\u6709\u6e10\u8fd1\u6700\u4f18\u8f6e\u590d\u6742\u5ea6O(n)\uff0c\u5e76\u4e14\u5f53\u8f93\u5165\u957f\u5ea6L\u9884\u5148\u56fa\u5b9a\u65f6\uff0c\u5bf9\u4e8e\u4efb\u4f55\u5e38\u6570\u03b5>0\uff0c\u53ef\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u5f39\u6027t < n/(\u03c9+\u03b5)\uff0c\u5176\u4e2d\u03c9\u662f\u51f8\u6027\u7a7a\u95f4\u7684Helly\u6570\u3002\u5982\u679cL\u672a\u77e5\uff0c\u4ecd\u53ef\u5bf9\u4efb\u4f55\u5e38\u6570\u03b5 > 0\u8fbe\u5230\u5f39\u6027t<n/(\u03c9+\u03b5+1)\u3002", "conclusion": "\u8be5\u8bba\u6587\u6210\u529f\u5730\u7f29\u5c0f\u4e86CA\u4e0eBA\u4e4b\u95f4\u5728\u901a\u4fe1\u590d\u6742\u5ea6\u4e0a\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u62bd\u8c61\u51f8\u6027\u7a7a\u95f4\u4e2d\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u6280\u672f\u624b\u6bb5\u2014\u2014\u5229\u7528\u63d0\u53d6\u5668\u56fe\u8fdb\u884c\u53c2\u4e0e\u8005\u5230\u59d4\u5458\u4f1a\u7684\u5206\u914d\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u534f\u8bae\u9762\u5bf9\u9002\u5e94\u6027\u5bf9\u624b\u65f6\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.21553", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21553", "abs": "https://arxiv.org/abs/2602.21553", "authors": ["Wenqing Zheng", "Dmitri Kalaev", "Noah Fatsi", "Daniel Barcklow", "Owen Reinert", "Igor Melnyk", "Senthil Kumar", "C. Bayan Bruss"], "title": "Revisiting RAG Retrievers: An Information Theoretic Benchmark", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MIGRASCOPE\uff0c\u4e00\u79cd\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684RAG\u68c0\u7d22\u5668\u5206\u6790\u8303\u56f4\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u4fe1\u606f\u548c\u7edf\u8ba1\u4f30\u8ba1\u7406\u8bba\u7684\u539f\u5219\u6027\u5ea6\u91cf\u6765\u91cf\u5316\u68c0\u7d22\u8d28\u91cf\u3001\u5197\u4f59\u6027\u3001\u534f\u540c\u6548\u5e94\u53ca\u8fb9\u9645\u8d21\u732e\uff0c\u5e76\u53d1\u73b0\u7cbe\u5fc3\u6311\u9009\u7684\u68c0\u7d22\u5668\u7ec4\u5408\u4f18\u4e8e\u4efb\u4f55\u5355\u4e00\u68c0\u7d22\u5668\u3002", "motivation": "\u73b0\u6709\u7684RAG\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u68c0\u7d22\u6a21\u5757\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u6392\u540d\u539f\u5219\uff08\u5982\u8bcd\u6c47\u5339\u914d\u3001\u5bc6\u96c6\u5d4c\u5165\u6216\u56fe\u8868\u5f15\u7528\uff09\u6784\u5efa\u7684\u5404\u79cd\u68c0\u7d22\u5668\u4e4b\u95f4\u5dee\u5f02\u548c\u91cd\u53e0\u7684\u7cfb\u7edf\u7406\u89e3\u3002\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u6bd4\u8f83\u6574\u4e2aRAG\u6d41\u7a0b\u6216\u5f15\u5165\u65b0\u6570\u636e\u96c6\uff0c\u5728\u9009\u62e9\u6216\u7ed3\u5408\u68c0\u7d22\u5668\u65b9\u9762\u63d0\u4f9b\u7684\u6307\u5bfc\u5f88\u5c11\u3002\u76f4\u63a5\u6bd4\u8f83\u68c0\u7d22\u5668\u7684\u7814\u7a76\u4f7f\u7528\u7684\u8bc4\u4f30\u5de5\u5177\u6709\u9650\uff0c\u65e0\u6cd5\u6355\u6349\u5230\u5b83\u4eec\u7684\u4e92\u8865\u4f18\u52bf\u548c\u91cd\u53e0\u5f3a\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86MIGRASCOPE\uff0c\u4e00\u79cd\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684RAG\u68c0\u7d22\u5668\u5206\u6790\u6846\u67b6\uff0c\u91cd\u65b0\u5ba1\u89c6\u4e86\u6700\u5148\u8fdb\u68c0\u7d22\u5668\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8e\u4fe1\u606f\u8bba\u548c\u7edf\u8ba1\u4f30\u8ba1\u7406\u8bba\u7684\u539f\u5219\u6027\u6307\u6807\u6765\u91cf\u5316\u68c0\u7d22\u8d28\u91cf\u3001\u5197\u4f59\u6027\u3001\u534f\u540c\u4f5c\u7528\u4ee5\u53ca\u8fb9\u9645\u8d21\u732e\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5982\u679c\u7cbe\u5fc3\u9009\u62e9\uff0c\u68c0\u7d22\u5668\u96c6\u5408\u7684\u8868\u73b0\u5c06\u4f18\u4e8e\u4efb\u4f55\u5355\u4e00\u68c0\u7d22\u5668\u3002\u4f7f\u7528\u6240\u5f00\u53d1\u5de5\u5177\u5bf9\u4e3b\u8981RAG\u8bed\u6599\u5e93\u8fdb\u884c\u5206\u6790\u540e\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u5668\u8d21\u732e\u6c34\u5e73\u7684\u72ec\u7279\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u73b0\u4ee3\u68c0\u7d22\u6280\u672f\u7684\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u5f3a\u5927\u4e14\u9ad8\u6548\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2602.21568", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21568", "abs": "https://arxiv.org/abs/2602.21568", "authors": ["Yuvraj Agrawal", "Pallav Jain"], "title": "From Ad-Hoc Scripts to Orchestrated Pipelines: Architecting a Resilient ELT Framework for Developer Productivity Metrics", "comment": null, "summary": "Developer Productivity Dashboards are essential for visualizing DevOps performance metrics such as Deployment Frequency and Change Failure Rate (DORA). However, the utility of these dashboards is frequently undermined by data reliability issues. In early iterations of our platform, ad-hoc ingestion scripts (Cron jobs) led to \"silent failures,\" where data gaps went undetected for days, eroding organizational trust. This paper reports on our experience migrating from legacy scheduling to a robust Extract-Load-Transform (ELT) pipeline using Directed Acyclic Graph (DAG) orchestration and Medallion Architecture. We detail the operational benefits of decoupling data extraction from transformation, the necessity of immutable raw history for metric redefinition, and the implementation of state-based dependency management. Our experience suggests that treating the metrics pipeline as a production-grade distributed system is a prerequisite for sustainable engineering analytics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u4ece\u4f20\u7edf\u7684\u8c03\u5ea6\u65b9\u5f0f\u8fc1\u79fb\u5230\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7f16\u6392\u548c\u5956\u724c\u67b6\u6784\u7684ELT\u7ba1\u9053\u7684\u8fc7\u7a0b\uff0c\u4ee5\u63d0\u9ad8\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u4eea\u8868\u76d8\u7684\u6570\u636e\u53ef\u9760\u6027\u3002\u901a\u8fc7\u5206\u79bb\u6570\u636e\u63d0\u53d6\u4e0e\u8f6c\u6362\uff0c\u5e76\u5b9e\u65bd\u57fa\u4e8e\u72b6\u6001\u7684\u4f9d\u8d56\u7ba1\u7406\uff0c\u63d0\u9ad8\u4e86\u5de5\u7a0b\u5206\u6790\u7684\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u5f00\u53d1\u4eba\u5458\u751f\u4ea7\u529b\u4eea\u8868\u677f\u5bf9\u4e8e\u53ef\u89c6\u5316DevOps\u6027\u80fd\u6307\u6807\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4e9b\u4eea\u8868\u677f\u7684\u5b9e\u7528\u6027\u7ecf\u5e38\u56e0\u4e3a\u6570\u636e\u53ef\u9760\u6027\u95ee\u9898\u800c\u53d7\u5230\u635f\u5bb3\u3002\u5728\u5e73\u53f0\u65e9\u671f\u7248\u672c\u4e2d\uff0c\u4e34\u65f6\u7684\u6444\u53d6\u811a\u672c\u5bfc\u81f4\u6570\u636e\u7f3a\u53e3\u672a\u88ab\u53ca\u65f6\u53d1\u73b0\uff0c\u964d\u4f4e\u4e86\u7ec4\u7ec7\u4fe1\u4efb\u5ea6\u3002", "method": "\u8fc1\u79fb\u81f3\u4e00\u4e2a\u5065\u58ee\u7684Extract-Load-Transform (ELT) \u7ba1\u9053\uff0c\u5229\u7528Directed Acyclic Graph (DAG) \u7f16\u6392\u4ee5\u53caMedallion\u67b6\u6784\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u65b9\u6cd5\u5305\u62ec\u89e3\u8026\u6570\u636e\u62bd\u53d6\u4e0e\u53d8\u6362\u8fc7\u7a0b\u3001\u786e\u4fdd\u539f\u59cb\u5386\u53f2\u8bb0\u5f55\u4e0d\u53ef\u53d8\u4ee5\u4fbf\u91cd\u65b0\u5b9a\u4e49\u5ea6\u91cf\u6807\u51c6\u3001\u5e76\u5f15\u5165\u57fa\u4e8e\u72b6\u6001\u7684\u4f9d\u8d56\u7ba1\u7406\u3002", "result": "\u5b9e\u73b0\u4e86\u66f4\u52a0\u53ef\u9760\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u652f\u6301\u5ea6\u91cf\u6807\u51c6\u7684\u91cd\u65b0\u5b9a\u4e49\u800c\u4e0d\u4e22\u5931\u5386\u53f2\u4fe1\u606f\uff0c\u5e76\u4e14\u901a\u8fc7\u57fa\u4e8e\u72b6\u6001\u7684\u4f9d\u8d56\u7ba1\u7406\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c06\u5ea6\u91cf\u7ba1\u9053\u89c6\u4e3a\u751f\u4ea7\u7ea7\u5206\u5e03\u5f0f\u7cfb\u7edf\u662f\u5b9e\u73b0\u53ef\u6301\u7eed\u5de5\u7a0b\u5206\u6790\u7684\u524d\u63d0\u6761\u4ef6\u3002"}}
{"id": "2602.21237", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21237", "abs": "https://arxiv.org/abs/2602.21237", "authors": ["Il-Sun Chang"], "title": "Premature Dimensional Collapse and Tensor-based Execution Paths for High-Dimensional Relational Operations in Cost-Based Database Systems", "comment": "24 pages, 7 figures", "summary": "Modern cost-based DBMSs frequently exhibit execution instability and tail-latency amplification when high-dimensional relational operations trigger memory-regime transitions such as hash-table spilling and external materialization. We identify a structural failure mode in which intermediate representations are prematurely linearized under memory pressure, causing disproportionate I/O amplification and phase-transition-like latency behavior. To mitigate this, we propose a tensor-based execution path that delays premature linearization and preserves higher-dimensional locality through late materialization and structured intermediate layouts. Using a modified PostgreSQL-based prototype and controlled microbenchmarks, we show that under constrained memory settings (e.g., work_mem=1MB) conventional execution can spill hundreds of megabytes and exceed multi-second P99 latency, while the proposed path maintains stable execution and reduces P99 latency to sub-second levels. Our results suggest that representation timing is a first-class design variable for execution stability, complementing traditional optimization efforts focused on cardinality estimation and operator throughput.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u7684\u6267\u884c\u8def\u5f84\uff0c\u901a\u8fc7\u5ef6\u8fdf\u8fc7\u65e9\u7ebf\u6027\u5316\u5e76\u4fdd\u6301\u9ad8\u7ef4\u5c40\u90e8\u6027\u6765\u89e3\u51b3\u5173\u7cfb\u64cd\u4f5c\u5728\u5185\u5b58\u538b\u529b\u4e0b\u5bfc\u81f4\u7684\u6267\u884c\u4e0d\u7a33\u5b9a\u548c\u5c3e\u90e8\u5ef6\u8fdf\u653e\u5927\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u53d7\u9650\u7684\u5185\u5b58\u8bbe\u7f6e\u4e0b\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u591a\u79d2\u7684P99\u5ef6\u8fdf\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u5c06P99\u5ef6\u8fdf\u964d\u4f4e\u5230\u79d2\u7ea7\u4ee5\u4e0b\u3002", "motivation": "\u5f53\u524d\u7684\u6210\u672c\u57fa\u7840\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf(DBMS)\u5728\u5904\u7406\u9ad8\u7ef4\u5ea6\u5173\u7cfb\u8fd0\u7b97\u65f6\uff0c\u7531\u4e8e\u5185\u5b58\u9650\u5236\u7ecf\u5e38\u89e6\u53d1\u54c8\u5e0c\u8868\u6ea2\u51fa\u53ca\u5916\u90e8\u7269\u5316\u7b49\u73b0\u8c61\uff0c\u5bfc\u81f4\u6267\u884c\u4e0d\u7a33\u5b9a\u6027\u548c\u5c3e\u90e8\u5ef6\u8fdf\u653e\u5927\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e2d\u95f4\u8868\u793a\u5728\u5185\u5b58\u538b\u529b\u4e0b\u8fc7\u65e9\u7ebf\u6027\u5316\u4f1a\u5f15\u53d1\u4e0d\u6210\u6bd4\u4f8b\u7684I/O\u653e\u5927\u4ee5\u53ca\u7c7b\u4f3c\u76f8\u53d8\u7684\u5ef6\u8fdf\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u7684\u6267\u884c\u7b56\u7565\uff0c\u65e8\u5728\u5ef6\u7f13\u8fd9\u79cd\u8fc7\u65e9\u7684\u7ebf\u6027\u5316\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u540e\u671f\u7269\u5316\u4e0e\u7ed3\u6784\u5316\u7684\u4e2d\u95f4\u5e03\u5c40\u4fdd\u6301\u66f4\u9ad8\u7684\u7ef4\u5ea6\u5c40\u90e8\u6027\u3002", "result": "\u5229\u7528\u4fee\u6539\u540e\u7684PostgreSQL\u539f\u578b\u7cfb\u7edf\u548c\u53d7\u63a7\u5fae\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5728\u5185\u5b58\u53d7\u9650\u6761\u4ef6\u4e0b\uff08\u4f8b\u5982work_mem=1MB\uff09\uff0c\u4f20\u7edf\u6267\u884c\u65b9\u5f0f\u53ef\u80fd\u4ea7\u751f\u6570\u767e\u5146\u5b57\u8282\u7684\u6570\u636e\u6ea2\u51fa\uff0c\u5e76\u4e14P99\u5ef6\u8fdf\u8d85\u8fc7\u6570\u79d2\uff1b\u800c\u63d0\u8bae\u7684\u65b9\u6cd5\u5219\u80fd\u591f\u4fdd\u6301\u7a33\u5b9a\u7684\u6267\u884c\u6027\u80fd\uff0c\u5e76\u5c06P99\u5ef6\u8fdf\u51cf\u5c11\u81f3\u4e9a\u79d2\u7ea7\u522b\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u8868\u793a\u65f6\u673a\u662f\u6267\u884c\u7a33\u5b9a\u6027\u7684\u4e00\u4e2a\u5173\u952e\u8bbe\u8ba1\u53d8\u91cf\uff0c\u8fd9\u8865\u5145\u4e86\u4ee5\u5f80\u96c6\u4e2d\u5728\u57fa\u6570\u4f30\u8ba1\u548c\u64cd\u4f5c\u7b26\u541e\u5410\u91cf\u4e0a\u7684\u4f18\u5316\u5de5\u4f5c\u3002"}}
{"id": "2602.21598", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21598", "abs": "https://arxiv.org/abs/2602.21598", "authors": ["Touseef Hasan", "Laila Cure", "Souvika Sarkar"], "title": "Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access", "comment": "3 pages, 1 figure", "summary": "Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u5bf9\u8bdd\u68c0\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8e\u6539\u5584\u98df\u54c1\u50a8\u85cf\u5ba4\u7b49\u5173\u952e\u516c\u5171\u670d\u52a1\u4fe1\u606f\u7cfb\u7edf\u7684\u8bbf\u95ee\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e0b\u3002\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u4e86\u7cfb\u7edf\u5728\u5904\u7406\u4e0d\u660e\u786e\u67e5\u8be2\u548c\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u516c\u5171\u4fe1\u606f\u670d\u52a1\u7cfb\u7edf\u901a\u5e38\u5b58\u5728\u788e\u7247\u5316\u3001\u683c\u5f0f\u4e0d\u4e00\u81f4\u4ee5\u53ca\u4fe1\u606f\u8fc7\u65f6\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u5bfc\u81f4\u4e86\u4f4e\u8d44\u6e90\u68c0\u7d22\u73af\u5883\uff0c\u963b\u788d\u4e86\u5bf9\u91cd\u8981\u670d\u52a1\u7684\u53ca\u65f6\u83b7\u53d6\u3002\u672c\u7814\u7a76\u901a\u8fc7\u89e3\u51b3\u98df\u54c1\u50a8\u85cf\u5ba4\u8bbf\u95ee\u8fd9\u4e00\u793e\u4f1a\u7d27\u8feb\u95ee\u9898\u6765\u63a2\u8ba8\u6b64\u7c7b\u8bbe\u7f6e\u4e0b\u7684\u68c0\u7d22\u6311\u6218\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u7531AI\u9a71\u52a8\u7684\u5bf9\u8bdd\u5f0f\u68c0\u7d22\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6293\u53d6\u5e76\u7d22\u5f15\u516c\u5f00\u53ef\u7528\u7684\u98df\u7269\u50a8\u85cf\u5ba4\u6570\u636e\uff0c\u5e76\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u7a0b\u652f\u6301\u901a\u8fc7\u7f51\u9875\u754c\u9762\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u5229\u7528\u793e\u533a\u63d0\u4f9b\u7684\u67e5\u8be2\u8fdb\u884c\u4e86\u521d\u6b65\u8bc4\u4f30\u7814\u7a76\uff0c\u4ee5\u68c0\u67e5\u7cfb\u7edf\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u7cfb\u7edf\u5728\u68c0\u7d22\u9c81\u68d2\u6027\u3001\u5904\u7406\u5b9a\u4e49\u4e0d\u8db3\u7684\u67e5\u8be2\u4ee5\u53ca\u57fa\u4e8e\u4e0d\u4e00\u81f4\u7684\u77e5\u8bc6\u5e93\u8fdb\u884c\u64cd\u4f5c\u65b9\u9762\u5b58\u5728\u7684\u5173\u952e\u9650\u5236\u3002", "conclusion": "\u8fd9\u9879\u6301\u7eed\u7684\u7814\u7a76\u66b4\u9732\u4e86\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u57fa\u7840\u4fe1\u606f\u68c0\u7d22\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u5173\u4e8e\u63d0\u9ad8\u5173\u952e\u516c\u5171\u8d44\u6e90\u8bbf\u95ee\u6027\u7684\u7a33\u5065\u5bf9\u8bdd\u68c0\u7d22\u7814\u7a76\u63d0\u4f9b\u4e86\u52a8\u529b\u3002"}}
{"id": "2602.21247", "categories": ["cs.DB", "cs.DC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.21247", "abs": "https://arxiv.org/abs/2602.21247", "authors": ["Tobias Rubel", "Richard Wen", "Laxman Dhulipala", "Lars Gottesb\u00fcren", "Rajesh Jayaram", "Jakub \u0141\u0105cki"], "title": "PiPNN: Ultra-Scalable Graph-Based Nearest Neighbor Indexing", "comment": null, "summary": "The fastest indexes for Approximate Nearest Neighbor Search today are also the slowest to build: graph-based methods like HNSW and Vamana achieve state-of-the-art query performance but have large construction times due to relying on random-access-heavy beam searches. We introduce PiPNN (Pick-in-Partitions Nearest Neighbors), an ultra-scalable graph construction algorithm that avoids this ``search bottleneck'' that existing graph-based methods suffer from.\n  PiPNN's core innovation is HashPrune, a novel online pruning algorithm which dynamically maintains sparse collections of edges. HashPrune enables PiPNN to partition the dataset into overlapping sub-problems, efficiently perform bulk distance comparisons via dense matrix multiplication kernels, and stream a subset of the edges into HashPrune. HashPrune guarantees bounded memory during index construction which permits PiPNN to build higher quality indices without the use of extra intermediate memory.\n  PiPNN builds state-of-the-art indexes up to 11.6x faster than Vamana (DiskANN) and up to 12.9x faster than HNSW. PiPNN is significantly more scalable than recent algorithms for fast graph construction. PiPNN builds indexes at least 19.1x faster than MIRAGE and 17.3x than FastKCNA while producing indexes that achieve higher query throughput. PiPNN enables us to build, for the first time, high-quality ANN indexes on billion-scale datasets in under 20 minutes using a single multicore machine.", "AI": {"tldr": "PiPNN, a new graph construction algorithm for Approximate Nearest Neighbor Search, significantly reduces the time to build high-quality indexes by using an innovative online pruning method called HashPrune. It outperforms existing methods in terms of speed and scalability.", "motivation": "The motivation behind PiPNN is to address the slow index building times of current state-of-the-art graph-based methods (e.g., HNSW, Vamana) for Approximate Nearest Neighbor Search, which are hampered by their reliance on random-access-heavy beam searches.", "method": "PiPNN introduces HashPrune, an online pruning algorithm that dynamically maintains sparse collections of edges. This allows PiPNN to partition the dataset into overlapping sub-problems, perform bulk distance comparisons efficiently through dense matrix multiplication, and stream a subset of edges into HashPrune, all while ensuring bounded memory usage during index construction.", "result": "PiPNN can build state-of-the-art indexes up to 11.6x faster than Vamana, 12.9x faster than HNSW, 19.1x faster than MIRAGE, and 17.3x faster than FastKCNA. It also achieves higher query throughput and enables the creation of high-quality ANN indexes on billion-scale datasets in under 20 minutes using a single multicore machine.", "conclusion": "By overcoming the 'search bottleneck' and offering superior scalability, PiPNN represents a significant advancement in the field of Approximate Nearest Neighbor Search, enabling faster and more efficient index construction without compromising on quality."}}
{"id": "2602.21626", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21626", "abs": "https://arxiv.org/abs/2602.21626", "authors": ["Yifan Sun", "Gholamreza Haffar", "Minxian Xu", "Rajkumar Buyya", "Adel N. Toosi"], "title": "Multi-Layer Scheduling for MoE-Based LLM Reasoning", "comment": "12 pages, 10 figures", "summary": "Large Language Models (LLMs) have achieved remarkable success across a wide range of tasks, but serving them efficiently at scale remains a critical challenge due to their substantial computational and latency demands. While most existing inference frameworks rely on simple scheduling strategies such as First-Come-First-Serve (FCFS) at the engine level and Round-Robin (RR) at the scheduler or coordinator level, they often fail to fully utilize system resources and may suffer from issues such as head-of-line blocking and load imbalance. Recent advances in Mixture-of-Experts (MoE) models have also introduced new challenges in scheduling arising from expert parallelism and routing complexity. This research proposes a multi-layer scheduling framework tailored for MoE-based LLM serving. It targets scheduling at three levels: request-level, enginelevel, and expert-level. At the request level, we explore algorithms such as Shortest-Job-First (SJF) and priority-aware aging to improve throughput and reduce latency. At the engine level, we design load-aware dispatching strategies that account for the current prefix token load, KV cache utilization, and user stickiness to achieve better resource matching. At the expert level, we focus on alleviating expert hotspots and strategically placing inter-layer expert dependencies to balance load and improve routing efficiency. Extensive experimental results from more than 100 experiments conducted under diverse workload distributions show that our approach consistently outperforms the state-of-theart inference framework vLLM, achieving up to 17.8% reduction in Time To First Token (TTFT) latency and 13.3% reduction in Time-Per-Output-Token (TPOT) latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u591a\u5c42\u6b21\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bf7\u6c42\u7ea7\u3001\u5f15\u64ce\u7ea7\u548c\u4e13\u5bb6\u7ea7\u4e09\u4e2a\u5c42\u6b21\u4e0a\u8fdb\u884c\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9996\u6b21\u751f\u6210\u8bcd\u5143\u7684\u65f6\u95f4\u5ef6\u8fdf\uff08TTFT\uff09\u548c\u6bcf\u8f93\u51fa\u8bcd\u5143\u65f6\u95f4\uff08TPOT\uff09\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u63a8\u7406\u6846\u67b6vLLM\u6709\u660e\u663e\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u56e0\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u4ecd\u9762\u4e34\u6548\u7387\u6311\u6218\u3002\u5f53\u524d\u5e38\u7528\u7684\u63a8\u7406\u6846\u67b6\u4f9d\u8d56\u4e8e\u5982\u5148\u6765\u5148\u670d\u52a1(FCFS)\u7b49\u7b80\u5355\u8c03\u5ea6\u7b56\u7565\uff0c\u8fd9\u5bfc\u81f4\u7cfb\u7edf\u8d44\u6e90\u672a\u80fd\u5145\u5206\u5229\u7528\uff0c\u5e76\u53ef\u80fd\u9047\u5230\u5934\u90e8\u963b\u585e\u548c\u8d1f\u8f7d\u4e0d\u5747\u7b49\u95ee\u9898\u3002\u968f\u7740\u6df7\u5408\u4e13\u5bb6(MoE)\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u8c03\u5ea6\u96be\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u8c03\u5ea6\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e2d\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u57fa\u4e8eMoE\u7684LLM\u670d\u52a1\u8bbe\u8ba1\u7684\u591a\u5c42\u8c03\u5ea6\u6846\u67b6\uff0c\u6db5\u76d6\u8bf7\u6c42\u7ea7\u3001\u5f15\u64ce\u7ea7\u53ca\u4e13\u5bb6\u7ea7\u4e09\u4e2a\u5c42\u9762\uff1a\n1. \u8bf7\u6c42\u7ea7\u522b\uff1a\u91c7\u7528\u6700\u77ed\u4f5c\u4e1a\u4f18\u5148(SJF)\u4e0e\u4f18\u5148\u7ea7\u611f\u77e5\u8001\u5316\u7b97\u6cd5\u4ee5\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u51cf\u5c11\u5ef6\u8fdf\u3002\n2. \u5f15\u64ce\u7ea7\u522b\uff1a\u5f00\u53d1\u4e86\u8003\u8651\u524d\u7f00\u4ee4\u724c\u8d1f\u8f7d\u3001KV\u7f13\u5b58\u5229\u7528\u7387\u4ee5\u53ca\u7528\u6237\u7c98\u6027\u7684\u8d1f\u8f7d\u611f\u77e5\u5206\u53d1\u7b56\u7565\uff0c\u65e8\u5728\u5b9e\u73b0\u66f4\u597d\u7684\u8d44\u6e90\u914d\u7f6e\u3002\n3. \u4e13\u5bb6\u7ea7\u522b\uff1a\u96c6\u4e2d\u4e8e\u7f13\u89e3\u4e13\u5bb6\u70ed\u70b9\u95ee\u9898\u5e76\u901a\u8fc7\u7b56\u7565\u6027\u5730\u653e\u7f6e\u8de8\u5c42\u4e13\u5bb6\u4f9d\u8d56\u5173\u7cfb\u6765\u5e73\u8861\u8d1f\u8f7d\u548c\u63d0\u9ad8\u8def\u7531\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5bf9\u8d85\u8fc7100\u6b21\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u5206\u5e03\u4e0b\u7684\u5b9e\u9a8c\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6846\u67b6vLLM\uff0c\u5728\u9996\u6b21\u751f\u6210\u8bcd\u5143\u7684\u65f6\u95f4\u5ef6\u8fdf(TTFT)\u65b9\u9762\u6700\u591a\u53ef\u964d\u4f4e17.8%\uff0c\u800c\u5728\u6bcf\u8f93\u51fa\u8bcd\u5143\u65f6\u95f4(TPOT)\u5ef6\u8fdf\u65b9\u9762\u5219\u80fd\u591f\u51cf\u5c11\u9ad8\u8fbe13.3%\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u4e13\u95e8\u4e3a\u57fa\u4e8eMoE\u67b6\u6784\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5b9a\u5236\u7684\u591a\u5c42\u7ea7\u8c03\u5ea6\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6548\u63d0\u5347LLM\u670d\u52a1\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u964d\u4f4e\u5ef6\u8fdf\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2602.21600", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.21600", "abs": "https://arxiv.org/abs/2602.21600", "authors": ["Ganap Ashit Tewary", "Nrusinga Charan Gantayat", "Jeff Zhang"], "title": "AQR-HNSW: Accelerating Approximate Nearest Neighbor Search via Density-aware Quantization and Multi-stage Re-ranking", "comment": "Accepted at DAC 2026", "summary": "Approximate Nearest Neighbor (ANN) search has become fundamental to modern AI infrastructure, powering recommendation systems, search engines, and large language models across industry leaders from Google to OpenAI. Hierarchical Navigable Small World (HNSW) graphs have emerged as the dominant ANN algorithm, widely adopted in production systems due to their superior recall versus latency balance. However, as vector databases scale to billions of embeddings, HNSW faces critical bottlenecks: memory consumption expands, distance computation overhead dominates query latency, and it suffers suboptimal performance on heterogeneous data distributions. This paper presents Adaptive Quantization and Rerank HNSW (AQR-HNSW), a novel framework that synergistically integrates three strategies to enhance HNSW scalability. AQR-HNSW introduces (1) density-aware adaptive quantization, achieving 4x compression while preserving distance relationships; (2) multi-state re-ranking that reduces unnecessary computations by 35%; and (3) quantization-optimized SIMD implementations delivering 16-64 operations per cycle across architectures. Evaluation on standard benchmarks demonstrates 2.5-3.3x higher queries per second (QPS) than state-of-the-art HNSW implementations while maintaining over 98% recall, with 75% memory reduction for the index graph and 5x faster index construction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6AQR-HNSW\uff0c\u901a\u8fc7\u96c6\u6210\u4e09\u79cd\u7b56\u7565\u6765\u63d0\u9ad8HNSW\u7b97\u6cd5\u5728\u5927\u89c4\u6a21\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u5bc6\u5ea6\u611f\u77e5\u81ea\u9002\u5e94\u91cf\u5316\u3001\u591a\u72b6\u6001\u91cd\u6392\u4ee5\u53ca\u9488\u5bf9SIMD\u4f18\u5316\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4ece\u800c\u5927\u5e45\u63d0\u9ad8\u4e86\u67e5\u8be2\u6027\u80fd\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5411\u91cf\u6570\u636e\u5e93\u589e\u957f\u81f3\u6570\u5341\u4ebf\u7ea7\u522b\u7684\u5d4c\u5165\u5411\u91cf\uff0c\u73b0\u6709\u7684\u4e3b\u5bfc\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7b97\u6cd5HNSW\u9762\u4e34\u5185\u5b58\u6d88\u8017\u5927\u3001\u8ddd\u79bb\u8ba1\u7b97\u5f00\u9500\u9ad8\u4ee5\u53ca\u5bf9\u5f02\u6784\u6570\u636e\u5206\u5e03\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u74f6\u9888\u5e76\u63d0\u9ad8HNSW\u7684\u53ef\u6269\u5c55\u6027\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u5bc6\u5ea6\u611f\u77e5\u81ea\u9002\u5e94\u91cf\u5316\uff1a\u8fbe\u52304\u500d\u538b\u7f29\u540c\u65f6\u4fdd\u6301\u8ddd\u79bb\u5173\u7cfb\u3002\n2. \u591a\u72b6\u6001\u91cd\u6392\u6280\u672f\uff1a\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u8fbe35%\u3002\n3. \u9488\u5bf9SIMD\u4f18\u5316\u7684\u5b9e\u73b0\uff1a\u8de8\u67b6\u6784\u6bcf\u5468\u671f\u6267\u884c16\u523064\u6b21\u64cd\u4f5c\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684HNSW\u5b9e\u73b0\u76f8\u6bd4\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e862.5\u52303.3\u500d\u66f4\u9ad8\u7684\u6bcf\u79d2\u67e5\u8be2\u6b21\u6570\uff08QPS\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u8fc798%\u7684\u53ec\u56de\u7387\uff0c\u7d22\u5f15\u56fe\u7684\u5185\u5b58\u51cf\u5c11\u4e8675%\uff0c\u5e76\u4e14\u7d22\u5f15\u6784\u5efa\u901f\u5ea6\u52a0\u5feb\u4e865\u500d\u3002", "conclusion": "AQR-HNSW\u6846\u67b6\u6210\u529f\u5730\u89e3\u51b3\u4e86HNSW\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u9047\u5230\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5305\u62ec\u5185\u5b58\u4f7f\u7528\u3001\u8ba1\u7b97\u6548\u7387\u53ca\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u6570\u636e\u7684\u80fd\u529b\uff0c\u4e3a\u5de5\u4e1a\u754c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684ANN\u641c\u7d22\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21641", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21641", "abs": "https://arxiv.org/abs/2602.21641", "authors": ["Man Zhang", "Yunyang Li", "Tao Yue"], "title": "Uncertainty Modeling for SysML v2", "comment": null, "summary": "Uncertainty is inherent in modern engineered systems, including cyber-physical systems, autonomous systems, and large-scale software-intensive infrastructures (such as microservice-based systems) operating in dynamic and partially observable environments. The recent publication of Precise Semantics for Uncertainty Modeling (PSUM) by the Object Management Group represents the first standardized specification for uncertainty modeling within the Model-Based Systems Engineering (MBSE) community, providing formally defined semantics for representing and reasoning about uncertainty in models. In parallel, the second version of Systems Modeling Language (SysML v2) was released as the next-generation systems modeling language, offering improved semantic rigor and reusability, yet lacking native constructs aligned with PSUM for first-class uncertainty representation. This paper proposes a systematic extension of SysML v2 that incorporates the PSUM metamodel into its modeling framework. The extension enables explicit specification of indeterminacy sources, structured characterization of uncertainties, and consistent propagation of uncertainty within system models, while preserving conformance with SysML v2 syntax and semantics. We validate the approach through seven case studies. Results demonstrate that the proposed extension (PSUM-SysMLv2) is expressive and applicable for uncertainty-aware MBSE, and potentially enables uncertainty and uncertainty propagation analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06PSUM\u5143\u6a21\u578b\u7cfb\u7edf\u5730\u96c6\u6210\u5230SysML v2\u5efa\u6a21\u6846\u67b6\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u8868\u793a\u548c\u4f20\u64ad\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eSysML v2\u8bed\u6cd5\u548c\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u4e03\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u4ee3\u5de5\u7a0b\u7cfb\u7edf\u4e2d\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u9700\u8981\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5de5\u7a0b\uff08MBSE\uff09\u4e2d\u5f97\u5230\u9002\u5f53\u7684\u5904\u7406\u3002\u5c3d\u7ba1OMG\u6700\u8fd1\u53d1\u5e03\u4e86\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u7684\u6807\u51c6\u89c4\u8303PSUM\uff0c\u5e76\u4e14SysML v2\u4f5c\u4e3a\u65b0\u4e00\u4ee3\u7cfb\u7edf\u5efa\u6a21\u8bed\u8a00\u4e5f\u5df2\u53d1\u5e03\uff0c\u4f46\u540e\u8005\u7f3a\u4e4f\u4e0ePSUM\u4e00\u81f4\u7684\u539f\u751f\u6784\u9020\u6765\u76f4\u63a5\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u6587\u7ae0\u5efa\u8bae\u5bf9SysML v2\u8fdb\u884c\u7cfb\u7edf\u6269\u5c55\uff0c\u4ee5\u4fbf\u5c06PSUM\u5143\u6a21\u578b\u7eb3\u5165\u5176\u4e2d\uff0c\u4ece\u800c\u5141\u8bb8\u660e\u786e\u6307\u5b9a\u4e0d\u786e\u5b9a\u6027\u7684\u6765\u6e90\u3001\u7ed3\u6784\u5316\u63cf\u8ff0\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u5728\u7cfb\u7edf\u6a21\u578b\u5185\u4e00\u81f4\u5730\u4f20\u64ad\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u4e03\u9879\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6269\u5c55(PSUM-SysMLv2)\u5177\u6709\u8868\u8fbe\u529b\u5e76\u4e14\u9002\u7528\u4e8e\u5173\u6ce8\u4e0d\u786e\u5b9a\u6027\u7684MBSE\uff0c\u5e76\u53ef\u80fd\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u53ca\u5176\u4f20\u64ad\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u7684SysML v2\u6269\u5c55\u80fd\u591f\u6709\u6548\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u4e3a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684MBSE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2602.21248", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21248", "abs": "https://arxiv.org/abs/2602.21248", "authors": ["Linus Baumg\u00e4rtner", "Adil Chhabra", "Marcelo Fonseca Faraj", "Christian Schulz"], "title": "BuffCut: Prioritized Buffered Streaming Graph Partitioning", "comment": null, "summary": "Streaming graph partitioners enable resource-efficient and massively scalable partitioning, but one-pass assignment heuristics are highly sensitive to stream order and often yield substantially higher edge cuts than in-memory methods. We present BuffCut, a buffered streaming partitioner that narrows this quality gap, particularly when stream ordering is adversarial, by combining prioritized buffering with batch-wise multilevel assignment. BuffCut maintains a bounded priority buffer to delay poorly informed decisions and regulate the order in which nodes are considered for assignment. It incrementally constructs high-locality batches of configurable size by iteratively inserting the highest-priority nodes from the buffer into the batch, effectively recovering locality structure from the stream. Each batch is then assigned via a multilevel partitioning algorithm. Experiments on diverse real-world and synthetic graphs show that BuffCut consistently outperforms state-of-the-art buffered streaming methods. Compared to the strongest prioritized buffering baseline, BuffCut achieves 20.8% fewer edge cuts while running 2.9 times faster and using 11.3 times less memory. Against the next-best buffered method, it reduces edge cut by 15.8% with only modest overheads of 1.8 times runtime and 1.09 times memory.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBuffCut\u7684\u65b0\u578b\u7f13\u51b2\u6d41\u5f0f\u56fe\u5206\u5272\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4f18\u5148\u7ea7\u7f13\u51b2\u4e0e\u6279\u91cf\u591a\u7ea7\u5206\u914d\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8d44\u6e90\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u5bf9\u6297\u6027\u6d41\u987a\u5e8f\u4e0b\u7684\u5206\u5272\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u6d41\u5f0f\u56fe\u5206\u5272\u7b97\u6cd5\u867d\u7136\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u65f6\u5177\u6709\u5f88\u9ad8\u7684\u8d44\u6e90\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5176\u5bf9\u4e8e\u6570\u636e\u6d41\u987a\u5e8f\u975e\u5e38\u654f\u611f\uff0c\u5bfc\u81f4\u8fb9\u7f18\u5207\u5272\u6570\u91cf\u5f80\u5f80\u9ad8\u4e8e\u5185\u5b58\u4e2d\u7684\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u7f29\u5c0f\u8fd9\u79cd\u8d28\u91cf\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5229\u7684\u6d41\u987a\u5e8f\u4e0b\u3002", "method": "BuffCut\u7b97\u6cd5\u901a\u8fc7\u7ef4\u62a4\u4e00\u4e2a\u6709\u754c\u7684\u4f18\u5148\u7ea7\u7f13\u51b2\u533a\u5ef6\u8fdf\u4f4e\u6548\u51b3\u7b56\uff0c\u5e76\u8c03\u8282\u8282\u70b9\u5206\u914d\u7684\u987a\u5e8f\uff1b\u540c\u65f6\uff0c\u5b83\u901a\u8fc7\u8fed\u4ee3\u5730\u5c06\u6700\u9ad8\u4f18\u5148\u7ea7\u7684\u8282\u70b9\u4ece\u7f13\u51b2\u533a\u63d2\u5165\u5230\u6279\u6b21\u4e2d\uff0c\u9010\u6b65\u6784\u5efa\u5177\u6709\u9ad8\u5c40\u90e8\u6027\u7684\u6279\u6b21\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u6279\u6b21\u91c7\u7528\u591a\u7ea7\u5206\u914d\u7b97\u6cd5\u8fdb\u884c\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65e0\u8bba\u662f\u5728\u771f\u5b9e\u4e16\u754c\u8fd8\u662f\u5408\u6210\u56fe\u4e0a\uff0cBuffCut\u7684\u8868\u73b0\u90fd\u4f18\u4e8e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u7f13\u51b2\u6d41\u5f0f\u65b9\u6cd5\u3002\u76f8\u8f83\u4e8e\u6700\u5f3a\u7684\u57fa\u4e8e\u4f18\u5148\u7ea7\u7f13\u51b2\u57fa\u7ebf\u65b9\u6cd5\uff0cBuffCut\u5b9e\u73b0\u4e8620.8%\u7684\u66f4\u5c11\u8fb9\u7f18\u5207\u5272\uff0c\u8fd0\u884c\u901f\u5ea6\u63d0\u9ad8\u4e862.9\u500d\uff0c\u4f7f\u7528\u7684\u5185\u5b58\u51cf\u5c11\u4e8611.3\u500d\u3002\u76f8\u6bd4\u6b21\u4f18\u7f13\u51b2\u65b9\u6cd5\uff0c\u5b83\u5728\u4ec5\u589e\u52a01.8\u500d\u8fd0\u884c\u65f6\u95f4\u548c1.09\u500d\u5185\u5b58\u6d88\u8017\u7684\u60c5\u51b5\u4e0b\uff0c\u51cf\u5c11\u4e8615.8%\u7684\u8fb9\u7f18\u5207\u5272\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5165\u4f18\u5148\u7ea7\u7f13\u51b2\u673a\u5236\u548c\u6279\u91cf\u591a\u7ea7\u5206\u914d\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6d41\u5f0f\u56fe\u5206\u5272\u7684\u8d28\u91cf\uff0c\u5373\u4f7f\u9762\u5bf9\u4e0d\u5229\u7684\u6570\u636e\u6d41\u987a\u5e8f\u4e5f\u80fd\u6709\u6548\u964d\u4f4e\u8fb9\u7f18\u5207\u5272\u7684\u6570\u91cf\u3002"}}
{"id": "2602.21233", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21233", "abs": "https://arxiv.org/abs/2602.21233", "authors": ["Rui Cen", "QiangQiang Hu", "Hong Huang", "Hong Liu", "Song Liu", "Xin Luo", "Lin Niu", "Yifan Tan", "Decheng Wu", "Linchuan Xie", "Rubing Yang", "Guanghua Yu", "Jianchen Zhu"], "title": "AngelSlim: A more accessible, comprehensive, and efficient toolkit for large model compression", "comment": null, "summary": "This technical report introduces AngelSlim, a comprehensive and versatile toolkit for large model compression developed by the Tencent Hunyuan team. By consolidating cutting-edge algorithms, including quantization, speculative decoding, token pruning, and distillation. AngelSlim provides a unified pipeline that streamlines the transition from model compression to industrial-scale deployment. To facilitate efficient acceleration, we integrate state-of-the-art FP8 and INT8 Post-Training Quantization (PTQ) algorithms alongside pioneering research in ultra-low-bit regimes, featuring HY-1.8B-int2 as the first industrially viable 2-bit large model. Beyond quantization, we propose a training-aligned speculative decoding framework compatible with multimodal architectures and modern inference engines, achieving 1.8x to 2.0x throughput gains without compromising output correctness. Furthermore, we develop a training-free sparse attention framework that reduces Time-to-First-Token (TTFT) in long-context scenarios by decoupling sparse kernels from model architectures through a hybrid of static patterns and dynamic token selection. For multimodal models, AngelSlim incorporates specialized pruning strategies, namely IDPruner for optimizing vision tokens via Maximal Marginal Relevance and Samp for adaptive audio token merging and pruning. By integrating these compression strategies from low-level implementations, AngelSlim enables algorithm-focused research and tool-assisted deployment.", "AI": {"tldr": "AngelSlim\u662f\u4e00\u4e2a\u7531\u817e\u8baf\u6df7\u5143\u56e2\u961f\u5f00\u53d1\u7684\u5927\u6a21\u578b\u538b\u7f29\u5de5\u5177\u5305\uff0c\u6574\u5408\u4e86\u91cf\u5316\u3001\u63a8\u6d4b\u89e3\u7801\u3001\u4ee4\u724c\u4fee\u526a\u548c\u84b8\u998f\u7b49\u5148\u8fdb\u6280\u672f\uff0c\u63d0\u4f9b\u4e86\u4ece\u6a21\u578b\u538b\u7f29\u5230\u5de5\u4e1a\u89c4\u6a21\u90e8\u7f72\u7684\u7edf\u4e00\u7ba1\u9053\u3002", "motivation": "\u4e3a\u4e86\u7b80\u5316\u5927\u578b\u6a21\u578b\u4ece\u538b\u7f29\u5230\u5de5\u4e1a\u7ea7\u90e8\u7f72\u7684\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u9ad8\u6548\u52a0\u901f\uff0c\u817e\u8baf\u6df7\u5143\u56e2\u961f\u5f00\u53d1\u4e86AngelSlim\u8fd9\u4e00\u5168\u9762\u4e14\u591a\u529f\u80fd\u7684\u5de5\u5177\u5305\u3002", "method": "AngelSlim\u901a\u8fc7\u7ed3\u5408\u91cf\u5316\uff08\u5305\u62ecFP8\u548cINT8\u540e\u8bad\u7ec3\u91cf\u5316\uff09\u3001\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u7a00\u758f\u6ce8\u610f\u529b\u6846\u67b6\u4ee5\u53ca\u9488\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u7684\u4e13\u4e1a\u4fee\u526a\u7b56\u7565\u6765\u5b9e\u73b0\u5176\u529f\u80fd\u3002", "result": "\u8be5\u5de5\u5177\u5305\u80fd\u591f\u5728\u4e0d\u727a\u7272\u8f93\u51fa\u6b63\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad81.8\u81f32.0\u500d\u541e\u5410\u91cf\uff1b\u51cf\u5c11\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u7684\u9996\u6b21\u4ee4\u724c\u65f6\u95f4\uff1b\u5e76\u4e14\u5bf9\u4e8e\u89c6\u89c9\u548c\u97f3\u9891\u4ee4\u724c\u4f18\u5316\u5177\u6709\u7279\u522b\u8bbe\u8ba1\u7684\u65b9\u6cd5\u3002", "conclusion": "AngelSlim\u901a\u8fc7\u4f4e\u7ea7\u522b\u5b9e\u73b0\u6574\u5408\u8fd9\u4e9b\u538b\u7f29\u7b56\u7565\uff0c\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u80fd\u591f\u4e13\u6ce8\u4e8e\u7b97\u6cd5\u7814\u7a76\uff0c\u5e76\u652f\u6301\u501f\u52a9\u5de5\u5177\u8f85\u52a9\u8fdb\u884c\u90e8\u7f72\u3002"}}
{"id": "2602.21730", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21730", "abs": "https://arxiv.org/abs/2602.21730", "authors": ["Paul Borrill"], "title": "Lamport's Arrow of Time: The Category Mistake in Logical Clocks", "comment": "14 pages, 32 references", "summary": "Lamport's 1978 paper introduced the happens-before relation and logical clocks, freeing distributed systems from dependence on synchronized physical clocks. This is widely understood as a move away from Newtonian absolute time. We argue that Lamport's formalism retains a deeper and largely unexamined assumption: that causality induces a globally well-defined directed acyclic graph (DAG) over events -- a forward-in-time-only (FITO) structure that functions as an arrow of time embedded at the semantic level. Following Ryle's analysis of category mistakes, we show that this assumption conflates an epistemic construct (the logical ordering of messages) with an ontic claim (that physical causality is globally acyclic and monotonic). We trace this conflation through Shannon's channel model, TLA+, Bell's theorem, and the impossibility results of Fischer-Lynch-Paterson and Brewer's CAP theorem. We then show that special and general relativity permit only local causal structure, and that recent work on indefinite causal order demonstrates that nature admits correlations with no well-defined causal ordering. We propose that mutual information conservation, rather than temporal precedence, provides a more fundamental primitive for distributed consistency.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86Lamport 1978\u5e74\u8bba\u6587\u4e2d\u5173\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u903b\u8f91\u65f6\u949f\u548chappens-before\u5173\u7cfb\u7684\u5047\u8bbe\uff0c\u6307\u51fa\u4e86\u5176\u6f5c\u5728\u5730\u5047\u5b9a\u4e86\u56e0\u679c\u5173\u7cfb\u5f62\u6210\u4e86\u5168\u5c40\u5b9a\u4e49\u826f\u597d\u7684\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u3002\u6587\u7ae0\u901a\u8fc7\u4e0d\u540c\u7406\u8bba\u5206\u6790\u4e86\u8fd9\u4e00\u5047\u8bbe\u6df7\u6dc6\u4e86\u8ba4\u8bc6\u8bba\u6784\u9020\u4e0e\u672c\u4f53\u8bba\u4e3b\u5f20\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u4e92\u4fe1\u606f\u5b88\u6052\u800c\u975e\u65f6\u95f4\u4f18\u5148\u7ea7\u4f5c\u4e3a\u5206\u5e03\u5f0f\u4e00\u81f4\u6027\u66f4\u57fa\u7840\u7684\u6982\u5ff5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63ed\u793aLamport\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u6a21\u578b\u4e2d\u9690\u85cf\u7684\u6df1\u5c42\u5047\u8bbe\uff0c\u5373\u8ba4\u4e3a\u56e0\u679c\u6027\u5bfc\u81f4\u4e86\u4e00\u4e2a\u5168\u5c40\u5b9a\u4e49\u826f\u597d\u4e14\u4ec5\u5411\u524d\u53d1\u5c55\u7684\u7ed3\u6784\uff0c\u8fd9\u5b9e\u9645\u4e0a\u6df7\u6dc6\u4e86\u903b\u8f91\u6d88\u606f\u6392\u5e8f\u7684\u8ba4\u8bc6\u8bba\u6784\u5efa\u4e0e\u7269\u7406\u56e0\u679c\u6027\u7684\u672c\u4f53\u8bba\u58f0\u660e\u3002", "method": "\u901a\u8fc7\u5bf9Ryle\u7684\u8303\u7574\u9519\u8bef\u5206\u6790\u3001Shannon\u7684\u4fe1\u9053\u6a21\u578b\u3001TLA+\u3001Bell\u5b9a\u7406\u4ee5\u53caFischer-Lynch-Paterson\u548cBrewer CAP\u5b9a\u7406\u7684\u7814\u7a76\uff0c\u6587\u7ae0\u5c55\u793a\u4e86\u8fd9\u79cd\u6df7\u6dc6\u5982\u4f55\u8d2f\u7a7f\u4e8e\u8fd9\u4e9b\u91cd\u8981\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u4e0e\u7269\u7406\u5b66\u7406\u8bba\u4e4b\u4e2d\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u7279\u6b8a\u76f8\u5bf9\u8bba\u548c\u5e7f\u4e49\u76f8\u5bf9\u8bba\u53ea\u5141\u8bb8\u5c40\u90e8\u56e0\u679c\u7ed3\u6784\u7684\u5b58\u5728\uff0c\u800c\u6700\u8fd1\u5173\u4e8e\u4e0d\u786e\u5b9a\u56e0\u679c\u987a\u5e8f\u7684\u5de5\u4f5c\u8868\u660e\u81ea\u7136\u5141\u8bb8\u6ca1\u6709\u660e\u786e\u56e0\u679c\u987a\u5e8f\u7684\u76f8\u5173\u6027\u3002\u56e0\u6b64\uff0c\u6587\u7ae0\u5efa\u8bae\u4f7f\u7528\u4e92\u4fe1\u606f\u5b88\u6052\u6765\u66ff\u4ee3\u4f20\u7edf\u7684\u65f6\u95f4\u4f18\u5148\u7ea7\u6982\u5ff5\u4ee5\u4f5c\u4e3a\u5206\u5e03\u5f0f\u4e00\u81f4\u6027\u7684\u57fa\u7840\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u4e8b\u4ef6\u4e00\u81f4\u6027\uff0c\u9700\u8981\u4ece\u4f9d\u8d56\u4e8e\u7edd\u5bf9\u56e0\u679c\u5e8f\u8f6c\u5411\u8003\u8651\u66f4\u52a0\u57fa\u7840\u7684\u4fe1\u606f\u5b88\u6052\u539f\u5219\u3002"}}
{"id": "2602.21677", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21677", "abs": "https://arxiv.org/abs/2602.21677", "authors": ["Zhenxiang Xu", "Jiawei Chen", "Sirui Chen", "Yong He", "Jieyu Yang", "Chuan Yuan", "Ke Ding", "Can Wang"], "title": "Trie-Aware Transformers for Generative Recommendation", "comment": null, "summary": "Generative recommendation (GR) aligns with advances in generative AI by casting next-item prediction as token-level generation rather than score-based ranking. Most GR methods adopt a two-stage pipeline: (i) \\textit{item tokenization}, which maps each item to a sequence of discrete, hierarchically organized tokens; and (ii) \\textit{autoregressive generation}, which predicts the next item's tokens conditioned on the tokens of user's interaction history. Although hierarchical tokenization induces a prefix tree (trie) over items, standard autoregressive modeling with conventional Transformers often flattens item tokens into a linear stream and overlooks the underlying topology.\n  To address this, we propose TrieRec, a trie-aware generative recommendation method that augments Transformers with structural inductive biases via two positional encodings. First, a \\textit{trie-aware absolute positional encoding} aggregates a token's (node's) local structural context (\\eg depth, ancestors, and descendants) into the token representation. Second, a \\textit{topology-aware relative positional encoding} injects pairwise structural relations into self-attention to capture topology-induced semantic relatedness. TrieRec is also model-agnostic, efficient, and hyperparameter-free. In our experiments, we implement TrieRec within three representative GR backbones, achieving notably improvements of 8.83\\% on average across four real-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5TrieRec\uff0c\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u4f4d\u7f6e\u7f16\u7801\u6765\u589e\u5f3aTransformer\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u9879\u76ee\u4ee4\u724c\u7684\u5c42\u7ea7\u7ed3\u6784\u4fe1\u606f\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e868.83%\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u5728\u5904\u7406\u9879\u76ee\u4ee4\u724c\u65f6\uff0c\u901a\u5e38\u4f1a\u5ffd\u7565\u5176\u80cc\u540e\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u800c\u53ea\u662f\u7b80\u5355\u5730\u5c06\u8fd9\u4e9b\u4ee4\u724c\u7ebf\u6027\u5316\u5904\u7406\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86TrieRec\uff0c\u4e00\u79cd\u80fd\u591f\u7406\u89e3\u5e76\u5229\u7528\u8fd9\u79cd\u5c42\u7ea7\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "TrieRec\u901a\u8fc7\u5411Transformer\u6dfb\u52a0\u7ed3\u6784\u6027\u5f52\u7eb3\u504f\u7f6e\u6765\u5b9e\u73b0\uff0c\u4e3b\u8981\u901a\u8fc7\u4e24\u79cd\u4f4d\u7f6e\u7f16\u7801\uff1a1\uff09trie\u611f\u77e5\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u5b83\u5c06\u4ee4\u724c\uff08\u8282\u70b9\uff09\u7684\u5c40\u90e8\u7ed3\u6784\u4e0a\u4e0b\u6587\u6574\u5408\u5230\u4ee4\u724c\u8868\u793a\u4e2d\uff1b2\uff09\u62d3\u6251\u611f\u77e5\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u5b83\u5411\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6ce8\u5165\u6210\u5bf9\u7ed3\u6784\u5173\u7cfb\u4ee5\u6355\u83b7\u7531\u62d3\u6251\u5f15\u8d77\u8bed\u4e49\u76f8\u5173\u6027\u3002", "result": "\u7814\u7a76\u8005\u4eec\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\u5185\u5b9e\u73b0\u4e86TrieRec\uff0c\u5e76\u5728\u56db\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\uff0cTrieRec\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\u4e0b\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u5e73\u5747\u6539\u5584\u4e868.83%\u3002", "conclusion": "TrieRec\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u751f\u6210\u5f0f\u63a8\u8350\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u5c06\u9879\u76ee\u7684\u5c42\u7ea7\u7ed3\u6784\u878d\u5165\u5230\u4e86\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u800c\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u5177\u6709\u6a21\u578b\u65e0\u5173\u3001\u9ad8\u6548\u53ca\u65e0\u9700\u989d\u5916\u8d85\u53c2\u6570\u8c03\u6574\u7684\u4f18\u70b9\u3002"}}
{"id": "2602.21249", "categories": ["cs.DB", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.21249", "abs": "https://arxiv.org/abs/2602.21249", "authors": ["Markus Matoni", "Arno Kesper", "Gabriele Taentzer"], "title": "Quality of Descriptive Information on Cultural Heritage Objects: Definition and Empirical Evaluation", "comment": "preprint", "summary": "Effective data processing depends on the quality of the underlying data. However, quality issues such as inconsistencies and uncertainties, can significantly impede the processing and subsequent use of data. Despite the centrality of data quality to a wide range of computational tasks, there is currently no broadly accepted, domain-independent consensus on the definition of data quality. Existing frameworks primarily define data quality in ways that are tailored to specific domains, data types, or contexts of use. Although quality assessment frameworks exist for specific domains, such as electronic health record data and linked data, corresponding approaches for descriptive information about cultural heritage objects remain underdeveloped. Moreover, existing quality definitions are often theoretical in nature and lack empirical validation based on real-world data problems. In this paper, we address these limitations by first defining a set of quality dimensions specifically designed to capture the characteristics of descriptive information about cultural heritage objects. Our definition is based on an in-depth analysis of existing dimensions and is illustrated through domain-specific examples. We then evaluate the practical applicability of our proposed quality definition using a curated set of real-world data quality problems from the cultural heritage domain. This empirical evaluation substantiates our definition of data quality, resulting in a comprehensive definition of data quality in this domain.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6587\u5316\u9057\u4ea7\u5bf9\u8c61\u63cf\u8ff0\u4fe1\u606f\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u5b9a\u4e49\u4e86\u4e00\u7ec4\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5b9a\u4e49\u7684\u6709\u6548\u6027\uff0c\u4ece\u800c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6570\u636e\u8d28\u91cf\u5b9a\u4e49\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5e7f\u6cdb\u63a5\u53d7\u7684\u3001\u72ec\u7acb\u4e8e\u9886\u57df\u7684\u6570\u636e\u8d28\u91cf\u5b9a\u4e49\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u6587\u5316\u9057\u4ea7\u5bf9\u8c61\u63cf\u8ff0\u4fe1\u606f\u7684\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\u5c1a\u4e0d\u5b8c\u5584\u3002\u73b0\u6709\u7684\u8d28\u91cf\u5b9a\u4e49\u5f80\u5f80\u8fc7\u4e8e\u7406\u8bba\u5316\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u5b9e\u9645\u6570\u636e\u95ee\u9898\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "method": "\u9996\u5148\uff0c\u57fa\u4e8e\u5bf9\u73b0\u6709\u7ef4\u5ea6\u7684\u6df1\u5165\u5206\u6790\uff0c\u5b9a\u4e49\u4e86\u4e00\u7ec4\u4e13\u95e8\u7528\u4e8e\u6355\u6349\u6587\u5316\u9057\u4ea7\u5bf9\u8c61\u63cf\u8ff0\u4fe1\u606f\u7279\u5f81\u7684\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u7684\u4f8b\u5b50\u52a0\u4ee5\u8bf4\u660e\u3002\u7136\u540e\uff0c\u4f7f\u7528\u4ece\u6587\u5316\u9057\u4ea7\u9886\u57df\u6536\u96c6\u7684\u4e00\u7cfb\u5217\u5b9e\u9645\u6570\u636e\u8d28\u91cf\u95ee\u9898\u6765\u8bc4\u4f30\u6240\u63d0\u51fa\u8d28\u91cf\u5b9a\u4e49\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u652f\u6301\u4e86\u63d0\u51fa\u7684\u8d28\u91cf\u5b9a\u4e49\uff0c\u4e3a\u6587\u5316\u9057\u4ea7\u9886\u57df\u7684\u63cf\u8ff0\u4fe1\u606f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u4e14\u5b9e\u7528\u7684\u6570\u636e\u8d28\u91cf\u5b9a\u4e49\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u6587\u5316\u9057\u4ea7\u5bf9\u8c61\u63cf\u8ff0\u4fe1\u606f\u7684\u6570\u636e\u8d28\u91cf\u5b9a\u4e49\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u586b\u8865\u4e86\u8fd9\u4e00\u9886\u57df\u5185\u6570\u636e\u8d28\u91cf\u7ba1\u7406\u4e0a\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.21269", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21269", "abs": "https://arxiv.org/abs/2602.21269", "authors": ["Wang Zixian"], "title": "Group Orthogonalized Policy Optimization:Group Policy Optimization as Orthogonal Projection in Hilbert Space", "comment": null, "summary": "We present Group Orthogonalized Policy Optimization (GOPO), a new alignment algorithm for large language models derived from the geometry of Hilbert function spaces. Instead of optimizing on the probability simplex and inheriting the exponential curvature of Kullback-Leibler divergence, GOPO lifts alignment into the Hilbert space L2(pi_k) of square-integrable functions with respect to the reference policy. Within this space, the simplex constraint reduces to a linear orthogonality condition <v, 1> = 0, defining a codimension-one subspace H0. Minimizing distance to an unconstrained target u_star yields the work-dissipation functional J(v) = <g, v> - (mu / 2) ||v||^2, whose maximizer follows directly from the Hilbert projection theorem. Enforcing the boundary v >= -1 produces a bounded Hilbert projection that induces exact sparsity, assigning zero probability to catastrophically poor actions through a closed-form threshold. To connect this functional theory with practice, GOPO projects from infinite-dimensional L2(pi_k) to a finite empirical subspace induced by group sampling. Because group-normalized advantages sum to zero, the Lagrange multiplier enforcing probability conservation vanishes exactly, reducing the constrained projection to an unconstrained empirical loss. The resulting objective has constant Hessian curvature mu I, non-saturating linear gradients, and an intrinsic dead-zone mechanism without heuristic clipping. Experiments on mathematical reasoning benchmarks show that GOPO achieves competitive generalization while maintaining stable gradient dynamics and entropy preservation in regimes where clipping-based methods plateau.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7b97\u6cd5\u2014\u2014\u7ec4\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\uff08GOPO\uff09\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8eHilbert\u51fd\u6570\u7a7a\u95f4\u7684\u51e0\u4f55\u5b66\u3002\u901a\u8fc7\u5c06\u5bf9\u9f50\u95ee\u9898\u63d0\u5347\u5230Hilbert\u7a7a\u95f4L2(pi_k)\u4e2d\uff0cGOPO\u907f\u514d\u4e86\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u7684\u4f18\u5316\u4ee5\u53caKullback-Leibler\u6563\u5ea6\u5e26\u6765\u7684\u6307\u6570\u66f2\u7387\u95ee\u9898\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cGOPO\u4ece\u65e0\u9650\u7ef4L2(pi_k)\u6295\u5f71\u5230\u7531\u7fa4\u4f53\u91c7\u6837\u8bf1\u5bfc\u7684\u6709\u9650\u7ecf\u9a8c\u5b50\u7a7a\u95f4\uff0c\u5e76\u4e14\u7531\u4e8e\u7fa4\u5f52\u4e00\u5316\u4f18\u52bf\u603b\u548c\u4e3a\u96f6\uff0c\u5f3a\u5236\u6982\u7387\u5b88\u6052\u7684\u62c9\u683c\u6717\u65e5\u4e58\u6570\u6070\u597d\u6d88\u5931\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u7ea6\u675f\u6295\u5f71\u4e3a\u65e0\u7ea6\u675f\u7684\u7ecf\u9a8c\u635f\u5931\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGOPO\u4fdd\u6301\u4e86\u7a33\u5b9a\u7684\u68af\u5ea6\u52a8\u6001\u548c\u71b5\u4fdd\u7559\u7684\u540c\u65f6\u8fbe\u5230\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u5bf9\u9f50\u7b97\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u9047\u5230\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u4f7f\u7528\u4f20\u7edf\u7684\u57fa\u4e8e\u6982\u7387\u5355\u7eaf\u5f62\u7684\u65b9\u6cd5\u8fdb\u884c\u4f18\u5316\u65f6\uff0c\u4f1a\u906d\u9047\u7531\u4e8eKullback-Leibler\u6563\u5ea6\u5bfc\u81f4\u7684\u9ad8\u66f2\u7387\u95ee\u9898\u3002GOPO\u901a\u8fc7\u5c06\u5bf9\u9f50\u8fc7\u7a0b\u7f6e\u4e8eHilbert\u7a7a\u95f4\u5185\u6267\u884c\uff0c\u4ee5\u671f\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u7ec4\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\uff08Group Orthogonalized Policy Optimization, GOPO\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528Hilbert\u7a7a\u95f4L2(pi_k)\u4e2d\u7684\u7ebf\u6027\u6b63\u4ea4\u6761\u4ef6\u4ee3\u66ff\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u5355\u7eaf\u5f62\u7ea6\u675f\u3002\u901a\u8fc7\u5bf9\u76ee\u6807\u51fd\u6570\u65bd\u52a0\u8fb9\u754cv >= -1\u7684\u9650\u5236\uff0c\u4f7f\u5f97\u6295\u5f71\u7ed3\u679c\u81ea\u7136\u5730\u4ea7\u751f\u7a00\u758f\u6027\uff0c\u4ece\u800c\u80fd\u591f\u81ea\u52a8\u6392\u9664\u707e\u96be\u6027\u5dee\u7684\u52a8\u4f5c\u3002\u6b64\u5916\uff0cGOPO\u8fd8\u901a\u8fc7\u5c06\u65e0\u9650\u7ef4\u7a7a\u95f4\u6620\u5c04\u81f3\u6709\u9650\u7ecf\u9a8c\u5b50\u7a7a\u95f4\u6765\u5b9e\u73b0\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u6570\u5b66\u63a8\u7406\u76f8\u5173\u4efb\u52a1\u4e0a\uff0c\u76f8\u6bd4\u4e8e\u4f9d\u8d56\u4e8e\u88c1\u526a\u6280\u672f\u7684\u4f20\u7edf\u65b9\u6cd5\uff0cGOPO\u4e0d\u4ec5\u80fd\u591f\u5728\u4fdd\u6301\u7a33\u5b9a\u68af\u5ea6\u52a8\u6001\u548c\u71b5\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u4e14\u8fd8\u80fd\u6709\u6548\u907f\u514d\u540e\u8005\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u51fa\u73b0\u7684\u8868\u73b0\u505c\u6ede\u73b0\u8c61\u3002", "conclusion": "\u7ec4\u6b63\u4ea4\u5316\u7b56\u7565\u4f18\u5316\uff08GOPO\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u521b\u65b0\u6027\u7684\u89c6\u89d2\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5bf9\u9f50\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165Hilbert\u7a7a\u95f4\u6846\u67b6\u4e0b\u7684\u65b0\u65b9\u6cd5\u8bba\uff0c\u6210\u529f\u5730\u63d0\u5347\u4e86\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7a33\u5b9a\u6027\u53ca\u6700\u7ec8\u6027\u80fd\u3002"}}
{"id": "2602.21788", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21788", "abs": "https://arxiv.org/abs/2602.21788", "authors": ["Yifan Niu", "Han Xiao", "Dongyi Liu", "Wei Zhou", "Jia Li"], "title": "DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism", "comment": null, "summary": "Scaling long-context capabilities is crucial for Multimodal Large Language Models (MLLMs). However, real-world multimodal datasets are extremely heterogeneous. Existing training frameworks predominantly rely on static parallelism strategies, which suffer from severe load imbalance, redundant communication, and suboptimal hardware utilization under data heterogeneity. In this work, we propose Dynamic Hybrid Parallelism (DHP), an efficient parallelism strategy that adaptively reconfigures communication groups and parallelism degrees during MLLM training. We generalize the non-power-of-two parallelism degrees and develop a polynomial-time algorithm to generate near-optimal parallelism strategies with only millisecond-level overhead per training batch. DHP is able to maintain high hardware efficiency even under extreme data variability. Experimental results demonstrate that DHP significantly outperforms Megatron-LM and DeepSpeed, achieving up to 1.36 $\\times$ speedup in training throughput while maintaining near-linear scaling efficiency across large-scale NPU clusters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u6df7\u5408\u5e76\u884c\uff08DHP\uff09\u7684\u65b0\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u80fd\u81ea\u9002\u5e94\u5730\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91cd\u65b0\u914d\u7f6e\u901a\u4fe1\u7ec4\u548c\u5e73\u884c\u5ea6\uff0c\u4ee5\u63d0\u9ad8\u786c\u4ef6\u6548\u7387\u548c\u8bad\u7ec3\u541e\u5410\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0eMegatron-LM\u548cDeepSpeed\u76f8\u6bd4\uff0cDHP\u80fd\u591f\u5b9e\u73b0\u9ad8\u8fbe1.36\u500d\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u5927\u89c4\u6a21NPU\u96c6\u7fa4\u4e0a\u4fdd\u6301\u63a5\u8fd1\u7ebf\u6027\u7684\u6269\u5c55\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u8bad\u7ec3\u6846\u67b6\u4e3b\u8981\u4f9d\u8d56\u4e8e\u9759\u6001\u5e76\u884c\u7b56\u7565\uff0c\u5728\u9762\u5bf9\u6570\u636e\u5f02\u6784\u6027\u65f6\u5b58\u5728\u4e25\u91cd\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u3001\u5197\u4f59\u901a\u4fe1\u4ee5\u53ca\u6b21\u4f18\u7684\u786c\u4ef6\u5229\u7528\u7387\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u6570\u636e\u9ad8\u5ea6\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u786c\u4ef6\u6548\u7387\u7684\u6709\u6548\u5e76\u884c\u7b56\u7565\u53d8\u5f97\u5341\u5206\u5fc5\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u6df7\u5408\u5e76\u884c\uff08DHP\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u53ef\u4ee5\u81ea\u9002\u5e94\u8c03\u6574\u901a\u4fe1\u7ec4\u548c\u5e73\u884c\u5ea6\u7684\u9ad8\u6548\u5e76\u884c\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u63a8\u5e7f\u4e86\u975e2\u7684\u5e42\u6b21\u65b9\u5e73\u884c\u5ea6\u7684\u5e94\u7528\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u751f\u6210\u51e0\u4e4e\u6700\u4f18\u7684\u5e76\u884c\u7b56\u7565\uff0c\u6bcf\u4e2a\u8bad\u7ec3\u6279\u6b21\u4ec5\u9700\u6beb\u79d2\u7ea7\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4e8eMegatron-LM\u548cDeepSpeed\uff0cDHP\u80fd\u591f\u8fbe\u5230\u6700\u9ad81.36\u500d\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u52a0\u901f\uff0c\u5e76\u4e14\u5373\u4f7f\u662f\u5728\u6781\u7aef\u7684\u6570\u636e\u53d8\u5316\u60c5\u51b5\u4e0b\u4e5f\u80fd\u7ef4\u6301\u9ad8\u6c34\u5e73\u7684\u786c\u4ef6\u4f7f\u7528\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u6df7\u5408\u5e76\u884c\u6280\u672f\uff0c\u7814\u7a76\u6210\u529f\u89e3\u51b3\u4e86\u7531\u4e8e\u6570\u636e\u5f02\u6784\u6027\u5bfc\u81f4\u7684\u4f20\u7edf\u9759\u6001\u5e76\u884c\u7b56\u7565\u6240\u9762\u4e34\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.21756", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21756", "abs": "https://arxiv.org/abs/2602.21756", "authors": ["Deogyong Kim", "Junseong Lee", "Jeongeun Lee", "Changhoe Kim", "Junguel Lee", "Jungseok Lee", "Dongha Lee"], "title": "Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing", "comment": "Under review", "summary": "Recent advances in large language models (LLMs) offer new opportunities for recommender systems by capturing the nuanced semantics of user interests and item characteristics through rich semantic understanding and contextual reasoning. In particular, LLMs have been employed as rerankers that reorder candidate items based on inferred user-item relevance. However, these approaches often require expensive online inference-time reasoning, leading to high latency that hampers real-world deployment. In this work, we introduce Persona4Rec, a recommendation framework that performs offline reasoning to construct interpretable persona representations of items, enabling lightweight and scalable real-time inference. In the offline stage, Persona4Rec leverages LLMs to reason over item reviews, inferring diverse user motivations that explain why different types of users may engage with an item; these inferred motivations are materialized as persona representations, providing multiple, human-interpretable views of each item. Unlike conventional approaches that rely on a single item representation, Persona4Rec learns to align user profiles with the most plausible item-side persona through a dedicated encoder, effectively transforming user-item relevance into user-persona relevance. At the online stage, this persona-profiled item index allows fast relevance computation without invoking expensive LLM reasoning. Extensive experiments show that Persona4Rec achieves performance comparable to recent LLM-based rerankers while substantially reducing inference time. Moreover, qualitative analysis confirms that persona representations not only drive efficient scoring but also provide intuitive, review-grounded explanations. These results demonstrate that Persona4Rec offers a practical and interpretable solution for next-generation recommender systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPersona4Rec\u7684\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u7ebf\u63a8\u7406\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u4eba\u7269\u8868\u793a\uff0c\u4ee5\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u548c\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u63a8\u7406\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u5728\u6027\u80fd\u4e0a\u4e0e\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u91cd\u6392\u5668\u76f8\u5f53\uff0c\u800c\u4e14\u5927\u5927\u51cf\u5c11\u4e86\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u76f4\u89c2\u4e14\u57fa\u4e8e\u8bc4\u8bba\u7684\u89e3\u91ca\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u6355\u6349\u7528\u6237\u5174\u8da3\u548c\u9879\u76ee\u7279\u5f81\u4e4b\u95f4\u7684\u7ec6\u5fae\u8bed\u4e49\u5dee\u5f02\uff0c\u4ece\u800c\u4e3a\u63a8\u8350\u7cfb\u7edf\u5e26\u6765\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5728\u7ebf\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\uff0c\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86Persona4Rec\u63a8\u8350\u6846\u67b6\uff0c\u5728\u79bb\u7ebf\u9636\u6bb5\u5229\u7528LLMs\u5bf9\u9879\u76ee\u8bc4\u4ef7\u8fdb\u884c\u63a8\u7406\uff0c\u63a8\u65ad\u51fa\u4e0d\u540c\u7c7b\u578b\u7684\u7528\u6237\u53ef\u80fd\u53c2\u4e0e\u9879\u76ee\u7684\u591a\u6837\u5316\u52a8\u673a\uff0c\u5e76\u5c06\u8fd9\u4e9b\u63a8\u65ad\u51fa\u7684\u52a8\u673a\u5177\u4f53\u5316\u4e3a\u4eba\u683c\u8868\u793a\uff1b\u7136\u540e\u5b66\u4e60\u5c06\u7528\u6237\u753b\u50cf\u4e0e\u6700\u6709\u53ef\u80fd\u7684\u9879\u76ee\u4fa7\u4eba\u683c\u76f8\u5339\u914d\uff0c\u6709\u6548\u5730\u5c06\u7528\u6237-\u9879\u76ee\u76f8\u5173\u6027\u8f6c\u6362\u4e3a\u7528\u6237-\u4eba\u683c\u76f8\u5173\u6027\u3002\u5728\u7ebf\u9636\u6bb5\uff0c\u5219\u53ef\u4ee5\u5feb\u901f\u8ba1\u7b97\u76f8\u5173\u6027\u800c\u65e0\u9700\u8c03\u7528\u6602\u8d35\u7684LLM\u63a8\u7406\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPersona4Rec\u5728\u4fdd\u6301\u4e0e\u6700\u8fd1\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u5668\u76f8\u4f3c\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u65f6\u95f4\u3002\u6b64\u5916\uff0c\u5b9a\u6027\u5206\u6790\u8bc1\u5b9e\u4e86\u4eba\u7269\u8868\u793a\u4e0d\u4ec5\u80fd\u9a71\u52a8\u9ad8\u6548\u7684\u8bc4\u5206\uff0c\u8fd8\u63d0\u4f9b\u4e86\u76f4\u89c2\u4e14\u57fa\u4e8e\u8bc4\u8bba\u7684\u89e3\u91ca\u3002", "conclusion": "Persona4Rec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0b\u4e00\u4ee3\u63a8\u8350\u7cfb\u7edf\uff0c\u5b83\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5b58\u5728\u7684\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u63a8\u8350\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.21697", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21697", "abs": "https://arxiv.org/abs/2602.21697", "authors": ["Chenyan Liu", "Yun Lin", "Jiaxin Chang", "Jiawei Liu", "Binhang Qi", "Bo Jiang", "Zhiyong Huang", "Jin Song Dong"], "title": "EditFlow: Benchmarking and Optimizing Code Edit Recommendation Systems via Reconstruction of Developer Flows", "comment": "Accepted at OOPSLA 2026 (Proc. ACM Program. Lang., Vol. 10, OOPSLA1)", "summary": "Large language models (LLMs) for code editing have achieved remarkable progress, yet recent empirical studies reveal a fundamental disconnect between technical accuracy and developer productivity. Despite their strong benchmark performance, developers complete tasks 19% slower when using AI assistance, with over 68.81% of recommendations disrupting their mental flow. This misalignment stems from the use of static commit snapshots that lack temporal information, causing models to optimize for end results rather than the incremental, context-sensitive steps that align with developers' natural reasoning process.\n  To bridge this gap, we present EditFlow, which benchmarks and optimizes subsequent code edit recommendation systems through the reconstruction of developer editing flows. EditFlow addresses three key challenges. First, collecting edit-order data that reflects developers' flow is inherently difficult: manual annotation introduces prohibitive overhead, while development logs capture only single trajectories instead of all plausible editing flows. Second, benchmarking recommendation performance against developers' ongoing editing flow requires a digital-twin-like simulation that can faithfully simulate the editing process. Third, existing heterogeneous systems vary drastically in scale and architecture, posing challenges for developing a unified optimization strategy that endows all models with mental-flow awareness regardless of design or capability.\n  ......", "AI": {"tldr": "EditFlow\u65e8\u5728\u901a\u8fc7\u91cd\u5efa\u5f00\u53d1\u8005\u7684\u7f16\u8f91\u6d41\u7a0b\u6765\u4f18\u5316\u4ee3\u7801\u7f16\u8f91\u63a8\u8350\u7cfb\u7edf\uff0c\u89e3\u51b3\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f85\u52a9\u7f16\u7a0b\u65f6\u867d\u7136\u6280\u672f\u51c6\u786e\u4f46\u964d\u4f4e\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c3d\u7ba1\u5728\u6280\u672f\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5374\u672a\u80fd\u6709\u6548\u63d0\u5347\u5f00\u53d1\u8005\u7684\u5b9e\u9645\u751f\u4ea7\u529b\uff1b\u4f7f\u7528AI\u8f85\u52a9\u53cd\u800c\u8ba9\u4efb\u52a1\u5b8c\u6210\u901f\u5ea6\u51cf\u6162\uff0c\u5e76\u4e14\u5927\u90e8\u5206\u5efa\u8bae\u4f1a\u6253\u65ad\u5f00\u53d1\u8005\u7684\u601d\u7ef4\u6d41\u3002\u95ee\u9898\u6838\u5fc3\u5728\u4e8e\u8fd9\u4e9b\u6a21\u578b\u57fa\u4e8e\u9759\u6001\u63d0\u4ea4\u5feb\u7167\u8bad\u7ec3\u800c\u6210\uff0c\u5ffd\u7565\u4e86\u65f6\u95f4\u987a\u5e8f\u4fe1\u606f\u4ee5\u53ca\u4e0e\u5f00\u53d1\u8005\u81ea\u7136\u63a8\u7406\u8fc7\u7a0b\u76f8\u5339\u914d\u7684\u9010\u6b65\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u6b65\u9aa4\u3002", "method": "\u63d0\u51faEditFlow\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u91cd\u5efa\u5f00\u53d1\u8005\u7684\u7f16\u8f91\u6d41\u7a0b\u6765\u5bf9\u540e\u7eed\u4ee3\u7801\u7f16\u8f91\u63a8\u8350\u7cfb\u7edf\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u548c\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u9488\u5bf9\u6536\u96c6\u53cd\u6620\u5f00\u53d1\u8005\u7f16\u8f91\u6d41\u7a0b\u7684\u6570\u636e\u96be\u9898\u3001\u9700\u8981\u7c7b\u4f3c\u6570\u5b57\u5b6a\u751f\u7684\u6a21\u62df\u73af\u5883\u4ee5\u8bc4\u4f30\u63a8\u8350\u6027\u80fd\u3001\u4ee5\u53ca\u4e3a\u4e0d\u540c\u89c4\u6a21\u548c\u67b6\u6784\u7684\u5f02\u6784\u7cfb\u7edf\u63d0\u4f9b\u7edf\u4e00\u4f18\u5316\u7b56\u7565\u8fd9\u4e09\u5927\u6311\u6218\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "result": "EditFlow\u80fd\u591f\u66f4\u6709\u6548\u5730\u652f\u6301\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u4ee3\u7801\u7f16\u8f91\u63a8\u8350\uff0c\u6f5c\u5728\u5730\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\u5e76\u51cf\u5c11\u4e86AI\u8f85\u52a9\u5e26\u6765\u7684\u5e72\u6270\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165EditFlow\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u4f7f\u4ee3\u7801\u7f16\u8f91\u63a8\u8350\u7cfb\u7edf\u9002\u5e94\u5f00\u53d1\u8005\u7684\u601d\u7ef4\u6d41\u52a8\u65b9\u5f0f\uff0c\u4ece\u800c\u63d0\u9ad8\u6574\u4f53\u751f\u4ea7\u529b\u3002"}}
{"id": "2602.21897", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.21897", "abs": "https://arxiv.org/abs/2602.21897", "authors": ["Aleix Bon\u00e9", "Alejandro Aguirre", "David \u00c1lvarez", "Pedro J. Martinez-Ferrer", "Vicen\u00e7 Beltran"], "title": "A task-based data-flow methodology for programming heterogeneous systems with multiple accelerator APIs", "comment": "13 pages, 8 figures", "summary": "Heterogeneous nodes that combine multi-core CPUs with diverse accelerators are rapidly becoming the norm in both high-performance computing (HPC) and AI infrastructures. Exploiting these platforms, however, requires orchestrating several low-level accelerator APIs such as CUDA, SYCL, and Triton. In some occasions they can be combined with optimized vendor math libraries: e.g., cuBLAS and oneAPI. Each API or library introduces its own abstractions, execution semantics, and synchronization mechanisms. Combining them within a single application is therefore error-prone and labor-intensive. We propose reusing a task-based data-flow methodology together with Task-Aware APIs (TA-libs) to overcome these limitations and facilitate the seamless integration of multiple accelerator programming models, while still leveraging the best-in-class kernels offered by each API.\n  Applications are expressed as a directed acyclic graph (DAG) of host tasks and device kernels managed by an OpenMP/OmpSs-2 runtime. We introduce Task-Aware SYCL (TASYCL) and leverage Task-Aware CUDA (TACUDA), which elevate individual accelerator invocations to first-class tasks. When multiple native runtimes coexist on the same multi-core CPU, they contend for threads, leading to oversubscription and performance variability. To address this, we unify their thread management under the nOS-V tasking and threading library, to which we contribute a new port of the PoCL (Portable OpenCL) runtime.\n  These results demonstrate that task-aware libraries, coupled with the nOS-V library, enable a single application to harness multiple accelerator programming models transparently and efficiently. The proposed methodology is immediately applicable to current heterogeneous nodes and is readily extensible to future systems that integrate even richer combinations of CPUs, GPUs, FPGAs, and AI accelerators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4efb\u52a1\u7684\u6570\u636e\u6d41\u65b9\u6cd5\u548c\u4efb\u52a1\u611f\u77e5API\uff08TA-libs\uff09\uff0c\u4ee5\u514b\u670d\u5728\u5355\u4e2a\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7ed3\u5408\u591a\u4e2a\u52a0\u901f\u5668\u7f16\u7a0b\u6a21\u578b\u65f6\u7684\u9650\u5236\uff0c\u5e76\u5b9e\u73b0\u591a\u79cd\u52a0\u901f\u5668\u7f16\u7a0b\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u540c\u65f6\u5229\u7528\u6bcf\u4e2aAPI\u63d0\u4f9b\u7684\u6700\u4f73\u5185\u6838\u3002", "motivation": "\u5f02\u6784\u8282\u70b9\u6b63\u5728\u6210\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97(HPC)\u548cAI\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u6807\u51c6\u914d\u7f6e\uff0c\u4f46\u8fd9\u4e9b\u5e73\u53f0\u7684\u4f7f\u7528\u9700\u8981\u534f\u8c03\u591a\u4e2a\u4f4e\u7ea7\u52a0\u901f\u5668API\uff0c\u5982CUDA\u3001SYCL\u548cTriton\u7b49\uff0c\u6709\u65f6\u8fd8\u9700\u4e0e\u4f18\u5316\u8fc7\u7684\u4f9b\u5e94\u5546\u6570\u5b66\u5e93\u7ed3\u5408\u4f7f\u7528\u3002\u4e0d\u540cAPI\u6216\u5e93\u5f15\u5165\u4e86\u5404\u81ea\u7684\u62bd\u8c61\u3001\u6267\u884c\u8bed\u4e49\u548c\u540c\u6b65\u673a\u5236\uff0c\u5728\u4e00\u4e2a\u5e94\u7528\u4e2d\u7ed3\u5408\u4f7f\u7528\u5b83\u4eec\u5bb9\u6613\u51fa\u9519\u4e14\u8017\u65f6\u8d39\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u91cd\u7528\u4e00\u79cd\u57fa\u4e8e\u4efb\u52a1\u7684\u6570\u636e\u6d41\u65b9\u6cd5\u8bba\uff0c\u4ee5\u53ca\u4efb\u52a1\u611f\u77e5API\uff08TA-libs\uff09\uff0c\u6765\u514b\u670d\u4e0a\u8ff0\u5c40\u9650\u6027\u5e76\u7b80\u5316\u591a\u79cd\u52a0\u901f\u5668\u7f16\u7a0b\u6a21\u578b\u7684\u6574\u5408\u8fc7\u7a0b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u901a\u8fc7Task-Aware SYCL (TASYCL) \u548c Task-Aware CUDA (TACUDA)\uff0c\u5c06\u5355\u72ec\u7684\u52a0\u901f\u5668\u8c03\u7528\u63d0\u5347\u4e3a\u4e00\u7b49\u516c\u6c11\u7684\u4efb\u52a1\u3002\u5f53\u591a\u4e2a\u539f\u751f\u8fd0\u884c\u65f6\u5728\u540c\u4e00\u591a\u6838CPU\u4e0a\u5171\u5b58\u65f6\uff0c\u53ef\u80fd\u4f1a\u56e0\u4e89\u593a\u7ebf\u7a0b\u800c\u5bfc\u81f4\u8d85\u8ba2\u9605\u53ca\u6027\u80fd\u6ce2\u52a8\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4ed6\u4eec\u8fd8\u7edf\u4e00\u4e86\u8fd9\u4e9b\u8fd0\u884c\u65f6\u7684\u7ebf\u7a0b\u7ba1\u7406\u5230nOS-V\u4efb\u52a1\u8c03\u5ea6\u548c\u7ebf\u7a0b\u5e93\u4e0b\uff0c\u5e76\u8d21\u732e\u4e86\u4e00\u4e2a\u65b0\u7684PoCL\uff08\u4fbf\u643a\u5f0fOpenCL\uff09\u8fd0\u884c\u65f6\u7aef\u53e3\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4efb\u52a1\u611f\u77e5\u5e93\u4e0enOS-V\u5e93\u76f8\u7ed3\u5408\uff0c\u4f7f\u5f97\u5355\u4e00\u5e94\u7528\u7a0b\u5e8f\u80fd\u591f\u900f\u660e\u800c\u9ad8\u6548\u5730\u5229\u7528\u591a\u79cd\u52a0\u901f\u5668\u7f16\u7a0b\u6a21\u578b\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8bba\u4e0d\u4ec5\u9002\u7528\u4e8e\u5f53\u524d\u7684\u5f02\u6784\u8282\u70b9\uff0c\u800c\u4e14\u5f88\u5bb9\u6613\u6269\u5c55\u5230\u672a\u6765\u96c6\u6210\u4e86\u66f4\u4e30\u5bcc\u7ec4\u5408\u7684CPU\u3001GPU\u3001FPGA\u548cAI\u52a0\u901f\u5668\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5373\u901a\u8fc7\u4efb\u52a1\u611f\u77e5\u5e93\u548cnOS-V\u5e93\u6765\u4fc3\u8fdb\u4e0d\u540c\u7c7b\u578b\u52a0\u901f\u5668\u7f16\u7a0b\u6a21\u578b\u4e4b\u95f4\u7684\u65e0\u7f1d\u534f\u4f5c\uff0c\u4ece\u800c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u7a0b\u5e8f\u6027\u80fd\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u73b0\u6709\u6311\u6218\uff0c\u4e5f\u4e3a\u672a\u6765\u66f4\u52a0\u590d\u6742\u7684\u5f02\u6784\u8ba1\u7b97\u73af\u5883\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u652f\u6301\u3002"}}
{"id": "2602.21957", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21957", "abs": "https://arxiv.org/abs/2602.21957", "authors": ["Yuchun Tu", "Zhiwei Li", "Bingli Sun", "Yixuan Li", "Xiao Song"], "title": "Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation", "comment": "18 pages, 9 figures", "summary": "Federated recommendation facilitates collaborative model training across distributed clients while keeping sensitive user interaction data local. Conventional approaches typically rely on synchronizing high-dimensional item representations between the server and clients. This paradigm implicitly assumes that precise geometric alignment of embedding coordinates is necessary for collaboration across clients. We posit that establishing relative semantic relationships among items is more effective than enforcing shared representations. Specifically, global semantic relations serve as structural constraints for items. Within these constraints, the framework allows item representations to vary locally on each client, which flexibility enables the model to capture fine-grained user personalization while maintaining global consistency. To this end, we propose Cluster-Guided FedRec framework (CGFedRec), a framework that transforms uploaded embeddings into compact cluster labels. In this framework, the server functions as a global structure discoverer to learn item clusters and distributes only the resulting labels. This mechanism explicitly cuts off the downstream transmission of item embeddings, relieving clients from maintaining global shared item embeddings. Consequently, CGFedRec achieves the effective injection of global collaborative signals into local item representations without transmitting full embeddings. Extensive experiments demonstrate that our approach significantly improves communication efficiency while maintaining superior recommendation accuracy across multiple datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCluster-Guided FedRec (CGFedRec) \u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u4e0a\u4f20\u7684\u5d4c\u5165\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u805a\u7c7b\u6807\u7b7e\u6765\u6539\u5584\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u548c\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u8054\u90a6\u63a8\u8350\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5728\u670d\u52a1\u5668\u548c\u5ba2\u6237\u7aef\u4e4b\u95f4\u540c\u6b65\u9ad8\u7ef4\u9879\u76ee\u8868\u793a\uff0c\u8fd9\u5047\u8bbe\u4e86\u5d4c\u5165\u5750\u6807\u7cbe\u786e\u5bf9\u9f50\u5bf9\u4e8e\u8de8\u5ba2\u6237\u7aef\u534f\u4f5c\u662f\u5fc5\u8981\u7684\u3002\u4f5c\u8005\u8ba4\u4e3a\u5efa\u7acb\u9879\u76ee\u4e4b\u95f4\u7684\u76f8\u5bf9\u8bed\u4e49\u5173\u7cfb\u6bd4\u5f3a\u5236\u5171\u4eab\u8868\u793a\u66f4\u6709\u6548\uff0c\u5e76\u4e14\u53ef\u4ee5\u6355\u6349\u5230\u7ec6\u7c92\u5ea6\u7684\u7528\u6237\u4e2a\u6027\u5316\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e86Cluster-Guided FedRec (CGFedRec) \u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5c06\u4e0a\u4f20\u7684\u5d4c\u5165\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u805a\u7c7b\u6807\u7b7e\u3002\u670d\u52a1\u5668\u4f5c\u4e3a\u5168\u5c40\u7ed3\u6784\u53d1\u73b0\u8005\u5b66\u4e60\u9879\u76ee\u805a\u7c7b\u5e76\u4ec5\u5206\u53d1\u7ed3\u679c\u6807\u7b7e\uff0c\u4ece\u800c\u5207\u65ad\u4e86\u9879\u5d4c\u5165\u7684\u4e0b\u6e38\u4f20\u8f93\uff0c\u4f7f\u5f97\u5ba2\u6237\u7aef\u65e0\u9700\u7ef4\u62a4\u5168\u5c40\u5171\u4eab\u7684\u9879\u5d4c\u5165\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u901a\u4fe1\u6548\u7387\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u63a8\u8350\u51c6\u786e\u6027\u3002", "conclusion": "CGFedRec\u6846\u67b6\u901a\u8fc7\u5141\u8bb8\u9879\u76ee\u8868\u793a\u5728\u6bcf\u4e2a\u5ba2\u6237\u7aef\u5c40\u90e8\u53d8\u5316\uff0c\u4ee5\u53ca\u901a\u8fc7\u53ea\u4f20\u9012\u805a\u7c7b\u6807\u7b7e\u800c\u975e\u5b8c\u6574\u7684\u5d4c\u5165\u5411\u91cf\uff0c\u6709\u6548\u5730\u6ce8\u5165\u4e86\u5168\u5c40\u534f\u4f5c\u4fe1\u53f7\u5230\u672c\u5730\u9879\u76ee\u8868\u793a\u4e2d\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u7684\u901a\u4fe1\u6548\u7387\u548c\u63a8\u8350\u8d28\u91cf\u3002"}}
{"id": "2602.21734", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21734", "abs": "https://arxiv.org/abs/2602.21734", "authors": ["Selin Coban", "Miguel Perez", "Horst Lichter"], "title": "Proto-ML: An IDE for ML Solution Prototyping", "comment": "To be published at 3rd International Workshop on Integrated Development Environments (IDE '26), April 12--18, 2026, Rio de Janeiro, Brazil", "summary": "Prototyping plays a critical role in the development of machine learning (ML) solutions, yet existing tools often provide limited support for effective collaboration and knowledge reuse among stakeholders. This paper introduces Proto-ML, an IDE designed to strengthen ML prototyping workflows. By addressing key deficiencies such as insufficient stakeholder involvement, limited cross-project knowledge reuse, and fragmented tool support, Proto-ML offers a unified framework that enables structured documentation of prototyping activities and promotes knowledge sharing across projects.\n  The Proto-ML IDE consists of three extension bundles: prototype implementation, analysis, and knowledge management. These extensions support tasks ranging from evaluating prototype quality against defined criteria to incorporating stakeholder perspectives throughout the development process. Preliminary user feedback suggests that Proto-ML can increase prototyping efficiency and foster more transparent and reusable ML solution development.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aProto-ML\u7684IDE\uff0c\u65e8\u5728\u52a0\u5f3a\u673a\u5668\u5b66\u4e60\u539f\u578b\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u7a0b\u3002\u901a\u8fc7\u63d0\u4f9b\u4e09\u4e2a\u6269\u5c55\u5305\u6765\u652f\u6301\u4ece\u539f\u578b\u5b9e\u73b0\u3001\u5206\u6790\u5230\u77e5\u8bc6\u7ba1\u7406\u7684\u4efb\u52a1\uff0cProto-ML\u6709\u52a9\u4e8e\u63d0\u9ad8\u539f\u578b\u8bbe\u8ba1\u6548\u7387\u548c\u4fc3\u8fdb\u900f\u660e\u5ea6\u53ca\u53ef\u91cd\u7528\u6027\u66f4\u5f3a\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5728\u652f\u6301\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u6709\u6548\u534f\u4f5c\u548c\u77e5\u8bc6\u91cd\u7528\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5305\u62ec\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\u4e0d\u8db3\u3001\u8de8\u9879\u76ee\u77e5\u8bc6\u91cd\u7528\u6709\u9650\u4ee5\u53ca\u5de5\u5177\u652f\u6301\u5206\u6563\u7b49\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u8fd9\u4e9b\u95ee\u9898\u7684\u65b0IDE\u3002", "method": "\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86Proto-ML IDE\uff0c\u8be5IDE\u7531\u4e09\u4e2a\u6269\u5c55\u5305\u7ec4\u6210\uff1a\u539f\u578b\u5b9e\u73b0\u3001\u5206\u6790\u548c\u77e5\u8bc6\u7ba1\u7406\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u5171\u540c\u4f5c\u7528\u4e8e\u6539\u5584\u6574\u4e2a\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u4ece\u8bc4\u4f30\u539f\u578b\u8d28\u91cf\u5230\u8fbe\u6210\u5229\u76ca\u76f8\u5173\u8005\u671f\u671b\u7b49\u4efb\u52a1\u7684\u652f\u6301\u60c5\u51b5\u3002", "result": "\u521d\u6b65\u7528\u6237\u53cd\u9988\u8868\u660e\uff0c\u4f7f\u7528Proto-ML\u53ef\u4ee5\u63d0\u9ad8\u539f\u578b\u8bbe\u8ba1\u7684\u6548\u7387\uff0c\u5e76\u4e14\u6709\u52a9\u4e8e\u521b\u5efa\u66f4\u52a0\u900f\u660e\u548c\u6613\u4e8e\u91cd\u7528\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "Proto-ML\u4f5c\u4e3a\u4e00\u4e2a\u4e3a\u673a\u5668\u5b66\u4e60\u539f\u578b\u8bbe\u8ba1\u91cf\u8eab\u5b9a\u5236\u7684IDE\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u6548\u7387\u3001\u4fc3\u8fdb\u77e5\u8bc6\u5171\u4eab\u4ee5\u53ca\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u53ef\u91cd\u7528\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.21514", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21514", "abs": "https://arxiv.org/abs/2602.21514", "authors": ["Liang Li", "Shufeng Gong", "Yanan Yang", "Yiduo Wang", "Jie Wu"], "title": "I/O Optimizations for Graph-Based Disk-Resident Approximate Nearest Neighbor Search: A Design Space Exploration", "comment": null, "summary": "Approximate nearest neighbor (ANN) search on SSD-backed indexes is increasingly I/O-bound (I/O accounts for 70--90\\% of query latency). We present an I/O-first framework for disk-based ANN that organizes techniques along three dimensions: memory layout, disk layout, and search algorithm. We introduce a page-level complexity model that explains how page locality and path length jointly determine page reads, and we validate the model empirically. Using consistent implementations across four public datasets, we quantify both single-factor effects and cross-dimensional synergies. We find that (i) memory-resident navigation and dynamic width provide the strongest standalone gains; (ii) page shuffle and page search are weak alone but complementary together; and (iii) a principled composition, OctopusANN, substantially reduces I/O and achieves 4.1--37.9\\% higher throughput than the state-of-the-art system Starling and 87.5--149.5\\% higher throughput than DiskANN at matched Recall@10=90\\%. Finally, we distill actionable guidelines for selecting storage-centric or hybrid designs across diverse concurrency levels and accuracy constraints, advocating systematic composition rather than isolated tweaks when pushing the performance frontier of disk-based ANN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8eSSD\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7684I/O\u4f18\u5148\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u5b58\u5e03\u5c40\u3001\u78c1\u76d8\u5e03\u5c40\u548c\u641c\u7d22\u7b97\u6cd5\u4e09\u4e2a\u7ef4\u5ea6\u7ec4\u7ec7\u6280\u672f\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u9875\u7ea7\u590d\u6742\u6027\u6a21\u578b\u6765\u89e3\u91ca\u9875\u9762\u5c40\u90e8\u6027\u548c\u8def\u5f84\u957f\u5ea6\u5982\u4f55\u5171\u540c\u51b3\u5b9a\u9875\u9762\u8bfb\u53d6\u3002\u901a\u8fc7\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u4e00\u81f4\u5b9e\u73b0\uff0c\u7814\u7a76\u4e86\u5355\u56e0\u7d20\u6548\u5e94\u548c\u8de8\u7ef4\u5ea6\u534f\u540c\u4f5c\u7528\u3002\u63d0\u51fa\u7684OctopusANN\u7cfb\u7edf\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7cfb\u7edfStarling\u548cDiskANN\uff0c\u5728\u5339\u914d\u7684\u53ec\u56de\u7387\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u641c\u7d22\u5728\u57fa\u4e8eSSD\u7684\u652f\u6301\u7d22\u5f15\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u53d7I/O\u9650\u5236\uff08I/O\u5360\u67e5\u8be2\u5ef6\u8fdf\u768470-90%\uff09\u3002\u9762\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u4f5c\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u78c1\u76d8\u4e0a\u7684ANN\u6027\u80fd\uff0c\u51cf\u5c11I/O\u74f6\u9888\u5e76\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u4e2aI/O\u4f18\u5148\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6cbf\u5185\u5b58\u5e03\u5c40\u3001\u78c1\u76d8\u5e03\u5c40\u4ee5\u53ca\u641c\u7d22\u7b97\u6cd5\u4e09\u4e2a\u65b9\u5411\u7ec4\u7ec7\u6280\u672f\uff1b\u5f15\u5165\u4e86\u9875\u7ea7\u590d\u6742\u5ea6\u6a21\u578b\u6765\u89e3\u91ca\u9875\u9762\u5c40\u90e8\u6027\u548c\u8def\u5f84\u957f\u5ea6\u5982\u4f55\u5171\u540c\u5f71\u54cd\u9875\u9762\u8bfb\u53d6\u6b21\u6570\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "result": "\u53d1\u73b0\u5185\u5b58\u9a7b\u7559\u5bfc\u822a\u4e0e\u52a8\u6001\u5bbd\u5ea6\u5355\u72ec\u4f7f\u7528\u65f6\u63d0\u4f9b\u4e86\u6700\u5f3a\u52b2\u7684\u6027\u80fd\u63d0\u5347\uff1b\u9875\u9762\u91cd\u6392\u548c\u9875\u9762\u641c\u7d22\u5355\u72ec\u6548\u679c\u8f83\u5f31\u4f46\u8054\u5408\u4f7f\u7528\u65f6\u5177\u6709\u4e92\u8865\u4f18\u52bf\uff1b\u7efc\u5408\u8003\u8651\u4e0a\u8ff0\u56e0\u7d20\u8bbe\u8ba1\u7684OctopusANN\u7cfb\u7edf\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7cfb\u7edfStarling\u63d0\u9ad8\u4e864.1-37.9%\u7684\u541e\u5410\u91cf\uff0c\u5728\u4fdd\u6301Recall@10=90%\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u8f83\u4e8eDiskANN\u63d0\u5347\u4e8687.5-149.5%\u7684\u541e\u5410\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7cfb\u7edf\u5730\u7ec4\u5408\u4e0d\u540c\u6280\u672f\u800c\u975e\u5b64\u7acb\u8c03\u6574\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u5584\u57fa\u4e8e\u78c1\u76d8\u7684ANN\u641c\u7d22\u6027\u80fd\u3002\u4e3a\u4e0d\u540c\u5e76\u53d1\u7ea7\u522b\u53ca\u7cbe\u5ea6\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u5b58\u50a8\u4e2d\u5fc3\u6216\u6df7\u5408\u8bbe\u8ba1\u65b9\u6848\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5357\u3002"}}
{"id": "2602.21800", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21800", "abs": "https://arxiv.org/abs/2602.21800", "authors": ["Madhusudan Ghosh", "Rishabh Gupta"], "title": "An Evaluation of Context Length Extrapolation in Long Code via Positional Embeddings and Efficient Attention", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has led to a significant increase in automated tools in the software engineering, capable of performing various code-related tasks such as code generation, completion, and translation. Despite these advancements, its effectiveness is constrained by fixed context lengths, limiting its ability to generalize across long, domain-specific code sequences. To address this challenge, we investigate zero-shot, inference-only methods aimed at improving position encodings and optimizing attention mechanisms. Our goal is to provide a thorough analysis of current approaches that facilitate context length extrapolation in code, particularly in the context of long code completion tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u96f6\u6837\u672c\u3001\u4ec5\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u4f4d\u7f6e\u7f16\u7801\u548c\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4ee3\u7801\u5e8f\u5217\u65f6\u7531\u4e8e\u56fa\u5b9a\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\u5bfc\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u80fd\u591f\u6267\u884c\u5404\u79cd\u4e0e\u4ee3\u7801\u76f8\u5173\u7684\u4efb\u52a1\uff0c\u4f46\u5176\u6709\u6548\u6027\u53d7\u5230\u56fa\u5b9a\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u4e14\u7279\u5b9a\u9886\u57df\u7684\u4ee3\u7801\u5e8f\u5217\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u96f6\u6837\u672c\u3001\u4ec5\u63a8\u7406\u7684\u65b9\u6cd5\u6765\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6539\u8fdb\u4f4d\u7f6e\u7f16\u7801\u548c\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\u6765\u4fc3\u8fdb\u4ee3\u7801\u4e2d\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u5916\u63a8\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u5f53\u524d\u6709\u52a9\u4e8e\u4ee3\u7801\u4e2d\u4e0a\u4e0b\u6587\u957f\u5ea6\u5916\u63a8\u65b9\u6cd5\u7684\u5168\u9762\u5206\u6790\uff0c\u5c24\u5176\u662f\u5728\u957f\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u80cc\u666f\u4e0b\u3002", "conclusion": "\u901a\u8fc7\u6539\u5584\u4f4d\u7f6e\u7f16\u7801\u548c\u4f18\u5316\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4ee3\u7801\u5e8f\u5217\u7684\u80fd\u529b\uff0c\u4ece\u800c\u514b\u670d\u56fa\u5b9a\u4e0a\u4e0b\u6587\u957f\u5ea6\u5e26\u6765\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.21547", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21547", "abs": "https://arxiv.org/abs/2602.21547", "authors": ["Yuchong Wu", "Zihuan Xu", "Wangze Ni", "Peng Cheng", "Lei Chen", "Xuemin Lin", "Heng Tao Shen", "Kui Ren"], "title": "RAC: Relation-Aware Cache Replacement for Large Language Models", "comment": null, "summary": "The scaling of Large Language Model (LLM) services faces significant cost and latency challenges, making effective caching under tight capacity crucial. Existing cache replacement policies, from heuristics to learning-based methods, predominantly rely on limited-window statistics such as recency and frequency. We show these signals are not robust for real-world LLM workloads, which exhibit long reuse distances and sparse local recurrence.\n  To address these limitations, we propose Relation-Aware Cache (RAC), an online eviction strategy that leverages semantic relations among requests to guide eviction decisions. RAC synthesizes two relation-aware signals: (1) Topical Prevalence, which aggregates access evidence at the topic level to capture long-horizon reuse; and (2) Structural Importance, which leverages local intra-topic dependency structure to discriminate entries by their future reuse value. Extensive evaluations show that RAC maintains high effectiveness across diverse workloads, consistently surpassing state-of-the-art baselines by 20%--30% in cache hit ratio.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRelation-Aware Cache (RAC)\u7684\u5728\u7ebf\u6dd8\u6c70\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u8bf7\u6c42\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u6765\u6307\u5bfc\u7f13\u5b58\u6dd8\u6c70\u51b3\u7b56\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u5728\u6269\u5c55\u65f6\u9047\u5230\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u670d\u52a1\u7684\u6269\u5c55\u9762\u4e34\u7740\u663e\u8457\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u6311\u6218\uff0c\u800c\u73b0\u6709\u7684\u7f13\u5b58\u66ff\u6362\u7b56\u7565\u57fa\u4e8e\u5982\u6700\u8fd1\u4f7f\u7528\u6216\u9891\u7387\u8fd9\u6837\u7684\u6709\u9650\u7a97\u53e3\u7edf\u8ba1\u4fe1\u606f\uff0c\u5728\u5b9e\u9645LLM\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e9b\u5de5\u4f5c\u8d1f\u8f7d\u8868\u73b0\u51fa\u957f\u91cd\u7528\u8ddd\u79bb\u548c\u5c40\u90e8\u7a00\u758f\u91cd\u590d\u6027\u3002", "method": "\u63d0\u51fa\u4e86Relation-Aware Cache (RAC)\uff0c\u4e00\u79cd\u5728\u7ebf\u6dd8\u6c70\u7b56\u7565\uff0c\u5b83\u5229\u7528\u8bf7\u6c42\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u6765\u6307\u5bfc\u6dd8\u6c70\u51b3\u7b56\u3002\u8be5\u65b9\u6cd5\u7efc\u5408\u4e86\u4e24\u79cd\u5173\u8054\u611f\u77e5\u4fe1\u53f7\uff1a\u4e3b\u9898\u666e\u904d\u6027\uff08Topical Prevalence\uff09\uff0c\u7528\u4e8e\u6355\u6349\u957f\u671f\u91cd\u7528\uff1b\u4ee5\u53ca\u7ed3\u6784\u91cd\u8981\u6027\uff08Structural Importance\uff09\uff0c\u5229\u7528\u5c40\u90e8\u4e3b\u9898\u5185\u4f9d\u8d56\u7ed3\u6784\u6765\u533a\u5206\u6761\u76ee\u5bf9\u672a\u6765\u91cd\u7528\u7684\u4ef7\u503c\u3002", "result": "\u5e7f\u6cdb\u7684\u8bc4\u4f30\u8868\u660e\uff0cRAC\u80fd\u591f\u5728\u591a\u6837\u5316\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u9ad8\u6548\u6027\uff0c\u5728\u7f13\u5b58\u547d\u4e2d\u7387\u65b9\u9762\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u9ad8\u51fa20%\u523030%\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86RAC\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u7f13\u5b58\u7ba1\u7406\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u6210\u672c\u4e0e\u5ef6\u8fdf\u6311\u6218\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.22017", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.22017", "abs": "https://arxiv.org/abs/2602.22017", "authors": ["Chris Egersdoerfer", "Arnav Sareen", "Jean Luca Bez", "Suren Byna", "Dongkuan", "Xu", "Dong Dai"], "title": "IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs", "comment": "Published in the Proceedings of the 2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS 2025)", "summary": "As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex interactions.In this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detailed justifications and references for its diagnoses and offers an interactive interface for scientists to ask targeted follow-up questions. To evaluate IOAgent, we collected a diverse set of labeled job traces and released the first open diagnosis test suite, TraceBench. Using this test suite, we conducted extensive evaluations, demonstrating that IOAgent matches or outperforms state-of-the-art I/O diagnosis tools with accurate and useful diagnosis results. We also show that IOAgent is not tied to specific LLMs, performing similarly well with both proprietary and open-source LLMs. We believe IOAgent has the potential to become a powerful tool for scientists navigating complex HPC I/O subsystems in the future.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIOAgent\u7684\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u79d1\u5b66\u5bb6\u4eec\u66f4\u6709\u6548\u5730\u8bca\u65adHPC\u5b58\u50a8\u7cfb\u7edf\u4e2d\u7684I/O\u6027\u80fd\u95ee\u9898\u3002\u8be5\u5de5\u5177\u7ed3\u5408\u4e86\u6a21\u5757\u5316\u7684\u9884\u5904\u7406\u5668\u3001\u57fa\u4e8eRAG\u7684\u9886\u57df\u77e5\u8bc6\u96c6\u6210\u5668\u548c\u6811\u72b6\u5408\u5e76\u5668\uff0c\u80fd\u591f\u4eceDarshan\u8ddf\u8e2a\u6587\u4ef6\u4e2d\u51c6\u786e\u8bca\u65adI/O\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u8be6\u7ec6\u7684\u89e3\u91ca\u548c\u53c2\u8003\u3002\u901a\u8fc7\u591a\u6837\u5316\u7684\u6807\u8bb0\u4f5c\u4e1a\u8ddf\u8e2a\u6d4b\u8bd5\u96c6TraceBench\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aIOAgent\u7684\u8868\u73b0\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u73b0\u6709\u7684I/O\u8bca\u65ad\u5de5\u5177\uff0c\u5e76\u4e14\u4e0e\u4e13\u6709\u53ca\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u517c\u5bb9\u3002", "motivation": "\u968f\u7740HPC\uff08\u9ad8\u6027\u80fd\u8ba1\u7b97\uff09\u5b58\u50a8\u6808\u590d\u6742\u6027\u7684\u5feb\u901f\u589e\u957f\uff0c\u9886\u57df\u79d1\u5b66\u5bb6\u5728\u6709\u6548\u5229\u7528HPC\u5b58\u50a8\u7cfb\u7edf\u4ee5\u8fbe\u5230\u7406\u60f3\u7684I/O\u6027\u80fd\u65b9\u9762\u9047\u5230\u4e86\u8d8a\u6765\u8d8a\u591a\u7684\u6311\u6218\u3002\u5f53\u524d\u89e3\u51b3I/O\u95ee\u9898\u9ad8\u5ea6\u4f9d\u8d56\u6709\u9650\u6570\u91cf\u7684I/O\u4e13\u5bb6\uff0c\u8fd9\u5bfc\u81f4\u4e86\u83b7\u53d6\u4e13\u5bb6\u652f\u6301\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\uff0c\u6210\u4e3a\u79d1\u5b66\u5bb6\u63d0\u9ad8\u751f\u4ea7\u529b\u7684\u4e3b\u8981\u74f6\u9888\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8fdb\u6b65\u4e3a\u6784\u5efa\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u8bf8\u5982\u65e0\u6cd5\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7a97\u53e3\u3001\u7f3a\u4e4f\u5173\u4e8eHPC I/O\u7684\u51c6\u786e\u9886\u57df\u77e5\u8bc6\u4ee5\u53ca\u5728\u590d\u6742\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u751f\u6210\u5e7b\u89c9\u7b49\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aIOAgent\u7684\u7cfb\u7edf\uff0c\u5b83\u5305\u62ec\u4e00\u4e2a\u6a21\u5757\u5316\u9884\u5904\u7406\u5668\u7528\u4e8e\u5904\u7406\u8f93\u5165\u6570\u636e\uff0c\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u9886\u57df\u77e5\u8bc6\u96c6\u6210\u5668\u6765\u6574\u5408\u76f8\u5173\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u6811\u72b6\u5408\u5e76\u5668\u6765\u7efc\u5408\u5206\u6790\u7ed3\u679c\u3002\u6b64\u7cfb\u7edf\u6a21\u4effI/O\u4e13\u5bb6\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4e0d\u4ec5\u63d0\u4f9b\u5177\u4f53\u7684\u95ee\u9898\u8bca\u65ad\uff0c\u8fd8\u80fd\u7ed9\u51fa\u76f8\u5e94\u7684\u7406\u7531\u548c\u53c2\u8003\u8d44\u6599\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u901a\u8fc7\u4e92\u52a8\u754c\u9762\u63d0\u51fa\u540e\u7eed\u95ee\u9898\u3002", "result": "\u4f7f\u7528\u81ea\u5efa\u7684\u591a\u6837\u5316\u6807\u8bb0\u4f5c\u4e1a\u8ddf\u8e2a\u6d4b\u8bd5\u5957\u4ef6TraceBench\u5bf9IOAgent\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\u3002\u5b9e\u9a8c\u8868\u660e\uff0cIOAgent\u80fd\u591f\u5728\u51c6\u786e\u6027\u4e0e\u5b9e\u7528\u6027\u65b9\u9762\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u7684I/O\u8bca\u65ad\u5de5\u5177\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5c55\u793a\u4e86IOAgent\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u3002", "conclusion": "IOAgent\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u6210\u4e3a\u672a\u6765\u79d1\u5b66\u5bb6\u4eec\u5728\u9762\u5bf9\u590d\u6742\u7684HPC I/O\u5b50\u7cfb\u7edf\u65f6\u7684\u5f3a\u5927\u52a9\u624b\u3002\u5b83\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5f53\u524dI/O\u6027\u80fd\u8bca\u65ad\u8fc7\u7a0b\u4e2d\u7684\u82e5\u5e72\u5173\u952e\u96be\u9898\uff0c\u4e5f\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u66f4\u597d\u5730\u5e94\u7528AI\u6280\u672f\u4e8e\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.22103", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.22103", "abs": "https://arxiv.org/abs/2602.22103", "authors": ["Mao Lin", "Hyeran Jeon", "Keren Zhou"], "title": "PASTA: A Modular Program Analysis Tool Framework for Accelerators", "comment": null, "summary": "The increasing complexity and diversity of hardware accelerators in modern computing systems demand flexible, low-overhead program analysis tools. We present PASTA, a low-overhead and modular Program AnalysiS Tool Framework for Accelerators. PASTA abstracts over low-level profiling APIs and diverse deep learning frameworks, offering users a unified interface to capture and analyze runtime events at multiple levels. Its extensible design enables researchers and practitioners to rapidly prototype custom tools with minimal overhead. We demonstrate the utility of PASTA by developing several analysis tools, including a deep learning workload characterization tool and a UVM optimization tool. Through extensive evaluation on mainstream deep learning workloads tested on NVIDIA and AMD GPUs under both single- and multi-GPU scenarios, we demonstrate PASTA's broad applicability. On NVIDIA GPUs, we further show that PASTA provides detailed performance insights with significantly lower overhead, up to 1.3*10^4 faster than conventional analysis tools, thanks to its GPU-accelerated backend. PASTA strikes a practical balance between usability, extensibility, and efficiency, making it well-suited for modern accelerator-based computing environments.", "AI": {"tldr": "PASTA\u662f\u4e00\u4e2a\u9488\u5bf9\u52a0\u901f\u5668\u7684\u4f4e\u5f00\u9500\u3001\u6a21\u5757\u5316\u7684\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u6846\u67b6\uff0c\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\u6765\u6355\u83b7\u548c\u5206\u6790\u8fd0\u884c\u65f6\u4e8b\u4ef6\u3002\u5b83\u652f\u6301\u5feb\u901f\u5f00\u53d1\u81ea\u5b9a\u4e49\u5de5\u5177\uff0c\u5e76\u5728NVIDIA\u548cAMD GPU\u4e0a\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u6027\u53ca\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u786c\u4ef6\u52a0\u901f\u5668\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u7684\u589e\u52a0\uff0c\u9700\u8981\u66f4\u52a0\u7075\u6d3b\u4e14\u4f4e\u5f00\u9500\u7684\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86PASTA\uff0c\u4e00\u4e2a\u9762\u5411\u52a0\u901f\u5668\u7684\u4f4e\u5f00\u9500\u4e0e\u6a21\u5757\u5316\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u6846\u67b6\u3002PASTA\u62bd\u8c61\u4e86\u5e95\u5c42\u5256\u6790API\u548c\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u754c\u9762\u4ee5\u591a\u5c42\u7ea7\u5730\u6355\u6349\u548c\u5206\u6790\u8fd0\u884c\u65f6\u4e8b\u4ef6\u3002", "result": "\u901a\u8fc7\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u5728NVIDIA\u548cAMD GPU\u4e0a\u7684\u5e7f\u6cdb\u6d4b\u8bd5\uff08\u5305\u62ec\u5355GPU\u548c\u591aGPU\u573a\u666f\uff09\uff0c\u8bc1\u660e\u4e86PASTA\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002\u7279\u522b\u662f\uff0c\u5728NVIDIA GPU\u4e0a\uff0cPASTA\u80fd\u591f\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u5f00\u9500\u63d0\u4f9b\u8be6\u7ec6\u7684\u6027\u80fd\u6d1e\u5bdf\uff0c\u6bd4\u4f20\u7edf\u5206\u6790\u5de5\u5177\u5feb\u8fbe1.3*10^4\u500d\u3002", "conclusion": "PASTA\u5728\u53ef\u7528\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u4e4b\u95f4\u8fbe\u5230\u4e86\u5b9e\u9645\u5e73\u8861\uff0c\u975e\u5e38\u9002\u5408\u57fa\u4e8e\u73b0\u4ee3\u52a0\u901f\u5668\u7684\u8ba1\u7b97\u73af\u5883\u3002"}}
{"id": "2602.21833", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21833", "abs": "https://arxiv.org/abs/2602.21833", "authors": ["Norman Peitek", "Julia Hess", "Sven Apel"], "title": "From Restructuring to Stabilization: A Large-Scale Experiment on Iterative Code Readability Refactoring with Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly used for automated code refactoring tasks. Although these models can quickly refactor code, the quality may exhibit inconsistencies and unpredictable behavior. In this article, we systematically study the capabilities of LLMs for code refactoring with a specific focus on improving code readability.\n  We conducted a large-scale experiment using GPT5.1 with 230 Java snippets, each systematically varied and refactored regarding code readability across five iterations under three different prompting strategies. We categorized fine-grained code changes during the refactoring into implementation, syntactic, and comment-level transformations. Subsequently, we investigated the functional correctness and tested the robustness of the results with novel snippets.\n  Our results reveal three main insights: First, iterative code refactoring exhibits an initial phase of restructuring followed by stabilization. This convergence tendency suggests that LLMs possess an internalized understanding of an \"optimally readable\" version of code. Second, convergence patterns are fairly robust across different code variants. Third, explicit prompting toward specific readability factors slightly influences the refactoring dynamics.\n  These insights provide an empirical foundation for assessing the reliability of LLM-assisted code refactoring, which opens pathways for future research, including comparative analyses across models and a systematic evaluation of additional software quality dimensions in LLM-refactored code.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u91cd\u6784\u4ee5\u63d0\u9ad8\u53ef\u8bfb\u6027\u65b9\u9762\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u4f7f\u7528GPT5.1\u5bf9230\u4e2aJava\u4ee3\u7801\u7247\u6bb5\u8fdb\u884c\u4e94\u8f6e\u8fed\u4ee3\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u91cd\u6784\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u7684\u8d8b\u540c\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u6307\u51fa\u660e\u786e\u63d0\u793a\u7279\u5b9a\u53ef\u8bfb\u6027\u56e0\u7d20\u5bf9\u91cd\u6784\u52a8\u6001\u6709\u8f7b\u5fae\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5feb\u901f\u91cd\u6784\u4ee3\u7801\uff0c\u4f46\u5176\u8d28\u91cf\u53ef\u80fd\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u7684\u884c\u4e3a\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u4e9b\u6a21\u578b\u5728\u6539\u8fdb\u4ee3\u7801\u53ef\u8bfb\u6027\u7684\u91cd\u6784\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u5927\u89c4\u6a21\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5229\u7528GPT5.1\u5904\u7406230\u6bb5Java\u4ee3\u7801\uff0c\u5728\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u8fdb\u884c\u4e86\u5173\u4e8e\u4ee3\u7801\u53ef\u8bfb\u6027\u7684\u4e94\u4e2a\u8fed\u4ee3\u5468\u671f\u7684\u91cd\u6784\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9\u91cd\u6784\u8fc7\u7a0b\u4e2d\u7684\u7ec6\u7c92\u5ea6\u4ee3\u7801\u53d8\u66f4\u8fdb\u884c\u4e86\u5206\u7c7b\u5206\u6790\uff0c\u5e76\u68c0\u67e5\u4e86\u529f\u80fd\u6b63\u786e\u6027\u548c\u7ed3\u679c\u7a33\u5065\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8868\u660e\uff1a\u4e00\u3001\u8fed\u4ee3\u5f0f\u4ee3\u7801\u91cd\u6784\u7ecf\u5386\u4e86\u4e00\u4e2a\u521d\u59cb\u91cd\u7ec4\u9636\u6bb5\u540e\u8d8b\u4e8e\u7a33\u5b9a\uff1b\u4e8c\u3001\u8fd9\u79cd\u6536\u655b\u6a21\u5f0f\u5bf9\u4e8e\u4e0d\u540c\u7684\u4ee3\u7801\u53d8\u4f53\u6765\u8bf4\u662f\u76f8\u5f53\u7a33\u5065\u7684\uff1b\u4e09\u3001\u9488\u5bf9\u7279\u5b9a\u53ef\u8bfb\u6027\u56e0\u7d20\u7684\u5177\u4f53\u63d0\u793a\u7a0d\u5fae\u6539\u53d8\u4e86\u91cd\u6784\u52a8\u6001\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u91cd\u6784\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5f00\u8f9f\u4e86\u9053\u8def\uff0c\u6bd4\u5982\u8de8\u6a21\u578b\u6bd4\u8f83\u5206\u6790\u4ee5\u53caLLM\u91cd\u6784\u4ee3\u7801\u4e2d\u5176\u4ed6\u8f6f\u4ef6\u8d28\u91cf\u7ef4\u5ea6\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002"}}
{"id": "2602.21319", "categories": ["cs.LG", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.21319", "abs": "https://arxiv.org/abs/2602.21319", "authors": ["Marion Neumeier", "Niklas Ro\u00dfberg", "Michael Botsch", "Wolfgang Utschick"], "title": "Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling", "comment": "Accepted as a conference paper in IEEE Intelligent Vehicles Symposium (IV) 2026, Detroit, MI, United States", "summary": "Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.\n  This work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u6269\u6563\u7684\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6cVMDx\uff0c\u901a\u8fc7DDIM\u91c7\u6837\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u63d0\u9ad8\u4e86\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u591a\u6a21\u6001\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u5728\u516c\u5f00\u6570\u636e\u96c6highD\u4e0a\u5c55\u793a\u4e86\u6bd4cVMD\u66f4\u9ad8\u7684\u51c6\u786e\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff08\u5982cVMD\uff09\u867d\u7136\u5728\u6355\u6349\u591a\u6a21\u5f0f\u672a\u6765\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u91c7\u6837\u901f\u5ea6\u6162\u3001\u5bf9\u751f\u6210\u591a\u6837\u6027\u5229\u7528\u4e0d\u8db3\u4ee5\u53ca\u573a\u666f\u7f16\u7801\u8106\u5f31\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6846\u67b6cVMDx\u6765\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u4e2d\u8f68\u8ff9\u9884\u6d4b\u7684\u51c6\u786e\u6027\u53ca\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u3002", "method": "\u5f15\u5165\u4e86cVMDx\u6846\u67b6\uff0c\u91c7\u7528DDIM\u91c7\u6837\u6280\u672f\u5927\u5e45\u51cf\u5c11\u4e86\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u901a\u8fc7\u62df\u5408\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4ece\u751f\u6210\u7684\u8f68\u8ff9\u4e2d\u63d0\u4f9b\u53ef\u5904\u7406\u7684\u591a\u6a21\u6001\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u8bc4\u4f30\u4e86CVQ-VAE\u53d8\u4f53\u7528\u4e8e\u573a\u666f\u7f16\u7801\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u516c\u5f00\u53ef\u7528\u7684highD\u6570\u636e\u96c6\u4e0a\uff0ccVMDx\u76f8\u6bd4cVMD\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\uff0c\u800c\u4e14\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u80fd\u591f\u5b9e\u73b0\u5b8c\u5168\u968f\u673a\u5316\u7684\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u3002", "conclusion": "cVMDx\u4f5c\u4e3a\u4e00\u79cd\u589e\u5f3a\u578b\u7684\u57fa\u4e8e\u6269\u6563\u7684\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e00\u4e9b\u5173\u952e\u9650\u5236\uff0c\u4e3a\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u9760\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2602.22158", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.22158", "abs": "https://arxiv.org/abs/2602.22158", "authors": ["Minqiu Sun", "Xin Huang", "Luanzheng Guo", "Nathan R. Tallent", "Kento Sato", "Dong Dai"], "title": "LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models", "comment": "9 pages, 3 figures, accepted at PDSW'25", "summary": "Checkpointing is essential for fault tolerance in training large language models (LLMs). However, existing methods, regardless of their I/O strategies, periodically store the entire model and optimizer states, incurring substantial storage overhead and resource contention. Recent studies reveal that updates across LLM layers are highly non-uniform. Across training steps, some layers may undergo more significant changes, while others remain relatively stable or even unchanged. This suggests that selectively checkpointing only layers with significant updates could reduce overhead without harming training. Implementing such selective strategies requires fine-grained control over both weights and optimizer states, which no current tool provides. To address this gap, we propose \\texttt{LLMTailor}, a checkpoint-merging framework that filters and assembles layers from different checkpoints to form a composite checkpoint. Our evaluation indicates that LLMTailor can work with different selective checkpointing strategies and effectively reduce checkpoint size (e.g., 4.3 times smaller for Llama3.1-8B) and checkpoint time (e.g., 2.8 times faster for Qwen2.5-7B) while maintaining model quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLLMTailor\u7684\u68c0\u67e5\u70b9\u5408\u5e76\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u901a\u8fc7\u9009\u62e9\u6027\u5730\u5b58\u50a8\u6709\u663e\u8457\u66f4\u65b0\u7684\u5c42\u6765\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u5b58\u50a8\u5f00\u9500\u548c\u8d44\u6e90\u7ade\u4e89\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u51cf\u5c0f\u68c0\u67e5\u70b9\u5927\u5c0f\u548c\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bad\u7ec3\u4e2d\u7684\u68c0\u67e5\u70b9\u6280\u672f\u867d\u7136\u5bf9\u4e8e\u5bb9\u9519\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u4e3a\u5b83\u4eec\u9700\u8981\u5b9a\u671f\u5b58\u50a8\u6574\u4e2a\u6a21\u578b\u53ca\u5176\u4f18\u5316\u5668\u7684\u72b6\u6001\uff0c\u5bfc\u81f4\u4e86\u5de8\u5927\u7684\u5b58\u50a8\u5f00\u9500\u548c\u8d44\u6e90\u7ade\u4e89\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u4e2d\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u66f4\u65b0\u662f\u975e\u5747\u5300\u5206\u5e03\u7684\uff0c\u8fd9\u6697\u793a\u7740\u53ea\u5bf9\u90a3\u4e9b\u7ecf\u5386\u4e86\u91cd\u8981\u66f4\u65b0\u7684\u5c42\u8fdb\u884c\u9009\u62e9\u6027\u68c0\u67e5\u70b9\u53ef\u80fd\u662f\u51cf\u5c11\u5f00\u9500\u7684\u4e00\u4e2a\u6709\u6548\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u76ee\u524d\u6ca1\u6709\u5de5\u5177\u80fd\u591f\u63d0\u4f9b\u5bf9\u6743\u91cd\u548c\u4f18\u5316\u5668\u72b6\u6001\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u4ee5\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u6311\u6218\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86LLMTailor\uff0c\u8fd9\u662f\u4e00\u4e2a\u68c0\u67e5\u70b9\u5408\u5e76\u6846\u67b6\uff0c\u5b83\u80fd\u4ece\u4e0d\u540c\u7684\u68c0\u67e5\u70b9\u4e2d\u7b5b\u9009\u5e76\u7ec4\u88c5\u5c42\u4ee5\u5f62\u6210\u4e00\u4e2a\u590d\u5408\u68c0\u67e5\u70b9\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cLLMTailor\u5141\u8bb8\u4f7f\u7528\u5404\u79cd\u9009\u62e9\u6027\u68c0\u67e5\u70b9\u7b56\u7565\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cLLMTailor\u4e0d\u4ec5\u80fd\u591f\u517c\u5bb9\u591a\u79cd\u9009\u62e9\u6027\u68c0\u67e5\u70b9\u7b56\u7565\uff0c\u5e76\u4e14\u5728\u51cf\u5c11\u68c0\u67e5\u70b9\u5927\u5c0f\uff08\u4f8b\u5982Llama3.1-8B\u51cf\u5c11\u4e864.3\u500d\uff09\u4ee5\u53ca\u52a0\u5feb\u68c0\u67e5\u70b9\u8fc7\u7a0b\uff08\u4f8b\u5982Qwen2.5-7B\u5feb\u4e862.8\u500d\uff09\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6a21\u578b\u7684\u8d28\u91cf\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u7528\u5982LLMTailor\u8fd9\u6837\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5927\u5e45\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u671f\u95f4\u7684\u5b58\u50a8\u9700\u6c42\u548c\u76f8\u5173\u6210\u672c\u3002"}}
{"id": "2602.21997", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21997", "abs": "https://arxiv.org/abs/2602.21997", "authors": ["WeiZhe Xu", "Mengyu Liu", "Fanxin Kong"], "title": "Enhancing LLM-Based Test Generation by Eliminating Covered Code", "comment": "9 pages, 4 figures, supplementary material included", "summary": "Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4fe1\u606f\u68c0\u7d22\u548c\u8fed\u4ee3\u5f0f\u4ee3\u7801\u6d88\u9664\u6d4b\u8bd5\u751f\u6210\u4e24\u6b65\u6cd5\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5bf9\u590d\u6742\u65b9\u6cd5\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u5e76\u5728\u5f00\u6e90\u9879\u76ee\u8bc4\u4f30\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u641c\u7d22\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6848\u5bf9\u4e8e\u5c0f\u800c\u5b64\u7acb\u7684\u4ee3\u7801\u7247\u6bb5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u7684\u5f85\u6d4b\u65b9\u6cd5\u65f6\u9047\u5230\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u5e76\u63d0\u9ad8\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u53ef\u6269\u5c55\u7684\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a\u9996\u5148\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u9759\u6001\u5206\u6790\u6280\u672f\u76f8\u7ed3\u5408\u8fdb\u884c\u4e0a\u4e0b\u6587\u4fe1\u606f\u68c0\u7d22\uff0c\u6536\u96c6\u4e0e\u5f85\u6d4b\u590d\u6742\u65b9\u6cd5\u76f8\u5173\u7684\u80cc\u666f\u4fe1\u606f\uff1b\u5176\u6b21\uff0c\u91c7\u53d6\u4e00\u79cd\u8fed\u4ee3\u5f0f\u7684\u6d4b\u8bd5\u751f\u6210\u7b56\u7565\uff0c\u4f34\u968f\u4ee3\u7801\u6bb5\u7684\u9010\u6b65\u6392\u9664\uff0c\u6301\u7eed\u751f\u6210\u9488\u5bf9\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u540c\u65f6\u8ddf\u8e2a\u5df2\u5b9e\u73b0\u7684\u8986\u76d6\u7387\u60c5\u51b5\u3002", "result": "\u7ecf\u8fc7\u5bf9\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u8f83\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u641c\u7d22\u7684\u6280\u672f\uff0c\u5728\u63d0\u5347\u590d\u6742\u65b9\u6cd5\u6d4b\u8bd5\u8986\u76d6\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u521b\u65b0\u6027\u7684\u9014\u5f84\u6765\u589e\u5f3a\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u8986\u76d6\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u5177\u6709\u6311\u6218\u6027\u7684\u590d\u6742\u8f6f\u4ef6\u7ec4\u4ef6\u65f6\u3002"}}
{"id": "2602.22020", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.22020", "abs": "https://arxiv.org/abs/2602.22020", "authors": ["Andr\u00e9s Rodriguez", "Juan Cruz Gardey", "Alejandra Garrido"], "title": "Detecting UX smells in Visual Studio Code using LLMs", "comment": "4 pages, 2 figures, 1 table, 3rd International Workshop on Integrated Development Environments (IDE 2026)", "summary": "Integrated Development Environments shape developers' daily experience, yet the empirical study of their usability and user experience (UX) remains limited. This work presents an LLM-assisted approach to detecting UX smells in Visual Studio Code by mining and classifying user-reported issues from the GitHub repository. Using a validated taxonomy and expert review, we identified recurring UX problems that affect the developer experience. Our results show that the majority of UX smells are concentrated in informativeness, clarity, intuitiveness, and efficiency, qualities that developers value most.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6316\u6398\u548c\u5206\u7c7bGitHub\u4ed3\u5e93\u4e2d\u7528\u6237\u62a5\u544a\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLM\u8f85\u52a9\u7684\u65b9\u6cd5\u6765\u68c0\u6d4bVisual Studio Code\u4e2d\u7684\u7528\u6237\u4f53\u9a8c\u95ee\u9898\uff08UX smells\uff09\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5927\u591a\u6570\u7684\u7528\u6237\u4f53\u9a8c\u95ee\u9898\u96c6\u4e2d\u5728\u4fe1\u606f\u6027\u3001\u6e05\u6670\u5ea6\u3001\u76f4\u89c2\u6027\u548c\u6548\u7387\u4e0a\uff0c\u8fd9\u4e9b\u90fd\u662f\u5f00\u53d1\u8005\u6700\u770b\u91cd\u7684\u54c1\u8d28\u3002", "motivation": "\u96c6\u6210\u5f00\u53d1\u73af\u5883\u5bf9\u5f00\u53d1\u8005\u7684\u65e5\u5e38\u4f53\u9a8c\u6709\u5f88\u5927\u5f71\u54cd\uff0c\u4f46\u5bf9\u5176\u53ef\u7528\u6027\u548c\u7528\u6237\u4f53\u9a8c\u7684\u7814\u7a76\u4ecd\u7136\u6709\u9650\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e00\u60c5\u51b5\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u65b9\u6cd5\u6765\u8bc6\u522b\u8fd9\u4e9b\u5de5\u5177\u4e2d\u5b58\u5728\u7684\u7528\u6237\u4f53\u9a8c\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e2e\u52a9\uff0c\u4eceVisual Studio Code\u7684GitHub\u4ed3\u5e93\u4e2d\u6316\u6398\u5e76\u5206\u7c7b\u4e86\u7528\u6237\u62a5\u544a\u7684\u95ee\u9898\u3002\u63a5\u7740\uff0c\u4f7f\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5206\u7c7b\u6cd5\u53ca\u4e13\u5bb6\u8bc4\u5ba1\u6765\u8bc6\u522b\u51fa\u5e38\u89c1\u7684\u7528\u6237\u4f53\u9a8c\u95ee\u9898\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5927\u90e8\u5206\u7528\u6237\u4f53\u9a8c\u95ee\u9898\u4e3b\u8981\u51fa\u73b0\u5728\u4fe1\u606f\u6027\u3001\u6e05\u6670\u5ea6\u3001\u76f4\u89c2\u6027\u4ee5\u53ca\u6548\u7387\u8fd9\u51e0\u4e2a\u65b9\u9762\uff0c\u800c\u8fd9\u4e9b\u90fd\u662f\u5f00\u53d1\u8005\u6700\u4e3a\u91cd\u89c6\u7684\u8d28\u91cf\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5728IDEs\u4e2d\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u672a\u6765\u6539\u8fdb\u7684\u65b9\u5411\u5e94\u96c6\u4e2d\u5728\u63d0\u9ad8\u4fe1\u606f\u5448\u73b0\u8d28\u91cf\u3001\u754c\u9762\u6e05\u6670\u5ea6\u3001\u64cd\u4f5c\u76f4\u89c2\u6027\u4ee5\u53ca\u6574\u4f53\u6548\u7387\u7b49\u65b9\u9762\u3002"}}
{"id": "2602.21803", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21803", "abs": "https://arxiv.org/abs/2602.21803", "authors": ["Luisa Gerlach", "Tobias K\u00f6ppl", "Ren\u00e8 Zander", "Nicole Schweikardt", "Stefanie Scherzinger"], "title": "Quantum Computing for Query Containment of Conjunctive Queries", "comment": null, "summary": "We address the problem of checking query containment, a foundational problem in database research. Although extensively studied in theory research, optimization opportunities arising from query containment are not fully leveraged in commercial database systems, due to the high computational complexity and sometimes even undecidability of the underlying decision problem. In this article, we present the first approach to applying quantum computing to the query containment problem for conjunctive queries under set semantics. We propose a novel formulation as an optimization problem that can be solved on gate-based quantum hardware, and in some cases directly maps to quantum annealers. We formally prove this formulation to be correct and present a prototype implementation which we evaluate using simulator software as well as quantum devices. Our experiments successfully demonstrate that our approach is sound and scales within the current limitations of quantum hardware. In doing so, we show that quantum optimization can effectively address this problem. Thereby, we contribute a new computational perspective on the query containment problem.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c1d\u8bd5\u5c06\u91cf\u5b50\u8ba1\u7b97\u5e94\u7528\u4e8e\u96c6\u5408\u8bed\u4e49\u4e0b\u7684\u5408\u53d6\u67e5\u8be2\u7684\u67e5\u8be2\u5305\u542b\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u5728\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u786c\u4ef6\u4e0a\u89e3\u51b3\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u76f4\u63a5\u6620\u5c04\u5230\u91cf\u5b50\u9000\u706b\u5668\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u662f\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\uff0c\u4e3a\u67e5\u8be2\u5305\u542b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u89c6\u89d2\u3002", "motivation": "\u5c3d\u7ba1\u67e5\u8be2\u5305\u542b\u95ee\u9898\u662f\u6570\u636e\u5e93\u7814\u7a76\u4e2d\u7684\u4e00\u4e2a\u57fa\u7840\u95ee\u9898\uff0c\u5e76\u4e14\u5728\u7406\u8bba\u7814\u7a76\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u63a2\u8ba8\uff0c\u4f46\u7531\u4e8e\u5176\u80cc\u540e\u7684\u51b3\u7b56\u95ee\u9898\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u751a\u81f3\u6709\u65f6\u4e0d\u53ef\u5224\u5b9a\uff0c\u56e0\u6b64\u5546\u4e1a\u6570\u636e\u5e93\u7cfb\u7edf\u5c1a\u672a\u5145\u5206\u5229\u7528\u7531\u67e5\u8be2\u5305\u542b\u5e26\u6765\u7684\u4f18\u5316\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5c06\u67e5\u8be2\u5305\u542b\u95ee\u9898\u4f5c\u4e3a\u4f18\u5316\u95ee\u9898\u6765\u5904\u7406\uff0c\u8be5\u95ee\u9898\u53ef\u4ee5\u5728\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u786c\u4ef6\u4e0a\u6c42\u89e3\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u76f4\u63a5\u6620\u5c04\u5230\u91cf\u5b50\u9000\u706b\u5668\u4e0a\u3002", "result": "\u6b63\u5f0f\u8bc1\u660e\u4e86\u8be5\u5f62\u5f0f\u5316\u7684\u6b63\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u8f6f\u4ef6\u548c\u91cf\u5b50\u8bbe\u5907\u8fdb\u884c\u4e86\u539f\u578b\u5b9e\u73b0\u8bc4\u4f30\u3002\u5b9e\u9a8c\u6210\u529f\u5730\u5c55\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5728\u5f53\u524d\u91cf\u5b50\u786c\u4ef6\u9650\u5236\u5185\u5de5\u4f5c\u826f\u597d\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u91cf\u5b50\u4f18\u5316\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3\u67e5\u8be2\u5305\u542b\u95ee\u9898\uff0c\u4e3a\u8fd9\u4e00\u9886\u57df\u8d21\u732e\u4e86\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u89c6\u89d2\u3002"}}
{"id": "2602.21321", "categories": ["cs.LG", "cs.AR", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21321", "abs": "https://arxiv.org/abs/2602.21321", "authors": ["Quan Xiao", "Jindan Li", "Zhaoxian Wu", "Tayfun Gokmen", "Tianyi Chen"], "title": "Dynamic Symmetric Point Tracking: Tackling Non-ideal Reference in Analog In-memory Training", "comment": null, "summary": "Analog in-memory computing (AIMC) performs computation directly within resistive crossbar arrays, offering an energy-efficient platform to scale large vision and language models. However, non-ideal analog device properties make the training on AIMC devices challenging. In particular, its update asymmetry can induce a systematic drift of weight updates towards a device-specific symmetric point (SP), which typically does not align with the optimum of the training objective. To mitigate this bias, most existing works assume the SP is known and pre-calibrate it to zero before training by setting the reference point as the SP. Nevertheless, calibrating AIMC devices requires costly pulse updates, and residual calibration error can directly degrade training accuracy. In this work, we present the first theoretical characterization of the pulse complexity of SP calibration and the resulting estimation error. We further propose a dynamic SP estimation method that tracks the SP during model training, and establishes its convergence guarantees. In addition, we develop an enhanced variant based on chopping and filtering techniques from digital signal processing. Numerical experiments demonstrate both the efficiency and effectiveness of the proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u6a21\u62df\u5185\u5b58\u8ba1\u7b97\u8bbe\u5907\u4e2d\u6743\u91cd\u66f4\u65b0\u4e0d\u5bf9\u79f0\u6027\u95ee\u9898\u7684\u52a8\u6001\u5bf9\u79f0\u70b9(SP)\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5728\u6a21\u62df\u5185\u5b58\u8ba1\u7b97(AIMC)\u8bbe\u5907\u4e0a\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u7531\u4e8e\u975e\u7406\u60f3\u6a21\u62df\u5668\u4ef6\u7279\u6027\u5bfc\u81f4\u6743\u91cd\u66f4\u65b0\u5b58\u5728\u4e0d\u5bf9\u79f0\u6027\uff0c\u8fd9\u4f1a\u5f15\u8d77\u6743\u91cd\u66f4\u65b0\u5411\u7279\u5b9a\u4e8e\u8bbe\u5907\u7684\u5bf9\u79f0\u70b9(SP)\u7cfb\u7edf\u6f02\u79fb\uff0c\u800c\u8fd9\u4e00\u70b9\u901a\u5e38\u4e0e\u8bad\u7ec3\u76ee\u6807\u7684\u6700\u4f73\u503c\u4e0d\u4e00\u81f4\u3002\u73b0\u6709\u89e3\u51b3\u6b64\u504f\u5dee\u7684\u65b9\u6cd5\u9700\u8981\u9884\u5148\u6821\u51c6SP\u81f3\u96f6\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u6210\u672c\u9ad8\u6602\u4e14\u6b8b\u7559\u6821\u51c6\u8bef\u5dee\u4f1a\u76f4\u63a5\u5f71\u54cd\u8bad\u7ec3\u51c6\u786e\u6027\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5bf9SP\u6821\u51c6\u6240\u9700\u7684\u8109\u51b2\u590d\u6742\u5ea6\u53ca\u5176\u4ea7\u751f\u7684\u4f30\u8ba1\u8bef\u5dee\u8fdb\u884c\u4e86\u7406\u8bba\u8868\u5f81\u3002\u63a5\u7740\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u4ee5\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8ddf\u8e2aSP\u4f4d\u7f6e\u7684\u52a8\u6001SP\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u57fa\u4e8e\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u65a9\u6ce2\u548c\u6ee4\u6ce2\u6280\u672f\u5f00\u53d1\u4e86\u8be5\u65b9\u6cd5\u7684\u4e00\u4e2a\u589e\u5f3a\u7248\u672c\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u56e0SP\u504f\u79fb\u5f15\u8d77\u7684\u8bad\u7ec3\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898\uff0c\u800c\u4e14\u63d0\u9ad8\u4e86AIMC\u8bbe\u5907\u4e0a\u6a21\u578b\u8bad\u7ec3\u7684\u6574\u4f53\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u52a8\u6001SP\u4f30\u8ba1\u673a\u5236\uff0c\u672c\u7814\u7a76\u4e3a\u514b\u670dAIMC\u8bbe\u5907\u4e0a\u7684\u8bad\u7ec3\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u8fd9\u7c7b\u8282\u80fd\u8ba1\u7b97\u5e73\u53f0\u5728\u5927\u89c4\u6a21\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.22076", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.22076", "abs": "https://arxiv.org/abs/2602.22076", "authors": ["Eduardo Miranda"], "title": "Visual Milestone Planning in a Hybrid Development Context", "comment": "15 pages, Presented at QUATIC 2023", "summary": "This paper explains the Visual Milestone Planning (VMP) method using an agile vocabulary to facilitate its adoption by agile practitioners as a front end for a hybrid development process. VMP is a visual and collaborative planning approach which promotes a shared understanding of the work approach and commitment through the direct manipulation by team members of the reified planning constructs involved in the development of the plan. Once the product backlog has been established and relevant milestones identified, a novel construct called the milestone planning matrix is used to document the allocation of product backlog items to milestones. The milestones due dates are later determined by grouping sticky notes representing the work to be performed into time-boxes called work packages and accommodating them on a resource and time scaled scheduling canvas very much as it would be done in a Tetris game.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u89c6\u89c9\u91cc\u7a0b\u7891\u89c4\u5212\uff08VMP\uff09\u65b9\u6cd5\uff0c\u5b83\u91c7\u7528\u654f\u6377\u8bcd\u6c47\u4ee5\u4fc3\u8fdb\u654f\u6377\u5b9e\u8df5\u8005\u63a5\u53d7\u6b64\u65b9\u6cd5\u4f5c\u4e3a\u6df7\u5408\u5f00\u53d1\u8fc7\u7a0b\u7684\u524d\u7aef\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u79f0\u4e3a\u91cc\u7a0b\u7891\u8ba1\u5212\u77e9\u9635\u7684\u65b0\u6784\u9020\u6765\u8bb0\u5f55\u4ea7\u54c1\u5f85\u529e\u4e8b\u9879\u5230\u91cc\u7a0b\u7891\u7684\u5206\u914d\uff0c\u5e76\u901a\u8fc7\u7c7b\u4f3c\u4fc4\u7f57\u65af\u65b9\u5757\u6e38\u620f\u7684\u65b9\u5f0f\u5728\u8d44\u6e90\u548c\u65f6\u95f4\u6bd4\u4f8b\u8c03\u5ea6\u753b\u5e03\u4e0a\u5b89\u6392\u5de5\u4f5c\u5305\u6765\u786e\u5b9a\u91cc\u7a0b\u7891\u7684\u5230\u671f\u65e5\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u654f\u6377\u5b9e\u8df5\u8005\u80fd\u591f\u66f4\u5bb9\u6613\u5730\u91c7\u7528\u89c6\u89c9\u91cc\u7a0b\u7891\u89c4\u5212\u65b9\u6cd5\uff0c\u4f5c\u4e3a\u6df7\u5408\u5f00\u53d1\u6d41\u7a0b\u7684\u4e00\u90e8\u5206\uff0c\u4ece\u800c\u63d0\u9ad8\u56e2\u961f\u6210\u5458\u4e4b\u95f4\u7684\u5171\u540c\u7406\u89e3\u548c\u627f\u8bfa\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u89c6\u89c9\u91cc\u7a0b\u7891\u89c4\u5212\uff08VMP\uff09\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u62ec\u4e86\u91cc\u7a0b\u7891\u8ba1\u5212\u77e9\u9635\u8fd9\u4e00\u65b0\u5de5\u5177\u6765\u8bb0\u5f55\u4ea7\u54c1\u5f85\u529e\u4e8b\u9879\u4e0e\u91cc\u7a0b\u7891\u4e4b\u95f4\u7684\u5173\u8054\uff1b\u5e76\u901a\u8fc7\u5c06\u4ee3\u8868\u5de5\u4f5c\u7684\u4fbf\u7b7e\u5206\u7ec4\u653e\u5165\u88ab\u79f0\u4e3a\u5de5\u4f5c\u5305\u7684\u65f6\u95f4\u76d2\u4e2d\uff0c\u5728\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u73a9\u4fc4\u7f57\u65af\u65b9\u5757\u6e38\u620f\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e8e\u8d44\u6e90\u53ca\u65f6\u95f4\u6807\u5ea6\u8ba1\u5212\u753b\u5e03\u4e0a\u8fdb\u884c\u5e03\u5c40\u8c03\u6574\uff0c\u4ee5\u6b64\u6765\u51b3\u5b9a\u5404\u91cc\u7a0b\u7891\u7684\u5177\u4f53\u622a\u6b62\u65e5\u671f\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u654f\u6377\u56e2\u961f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89c6\u5316\u4e14\u534f\u4f5c\u5f0f\u7684\u89c4\u5212\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u589e\u5f3a\u5bf9\u5de5\u4f5c\u65b9\u6cd5\u7684\u5171\u8bc6\u4ee5\u53ca\u56e2\u961f\u6210\u5458\u95f4\u5bf9\u4e8e\u8ba1\u5212\u6267\u884c\u7684\u8d23\u4efb\u611f\u3002", "conclusion": "\u89c6\u89c9\u91cc\u7a0b\u7891\u89c4\u5212\uff08VMP\uff09\u4f5c\u4e3a\u4e00\u79cd\u7ed3\u5408\u4e86\u654f\u6377\u672f\u8bed\u7684\u76f4\u89c2\u5408\u4f5c\u89c4\u5212\u624b\u6bb5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u654f\u6377\u4ece\u4e1a\u8005\u7406\u89e3\u5e76\u53c2\u4e0e\u5230\u9879\u76ee\u89c4\u5212\u8fc7\u7a0b\u4e2d\uff0c\u540c\u65f6\u652f\u6301\u66f4\u7075\u6d3b\u7684\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2602.21955", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21955", "abs": "https://arxiv.org/abs/2602.21955", "authors": ["Xiu Tang", "Sai Wu", "Dongxiang Zhang", "Feifei Li", "Gang Chen"], "title": "Detecting Logic Bugs of Join Optimizations in DBMS", "comment": null, "summary": "Generation-based testing techniques have shown their effectiveness in detecting logic bugs of DBMS, which are often caused by improper implementation of query optimizers. Nonetheless, existing generation-based debug tools are limited to single-table queries and there is a substantial research gap regarding multi-table queries with join operators. In this paper, we propose TQS, a novel testing framework targeted at detecting logic bugs derived by queries involving multi-table joins. Given a target DBMS, TQS achieves the goal with two key components: Data-guided Schema and Query Generation (DSG) and Knowledge-guided Query Space Exploration (KQE). DSG addresses the key challenge of multi-table query debugging: how to generate ground-truth (query, result) pairs for verification. It adopts the database normalization technique to generate a testing schema and maintains a bitmap index for result tracking. To improve debug efficiency, DSG also artificially inserts some noises into the generated data. To avoid repetitive query space search, KQE forms the problem as isomorphic graph set discovery and combines the graph embedding and weighted random walk for query generation. We evaluated TQS on four popular DBMSs: MySQL, MariaDB, TiDB and the gray release of an industry-leading cloud-native database, anonymized as X-DB. Experimental results show that TQS is effective in finding logic bugs of join optimization in database management systems. It successfully detected 115 bugs within 24 hours, including 31 bugs in MySQL, 30 in MariaDB, 31 in TiDB, and 23 in X-DB respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u6846\u67b6TQS\uff0c\u65e8\u5728\u68c0\u6d4b\u6d89\u53ca\u591a\u8868\u8fde\u63a5\u67e5\u8be2\u7684\u903b\u8f91\u9519\u8bef\u3002\u901a\u8fc7\u6570\u636e\u5bfc\u5411\u7684\u6a21\u5f0f\u548c\u67e5\u8be2\u751f\u6210\uff08DSG\uff09\u4ee5\u53ca\u77e5\u8bc6\u5bfc\u5411\u7684\u67e5\u8be2\u7a7a\u95f4\u63a2\u7d22\uff08KQE\uff09\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0cTQS\u80fd\u591f\u6709\u6548\u5730\u627e\u5230\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e2d\u5173\u4e8e\u8fde\u63a5\u4f18\u5316\u7684\u903b\u8f91\u9519\u8bef\uff0c\u5e76\u5728\u56db\u4e2a\u6d41\u884c\u7684DBMS\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u6210\u529f\u68c0\u6d4b\u5230\u4e86115\u4e2abug\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u751f\u6210\u7684\u8c03\u8bd5\u5de5\u5177\u4ec5\u9650\u4e8e\u5355\u8868\u67e5\u8be2\uff0c\u5bf9\u4e8e\u5305\u542b\u8fde\u63a5\u64cd\u4f5c\u7b26\u7684\u591a\u8868\u67e5\u8be2\u7684\u7814\u7a76\u5b58\u5728\u660e\u663e\u7a7a\u767d\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7279\u522b\u662f\u9488\u5bf9\u7531\u67e5\u8be2\u4f18\u5316\u5668\u4e0d\u5f53\u5b9e\u73b0\u5f15\u8d77\u7684\u903b\u8f91\u9519\u8bef\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "TQS\u91c7\u7528\u4e86\u6570\u636e\u5bfc\u5411\u7684\u6a21\u5f0f\u548c\u67e5\u8be2\u751f\u6210\uff08DSG\uff09\u4e0e\u77e5\u8bc6\u5bfc\u5411\u7684\u67e5\u8be2\u7a7a\u95f4\u63a2\u7d22\uff08KQE\uff09\u3002\u5176\u4e2d\uff0cDSG\u5229\u7528\u6570\u636e\u5e93\u89c4\u8303\u5316\u6280\u672f\u751f\u6210\u6d4b\u8bd5\u67b6\u6784\u5e76\u901a\u8fc7\u4f4d\u56fe\u7d22\u5f15\u8ffd\u8e2a\u7ed3\u679c\uff1b\u800cKQE\u5219\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u540c\u6784\u56fe\u96c6\u53d1\u73b0\uff0c\u5e76\u7ed3\u5408\u56fe\u5d4c\u5165\u4e0e\u52a0\u6743\u968f\u673a\u6e38\u8d70\u4ee5\u751f\u6210\u67e5\u8be2\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTQS\u80fd\u591f\u5728MySQL\u3001MariaDB\u3001TiDB\u53ca\u4e00\u4e2a\u533f\u540d\u7684\u884c\u4e1a\u9886\u5148\u4e91\u539f\u751f\u6570\u636e\u5e93X-DB\u4e0a\u6709\u6548\u8bc6\u522b\u51fa\u7531\u4e8e\u8fde\u63a5\u4f18\u5316\u5bfc\u81f4\u7684\u903b\u8f91\u9519\u8bef\uff0c\u572824\u5c0f\u65f6\u5185\u5171\u53d1\u73b0\u4e86115\u4e2abug\u3002", "conclusion": "TQS\u8bc1\u660e\u4e86\u5176\u5728\u68c0\u6d4b\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u4e2d\u56e0\u591a\u8868\u8fde\u63a5\u67e5\u8be2\u6240\u5f15\u53d1\u903b\u8f91\u9519\u8bef\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.22124", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22124", "abs": "https://arxiv.org/abs/2602.22124", "authors": ["Patrick Tser Jern Kon", "Archana Pradeep", "Ang Chen", "Alexander P. Ellis", "Warren Hunt", "Zijian Wang", "John Yang", "Samuel Thompson"], "title": "SWE-Prot\u00e9g\u00e9: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents", "comment": null, "summary": "Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Prot\u00e9g\u00e9, a post-training framework that reframes software repair as an expert-prot\u00e9g\u00e9 collaboration problem. In SWE-Prot\u00e9g\u00e9, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).", "AI": {"tldr": "\u4ecb\u7ecd\u4e86SWE-Prot\u00e9g\u00e9\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u8f6f\u4ef6\u4fee\u590d\u89c6\u4e3a\u4e13\u5bb6-\u5b66\u5f92\u5408\u4f5c\u95ee\u9898\uff0c\u4f7f\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u957f\u5468\u671f\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u9002\u5e94\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u5904\u7406\u957f\u5468\u671f\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u5b58\u5728\u52a8\u4f5c\u5faa\u73af\u548c\u4f4e\u89e3\u51b3\u7387\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86SWE-Prot\u00e9g\u00e9\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8ba9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u552f\u4e00\u51b3\u7b56\u8005\uff0c\u540c\u65f6\u5b66\u4f1a\u4ece\u5f3a\u5927\u7684\u4e13\u5bb6\u6a21\u578b\u90a3\u91cc\u6709\u9009\u62e9\u5730\u5bfb\u6c42\u6307\u5bfc\u3001\u8bc6\u522b\u505c\u6ede\u72b6\u6001\uff0c\u5e76\u9075\u5faa\u4e13\u5bb6\u53cd\u9988\u3002\u65b9\u6cd5\u7ed3\u5408\u4e86\u57fa\u4e8e\u4e13\u5bb6\u589e\u5f3a\u8f68\u8ff9\u7684\u76d1\u7763\u5fae\u8c03\u4ee5\u53ca\u9f13\u52b1\u907f\u514d\u9000\u5316\u5faa\u73af\u548c\u975e\u751f\u4ea7\u6027\u4e13\u5bb6\u534f\u4f5c\u7684\u81ea\u4e3b\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u5bf9Qwen2.5-Coder-7B-Instruct\u8fdb\u884c\u8f7b\u5ea6\u540e\u8bad\u7ec3\uff0c\u5728SWE-bench Verified\u4e0a\u8fbe\u5230\u4e8642.4%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u76f8\u8f83\u4e8e\u5148\u524d\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6280\u672f\u6709\u4e86+25.4%\u7684\u6539\u8fdb\uff0c\u540c\u65f6\u4ec5\u5c11\u91cf\u4f7f\u7528\u4e13\u5bb6\u5e2e\u52a9\uff08\u6bcf\u4e2a\u4efb\u52a1\u7ea64\u6b21\u8c03\u7528\u548c\u603btoken\u768411%\uff09\u3002", "conclusion": "SWE-Prot\u00e9g\u00e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u4f18\u5316\u4e0e\u4e13\u5bb6\u6a21\u578b\u7684\u5408\u4f5c\u65b9\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002"}}
{"id": "2602.21717", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.21717", "abs": "https://arxiv.org/abs/2602.21717", "authors": ["Sijia Xu", "Fan Li", "Xiaoyang Wang", "Zhengyi Yang", "Xuemin Lin"], "title": "C$^{2}$TC: A Training-Free Framework for Efficient Tabular Data Condensation", "comment": null, "summary": "Tabular data is the primary data format in industrial relational databases, underpinning modern data analytics and decision-making. However, the increasing scale of tabular data poses significant computational and storage challenges to learning-based analytical systems. This highlights the need for data-efficient learning, which enables effective model training and generalization using substantially fewer samples. Dataset condensation (DC) has emerged as a promising data-centric paradigm that synthesizes small yet informative datasets to preserve data utility while reducing storage and training costs. However, existing DC methods are computationally intensive due to reliance on complex gradient-based optimization. Moreover, they often overlook key characteristics of tabular data, such as heterogeneous features and class imbalance. To address these limitations, we introduce C$^{2}$TC (Class-Adaptive Clustering for Tabular Condensation), the first training-free tabular dataset condensation framework that jointly optimizes class allocation and feature representation, enabling efficient and scalable condensation. Specifically, we reformulate the dataset condensation objective into a novel class-adaptive cluster allocation problem (CCAP), which eliminates costly training and integrates adaptive label allocation to handle class imbalance. To solve the NP-hard CCAP, we develop HFILS, a heuristic local search that alternates between soft allocation and class-wise clustering to efficiently obtain high-quality solutions. Moreover, a hybrid categorical feature encoding (HCFE) is proposed for semantics-preserving clustering of heterogeneous discrete attributes. Extensive experiments on 10 real-world datasets demonstrate that C$^{2}$TC improves efficiency by at least 2 orders of magnitude over state-of-the-art baselines, while achieving superior downstream performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u8868\u683c\u6570\u636e\u96c6\u538b\u7f29\u6846\u67b6C$^{2}$TC\uff0c\u901a\u8fc7\u4f18\u5316\u7c7b\u522b\u5206\u914d\u548c\u7279\u5f81\u8868\u793a\u6765\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u6570\u636e\u538b\u7f29\u3002", "motivation": "\u968f\u7740\u8868\u683c\u6570\u636e\u89c4\u6a21\u7684\u589e\u957f\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u5206\u6790\u7cfb\u7edf\u9762\u4e34\u7740\u8ba1\u7b97\u548c\u5b58\u50a8\u65b9\u9762\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\u65b9\u5f0f\u3002\u73b0\u6709\u7684\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u4ee5\u53ca\u5ffd\u89c6\u8868\u683c\u6570\u636e\u7279\u6027\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86C$^{2}$TC\u6846\u67b6\uff0c\u5b83\u5c06\u6570\u636e\u96c6\u538b\u7f29\u76ee\u6807\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u65b0\u9896\u7684\u81ea\u9002\u5e94\u7c7b\u7fa4\u5206\u914d\u95ee\u9898(CCAP)\uff0c\u5e76\u5f00\u53d1\u4e86HFILS\u542f\u53d1\u5f0f\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u89e3\u51b3CCAP\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5206\u7c7b\u7279\u5f81\u7f16\u7801(HCFE)\u4ee5\u4fdd\u6301\u5f02\u6784\u79bb\u6563\u5c5e\u6027\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0cC$^{2}$TC\u81f3\u5c11\u63d0\u9ad8\u4e86\u4e24\u4e2a\u6570\u91cf\u7ea7\u7684\u6548\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "C$^{2}$TC\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u8868\u683c\u6570\u636e\u96c6\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u63d0\u9ad8\u6548\u7387\u7684\u540c\u65f6\u4e5f\u4fdd\u8bc1\u4e86\u9ad8\u8d28\u91cf\u7684\u7ed3\u679c\uff0c\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21328", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.21328", "abs": "https://arxiv.org/abs/2602.21328", "authors": ["Teodor Vanislavov Marinov", "Mehryar Mohri", "Princewill Okoroafor", "Jon Schneider", "Julian Zimmert"], "title": "Efficient Opportunistic Approachability", "comment": null, "summary": "We study the problem of opportunistic approachability: a generalization of Blackwell approachability where the learner would like to obtain stronger guarantees (i.e., approach a smaller set) when their adversary limits themselves to a subset of their possible action space. Bernstein et al. (2014) introduced this problem in 2014 and presented an algorithm that guarantees sublinear approachability rates for opportunistic approachability. However, this algorithm requires the ability to produce calibrated online predictions of the adversary's actions, a problem whose standard implementations require time exponential in the ambient dimension and result in approachability rates that scale as $T^{-O(1/d)}$. In this paper, we present an efficient algorithm for opportunistic approachability that achieves a rate of $O(T^{-1/4})$ (and an inefficient one that achieves a rate of $O(T^{-1/3})$), bypassing the need for an online calibration subroutine. Moreover, in the case where the dimension of the adversary's action set is at most two, we show it is possible to obtain the optimal rate of $O(T^{-1/2})$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u673a\u4f1a\u63a5\u8fd1\u6027\u7b97\u6cd5\uff0c\u65e0\u9700\u5728\u7ebf\u6821\u51c6\u5b50\u7a0b\u5e8f\u5373\u53ef\u5b9e\u73b0$O(T^{-1/4})$\u7684\u63a5\u8fd1\u7387\uff0c\u5e76\u4e14\u5728\u5bf9\u624b\u884c\u52a8\u96c6\u7ef4\u5ea6\u6700\u591a\u4e3a2\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u8fbe\u5230\u6700\u4f18\u7684$O(T^{-1/2})$\u63a5\u8fd1\u7387\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u5728\u5bf9\u624b\u9650\u5236\u81ea\u5df1\u884c\u52a8\u7a7a\u95f4\u65f6\uff0c\u5b66\u4e60\u8005\u80fd\u591f\u83b7\u5f97\u66f4\u5f3a\u7684\u4fdd\u8bc1\uff08\u5373\u63a5\u8fd1\u66f4\u5c0f\u7684\u96c6\u5408\uff09\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u7b97\u6cd5\u9700\u8981\u80fd\u591f\u4ea7\u751f\u5bf9\u624b\u52a8\u4f5c\u7684\u5728\u7ebf\u6821\u51c6\u9884\u6d4b\uff0c\u8fd9\u901a\u5e38\u5bfc\u81f4\u8ba1\u7b97\u65f6\u95f4\u6307\u6570\u7ea7\u589e\u957f\u5e76\u4e14\u63a5\u8fd1\u7387\u8f83\u4f4e\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u4f1a\u63a5\u8fd1\u6027\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4e0d\u9700\u8981\u4f9d\u8d56\u4e8e\u5728\u7ebf\u6821\u51c6\u5b50\u7a0b\u5e8f\u6765\u9884\u6d4b\u5bf9\u624b\u7684\u52a8\u4f5c\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u597d\u7684\u63a5\u8fd1\u7387\u3002", "result": "\u65b0\u7b97\u6cd5\u5bf9\u4e8e\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u673a\u4f1a\u63a5\u8fd1\u6027\u80fd\u8fbe\u5230$O(T^{-1/4})$\u7684\u901f\u5ea6\uff1b\u53e6\u5916\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f4e\u6548\u7248\u672c\uff0c\u5176\u901f\u5ea6\u4e3a$O(T^{-1/3})$\u3002\u7279\u522b\u5730\uff0c\u5f53\u5bf9\u624b\u884c\u52a8\u96c6\u7684\u7ef4\u5ea6\u4e0d\u8d85\u8fc72\u65f6\uff0c\u53ef\u4ee5\u83b7\u5f97\u6700\u4f73\u901f\u5ea6$O(T^{-1/2})$\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u514b\u670d\u4e86\u4e4b\u524d\u65b9\u6cd5\u4e2d\u5bf9\u5728\u7ebf\u6821\u51c6\u9884\u6d4b\u7684\u9700\u6c42\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u673a\u4f1a\u63a5\u8fd1\u6027\u95ee\u9898\u4e2d\u7684\u63a5\u8fd1\u901f\u7387\uff0c\u7279\u522b\u662f\u5728\u4f4e\u7ef4\u573a\u666f\u4e0b\u8fbe\u5230\u4e86\u6700\u4f18\u8868\u73b0\u3002"}}
{"id": "2602.21381", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2602.21381", "abs": "https://arxiv.org/abs/2602.21381", "authors": ["Gene Yu", "Ce Guo", "Wayne Luk"], "title": "VCDF: A Validated Consensus-Driven Framework for Time Series Causal Discovery", "comment": "This paper has been accepted to PAKDD 2026. Please cite the proceedings version when available", "summary": "Time series causal discovery is essential for understanding dynamic systems, yet many existing methods remain sensitive to noise, non-stationarity, and sampling variability. We propose the Validated Consensus-Driven Framework (VCDF), a simple and method-agnostic layer that improves robustness by evaluating the stability of causal relations across blocked temporal subsets. VCDF requires no modification to base algorithms and can be applied to methods such as VAR-LiNGAM and PCMCI. Experiments on synthetic datasets show that VCDF improves VAR-LiNGAM by approximately 0.08-0.12 in both window and summary F1 scores across diverse data characteristics, with gains most pronounced for moderate-to-long sequences. The framework also benefits from longer sequences, yielding up to 0.18 absolute improvement on time series of length 1000 and above. Evaluations on simulated fMRI data and IT-monitoring scenarios further demonstrate enhanced stability and structural accuracy under realistic noise conditions. VCDF provides an effective reliability layer for time series causal discovery without altering underlying modeling assumptions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVCDF\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bc4\u4f30\u65f6\u95f4\u5b50\u96c6\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u7a33\u5b9a\u6027\u6765\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u7684\u9c81\u68d2\u6027\u3002\u65e0\u9700\u4fee\u6539\u57fa\u7840\u7b97\u6cd5\u5373\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u65b9\u6cd5\u5982VAR-LiNGAM\u548cPCMCI\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u96c6\u3001\u6a21\u62dffMRI\u6570\u636e\u53caIT\u76d1\u63a7\u573a\u666f\u4e0b\u663e\u793a\u51fa\u6539\u8fdb\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5bf9\u566a\u58f0\u3001\u975e\u5e73\u7a33\u6027\u548c\u91c7\u6837\u53d8\u5f02\u6027\u654f\u611f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u9ad8\u8fd9\u4e9b\u65b9\u6cd5\u9c81\u68d2\u6027\u7684\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86\u9a8c\u8bc1\u5171\u8bc6\u9a71\u52a8\u6846\u67b6\uff08VCDF\uff09\uff0c\u5b83\u901a\u8fc7\u8de8\u5206\u5757\u65f6\u95f4\u5b50\u96c6\u8bc4\u4f30\u56e0\u679c\u5173\u7cfb\u7684\u7a33\u5b9a\u6027\u6765\u589e\u5f3a\u4efb\u4f55\u7ed9\u5b9a\u56e0\u679c\u53d1\u73b0\u6280\u672f\u7684\u53ef\u9760\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVCDF\u53ef\u4ee5\u5728\u4e0d\u540c\u7279\u5f81\u7684\u6570\u636e\u4e0a\u63d0\u9ad8VAR-LiNGAM\u7b49\u65b9\u6cd5\u7684\u7a97\u53e3\u548c\u6458\u8981F1\u5206\u6570\u7ea60.08-0.12\uff0c\u5728\u957f\u5ea6\u4e3a1000\u53ca\u4ee5\u4e0a\u7684\u5e8f\u5217\u4e2d\u53ef\u8fbe0.18\u7684\u7edd\u5bf9\u6539\u5584\u3002\u6b64\u5916\uff0c\u5728\u6a21\u62dffMRI\u6570\u636e\u4e0eIT\u76d1\u63a7\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e0b\u4e5f\u5c55\u793a\u4e86\u66f4\u597d\u7684\u7ed3\u6784\u51c6\u786e\u5ea6\u4e0e\u7a33\u5b9a\u6027\u3002", "conclusion": "VCDF\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u53ef\u9760\u6027\u5c42\uff0c\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u5e95\u5c42\u5efa\u6a21\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.21390", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21390", "abs": "https://arxiv.org/abs/2602.21390", "authors": ["Gabriele Farina", "Juan Carlos Perdomo"], "title": "Defensive Generation", "comment": null, "summary": "We study the problem of efficiently producing, in an online fashion, generative models of scalar, multiclass, and vector-valued outcomes that cannot be falsified on the basis of the observed data and a pre-specified collection of computational tests. Our contributions are twofold. First, we expand on connections between online high-dimensional multicalibration with respect to an RKHS and recent advances in expected variational inequality problems, enabling efficient algorithms for the former. We then apply this algorithmic machinery to the problem of outcome indistinguishability. Our procedure, Defensive Generation, is the first to efficiently produce online outcome indistinguishable generative models of non-Bernoulli outcomes that are unfalsifiable with respect to infinite classes of tests, including those that examine higher-order moments of the generated distributions. Furthermore, our method runs in near-linear time in the number of samples and achieves the optimal, vanishing T^{-1/2} rate for generation error.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aDefensive Generation\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u7ebf\u751f\u6210\u4e0d\u53ef\u88ab\u65e0\u9650\u7c7b\u6d4b\u8bd5\uff08\u5305\u62ec\u68c0\u67e5\u751f\u6210\u5206\u5e03\u7684\u9ad8\u9636\u77e9\uff09\u6240\u8bc1\u4f2a\u7684\u975e\u4f2f\u52aa\u5229\u7ed3\u679c\u7684\u751f\u6210\u6a21\u578b\u3002\u6b64\u65b9\u6cd5\u5728\u6837\u672c\u6570\u91cf\u4e0a\u51e0\u4e4e\u7ebf\u6027\u65f6\u95f4\u8fd0\u884c\uff0c\u5e76\u8fbe\u5230\u4e86\u751f\u6210\u8bef\u5dee\u6700\u4f18\u7684T^{-1/2}\u6d88\u5931\u7387\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u6709\u6548\u5730\u5728\u7ebf\u751f\u6210\u6807\u91cf\u3001\u591a\u5206\u7c7b\u548c\u5411\u91cf\u503c\u7ed3\u679c\u7684\u751f\u6210\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4e0d\u80fd\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u6570\u636e\u4ee5\u53ca\u9884\u5b9a\u4e49\u7684\u4e00\u7cfb\u5217\u8ba1\u7b97\u6d4b\u8bd5\u88ab\u8bc1\u4f2a\u3002", "method": "\u901a\u8fc7\u5c06\u5728\u7ebf\u9ad8\u7ef4\u591a\u6821\u51c6\u4e0eRKHS\u7684\u5173\u7cfb\u6269\u5c55\u5230\u9884\u671f\u53d8\u5206\u4e0d\u7b49\u5f0f\u95ee\u9898\u7684\u6700\u65b0\u8fdb\u5c55\u4e0a\uff0c\u5f00\u53d1\u4e86\u9488\u5bf9\u524d\u8005\uff08\u5373\u5728\u7ebf\u9ad8\u7ef4\u591a\u6821\u51c6\uff09\u7684\u6709\u6548\u7b97\u6cd5\u3002\u63a5\u7740\uff0c\u5c06\u8fd9\u79cd\u7b97\u6cd5\u673a\u5236\u5e94\u7528\u4e8e\u7ed3\u679c\u4e0d\u53ef\u533a\u5206\u6027\u7684\u95ee\u9898\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53eb\u505aDefensive Generation\u7684\u8fc7\u7a0b\u3002", "result": "Defensive Generation\u662f\u9996\u4e2a\u80fd\u591f\u6709\u6548\u5728\u7ebf\u751f\u4ea7\u51fa\u5bf9\u4e8e\u65e0\u9650\u7c7b\u522b\u6d4b\u8bd5\uff08\u5305\u542b\u90a3\u4e9b\u68c0\u67e5\u751f\u6210\u5206\u5e03\u66f4\u9ad8\u9636\u77e9\u7684\u6d4b\u8bd5\uff09\u6765\u8bf4\u4e0d\u53ef\u8bc1\u4f2a\u7684\u975e\u4f2f\u52aa\u5229\u7ed3\u679c\u751f\u6210\u6a21\u578b\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u6267\u884c\u901f\u5ea6\u63a5\u8fd1\u4e8e\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u8fbe\u6210\u4e86T^{-1/2}\u8fd9\u4e2a\u6700\u4f18\u6e10\u8fdb\u9519\u8bef\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u62d3\u5c55\u4e86\u5728\u7ebf\u9ad8\u7ef4\u591a\u6821\u51c6\u4e0e\u7279\u5b9a\u6570\u5b66\u95ee\u9898\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8fd8\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9\u5e7f\u6cdb\u6d4b\u8bd5\u96c6\u90fd\u5177\u6709\u9c81\u68d2\u6027\u7684\u9ad8\u6548\u5728\u7ebf\u751f\u6210\u6a21\u578b\u3002"}}
{"id": "2602.21399", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21399", "abs": "https://arxiv.org/abs/2602.21399", "authors": ["Alina Devkota", "Jacob Thrasher", "Donald Adjeroh", "Binod Bhattarai", "Prashnna K. Gyawali"], "title": "FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning", "comment": "Accepted to CVPR 2026 (Findings Track)", "summary": "Federated Learning (FL) enables collaborative model training across multiple clients without sharing their private data. However, data heterogeneity across clients leads to client drift, which degrades the overall generalization performance of the model. This effect is further compounded by overemphasis on poorly performing clients. To address this problem, we propose FedVG, a novel gradient-based federated aggregation framework that leverages a global validation set to guide the optimization process. Such a global validation set can be established using readily available public datasets, ensuring accessibility and consistency across clients without compromising privacy. In contrast to conventional approaches that prioritize client dataset volume, FedVG assesses the generalization ability of client models by measuring the magnitude of validation gradients across layers. Specifically, we compute layerwise gradient norms to derive a client-specific score that reflects how much each client needs to adjust for improved generalization on the global validation set, thereby enabling more informed and adaptive federated aggregation. Extensive experiments on both natural and medical image benchmarking datasets, across diverse model architectures, demonstrate that FedVG consistently improves performance, particularly in highly heterogeneous settings. Moreover, FedVG is modular and can be seamlessly integrated with various state-of-the-art FL algorithms, often further improving their results. Our code is available at https://github.com/alinadevkota/FedVG.", "AI": {"tldr": "FedVG, a new federated learning framework, utilizes a global validation set to optimize model training across clients, improving performance in data heterogeneity. It evaluates client models based on layerwise gradient norms, allowing for adaptive and informed aggregation, and can be integrated with other FL methods.", "motivation": "The motivation is to address the challenge of client drift and poor generalization in Federated Learning (FL) due to data heterogeneity among clients, by proposing a method that optimizes the training process without compromising privacy.", "method": "FedVG employs a global validation set, which can be constructed from public datasets, to guide the optimization. It assesses each client's model generalization through the magnitude of layerwise gradients, assigning a score that indicates the required adjustments for better performance on the global validation set.", "result": "Experiments show FedVG enhances performance, especially in environments with high data heterogeneity, and it can be combined with other state-of-the-art FL algorithms to further improve their outcomes.", "conclusion": "FedVG provides a solution to the issue of client drift in FL, offering an effective way to leverage a global validation set for more adaptive and efficient federated model aggregation."}}
{"id": "2602.21420", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21420", "abs": "https://arxiv.org/abs/2602.21420", "authors": ["Yuanda Xu", "Hejian Sang", "Zhengze Zhou", "Ran He", "Zhipeng Wang"], "title": "Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become the leading paradigm for enhancing reasoning in Large Language Models (LLMs). However, standard RLVR algorithms suffer from a well-documented pathology: while they improve Pass@1 accuracy through sharpened sampling, they simultaneously narrow the model's reasoning boundary and reduce generation diversity. We identify a root cause that existing methods overlook: the uniform penalization of errors. Current approaches -- whether data-filtering methods that select prompts by difficulty, or advantage normalization schemes -- treat all incorrect rollouts within a group identically. We show that this uniformity allows overconfident errors (incorrect reasoning paths that the RL process has spuriously reinforced) to persist and monopolize probability mass, ultimately suppressing valid exploratory trajectories. To address this, we propose the Asymmetric Confidence-aware Error Penalty (ACE). ACE introduces a per-rollout confidence shift metric, c_i = log(pi_theta(y_i|x) / pi_ref(y_i|x)), to dynamically modulate negative advantages. Theoretically, we demonstrate that ACE's gradient can be decomposed into the gradient of a selective regularizer restricted to overconfident errors, plus a well-characterized residual that partially moderates the regularizer's strength. We conduct extensive experiments fine-tuning Qwen2.5-Math-7B, Qwen3-8B-Base, and Llama-3.1-8B-Instruct on the DAPO-Math-17K dataset using GRPO and DAPO within the VERL framework. Evaluated on MATH-500 and AIME 2025, ACE composes seamlessly with existing methods and consistently improves the full Pass@k spectrum across all three model families and benchmarks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.21424", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21424", "abs": "https://arxiv.org/abs/2602.21424", "authors": ["Alexander Galozy"], "title": "On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation", "comment": "15 pages, 3 figures. Under review at RLC 2026", "summary": "Reinforcement learning (RL) agents under partial observability often condition actions on internally accumulated information such as memory or inferred latent context. We formalise such information-conditioned interaction patterns as behavioural dependency: variation in action selection with respect to internal information under fixed observations. This induces a probe-relative notion of $\u03b5$-behavioural equivalence and a within-policy behavioural distance that quantifies probe sensitivity. We establish three structural results. First, the set of policies exhibiting non-trivial behavioural dependency is not closed under convex aggregation. Second, behavioural distance contracts under convex combination. Third, we prove a sufficient local condition under which gradient ascent on a skewed mixture objective decreases behavioural distance when a dominant-mode gradient aligns with the direction of steepest contraction. Minimal bandit and partially observable gridworld experiments provide controlled witnesses of these mechanisms. In the examined settings, behavioural distance decreases under convex aggregation and under continued optimisation with skewed latent priors, and in these experiments it precedes degradation under latent prior shift. These results identify structural conditions under which probe-conditioned behavioural separation is not preserved under common policy transformations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u884c\u4e3a\u4f9d\u8d56\u6027\u7684\u6982\u5ff5\uff0c\u7528\u4ee5\u63cf\u8ff0\u5728\u56fa\u5b9a\u89c2\u5bdf\u4e0b\u5185\u90e8\u4fe1\u606f\u53d8\u5316\u5bf9\u52a8\u4f5c\u9009\u62e9\u7684\u5f71\u54cd\u3002\u57fa\u4e8e\u6b64\u5b9a\u4e49\u4e86\u03b5-\u884c\u4e3a\u7b49\u4ef7\u6027\u548c\u7b56\u7565\u5185\u7684\u884c\u4e3a\u8ddd\u79bb\u6765\u91cf\u5316\u63a2\u9488\u654f\u611f\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8868\u73b0\u51fa\u975e\u5e73\u51e1\u884c\u4e3a\u4f9d\u8d56\u6027\u7684\u7b56\u7565\u96c6\u5408\u5728\u51f8\u805a\u5408\u4e0b\u4e0d\u5c01\u95ed\uff1b\u884c\u4e3a\u8ddd\u79bb\u5728\u51f8\u7ec4\u5408\u4e0b\u6536\u7f29\uff1b\u5f53\u4e3b\u5bfc\u6a21\u5f0f\u68af\u5ea6\u4e0e\u6700\u9661\u6536\u7f29\u65b9\u5411\u4e00\u81f4\u65f6\uff0c\u5728\u504f\u659c\u6df7\u5408\u76ee\u6807\u4e0a\u8fdb\u884c\u68af\u5ea6\u4e0a\u5347\u53ef\u4ee5\u51cf\u5c11\u884c\u4e3a\u8ddd\u79bb\u3002\u901a\u8fc7\u6700\u5c0f\u5316\u5e26\u5b9e\u9a8c\u548c\u90e8\u5206\u53ef\u89c2\u5bdf\u7f51\u683c\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u901a\u5e38\u4f1a\u6839\u636e\u5185\u90e8\u79ef\u7d2f\u7684\u4fe1\u606f\uff08\u5982\u8bb0\u5fc6\u6216\u63a8\u65ad\u7684\u6f5c\u5728\u4e0a\u4e0b\u6587\uff09\u6765\u8c03\u8282\u5176\u884c\u52a8\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u5f62\u5f0f\u5316\u4e3a\u884c\u4e3a\u4f9d\u8d56\u6027\uff1a\u5373\u5728\u56fa\u5b9a\u89c2\u6d4b\u6761\u4ef6\u4e0b\uff0c\u5185\u90e8\u4fe1\u606f\u7684\u53d8\u5316\u5bfc\u81f4\u52a8\u4f5c\u9009\u62e9\u7684\u53d8\u5316\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u79cd\u884c\u4e3a\u4f9d\u8d56\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u6765\u91cf\u5316\u4e0d\u540c\u7b56\u7565\u4e4b\u95f4\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "method": "\u672c\u6587\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5173\u4e8e\u884c\u4e3a\u4f9d\u8d56\u6027\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5305\u62ec\u03b5-\u884c\u4e3a\u7b49\u4ef7\u6027\u548c\u7b56\u7565\u5185\u884c\u4e3a\u8ddd\u79bb\u7684\u6982\u5ff5\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u786e\u7acb\u4e86\u4e09\u4e2a\u7ed3\u6784\u7ed3\u679c\uff1a1) \u8868\u73b0\u51fa\u663e\u8457\u884c\u4e3a\u4f9d\u8d56\u6027\u7684\u7b56\u7565\u96c6\u5bf9\u4e8e\u51f8\u805a\u5408\u64cd\u4f5c\u6765\u8bf4\u4e0d\u662f\u5c01\u95ed\u7684\uff1b2) \u51f8\u7ec4\u5408\u4f1a\u5bfc\u81f4\u884c\u4e3a\u8ddd\u79bb\u51cf\u5c0f\uff1b3) \u5f53\u4e3b\u8981\u6a21\u5f0f\u68af\u5ea6\u4e0e\u6700\u5927\u6536\u7f29\u65b9\u5411\u4e00\u81f4\u65f6\uff0c\u4f7f\u7528\u503e\u659c\u6df7\u5408\u76ee\u6807\u51fd\u6570\u6267\u884c\u68af\u5ea6\u4e0a\u5347\u53ef\u4ee5\u8fdb\u4e00\u6b65\u964d\u4f4e\u884c\u4e3a\u8ddd\u79bb\u3002\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u4e9b\u7406\u8bba\u53d1\u73b0\uff0c\u4f5c\u8005\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u4e86\u4e24\u4e2a\u5b9e\u9a8c\uff1a\u4e00\u4e2a\u662f\u6700\u5c0f\u5316\u5e26\u95ee\u9898\uff0c\u53e6\u4e00\u4e2a\u662f\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\u7f51\u683c\u4e16\u754c\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6240\u8003\u5bdf\u7684\u8bbe\u7f6e\u4e2d\uff0c\u884c\u4e3a\u8ddd\u79bb\u786e\u5b9e\u968f\u7740\u51f8\u805a\u5408\u4ee5\u53ca\u6301\u7eed\u4f18\u5316\u5e26\u6709\u504f\u5dee\u7684\u6f5c\u5728\u5148\u9a8c\u800c\u51cf\u5c11\u3002\u6b64\u5916\uff0c\u5728\u8fd9\u4e9b\u5b9e\u9a8c\u4e2d\u8fd8\u89c2\u5bdf\u5230\uff0c\u884c\u4e3a\u8ddd\u79bb\u7684\u51cf\u5c11\u9884\u793a\u7740\u6f5c\u5728\u5148\u9a8c\u8f6c\u79fb\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u7ed3\u6784\u6027\u6761\u4ef6\u4e0b\uff0c\u57fa\u4e8e\u63a2\u9488\u6761\u4ef6\u7684\u884c\u4e3a\u5206\u79bb\u7279\u6027\u4e0d\u4f1a\u5728\u5e38\u89c1\u7684\u7b56\u7565\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u4e3a\u7406\u89e3\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u52a8\u6001\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.21426", "categories": ["cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21426", "abs": "https://arxiv.org/abs/2602.21426", "authors": ["Youguang Chen", "George Biros"], "title": "Proximal-IMH: Proximal Posterior Proposals for Independent Metropolis-Hastings with Approximate Operators", "comment": null, "summary": "We consider the problem of sampling from a posterior distribution arising in Bayesian inverse problems in science, engineering, and imaging. Our method belongs to the family of independence Metropolis-Hastings (IMH) sampling algorithms, which are common in Bayesian inference. Relying on the existence of an approximate posterior distribution that is cheaper to sample from but may have significant bias, we introduce Proximal-IMH, a scheme that removes this bias by correcting samples from the approximate posterior through an auxiliary optimization problem. This yields a local adjustment that trades off adherence to the exact model against stability around the approximate reference point. For idealized settings, we prove that the proximal correction tightens the match between approximate and exact posteriors, thereby improving acceptance rates and mixing. The method applies to both linear and nonlinear input-output operators and is particularly suitable for inverse problems where exact posterior sampling is too expensive. We present numerical experiments including multimodal and data-driven priors with nonlinear input-output operators. The results show that Proximal-IMH reliably outperforms existing IMH variants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aProximal-IMH\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u51b3\u4e00\u4e2a\u8f85\u52a9\u4f18\u5316\u95ee\u9898\u6765\u7ea0\u6b63\u4ece\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u4e2d\u62bd\u53d6\u7684\u6837\u672c\uff0c\u4ece\u800c\u6d88\u9664\u504f\u5dee\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u79d1\u5b66\u3001\u5de5\u7a0b\u548c\u6210\u50cf\u4e2d\u7684\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4e2d\u7528\u4e8e\u4ece\u540e\u9a8c\u5206\u5e03\u91c7\u6837\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684IMH\u53d8\u4f53\u76f8\u6bd4\uff0cProximal-IMH\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u5148\u9a8c\u548c\u975e\u7ebf\u6027\u8f93\u5165\u8f93\u51fa\u64cd\u4f5c\u5458\u7684\u6570\u636e\u9a71\u52a8\u5148\u9a8c\u4e0b\u8868\u73b0\u5f97\u66f4\u53ef\u9760\u3002", "motivation": "\u5728\u79d1\u5b66\u3001\u5de5\u7a0b\u548c\u6210\u50cf\u9886\u57df\uff0c\u4ece\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u4ea7\u751f\u7684\u540e\u9a8c\u5206\u5e03\u8fdb\u884c\u91c7\u6837\u65f6\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f53\u7cbe\u786e\u540e\u9a8c\u91c7\u6837\u6210\u672c\u8fc7\u9ad8\u65f6\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5229\u7528\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u5e76\u4fee\u6b63\u5176\u504f\u5dee\u4ee5\u63d0\u9ad8\u63a5\u53d7\u7387\u548c\u6df7\u5408\u6548\u7387\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86Proximal-IMH\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u72ec\u7acbMetropolis-Hastings (IMH)\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u4f18\u5316\u6b65\u9aa4\u6765\u6821\u6b63\u4ece\u5ec9\u4ef7\u4f46\u53ef\u80fd\u6709\u8f83\u5927\u504f\u5dee\u7684\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u4e2d\u62bd\u6837\u7684\u7ed3\u679c\u3002\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u5e73\u8861\u5bf9\u51c6\u786e\u6a21\u578b\u7684\u9075\u5faa\u4e0e\u56f4\u7ed5\u8fd1\u4f3c\u53c2\u8003\u70b9\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\uff0c\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\uff0cproximal correction\u80fd\u591f\u52a0\u5f3a\u8fd1\u4f3c\u540e\u9a8c\u4e0e\u771f\u5b9e\u540e\u9a8c\u4e4b\u95f4\u7684\u5339\u914d\u5ea6\uff0c\u8fdb\u800c\u63d0\u5347\u4e86\u63a5\u53d7\u7387\u53ca\u6df7\u5408\u6548\u679c\u3002\u6b64\u5916\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5bf9\u4e8e\u5305\u542b\u975e\u7ebf\u6027\u8f93\u5165-\u8f93\u51fa\u7b97\u5b50\u7684\u591a\u6a21\u5f0f\u548c\u6570\u636e\u9a71\u52a8\u5148\u9a8c\u60c5\u51b5\uff0cProximal-IMH\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684IMH\u53d8\u4f53\u3002", "conclusion": "Proximal-IMH\u4e3a\u5904\u7406\u590d\u6742\u7684\u8d1d\u53f6\u65af\u9006\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u90a3\u4e9b\u76f4\u63a5\u4ece\u7cbe\u786e\u540e\u9a8c\u5206\u5e03\u91c7\u6837\u6210\u672c\u8fc7\u9ad8\u7684\u60c5\u51b5\u4e0b\u3002\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\uff0c\u800c\u4e14\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u6a21\u578b\u7684\u652f\u6301\u80fd\u529b\u3002"}}
{"id": "2602.21429", "categories": ["cs.LG", "cs.AI", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21429", "abs": "https://arxiv.org/abs/2602.21429", "authors": ["Darshan Gadginmath", "Ahmed Allibhoy", "Fabio Pasqualetti"], "title": "Provably Safe Generative Sampling with Constricting Barrier Functions", "comment": "25 pages, 7 figures", "summary": "Flow-based generative models, such as diffusion models and flow matching models, have achieved remarkable success in learning complex data distributions. However, a critical gap remains for their deployment in safety-critical domains: the lack of formal guarantees that generated samples will satisfy hard constraints. We address this by proposing a safety filtering framework that acts as an online shield for any pre-trained generative model. Our key insight is to cooperate with the generative process rather than override it. We define a constricting safety tube that is relaxed at the initial noise distribution and progressively tightens to the target safe set at the final data distribution, mirroring the coarse-to-fine structure of the generative process itself. By characterizing this tube via Control Barrier Functions (CBFs), we synthesize a feedback control input through a convex Quadratic Program (QP) at each sampling step. As the tube is loosest when noise is high and intervention is cheapest in terms of control energy, most constraint enforcement occurs when it least disrupts the model's learned structure. We prove that this mechanism guarantees safe sampling while minimizing the distributional shift from the original model at each sampling step, as quantified by the KL divergence. Our framework applies to any pre-trained flow-based generative scheme requiring no retraining or architectural modifications. We validate the approach across constrained image generation, physically-consistent trajectory sampling, and safe robotic manipulation policies, achieving 100% constraint satisfaction while preserving semantic fidelity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b89\u5168\u8fc7\u6ee4\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u548c\u4e8c\u6b21\u89c4\u5212\u6280\u672f\uff0c\u5728\u4fdd\u6301\u751f\u6210\u6a21\u578b\u539f\u6709\u7ed3\u6784\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u751f\u6210\u6837\u672c\u6ee1\u8db3\u786c\u6027\u7ea6\u675f\u6761\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u5728\u5173\u952e\u5b89\u5168\u9886\u57df\u5e94\u7528\u65f6\u7f3a\u4e4f\u6b63\u5f0f\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u5373\u751f\u6210\u6837\u672c\u53ef\u80fd\u4e0d\u6ee1\u8db3\u786c\u6027\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ece\u521d\u59cb\u566a\u58f0\u5206\u5e03\u5230\u6700\u7ec8\u6570\u636e\u5206\u5e03\u9010\u6e10\u6536\u7d27\u7684\u5b89\u5168\u7ba1\uff0c\u5e76\u5229\u7528\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08CBFs\uff09\u901a\u8fc7\u51f8\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\u5728\u6bcf\u4e2a\u91c7\u6837\u6b65\u9aa4\u4e2d\u5408\u6210\u53cd\u9988\u63a7\u5236\u8f93\u5165\u3002", "result": "\u8be5\u673a\u5236\u4fdd\u8bc1\u4e86\u5b89\u5168\u91c7\u6837\u7684\u540c\u65f6\uff0c\u5728\u6bcf\u4e00\u6b65\u91c7\u6837\u4e2d\u6700\u5c0f\u5316\u4e86\u4e0e\u539f\u59cb\u6a21\u578b\u4e4b\u95f4\u7684\u5206\u5e03\u504f\u79fb\uff08\u4ee5KL\u6563\u5ea6\u8861\u91cf\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u9002\u7528\u4e8e\u4efb\u4f55\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u65b9\u6848\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u67b6\u6784\u4fee\u6539\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u53d7\u9650\u56fe\u50cf\u751f\u6210\u3001\u7269\u7406\u4e00\u81f4\u8f68\u8ff9\u91c7\u6837\u4ee5\u53ca\u5b89\u5168\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86100%\u7684\u7ea6\u675f\u6ee1\u8db3\u7387\u5e76\u4fdd\u6301\u4e86\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2602.21441", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21441", "abs": "https://arxiv.org/abs/2602.21441", "authors": ["Shiwei Tan", "Hengyi Wang", "Weiyi Qin", "Qi Xu", "Zhigang Hua", "Hao Wang"], "title": "Causal Decoding for Hallucination-Resistant Multimodal Large Language Models", "comment": "Published in Transactions on Machine Learning Research (TMLR), 2026", "summary": "Multimodal Large Language Models (MLLMs) deliver detailed responses on vision-language tasks, yet remain susceptible to object hallucination (introducing objects not present in the image), undermining reliability in practice. Prior efforts often rely on heuristic penalties, post-hoc correction, or generic decoding tweaks, which do not directly intervene in the mechanisms that trigger object hallucination and thus yield limited gains. To address this challenge, we propose a causal decoding framework that applies targeted causal interventions during generation to curb spurious object mentions. By reshaping the decoding dynamics to attenuate spurious dependencies, our approach reduces false object tokens while maintaining descriptive quality. Across captioning and QA benchmarks, our framework substantially lowers object-hallucination rates and achieves state-of-the-art faithfulness without degrading overall output quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56e0\u679c\u89e3\u7801\u6846\u67b6\u6765\u51cf\u5c11\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\u51fa\u73b0\u7684\u5bf9\u8c61\u5e7b\u89c9\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u4e0d\u964d\u4f4e\u8f93\u51fa\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u9ad8\u751f\u6210\u5185\u5bb9\u7684\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u591f\u63d0\u4f9b\u8be6\u7ec6\u7684\u54cd\u5e94\uff0c\u4f46\u5728\u5904\u7406\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u65f6\u5bb9\u6613\u4ea7\u751f\u5bf9\u8c61\u5e7b\u89c9\uff08\u5373\u63cf\u8ff0\u4e86\u56fe\u7247\u4e2d\u4e0d\u5b58\u5728\u7684\u5bf9\u8c61\uff09\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u53ef\u9760\u6027\u3002\u4ee5\u5f80\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u60e9\u7f5a\u3001\u4e8b\u540e\u4fee\u6b63\u6216\u901a\u7528\u89e3\u7801\u8c03\u6574\u7b49\u624b\u6bb5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5e76\u672a\u76f4\u63a5\u5e72\u9884\u5bfc\u81f4\u5bf9\u8c61\u5e7b\u89c9\u4ea7\u751f\u7684\u673a\u5236\uff0c\u56e0\u6b64\u6548\u679c\u6709\u9650\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u65bd\u9488\u5bf9\u6027\u7684\u56e0\u679c\u5e72\u9884\u6765\u6291\u5236\u865a\u5047\u5bf9\u8c61\u7684\u63d0\u53ca\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u91cd\u5851\u89e3\u7801\u52a8\u6001\u4ee5\u51cf\u5f31\u9519\u8bef\u4f9d\u8d56\u5173\u7cfb\uff0c\u51cf\u5c11\u4e86\u9519\u8bef\u5bf9\u8c61\u6807\u8bb0\u7684\u51fa\u73b0\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63cf\u8ff0\u7684\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u56fe\u50cf\u63cf\u8ff0\u548c\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5927\u5e45\u964d\u4f4e\u4e86\u5bf9\u8c61\u5e7b\u89c9\u7684\u53d1\u751f\u7387\uff0c\u5e76\u4e14\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u5fe0\u5b9e\u5ea6\u6c34\u5e73\uff0c\u540c\u65f6\u6ca1\u6709\u635f\u5bb3\u6574\u4f53\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u56e0\u679c\u89e3\u7801\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5bf9\u8c61\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u54cd\u5e94\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.21469", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21469", "abs": "https://arxiv.org/abs/2602.21469", "authors": ["Meet Hemant Parikh", "Yaqin Chen", "Jian-Xun Wang"], "title": "D-Flow SGLD: Source-Space Posterior Sampling for Scientific Inverse Problems with Flow Matching", "comment": null, "summary": "Data assimilation and scientific inverse problems require reconstructing high-dimensional physical states from sparse and noisy observations, ideally with uncertainty-aware posterior samples that remain faithful to learned priors and governing physics. While training-free conditional generation is well developed for diffusion models, corresponding conditioning and posterior sampling strategies for Flow Matching (FM) priors remain comparatively under-explored, especially on scientific benchmarks where fidelity must be assessed beyond measurement misfit. In this work, we study training-free conditional generation for scientific inverse problems under FM priors and organize existing inference-time strategies by where measurement information is injected: (i) guided transport dynamics that perturb sampling trajectories using likelihood information, and (ii) source-distribution inference that performs posterior inference over the source variable while keeping the learned transport fixed. Building on the latter, we propose D-Flow SGLD, a source-space posterior sampling method that augments differentiable source inference with preconditioned stochastic gradient Langevin dynamics, enabling scalable exploration of the source posterior induced by new measurement operators without retraining the prior or modifying the learned FM dynamics. We benchmark representative methods from both families on a hierarchy of problems: 2D toy posteriors, chaotic Kuramoto-Sivashinsky trajectories, and wall-bounded turbulence reconstruction. Across these settings, we quantify trade-offs among measurement assimilation, posterior diversity, and physics/statistics fidelity, and establish D-Flow SGLD as a practical FM-compatible posterior sampler for scientific inverse problems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728Flow Matching (FM)\u5148\u9a8c\u4e0b\u79d1\u5b66\u53cd\u95ee\u9898\u7684\u65e0\u8bad\u7ec3\u6761\u4ef6\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86D-Flow SGLD\uff0c\u4e00\u79cd\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u5148\u9a8c\u6216\u4fee\u6539\u5b66\u4e60\u5230\u7684FM\u52a8\u6001\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u65b0\u6d4b\u91cf\u7b97\u5b50\u63a2\u7d22\u6e90\u540e\u9a8c\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u95ee\u9898\u5c42\u6b21\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u79d1\u5b66\u53cd\u95ee\u9898\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u6570\u636e\u540c\u5316\u548c\u79d1\u5b66\u53cd\u95ee\u9898\u9700\u8981\u4ece\u7a00\u758f\u4e14\u5e26\u6709\u566a\u58f0\u7684\u89c2\u6d4b\u4e2d\u91cd\u5efa\u9ad8\u7ef4\u7269\u7406\u72b6\u6001\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u72b6\u6001\u5e94\u5177\u5907\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u540e\u9a8c\u6837\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5b66\u4e60\u5148\u9a8c\u548c\u7ba1\u7406\u7269\u7406\u5b66\u7684\u5fe0\u5b9e\u5ea6\u3002\u867d\u7136\u6269\u6563\u6a21\u578b\u7684\u65e0\u8bad\u7ec3\u6761\u4ef6\u751f\u6210\u5df2\u7ecf\u76f8\u5f53\u6210\u719f\uff0c\u4f46\u5bf9\u4e8eFM\u5148\u9a8c\u4e0b\u7684\u76f8\u5e94\u6761\u4ef6\u8bbe\u7f6e\u548c\u540e\u9a8c\u62bd\u6837\u7b56\u7565\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u7279\u522b\u662f\u5728\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9664\u4e86\u6d4b\u91cf\u8bef\u5dee\u5916\u8fd8\u9700\u8981\u8bc4\u4f30\u4fdd\u771f\u5ea6\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86FM\u5148\u9a8c\u4e0b\u79d1\u5b66\u53cd\u95ee\u9898\u7684\u65e0\u8bad\u7ec3\u6761\u4ef6\u751f\u6210\uff0c\u5e76\u5c06\u73b0\u6709\u63a8\u7406\u65f6\u7b56\u7565\u6309\u7167\u6d4b\u91cf\u4fe1\u606f\u6ce8\u5165\u7684\u4f4d\u7f6e\u5206\u4e3a\u4e24\u7c7b\uff1a\uff08i\uff09\u5229\u7528\u4f3c\u7136\u4fe1\u606f\u6270\u52a8\u91c7\u6837\u8f68\u8ff9\u7684\u5f15\u5bfc\u4f20\u8f93\u52a8\u529b\u5b66\uff1b\uff08ii\uff09\u6267\u884c\u540e\u9a8c\u63a8\u65ad\u7684\u540c\u65f6\u56fa\u5b9a\u5df2\u5b66\u4e60\u4f20\u8f93\u7684\u6e90\u5206\u5e03\u63a8\u65ad\u3002\u57fa\u4e8e\u540e\u8005\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aD-Flow SGLD\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u9884\u5904\u7406\u968f\u673a\u68af\u5ea6\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u589e\u5f3a\u53ef\u5fae\u5206\u6e90\u63a8\u65ad\uff0c\u4ece\u800c\u80fd\u591f\u9488\u5bf9\u7531\u65b0\u7684\u6d4b\u91cf\u7b97\u5b50\u5f15\u8d77\u7684\u6e90\u540e\u9a8c\u8fdb\u884c\u53ef\u6269\u5c55\u63a2\u7d22\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5148\u9a8c\u6216\u8c03\u6574\u5df2\u5b66\u4e60\u7684FM\u52a8\u6001\u3002", "result": "\u4ee3\u8868\u6027\u65b9\u6cd5\u5728\u4e0d\u540c\u5c42\u6b21\u7684\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec2D\u73a9\u5177\u540e\u9a8c\u3001\u6df7\u6c8cKuramoto-Sivashinsky\u8f68\u8ff9\u4ee5\u53ca\u58c1\u9762\u6e4d\u6d41\u91cd\u6784\u7b49\u3002\u5728\u8fd9\u4e9b\u60c5\u5883\u4e0b\uff0c\u7814\u7a76\u91cf\u5316\u4e86\u6d4b\u91cf\u540c\u5316\u3001\u540e\u9a8c\u591a\u6837\u6027\u4e0e\u7269\u7406/\u7edf\u8ba1\u4fdd\u771f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u786e\u7acb\u4e86D-Flow SGLD\u4f5c\u4e3a\u9002\u7528\u4e8e\u79d1\u5b66\u53cd\u95ee\u9898\u7684\u5b9e\u9645FM\u517c\u5bb9\u540e\u9a8c\u62bd\u6837\u5668\u7684\u5730\u4f4d\u3002", "conclusion": "D-Flow SGLD\u88ab\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u6539\u53d8\u5df2\u5b66\u4e60FM\u52a8\u6001\u7684\u524d\u63d0\u4e0b\uff0c\u4e3a\u79d1\u5b66\u53cd\u95ee\u9898\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7684\u540e\u9a8c\u6837\u672c\u3002\u8be5\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u5bf9\u4e8e\u5982\u4f55\u5728\u7ed9\u5b9a\u65b0\u578b\u6d4b\u91cf\u64cd\u4f5c\u7b26\u65f6\u63a2\u7d22\u6e90\u540e\u9a8c\u7684\u7406\u89e3\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u7ef4\u6301\u7269\u7406\u4e0e\u7edf\u8ba1\u4fdd\u771f\u5ea6\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2602.21472", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21472", "abs": "https://arxiv.org/abs/2602.21472", "authors": ["Louis Bethune", "Victor Turrisi", "Bruno Kacper Mlodozeniec", "Pau Rodriguez Lopez", "Lokesh Boominathan", "Nikhil Bhendawade", "Amitis Shidani", "Joris Pelemans", "Theo X. Olausson", "Devon Hjelm", "Paul Dixon", "Joao Monteiro", "Pierre Ablin", "Vishnu Banna", "Arno Blaas", "Nick Henderson", "Kari Noriy", "Dan Busbridge", "Josh Susskind", "Marco Cuturi", "Irina Belousova", "Luca Zappella", "Russ Webb", "Jason Ramapuram"], "title": "The Design Space of Tri-Modal Masked Diffusion Models", "comment": "41 pages, 29 figures, 10 tables", "summary": "Discrete diffusion models have emerged as strong alternatives to autoregressive language models, with recent work initializing and fine-tuning a base unimodal model for bimodal generation. Diverging from previous approaches, we introduce the first tri-modal masked diffusion model pretrained from scratch on text, image-text, and audio-text data. We systematically analyze multimodal scaling laws, modality mixing ratios, noise schedules, and batch-size effects, and we provide optimized inference sampling defaults. Our batch-size analysis yields a novel stochastic differential equation (SDE)-based reparameterization that eliminates the need for tuning the optimal batch size as reported in recent work. This reparameterization decouples the physical batch size, often chosen based on compute constraints (GPU saturation, FLOP efficiency, wall-clock time), from the logical batch size, chosen to balance gradient variance during stochastic optimization. Finally, we pretrain a preliminary 3B-parameter tri-modal model on 6.4T tokens, demonstrating the capabilities of a unified design and achieving strong results in text generation, text-to-image tasks, and text-to-speech tasks. Our work represents the largest-scale systematic open study of multimodal discrete diffusion models conducted to date, providing insights into scaling behaviors across multiple modalities.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4ece\u6587\u672c\u3001\u56fe\u6587\u548c\u97f3\u9891\u6587\u672c\u6570\u636e\u4e2d\u4ece\u5934\u5f00\u59cb\u9884\u8bad\u7ec3\u7684\u9996\u4e2a\u4e09\u6a21\u6001\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u591a\u6a21\u6001\u6269\u5c55\u89c4\u5f8b\u7b49\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eSDE\u7684\u91cd\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u6700\u7ec8\u5728\u6587\u672c\u751f\u6210\u3001\u6587\u5230\u56fe\u4efb\u52a1\u4ee5\u53ca\u6587\u5230\u8bed\u97f3\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u7ed3\u679c\u3002", "motivation": "\u4ee5\u5f80\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u4f7f\u7528\u5355\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u53cc\u6a21\u6001\u751f\u6210\uff0c\u800c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u4e2a\u5168\u65b0\u7684\u65b9\u5411\u2014\u2014\u6784\u5efa\u80fd\u591f\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf-\u6587\u672c\u548c\u97f3\u9891-\u6587\u672c\u4e09\u79cd\u6a21\u6001\u4fe1\u606f\u7684\u4e09\u6a21\u6001\u63a9\u7801\u6269\u6563\u6a21\u578b\u3002", "method": "\u7814\u7a76\u8005\u4eec\u9996\u5148\u4ece\u96f6\u5f00\u59cb\u5bf9\u4e00\u4e2a\u62e5\u670930\u4ebf\u53c2\u6570\u7684\u4e09\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u4e86\u9884\u8bad\u7ec3\uff0c\u8be5\u8fc7\u7a0b\u6d89\u53ca\u4e866.4\u4e07\u4ebf\u4e2a\u6807\u8bb0\u7684\u6570\u636e\u96c6\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u6df1\u5165\u5206\u6790\u4e86\u591a\u6a21\u6001\u6269\u5c55\u6cd5\u5219\u3001\u6a21\u6001\u6df7\u5408\u6bd4\u4f8b\u3001\u566a\u58f0\u8c03\u5ea6\u7b56\u7565\u53ca\u6279\u91cf\u5927\u5c0f\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8e\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08SDE\uff09\u7684\u91cd\u53c2\u6570\u5316\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6587\u672c\u751f\u6210\u3001\u6587\u672c\u5230\u56fe\u50cf\u8f6c\u6362\u4ee5\u53ca\u6587\u672c\u5230\u8bed\u97f3\u5408\u6210\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u4e09\u6a21\u6001\u6a21\u578b\u5747\u8868\u73b0\u51fa\u4e86\u4f18\u5f02\u6027\u80fd\u3002\u6b64\u5916\uff0c\u65b0\u63d0\u51fa\u7684SDE\u91cd\u53c2\u6570\u5316\u65b9\u6cd5\u6210\u529f\u5730\u89e3\u51b3\u4e86\u6700\u4f18\u6279\u91cf\u5927\u5c0f\u8c03\u6574\u7684\u95ee\u9898\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u89c4\u6a21\u7684\u591a\u6a21\u6001\u79bb\u6563\u6269\u6563\u6a21\u578b\u5f00\u653e\u7814\u7a76\u4e4b\u4e00\uff0c\u4e3a\u7406\u89e3\u8de8\u591a\u79cd\u6a21\u6001\u7684\u6269\u5c55\u884c\u4e3a\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.21492", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.21492", "abs": "https://arxiv.org/abs/2602.21492", "authors": ["Ningyuan Yang", "Weihua Du", "Weiwei Sun", "Sean Welleck", "Yiming Yang"], "title": "GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning", "comment": "14 pages. Preliminary work", "summary": "Reinforcement learning (RL) has become a central post-training paradigm for large language models (LLMs), but its performance is highly sensitive to the quality of training problems. This sensitivity stems from the non-stationarity of RL: rollouts are generated by an evolving policy, and learning is shaped by exploration and reward feedback, unlike supervised fine-tuning (SFT) with fixed trajectories. As a result, prior work often relies on manual curation or simple heuristic filters (e.g., accuracy), which can admit incorrect or low-utility problems. We propose GradAlign, a gradient-aligned data selection method for LLM reinforcement learning that uses a small, trusted validation set to prioritize training problems whose policy gradients align with validation gradients, yielding an adaptive curriculum. We evaluate GradAlign across three challenging data regimes: unreliable reward signals, distribution imbalance, and low-utility training corpus, showing that GradAlign consistently outperforms existing baselines, underscoring the importance of directional gradient signals in navigating non-stationary policy optimization and yielding more stable training and improved final performance. We release our implementation at https://github.com/StigLidu/GradAlign", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradAlign\u7684\u68af\u5ea6\u5bf9\u9f50\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u4f7f\u7528\u4e00\u4e2a\u5c0f\u800c\u53ef\u4fe1\u7684\u9a8c\u8bc1\u96c6\u6765\u4f18\u5148\u9009\u62e9\u7b56\u7565\u68af\u5ea6\u4e0e\u9a8c\u8bc1\u68af\u5ea6\u5bf9\u9f50\u7684\u8bad\u7ec3\u95ee\u9898\uff0c\u4ece\u800c\u751f\u6210\u81ea\u9002\u5e94\u8bfe\u7a0b\u3002\u5728\u4e09\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u573a\u666f\u4e0b\u8bc4\u4f30\u4e86GradAlign\u7684\u8868\u73b0\uff0c\u5e76\u53d1\u73b0\u5b83\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5df2\u7ecf\u6210\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u6838\u5fc3\u8303\u5f0f\uff0c\u4f46\u5176\u6027\u80fd\u6781\u6613\u53d7\u5230\u8bad\u7ec3\u95ee\u9898\u8d28\u91cf\u7684\u5f71\u54cd\u3002\u8fd9\u79cd\u654f\u611f\u6027\u6e90\u4e8eRL\u7684\u975e\u7a33\u6001\u7279\u6027\uff1arollouts\u7531\u4e0d\u65ad\u6f14\u5316\u7684\u7b56\u7565\u4ea7\u751f\uff0c\u5b66\u4e60\u8fc7\u7a0b\u53d7\u5230\u63a2\u7d22\u548c\u5956\u52b1\u53cd\u9988\u7684\u5f71\u54cd\uff0c\u8fd9\u4e0e\u8f68\u8ff9\u56fa\u5b9a\u7684\u76d1\u7763\u5fae\u8c03\u4e0d\u540c\u3002\u56e0\u6b64\uff0c\u5148\u524d\u7684\u5de5\u4f5c\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u5de5\u7b56\u5212\u6216\u7b80\u5355\u7684\u542f\u53d1\u5f0f\u8fc7\u6ee4\u5668\uff08\u4f8b\u5982\u51c6\u786e\u6027\uff09\uff0c\u4f46\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5f15\u5165\u9519\u8bef\u6216\u4f4e\u6548\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86GradAlign\uff0c\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u5bf9\u9f50\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3RL\u4e2d\u56e0\u975e\u7a33\u6001\u7279\u6027\u5bfc\u81f4\u7684\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e00\u5c0f\u90e8\u5206\u53ef\u4fe1\u9a8c\u8bc1\u96c6\u6765\u4f18\u5148\u8003\u8651\u90a3\u4e9b\u5176\u7b56\u7565\u68af\u5ea6\u4e0e\u9a8c\u8bc1\u96c6\u4e0a\u8ba1\u7b97\u5f97\u5230\u7684\u68af\u5ea6\u65b9\u5411\u4e00\u81f4\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u4ee5\u6b64\u5f62\u6210\u4e00\u4e2a\u80fd\u591f\u81ea\u6211\u8c03\u6574\u7684\u5b66\u4e60\u8def\u5f84\u3002", "result": "GradAlign\u5728\u5904\u7406\u4e0d\u53ef\u9760\u5956\u52b1\u4fe1\u53f7\u3001\u5206\u5e03\u4e0d\u5e73\u8861\u4ee5\u53ca\u4f4e\u6548\u8bad\u7ec3\u8bed\u6599\u5e93\u8fd9\u4e09\u4e2a\u96be\u9898\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u6301\u7eed\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u65b9\u5411\u6027\u68af\u5ea6\u4fe1\u53f7\u5bf9\u4e8e\u5e94\u5bf9\u975e\u7a33\u6001\u7b56\u7565\u4f18\u5316\u7684\u91cd\u8981\u6027\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u5b66\u4e60\u8fc7\u7a0b\u53ca\u63d0\u5347\u6700\u7ec8\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cGradAlign\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u66f4\u597d\u7684\u8bad\u7ec3\u95ee\u9898\u9009\u62e9\uff0c\u8fdb\u800c\u4fc3\u8fdb\u66f4\u7a33\u5065\u7684\u8bad\u7ec3\u6d41\u7a0b\u548c\u589e\u5f3a\u6700\u7ec8\u6a21\u578b\u7684\u80fd\u529b\u3002"}}
{"id": "2602.21498", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21498", "abs": "https://arxiv.org/abs/2602.21498", "authors": ["Boyuan Li", "Zhen Liu", "Yicheng Luo", "Qianli Ma"], "title": "Learning Recursive Multi-Scale Representations for Irregular Multivariate Time Series Forecasting", "comment": "Accepted in ICLR 2026", "summary": "Irregular Multivariate Time Series (IMTS) are characterized by uneven intervals between consecutive timestamps, which carry sampling pattern information valuable and informative for learning temporal and variable dependencies. In addition, IMTS often exhibit diverse dependencies across multiple time scales. However, many existing multi-scale IMTS methods use resampling to obtain the coarse series, which can alter the original timestamps and disrupt the sampling pattern information. To address the challenge, we propose ReIMTS, a Recursive multi-scale modeling approach for Irregular Multivariate Time Series forecasting. Instead of resampling, ReIMTS keeps timestamps unchanged and recursively splits each sample into subsamples with progressively shorter time periods. Based on the original sampling timestamps in these long-to-short subsamples, an irregularity-aware representation fusion mechanism is proposed to capture global-to-local dependencies for accurate forecasting. Extensive experiments demonstrate an average performance improvement of 27.1\\% in the forecasting task across different models and real-world datasets. Our code is available at https://github.com/Ladbaby/PyOmniTS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReIMTS\u7684\u9012\u5f52\u591a\u5c3a\u5ea6\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff08IMTS\uff09\u7684\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4fdd\u6301\u65f6\u95f4\u6233\u4e0d\u53d8\u5e76\u9012\u5f52\u5730\u5c06\u6bcf\u4e2a\u6837\u672c\u5206\u5272\u6210\u5177\u6709\u9010\u6e10\u7f29\u77ed\u65f6\u95f4\u6bb5\u7684\u5b50\u6837\u672c\uff0c\u6765\u6355\u6349\u5168\u5c40\u5230\u5c40\u90e8\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cReIMTS\u5728\u4e0d\u540c\u6a21\u578b\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e73\u5747\u6027\u80fd\u63d0\u9ad8\u4e8627.1%\u3002", "motivation": "\u73b0\u6709\u7684\u5904\u7406\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u65b9\u6cd5\u901a\u5e38\u4f1a\u91c7\u7528\u91cd\u91c7\u6837\u6280\u672f\u6765\u83b7\u53d6\u7c97\u7565\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4f46\u8fd9\u6837\u505a\u53ef\u80fd\u4f1a\u6539\u53d8\u539f\u59cb\u65f6\u95f4\u6233\uff0c\u5e76\u7834\u574f\u4e86\u6709\u4ef7\u503c\u7684\u65f6\u95f4\u91c7\u6837\u6a21\u5f0f\u4fe1\u606f\u3002\u6b64\u5916\uff0cIMTS\u5f80\u5f80\u5728\u591a\u4e2a\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5c55\u793a\u51fa\u4e0d\u540c\u7684\u4f9d\u8d56\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "ReIMTS\u662f\u4e00\u79cd\u9488\u5bf9\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u9012\u5f52\u591a\u5c3a\u5ea6\u5efa\u6a21\u65b9\u6cd5\uff0c\u5b83\u907f\u514d\u4e86\u4f7f\u7528\u91cd\u91c7\u6837\u7684\u624b\u6bb5\uff0c\u800c\u662f\u76f4\u63a5\u57fa\u4e8e\u539f\u6709\u7684\u65f6\u95f4\u6233\u4fe1\u606f\uff0c\u901a\u8fc7\u9012\u5f52\u5730\u5c06\u6bcf\u4e00\u4e2a\u6837\u672c\u5212\u5206\u4e3a\u8d8a\u6765\u8d8a\u77ed\u7684\u65f6\u95f4\u6bb5\u5b50\u6837\u672c\u7684\u65b9\u5f0f\u6765\u8fdb\u884c\u3002\u57fa\u4e8e\u8fd9\u4e9b\u4ece\u957f\u5230\u77ed\u7684\u5b50\u6837\u672c\u4e2d\u7684\u539f\u59cb\u65f6\u95f4\u6233\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u610f\u8bc6\u5230\u4e0d\u89c4\u5219\u6027\u7684\u8868\u793a\u878d\u5408\u673a\u5236\uff0c\u4ee5\u6355\u6349\u4ece\u5168\u5c40\u5230\u5c40\u90e8\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86ReIMTS\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u6a21\u578b\u4ee5\u53ca\u5b9e\u9645\u5e94\u7528\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u76f8\u5bf9\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0cReIMTS\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5e73\u574727.1%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "ReIMTS\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u95ee\u9898\uff0c\u901a\u8fc7\u4fdd\u7559\u539f\u59cb\u65f6\u95f4\u6233\u4fe1\u606f\u5e76\u5229\u7528\u9012\u5f52\u591a\u5c3a\u5ea6\u5efa\u6a21\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2602.21508", "categories": ["cs.LG", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21508", "abs": "https://arxiv.org/abs/2602.21508", "authors": ["Haoyuan He", "Yu Zheng", "Jie Zhou", "Jiwen Lu"], "title": "WaterVIB: Learning Minimal Sufficient Watermark Representations via Variational Information Bottleneck", "comment": "22 pages, 7 figures. Preprint", "summary": "Robust watermarking is critical for intellectual property protection, whereas existing methods face a severe vulnerability against regeneration-based AIGC attacks. We identify that existing methods fail because they entangle the watermark with high-frequency cover texture, which is susceptible to being rewritten during generative purification. To address this, we propose WaterVIB, a theoretically grounded framework that reformulates the encoder as an information sieve via the Variational Information Bottleneck. Instead of overfitting to fragile cover details, our approach forces the model to learn a Minimal Sufficient Statistic of the message. This effectively filters out redundant cover nuances prone to generative shifts, retaining only the essential signal invariant to regeneration. We theoretically prove that optimizing this bottleneck is a necessary condition for robustness against distribution-shifting attacks. Extensive experiments demonstrate that WaterVIB significantly outperforms state-of-the-art methods, achieving superior zero-shot resilience against unknown diffusion-based editing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWaterVIB\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u53d8\u5206\u4fe1\u606f\u74f6\u9888\u5c06\u7f16\u7801\u5668\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4fe1\u606f\u7b5b\u5b50\uff0c\u4ece\u800c\u5728\u5bf9\u6297\u751f\u6210\u6027\u51c0\u5316\u653b\u51fb\u65f6\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u6c34\u5370\u3002", "motivation": "\u73b0\u6709\u7684\u9c81\u68d2\u6c34\u5370\u65b9\u6cd5\u5728\u9762\u5bf9\u57fa\u4e8e\u518d\u751f\u7684AIGC\u653b\u51fb\u65f6\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff0c\u56e0\u4e3a\u5b83\u4eec\u5c06\u6c34\u5370\u4e0e\u5bb9\u6613\u88ab\u91cd\u5199\u7684\u9ad8\u9891\u8986\u76d6\u7eb9\u7406\u7ea0\u7f20\u5728\u4e00\u8d77\u3002", "method": "WaterVIB\u6846\u67b6\u5229\u7528\u53d8\u5206\u4fe1\u606f\u74f6\u9888\u6765\u5f3a\u5236\u6a21\u578b\u5b66\u4e60\u6d88\u606f\u7684\u6700\u5c0f\u5145\u5206\u7edf\u8ba1\u91cf\uff0c\u4ee5\u8fc7\u6ee4\u6389\u6613\u53d7\u751f\u6210\u6027\u53d8\u5316\u5f71\u54cd\u7684\u591a\u4f59\u8986\u76d6\u7ec6\u8282\uff0c\u4ec5\u4fdd\u7559\u5bf9\u518d\u751f\u4e0d\u53d8\u7684\u57fa\u672c\u4fe1\u53f7\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86WaterVIB\u5728\u672a\u77e5\u6269\u6563\u7f16\u8f91\u9762\u524d\u5177\u6709\u4f18\u8d8a\u7684\u96f6\u6837\u672c\u97e7\u6027\uff0c\u5e76\u4e14\u660e\u663e\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u4f18\u5316\u8fd9\u4e00\u74f6\u9888\u662f\u62b5\u5fa1\u5206\u5e03\u504f\u79fb\u653b\u51fb\u9c81\u68d2\u6027\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u4e14WaterVIB\u80fd\u6709\u6548\u63d0\u5347\u6c34\u5370\u62b5\u6297\u57fa\u4e8eAI\u7684\u5185\u5bb9\u751f\u6210\u653b\u51fb\u7684\u80fd\u529b\u3002"}}
{"id": "2602.21515", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.21515", "abs": "https://arxiv.org/abs/2602.21515", "authors": ["Chengrui Qu", "Yizhou Zhang", "Nicholas Lanzetti", "Eric Mazumdar"], "title": "Training Generalizable Collaborative Agents via Strategic Risk Aversion", "comment": null, "summary": "Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u5b66\u4e60\u5408\u4f5c\u95ee\u9898\u7b56\u7565\u65f6\u4ea7\u751f\u7684\u89e3\u51b3\u65b9\u6848\u8106\u5f31\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b56\u7565\u98ce\u9669\u89c4\u907f\u7684\u6982\u5ff5\u6765\u589e\u5f3a\u4e0e\u672a\u89c1\u8fc7\u7684\u4f19\u4f34\u7684\u5408\u4f5c\u6cdb\u5316\u80fd\u529b\u3002\u901a\u8fc7\u5c06\u7b56\u7565\u98ce\u9669\u89c4\u907f\u6574\u5408\u5230\u6807\u51c6\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e2d\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4e0e\u5f02\u8d28\u548c\u672a\u89c1\u8fc7\u7684\u4f19\u4f34\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u53ef\u9760\u5408\u4f5c\u3002", "motivation": "\u73b0\u6709\u7684\u5b66\u4e60\u5408\u4f5c\u95ee\u9898\u7b56\u7565\u7684\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u51fa\u8106\u5f31\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f53\u9047\u5230\u65b0\u7684\u5408\u4f5c\u4f19\u4f34\u65f6\u5bb9\u6613\u5931\u8d25\u3002\u8fd9\u4e9b\u95ee\u9898\u4e3b\u8981\u5f52\u56e0\u4e8e\u8bad\u7ec3\u671f\u95f4\u7684\u642d\u4fbf\u8f66\u73b0\u8c61\u4ee5\u53ca\u7f3a\u4e4f\u7b56\u7565\u9c81\u68d2\u6027\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\uff0c\u7814\u7a76\u5f15\u5165\u4e86\u7b56\u7565\u98ce\u9669\u89c4\u907f\u7684\u6982\u5ff5\uff0c\u65e8\u5728\u63d0\u9ad8\u4e0e\u672a\u77e5\u4f19\u4f34\u5408\u4f5c\u65f6\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7b56\u7565\u98ce\u9669\u89c4\u907f\u6982\u5ff5\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5c06\u7b56\u7565\u98ce\u9669\u89c4\u907f\u4f5c\u4e3a\u539f\u5219\u6027\u7684\u5f52\u7eb3\u504f\u7f6e\u96c6\u6210\u5230\u4e86\u6807\u51c6\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e4b\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u8bbe\u8ba1\u4e0a\u5bf9\u4e8e\u4f19\u4f34\u884c\u4e3a\u7684\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5728\u5408\u4f5c\u6e38\u620f\u4e2d\u8fd8\u663e\u793a\u51fa\u66f4\u4f18\u7684\u5747\u8861\u7ed3\u679c\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u6216\u5b8c\u5168\u907f\u514d\u4e86\u642d\u4fbf\u8f66\u73b0\u8c61\u3002", "result": "\u901a\u8fc7\u5bf9\u591a\u4e2a\u534f\u4f5c\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u4e00\u4e2aLLM\u534f\u4f5c\u4efb\u52a1\uff09\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u7406\u8bba\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5404\u79cd\u534f\u4f5c\u4efb\u52a1\u4e2d\u4e0e\u4e0d\u540c\u7c7b\u578b\u7684\u3001\u4ee5\u524d\u672a\u89c1\u8fc7\u7684\u4f19\u4f34\u5b9e\u73b0\u4e00\u81f4\u800c\u53ef\u9760\u7684\u534f\u4f5c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5e76\u5e94\u7528\u7b56\u7565\u98ce\u9669\u89c4\u907f\u7684\u6982\u5ff5\uff0c\u7814\u7a76\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u9762\u5bf9\u65b0\u4f19\u4f34\u65f6\u7684\u534f\u4f5c\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002\u8fd9\u4e3a\u672a\u6765\u6784\u5efa\u66f4\u52a0\u7075\u6d3b\u3001\u9002\u5e94\u6027\u5f3a\u7684\u534f\u4f5c\u578b\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2602.21545", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21545", "abs": "https://arxiv.org/abs/2602.21545", "authors": ["Ruijie Zhang", "Yequan Zhao", "Ziyue Liu", "Zhengyang Wang", "Zheng Zhang"], "title": "Muon+: Towards Better Muon via One Additional Normalization Step", "comment": null, "summary": "The Muon optimizer has demonstrated promising performance in pre-training large language models through gradient (or momentum) orthogonalization. In this work, we propose a simple yet effective enhancement to Muon, namely Muon+, which introduces an additional normalization step after orthogonalization. We demonstrate the effectiveness of Muon+ through extensive pre-training experiments across a wide range of model scales and architectures. Our evaluation includes GPT-style models ranging from 130M to 774M parameters and LLaMA-style models ranging from 60M to 1B parameters. We comprehensively evaluate the effectiveness of Muon+ in the compute-optimal training regime and further extend the token-to-parameter (T2P) ratio to an industrial level of $\\approx 200$. Experimental results show that Muon+ provides a consistent boost on training and validation perplexity over Muon. We provide our code here: https://github.com/K1seki221/MuonPlus.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9Muon\u4f18\u5316\u5668\u7684\u6539\u8fdb\u7248\u672c\uff0c\u79f0\u4e3aMuon+\uff0c\u901a\u8fc7\u5728\u6b63\u4ea4\u5316\u540e\u6dfb\u52a0\u989d\u5916\u7684\u5f52\u4e00\u5316\u6b65\u9aa4\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMuon+\u76f8\u6bd4Muon\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u67b6\u6784\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u90fd\u80fd\u63d0\u4f9b\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u8fdb\u4e00\u6b65\u63d0\u9ad8Muon\u4f18\u5316\u5668\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u6b64\u5f15\u5165\u4e86\u989d\u5916\u7684\u5f52\u4e00\u5316\u6b65\u9aa4\u6765\u589e\u5f3a\u5176\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Muon+\uff0c\u5b83\u5728\u539f\u6709Muon\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u6b63\u4ea4\u5316\u540e\u7684\u5f52\u4e00\u5316\u5904\u7406\u3002\u8be5\u65b9\u6cd5\u88ab\u5e94\u7528\u4e8e\u4ece130M\u5230774M\u53c2\u6570\u7684GPT\u98ce\u683c\u6a21\u578b\u4ee5\u53ca\u4ece60M\u52301B\u53c2\u6570\u7684LLaMA\u98ce\u683c\u6a21\u578b\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u7684\u6a21\u578b\u89c4\u6a21\u4e0b\uff0c\u4f7f\u7528Muon+\u6bd4\u5355\u72ec\u4f7f\u7528Muon\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u56f0\u60d1\u5ea6\uff08perplexity\uff09\u3002\u6b64\u5916\uff0c\u8fd8\u5c06token-to-parameter\u6bd4\u7387\u6269\u5c55\u5230\u4e86\u7ea6200\u8fd9\u4e00\u5de5\u4e1a\u7ea7\u522b\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86Muon+\u4f5c\u4e3a\u5bf9Muon\u7684\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684\u6539\u8fdb\uff0c\u5728\u5e7f\u6cdb\u7684\u6a21\u578b\u5c3a\u5ea6\u548c\u67b6\u6784\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u6700\u4f18\u8bad\u7ec3\u6761\u4ef6\u4e0b\u4e5f\u80fd\u5e26\u6765\u663e\u8457\u7684\u597d\u5904\u3002"}}
{"id": "2602.21550", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2602.21550", "abs": "https://arxiv.org/abs/2602.21550", "authors": ["Zhao Yang", "Yi Duan", "Jiwei Zhu", "Ying Ba", "Chuan Cao", "Bing Su"], "title": "Extending Sequence Length is Not All You Need: Effective Integration of Multimodal Signals for Gene Expression Prediction", "comment": "Accepted at ICLR 2026", "summary": "Gene expression prediction, which predicts mRNA expression levels from DNA sequences, presents significant challenges. Previous works often focus on extending input sequence length to locate distal enhancers, which may influence target genes from hundreds of kilobases away. Our work first reveals that for current models, long sequence modeling can decrease performance. Even carefully designed algorithms only mitigate the performance degradation caused by long sequences. Instead, we find that proximal multimodal epigenomic signals near target genes prove more essential. Hence we focus on how to better integrate these signals, which has been overlooked. We find that different signal types serve distinct biological roles, with some directly marking active regulatory elements while others reflect background chromatin patterns that may introduce confounding effects. Simple concatenation may lead models to develop spurious associations with these background patterns. To address this challenge, we propose Prism, a framework that learns multiple combinations of high-dimensional epigenomic features to represent distinct background chromatin states and uses backdoor adjustment to mitigate confounding effects. Our experimental results demonstrate that proper modeling of multimodal epigenomic signals achieves state-of-the-art performance using only short sequences for gene expression prediction.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u5f53\u524d\u6a21\u578b\u800c\u8a00\uff0c\u957f\u5e8f\u5217\u5efa\u6a21\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002\u66f4\u91cd\u8981\u7684\u662f\u6574\u5408\u76ee\u6807\u57fa\u56e0\u9644\u8fd1\u7684\u591a\u6a21\u6001\u8868\u89c2\u9057\u4f20\u4fe1\u53f7\u3002\u4e3a\u6b64\u63d0\u51faPrism\u6846\u67b6\uff0c\u901a\u8fc7\u5b66\u4e60\u9ad8\u7ef4\u8868\u89c2\u9057\u4f20\u7279\u5f81\u7684\u591a\u79cd\u7ec4\u5408\u6765\u8868\u793a\u4e0d\u540c\u7684\u80cc\u666f\u67d3\u8272\u8d28\u72b6\u6001\uff0c\u5e76\u4f7f\u7528\u540e\u95e8\u8c03\u6574\u6765\u51cf\u8f7b\u6df7\u6dc6\u6548\u5e94\uff0c\u4ece\u800c\u5728\u4ec5\u4f7f\u7528\u77ed\u5e8f\u5217\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u5f80\u5f80\u96c6\u4e2d\u5728\u6269\u5c55\u8f93\u5165\u5e8f\u5217\u957f\u5ea6\u4ee5\u5b9a\u4f4d\u8fdc\u7aef\u589e\u5f3a\u5b50\u4e0a\uff0c\u800c\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u5bf9\u5f53\u524d\u6a21\u578b\u6765\u8bf4\uff0c\u957f\u5e8f\u5217\u5efa\u6a21\u5b9e\u9645\u4e0a\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u7814\u7a76\u8f6c\u800c\u5f3a\u8c03\u76ee\u6807\u57fa\u56e0\u9644\u8fd1\u8fd1\u7aef\u591a\u6a21\u6001\u8868\u89c2\u9057\u4f20\u4fe1\u53f7\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u8fd9\u4e9b\u4fe1\u53f7\u5bf9\u4e8e\u63d0\u9ad8\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86Prism\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5b66\u4e60\u9ad8\u7ef4\u5ea6\u8868\u89c2\u9057\u4f20\u7279\u5f81\u7684\u591a\u79cd\u7ec4\u5408\u65b9\u5f0f\uff0c\u4ee5\u6b64\u6765\u63cf\u7ed8\u51fa\u4e0d\u540c\u7684\u80cc\u666f\u67d3\u8272\u8d28\u72b6\u6001\uff0c\u5e76\u91c7\u7528\u540e\u95e8\u8c03\u6574\u7b56\u7565\u51cf\u5c11\u7531\u4e8e\u80cc\u666f\u6a21\u5f0f\u5e26\u6765\u7684\u6df7\u6dc6\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u6b63\u786e\u5904\u7406\u591a\u6a21\u6001\u8868\u89c2\u9057\u4f20\u4fe1\u53f7\uff0c\u5728\u4ec5\u5229\u7528\u8f83\u77edDNA\u5e8f\u5217\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u6700\u4f73\u6c34\u5e73\u7684\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u5355\u7eaf\u589e\u52a0\u5e8f\u5217\u957f\u5ea6\uff0c\u6709\u6548\u6574\u5408\u76ee\u6807\u57fa\u56e0\u90bb\u8fd1\u533a\u57df\u5185\u7684\u591a\u6a21\u6001\u8868\u89c2\u9057\u4f20\u4fe1\u606f\u5bf9\u4e8e\u6539\u5584\u57fa\u56e0\u8868\u8fbe\u9884\u6d4b\u6a21\u578b\u66f4\u4e3a\u5173\u952e\u3002"}}
{"id": "2602.21551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21551", "abs": "https://arxiv.org/abs/2602.21551", "authors": ["Zhihao Li", "Yu Feng", "Zhilu Lai", "Wei Wang"], "title": "From Basis to Basis: Gaussian Particle Representation for Interpretable PDE Operators", "comment": null, "summary": "Learning PDE dynamics for fluids increasingly relies on neural operators and Transformer-based models, yet these approaches often lack interpretability and struggle with localized, high-frequency structures while incurring quadratic cost in spatial samples. We propose representing fields with a Gaussian basis, where learned atoms carry explicit geometry (centers, anisotropic scales, weights) and form a compact, mesh-agnostic, directly visualizable state. Building on this representation, we introduce a Gaussian Particle Operator that acts in modal space: learned Gaussian modal windows perform a Petrov-Galerkin measurement, and PG Gaussian Attention enables global cross-scale coupling. This basis-to-basis design is resolution-agnostic and achieves near-linear complexity in N for a fixed modal budget, supporting irregular geometries and seamless 2D-to-3D extension. On standard PDE benchmarks and real datasets, our method attains state-of-the-art competitive accuracy while providing intrinsic interpretability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u57fa\u8868\u793a\u7684\u6d41\u4f53PDE\u52a8\u529b\u5b66\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u9ad8\u65af\u7c92\u5b50\u7b97\u5b50\u5b9e\u73b0\u4e86\u6a21\u6001\u7a7a\u95f4\u4e2d\u7684\u64cd\u4f5c\uff0c\u5177\u6709\u8fd1\u7ebf\u6027\u590d\u6742\u5ea6\u548c\u56fa\u6709\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u6807\u51c6PDE\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u795e\u7ecf\u7b97\u5b50\u548cTransformer\u6a21\u578b\u7684\u5b66\u4e60\u6d41\u4f53PDE\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u5904\u7406\u5c40\u90e8\u9ad8\u9891\u7ed3\u6784\uff0c\u5e76\u4e14\u968f\u7740\u7a7a\u95f4\u6837\u672c\u6570\u91cf\u589e\u52a0\u800c\u9762\u4e34\u4e8c\u6b21\u6210\u672c\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4f7f\u7528\u5e26\u6709\u660e\u786e\u51e0\u4f55\u5c5e\u6027\uff08\u4e2d\u5fc3\u3001\u5404\u5411\u5f02\u6027\u5c3a\u5ea6\u3001\u6743\u91cd\uff09\u7684\u9ad8\u65af\u57fa\u6765\u8868\u793a\u573a\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u7d27\u51d1\u3001\u4e0e\u7f51\u683c\u65e0\u5173\u4e14\u53ef\u4ee5\u76f4\u63a5\u53ef\u89c6\u5316\u7684\u72b6\u6001\uff1b\u57fa\u4e8e\u6b64\u8868\u793a\u6cd5\uff0c\u5f15\u5165\u4e86\u5728\u6a21\u6001\u7a7a\u95f4\u4e2d\u4f5c\u7528\u7684\u9ad8\u65af\u7c92\u5b50\u7b97\u5b50\uff1a\u5b66\u4e60\u5230\u7684\u9ad8\u65af\u6a21\u6001\u7a97\u53e3\u6267\u884cPetrov-Galerkin\u6d4b\u91cf\uff0c\u800cPG\u9ad8\u65af\u6ce8\u610f\u529b\u673a\u5236\u5219\u5141\u8bb8\u5168\u5c40\u8de8\u5c3a\u5ea6\u8026\u5408\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u6807\u51c6PDE\u57fa\u51c6\u6d4b\u8bd5\u53ca\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u529b\u5f3a\u7684\u6700\u65b0\u51c6\u786e\u5ea6\u8868\u73b0\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5185\u5728\u7684\u53ef\u89e3\u91ca\u6027\u652f\u6301\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u9ad8\u65af\u57fa\u7684\u65b9\u6cd5\u4e3a\u6d41\u4f53PDE\u52a8\u529b\u5b66\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u7684\u8def\u5f84\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u5904\u7406\u5c40\u90e8\u9ad8\u9891\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u8fd8\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.21565", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21565", "abs": "https://arxiv.org/abs/2602.21565", "authors": ["Seokwon Yoon", "Youngbin Choi", "Seunghyuk Cho", "Seungbeom Lee", "MoonJeong Park", "Dongwoo Kim"], "title": "Training-free Composition of Pre-trained GFlowNets for Multi-Objective Generation", "comment": "22 pages, 12 figures, 12 tables", "summary": "Generative Flow Networks (GFlowNets) learn to sample diverse candidates in proportion to a reward function, making them well-suited for scientific discovery, where exploring multiple promising solutions is crucial. Further extending GFlowNets to multi-objective settings has attracted growing interest since real-world applications often involve multiple, conflicting objectives. However, existing approaches require additional training for each set of objectives, limiting their applicability and incurring substantial computational overhead. We propose a training-free mixing policy that composes pre-trained GFlowNets at inference time, enabling rapid adaptation without finetuning or retraining. Importantly, our framework is flexible, capable of handling diverse reward combinations ranging from linear scalarization to complex non-linear logical operators, which are often handled separately in previous literature. We prove that our method exactly recovers the target distribution for linear scalarization and quantify the approximation quality for nonlinear operators through a distortion factor. Experiments on a synthetic 2D grid and real-world molecule-generation tasks demonstrate that our approach achieves performance comparable to baselines that require additional training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5728\u63a8\u7406\u65f6\u7ec4\u5408\u9884\u8bad\u7ec3GFlowNets\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u4ece\u7ebf\u6027\u6807\u91cf\u5316\u5230\u590d\u6742\u975e\u7ebf\u6027\u903b\u8f91\u8fd0\u7b97\u7b26\u7684\u591a\u6837\u5316\u5956\u52b1\u7ec4\u5408\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5408\u62102D\u7f51\u683c\u548c\u771f\u5b9e\u5206\u5b50\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0e\u9700\u8981\u989d\u5916\u8bad\u7ec3\u7684\u57fa\u7ebf\u76f8\u5f53\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u7ecf\u5e38\u6d89\u53ca\u591a\u4e2a\u76f8\u4e92\u51b2\u7a81\u7684\u76ee\u6807\uff0c\u4f46\u73b0\u6709\u7684\u591a\u76ee\u6807\u8bbe\u7f6e\u4e0b\u7684GFlowNets\u65b9\u6cd5\u9700\u8981\u5bf9\u6bcf\u7ec4\u76ee\u6807\u8fdb\u884c\u989d\u5916\u8bad\u7ec3\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u5e94\u7528\u5e76\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6df7\u5408\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u63a8\u7406\u9636\u6bb5\u7ec4\u5408\u9884\u8bad\u7ec3\u7684GFlowNets\uff0c\u4ee5\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u800c\u65e0\u9700\u5fae\u8c03\u6216\u91cd\u65b0\u8bad\u7ec3\u3002\u6846\u67b6\u7075\u6d3b\uff0c\u80fd\u591f\u5904\u7406\u4ece\u7ebf\u6027\u6807\u91cf\u5316\u5230\u590d\u6742\u7684\u975e\u7ebf\u6027\u903b\u8f91\u8fd0\u7b97\u7b26\u7684\u5404\u79cd\u5956\u52b1\u7ec4\u5408\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u5728\u5408\u62102D\u7f51\u683c\u548c\u5b9e\u9645\u5206\u5b50\u751f\u6210\u4efb\u52a1\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fbe\u5230\u4e86\u4e0e\u9700\u8981\u989d\u5916\u8bad\u7ec3\u7684\u57fa\u51c6\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65e0\u8bad\u7ec3\u6df7\u5408\u7b56\u7565\u4e3aGFlowNets\u5728\u591a\u76ee\u6807\u573a\u666f\u4e0b\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u3002"}}
{"id": "2602.21585", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21585", "abs": "https://arxiv.org/abs/2602.21585", "authors": ["Sweta Karlekar", "Carolina Zheng", "Magnus Saebo", "Nicolas Beltran-Velez", "Shuyang Yu", "John Bowlan", "Michal Kucer", "David Blei"], "title": "Duel-Evolve: Reward-Free Test-Time Scaling via LLM Self-Preferences", "comment": null, "summary": "Many applications seek to optimize LLM outputs at test time by iteratively proposing, scoring, and refining candidates over a discrete output space. Existing methods use a calibrated scalar evaluator for the target objective to guide search, but for many tasks such scores are unavailable, too sparse, or unreliable. Pairwise comparisons, by contrast, are often easier to elicit, still provide useful signal on improvement directions, and can be obtained from the LLM itself without external supervision. Building on this observation, we introduce Duel-Evolve, an evolutionary optimization algorithm that replaces external scalar rewards with pairwise preferences elicited from the same LLM used to generate candidates. Duel-Evolve aggregates these noisy candidate comparisons via a Bayesian Bradley-Terry model, yielding uncertainty-aware estimates of candidate quality. These quality estimates guide allocation of the comparison budget toward plausible optima using Double Thompson Sampling, as well as selection of high-quality parents to generate improved candidates. We evaluate Duel-Evolve on MathBench, where it achieves 20 percentage points higher accuracy over existing methods and baselines, and on LiveCodeBench, where it improves over comparable iterative methods by over 12 percentage points. Notably, the method requires no reward model, no ground-truth labels during search, and no hand-crafted scoring function. Results show that pairwise self-preferences provide strong optimization signal for test-time improvement over large, discrete output spaces.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDuel-Evolve\u7684\u8fdb\u5316\u4f18\u5316\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u6765\u81ea\u540c\u4e00\u8bed\u8a00\u6a21\u578b\u7684\u6210\u5bf9\u504f\u597d\u6765\u66ff\u4ee3\u5916\u90e8\u6807\u91cf\u5956\u52b1\uff0c\u901a\u8fc7\u8d1d\u53f6\u65afBradley-Terry\u6a21\u578b\u805a\u5408\u8fd9\u4e9b\u566a\u58f0\u5019\u9009\u6bd4\u8f83\uff0c\u4ece\u800c\u4f30\u8ba1\u5019\u9009\u8d28\u91cf\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u5956\u52b1\u6a21\u578b\u3001\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u771f\u5b9e\u6807\u7b7e\u6216\u624b\u5de5\u5236\u4f5c\u7684\u8bc4\u5206\u51fd\u6570\uff0c\u5e76\u4e14\u5728MathBench\u548cLiveCodeBench\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u4e8e\u8bb8\u591a\u4efb\u52a1\u800c\u8a00\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u4f7f\u7528\u6821\u51c6\u540e\u7684\u6807\u91cf\u8bc4\u4f30\u5668\u6765\u6307\u5bfc\u641c\u7d22\uff0c\u4f46\u8fd9\u6837\u7684\u5206\u6570\u53ef\u80fd\u4e0d\u53ef\u7528\u3001\u8fc7\u4e8e\u7a00\u758f\u6216\u4e0d\u53ef\u9760\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6210\u5bf9\u6bd4\u8f83\u5f80\u5f80\u66f4\u5bb9\u6613\u83b7\u5f97\uff0c\u4ecd\u7136\u80fd\u591f\u63d0\u4f9b\u6539\u8fdb\u65b9\u5411\u7684\u6709\u6548\u4fe1\u53f7\uff0c\u5e76\u4e14\u53ef\u4ee5\u4ece\u8bed\u8a00\u6a21\u578b\u672c\u8eab\u83b7\u5f97\u800c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002\u57fa\u4e8e\u8fd9\u4e00\u89c2\u5bdf\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86Duel-Evolve\u7b97\u6cd5\u3002", "method": "Duel-Evolve\u662f\u4e00\u79cd\u8fdb\u5316\u4f18\u5316\u7b97\u6cd5\uff0c\u5b83\u4f7f\u7528\u6765\u81ea\u751f\u6210\u5019\u9009\u8005\u7684\u540c\u4e00\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6210\u5bf9\u504f\u597d\u53d6\u4ee3\u4e86\u5916\u90e8\u6807\u91cf\u5956\u52b1\u3002\u901a\u8fc7\u8d1d\u53f6\u65afBradley-Terry\u6a21\u578b\u6c47\u603b\u8fd9\u4e9b\u566a\u97f3\u5019\u9009\u6bd4\u8f83\uff0c\u4ea7\u751f\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u610f\u8bc6\u7684\u5019\u9009\u8d28\u91cf\u4f30\u8ba1\u3002\u8fd9\u4e9b\u8d28\u91cf\u4f30\u8ba1\u6307\u5bfc\u7740\u6bd4\u8f83\u9884\u7b97\u5411\u53ef\u80fd\u6700\u4f18\u89e3\u5206\u914d\uff0c\u540c\u65f6\u9009\u62e9\u9ad8\u8d28\u91cf\u7236\u4ee3\u4ee5\u751f\u6210\u6539\u8fdb\u540e\u7684\u5019\u9009\u8005\u3002", "result": "\u5728MathBench\u4e0a\uff0cDuel-Evolve\u6bd4\u73b0\u6709\u65b9\u6cd5\u548c\u57fa\u7ebf\u9ad8\u51fa20\u4e2a\u767e\u5206\u70b9\uff1b\u5728LiveCodeBench\u4e0a\uff0c\u4e0e\u53ef\u6bd4\u8f83\u7684\u8fed\u4ee3\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b83\u63d0\u9ad8\u4e86\u8d85\u8fc712\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5927\u89c4\u6a21\u79bb\u6563\u8f93\u51fa\u7a7a\u95f4\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\u6539\u5584\uff0c\u6210\u5bf9\u81ea\u6211\u504f\u597d\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u4f18\u5316\u4fe1\u53f7\u3002\u6b64\u65b9\u6cd5\u4e0d\u9700\u8981\u4efb\u4f55\u5956\u52b1\u6a21\u578b\u3001\u641c\u7d22\u671f\u95f4\u7684\u771f\u5b9e\u6807\u7b7e\u6216\u624b\u5de5\u5236\u4f5c\u7684\u8bc4\u5206\u51fd\u6570\u3002"}}
{"id": "2602.21597", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21597", "abs": "https://arxiv.org/abs/2602.21597", "authors": ["Zhongwei Xie", "Jiaxin Bai", "Shujie Liu", "Haoyu Huang", "Yufei Li", "Yisen Gao", "Hong Ting Tsang", "Yangqiu Song"], "title": "NGDB-Zoo: Towards Efficient and Scalable Neural Graph Databases Training", "comment": null, "summary": "Neural Graph Databases (NGDBs) facilitate complex logical reasoning over incomplete knowledge structures, yet their training efficiency and expressivity are constrained by rigid query-level batching and structure-exclusive embeddings. We present NGDB-Zoo, a unified framework that resolves these bottlenecks by synergizing operator-level training with semantic augmentation. By decoupling logical operators from query topologies, NGDB-Zoo transforms the training loop into a dynamically scheduled data-flow execution, enabling multi-stream parallelism and achieving a $1.8\\times$ - $6.8\\times$ throughput compared to baselines. Furthermore, we formalize a decoupled architecture to integrate high-dimensional semantic priors from Pre-trained Text Encoders (PTEs) without triggering I/O stalls or memory overflows. Extensive evaluations on six benchmarks, including massive graphs like ogbl-wikikg2 and ATLAS-Wiki, demonstrate that NGDB-Zoo maintains high GPU utilization across diverse logical patterns and significantly mitigates representation friction in hybrid neuro-symbolic reasoning.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86NGDB-Zoo\uff0c\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u64cd\u4f5c\u7ea7\u8bad\u7ec3\u548c\u8bed\u4e49\u589e\u5f3a\u6765\u89e3\u51b3\u795e\u7ecf\u56fe\u6570\u636e\u5e93\u7684\u8bad\u7ec3\u6548\u7387\u548c\u8868\u8fbe\u529b\u95ee\u9898\u3002\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u5904\u7406\u541e\u5410\u91cf\uff0c\u5e76\u4e14\u80fd\u591f\u6574\u5408\u9884\u8bad\u7ec3\u6587\u672c\u7f16\u7801\u5668\u7684\u9ad8\u7ef4\u8bed\u4e49\u5148\u9a8c\u77e5\u8bc6\uff0c\u540c\u65f6\u907f\u514dI/O\u505c\u6ede\u6216\u5185\u5b58\u6ea2\u51fa\u7684\u95ee\u9898\u3002\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u56fe\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u9ad8GPU\u5229\u7528\u7387\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u6df7\u5408\u795e\u7ecf-\u7b26\u53f7\u63a8\u7406\u4e2d\u7684\u8868\u793a\u6469\u64e6\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u56fe\u6570\u636e\u5e93\uff08NGDBs\uff09\u867d\u7136\u80fd\u591f\u5904\u7406\u4e0d\u5b8c\u6574\u77e5\u8bc6\u7ed3\u6784\u4e0a\u7684\u590d\u6742\u903b\u8f91\u63a8\u7406\uff0c\u4f46\u5176\u8bad\u7ec3\u6548\u7387\u548c\u8868\u8fbe\u80fd\u529b\u53d7\u5230\u56fa\u5b9a\u67e5\u8be2\u7ea7\u522b\u6279\u5904\u7406\u548c\u7ed3\u6784\u4e13\u5c5e\u5d4c\u5165\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86NGDB-Zoo\uff0c\u4e00\u4e2a\u5c06\u64cd\u4f5c\u7ea7\u8bad\u7ec3\u4e0e\u8bed\u4e49\u589e\u5f3a\u76f8\u7ed3\u5408\u7684\u7edf\u4e00\u6846\u67b6\u3002\u901a\u8fc7\u5c06\u903b\u8f91\u8fd0\u7b97\u7b26\u4e0e\u67e5\u8be2\u62d3\u6251\u89e3\u8026\uff0c\u4f7f\u5f97\u8bad\u7ec3\u5faa\u73af\u8f6c\u53d8\u4e3a\u52a8\u6001\u8c03\u5ea6\u7684\u6570\u636e\u6d41\u6267\u884c\uff0c\u4ece\u800c\u5b9e\u73b0\u591a\u6d41\u5e76\u884c\u5316\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u89e3\u8026\u67b6\u6784\u4ee5\u96c6\u6210\u6765\u81ea\u9884\u8bad\u7ec3\u6587\u672c\u7f16\u7801\u5668\uff08PTEs\uff09\u7684\u9ad8\u7ef4\u8bed\u4e49\u5148\u9a8c\uff0c\u800c\u4e0d\u5f15\u8d77I/O\u505c\u6ede\u6216\u5185\u5b58\u6ea2\u51fa\u3002", "result": "NGDB-Zoo\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e861.8\u500d\u81f36.8\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002\u5728\u5305\u62ecogbl-wikikg2\u548cATLAS-Wiki\u5728\u5185\u7684\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u540c\u7684\u903b\u8f91\u6a21\u5f0f\u4e0b\u7ef4\u6301\u9ad8GPU\u5229\u7528\u7387\uff0c\u5e76\u5927\u5e45\u7f13\u89e3\u4e86\u6df7\u5408\u795e\u7ecf-\u7b26\u53f7\u63a8\u7406\u4e2d\u7684\u8868\u793a\u6469\u64e6\u95ee\u9898\u3002", "conclusion": "NGDB-Zoo\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\u6765\u514b\u670d\u73b0\u6709\u795e\u7ecf\u56fe\u6570\u636e\u5e93\u9762\u4e34\u7684\u8bad\u7ec3\u6548\u7387\u4f4e\u53ca\u8868\u8fbe\u529b\u53d7\u9650\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u521b\u65b0\u6027\u7684\u64cd\u4f5c\u7ea7\u8bad\u7ec3\u673a\u5236\u548c\u8bed\u4e49\u589e\u5f3a\u7b56\u7565\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5904\u7406\u901f\u5ea6\uff0c\u4e5f\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u4e8e\u590d\u6742\u903b\u8f91\u5173\u7cfb\u7684\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2602.21648", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2602.21648", "abs": "https://arxiv.org/abs/2602.21648", "authors": ["Toktam Khatibi"], "title": "Multimodal Survival Modeling and Fairness-Aware Clinical Machine Learning for 5-Year Breast Cancer Risk Prediction", "comment": null, "summary": "Clinical risk prediction models often underperform in real-world settings due to poor calibration, limited transportability, and subgroup disparities. These challenges are amplified in high-dimensional multimodal cancer datasets characterized by complex feature interactions and a p >> n structure. We present a fully reproducible multimodal machine learning framework for 5-year overall survival prediction in breast cancer, integrating clinical variables with high-dimensional transcriptomic and copy-number alteration (CNA) features from the METABRIC cohort.\n  After variance- and sparsity-based filtering and dimensionality reduction, models were trained using stratified train/validation/test splits with validation-based hyperparameter tuning. Two survival approaches were compared: an elastic-net regularized Cox model (CoxNet) and a gradient-boosted survival tree model implemented using XGBoost. CoxNet provides embedded feature selection and stable estimation, whereas XGBoost captures nonlinear effects and higher-order interactions.\n  Performance was assessed using time-dependent area under the ROC curve (AUC), average precision (AP), calibration curves, Brier score, and bootstrapped 95 percent confidence intervals. CoxNet achieved validation and test AUCs of 98.3 and 96.6, with AP values of 90.1 and 80.4. XGBoost achieved validation and test AUCs of 98.6 and 92.5, with AP values of 92.5 and 79.9. Fairness diagnostics showed stable discrimination across age groups, estrogen receptor status, molecular subtypes, and menopausal state.\n  This work introduces a governance-oriented multimodal survival framework emphasizing calibration, fairness auditing, robustness, and reproducibility for high-dimensional clinical machine learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4e73\u817a\u764c5\u5e74\u603b\u4f53\u751f\u5b58\u9884\u6d4b\uff0c\u7ed3\u5408\u4e86\u4e34\u5e8a\u53d8\u91cf\u4e0e\u9ad8\u7ef4\u8f6c\u5f55\u7ec4\u548c\u62f7\u8d1d\u6570\u53d8\u5f02\u7279\u5f81\u3002\u901a\u8fc7\u6bd4\u8f83\u5f39\u6027\u7f51\u6b63\u5219\u5316\u7684Cox\u6a21\u578b\uff08CoxNet\uff09\u548c\u57fa\u4e8eXGBoost\u7684\u68af\u5ea6\u63d0\u5347\u751f\u5b58\u6811\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u4e24\u79cd\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6821\u51c6\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u56e0\u6821\u51c6\u4e0d\u4f73\u3001\u53ef\u79fb\u690d\u6027\u5dee\u53ca\u4e9a\u7fa4\u5dee\u5f02\u800c\u8868\u73b0\u6b20\u4f73\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u591a\u6a21\u6001\u764c\u75c7\u6570\u636e\u96c6\u4e2d\u8fd9\u4e9b\u95ee\u9898\u66f4\u4e3a\u7a81\u51fa\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u5168\u53ef\u91cd\u590d\u7684\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u4e86\u6765\u81eaMETABRIC\u961f\u5217\u7684\u4e34\u5e8a\u53d8\u91cf\u4ee5\u53ca\u9ad8\u7ef4\u8f6c\u5f55\u7ec4\u5b66\u548c\u62f7\u8d1d\u6570\u53d8\u5f02\u7279\u5f81\u3002\u7ecf\u8fc7\u65b9\u5dee-\u7a00\u758f\u6027\u8fc7\u6ee4\u548c\u964d\u7ef4\u5904\u7406\u540e\uff0c\u4f7f\u7528\u5206\u5c42\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u62c6\u5206\u6cd5\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u9a8c\u8bc1\u96c6\u8c03\u6574\u8d85\u53c2\u6570\u3002\u6bd4\u8f83\u4e86\u4e24\u79cd\u751f\u5b58\u5206\u6790\u65b9\u6cd5\uff1a\u4e00\u79cd\u662f\u5f39\u6027\u7f51\u6b63\u5219\u5316\u7684Cox\u6a21\u578b(CoxNet)\uff0c\u53e6\u4e00\u79cd\u662f\u5229\u7528XGBoost\u5b9e\u73b0\u7684\u68af\u5ea6\u63d0\u5347\u751f\u5b58\u6811\u6a21\u578b\u3002", "result": "CoxNet\u5728\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u7684AUC\u5206\u522b\u4e3a98.3\u548c96.6\uff0cAP\u503c\u4e3a90.1\u548c80.4\uff1bXGBoost\u5bf9\u5e94\u7684AUC\u4e3a98.6\u548c92.5\uff0cAP\u503c\u4e3a92.5\u548c79.9\u3002\u516c\u5e73\u6027\u8bca\u65ad\u8868\u660e\uff0c\u5728\u4e0d\u540c\u5e74\u9f84\u7ec4\u3001\u96cc\u6fc0\u7d20\u53d7\u4f53\u72b6\u6001\u3001\u5206\u5b50\u4e9a\u578b\u53ca\u66f4\u5e74\u671f\u72b6\u6001\u4e4b\u95f4\u5177\u6709\u7a33\u5b9a\u7684\u533a\u5206\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9762\u5411\u6cbb\u7406\u7684\u591a\u6a21\u6001\u751f\u5b58\u5206\u6790\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5728\u6821\u51c6\u3001\u516c\u5e73\u5ba1\u8ba1\u3001\u9c81\u68d2\u6027\u548c\u53ef\u91cd\u590d\u6027\u65b9\u9762\u7684\u8003\u8651\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u5ea6\u4e34\u5e8a\u673a\u5668\u5b66\u4e60\u73af\u5883\u3002"}}
{"id": "2602.21674", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.21674", "abs": "https://arxiv.org/abs/2602.21674", "authors": ["Loes Kruger", "Sebastian Junges", "Jurriaan Rot"], "title": "Error-awareness Accelerates Active Automata Learning", "comment": null, "summary": "Active automata learning (AAL) algorithms can learn a behavioral model of a system from interacting with it. The primary challenge remains scaling to larger models, in particular in the presence of many possible inputs to the system. Modern AAL algorithms fail to scale even if, in every state, most inputs lead to errors. In various challenging problems from the literature, these errors are observable, i.e., they emit a known error output. Motivated by these problems, we study learning these systems more efficiently. Further, we consider various degrees of knowledge about which inputs are non-error producing at which state. For each level of knowledge, we provide a matching adaptation of the state-of-the-art AAL algorithm L# to make the most of this domain knowledge. Our empirical evaluation demonstrates that the methods accelerate learning by orders of magnitude with strong but realistic domain knowledge to a single order of magnitude with limited domain knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u7b97\u6cd5\uff0c\u9488\u5bf9\u7cfb\u7edf\u4e2d\u591a\u6570\u8f93\u5165\u5bfc\u81f4\u9519\u8bef\u7684\u95ee\u9898\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u7a0b\u5ea6\u7684\u77e5\u8bc6\u8c03\u6574\u7b97\u6cd5\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u6709\u5f3a\u9886\u57df\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u5c06\u5b66\u4e60\u901f\u5ea6\u63d0\u9ad8\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5728\u6709\u9650\u9886\u57df\u77e5\u8bc6\u4e0b\u4e5f\u80fd\u63d0\u9ad8\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709\u7684\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u578b\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u7cfb\u7edf\u9762\u4e34\u8bb8\u591a\u53ef\u80fd\u8f93\u5165\u65f6\u3002\u5373\u4f7f\u5728\u6bcf\u4e2a\u72b6\u6001\u4e0b\u5927\u591a\u6570\u8f93\u5165\u90fd\u4f1a\u5bfc\u81f4\u9519\u8bef\uff0c\u73b0\u4ee3\u7b97\u6cd5\u4e5f\u96be\u4ee5\u6269\u5c55\u3002\u672c\u6587\u65e8\u5728\u66f4\u6709\u6548\u5730\u5b66\u4e60\u8fd9\u7c7b\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5f53\u9519\u8bef\u662f\u53ef\u89c2\u5bdf\u4e14\u5df2\u77e5\u5176\u8f93\u51fa\u65f6\u3002", "method": "\u4f5c\u8005\u8003\u8651\u4e86\u5173\u4e8e\u54ea\u4e9b\u8f93\u5165\u4e0d\u4f1a\u5728\u54ea\u4e2a\u72b6\u6001\u4ea7\u751f\u9519\u8bef\u7684\u4e0d\u540c\u7a0b\u5ea6\u7684\u77e5\u8bc6\uff0c\u5e76\u4e3a\u6bcf\u79cd\u77e5\u8bc6\u6c34\u5e73\u63d0\u4f9b\u4e86\u73b0\u6709\u6700\u4f18AAL\u7b97\u6cd5L#\u7684\u76f8\u5e94\u8c03\u6574\u7248\u672c\uff0c\u4ee5\u4fbf\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u9886\u57df\u77e5\u8bc6\u6765\u4f18\u5316\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5f3a\u5927\u7684\u4f46\u73b0\u5b9e\u7684\u9886\u57df\u77e5\u8bc6\u65f6\u80fd\u591f\u5c06\u5b66\u4e60\u52a0\u901f\u51e0\u4e2a\u6570\u91cf\u7ea7\uff1b\u800c\u5728\u4ec5\u6709\u6709\u9650\u9886\u57df\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u5b9e\u73b0\u5355\u4e2a\u6570\u91cf\u7ea7\u7684\u5b66\u4e60\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u7a0b\u5ea6\u7684\u9886\u57df\u77e5\u8bc6\u6765\u8c03\u6574\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5728\u9762\u5bf9\u5927\u91cf\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u8f93\u5165\u65f6\u663e\u8457\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2602.21680", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.21680", "abs": "https://arxiv.org/abs/2602.21680", "authors": ["David Eckel", "Henri Mee\u00df"], "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning", "comment": "16 pages, 10 Figures, Preprint", "summary": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e8f\u5217\u8bad\u7ec3\u65b9\u6848\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u79f0\u4e3a\u5c42\u6b21\u9886\u5bfc\u6279\u8bc4\u5bb6\uff08HLC\uff09\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u89c6\u89d2\uff0c\u5728\u4e0d\u540c\u5c42\u6b21\u4e0a\u5b66\u4e60\uff0c\u4ece\u800c\u5728\u5408\u4f5c\u3001\u975e\u901a\u4fe1\u548c\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u5c40\u90e8\u6216\u5168\u5c40\u89c6\u89d2\u4e4b\u4e00\uff0c\u9650\u5236\u4e86\u5176\u5904\u7406\u9700\u8981\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u4ee5\u4ece\u591a\u4e2a\u89c6\u89d2\u5728\u4e0d\u540c\u5c42\u7ea7\u5b66\u4e60\u7684\u65b0\u9896\u8bad\u7ec3\u65b9\u6848\u548c\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u5c42\u6b21\u9886\u5bfc\u6279\u8bc4\u5bb6\uff08HLC\uff09\u6846\u67b6\uff0c\u53d7\u5230\u56e2\u961f\u7ed3\u6784\u4e2d\u81ea\u7136\u51fa\u73b0\u7684\u5206\u5e03\u542f\u53d1\uff0c\u5c06\u9075\u5faa\u9ad8\u5c42\u6b21\u76ee\u6807\u4e0e\u4f4e\u5c42\u6b21\u6267\u884c\u76f8\u7ed3\u5408\u3002HLC\u901a\u8fc7\u5f15\u5165\u591a\u5c42\u6b21\uff0c\u5229\u7528\u5c40\u90e8\u548c\u5168\u5c40\u89c6\u89d2\u6765\u63d0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6837\u672c\u6548\u7387\u548c\u7a33\u5065\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHLC\u5728\u5408\u4f5c\u6027\u3001\u65e0\u901a\u8baf\u4ee5\u53ca\u90e8\u5206\u53ef\u89c2\u6d4b\u7684MARL\u57fa\u51c6\u4e0a\u4f18\u4e8e\u5355\u5c42\u6b21\u57fa\u7ebf\uff0c\u5e76\u4e14\u968f\u7740\u667a\u80fd\u4f53\u6570\u91cf\u548c\u96be\u5ea6\u7684\u589e\u52a0\uff0c\u5b83\u80fd\u591f\u7a33\u5065\u5730\u6269\u5c55\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u591a\u5c42\u7ea7\u5e76\u7ed3\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u89c6\u89d2\u8fdb\u884c\u5b66\u4e60\uff0cHLC\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u6837\u672c\u6548\u7387\u548c\u7b56\u7565\u7a33\u5065\u6027\u65b9\u9762\u3002"}}
{"id": "2602.21693", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21693", "abs": "https://arxiv.org/abs/2602.21693", "authors": ["Jiafeng Lin", "Yuxuan Wang", "Huakun Luo", "Zhongyi Pei", "Jianmin Wang"], "title": "TiMi: Empower Time Series Transformers with Multimodal Mixture of Experts", "comment": null, "summary": "Multimodal time series forecasting has garnered significant attention for its potential to provide more accurate predictions than traditional single-modality models by leveraging rich information inherent in other modalities. However, due to fundamental challenges in modality alignment, existing methods often struggle to effectively incorporate multimodal data into predictions, particularly textual information that has a causal influence on time series fluctuations, such as emergency reports and policy announcements. In this paper, we reflect on the role of textual information in numerical forecasting and propose Time series transformers with Multimodal Mixture-of-Experts, TiMi, to unleash the causal reasoning capabilities of LLMs. Concretely, TiMi utilizes LLMs to generate inferences on future developments, which serve as guidance for time series forecasting. To seamlessly integrate both exogenous factors and time series into predictions, we introduce a Multimodal Mixture-of-Experts (MMoE) module as a lightweight plug-in to empower Transformer-based time series models for multimodal forecasting, eliminating the need for explicit representation-level alignment. Experimentally, our proposed TiMi demonstrates consistent state-of-the-art performance on sixteen real-world multimodal forecasting benchmarks, outperforming advanced baselines while offering both strong adaptability and interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTiMi\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u6765\u751f\u6210\u5bf9\u672a\u6765\u53d1\u5c55\u7684\u63a8\u65ad\uff0c\u4ece\u800c\u6307\u5bfc\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002TiMi\u5f15\u5165\u4e86\u591a\u6a21\u6001\u6df7\u5408\u4e13\u5bb6\u6a21\u5757\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u63d2\u4ef6\uff0c\u4ee5\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5728\u591a\u6a21odal\u9884\u6d4b\u4e2d\u7684\u80fd\u529b\uff0c\u65e0\u9700\u663e\u5f0f\u7684\u8868\u5f81\u7ea7\u522b\u5bf9\u9f50\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTiMi\u5728\u5341\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u9884\u6d4b\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5148\u8fdb\u57fa\u7ebf\uff0c\u5e76\u4e14\u5177\u6709\u5f3a\u5927\u7684\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u80fd\u591f\u901a\u8fc7\u5229\u7528\u5176\u4ed6\u6a21\u5f0f\u4e2d\u7684\u4e30\u5bcc\u4fe1\u606f\u63d0\u4f9b\u6bd4\u4f20\u7edf\u5355\u4e00\u6a21\u5f0f\u6a21\u578b\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u6a21\u6001\u5bf9\u9f50\u7684\u57fa\u672c\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u6709\u6548\u5c06\u591a\u6a21\u6001\u6570\u636e\uff08\u7279\u522b\u662f\u6587\u672c\u4fe1\u606f\uff09\u7eb3\u5165\u9884\u6d4b\u4e2d\u3002\u6587\u672c\u4fe1\u606f\u5982\u7d27\u6025\u62a5\u544a\u548c\u653f\u7b56\u516c\u544a\u7b49\u5bf9\u65f6\u95f4\u5e8f\u5217\u6ce2\u52a8\u6709\u56e0\u679c\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u6587\u672c\u4fe1\u606f\u5728\u6570\u503c\u9884\u6d4b\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Time series transformers with Multimodal Mixture-of-Experts (TiMi)\uff0c\u5b83\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4ea7\u751f\u5bf9\u672a\u6765\u53d1\u5c55\u7684\u63a8\u6d4b\uff0c\u4ee5\u6b64\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u63d0\u4f9b\u6307\u5bfc\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u65e0\u7f1d\u6574\u5408\u5916\u751f\u56e0\u7d20\u4e0e\u65f6\u95f4\u5e8f\u5217\u8fdb\u5165\u9884\u6d4b\u8fc7\u7a0b\uff0c\u7814\u7a76\u8005\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aMultimodal Mixture-of-Experts (MMoE) \u7684\u6a21\u5757\u4f5c\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u63d2\u4ef6\uff0c\u589e\u5f3a\u4e86\u57fa\u4e8eTransformer\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5904\u7406\u591a\u6a21\u6001\u9884\u62a5\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u9700\u8981\u5728\u8868\u793a\u5c42\u9762\u4e0a\u8fdb\u884c\u660e\u786e\u7684\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5341\u516d\u4e2a\u5b9e\u9645\u5e94\u7528\u7684\u591a\u6a21\u6001\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684TiMi\u65b9\u6cd5\u4e00\u81f4\u5730\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u8868\u73b0\uff0c\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u9ad8\u7ea7\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fd8\u5c55\u73b0\u4e86\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u89e3\u91ca\u6027\u3002", "conclusion": "TiMi\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u63d0\u5347\u4e86\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u6548\u679c\uff0c\u5c24\u5176\u662f\u901a\u8fc7\u6709\u6548\u5229\u7528\u6587\u672c\u4fe1\u606f\u6765\u6539\u8fdb\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5176\u8bbe\u8ba1\u5141\u8bb8\u66f4\u597d\u5730\u6574\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u5165\u6570\u636e\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f18\u79c0\u7684\u6027\u80fd\u3001\u9002\u5e94\u6027\u53ca\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.21701", "categories": ["cs.LG", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21701", "abs": "https://arxiv.org/abs/2602.21701", "authors": ["Michele Cazzola", "Alberto Ghione", "Lucia Sargentini", "Julien Nespoulous", "Riccardo Finotello"], "title": "Learning Complex Physical Regimes via Coverage-oriented Uncertainty Quantification: An application to the Critical Heat Flux", "comment": "34 pages, 14 figures", "summary": "A central challenge in scientific machine learning (ML) is the correct representation of physical systems governed by multi-regime behaviours. In these scenarios, standard data analysis techniques often fail to capture the nature of the data, as the system's response varies significantly across the state space due to its stochasticity and the different physical regimes. Uncertainty quantification (UQ) should thus not be viewed merely as a safety assessment, but as a support to the learning task itself, guiding the model to internalise the behaviour of the data. We address this by focusing on the Critical Heat Flux (CHF) benchmark and dataset presented by the OECD/NEA Expert Group on Reactor Systems Multi-Physics. This case study represents a test for scientific ML due to the non-linear dependence of CHF on the inputs and the existence of distinct microscopic physical regimes. These regimes exhibit diverse statistical profiles, a complexity that requires UQ techniques to internalise the data behaviour and ensure reliable predictions. In this work, we conduct a comparative analysis of UQ methodologies to determine their impact on physical representation. We contrast post-hoc methods, specifically conformal prediction, against end-to-end coverage-oriented pipelines, including (Bayesian) heteroscedastic regression and quality-driven losses. These approaches treat uncertainty not as a final metric, but as an active component of the optimisation process, modelling the prediction and its behaviour simultaneously. We show that while post-hoc methods ensure statistical calibration, coverage-oriented learning effectively reshapes the model's representation to match the complex physical regimes. The result is a model that delivers not only high predictive accuracy but also a physically consistent uncertainty estimation that adapts dynamically to the intrinsic variability of the CHF.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u591a\u7269\u7406\u673a\u5236\u7cfb\u7edf\u6b63\u786e\u8868\u793a\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u4e0d\u540c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\u5728\u4e34\u754c\u70ed\u6d41\u5bc6\u5ea6(CHF)\u9884\u6d4b\u4e0a\u7684\u5e94\u7528\u6548\u679c\uff0c\u53d1\u73b0\u8986\u76d6\u5bfc\u5411\u7684\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u8c03\u6574\u6a21\u578b\u4ee5\u9002\u5e94\u590d\u6742\u7684\u7269\u7406\u673a\u5236\uff0c\u4ece\u800c\u4e0d\u4ec5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e0e\u5185\u5728\u53d8\u5f02\u6027\u76f8\u5339\u914d\u7684\u7269\u7406\u4e00\u81f4\u6027\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "motivation": "\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u9762\u4e34\u7684\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u662f\u5982\u4f55\u51c6\u786e\u5730\u8868\u793a\u7531\u591a\u79cd\u7269\u7406\u673a\u5236\u63a7\u5236\u7684\u7cfb\u7edf\u3002\u4f20\u7edf\u7684\u6570\u636e\u5206\u6790\u6280\u672f\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u5230\u8fd9\u4e9b\u7cfb\u7edf\u7684\u6570\u636e\u672c\u8d28\uff0c\u56e0\u4e3a\u7cfb\u7edf\u54cd\u5e94\u7531\u4e8e\u5176\u968f\u673a\u6027\u548c\u4e0d\u540c\u7269\u7406\u673a\u5236\u7684\u5b58\u5728\uff0c\u5728\u72b6\u6001\u7a7a\u95f4\u5185\u53d8\u5316\u6781\u5927\u3002\u56e0\u6b64\uff0c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316(UQ)\u4e0d\u4ec5\u4ec5\u662f\u5b89\u5168\u8bc4\u4f30\u5de5\u5177\uff0c\u66f4\u662f\u652f\u6301\u5b66\u4e60\u4efb\u52a1\u672c\u8eab\u7684\u5173\u952e\uff0c\u5e2e\u52a9\u6a21\u578b\u5185\u5316\u6570\u636e\u7684\u884c\u4e3a\u7279\u5f81\u3002", "method": "\u7814\u7a76\u805a\u7126\u4e8eOECD/NEA\u4e13\u5bb6\u5c0f\u7ec4\u63d0\u4f9b\u7684\u4e34\u754c\u70ed\u6d41\u5bc6\u5ea6(CHF)\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u91c7\u7528\u6bd4\u8f83\u5206\u6790\u6cd5\u6765\u8bc4\u4f30\u4e0d\u540cUQ\u65b9\u6cd5\u5bf9\u4e8e\u7269\u7406\u8868\u73b0\u7684\u5f71\u54cd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c06\u540e\u9a8c\u65b9\u6cd5\u5373\u4e00\u81f4\u6027\u9884\u6d4b\u4e0e\u7aef\u5230\u7aef\u8986\u76d6\u5bfc\u5411\u6d41\u7a0b\u5305\u62ec(\u8d1d\u53f6\u65af)\u5f02\u65b9\u5dee\u56de\u5f52\u53ca\u8d28\u91cf\u9a71\u52a8\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u540e\u9a8c\u65b9\u6cd5\u4fdd\u8bc1\u4e86\u7edf\u8ba1\u6821\u51c6\u6027\uff0c\u4f46\u8986\u76d6\u5bfc\u5411\u7684\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u91cd\u5851\u6a21\u578b\u8868\u5f81\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u5339\u914d\u590d\u6742\u7269\u7406\u673a\u5236\u3002\u8fd9\u6837\u5f97\u5230\u7684\u6a21\u578b\u4e0d\u4ec5\u80fd\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u8fd8\u80fd\u751f\u6210\u968fCHF\u5185\u5728\u53d8\u5f02\u6027\u52a8\u6001\u8c03\u6574\u7684\u7269\u7406\u4e00\u81f4\u6027\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u5904\u7406\u50cfCHF\u8fd9\u6837\u7684\u591a\u7269\u7406\u673a\u5236\u95ee\u9898\u65f6\uff0c\u91c7\u7528\u7279\u5b9a\u8bbe\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u8868\u73b0\u529b\u548c\u53ef\u9760\u6027\u3002\u7279\u522b\u5730\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e2a\u6d3b\u8dc3\u7ec4\u6210\u90e8\u5206\u800c\u975e\u6700\u7ec8\u5ea6\u91cf\u6307\u6807\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4f7f\u6a21\u578b\u540c\u65f6\u6a21\u62df\u9884\u6d4b\u53ca\u5176\u884c\u4e3a\u7279\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u52a0\u7cbe\u51c6\u4e14\u53ef\u9760\u7684\u9884\u6d4b\u3002"}}
{"id": "2602.21750", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21750", "abs": "https://arxiv.org/abs/2602.21750", "authors": ["Aleena Siji", "Amir Mohammad Karimi Mamaghan", "Ferdinand Kapl", "Tobias H\u00f6ppe", "Emmanouil Angelis", "Andrea Dittadi", "Maurice Brenner", "Michael Heinzinger", "Karl Henrik Johansson", "Kaitlin Maile", "Johannes von Oswald", "Stefan Bauer"], "title": "From Words to Amino Acids: Does the Curse of Depth Persist?", "comment": null, "summary": "Protein language models (PLMs) have become widely adopted as general-purpose models, demonstrating strong performance in protein engineering and de novo design. Like large language models (LLMs), they are typically trained as deep transformers with next-token or masked-token prediction objectives on massive sequence corpora and are scaled by increasing model depth. Recent work on autoregressive LLMs has identified the Curse of Depth: later layers contribute little to the final output predictions. These findings naturally raise the question of whether a similar depth inefficiency also appears in PLMs, where many widely used models are not autoregressive, and some are multimodal, accepting both protein sequence and structure as input. In this work, we present a depth analysis of six popular PLMs across model families and scales, spanning three training objectives, namely autoregressive, masked, and diffusion, and quantify how layer contributions evolve with depth using a unified set of probing- and perturbation-based measurements. Across all models, we observe consistent depth-dependent patterns that extend prior findings on LLMs: later layers depend less on earlier computations and mainly refine the final output distribution, and these effects are increasingly pronounced in deeper models. Taken together, our results suggest that PLMs exhibit a form of depth inefficiency, motivating future work on more depth-efficient architectures and training methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u5728\u6df1\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u51fa\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u76f8\u4f3c\u7684\u6df1\u5ea6\u6548\u7387\u95ee\u9898\uff0c\u5373\u6df1\u5c42\u5bf9\u6700\u7ec8\u8f93\u51fa\u8d21\u732e\u8f83\u5c0f\u3002\u8fd9\u4e00\u89c2\u5bdf\u7ed3\u679c\u9002\u7528\u4e8e\u591a\u79cd\u8bad\u7ec3\u76ee\u6807\u548c\u6a21\u578b\u89c4\u6a21\uff0c\u5e76\u63d0\u793a\u672a\u6765\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u6df1\u5ea6\u67b6\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u9274\u4e8e\u6700\u8fd1\u5173\u4e8e\u81ea\u56de\u5f52\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u6307\u51fa\u6df1\u5ea6\u8bc5\u5492\u73b0\u8c61\u2014\u2014\u6df1\u5c42\u5bf9\u4e8e\u6700\u7ec8\u9884\u6d4b\u8d21\u732e\u4e0d\u5927\uff0c\u7814\u7a76\u8005\u4eec\u81ea\u7136\u5730\u63d0\u51fa\u7591\u95ee\uff1a\u8fd9\u79cd\u6df1\u5ea6\u6548\u7387\u4f4e\u4e0b\u7684\u60c5\u51b5\u662f\u5426\u4e5f\u5b58\u5728\u4e8e\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u4e2d\uff1f\u7279\u522b\u662f\u8003\u8651\u5230\u8bb8\u591a\u5e7f\u6cdb\u4f7f\u7528\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5e76\u975e\u81ea\u56de\u5f52\u7c7b\u578b\uff0c\u4e14\u6709\u4e9b\u8fd8\u80fd\u63a5\u53d7\u86cb\u767d\u8d28\u5e8f\u5217\u548c\u7ed3\u6784\u4f5c\u4e3a\u8f93\u5165\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u516d\u79cd\u6d41\u884c\u7684\u3001\u8de8\u8d8a\u4e0d\u540c\u5bb6\u65cf\u53ca\u89c4\u6a21\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u6765\u63a2\u8ba8\u4e0a\u8ff0\u95ee\u9898\uff0c\u8fd9\u4e9b\u6a21\u578b\u8986\u76d6\u4e86\u4e09\u79cd\u8bad\u7ec3\u76ee\u6807\uff1a\u81ea\u56de\u5f52\u3001\u63a9\u7801\u4ee5\u53ca\u6269\u6563\u3002\u7814\u7a76\u8005\u91c7\u7528\u4e86\u4e00\u5957\u7edf\u4e00\u7684\u63a2\u6d4b-\u6270\u52a8\u6d4b\u91cf\u65b9\u6cd5\u6765\u91cf\u5316\u968f\u7740\u5c42\u6570\u589e\u52a0\u6bcf\u4e00\u5c42\u8d21\u732e\u7684\u53d8\u5316\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6240\u6709\u88ab\u7814\u7a76\u7684\u6a21\u578b\u4e2d\u90fd\u89c2\u5bdf\u5230\u4e86\u968f\u6df1\u5ea6\u53d8\u5316\u7684\u4e00\u81f4\u6a21\u5f0f\uff0c\u8fd9\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u5148\u524d\u5173\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u53d1\u73b0\uff1a\u8f83\u6df1\u5c42\u7ea7\u66f4\u591a\u4f9d\u8d56\u4e8e\u81ea\u8eab\u7684\u8ba1\u7b97\uff0c\u5e76\u4e3b\u8981\u662f\u5728\u5fae\u8c03\u6700\u7ec8\u8f93\u51fa\u5206\u5e03\uff1b\u800c\u4e14\u8fd9\u79cd\u6548\u5e94\u5728\u66f4\u6df1\u7684\u6a21\u578b\u4e2d\u66f4\u4e3a\u663e\u8457\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0c\u8be5\u7814\u7a76\u8868\u660e\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u5b58\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u7684\u6df1\u5ea6\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u8fd9\u4e3a\u5f00\u53d1\u66f4\u52a0\u6df1\u5ea6\u9ad8\u6548\u7684\u67b6\u6784\u53ca\u8bad\u7ec3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u52a8\u529b\u3002"}}
{"id": "2602.21757", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21757", "abs": "https://arxiv.org/abs/2602.21757", "authors": ["Xiannan Huang", "Quan Yuan", "Chao Yang"], "title": "Learning from Yesterday's Error: An Efficient Online Learning Method for Traffic Demand Prediction", "comment": null, "summary": "Accurately predicting short-term traffic demand is critical for intelligent transportation systems. While deep learning models achieve strong performance under stationary conditions, their accuracy often degrades significantly when faced with distribution shifts caused by external events or evolving urban dynamics. Frequent model retraining to adapt to such changes incurs prohibitive computational costs, especially for large-scale or foundation models. To address this challenge, we propose FORESEE (Forecasting Online with Residual Smoothing and Ensemble Experts), a lightweight online adaptation framework that is accurate, robust, and computationally efficient. FORESEE operates without any parameter updates to the base model. Instead, it corrects today's forecast in each region using yesterday's prediction error, stabilized through exponential smoothing guided by a mixture-of-experts mechanism that adapts to recent error dynamics. Moreover, an adaptive spatiotemporal smoothing component propagates error signals across neighboring regions and time slots, capturing coherent shifts in demand patterns. Extensive experiments on seven real-world datasets with three backbone models demonstrate that FORESEE consistently improves prediction accuracy, maintains robustness even when distribution shifts are minimal (avoiding performance degradation), and achieves the lowest computational overhead among existing online methods. By enabling real-time adaptation of traffic forecasting models with negligible computational cost, FORESEE paves the way for deploying reliable, up-to-date prediction systems in dynamic urban environments. Code and data are available at https://github.com/xiannanhuang/FORESEE", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFORESEE\u7684\u8f7b\u91cf\u7ea7\u5728\u7ebf\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u77ed\u671f\u4ea4\u901a\u9700\u6c42\u9884\u6d4b\u7684\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6628\u65e5\u9884\u6d4b\u8bef\u5dee\u4fee\u6b63\u4eca\u65e5\u9884\u6d4b\uff0c\u5e76\u7ed3\u5408\u65f6\u7a7a\u5e73\u6ed1\u7ec4\u4ef6\u4f20\u64ad\u8bef\u5dee\u4fe1\u53f7\uff0c\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u57ce\u5e02\u52a8\u6001\u3002\u5b9e\u9a8c\u8868\u660eFORESEE\u80fd\u591f\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5373\u4f7f\u5728\u5206\u5e03\u53d8\u5316\u5f88\u5c0f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u7ef4\u6301\u7a33\u5065\u6027\uff0c\u5e76\u4e14\u76f8\u6bd4\u4e8e\u73b0\u6709\u5728\u7ebf\u65b9\u6cd5\u5177\u6709\u6700\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u77ed\u671f\u4ea4\u901a\u9700\u6c42\u5bf9\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9762\u5bf9\u7531\u5916\u90e8\u4e8b\u4ef6\u6216\u57ce\u5e02\u53d1\u5c55\u5f15\u8d77\u7684\u6570\u636e\u5206\u5e03\u53d8\u5316\u65f6\uff0c\u5176\u51c6\u786e\u6027\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u9891\u7e41\u5730\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u6765\u9002\u5e94\u8fd9\u4e9b\u53d8\u5316\u4f1a\u5bfc\u81f4\u5de8\u5927\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u89c4\u6a21\u6216\u57fa\u7840\u6a21\u578b\u800c\u8a00\u3002", "method": "\u63d0\u51fa\u4e86FORESEE\uff08Forecasting Online with Residual Smoothing and Ensemble Experts\uff09\uff0c\u4e00\u79cd\u65e0\u9700\u66f4\u65b0\u57fa\u7840\u6a21\u578b\u53c2\u6570\u7684\u8f7b\u91cf\u7ea7\u5728\u7ebf\u9002\u5e94\u6846\u67b6\u3002\u5b83\u5229\u7528\u524d\u4e00\u5929\u7684\u9884\u6d4b\u8bef\u5dee\u6765\u6821\u6b63\u5f53\u524d\u5730\u533a\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u673a\u5236\u6307\u5bfc\u4e0b\u7684\u6307\u6570\u5e73\u6ed1\u6280\u672f\u7a33\u5b9a\u8fd9\u4e00\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u65f6\u7a7a\u5e73\u6ed1\u7ec4\u4ef6\uff0c\u80fd\u591f\u5728\u76f8\u90bb\u5730\u533a\u548c\u65f6\u95f4\u6bb5\u4e4b\u95f4\u4f20\u64ad\u9519\u8bef\u4fe1\u53f7\uff0c\u4ece\u800c\u6355\u6349\u9700\u6c42\u6a21\u5f0f\u7684\u4e00\u81f4\u6027\u53d8\u5316\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u4e09\u79cd\u4e0d\u540c\u7684\u9aa8\u5e72\u6a21\u578b\u65f6\uff0cFORESEE\u59cb\u7ec8\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5373\u4f7f\u662f\u5728\u5206\u5e03\u53d8\u5316\u6781\u5c0f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7a33\u5b9a\u6027\uff08\u907f\u514d\u6027\u80fd\u4e0b\u964d\uff09\uff0c\u5e76\u4e14\u76f8\u8f83\u4e8e\u5176\u4ed6\u73b0\u6709\u7684\u5728\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u73b0\u51e0\u4e4e\u96f6\u989d\u5916\u8ba1\u7b97\u6210\u672c\u4e0b\u7684\u5b9e\u65f6\u9002\u5e94\u6027\u8c03\u6574\uff0cFORESEE\u4e3a\u5728\u52a8\u6001\u57ce\u5e02\u73af\u5883\u4e2d\u90e8\u7f72\u53ef\u9760\u4e14\u6700\u65b0\u7684\u9884\u6d4b\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.21765", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21765", "abs": "https://arxiv.org/abs/2602.21765", "authors": ["Kenton Tang", "Yuzhu Chen", "Fengxiang He"], "title": "Generalisation of RLHF under Reward Shift and Clipped KL Regularisation", "comment": null, "summary": "Alignment and adaptation in large language models heavily rely on reinforcement learning from human feedback (RLHF); yet, theoretical understanding of its generalisability remains premature, especially when the learned reward could shift, and the KL control is estimated and clipped. To address this issue, we develop generalisation theory for RLHF that explicitly accounts for (1) \\emph{reward shift}: reward models are trained on preference data from earlier or mixed behaviour policies while RLHF optimises the current policy on its own rollouts; and (2) \\emph{clipped KL regularisation}: the KL regulariser is estimated from sampled log-probability ratios and then clipped for stabilisation, resulting in an error to RLHF. We present generalisation bounds for RLHF, suggesting that the generalisation error stems from a sampling error from prompts and rollouts, a reward shift error, and a KL clipping error. We also discuss special cases of (1) initialising RLHF parameters with a uniform prior over a finite space, and (2) training RLHF by stochastic gradient descent, as an Ornstein-Uhlenbeck process. The theory yields practical implications in (1) optimal KL clipping threshold, and (2) budget allocation in prompts, rollouts, and preference data.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u9488\u5bf9\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u7684\u6cdb\u5316\u7406\u8bba\uff0c\u7279\u522b\u8003\u8651\u4e86\u5956\u52b1\u504f\u79fb\u548cKL\u526a\u88c1\u6b63\u5219\u5316\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u6cdb\u5316\u8bef\u5dee\u6765\u6e90\u4e8e\u63d0\u793a\u548c\u5c55\u5f00\u7684\u91c7\u6837\u8bef\u5dee\u3001\u5956\u52b1\u504f\u79fb\u8bef\u5dee\u4ee5\u53caKL\u526a\u88c1\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u8fd8\u8ba8\u8bba\u4e86\u4f7f\u7528\u6709\u9650\u7a7a\u95f4\u4e0a\u5747\u5300\u5148\u9a8c\u521d\u59cb\u5316RLHF\u53c2\u6570\u7684\u60c5\u51b5\uff0c\u4ee5\u53ca\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3RLHF\u4f5c\u4e3aOrnstein-Uhlenbeck\u8fc7\u7a0b\u7684\u60c5\u51b5\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5bf9\u9f50\u4e0e\u9002\u5e94\u4e25\u91cd\u4f9d\u8d56\u4e8e\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u7684\u5f3a\u5316\u5b66\u4e60(RLHF)\uff0c\u4f46\u5176\u6cdb\u5316\u80fd\u529b\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u4e0d\u6210\u719f\uff0c\u7279\u522b\u662f\u5728\u5b66\u4e60\u5230\u7684\u5956\u52b1\u53ef\u80fd\u53d1\u751f\u53d8\u5316\u4ee5\u53caKL\u63a7\u5236\u88ab\u4f30\u8ba1\u548c\u526a\u88c1\u7684\u60c5\u51b5\u4e0b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u80fd\u591f\u660e\u786e\u8003\u8651\u5230\u8fd9\u4e9b\u56e0\u7d20\u7684RLHF\u6cdb\u5316\u7406\u8bba\u3002", "method": "\u7814\u7a76\u8005\u53d1\u5c55\u4e86\u4e00\u5957\u9488\u5bf9RLHF\u7684\u6cdb\u5316\u7406\u8bba\uff0c\u8be5\u7406\u8bba\u7279\u522b\u8003\u8651\u5230\u4e86\u4e24\u4e2a\u65b9\u9762\uff1a1. \u5956\u52b1\u504f\u79fb\uff1a\u5373\u5956\u52b1\u6a21\u578b\u662f\u5728\u65e9\u671f\u6216\u6df7\u5408\u884c\u4e3a\u7b56\u7565\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\uff0c\u800cRLHF\u5219\u57fa\u4e8e\u5f53\u524d\u7b56\u7565\u81ea\u8eab\u7684\u5c55\u5f00\u6765\u4f18\u5316\uff1b2. KL\u526a\u88c1\u6b63\u5219\u5316\uff1aKL\u6b63\u5219\u5316\u5668\u662f\u4ece\u62bd\u6837\u7684\u5bf9\u6570\u6982\u7387\u6bd4\u503c\u4e2d\u4f30\u8ba1\u51fa\u6765\u7684\uff0c\u7136\u540e\u4e3a\u4e86\u7a33\u5b9a\u76ee\u7684\u5bf9\u5176\u8fdb\u884c\u526a\u88c1\uff0c\u8fd9\u7ed9RLHF\u5e26\u6765\u4e86\u4e00\u5b9a\u7684\u8bef\u5dee\u3002", "result": "\u7ed9\u51fa\u4e86RLHF\u7684\u6cdb\u5316\u8fb9\u754c\uff0c\u8868\u660e\u6cdb\u5316\u8bef\u5dee\u6765\u81ea\u4e8e\u63d0\u793a\u548c\u5c55\u5f00\u4e2d\u7684\u91c7\u6837\u8bef\u5dee\u3001\u5956\u52b1\u504f\u79fb\u8bef\u5dee\u4ee5\u53caKL\u526a\u88c1\u8bef\u5dee\u3002\u540c\u65f6\uff0c\u4e5f\u63a2\u8ba8\u4e86\u5f53\u4ee5\u6709\u9650\u7a7a\u95f4\u4e0a\u7684\u5747\u5300\u5148\u9a8c\u521d\u59cb\u5316RLHF\u53c2\u6570\u65f6\uff0c\u4ee5\u53ca\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5\uff08\u88ab\u89c6\u4e3aOrnstein-Uhlenbeck\u8fc7\u7a0b\uff09\u8bad\u7ec3RLHF\u65f6\u7684\u4e00\u4e9b\u7279\u6b8a\u60c5\u51b5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u6539\u8fdbRLHF\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5982\u4f55\u8bbe\u7f6e\u6700\u4f73\u7684KL\u526a\u88c1\u9608\u503c\u4ee5\u53ca\u5982\u4f55\u5728\u63d0\u793a\u3001\u5c55\u5f00\u548c\u504f\u597d\u6570\u636e\u4e4b\u95f4\u5206\u914d\u9884\u7b97\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2602.21773", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21773", "abs": "https://arxiv.org/abs/2602.21773", "authors": ["JuneHyoung Kwon", "MiHyeon Kim", "Eunju Lee", "Yoonji Lee", "Seunghoon Lee", "YoungBin Kim"], "title": "Easy to Learn, Yet Hard to Forget: Towards Robust Unlearning Under Bias", "comment": "Accepted to AAAI 2026", "summary": "Machine unlearning, which enables a model to forget specific data, is crucial for ensuring data privacy and model reliability. However, its effectiveness can be severely undermined in real-world scenarios where models learn unintended biases from spurious correlations within the data. This paper investigates the unique challenges of unlearning from such biased models. We identify a novel phenomenon we term ``shortcut unlearning,\" where models exhibit an ``easy to learn, yet hard to forget\" tendency. Specifically, models struggle to forget easily-learned, bias-aligned samples; instead of forgetting the class attribute, they unlearn the bias attribute, which can paradoxically improve accuracy on the class intended to be forgotten. To address this, we propose CUPID, a new unlearning framework inspired by the observation that samples with different biases exhibit distinct loss landscape sharpness. Our method first partitions the forget set into causal- and bias-approximated subsets based on sample sharpness, then disentangles model parameters into causal and bias pathways, and finally performs a targeted update by routing refined causal and bias gradients to their respective pathways. Extensive experiments on biased datasets including Waterbirds, BAR, and Biased NICO++ demonstrate that our method achieves state-of-the-art forgetting performance and effectively mitigates the shortcut unlearning problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u9057\u5fd8\u6846\u67b6CUPID\uff0c\u65e8\u5728\u89e3\u51b3\u7531\u4e8e\u6570\u636e\u4e2d\u5b58\u5728\u610f\u5916\u504f\u5dee\u5bfc\u81f4\u7684\"\u6377\u5f84\u9057\u5fd8\"\u95ee\u9898\u3002\u901a\u8fc7\u6839\u636e\u6837\u672c\u9510\u5ea6\u5c06\u9057\u5fd8\u96c6\u5212\u5206\u4e3a\u56e0\u679c\u548c\u504f\u5dee\u8fd1\u4f3c\u5b50\u96c6\uff0c\u5e76\u89e3\u8026\u6a21\u578b\u53c2\u6570\u4e3a\u56e0\u679c\u8def\u5f84\u548c\u504f\u5dee\u8def\u5f84\uff0c\u6700\u7ec8\u5b9e\u73b0\u9488\u5bf9\u6027\u66f4\u65b0\uff0c\u4ee5\u6539\u5584\u9057\u5fd8\u6548\u679c\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u80fd\u4f1a\u4ece\u6570\u636e\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\u5b66\u5230\u975e\u9884\u671f\u7684\u504f\u5dee\uff0c\u8fd9\u4f7f\u5f97\u673a\u5668\u9057\u5fd8\u53d8\u5f97\u590d\u6742\u3002\u672c\u6587\u7814\u7a76\u4e86\u4ece\u8fd9\u79cd\u6709\u504f\u6a21\u578b\u4e2d\u8fdb\u884c\u9057\u5fd8\u7684\u72ec\u7279\u6311\u6218\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u73b0\u8c61\u2014\u2014\u201c\u6377\u5f84\u9057\u5fd8\u201d\uff0c\u5373\u6a21\u578b\u5bb9\u6613\u5b66\u4e60\u5374\u96be\u4ee5\u5fd8\u8bb0\u90a3\u4e9b\u4e0e\u504f\u5dee\u4e00\u81f4\u7684\u6837\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aCUPID\u7684\u65b0\u9057\u5fd8\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u57fa\u4e8e\u6837\u672c\u9510\u5ea6\u5c06\u9057\u5fd8\u96c6\u5408\u5212\u5206\u6210\u56e0\u679c-\u8fd1\u4f3c\u5b50\u96c6\u548c\u504f\u5dee-\u8fd1\u4f3c\u5b50\u96c6\uff1b\u63a5\u7740\u89e3\u8026\u6a21\u578b\u53c2\u6570\u4e3a\u56e0\u679c\u8def\u5f84\u548c\u504f\u5dee\u8def\u5f84\u4e24\u90e8\u5206\uff1b\u6700\u540e\u901a\u8fc7\u5411\u5404\u81ea\u8def\u5f84\u8def\u7531\u7ec6\u5316\u540e\u7684\u56e0\u679c\u68af\u5ea6\u548c\u504f\u5dee\u68af\u5ea6\u6765\u6267\u884c\u6709\u9488\u5bf9\u6027\u7684\u66f4\u65b0\u3002", "result": "\u5728\u5305\u62ecWaterbirds\u3001BAR\u4ee5\u53caBiased NICO++\u5728\u5185\u7684\u51e0\u4e2a\u5e26\u6709\u504f\u5dee\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u6027\u80fd\uff0c\u5e76\u6709\u6548\u5730\u7f13\u89e3\u4e86\u6377\u5f84\u9057\u5fd8\u95ee\u9898\u3002", "conclusion": "\u9488\u5bf9\u5177\u6709\u6f5c\u5728\u504f\u5dee\u7684\u6570\u636e\u96c6\uff0cCUPID\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u673a\u5668\u9057\u5fd8\u7684\u6548\u679c\uff0c\u4ece\u800c\u63d0\u9ad8\u6570\u636e\u9690\u79c1\u6027\u548c\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2602.21798", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21798", "abs": "https://arxiv.org/abs/2602.21798", "authors": ["Sagi Shaier"], "title": "Excitation: Momentum For Experts", "comment": null, "summary": "We propose Excitation, a novel optimization framework designed to accelerate learning in sparse architectures such as Mixture-of-Experts (MoEs). Unlike traditional optimizers that treat all parameters uniformly, Excitation dynamically modulates updates using batch-level expert utilization. It introduces a competitive update dynamic that amplifies updates to highly-utilized experts and can selectively suppress low-utilization ones, effectively sharpening routing specialization. Notably, we identify a phenomenon of \"structural confusion\" in deep MoEs, where standard optimizers fail to establish functional signal paths; Excitation acts as a specialization catalyst, \"rescuing\" these models and enabling stable training where baselines remain trapped. Excitation is optimizer-, domain-, and model-agnostic, requires minimal integration effort, and introduces neither additional per-parameter optimizer state nor learnable parameters, making it highly viable for memory-constrained settings. Across language and vision tasks, Excitation consistently improves convergence speed and final performance in MoE models, indicating that active update modulation is a key mechanism for effective conditional computation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u6846\u67b6Excitation\uff0c\u4e13\u95e8\u7528\u4e8e\u52a0\u901f\u7a00\u758f\u67b6\u6784\u5982\u6df7\u5408\u4e13\u5bb6(MoE)\u6a21\u578b\u7684\u5b66\u4e60\u3002\u5b83\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u66f4\u65b0\u6765\u63d0\u9ad8\u9ad8\u5229\u7528\u7387\u4e13\u5bb6\u7684\u5b66\u4e60\u6548\u7387\uff0c\u5e76\u53ef\u4ee5\u6291\u5236\u4f4e\u5229\u7528\u7387\u7684\u4e13\u5bb6\uff0c\u4ece\u800c\u4fc3\u8fdb\u8def\u7531\u4e13\u4e1a\u5316\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u6df1\u5ea6MoE\u4e2d\u7684\u201c\u7ed3\u6784\u6df7\u6dc6\u201d\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7a00\u758f\u67b6\u6784\u5982\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6a21\u578b\u4e2d\u9047\u5230\u7684\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u201c\u7ed3\u6784\u6df7\u6dc6\u201d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86Excitation\u8fd9\u4e00\u65b0\u578b\u4f18\u5316\u6846\u67b6\u3002\u76ee\u6807\u662f\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u5b66\u4e60\u8fc7\u7a0b\u6765\u589e\u5f3a\u8fd9\u4e9b\u6a21\u578b\u7684\u4e13\u4e1a\u5316\u7a0b\u5ea6\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "Excitation\u901a\u8fc7\u57fa\u4e8e\u6279\u6b21\u7ea7\u522b\u7684\u4e13\u5bb6\u5229\u7528\u7387\u52a8\u6001\u5730\u8c03\u5236\u53c2\u6570\u66f4\u65b0\uff0c\u5bf9\u9ad8\u5ea6\u5229\u7528\u7684\u4e13\u5bb6\u7ed9\u4e88\u66f4\u5927\u7684\u66f4\u65b0\u5e45\u5ea6\uff0c\u540c\u65f6\u53ef\u4ee5\u9009\u62e9\u6027\u5730\u51cf\u5c11\u5bf9\u4f4e\u5229\u7528\u7387\u4e13\u5bb6\u7684\u66f4\u65b0\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u989d\u5916\u7684\u6bcf\u53c2\u6570\u4f18\u5316\u5668\u72b6\u6001\u6216\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u56e0\u6b64\u975e\u5e38\u9002\u5408\u5185\u5b58\u53d7\u9650\u7684\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8bed\u8a00\u548c\u89c6\u89c9\u4efb\u52a1\u4e0a\uff0cExcitation\u80fd\u591f\u663e\u8457\u52a0\u5febMoE\u6a21\u578b\u7684\u6536\u655b\u901f\u5ea6\u5e76\u63d0\u5347\u6700\u7ec8\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u4e3b\u52a8\u66f4\u65b0\u8c03\u8282\u5bf9\u4e8e\u6709\u6548\u6761\u4ef6\u8ba1\u7b97\u7684\u91cd\u8981\u6027\u3002", "conclusion": "Excitation\u4f5c\u4e3a\u4e00\u4e2a\u901a\u7528\u6027\u5f3a\u3001\u6613\u4e8e\u96c6\u6210\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u89e3\u51b3\u4e86\u73b0\u6709\u4f18\u5316\u5668\u5728\u5904\u7406\u6df1\u5c42MoE\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u8fd8\u4e3a\u7a00\u758f\u67b6\u6784\u4e0b\u7684\u9ad8\u6548\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2602.21824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21824", "abs": "https://arxiv.org/abs/2602.21824", "authors": ["Marcel Lamott", "Saifullah Saifullah", "Nauman Riaz", "Yves-Noel Weweler", "Tobias Alt-Veit", "Ahmad Sarmad Ali", "Muhammad Armaghan Shakir", "Adrian Kalwa", "Momina Moetesum", "Andreas Dengel", "Sheraz Ahmed", "Faisal Shafait", "Ulrich Schwanecke", "Adrian Ulges"], "title": "DocDjinn: Controllable Synthetic Document Generation with VLMs and Handwriting Diffusion", "comment": null, "summary": "Effective document intelligence models rely on large amounts of annotated training data. However, procuring sufficient and high-quality data poses significant challenges due to the labor-intensive and costly nature of data acquisition. Additionally, leveraging language models to annotate real documents raises concerns about data privacy. Synthetic document generation has emerged as a promising, privacy-preserving alternative. We propose DocDjinn, a novel framework for controllable synthetic document generation using Vision-Language Models (VLMs) that produces annotated documents from unlabeled seed samples. Our approach generates visually plausible and semantically consistent synthetic documents that follow the distribution of an existing source dataset through clustering-based seed selection with parametrized sampling. By enriching documents with realistic diffusion-based handwriting and contextual visual elements via semantic-visual decoupling, we generate diverse, high-quality annotated synthetic documents. We evaluate across eleven benchmarks spanning key information extraction, question answering, document classification, and document layout analysis. To our knowledge, this is the first work demonstrating that VLMs can generate faithful annotated document datasets at scale from unlabeled seeds that can effectively enrich or approximate real, manually annotated data for diverse document understanding tasks. We show that with only 100 real training samples, our framework achieves on average $87\\%$ of the performance of the full real-world dataset. We publicly release our code and 140k+ synthetic document samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u63a7\u5408\u6210\u6587\u6863\u751f\u6210\u6846\u67b6DocDjinn\uff0c\u8be5\u6846\u67b6\u5229\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4ece\u672a\u6807\u8bb0\u7684\u79cd\u5b50\u6837\u672c\u4e2d\u751f\u6210\u5e26\u6709\u6ce8\u91ca\u7684\u6587\u6863\u3002\u901a\u8fc7\u57fa\u4e8e\u805a\u7c7b\u7684\u79cd\u5b50\u9009\u62e9\u548c\u53c2\u6570\u5316\u91c7\u6837\u65b9\u6cd5\uff0c\u751f\u6210\u89c6\u89c9\u4e0a\u5408\u7406\u4e14\u8bed\u4e49\u4e00\u81f4\u7684\u5408\u6210\u6587\u6863\uff0c\u5e76\u901a\u8fc7\u6269\u6563\u5f0f\u624b\u5199\u548c\u4e0a\u4e0b\u6587\u89c6\u89c9\u5143\u7d20\u4e30\u5bcc\u6587\u6863\u5185\u5bb9\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f7f\u7528100\u4e2a\u771f\u5b9e\u8bad\u7ec3\u6837\u672c\u65f6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u8fbe\u5230\u5b8c\u6574\u771f\u5b9e\u6570\u636e\u96c6\u5e73\u574787%\u7684\u8868\u73b0\u3002", "motivation": "\u6709\u6548\u7684\u6587\u6863\u667a\u80fd\u6a21\u578b\u4f9d\u8d56\u4e8e\u5927\u91cf\u6807\u6ce8\u8fc7\u7684\u8bad\u7ec3\u6570\u636e\u3002\u7136\u800c\uff0c\u83b7\u53d6\u8db3\u591f\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u7531\u4e8e\u6570\u636e\u91c7\u96c6\u52b3\u52a8\u5bc6\u96c6\u578b\u548c\u6210\u672c\u9ad8\u6602\u800c\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u6b64\u5916\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u6765\u6807\u6ce8\u771f\u5b9e\u6587\u6863\u5f15\u53d1\u4e86\u5bf9\u6570\u636e\u9690\u79c1\u7684\u5173\u6ce8\u3002\u56e0\u6b64\uff0c\u5408\u6210\u6587\u6863\u751f\u6210\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u4e14\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u66ff\u4ee3\u65b9\u6848\u88ab\u63d0\u51fa\u3002", "method": "\u63d0\u51fa\u4e86DocDjinn\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e\u53ef\u63a7\u5408\u6210\u6587\u6863\u751f\u6210\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u4f7f\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4ece\u65e0\u6807\u7b7e\u7684\u79cd\u5b50\u6837\u672c\u4e2d\u4ea7\u751f\u5e26\u6709\u6ce8\u89e3\u7684\u6587\u6863\u3002\u901a\u8fc7\u91c7\u7528\u57fa\u4e8e\u805a\u7c7b\u7684\u79cd\u5b50\u9009\u62e9\u4e0e\u53c2\u6570\u5316\u62bd\u6837\u6280\u672f\uff0c\u751f\u6210\u65e2\u5728\u89c6\u89c9\u4e0a\u53ef\u4fe1\u53c8\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u4eba\u5de5\u6587\u6863\uff1b\u5e76\u4e14\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u7684\u624b\u5199\u98ce\u683c\u4ee5\u53ca\u5177\u6709\u60c5\u5883\u610f\u4e49\u7684\u89c6\u89c9\u5143\u7d20\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u6587\u6863\u7684\u771f\u5b9e\u6027\u4e0e\u591a\u6837\u6027\u3002", "result": "\u8bc4\u4f30\u4e86\u5341\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4e86\u5173\u952e\u4fe1\u606f\u62bd\u53d6\u3001\u95ee\u7b54\u3001\u6587\u6863\u5206\u7c7b\u548c\u6587\u6863\u5e03\u5c40\u5206\u6790\u7b49\u9886\u57df\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4ec5\u6709100\u4e2a\u5b9e\u9645\u8bad\u7ec3\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u4e8e\u5b8c\u6574\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u5e73\u574787%\u7684\u8868\u73b0\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c55\u793aVLMs\u80fd\u591f\u4ece\u65e0\u6807\u7b7e\u6837\u672c\u5927\u89c4\u6a21\u751f\u6210\u5fe0\u5b9e\u6807\u6ce8\u6587\u6863\u6570\u636e\u96c6\u7684\u5de5\u4f5c\uff0c\u8fd9\u4e9b\u5408\u6210\u7684\u6570\u636e\u96c6\u53ef\u4ee5\u6709\u6548\u5730\u4e30\u5bcc\u6216\u8fd1\u4f3c\u771f\u5b9e\u624b\u52a8\u6807\u6ce8\u6570\u636e\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u6587\u6863\u7406\u89e3\u4efb\u52a1\u3002"}}
{"id": "2602.21845", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.21845", "abs": "https://arxiv.org/abs/2602.21845", "authors": ["Lin Zhu", "Lei You"], "title": "xai-cola: A Python library for sparsifying counterfactual explanations", "comment": "5pages, 1 figure", "summary": "Counterfactual explanation (CE) is an important domain within post-hoc explainability. However, the explanations generated by most CE generators are often highly redundant. This work introduces an open-source Python library xai-cola, which provides an end-to-end pipeline for sparsifying CEs produced by arbitrary generators, reducing superfluous feature changes while preserving their validity. It offers a documented API that takes as input raw tabular data in pandas DataFrame form, a preprocessing object (for standardization and encoding), and a trained scikit-learn or PyTorch model. On this basis, users can either employ the built-in or externally imported CE generators. The library also implements several sparsification policies and includes visualization routines for analysing and comparing sparsified counterfactuals. xai-cola is released under the MIT license and can be installed from PyPI. Empirical experiments indicate that xai-cola produces sparser counterfactuals across several CE generators, reducing the number of modified features by up to 50% in our setting. The source code is available at https://github.com/understanding-ml/COLA.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5f00\u6e90Python\u5e93xai-cola\uff0c\u8be5\u5e93\u65e8\u5728\u51cf\u5c11\u7531\u4efb\u610f\u751f\u6210\u5668\u4ea7\u751f\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e2d\u7684\u5197\u4f59\u7279\u5f81\u53d8\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CE\uff09\u751f\u6210\u5668\u6240\u4ea7\u751f\u7684\u89e3\u91ca\u901a\u5e38\u975e\u5e38\u5197\u4f59\u3002\u4e3a\u4e86\u51cf\u5c11\u8fd9\u4e9b\u591a\u4f59\u7684\u7279\u5f81\u53d8\u5316\u5e76\u4fdd\u6301\u89e3\u91ca\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u4e86\u8fd9\u4e2a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u7ba1\u9053\uff0cxai-cola\u80fd\u591f\u5904\u7406\u7531pandas DataFrame\u683c\u5f0f\u7684\u539f\u59cb\u8868\u683c\u6570\u636e\u3001\u9884\u5904\u7406\u5bf9\u8c61\u4ee5\u53ca\u8bad\u7ec3\u597d\u7684scikit-learn\u6216PyTorch\u6a21\u578b\u8f93\u5165\u751f\u6210\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002\u7528\u6237\u53ef\u4ee5\u4f7f\u7528\u5185\u7f6e\u6216\u662f\u5916\u90e8\u5bfc\u5165\u7684CE\u751f\u6210\u5668\uff0c\u5e76\u4e14\u5e93\u4e2d\u5b9e\u73b0\u4e86\u51e0\u79cd\u7a00\u758f\u5316\u7b56\u7565\u53ca\u53ef\u89c6\u5316\u4f8b\u7a0b\u6765\u5206\u6790\u548c\u6bd4\u8f83\u7a00\u758f\u5316\u7684\u53cd\u4e8b\u5b9e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cxai-cola\u80fd\u591f\u5728\u591a\u4e2aCE\u751f\u6210\u5668\u4e0a\u4ea7\u751f\u66f4\u7a00\u758f\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u5728\u7ed9\u5b9a\u8bbe\u7f6e\u4e0b\u51cf\u5c11\u4e86\u591a\u8fbe50%\u7684\u4fee\u6539\u7279\u5f81\u6570\u91cf\u3002", "conclusion": "xai-cola\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\uff0c\u6709\u6548\u5730\u5e2e\u52a9\u4e86\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u7b80\u5316\u590d\u6742\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u4ece\u800c\u4f7f\u5f97\u673a\u5668\u5b66\u4e60\u6a21\u578b\u66f4\u52a0\u900f\u660e\u6613\u61c2\u3002"}}
{"id": "2602.21919", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.21919", "abs": "https://arxiv.org/abs/2602.21919", "authors": ["Cuong Anh Pham", "Praneeth Vepakomma", "Samuel Horv\u00e1th"], "title": "Learning in the Null Space: Small Singular Values for Continual Learning", "comment": "17 pages, accepted as Oral presentation at the Third Conference on Parsimony and Learning (CPAL 2026)", "summary": "Alleviating catastrophic forgetting while enabling further learning is a primary challenge in continual learning (CL). Orthogonal-based training methods have gained attention for their efficiency and strong theoretical properties, and many existing approaches enforce orthogonality through gradient projection. In this paper, we revisit orthogonality and exploit the fact that small singular values correspond to directions that are nearly orthogonal to the input space of previous tasks. Building on this principle, we introduce NESS (Null-space Estimated from Small Singular values), a CL method that applies orthogonality directly in the weight space rather than through gradient manipulation. Specifically, NESS constructs an approximate null space using the smallest singular values of each layer's input representation and parameterizes task-specific updates via a compact low-rank adaptation (LoRA-style) formulation constrained to this subspace. The subspace basis is fixed to preserve the null-space constraint, and only a single trainable matrix is learned for each task. This design ensures that the resulting updates remain approximately in the null space of previous inputs while enabling adaptation to new tasks. Our theoretical analysis and experiments on three benchmark datasets demonstrate competitive performance, low forgetting, and stable accuracy across tasks, highlighting the role of small singular values in continual learning. The code is available at https://github.com/pacman-ctm/NESS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNESS\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u4e2d\u5e94\u7528\u6b63\u4ea4\u6027\u6765\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u901a\u8fc7\u6700\u5c0f\u5947\u5f02\u503c\u6784\u5efa\u8fd1\u4f3c\u7684\u96f6\u7a7a\u95f4\u4ee5\u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u66f4\u65b0\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u51cf\u5c11\u9057\u5fd8\uff0c\u5e76\u4fdd\u6301\u8de8\u4efb\u52a1\u7684\u7a33\u5b9a\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5373\u5728\u5141\u8bb8\u8fdb\u4e00\u6b65\u5b66\u4e60\u7684\u540c\u65f6\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u3002\u5df2\u6709\u57fa\u4e8e\u6b63\u4ea4\u6027\u7684\u8bad\u7ec3\u65b9\u6cd5\u867d\u7136\u6709\u6548\u4e14\u7406\u8bba\u6027\u8d28\u5f3a\uff0c\u4f46\u591a\u901a\u8fc7\u68af\u5ea6\u6295\u5f71\u6765\u5f3a\u5236\u6267\u884c\u6b63\u4ea4\u6027\u3002", "method": "NESS\uff08\u4ece\u6700\u5c0f\u5947\u5f02\u503c\u4f30\u8ba1\u7684\u96f6\u7a7a\u95f4\uff09\u662f\u4e00\u79cd\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u800c\u4e0d\u662f\u901a\u8fc7\u68af\u5ea6\u64cd\u4f5c\u6765\u5e94\u7528\u6b63\u4ea4\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0cNESS\u5229\u7528\u6bcf\u4e00\u5c42\u8f93\u5165\u8868\u793a\u7684\u6700\u5c0f\u5947\u5f02\u503c\u6784\u9020\u4e00\u4e2a\u8fd1\u4f3c\u7684\u96f6\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u9650\u5236\u5728\u8fd9\u4e2a\u5b50\u7a7a\u95f4\u5185\u7684\u7d27\u51d1\u4f4e\u79e9\u9002\u5e94\uff08LoRA\u98ce\u683c\uff09\u516c\u5f0f\u6765\u53c2\u6570\u5316\u4efb\u52a1\u7279\u5b9a\u66f4\u65b0\u3002\u5b50\u7a7a\u95f4\u57fa\u56fa\u5b9a\u4ee5\u4fdd\u6301\u96f6\u7a7a\u95f4\u7ea6\u675f\uff0c\u6bcf\u4e2a\u4efb\u52a1\u4ec5\u5b66\u4e60\u4e00\u4e2a\u53ef\u8bad\u7ec3\u77e9\u9635\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNESS\u80fd\u591f\u5b9e\u73b0\u5177\u6709\u7ade\u4e89\u529b\u7684\u8868\u73b0\u3001\u4f4e\u9057\u5fd8\u4ee5\u53ca\u8de8\u4efb\u52a1\u7684\u7a33\u5b9a\u51c6\u786e\u6027\u3002", "conclusion": "\u5c0f\u5947\u5f02\u503c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\u3002\u901a\u8fc7\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u5185\u5229\u7528\u8fd9\u4e9b\u503c\u6765\u7ef4\u6301\u4e0e\u5148\u524d\u4efb\u52a1\u8f93\u5165\u7a7a\u95f4\u8fd1\u4e4e\u6b63\u4ea4\u7684\u65b9\u5411\uff0cNESS\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.21959", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21959", "abs": "https://arxiv.org/abs/2602.21959", "authors": ["Dusica Marijan", "Hamza Haruna Mohammed", "Bakht Zaman"], "title": "Estimation and Optimization of Ship Fuel Consumption in Maritime: Review, Challenges and Future Directions", "comment": "23 pages, 4 figures. Published in Journal of Marine Science and Technology (2026)", "summary": "To reduce carbon emissions and minimize shipping costs, improving the fuel efficiency of ships is crucial. Various measures are taken to reduce the total fuel consumption of ships, including optimizing vessel parameters and selecting routes with the lowest fuel consumption. Different estimation methods are proposed for predicting fuel consumption, while various optimization methods are proposed to minimize fuel oil consumption. This paper provides a comprehensive review of methods for estimating and optimizing fuel oil consumption in maritime transport. Our novel contributions include categorizing fuel oil consumption \\& estimation methods into physics-based, machine-learning, and hybrid models, exploring their strengths and limitations. Furthermore, we highlight the importance of data fusion techniques, which combine AIS, onboard sensors, and meteorological data to enhance accuracy. We make the first attempt to discuss the emerging role of Explainable AI in enhancing model transparency for decision-making. Uniquely, key challenges, including data quality, availability, and the need for real-time optimization, are identified, and future research directions are proposed to address these gaps, with a focus on hybrid models, real-time optimization, and the standardization of datasets.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6d77\u8fd0\u4e2d\u71c3\u6cb9\u6d88\u8017\u7684\u4f30\u7b97\u4e0e\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7269\u7406\u3001\u673a\u5668\u5b66\u4e60\u53ca\u6df7\u5408\u6a21\u578b\u7684\u5206\u7c7b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5404\u7c7b\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002\u540c\u65f6\u5f3a\u8c03\u4e86\u6570\u636e\u878d\u5408\u6280\u672f\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u53ef\u89e3\u91caAI\u5728\u63d0\u9ad8\u6a21\u578b\u900f\u660e\u5ea6\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11\u78b3\u6392\u653e\u5e76\u964d\u4f4e\u822a\u8fd0\u6210\u672c\uff0c\u63d0\u9ad8\u8239\u8236\u7684\u71c3\u6cb9\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002\u6587\u7ae0\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u5168\u9762\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u4f18\u5316\u6d77\u4e0a\u8fd0\u8f93\u4e2d\u7684\u71c3\u6cb9\u6d88\u8017\u95ee\u9898\u3002", "method": "\u5bf9\u73b0\u6709\u7684\u71c3\u6cb9\u6d88\u8017\u4f30\u8ba1\u4e0e\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u4e86\u5206\u7c7b\uff08\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u3001\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u6df7\u5408\u6a21\u578b\uff09\uff0c\u8ba8\u8bba\u4e86\u6bcf\u79cd\u7c7b\u578b\u65b9\u6cd5\u7684\u4f18\u70b9\u548c\u5c40\u9650\uff1b\u63d0\u51fa\u5229\u7528AIS\u3001\u8239\u4e0a\u4f20\u611f\u5668\u548c\u6c14\u8c61\u6570\u636e\u7684\u6570\u636e\u878d\u5408\u6280\u672f\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff1b\u9996\u6b21\u63a2\u8ba8\u4e86\u53ef\u89e3\u91caAI\u5728\u589e\u5f3a\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u6a21\u578b\u900f\u660e\u5ea6\u65b9\u9762\u7684\u65b0\u5174\u4f5c\u7528\u3002", "result": "\u660e\u786e\u4e86\u4e0d\u540c\u7c7b\u578b\u71c3\u6cb9\u6d88\u8017\u4f30\u7b97\u65b9\u6cd5\u7684\u7279\u70b9\uff1b\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u5bf9\u4e8e\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u7684\u91cd\u8981\u6027\uff1b\u6307\u51fa\u4e86\u5f53\u524d\u7814\u7a76\u4e2d\u5b58\u5728\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5982\u6570\u636e\u8d28\u91cf\u3001\u53ef\u7528\u6027\u548c\u5b9e\u65f6\u4f18\u5316\u7684\u9700\u6c42\u7b49\u3002", "conclusion": "\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5e94\u96c6\u4e2d\u5728\u6df7\u5408\u6a21\u578b\u7684\u53d1\u5c55\u3001\u5b9e\u73b0\u5b9e\u65f6\u4f18\u5316\u4ee5\u53ca\u6570\u636e\u96c6\u6807\u51c6\u5316\u4e0a\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\u4e4b\u5904\u3002"}}
{"id": "2602.22018", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22018", "abs": "https://arxiv.org/abs/2602.22018", "authors": ["Sterre de Jonge", "Elisabeth J. Vinke", "Meike W. Vernooij", "Daniel C. Alexander", "Alexandra L. Young", "Esther E. Bron"], "title": "Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data", "comment": "Accepted for publication, 2026 IEEE 23rd International Symposium on Biomedical Imaging (ISBI), April 2026, London, United Kingdom", "summary": "Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u75be\u75c5\u8fdb\u5c55\u6a21\u578b\u2014\u2014\u6df7\u5408\u4e8b\u4ef6\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u79bb\u6563\u548c\u8fde\u7eed\u4e24\u79cd\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u591a\u6570\u75be\u75c5\u8fdb\u5c55\u6a21\u578b\u4ec5\u9002\u7528\u4e8e\u5355\u4e00\u7c7b\u578b\u7684\u6570\u636e\uff08\u5982\u8fde\u7eed\u6570\u636e\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5bf9\u5f02\u8d28\u6027\u7684\u3001\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u4ee5\u540c\u65f6\u5904\u7406\u79bb\u6563\u548c\u8fde\u7eed\u6570\u636e\u7c7b\u578b\u7684\u65b0\u578b\u75be\u75c5\u8fdb\u5c55\u6a21\u578b\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3a\u6df7\u5408\u4e8b\u4ef6\u6a21\u578b\u7684\u65b0\u75be\u75c5\u8fdb\u5c55\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u5b50\u7c7b\u578b\u4e0e\u9636\u6bb5\u63a8\u65ad\uff08SuStaIn\uff09\u6846\u67b6\u4e2d\uff0c\u5f62\u6210\u4e86Mixed-SuStaIn\u65b9\u6cd5\u3002\u8fd9\u6837\u65e2\u652f\u6301\u5b50\u7c7b\u578b\u4e5f\u652f\u6301\u8fdb\u5c55\u5efa\u6a21\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u4ee5\u53ca\u6765\u81ea\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u795e\u7ecf\u5f71\u50cf\u5b66\u5021\u8bae\u7684\u771f\u5b9e\u6570\u636e\u8bc1\u660e\uff0cMixed-SuStaIn\u5728\u5904\u7406\u6df7\u5408\u6570\u636e\u96c6\u65f6\u8868\u73b0\u826f\u597d\u3002", "conclusion": "Mixed-SuStaIn\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u624b\u6bb5\u6765\u5206\u6790\u5305\u542b\u4e0d\u540c\u7c7b\u578b\u6570\u636e\u7684\u590d\u6742\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u50cf\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8fd9\u6837\u5177\u6709\u957f\u671f\u53d1\u5c55\u8f68\u8ff9\u7684\u75be\u75c5\u6765\u8bf4\u975e\u5e38\u6709\u7528\u3002"}}
{"id": "2602.22101", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.22101", "abs": "https://arxiv.org/abs/2602.22101", "authors": ["Pantia-Marina Alchirch", "Dimitrios I. Diochnos"], "title": "On Imbalanced Regression with Hoeffding Trees", "comment": "13 pages, 6 figures, 1 table, 2 algorithms, authors' version of paper accepted in PAKDD 2026 special session on Data Science: Foundations and Applications (DSFA)", "summary": "Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest. Hoeffding trees and their variants have a long-standing tradition due to their effectiveness, either alone or as base models in broader ensembles. At the same time a recent line of work in batch learning has shown that kernel density estimation (KDE) is an effective approach for smoothed predictions in imbalanced regression tasks [Yang et al., 2021]. Moreover, another recent line of work for batch learning, called hierarchical shrinkage (HS) [Agarwal et al., 2022], has introduced a post-hoc regularization method for decision trees that does not alter the structure of the learned tree. Using a telescoping argument we cast KDE to streaming environments and extend the implementation of HS to incremental decision tree models. Armed with these extensions we investigate the performance of decision trees that may enjoy such options in datasets commonly used for regression in online settings. We conclude that KDE is beneficial in the early parts of the stream, while HS hardly, if ever, offers performance benefits. Our code is publicly available at: https://github.com/marinaAlchirch/DSFA_2026.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6838\u5bc6\u5ea6\u4f30\u8ba1(KDE)\u548c\u5c42\u6b21\u6536\u7f29(HS)\u65b9\u6cd5\u5728\u6d41\u5f0f\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u4e0d\u5e73\u8861\u56de\u5f52\u4efb\u52a1\u4e2d\u3002\u7814\u7a76\u8868\u660eKDE\u5728\u6570\u636e\u6d41\u7684\u65e9\u671f\u9636\u6bb5\u662f\u6709\u76ca\u7684\uff0c\u800cHS\u5f88\u5c11\u63d0\u4f9b\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u8fde\u7eed\u6570\u636e\u6d41\u7684\u5e94\u7528\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u627e\u5230\u66f4\u6709\u6548\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u89e3\u51b3\u611f\u5174\u8da3\u7684\u56de\u5f52\u4efb\u52a1\u3002\u5df2\u6709\u5de5\u4f5c\u8868\u660e\uff0c\u6838\u5bc6\u5ea6\u4f30\u8ba1\uff08KDE\uff09\u5728\u6279\u91cf\u5b66\u4e60\u4e2d\u7684\u4e0d\u5e73\u8861\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u800c\u5c42\u6b21\u6536\u7f29\uff08HS\uff09\u5219\u4e3a\u51b3\u7b56\u6811\u63d0\u4f9b\u4e86\u4e0d\u6539\u53d8\u5176\u7ed3\u6784\u7684\u540e\u5904\u7406\u6b63\u5219\u5316\u65b9\u6cd5\u3002\u57fa\u4e8e\u8fd9\u4e9b\u80cc\u666f\uff0c\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e24\u79cd\u65b9\u6cd5\u6269\u5c55\u5230\u6d41\u5f0f\u73af\u5883\u4e2d\uff0c\u5e76\u8bc4\u4f30\u5b83\u4eec\u5bf9\u4e8e\u5728\u7ebf\u8bbe\u7f6e\u4e0b\u5e38\u7528\u7684\u56de\u5f52\u6570\u636e\u96c6\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u4e00\u79cd\u4f38\u7f29\u8bba\u8bc1\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u4eec\u6210\u529f\u5730\u628aKDE\u5e94\u7528\u4e8e\u6d41\u5f0f\u73af\u5883\u4e2d\uff0c\u5e76\u4e14\u5c06HS\u5b9e\u65bd\u6269\u5c55\u5230\u4e86\u589e\u91cf\u51b3\u7b56\u6811\u6a21\u578b\u4e0a\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u5229\u7528\u8fd9\u4e9b\u6539\u8fdb\u6765\u8003\u5bdf\u5728\u5728\u7ebf\u73af\u5883\u4e0b\u5e38\u7528\u4e8e\u56de\u5f52\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u5177\u5907\u8fd9\u4e9b\u9009\u9879\u7684\u51b3\u7b56\u6811\u7684\u8868\u73b0\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6570\u636e\u6d41\u7684\u65e9\u671f\u90e8\u5206\uff0cKDE\u5bf9\u51b3\u7b56\u6811\u6709\u79ef\u6781\u5f71\u54cd\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0cHS\u51e0\u4e4e\u4e0d\u63d0\u4f9b\u4efb\u4f55\u6027\u80fd\u4e0a\u7684\u597d\u5904\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5f53\u9762\u5bf9\u6d41\u5f0f\u6570\u636e\u65f6\uff0c\u91c7\u7528KDE\u53ef\u4ee5\u5728\u521d\u671f\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46HS\u6280\u672f\u5e76\u672a\u663e\u793a\u51fa\u663e\u8457\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.22130", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.22130", "abs": "https://arxiv.org/abs/2602.22130", "authors": ["Ilias Diakonikolas", "Giannis Iakovidis", "Daniel M. Kane", "Sihan Liu"], "title": "Sample Complexity Bounds for Robust Mean Estimation with Mean-Shift Contamination", "comment": null, "summary": "We study the basic task of mean estimation in the presence of mean-shift contamination. In the mean-shift contamination model, an adversary is allowed to replace a small constant fraction of the clean samples by samples drawn from arbitrarily shifted versions of the base distribution. Prior work characterized the sample complexity of this task for the special cases of the Gaussian and Laplace distributions. Specifically, it was shown that consistent estimation is possible in these cases, a property that is provably impossible in Huber's contamination model. An open question posed in earlier work was to determine the sample complexity of mean estimation in the mean-shift contamination model for general base distributions. In this work, we study and essentially resolve this open question. Specifically, we show that, under mild spectral conditions on the characteristic function of the (potentially multivariate) base distribution, there exists a sample-efficient algorithm that estimates the target mean to any desired accuracy. We complement our upper bound with a qualitatively matching sample complexity lower bound. Our techniques make critical use of Fourier analysis, and in particular introduce the notion of a Fourier witness as an essential ingredient of our upper and lower bounds.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5728\u5747\u503c\u504f\u79fb\u6c61\u67d3\u6a21\u578b\u4e0b\uff0c\u5bf9\u4e8e\u4e00\u822c\u57fa\u7840\u5206\u5e03\u7684\u5747\u503c\u4f30\u8ba1\u95ee\u9898\u6240\u9700\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u5085\u91cc\u53f6\u89c1\u8bc1\u7684\u6982\u5ff5\u4f5c\u4e3a\u4e0a\u4e0b\u754c\u8bc1\u660e\u7684\u5173\u952e\u6280\u672f\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u5df2\u7ecf\u786e\u5b9a\u4e86\u9ad8\u65af\u548c\u62c9\u666e\u62c9\u65af\u5206\u5e03\u4e0b\u7684\u5747\u503c\u4f30\u8ba1\u4efb\u52a1\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4f46\u5bf9\u4e8e\u4e00\u822c\u7684\u57fa\u7840\u5206\u5e03\uff0c\u8fd9\u4e00\u95ee\u9898\u4ecd\u7136\u5f00\u653e\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5f00\u653e\u6027\u95ee\u9898\uff0c\u5373\u786e\u5b9a\u5728\u5747\u503c\u504f\u79fb\u6c61\u67d3\u6a21\u578b\u4e2d\u5bf9\u4e00\u822c\u57fa\u7840\u5206\u5e03\u8fdb\u884c\u5747\u503c\u4f30\u8ba1\u6240\u9700\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u5085\u91cc\u53f6\u5206\u6790\uff0c\u7279\u522b\u662f\u63d0\u51fa\u201c\u5085\u91cc\u53f6\u89c1\u8bc1\u201d\u7684\u6982\u5ff5\uff0c\u4e3a\u4e0a\u754c\u548c\u4e0b\u754c\u7684\u8bc1\u660e\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6280\u672f\u652f\u6301\u3002\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u6837\u672c\u6548\u7387\u9ad8\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u57fa\u4e8e\u57fa\u7840\u5206\u5e03\u7279\u5f81\u51fd\u6570\u6ee1\u8db3\u6e29\u548c\u8c31\u6761\u4ef6\u7684\u524d\u63d0\u4e0b\uff0c\u4ee5\u4efb\u610f\u6240\u9700\u7cbe\u5ea6\u4f30\u8ba1\u76ee\u6807\u5747\u503c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u57fa\u7840\u5206\u5e03\u7684\u7279\u5f81\u51fd\u6570\u6ee1\u8db3\u67d0\u4e9b\u6e29\u548c\u8c31\u6761\u4ef6\u4e0b\uff0c\u5b58\u5728\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684\u7b97\u6cd5\u53ef\u4ee5\u5c06\u76ee\u6807\u5747\u503c\u4f30\u8ba1\u5230\u4efb\u610f\u671f\u671b\u7684\u7cbe\u5ea6\u3002\u6b64\u5916\uff0c\u8fd8\u7ed9\u51fa\u4e86\u4e00\u4e2a\u4e0e\u4e4b\u5b9a\u6027\u5339\u914d\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\u3002", "conclusion": "\u672c\u7814\u7a76\u57fa\u672c\u89e3\u51b3\u4e86\u5728\u5747\u503c\u504f\u79fb\u6c61\u67d3\u6a21\u578b\u4e0b\u5bf9\u4e00\u822c\u57fa\u7840\u5206\u5e03\u6267\u884c\u5747\u503c\u4f30\u8ba1\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u6837\u672c\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u8868\u660e\u4e86\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u4e00\u81f4\u4f30\u8ba1\u662f\u53ef\u80fd\u5b9e\u73b0\u7684\u3002\u540c\u65f6\uff0c\u5f15\u5165\u7684\u65b0\u65b9\u6cd5\u2014\u2014\u5085\u91cc\u53f6\u89c1\u8bc1\u2014\u2014\u4e3a\u5904\u7406\u6b64\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2602.22146", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.22146", "abs": "https://arxiv.org/abs/2602.22146", "authors": ["Yining Li", "Peizhong Ju", "Ness Shroff"], "title": "Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b89\u5168RLHF\uff08\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u7684\u901a\u7528\u539f\u59cb\u5bf9\u5076\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u5305\u62ec\u5b89\u5168-RLHF\u3001\u4e00\u6b21\u6027\u4ee5\u53ca\u591a\u6b21\u57fa\u4e8e\u7684\u65b9\u6cd5\u5728\u5185\u7684\u4e00\u5927\u7c7b\u73b0\u6709\u5bf9\u9f50\u7b97\u6cd5\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u4e50\u89c2\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5(OPD)\uff0c\u901a\u8fc7\u9884\u6d4b\u66f4\u65b0\u6765\u7a33\u5b9a\u978d\u70b9\u52a8\u529b\u5b66\uff0c\u5e76\u4e3a\u6240\u63d0\u65b9\u6cd5\u5efa\u7acb\u4e86\u6700\u540e\u8fed\u4ee3\u6536\u655b\u4fdd\u8bc1\uff0c\u63ed\u793a\u4e86\u4e50\u89c2\u4e3b\u4e49\u5728\u7f13\u89e3\u7ea6\u675f\u5bf9\u9f50\u76ee\u6807\u56fa\u6709\u632f\u8361\u65b9\u9762\u7684\u91cd\u8981\u4f5c\u7528\u3002", "motivation": "\u867d\u7136\u53ef\u4ee5\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u5b66\u4e60\u5230\u5f3a\u5316\u5b66\u4e60(RLHF)\u5bf9\u4e8e\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4e0e\u4eba\u7c7b\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u8d77\u7740\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u73b0\u6709\u7684\u6807\u51c6\u539f\u59cb\u5bf9\u5076\u65b9\u6cd5\u53ea\u80fd\u4fdd\u8bc1\u5728\u5206\u5e03\u7b56\u7565\u4e0b\u6536\u655b\uff0c\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7b56\u7565\u53c2\u6570\u5316\u53ef\u80fd\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u6216\u53d1\u6563\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8RLHF\u7684\u5b89\u5168\u6027\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u539f\u59cb\u5bf9\u5076\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5b89\u5168RLHF\u95ee\u9898\uff0c\u5e76\u4e14\u80fd\u591f\u7edf\u4e00\u4e00\u7cfb\u5217\u73b0\u6709\u7684\u5bf9\u9f50\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4e50\u89c2\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5(OPD)\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5bf9\u539f\u59cb\u53d8\u91cf\u548c\u5bf9\u5076\u53d8\u91cf\u8fdb\u884c\u9884\u6d4b\u6027\u66f4\u65b0\u4ee5\u7a33\u5b9a\u978d\u70b9\u52a8\u6001\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684\u4e50\u89c2\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5\u4e0d\u4ec5\u80fd\u591f\u5728\u5206\u5e03\u7a7a\u95f4\u4e2d\u7cbe\u786e\u4f18\u5316\u7b56\u7565\u65f6\u5b9e\u73b0\u6536\u655b\uff0c\u800c\u4e14\u5f53\u4f7f\u7528\u53c2\u6570\u5316\u7b56\u7565\u65f6\u4e5f\u80fd\u591f\u6536\u655b\u81f3\u6700\u4f18\u89e3\u9644\u8fd1\u7684\u4e00\u4e2a\u90bb\u57df\u5185\uff0c\u5176\u4e2d\u5dee\u8ddd\u4e0e\u8fd1\u4f3c\u8bef\u5dee\u53ca\u504f\u5dee\u6709\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e50\u89c2\u4e3b\u4e49\u5728\u51cf\u5c11\u53d7\u9650\u5bf9\u9f50\u76ee\u6807\u5e26\u6765\u7684\u5185\u5728\u6ce2\u52a8\u65b9\u9762\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4ece\u800c\u586b\u8865\u4e86\u7ea6\u675fRL\u4e0e\u5b9e\u9645RLHF\u4e4b\u95f4\u91cd\u8981\u7684\u7406\u8bba\u7a7a\u767d\u3002"}}
{"id": "2602.22179", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.22179", "abs": "https://arxiv.org/abs/2602.22179", "authors": ["Mhd Jawad Al Rahwanji", "Sascha Xu", "Nils Philipp Walter", "Jilles Vreeken"], "title": "Learning and Naming Subgroups with Exceptional Survival Characteristics", "comment": null, "summary": "In many applications, it is important to identify subpopulations that survive longer or shorter than the rest of the population. In medicine, for example, it allows determining which patients benefit from treatment, and in predictive maintenance, which components are more likely to fail. Existing methods for discovering subgroups with exceptional survival characteristics require restrictive assumptions about the survival model (e.g. proportional hazards), pre-discretized features, and, as they compare average statistics, tend to overlook individual deviations. In this paper, we propose Sysurv, a fully differentiable, non-parametric method that leverages random survival forests to learn individual survival curves, automatically learns conditions and how to combine these into inherently interpretable rules, so as to select subgroups with exceptional survival characteristics. Empirical evaluation on a wide range of datasets and settings, including a case study on cancer data, shows that Sysurv reveals insightful and actionable survival subgroups.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u5b8c\u5168\u53ef\u5fae\u4e14\u975e\u53c2\u6570\u7684\u65b9\u6cd5Sysurv\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u968f\u673a\u751f\u5b58\u68ee\u6797\u5b66\u4e60\u4e2a\u4f53\u751f\u5b58\u66f2\u7ebf\uff0c\u5e76\u81ea\u52a8\u5b66\u4e60\u6761\u4ef6\u53ca\u5982\u4f55\u5c06\u8fd9\u4e9b\u6761\u4ef6\u7ec4\u5408\u6210\u5185\u5728\u53ef\u89e3\u91ca\u7684\u89c4\u5219\uff0c\u4ece\u800c\u6311\u9009\u51fa\u751f\u5b58\u7279\u5f81\u5f02\u5e38\u7684\u5b50\u7fa4\u4f53\u3002", "motivation": "\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0c\u8bc6\u522b\u51fa\u6bd4\u5176\u4ed6\u7fa4\u4f53\u751f\u5b58\u65f6\u95f4\u66f4\u957f\u6216\u66f4\u77ed\u7684\u5b50\u7fa4\u4f53\u975e\u5e38\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u53d1\u73b0\u5177\u6709\u7279\u6b8a\u751f\u5b58\u7279\u5f81\u5b50\u7fa4\u4f53\u7684\u65b9\u6cd5\u9700\u8981\u5bf9\u751f\u5b58\u6a21\u578b\u505a\u51fa\u4e25\u683c\u7684\u5047\u8bbe\uff08\u4f8b\u5982\u6bd4\u4f8b\u98ce\u9669\uff09\uff0c\u5e76\u4e14\u9700\u8981\u9884\u79bb\u6563\u5316\u7684\u7279\u5f81\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u5b83\u4eec\u6bd4\u8f83\u7684\u662f\u5e73\u5747\u7edf\u8ba1\u503c\uff0c\u56e0\u6b64\u5f80\u5f80\u4f1a\u5ffd\u7565\u4e2a\u4f53\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Sysurv\uff0c\u8fd9\u662f\u4e00\u79cd\u5b8c\u5168\u53ef\u5fae\u3001\u975e\u53c2\u6570\u5316\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u968f\u673a\u751f\u5b58\u68ee\u6797\u6765\u5b66\u4e60\u4e2a\u4f53\u7684\u751f\u5b58\u66f2\u7ebf\uff0c\u5e76\u80fd\u81ea\u52a8\u5b66\u4e60\u6761\u4ef6\u4ee5\u53ca\u5982\u4f55\u628a\u8fd9\u4e9b\u6761\u4ef6\u7ed3\u5408\u6210\u5185\u5728\u53ef\u89e3\u91ca\u7684\u89c4\u5219\uff0c\u4ee5\u9009\u62e9\u5177\u6709\u7279\u6b8a\u751f\u5b58\u7279\u6027\u7684\u5b50\u7fa4\u4f53\u3002", "result": "\u901a\u8fc7\u5bf9\u5e7f\u6cdb\u7684\u6570\u636e\u96c6\u548c\u8bbe\u7f6e\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5305\u62ec\u4e00\u9879\u5173\u4e8e\u764c\u75c7\u6570\u636e\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u8868\u660eSysurv\u80fd\u591f\u63ed\u793a\u6709\u89c1\u5730\u4e14\u53ef\u64cd\u4f5c\u7684\u751f\u5b58\u5b50\u7fa4\u4f53\u3002", "conclusion": "Sysurv\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5728\u65e0\u9700\u5bf9\u751f\u5b58\u6a21\u578b\u505a\u4e25\u683c\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u51fa\u5177\u6709\u663e\u8457\u751f\u5b58\u7279\u5f81\u7684\u5b50\u7fa4\u4f53\uff0c\u4e3a\u533b\u5b66\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
