<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 5]
- [cs.MM](#cs.MM) [Total: 4]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [From AutoRecSys to AutoRecLab: A Call to Build, Evaluate, and Govern Autonomous Recommender-Systems Research Labs](https://arxiv.org/abs/2510.18104)
*Joeran Beel,Bela Gipp,Tobias Vente,Moritz Baumgart,Philipp Meister*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recommender-systems research has accelerated model and evaluation advances,
yet largely neglects automating the research process itself. We argue for a
shift from narrow AutoRecSys tools -- focused on algorithm selection and
hyper-parameter tuning -- to an Autonomous Recommender-Systems Research Lab
(AutoRecLab) that integrates end-to-end automation: problem ideation,
literature analysis, experimental design and execution, result interpretation,
manuscript drafting, and provenance logging. Drawing on recent progress in
automated science (e.g., multi-agent AI Scientist and AI Co-Scientist systems),
we outline an agenda for the RecSys community: (1) build open AutoRecLab
prototypes that combine LLM-driven ideation and reporting with automated
experimentation; (2) establish benchmarks and competitions that evaluate agents
on producing reproducible RecSys findings with minimal human input; (3) create
review venues for transparently AI-generated submissions; (4) define standards
for attribution and reproducibility via detailed research logs and metadata;
and (5) foster interdisciplinary dialogue on ethics, governance, privacy, and
fairness in autonomous research. Advancing this agenda can increase research
throughput, surface non-obvious insights, and position RecSys to contribute to
emerging Artificial Research Intelligence. We conclude with a call to organise
a community retreat to coordinate next steps and co-author guidance for the
responsible integration of automated research systems.

</details>


### [2] [LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling](https://arxiv.org/abs/2510.18239)
*Yunjiang Jiang,Ayush Agarwal,Yang Liu,Bi Xue*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Scaling large recommendation systems requires advancing three major
frontiers: processing longer user histories, expanding candidate sets, and
increasing model capacity. While promising, transformers' computational cost
scales quadratically with the user sequence length and linearly with the number
of candidates. This trade-off makes it prohibitively expensive to expand
candidate sets or increase sequence length at inference, despite the
significant performance improvements.
  We introduce \textbf{LIME}, a novel architecture that resolves this
trade-off. Through two key innovations, LIME fundamentally reduces
computational complexity. First, low-rank ``link embeddings" enable
pre-computation of attention weights by decoupling user and candidate
interactions, making the inference cost nearly independent of candidate set
size. Second, a linear attention mechanism, \textbf{LIME-XOR}, reduces the
complexity with respect to user sequence length from quadratic ($O(N^2)$) to
linear ($O(N)$).
  Experiments on public and industrial datasets show LIME achieves near-parity
with state-of-the-art transformers but with a 10$\times$ inference speedup on
large candidate sets or long sequence lengths. When tested on a major
recommendation platform, LIME improved user engagement while maintaining
minimal inference costs with respect to candidate set size and user history
length, establishing a new paradigm for efficient and expressive recommendation
systems.

</details>


### [3] [Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and Query-Driven Insights](https://arxiv.org/abs/2510.18277)
*Nikolaos Belibasakis,Anastasios Giannaros,Ioanna Giannoukou,Spyros Sioutas*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The increasing number of data a booking platform such as Booking.com and
AirBnB offers make it challenging for interested parties to browse through the
available accommodations and analyze reviews in an efficient way. Efforts have
been made from the booking platform providers to utilize recommender systems in
an effort to enable the user to filter the results by factors such as stars,
amenities, cost but most valuable insights can be provided by the unstructured
text-based reviews. Going through these reviews one-by-one requires a
substantial amount of time to be devoted while a respectable percentage of the
reviews won't provide to the user what they are actually looking for.
  This research publication explores how Large Language Models (LLMs) can
enhance short rental apartments recommendations by summarizing and mining key
insights from user reviews. The web application presented in this paper, named
"instaGuide", automates the procedure of isolating the text-based user reviews
from a property on the Booking.com platform, synthesizing the summary of the
reviews, and enabling the user to query specific aspects of the property in an
effort to gain feedback on their personal questions/criteria.
  During the development of the instaGuide tool, numerous LLM models were
evaluated based on accuracy, cost, and response quality. The results suggest
that the LLM-powered summarization reduces significantly the amount of time the
users need to devote on their search for the right short rental apartment,
improving the overall decision-making procedure.

</details>


### [4] [Evaluating LLM-Based Mobile App Recommendations: An Empirical Study](https://arxiv.org/abs/2510.18364)
*Quim Motger,Xavier Franch,Vincenzo Gervasi,Jordi Marco*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) are increasingly used to recommend mobile
applications through natural language prompts, offering a flexible alternative
to keyword-based app store search. Yet, the reasoning behind these
recommendations remains opaque, raising questions about their consistency,
explainability, and alignment with traditional App Store Optimization (ASO)
metrics. In this paper, we present an empirical analysis of how widely-used
general purpose LLMs generate, justify, and rank mobile app recommendations.
Our contributions are: (i) a taxonomy of 16 generalizable ranking criteria
elicited from LLM outputs; (ii) a systematic evaluation framework to analyse
recommendation consistency and responsiveness to explicit ranking instructions;
and (iii) a replication package to support reproducibility and future research
on AI-based recommendation systems. Our findings reveal that LLMs rely on a
broad yet fragmented set of ranking criteria, only partially aligned with
standard ASO metrics. While top-ranked apps tend to be consistent across runs,
variability increases with ranking depth and search specificity. LLMs exhibit
varying sensitivity to explicit ranking instructions - ranging from substantial
adaptations to near-identical outputs - highlighting their complex reasoning
dynamics in conversational app discovery. Our results aim to support end-users,
app developers, and recommender-systems researchers in navigating the emerging
landscape of conversational app discovery.

</details>


### [5] [LLMs as Sparse Retrievers:A Framework for First-Stage Product Search](https://arxiv.org/abs/2510.18527)
*Hongru Song,Yu-an Liu,Ruqing Zhang,Jiafeng Guo,Maarten de Rijke,Sen Li,Wenjun Peng,Fuyu Lv,Xueqi Cheng*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Product search is a crucial component of modern e-commerce platforms, with
billions of user queries every day. In product search systems, first-stage
retrieval should achieve high recall while ensuring efficient online
deployment. Sparse retrieval is particularly attractive in this context due to
its interpretability and storage efficiency. However, sparse retrieval methods
suffer from severe vocabulary mismatch issues, leading to suboptimal
performance in product search scenarios.With their potential for semantic
analysis, large language models (LLMs) offer a promising avenue for mitigating
vocabulary mismatch issues and thereby improving retrieval quality. Directly
applying LLMs to sparse retrieval in product search exposes two key
challenges:(1)Queries and product titles are typically short and highly
susceptible to LLM-induced hallucinations, such as generating irrelevant
expansion terms or underweighting critical literal terms like brand names and
model numbers;(2)The large vocabulary space of LLMs leads to difficulty in
initializing training effectively, making it challenging to learn meaningful
sparse representations in such ultra-high-dimensional spaces.To address these
challenges, we propose PROSPER, a framework for PROduct search leveraging LLMs
as SParsE Retrievers. PROSPER incorporates: (1)A literal residual network that
alleviates hallucination in lexical expansion by reinforcing underweighted
literal terms through a residual compensation mechanism; and (2)A lexical
focusing window that facilitates effective training initialization via a
coarse-to-fine sparsification strategy.Extensive offline and online experiments
show that PROSPER significantly outperforms sparse baselines and achieves
recall performance comparable to advanced dense retrievers, while also
achieving revenue increments online.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [6] [EVER: Edge-Assisted Auto-Verification for Mobile MR-Aided Operation](https://arxiv.org/abs/2510.18224)
*Jiangong Chen,Mingyu Zhu,Bin Li*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mixed Reality (MR)-aided operation overlays digital objects on the physical
world to provide a more immersive and intuitive operation process. A primary
challenge is the precise and fast auto-verification of whether the user follows
MR guidance by comparing frames before and after each operation. The
pre-operation frame includes virtual guiding objects, while the post-operation
frame contains physical counterparts. Existing approaches fall short of
accounting for the discrepancies between physical and virtual objects due to
imperfect 3D modeling or lighting estimation. In this paper, we propose EVER:
an edge-assisted auto-verification system for mobile MR-aided operations.
Unlike traditional frame-based similarity comparisons, EVER leverages the
segmentation model and rendering pipeline adapted to the unique attributes of
frames with physical pieces and those with their virtual counterparts; it
adopts a threshold-based strategy using Intersection over Union (IoU) metrics
for accurate auto-verification. To ensure fast auto-verification and low energy
consumption, EVER offloads compute-intensive tasks to an edge server. Through
comprehensive evaluations of public datasets and custom datasets with practical
implementation, EVER achieves over 90% verification accuracy within 100
milliseconds (significantly faster than average human reaction time of
approximately 273 milliseconds), while consuming only minimal additional
computational resources and energy compared to a system without
auto-verification.

</details>


### [7] [How2Compress: Scalable and Efficient Edge Video Analytics via Adaptive Granular Video Compression](https://arxiv.org/abs/2510.18409)
*Yuheng Wu,Thanh-Tung Nguyen,Lucas Liebe,Quang Tau,Pablo Espinosa Campos,Jinghan Cheng,Dongman Lee*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the rapid proliferation of the Internet of Things, video analytics has
become a cornerstone application in wireless multimedia sensor networks. To
support such applications under bandwidth constraints, learning-based adaptive
quantization for video compression have demonstrated strong potential in
reducing bitrate while maintaining analytical accuracy. However, existing
frameworks often fail to fully exploit the fine-grained quality control enabled
by modern blockbased video codecs, leaving significant compression efficiency
untapped.
  In this paper, we present How2Compress, a simple yet effective framework
designed to enhance video compression efficiency through precise, fine-grained
quality control at the macroblock level. How2Compress is a plug-and-play module
and can be seamlessly integrated into any existing edge video analytics
pipelines. We implement How2Compress on the H.264 codec and evaluate its
performance across diverse real-world scenarios. Experimental results show that
How2Compress achieves up to $50.4\%$ bitrate savings and outperforms baselines
by up to $3.01\times$ without compromising accuracy, demonstrating its
practical effectiveness and efficiency. Code is available at
https://github.com/wyhallenwu/how2compress and a reproducible docker image at
https://hub.docker.com/r/wuyuheng/how2compress.

</details>


### [8] [DeLoad: Demand-Driven Short-Video Preloading with Scalable Watch-Time Estimation](https://arxiv.org/abs/2510.18459)
*Tong Liu,Zhiwei Fan,Guanyan Peng,Haodan Zhang,Yucheng Zhang,Zhen Wang,Pengjin Xie,Liang Liu*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Short video streaming has become a dominant paradigm in digital media,
characterized by rapid swiping interactions and diverse media content. A key
technical challenge is designing an effective preloading strategy that
dynamically selects and prioritizes download tasks from an evolving playlist,
balancing Quality of Experience (QoE) and bandwidth efficiency under practical
commercial constraints. However, real world analysis reveals critical
limitations of existing approaches: (1) insufficient adaptation of download
task sizes to dynamic conditions, and (2) watch time prediction models that are
difficult to deploy reliably at scale. In this paper, we propose DeLoad, a
novel preloading framework that addresses these issues by introducing dynamic
task sizing and a practical, multi dimensional watch time estimation method.
Additionally, a Deep Reinforcement Learning (DRL) enhanced agent is trained to
optimize the download range decisions adaptively. Extensive evaluations
conducted on an offline testing platform, leveraging massive real world network
data, demonstrate that DeLoad achieves significant improvements in QoE metrics
(34.4% to 87.4% gain). Furthermore, after deployment on a large scale
commercial short video platform, DeLoad has increased overall user watch time
by 0.09% while simultaneously reducing rebuffering events and 3.76% bandwidth
consumption.

</details>


### [9] [PIRA: Pan-CDN Intra-video Resource Adaptation for Short Video Streaming](https://arxiv.org/abs/2510.18606)
*Chunyu Qiao,Tong Liu,Yucheng Zhang,Zhiwei Fan,Pengjin Xie,Zhen Wang,Liang Liu*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In large scale short video platforms, CDN resource selection plays a critical
role in maintaining Quality of Experience (QoE) while controlling escalating
traffic costs. To better understand this phenomenon, we conduct in the wild
network measurements during video playback in a production short video system.
The results reveal that CDNs delivering higher average QoE often come at
greater financial cost, yet their connection quality fluctuates even within a
single video underscoring a fundamental and dynamic trade off between QoE and
cost. However, the problem of sustaining high QoE under cost constraints
remains insufficiently investigated in the context of CDN selection for short
video streaming. To address this, we propose PIRA, a dynamic resource selection
algorithm that optimizes QoE and cost in real time during video playback. PIRA
formally integrating QoE and cost by a mathematical model, and introduce a
intra video control theoretic CDN resource selection approach which can balance
QoE and cost under network dynamics. To reduce the computation overheads, PIRA
employs state space pruning and adaptive parameter adjustment to efficiently
solve the high dimensional optimization problem. In large scale production
experiments involving 450,000 users over two weeks, PIRA outperforms the
production baseline, achieving a 2.1% reduction in start up delay, 15.2%
shorter rebuffering time, and 10% lower average unit traffic cost,
demonstrating its effectiveness in balancing user experience and financial cost
at scale.

</details>
