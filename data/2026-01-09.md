<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 4]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.IR](#cs.IR) [Total: 10]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.LG](#cs.LG) [Total: 49]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review](https://arxiv.org/abs/2601.04252)
*Daoan Zhang,Shuo Zhang,Zijian Jin,Jiebo Luo,Shengyu Fu,Elsie Nallipogu*

Main category: cs.SE

TL;DR: Sphinx框架通过结构化数据生成管道、基于清单的评估基准以及Checklist Reward Policy Optimization（CRPO）训练方法，有效提升了拉取请求审查自动化过程中的上下文理解能力和技术准确性。


<details>
  <summary>Details</summary>
Motivation: 当前拉取请求(PR)审查自动化面临的主要挑战包括噪声监督、有限的上下文理解能力以及不足的评估指标。为了解决这些问题并提高软件质量保证流程效率，提出了Sphinx这一统一框架。

Method: Sphinx包含三个核心组件：1. 一种能够生成富含上下文信息和语义基础评论的数据生成管道；2. 基于清单的评价标准，该标准依据可操作验证点的结构化覆盖程度来衡量审查质量；3. Checklist Reward Policy Optimization (CRPO)，这是一种新的训练范式，使用基于规则的可解释奖励来使模型行为与实际审查实践相一致。

Result: 实验结果表明，使用Sphinx训练的模型在审查完整性和精确度方面达到了最先进的性能，在检查表覆盖率上比专有和开源基线高出高达40%。

Conclusion: Sphinx不仅提高了PR审查自动化工具的语言流畅性，还增强了其上下文感知能力、技术准确性，并使其能够在实际开发工作流中得到应用。

Abstract: Pull request (PR) review is essential for ensuring software quality, yet automating this task remains challenging due to noisy supervision, limited contextual understanding, and inadequate evaluation metrics. We present Sphinx, a unified framework for LLM-based PR review that addresses these limitations through three key components: (1) a structured data generation pipeline that produces context-rich, semantically grounded review comments by comparing pseudo-modified and merged code; (2) a checklist-based evaluation benchmark that assesses review quality based on structured coverage of actionable verification points, moving beyond surface-level metrics like BLEU; and (3) Checklist Reward Policy Optimization (CRPO), a novel training paradigm that uses rule-based, interpretable rewards to align model behavior with real-world review practices. Extensive experiments show that models trained with Sphinx achieve state-of-the-art performance on review completeness and precision, outperforming both proprietary and open-source baselines by up to 40\% in checklist coverage. Together, Sphinx enables the development of PR review models that are not only fluent but also context-aware, technically precise, and practically deployable in real-world development workflows. The data will be released after review.

</details>


### [2] [AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation](https://arxiv.org/abs/2601.04540)
*Tanghaoran Zhang,Xinjun Mao,Shangwen Wang,Yuxin Zhao,Yao Lu,Jin Zhang,Zhang Zhang,Kang Yang,Yue Yu*

Main category: cs.SE

TL;DR: 提出了一种新的基准测试AdaptEval，用于评估大型语言模型在代码片段适应性方面的性能。该基准测试基于实际开发情境、多层次注释以及细粒度的评估框架设计，以全面评价模型在不同适应场景下的表现，并通过实验研究了六个指令调优的大型语言模型在代码片段适应任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对代码重用过程中适应性调整这一关键活动的基准测试来衡量大型语言模型的表现，这使得它们在这领域的实际应用价值尚不清楚。

Method: 设计并提出了名为AdaptEval的新基准测试，它具有三个独特特点：1) 实践背景，任务来源于开发者实践；2) 多层次标注，每个任务都有任务级和适应级的需求说明；3) 细粒度评估，包含两层测试框架以评估多种单独适应情况下的模型表现。

Result: 实验结果表明，AdaptEval能够从多个角度评估大型语言模型的适应能力，并揭示了这些模型目前存在的局限性，特别是难以遵循明确指示的问题。

Conclusion: AdaptEval为研究和提升大型语言模型在代码片段适应方面的能力提供了有力工具，有助于促进其实际应用。

Abstract: Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.

</details>


### [3] [A Longitudinal Analysis of Gamification in Untappd: Ethical Reflections on a Social Drinking Application](https://arxiv.org/abs/2601.04841)
*Jefferson Seide Molléri,Sami Hyrynsalmi,Antti Hakkala,Kai K. Kimppa,Jouni Smed*

Main category: cs.SE

TL;DR: 本文对社交饮酒应用Untappd进行了纵向伦理分析，研究其游戏化功能（如徽章、连胜和社会分享）如何影响用户自主权和福祉，并指出尽管有小调整，许多原始的伦理问题仍然存在。


<details>
  <summary>Details</summary>
Motivation: 通过对Untappd这一将啤酒消费游戏化的社交应用程序进行纵向伦理分析，旨在探索其游戏化特性及其伦理框架随时间的变化情况。

Method: 基于2020年的初步研究，在2025年再次访问该平台，运用传统伦理理论与软件工程实用框架分析五类徽章及其对用户自主性和福祉的影响。

Result: 研究表明，即便经过一些细微调整和表面免责声明，许多原有的伦理问题仍旧存在。

Conclusion: 建议将持续性的伦理反思嵌入软件生命周期中，以防止通过设计使冒险行为正常化。

Abstract: This paper presents a longitudinal ethical analysis of Untappd, a social drinking application that gamifies beer consumption through badges, streaks, and social sharing. Building on an exploratory study conducted in 2020, we revisit the platform in 2025 to examine how its gamification features and ethical framings have evolved. Drawing on traditional ethical theory and practical frameworks for Software Engineering, we analyze five categories of badges and their implications for user autonomy and well-being. Our findings show that, despite small adjustments and superficial disclaimers, many of the original ethical issues remain. We argue for continuous ethical reflection built embedded into software lifecycles to prevent the normalization of risky behaviors through design.

</details>


### [4] [AVX / NEON Intrinsic Functions: When Should They Be Used?](https://arxiv.org/abs/2601.04922)
*Théo Boivin,Joeffrey Legaux*

Main category: cs.SE

TL;DR: 本文提出了一种跨配置基准，用于探索AVX/NEON内在函数在需要矢量化策略以优化代码的一般开发项目中的能力与限制。研究发现，在条件分支中使用内在函数非常高效，执行时间仅为普通代码的大约5%。然而，在许多情况下，由于编译器已经很好地实现了自动矢量化，因此使用内在函数是不必要的。


<details>
  <summary>Details</summary>
Motivation: 为了帮助开发者根据操作系统、架构和/或可用编译器选择何时使用内在函数来优化代码，特别是在考虑采用矢量化策略时。

Method: 通过提出一个跨配置基准测试，评估了AVX/NEON内在函数在通用开发场景下的性能及其局限性。

Result: 结果显示，在涉及条件分支的情况下，内在函数的效率非常高，但同时指出在很多情形下因现代编译器的良好自动矢量化功能使得直接应用内在函数变得不必要。

Conclusion: 本研究为开发者提供了关于在何种条件下利用AVX/NEON内在函数能够有效提升程序性能的指导建议，同时也强调了不应盲目依赖这些技术的重要性。

Abstract: A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks](https://arxiv.org/abs/2601.04523)
*Ajay Singh,Nikos Metaxakis,Panagiota Fatourou*

Main category: cs.DC

TL;DR: 提出了一种新的阻塞线性化堆栈实现，利用分片和取&增操作达到了比现有并发堆栈更好的性能。实验表明，在大多数工作负载下，该堆栈实现的性能优于所有现有的并发堆栈高达2倍，并且在支持大量线程和高竞争场景中特别有效。


<details>
  <summary>Details</summary>
Motivation: 为了提高并发堆栈在多线程环境下的性能以及降低访问共享堆栈时的竞争情况。

Method: 通过引入一种新颖的消除机制和一种新的组合方法来实现高性能的堆栈。使用了分片（sharding）和取&增（fetch&increment）技术。

Result: 所提出的堆栈实现在大多数工作负载下比现有并发堆栈性能高出最多2倍，并且在处理大量线程和支持高竞争情形时表现出色。

Conclusion: 这种基于新消除机制与组合方法设计的堆栈能够显著提升并发执行效率并减少资源竞争。

Abstract: We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.

</details>


### [6] [Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers](https://arxiv.org/abs/2601.04750)
*Krishna Chaitanya Sunkara*

Main category: cs.DC

TL;DR: 本文介绍了DCIM 3.0，一种综合框架，通过基于知识图谱的智能、热建模和统一设备连接协议来解决下一代AI数据中心管理中的基础设施自动化、可持续性和数字孪生设计等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决下一代AI数据中心管理中面临的基础设施自动化、可持续性以及数字孪生设计的关键挑战。

Method: 提出了一个集成语义推理、预测分析、自主编排和统一连接性的框架DCIM 3.0，该框架利用知识图谱智能、热模型及统一设备连接协议（UDCP）。

Result: 构建了一个能够有效应对现代AI数据中心复杂需求的综合管理系统。

Conclusion: DCIM 3.0为实现更加智能、自动化的数据中心运营提供了新的方法论和技术支持。

Abstract: This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center

</details>


### [7] [Asynchronous Secure Federated Learning with Byzantine aggregators](https://arxiv.org/abs/2601.04930)
*Antonella Del Pozzo,Achille Desreumaux,Mathieu Gestin,Alexandre Rapetti,Sara Tucci-Piergiovanni*

Main category: cs.DC

TL;DR: 本文提出了一种在异步通信环境中应对恶意聚合器的隐私保护联邦平均方法，通过安全聚合和差分隐私保护客户端数据隐私。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在存在恶意聚合服务器的情况下，如何在异步通信设置中实现隐私保护联邦学习的问题。这些恶意聚合服务器可能操纵模型以泄露客户数据或停止计算。

Method: 本文的方法包括复制聚合器以容忍部分被破坏的情况、提出新的隐私保护协议让客户端对值进行掩码并添加高斯噪声至其模型、以及引入一种包含机制来确保客户端参与的一致性和平衡隐私预算。

Result: 该解决方案保持了与现有最先进方法相同的性能，并且不依赖于聚合器之间的共识，从而绕过了异步环境中已知的不可能达成一致的问题。

Conclusion: 本文为在存在恶意及拜占庭式聚合器的环境下提供了有效的隐私保护方案，同时保证了训练过程中的活跃性以及客户端隐私的安全。

Abstract: Privacy-preserving federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous communications setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous communication models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous communication model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [8] [Correct and Weight: A Simple Yet Effective Loss for Implicit Feedback Recommendation](https://arxiv.org/abs/2601.04291)
*Minglei Yin,Chuanbo Hu,Bin Liu,Neil Zhenqiang Gong,Yanfang,Ye,Xin Li*

Main category: cs.IR

TL;DR: 本文提出了一种新的损失函数——校正加权(CW)损失，旨在解决推荐系统中隐式反馈学习时存在的假阴性问题。通过重新校准假设的负分布并引入动态重加权机制来调整每个负样本的重要性，从而提高模型区分正负样本的能力。实验结果表明，该方法在多个排名导向指标上优于现有的最先进损失函数。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统主要依赖于从隐式反馈中学习，但这种方法面临一个持续的挑战：未观察到的用户-项目交互并不一定表示负面偏好，即存在假阴性的问题。为了解决这个问题，提出了一个新的、有原则的损失函数。

Method: 1. 采用类似于正例-未标记（Positive-Unlabeled）学习的方法，通过理论近似真正的负分布。
2. 引入一种动态重加权机制，根据模型当前预测调整每个负实例的重要性，以鼓励模型对正项和高置信度预测（容易）的负项之间施加更大的排序间隔，并同时降低对可能为假阴性的不确定负项的惩罚。

Result: 通过对四个大规模稀疏基准数据集进行广泛的实验，证明了所提出的损失函数在多个面向排名的度量标准上一致且显著地优于一系列最先进的损失函数。

Conclusion: 本文介绍了一种创新的校正加权(CW)损失函数，有效解决了推荐系统中由于假阴性带来的训练目标偏差问题。该方法不仅提高了模型性能，而且易于集成到现有推荐模型中，无需复杂的数据采样过程修改或显著增加计算开销。

Abstract: Learning from implicit feedback has become the standard paradigm for modern recommender systems. However, this setting is fraught with the persistent challenge of false negatives, where unobserved user-item interactions are not necessarily indicative of negative preference. To address this issue, this paper introduces a novel and principled loss function, named Corrected and Weighted (CW) loss, that systematically corrects for the impact of false negatives within the training objective. Our approach integrates two key techniques. First, inspired by Positive-Unlabeled learning, we debias the negative sampling process by re-calibrating the assumed negative distribution. By theoretically approximating the true negative distribution (p-) using the observable general data distribution (p) and the positive interaction distribution (p^+), our method provides a more accurate estimate of the likelihood that a sampled unlabeled item is truly negative. Second, we introduce a dynamic re-weighting mechanism that modulates the importance of each negative instance based on the model's current prediction. This scheme encourages the model to enforce a larger ranking margin between positive items and confidently predicted (i.e., easy) negative items, while simultaneously down-weighting the penalty on uncertain negatives that have a higher probability of being false negatives. A key advantage of our approach is its elegance and efficiency; it requires no complex modifications to the data sampling process or significant computational overhead, making it readily applicable to a wide array of existing recommendation models. Extensive experiments conducted on four large-scale, sparse benchmark datasets demonstrate the superiority of our proposed loss. The results show that our method consistently and significantly outperforms a suite of state-of-the-art loss functions across multiple ranking-oriented metrics.

</details>


### [9] [The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval](https://arxiv.org/abs/2601.04395)
*Tomer Wullach,Ori Shapira,Amir DN Cohen*

Main category: cs.IR

TL;DR: 研究分析了分级相关性评分和转换为二元标签的阈值对多语言密集检索的影响，发现最佳阈值随语言和任务的不同而变化，并指出校准阈值是密集检索微调过程中一个重要的环节。


<details>
  <summary>Details</summary>
Motivation: 探索分级相关性评分以及将这些评分转换成二元标签时所使用的阈值如何影响多语言环境下的密集检索模型表现。

Method: 使用带有LLM标注的相关性分数的多语言数据集，在单语种、多语种混合及跨语种检索情境下进行实验。

Result: 不同语言和任务的最佳阈值存在系统性差异；选择合适的阈值可以提高效率、减少所需的微调数据量并减轻标注噪声带来的负面影响；而不当的选择则会降低性能。

Conclusion: 分级相关性对于密集检索而言是一个有价值但未被充分利用的信号，阈值校准应当被视为微调流程中的一个重要且有原则性的组成部分。

Abstract: Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.

</details>


### [10] [Re-Rankers as Relevance Judges](https://arxiv.org/abs/2601.04455)
*Chuan Meng,Jiqun Liu,Mohammad Aliannejadi,Fengran Mo,Jeff Dalton,Maarten de Rijke*

Main category: cs.IR

TL;DR: 该研究旨在通过重用或适应已建立的重排序方法来预测相关性判断，以减少资源浪费和重复开发。实验表明基于重排序器的相关性判断在某些情况下可以超越当前最先进的基于大语言模型的相关性判断，并且显示出对自身或同系列重排序器的强烈偏好以及跨系列偏差。


<details>
  <summary>Details</summary>
Motivation: 尽管预测相关性判断本质上是一种相关性预测问题，与重排序任务有潜在重叠，但很少有研究探索重用或调整现有的重排序方法来进行相关性判断预测，这导致了可能的资源浪费和不必要的开发工作。

Method: 研究者们采用了两种适应策略：(i) 使用重排序器生成的二进制标记（如“真”和“假”）作为直接判断；(ii) 通过阈值处理将连续的重排序分数转换为二进制标签。他们使用来自3个系列、规模从2.2亿到320亿不等的8个重排序器，在TREC-DL 2019至2023的数据集上进行了广泛的实验。

Result: 结果显示，基于重排序器的相关性评判者在大约40%到50%的情况下能够优于UMBRELA，后者是基于大型语言模型的最先进相关性评判工具。此外，基于重排序器的评判还表现出对自己及同系重排序器的强大偏好，以及跨系偏见。

Conclusion: 研究证明了利用现有重排序技术进行相关性判断预测的有效性和潜力，同时也揭示了这种方法可能存在的一些偏见问题。

Abstract: Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., "true" and "false") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.

</details>


### [11] [Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering](https://arxiv.org/abs/2601.04531)
*Jessica Ryan,Alexander I. Gumilang,Robert Wiliam,Derwin Suhartono*

Main category: cs.IR

TL;DR: 提出了一种名为Self-MedRAG的自我反思混合框架，通过结合稀疏和密集检索器以及迭代假设-验证过程来提高大型语言模型在医学问答中的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医学问答中展现出巨大潜力，但由于存在幻觉和无根据推理的问题，在高风险临床场景下的可靠性受到限制。传统的单次检索方法无法有效解决需要多步骤推理的复杂生物医学查询。

Method: Self-MedRAG采用了一种混合检索策略，结合了稀疏检索器BM25与密集检索器Contriever，并通过互惠排名融合（RRF）技术最大化证据覆盖范围。该框架使用生成器创建带有支持理由的答案，随后由轻量级自反思模块利用自然语言推理（NLI）或基于LLM的验证进行评估。当理由缺乏足够证据支持时，系统能够自动重新表述查询并迭代以优化上下文。

Result: 在MedQA和PubMedQA基准测试上的评估显示，所提出的混合检索方法显著优于单一检索基线；此外，加入自我反思循环后，进一步提高了准确性，其中MedQA从80.00%提升至83.33%，而PubMedQA则从69.10%增长到了79.82%。

Conclusion: 研究结果表明，将混合检索与基于证据的迭代自我反思相结合，能有效减少不支持的声明，从而增强基于LLM系统的临床可靠性。

Abstract: Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.

</details>


### [12] [Adaptive Retrieval for Reasoning-Intensive Retrieval](https://arxiv.org/abs/2601.04618)
*Jongho Kim,Jaeyoung Kim,Seung-won Hwang,Jihyuk Kim,Yu Jin Kim,Moontae Lee*

Main category: cs.IR

TL;DR: 本文提出了一种名为REPAIR的框架，通过将推理计划重新用作自适应检索的密集反馈信号来确保在推理密集型检索中获取足够的'桥梁'文档。实验结果表明，该方法在推理密集型检索和复杂问答任务上比现有基线高出5.6个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有的基于推理的重排器流水线试图在排名中突出这些文档，但它们存在召回率有限的问题。直接将自适应检索引入这些流水线往往会导致规划错误传播。为了解决这个问题，研究者提出了REPAIR框架。

Method: REPAIR框架通过将推理计划作为自适应检索的密集反馈信号，并允许在重排序过程中进行中途修正，选择性地进行自适应检索以获取支持关键计划的文档。

Result: 实验证明，在处理推理密集型检索及复杂的QA任务时，所提出的方法相比现有基线性能提高了5.6%。

Conclusion: REPAIR框架成功地解决了如何在推理密集型检索过程中有效利用桥梁文档的问题，通过改进自适应检索策略显著提升了系统性能。

Abstract: We study leveraging adaptive retrieval to ensure sufficient "bridge" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.

</details>


### [13] [Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search](https://arxiv.org/abs/2601.04646)
*Prateek Jain,Shabari S Nair,Ritesh Goru,Prakhar Agarwal,Ajay Yadav,Yoga Sri Varshan Varadharajan,Constantine Caramanis*

Main category: cs.IR

TL;DR: 本文提出了DevRev Search，一个通过全自动流程构建的技术客户支持段落检索基准。采用基于融合的候选生成策略，并利用LLM作为裁判进行一致性过滤和相关性分配。同时提出了一种保持索引不变的适应策略，仅通过对查询编码器进行微调来实现性能改进，为个性化企业搜索提供了一个可扩展路径。


<details>
  <summary>Details</summary>
Motivation: 大规模多租户检索系统积累了大量的用户查询日志，但严重缺乏有效领域适应所需的相关标签。此外，模型更新的操作成本高：联合微调查询和文档编码器需要重新索引整个语料库，在拥有数千个隔离索引的多租户环境中是不可行的。

Method: 通过全自动流程构建了名为DevRev Search的技术客户支持段落检索基准。采用了基于融合的候选生成策略，结合了多种稀疏和密集检索器的结果，并使用大语言模型作为裁判执行严格的一致性过滤和相关性分配。进一步提出了保持索引不变的适应策略：仅通过低秩适应（LoRA）技术对查询编码器进行微调，在保持文档索引冻结的情况下实现了竞争性的性能提升。

Result: 实验表明，针对查询编码器中特定的变压器层可以达到最佳的质量-效率平衡，为个性化企业搜索提供了一个可扩展路径。

Conclusion: 该研究提出的方法不仅解决了大规模多租户检索系统中缺乏标注数据的问题，还通过只微调查询编码器而保持文档索引不变的方式降低了操作成本，从而为个性化企业搜索提供了新的可能性。

Abstract: Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This "dark data" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \textbf{consistency filtering} and relevance assignment. We further propose a practical \textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.

</details>


### [14] [PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations](https://arxiv.org/abs/2601.04674)
*Chengcheng Guo,Kuo Cai,Yu Zhou,Qiang Luo,Ruiming Tang,Han Li,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: 提出了一种名为Promise的新框架，通过集成密集的逐步验证到生成模型中来解决现有生成推荐方法中的语义漂移问题。该框架包括轻量级的过程奖励模型以评估中间推理步骤的质量，并结合了由过程奖励模型引导的束搜索策略，利用密集反馈动态剪枝错误路径。此外，该方法揭示了推荐系统在测试时的规模法则：通过增加推理计算，较小的模型能够匹配甚至超越较大的模型。离线实验和在线A/B测试表明Promise有效缓解了语义漂移问题，显著提高了推荐准确性同时实现了高效部署。


<details>
  <summary>Details</summary>
Motivation: 现有的生成推荐方法面临一个关键问题——语义漂移，即早期高层令牌中的错误会不可逆转地将生成轨迹导向无关的语义子空间。为了解决这个问题，并提高推荐系统的准确性和效率，提出了新的解决方案。

Method: 开发了一个名为Promise的新框架，它将密集、逐步验证整合进生成模型中。此框架采用了轻量级的过程奖励模型（PRM）来评估中间推理步骤的质量，并且结合了由PRM指导的束搜索策略，使用密集反馈机制动态修剪出错分支。

Result: 广泛的离线实验以及在一个大规模平台上的在线A/B测试显示，Promise能有效地减轻语义漂移现象，大大提升了推荐的准确性，同时也支持了更高效的部署方式。

Conclusion: Promise框架通过引入过程奖励模型和改进的束搜索策略成功解决了生成推荐中存在的语义漂移问题，不仅提高了推荐质量还促进了资源的有效利用。

Abstract: Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.

</details>


### [15] [Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective](https://arxiv.org/abs/2601.04918)
*Ziwen Wang,Shangshang Yang,Xiaoshan Yu,Haiping Ma,Xingyi Zhang*

Main category: cs.IR

TL;DR: 提出了一种名为OSCD的方法，通过两阶段（训练和搜索）过程来优化认知诊断模型的结构设计，以提高学习者能力评估的有效性和鲁棒性。该方法在处理噪声数据时表现出色，并通过实验证明了其在实际教育数据集上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究过于关注提升模型性能而忽视了观察响应数据中的噪声污染问题，同时当前的认知诊断模型设计依赖于研究人员的专业知识，未能充分探索可能的架构潜力。

Method: OSCD方法分为两个阶段：1) 训练阶段，构建一个包含多种架构组合的搜索空间，并通过完全二叉树拓扑结构训练一个权重共享超网；2) 搜索阶段，将最佳架构搜索定义为一个多目标优化问题(MOP)，并开发了一个结合Pareto最优解搜索策略与跨场景性能评估的优化框架。

Result: 通过对真实世界教育数据集进行广泛实验，证明了由OSCD模型发现的最佳架构对于执行认知诊断任务既有效又稳健。

Conclusion: OSCD作为一种进化多目标一次性神经架构搜索方法，能够有效地克服现有认知诊断模型中存在的局限性，特别是在处理含噪数据方面展现出更强的适应性和准确性。

Abstract: With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.

</details>


### [16] [Dynamics in Search Engine Query Suggestions for European Politicians](https://arxiv.org/abs/2601.05081)
*Franziska Pradel,Fabian Haak*

Main category: cs.IR

TL;DR: 本研究系统地分析了十个国家中针对欧洲和国家政治家的谷歌搜索引擎查询建议，发现政治家本国、担任超国家角色的政治家以及女性政治家的查询建议随时间变化较大。此外，对于政治领导人和男性政治家的查询建议在不同国家之间更为相似。


<details>
  <summary>Details</summary>
Motivation: 探讨不同国家及时间点上反映互联网用户潜在兴趣的政治搜索查询建议的变化情况。

Method: 通过收集十个国家内关于欧洲政治人物的原始查询建议数据集来进行分析。

Result: 发现在政治家本国、对于具有超国家角色或为女性的政治家，其查询建议随时间更不稳定；而对领导层人物和男性政治家来说，跨国家间查询建议较为一致。

Conclusion: 讨论了未来在线搜索中关于欧洲政治人物信息检索研究可能的方向。

Abstract: Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.

</details>


### [17] [Multivector Reranking in the Era of Strong First-Stage Retrievers](https://arxiv.org/abs/2601.05200)
*Silvio Martinico,Franco Maria Nardini,Cosimo Rulli,Rossano Venturini*

Main category: cs.IR

TL;DR: 该论文提出了一种两阶段检索架构，通过用单向量文档检索器（具体为学习稀疏检索器LSR）替换传统的token-level检索阶段，从而减少了检索延迟并提高了候选集的质量。此外，还引入了无需推理的LSR方法来减少查询编码时间，并通过多种重排序配置和优化技术进一步提升了检索效率，最终实现了比现有最先进多向量检索系统快24倍以上的速度，同时保持了相当或更优的检索质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的多向量表示在现代搜索系统中表现出强大的检索效果，但由于逐标记级检索成本高昂而限制了实际应用。因此，许多系统采用'聚集-细化'策略以降低成本，但这通常需要对大型标记级别索引进行昂贵搜索且容易错过最佳匹配文档。

Method: 研究者们首先复现了几种最先进的多向量检索方法，并观察到标记级聚集阶段的低效性。随后，他们提出使用单向量文档检索器（即学习稀疏检索器LSR）替代原有的标记级聚集步骤，形成一个更为紧凑且语义连贯的候选集合。针对由此产生的新瓶颈——双神经编码器的查询编码过程，研究团队采用了最近发展的无推理LSR技术来缓解问题。此外，为了进一步优化整个流程，作者探索了多种重新排名设置，并提出了两种能够及早排除低质量候选者的优化技术。

Result: 实验结果表明，所提出的这些技术可以在不牺牲检索质量的前提下将效率提高至1.8倍。总体而言，相较于现有的多向量检索系统，这种两阶段方法实现了超过24倍的速度提升，同时保持了相同甚至更好的检索性能。

Conclusion: 本文介绍了一种新颖的两阶段检索框架，有效地解决了传统多向量检索中存在的高成本与低效率问题。通过结合学习稀疏检索器和其他优化措施，不仅大幅度提高了检索速度，同时也确保了高质量的检索结果。

Abstract: Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [18] [AHA: Scalable Alternative History Analysis for Operational Timeseries Applications](https://arxiv.org/abs/2601.04432)
*Harshavardhan Kamarthi,Harshil Shah,Henry Milner,Sayan Sinha,Yan Li,B. Aditya Prakash,Vyas Sekar*

Main category: cs.DB

TL;DR: 本文介绍了一种名为AHA（Alternative History Analytics）的系统，该系统针对高维时间序列数据提供成本效益和准确性。通过利用统计学的可分解性、子群体活跃数量的稀疏性以及现代分析数据库中聚合操作的效率结构，AHA能够为广泛的下游任务提供100%的准确度，并且与传统方法相比总拥有成本降低了高达85倍。


<details>
  <summary>Details</summary>
Motivation: 在许多运营系统中，收集关于用户/系统的关键性能指标的高维时间序列数据已成为常态。然而，对于这些历史数据执行回顾性分析时，传统的数据处理方案要么成本高昂，要么无法保证回放的准确性。为了克服这些问题，需要一种新的解决方案来有效处理此类工作负载。

Method: 设计并实现了一个名为AHA的新系统，它基于对这类工作负载的分析性和实证洞察：1) 底层统计量的可分解性；2) 在属性值组合上活跃子群体数量上的稀疏性；3) 现代分析数据库中聚合操作的效率结构。

Result: 使用多个真实世界的数据集及一家大型视频分析公司的生产管道案例研究显示，AHA能够为广泛范围内的下游任务提供100%的准确度，并且与传统方法相比总拥有成本（即计算+存储）最高可降低85倍。

Conclusion: AHA系统有效地解决了高维运营数据集中的替代历史分析问题，提供了比现有方法更高的准确性同时大幅减少了成本。

Abstract: Many operational systems collect high-dimensional timeseries data about users/systems on key performance metrics. For instance, ISPs, content distribution networks, and video delivery services collect quality of experience metrics for user sessions associated with metadata (e.g., location, device, ISP). Over such historical data, operators and data analysts often need to run retrospective analysis; e.g., analyze anomaly detection algorithms, experiment with different configurations for alerts, evaluate new algorithms, and so on. We refer to this class of workloads as alternative history analysis for operational datasets. We show that in such settings, traditional data processing solutions (e.g., data warehouses, sampling, sketching, big-data systems) either pose high operational costs or do not guarantee accurate replay. We design and implement a system, called AHA (Alternative History Analytics), that overcomes both challenges to provide cost efficiency and fidelity for high-dimensional data. The design of AHA is based on analytical and empirical insights about such workloads: 1) the decomposability of underlying statistics; 2) sparsity in terms of active number of subpopulations over attribute-value combinations; and 3) efficiency structure of aggregation operations in modern analytics databases. Using multiple real-world datasets and as well as case-studies on production pipelines at a large video analytics company, we show that AHA provides 100% accuracy for a broad range of downstream tasks and up to 85x lower total cost of ownership (i.e., compute + storage) compared to conventional methods.

</details>


### [19] [Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries](https://arxiv.org/abs/2601.04757)
*Cristian Riveros,Benjamin Scheidt,Nicole Schweikardt*

Main category: cs.DB

TL;DR: 提出了一种新的索引结构，用于加速关系数据库中自由连接无环合取查询(fc-ACQs)的评估。该索引基于数据库内部结构对称性，并且其大小与通过Scheidt和Schweikardt提出的'relational color refinement'分配给数据库的颜色数量相关。


<details>
  <summary>Details</summary>
Motivation: 为了加速关系数据库中自由连接无环合取查询（fc-ACQs）的评估，同时减少预处理时间和查询响应时间。

Method: 开发了一种新型索引结构，该结构依赖于原数据库$D$的一个辅助数据库$D_{col}$。此索引方法不同于以往基于值或顺序的方法，而是利用了数据库内元组之间的结构性对称性。

Result: 对于任何在$D$上的fc-ACQ $Q$，可以在经过线性于$D_{col}$大小的预处理阶段后，以常数延迟计算$Q$的答案数量或枚举答案。$D_{col}$的大小与数据库$D$相比可能小得多，甚至对于某些数据库家族来说是恒定不变的。

Conclusion: 这项工作首次证明了通过索引数据库内部的结构对称性来评估所有fc-ACQs的可能性，其性能可能严格小于数据库本身的大小。

Abstract: We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.
  Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's "relational color refinement" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.
  Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.

</details>


### [20] [LGTD: Local-Global Trend Decomposition for Season-Length-Free Time Series Analysis](https://arxiv.org/abs/2601.04820)
*Chotanansub Sophaken,Thanadej Rattanakornphan,Piyanon Charoenpoonpanich,Thanapol Phungtua-eng,Chainarong Amornbunchornvej*

Main category: cs.DB

TL;DR: 本文提出了一种无需指定季节长度的时间序列分解框架LGTD，该方法通过自适应局部趋势推断模块AutoTrend来处理周期性结构，并能够自动部署到具有不规则、漂移或弱周期性结构的时间序列上。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列分解方法通常依赖于用户指定或估计的季节长度，并假设周期结构稳定。然而，在大型异构集合中，这些假设限制了鲁棒性和可部署性，因为重复模式可能会漂移、间歇出现或存在于多个时间尺度上。

Method: 提出了LGTD（Local-Global Trend Decomposition），一种不需要指定季节长度的分解框架，它将时间序列表示为平滑的全局趋势、自适应局部趋势（其重复导致隐含的季节结构）和残差成分之和。LGTD首先估计一个捕捉长期演变的全局趋势，然后应用AutoTrend——一个自适应误差驱动的局部线性趋势推断模块——来将去趋势信号分割成短期的分段线性区域。

Result: 实验结果表明，LGTD在固定、过渡和可变季节长度设置下均表现出稳健且均衡的分解性能，特别是在基于周期的方法性能下降的情况下。此外，分析显示在温和条件下LGTD的计算复杂度随序列长度线性增长。

Conclusion: LGTD支持自动化低接触部署，适用于具有不规则、漂移或弱周期性结构的时间序列，提供了一种更灵活和强大的时间序列分解手段。

Abstract: Time series decomposition into trend, seasonal structure, and residual components is a core primitive for downstream analytics such as anomaly detection, change-point detection, and forecasting. However, most existing seasonal-trend decomposition methods rely on user-specified or estimated season lengths and implicitly assume stable periodic structure. These assumptions limit robustness and deployability in large, heterogeneous collections where recurring patterns may drift, appear intermittently, or exist at multiple time scales.
  We propose LGTD (Local-Global Trend Decomposition), a season-length-free decomposition framework that represents a time series as the sum of a smooth global trend, adaptive local trends whose recurrence induces implicit (emergent) seasonal structure, and a residual component. Rather than explicitly modeling seasonality through a fixed or estimated period, LGTD treats seasonal structure as an emergent property arising from repeated local trend regimes. Concretely, LGTD first estimates a global trend capturing long-term evolution, then applies AutoTrend, an adaptive error-driven local linear trend inference module, to segment the detrended signal into short-lived piecewise-linear regimes. Residuals are obtained after removing both global and local trends.
  By eliminating manual season-length specification, LGTD supports automated, low-touch deployment across time series with irregular, drifting, or weakly periodic structure. We analyze computational complexity and show that LGTD scales linearly with series length under mild conditions. Experiments on synthetic benchmarks demonstrate robust and balanced decomposition performance across fixed, transitive, and variable season-length settings, especially where period-based methods degrade.

</details>


### [21] [Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP](https://arxiv.org/abs/2601.05108)
*Philipp Hanisch,Markus Krötzsch*

Main category: cs.DB

TL;DR: This paper revisits and updates the static filtering method for Datalog, broadening its application to answer set programming (ASP) while addressing its increased complexity through tractable approximations that improve performance.


<details>
  <summary>Details</summary>
Motivation: The motivation is to revive and enhance the static filtering method for Datalog, which has been overlooked in recent research, and to extend its use to ASP. The aim is also to deal with the higher complexity of the updated method by proposing more manageable approximations that can still significantly improve the performance of logic programs.

Method: The authors revisit the original static filtering approach, updating it with modern terminology and more general filter predicates. They then expand the technique's applicability to ASP. To address the increased computational complexity, they develop tractable approximation algorithms that maintain the benefits of the method without the full computational cost.

Result: The result is a more generalized but also more complex static filtering method, with the worst-case complexity being double exponential and single exponential for predicates of bounded arity. The proposed approximations are shown to be effective in improving the performance of rule systems, particularly over real-world data, by an order of magnitude.

Conclusion: The conclusion suggests that the extended static filtering method, despite its increased complexity, offers significant improvements in the performance of logic programs when applied to ASP, especially with the use of tractable approximations.

Abstract: Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [22] [The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs](https://arxiv.org/abs/2601.04199)
*Jiale Zhao,Xing Mou,Jinlin Wu,Hongyuan Yu,Mingrui Sun,Yang Shi,Xuanwu Yin,Zhen Chen,Zhen Lei,Yaohua Wang*

Main category: cs.LG

TL;DR: 本文构建了一个多维度评估框架来系统地衡量当前最先进医学多模态大语言模型的安全性，并发现现有模型在一般和特定医学安全维度上普遍存在脆弱性。提出了一种"参数空间干预"方法，在不依赖额外领域特定安全数据的情况下显著增强了医学多模态大语言模型的安全防护，同时最小化对核心医学性能的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管医学多模态大语言模型在专业医疗任务上取得了显著进展，但其安全性研究滞后，给实际部署带来了潜在风险。特别指出这些模型对于跨模态越狱攻击的脆弱性以及医学微调过程中导致的原始安全对齐灾难性遗忘问题。

Method: 首先建立一个多维度评价体系全面评测当前最优医学多模态大语言模型的安全表现；接着提出一种新的“参数空间干预”方法，从基础模型中提取内在安全知识表示，并在开发医学功能时将其注入目标模型；还设计了一种精细参数搜索算法以寻找安全与医学性能之间的最佳平衡点。

Result: 实验结果表明，所提方法能够显著加强医学多模态大语言模型的安全防线，无需依赖更多领域特有的安全资料，同时最大程度地减少了对主要医学效能的负面影响。

Conclusion: 通过引入参数空间干预手段及优化参数搜索策略，可以在不影响医学性能的前提下有效提升医学多模态大语言模型的安全水平。

Abstract: Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel "Parameter-Space Intervention" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.

</details>


### [23] [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)
*Mustapha Hamdi,Mourad Jabou*

Main category: cs.LG

TL;DR: 该论文提出了一种受生物启发的框架，通过将蛋白质折叠能量盆地映射到推理成本景观，并利用一个衰减的闭环阈值来控制执行，以提高AI部署中的能效。实验表明，这种方法可以显著减少处理时间，同时对准确性的影响极小。


<details>
  <summary>Details</summary>
Motivation: 随着长期运行的推理在累积碳排放方面可能超过训练过程，提升AI部署中的能效率变得至关重要。

Method: 作者们开发了一个灵感来源于生物学的过程控制机制，它模仿了蛋白质折叠时的能量盆地分布特性应用于推理成本的管理上；通过设置一个逐渐减弱的反馈环路阈值来决定是否接受新的请求，确保只有当预期的效用-能耗比有利时才会继续执行。

Result: 实验评估显示，与传统的开环执行相比，所提出的生物控制器能够将处理时间减少42%，同时准确性的下降小于0.5%。此外，还研究了轻量级本地服务和管理批处理之间的效率界限。

Conclusion: 研究成果为绿色MLOps提供了理论基础，并为生产环境中实施闭环、节能意识强的推理提供了一种实用且可审计的方法。

Abstract: Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.

</details>


### [24] [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)
*Wang Cai,Yilin Wen,Jinchang Hou,Du Su,Guoqiu Wang,Zhonghou Lv,Chenfu Bao,Yunfang Wu*

Main category: cs.LG

TL;DR: 本文提出了一种名为Conflict-Aware Sparse Tuning (CAST)的新框架，通过构建预对齐冲突图来指导参数选择性更新，从而解决大型语言模型中安全对齐的多目标优化冲突问题。实验表明，通过跳过一小部分高冲突注意力头进行训练，可以在不牺牲安全性的同时显著减少通用能力下降的问题，提供了一种可解释且参数效率高的方法来改善安全-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的缓解策略通常依赖于全局梯度几何来解决大语言模型（LLMs）中的安全对齐所固有的多目标优化冲突，但忽略了Transformer内部不同注意力头之间存在的模块异质性，即功能敏感性和冲突程度在不同注意力头间存在巨大差异。这种全局方法对所有参数施加统一的更新规则，往往导致次优折衷，因为它们无差别地更新了表现出强烈梯度冲突的实用敏感头部。

Method: 提出了Conflict-Aware Sparse Tuning (CAST)框架，该框架结合了头部层面诊断与稀疏微调。首先，通过综合优化冲突和功能敏感性来构建一个预对齐冲突图，然后使用该图指导参数的选择性更新。

Result: 实验显示，LLMs中的对齐冲突并非均匀分布；大部分通用能力下降源自于更新少数“高冲突”头部。简单地在训练过程中跳过这些头部可以显著降低这种损失，同时不影响安全性。

Conclusion: Conflict-Aware Sparse Tuning (CAST) 提供了一个有效的方法来改进大语言模型的安全-效用权衡问题，通过有选择地更新参数并避免更新那些容易引起性能下降的‘高冲突’头部，能够在保持模型安全性的前提下提高整体效能。

Abstract: Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.

</details>


### [25] [Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer](https://arxiv.org/abs/2601.04263)
*Nilushika Udayangani Hewa Dehigahawattage,Kishor Nandakishor,Marimuthu Palaniswami*

Main category: cs.LG

TL;DR: 本文提出了一种新的时间序列知识蒸馏方法——时序显著性蒸馏(Temporal Saliency Distillation)，通过从教师模型传递可解释的知识，不仅传递正确的预测结果，还传递教师的推理过程。这种方法提高了基线方法的性能，并且不需要额外的参数或特定架构假设。


<details>
  <summary>Details</summary>
Motivation: 现有针对时间序列的知识蒸馏方法主要基于最初为计算机视觉任务开发的日志和特征对齐技术，这些方法没有明确考虑到时间数据的特点，存在两个关键问题：一是转移的知识如何帮助学生模型学习的过程不清楚；二是这些方法只转移了有限的知识，主要是复制教师模型的预测准确性。因此，学生模型产生的预测分布往往与教师模型有较大差异，阻碍了它们安全地替代教师模型。

Method: 提出的方法是将传统日志转移扩展到传递可解释的知识，即不仅传递正确的预测，还传递教师的正确推理。具体来说，从教师日志中诱导出所谓的时序显著性，它捕捉了每个输入时间步骤对于教师预测的重要性。通过使用时序显著性蒸馏训练学生模型，鼓励其基于与教师相同的输入特征进行预测。

Result: 实验表明，时序显著性蒸馏有效提升了基线方法的性能，并在预测准确性之外也达到了理想的属性。

Conclusion: 本研究希望为时间序列分析中的可解释知识蒸馏建立一个新的范式。

Abstract: Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.

</details>


### [26] [Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception](https://arxiv.org/abs/2601.04542)
*Mengmeng Zhu,Yuxuan Sun,Yukuan Jia,Wei Chen,Bo Ai,Sheng Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种时延感知多区域优先(TAMP)调度算法，用于解决协作感知中的动态调度问题。通过平衡感知精度与通信资源使用，TAMP算法在实际测试中表现出色，平均精确度(AP)相比最佳基线提高了高达27%。


<details>
  <summary>Details</summary>
Motivation: 协作感知技术在自动驾驶和智慧城市等应用中至关重要，它通过传感器间的信息共享与融合来克服单个感知的局限性。然而，由于环境的动态变化导致信息时效性的要求非常高，加上传感器计算能力和无线带宽有限，如何设计有效的通信量成为一个关键挑战。

Method: 研究了多区域协作感知场景下的动态调度问题，并提出了一个名为TAMP（Timeliness-Aware Multi-region Prioritized）的调度算法。该算法利用Lyapunov优化策略将长期平均目标分解为每时隙的优先级问题，从而平衡调度价值与资源成本之间的关系。此外，还引入了一个经验惩罚函数来反映信息年龄(AoI)和通信量对感知性能的影响。

Result: 通过对交叉口和走廊两种场景下真实世界路边协同感知(RCooper)数据集的验证，广泛模拟表明TAMP算法相较于表现最好的基准，在各种配置下平均精度(AP)提升可达27%。

Conclusion: 提出的TAMP调度算法有效地解决了协作感知中存在的信息时效性和资源限制问题，实现了感知精度与通信资源使用的良好折衷，显著提升了系统的整体性能。

Abstract: Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.

</details>


### [27] [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)
*Beier Luo,Cheng Wang,Hongxin Wei,Sharon Li,Xuefeng Du*

Main category: cs.LG

TL;DR: 本文提出了一种名为Dual-Align的无监督事后框架，旨在通过最终分布匹配和过程对齐来解决大型语言模型后训练导致的信心校准问题。实验表明该方法能有效减少校准误差，并接近有监督的最优解。


<details>
  <summary>Details</summary>
Motivation: 后训练虽然可以改进大型语言模型（LLMs），但通常会导致信心校准变差，产生系统性过度自信的问题。现有针对后训练模型（PoLMs）的事后无监督方法试图通过将PoLM的信心与预训练模型的信心进行对齐来缓解这一问题。然而，这些方法忽略了后训练引入的推理时间动态特性。

Method: 提出了Dual-Align框架，它不仅执行信心对齐以纠正信心漂移，还引入了过程对齐来解决过程中间推理路径发散的问题。Dual-Align定位到轨迹开始分化的层，并重新调整后续推理过程的稳定性。整个策略学习单一温度参数，在不牺牲后训练性能增益的前提下修正两种漂移类型。

Result: 实验结果显示，与基线相比，Dual-Align能够一致地减少校准误差，并且其表现接近于有监督的理想情况。

Conclusion: Dual-Align提供了一个有效的解决方案，用于改善后训练大型语言模型中的信心校准问题，同时保持了性能优势。

Abstract: Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.

</details>


### [28] [Generation of synthetic delay time series for air transport applications](https://arxiv.org/abs/2601.04279)
*Pau Esteve,Massimiliano Zanin*

Main category: cs.LG

TL;DR: 本文探讨了使用三种不同模型生成机场延误时间序列的合成数据，发现基于简化遗传算法的方法能够产生与真实数据几乎无法区分的时间序列，并且保持了高度的变异性。生成的数据在检测机场间延误传播的问题上得到了验证，并被提供给科学界使用。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺和隐私问题，特别是在航空运输领域中生成逼真的机场延误时间序列数据。

Method: 比较了两种基于最先进深度学习算法的模型与一种简化的遗传算法方法来生成机场延误时间序列的合成数据。

Result: 简化遗传算法生成的时间序列与真实数据非常相似，同时保持了高变异性；这些生成的数据也被用于验证延迟传播检测的有效性。

Conclusion: 简化遗传算法为生成逼真的机场延误合成数据提供了有效手段，这对促进相关研究具有重要意义。

Abstract: The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.

</details>


### [29] [LEGATO: Good Identity Unlearning Is Continuous](https://arxiv.org/abs/2601.04282)
*Qiang Chen,Chun-Wun Cheng,Xiu Su,Hongyan Xu,Xi Lin,Shan You,Angelica I. Aviles-Rivero,Yi Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为LEGATO的方法，通过轨迹一致的神经常微分方程来实现生成模型中身份信息的连续且可控遗忘过程。该方法解决了现有机器遗忘技术中的低效、可控性差以及灾难性崩溃等问题，实现了在不大幅降低模型性能的情况下移除敏感数据的目标。


<details>
  <summary>Details</summary>
Motivation: 当前的机器遗忘方法在处理生成模型中的身份信息删除时存在效率低下、控制力有限和解释性不足的问题，而且随着遗忘过程的推进，模型保持能力可能会出现急剧下降的情况。为了解决这些问题，研究者认为应该将身份遗忘建模为一个连续的过程，并提出了新的解决方案。

Method: 提出的方法名为LEGATO，它利用了轻量级的神经ODE适配器来增强预训练生成器，使得可以在冻结原始模型权重的前提下平滑地进行可调控的遗忘操作。通过调整ODE步长大小可以精确调节遗忘强度，并且引入了轨迹一致性约束以防止在解除学习过程中发生灾难性的性能下降。

Result: 实验结果表明，在领域内外的身份解除学习基准测试中，LEGATO达到了最先进的遗忘表现，不仅避免了灾难性崩溃还减少了需要微调的参数数量。

Conclusion: 综上所述，LEGATO提供了一种有效解决生成模型中身份信息去除问题的新途径，能够在保证模型原有功能不受严重影响的同时实现对特定信息的安全移除。

Abstract: Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.

</details>


### [30] [Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity](https://arxiv.org/abs/2601.04283)
*Nikolay Yudin*

Main category: cs.LG

TL;DR: 本研究关注字符级Transformer在计算文本中的模加运算时对输入格式变化的鲁棒性，而不仅仅是分布内准确度。研究发现即使模型达到了高分布内准确度，在面对位置偏移或超出分布的自然语言模板时仍可能失败。为此提出了一种结合明确表达边界标记、位置课程、多样模板混合及一致性训练的新训练方法，显著提高了模型对于位置偏移和模板分布外情况下的鲁棒性，同时保持了较高的分布内准确度。


<details>
  <summary>Details</summary>
Motivation: 研究者注意到先前被忽视的一种失效模式：即尽管模型能在给定数据分布下达到很高的准确率，但当相同的表达式移动到不同的绝对字符位置（位置偏移）或者以不同寻常的自然语言形式呈现时，模型可能会严重失败。这种观察促使研究团队探索如何增强模型在面对输入格式变化时的表现力。

Method: 1. 使用了显式的表达边界标记来帮助模型识别有效信息。
2. 通过位置课程逐渐扩大训练过程中遇到的绝对位置范围。
3. 引入多种不同的模板混合策略增加多样性。
4. 对每个示例的不同变体实施一致性训练，以促进模型学习不变性特征。

Result: 经过上述干预措施后，模型不仅维持了高水平的分布内准确性，而且在处理位置偏移和超出分布的模板时展现出了显著提升的鲁棒性。此外，研究还表明，采用ALiBi风格的方法在这种设置下无法成功完成任务。

Conclusion: 结果表明，通过对监督信号中原本缺失的不变性进行显式训练，可以有效地指导程序化泛化过程。研究提供了一个可重复使用的评估协议及其实验材料，为未来相关工作奠定了基础。

Abstract: Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions ("position shift") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.

</details>


### [31] [ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues](https://arxiv.org/abs/2601.04297)
*Behrad Binaei-Haghighi,Nafiseh Sadat Sajadi,Mehrad Liviyan,Reyhane Akhavan Kharazi,Fatemeh Amirkhani,Behnam Bahrak*

Main category: cs.LG

TL;DR: 本文提出了一种名为ArtCognition的新框架，通过融合数字绘画中的静态视觉特征和动态行为运动线索来自动分析广泛使用的心理测试——屋树人(HTP)测试。该研究使用检索增强生成(RAG)架构将低级特征与高级心理解释联系起来，提高了可解释性并减少了模型幻觉的可能性。结果显示，结合视觉和行为运动线索可以比单独使用任何一种模态提供更细致的评估，并且所提取的多模态特征与标准化心理指标之间存在显著相关性，这表明该框架作为支持临床医生的可扩展工具有潜力。


<details>
  <summary>Details</summary>
Motivation: 对人类情感和心理状态进行客观评估是一个重大挑战，尤其是在非语言渠道上。本文旨在探索数字绘画作为一种丰富但未充分开发的情感感知模式，并为此提出了一种新的多模态框架，以期为心理健康护理提供技术支持。

Method: 本文介绍了ArtCognition框架，它整合了从最终艺术作品中捕捉到的静态视觉特征（由计算机视觉模型实现）以及直接从绘图过程中获取的动态行为运动线索（如笔画速度、停顿和流畅度）。为了连接低级别特征与高级别心理解读，采用了检索增强生成（RAG）架构，以便基于已建立的心理学知识基础来进行分析。

Result: 研究表明，视觉与行为运动线索相结合的方式能够提供比单独任一模态更加细致入微的评估结果。此外，还发现提取出的多模态特征与标准心理学量表之间存在着显著的相关性，证明了该框架作为辅助临床工作者工具的可能性。

Conclusion: 本研究贡献了一种用于非侵入式情感状态评估的新方法论，并为技术辅助下的心理健康护理开辟了新途径。

Abstract: The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.

</details>


### [32] [Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles](https://arxiv.org/abs/2601.04286)
*Niklas Kueper,Kartik Chari,Elsa Andrea Kirchner*

Main category: cs.LG

TL;DR: 研究通过结合分类器集成和滑动窗口后处理技术，提高了从EEG信号中异步检测运动意图的鲁棒性。在线评估中，分类器集成比单个最佳模型表现更好，并且减少了错误检测。


<details>
  <summary>Details</summary>
Motivation: 为了改善中风患者康复治疗的效果，研究旨在通过识别患者的运动意图来触发机器人辅助装置的帮助。该研究特别关注于如何更准确地解码人类表面脑电图（EEG）信号中的运动意图，尤其是在在线和异步条件下进行分类时面临的挑战。

Method: 研究者分析了包含14名健康受试者的两个EEG数据集，这些受试者执行了自发起的手臂运动。采用了支持向量机(SVM)、多层感知器(MLP)以及EEGNet分类模型的集成组合，并进行了离线与伪在线评估以比较不同方法的表现。此外，还探讨了滑动窗口后处理技术对分类性能的影响。

Result: 伪在线评估结果显示，在最优数量的后处理窗口下，两种模型集成方案显著优于单一最佳模型。对于单个模型来说，增加后处理窗口的数量能够显著提高分类性能。但在线下评估中，最佳单一模型与分类器集成之间没有观察到显著差异。

Conclusion: 研究表明，分类器集成加上适当的后处理方法可以有效提升从EEG信号中异步检测运动意图的能力。尤其值得注意的是，在线分类方面，分类器集成比线下分类表现出更大的改进，并且有助于减少提前误报的情况。

Abstract: Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.

</details>


### [33] [Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control](https://arxiv.org/abs/2601.04287)
*Ben Carvell,George De Ath,Eseoghene Benjamin,Richard Everson*

Main category: cs.LG

TL;DR: 本文介绍了一种名为在线动作堆叠的方法，它是一种强化学习策略的推理时间封装器，能够在训练时使用较小的离散动作空间产生现实的空中交通管制指令。通过近端策略优化和BluebirdDT数字孪生平台，训练智能体执行航线导航、爬升与下降管理以及两机防撞等任务。实验表明，在侧向导航实验中，该方法显著减少了发出的指令数量，并且尽管只使用了五个动作，但其性能可与使用37维动作空间训练的策略相媲美。


<details>
  <summary>Details</summary>
Motivation: 为了在保持操作实际性的同时简化空中交通管制（ATC）中的强化学习问题，作者提出了一种称为在线动作堆叠的技术，允许在较小的离散动作空间上进行训练，同时生成符合领域需求的复合许可命令。

Method: 采用近端策略优化算法结合BluebirdDT数字孪生平台，训练智能体完成沿着预定路线导航飞机、管理至目标飞行高度层的爬升与下降过程以及满足最小间隔约束下的双机避碰任务。训练过程中利用简单的增量航向或高度调整加上一个动作阻尼惩罚来减少指令频率。

Result: 在侧向导航实验中，相较于基础版本，在线动作堆叠大幅降低了所需发出的指令数量，并且即使只有五个基本动作选项也能达到接近于使用37个维度动作空间训练出模型的效果。

Conclusion: 在线动作堆叠有助于填补标准强化学习形式与实际ATC需求之间的重要空白，为扩展到更复杂的控制场景提供了一个简单机制。

Abstract: We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.

</details>


### [34] [Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes](https://arxiv.org/abs/2601.04299)
*Pir Bakhsh Khokhar,Carmine Gravino,Fabio Palomba,Sule Yildrim Yayilgan,Sarang Shaikh*

Main category: cs.LG

TL;DR: 本研究提出了一种可解释的深度学习框架，该框架结合了连续血糖监测数据和实验室检测结果，以识别1型糖尿病患者的代谢表型。通过这种方法，研究者们发现了五种潜在的代谢表型，并且这些表型与高血压、心肌梗死和心力衰竭有统计学上显著但适度的关联。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病是一种代谢高度异质性的疾病，传统的生物标志物如糖化血红蛋白（HbA1c）不足以充分描述其特征。因此，需要一种新的方法来更好地理解个体间的代谢差异。

Method: 采用深度学习框架整合连续血糖监测（CGM）数据和实验室检查资料，使用Transformer编码器建模跨模态的时间依赖性，通过高斯混合模型识别潜在的代谢表型。利用Transformer注意力可视化和基于SHAP的方法实现模型解释性。

Result: 在577名1型糖尿病患者中确定了五个从代谢稳定到心血管代谢风险升高的潜在代谢表型。这些表型具有不同的生化特征，包括血糖控制、脂质代谢、肾功能指标及促甲状腺激素水平等方面的不同。注意力分析表明葡萄糖变异性是主要的时间因素；而SHAP分析则指出HbA1c、甘油三酯、胆固醇、肌酐以及TSH是对表型区分的重要贡献者。表型成员资格显示出与高血压、心肌梗塞和心力衰竭之间存在统计学意义但程度轻微的联系。

Conclusion: 这项研究表明，可解释的多模态时间嵌入框架能够揭示1型糖尿病中生理一致的代谢亚群，并支持超出单一生物标记的风险分层。

Abstract: Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.

</details>


### [35] [Causally-Aware Information Bottleneck for Domain Adaptation](https://arxiv.org/abs/2601.04361)
*Mohammad Ali Javidian*

Main category: cs.LG

TL;DR: 本文提出了一种在因果系统中处理域适应问题的新方法，通过学习紧凑且机制稳定的表示来预测目标变量。对于线性高斯因果模型提供了闭式解，并为非线性或非高斯数据引入了变分信息瓶颈编码器-预测器方法，在合成和真实数据集上均显示出准确的预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在因果系统中的一个常见域适应问题，即目标变量在源域中有观察值但在目标域中完全缺失的情况下，如何从剩余观察变量中预测目标变量。

Method: 提出了一种基于学习紧凑且机制稳定表示的方法来实现这一目标；针对线性高斯因果模型给出了闭式Gaussian Information Bottleneck (GIB) 解决方案；对于非线性和/或非高斯情况，则提出了Variational Information Bottleneck (VIB) 编码器-预测器方法。

Result: 所提方法在多种合成与实际数据集上均能获得准确的目标变量预测结果，证明了其有效性及实用性。

Conclusion: 该研究开发了一个统一轻量级工具包用于因果域适应任务，能够在保持重要信息的同时去除无关变化，支持高维因果模型的实际应用。

Abstract: We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.

</details>


### [36] [Machine Learning Model for Sparse PCM Completion](https://arxiv.org/abs/2601.04366)
*Selcuk Koyuncu,Ronak Nouri,Stephen Providence*

Main category: cs.LG

TL;DR: 本文提出了一种用于稀疏成对比较矩阵(PCM)的机器学习模型，结合了经典的PCM方法和基于图的学习技术，并通过数值结果证明了该方法的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了提高稀疏成对比较矩阵处理上的效率与准确性，同时利用经典PCM方法和现代基于图的学习技术的优势。

Method: 开发一种新的机器学习模型，该模型整合了传统的PCM技术和基于图的学习方法。

Result: 实验结果显示，所提方法在有效性及可扩展性方面表现出色。

Conclusion: 提出的机器学习模型为稀疏PCM提供了一个有效且可扩展的解决方案。

Abstract: In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.

</details>


### [37] [Enhanced-FQL($λ$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay](https://arxiv.org/abs/2601.04392)
*Mohsen Jalaeian-Farimani*

Main category: cs.LG

TL;DR: 本文提出了一种模糊强化学习框架Enhanced-FQL(λ)，通过结合新颖的模糊资格迹(FET)和分段经验回放(SER)机制，提高了连续控制任务中的样本效率并降低了方差。该方法在保持较低计算复杂度的同时提供了理论收敛性保证，并且由于其固有的可解释性，在安全关键应用中特别有用。


<details>
  <summary>Details</summary>
Motivation: 为了提高模糊Q学习在连续控制任务中的性能，同时保持较低的计算复杂度和提供更好的可解释性。

Method: 提出了一种新的模糊强化学习框架Enhanced-FQL(λ)，它将模糊资格迹（FET）与分段经验回放（SER）整合进基于模糊贝尔曼方程（FBE）的模糊Q学习中。

Result: 广泛评估表明，相较于n步模糊TD和模糊SARSA(λ)基线算法，Enhanced-FQL(λ)在连续控制领域实现了更高的样本效率和更低的方差，同时相比深度强化学习方法如DDPG拥有显著更低的计算复杂度。

Conclusion: Enhanced-FQL(λ)不仅在样本效率和降低方差方面表现出色，而且因其内在的可解释性和理论上的收敛性证明，非常适合应用于那些需要透明度和受限资源的安全关键场景。

Abstract: This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($λ$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($λ$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($λ$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.

</details>


### [38] [Rate or Fate? RLV$^\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards](https://arxiv.org/abs/2601.04411)
*Ali Rad,Khashayar Filom,Darioush Keivan,Peyman Mohajerin Esfahani,Ehsan Kamalinejad*

Main category: cs.LG

TL;DR: 该论文探讨了在奖励验证存在噪声的情况下，强化学习模型的学习效果。通过建立一个多臂赌博机的分析框架来研究RLVR动力学，发现噪声主要影响收敛时间（速率而非结果）。当Youden指数J>0时，系统趋向于学习；J=0时，过程是中性的；J<0时，则会出现反学习现象。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决实际应用中奖励验证不纯净的问题，即单位测试、人工和合成标签以及大型语言模型评估都存在缺陷，尤其是在编码等复杂领域。研究者希望了解这种验证噪声是否仅减慢学习速度，还是能够改变最终学习结果。

Method: 采用多臂赌博机视角对RLVR动态进行建模，并用GRPO方法实例化，通过控制实验验证其有效性。通过模拟假阳性和假阴性情况，并将完成情况分为重复出现的推理模式，从而得到一个概率单纯形上的复制式流动。

Result: 研究表明，在J>0的学习状态下，噪声主要作用于调整收敛时间而不是改变学习结局。实验还表明，在合成噪声下可验证编程任务的结果符合预期的J=0边界条件。此外，该框架为分析RLVR稳定性、收敛性和算法干预提供了一种通用方法。

Conclusion: 对于带有验证噪声的强化学习而言，关键指标Youden指数J决定了学习或反学习的发生。当J大于零时，尽管存在噪声，但模型仍能有效学习；反之则可能导致错误模式放大直至主导。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?
  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time ("rate, not fate"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.

</details>


### [39] [Distribution-Guided and Constrained Quantum Machine Unlearning](https://arxiv.org/abs/2601.04413)
*Nausherwan Malik,Zubair Khalid,Muhammad Faryad*

Main category: cs.LG

TL;DR: 提出了一种基于分布引导的量子机器遗忘框架，通过约束优化问题处理类别级别的数据遗忘，同时保持模型在保留数据上的预测行为。实验结果表明该方法能够有效抑制被遗忘类别的置信度，最小化保留类别性能的下降，并且与重新训练的模型基准更加一致。


<details>
  <summary>Details</summary>
Motivation: 现有的量子机器学习中的遗忘方法大多依赖于固定的、均匀的目标分布，且未能明确控制遗忘和保留模型行为之间的权衡。

Method: 提出的方法引入了一个可调节的目标分布，该分布来自于模型相似性统计，将被遗忘类别的置信度压制与对保留类别之间再分配的假设解耦开来。此外，还加入了一个基于锚点的保存约束条件，以显式地维持选定保留数据上的预测行为。

Result: 通过Iris和Covertype数据集上训练的变分量子分类器对该方法进行了评估。结果显示，对于被遗忘类别的置信度有明显的抑制作用，保留类别的表现几乎没有退化，并且比使用统一目标分布的遗忘方法更接近于黄金重训练模型基线。

Conclusion: 这些发现强调了目标设计以及基于约束条件公式的重要性，这对于实现可靠且可解释的量子机器遗忘至关重要。

Abstract: Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.

</details>


### [40] [When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning](https://arxiv.org/abs/2601.04447)
*Gal Fybish,Teo Susnjak*

Main category: cs.LG

TL;DR: 本文对表现性预测的相关文献进行了全面综述，提出了一个'表现力强度与影响矩阵'评估框架，帮助从业者评估其部署的预测模型的表现力潜在影响和严重性，并选择适当的算法或人为干预水平。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在高风险领域的使用增加，它们的预测可能会主动塑造所处环境，这种现象被称为表现性预测。然而，目前缺乏一个系统化知识（SoK）来综合这一现象的概念并提供实际指导。

Method: 通过文献回顾，本文概述了表现性主要体现机制、相关风险类型以及文献中提出的解决方案，并提出了一种名为'表现力强度与影响矩阵'的评估框架。

Result: 构建了一个新的评估框架——'表现力强度与影响矩阵'，用以辅助从业者更好地理解和处理模型中的表现性问题。

Conclusion: 本文填补了现有研究中关于表现性预测系统化知识整理及实用指南方面的空白，为该领域提供了宝贵的见解。

Abstract: Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.

</details>


### [41] [Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries](https://arxiv.org/abs/2601.04449)
*Daniel Sierra-Botero,Ana Molina-Taborda,Leonardo Espinosa-Leal,Alexander Karpenko,Alejandro Hernandez,Olga Lopez-Acevedo*

Main category: cs.LG

TL;DR: 研究开发了一个预测模型，用于根据患者入院和医院管理数据预测长时间住院（pLoS），通过选择非相关且信息价值高的特征，并使用逻辑回归模型进行分类。在验证队列中，该模型表现出了良好的预测性能，为减少长时间住院提供了有价值的工具。


<details>
  <summary>Details</summary>
Motivation: 长时间住院与不良院内事件的风险增加有关。为了更好地管理和减少长时间住院的情况，研究人员希望通过开发一个能够预测长时间住院的模型来识别关键影响因素。

Method: 采用图论中的团代表方法选取特征权重作为特征选择手段，构建逻辑回归模型以区分住院时间是否超过7天。使用的数据集来自2017年1月至2022年3月期间哥伦比亚安蒂奥基亚大学附属医院的120,354次住院记录。

Result: 最终模型在验证队列上达到了0.83的特异性、0.64的敏感性、0.76的准确性、0.67的精确度以及0.82的AUC-ROC值。选定的九个变量提高了模型解释性。

Conclusion: 所提出的预测模型展现了优秀的预测能力，对于理解导致长时间住院的因素及未来干预研究的设计具有重要意义，可作为医院管理的有效工具。

Abstract: Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.

</details>


### [42] [Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning](https://arxiv.org/abs/2601.04458)
*Jiayi Zhang,Conrad Borchers,Clayton Cohn,Namrata Srivastava,Caitlin Snyder,Siyuan Guo,Ashwin T S,Naveeduddin Mohammed,Haley Noh,Gautam Biswas*

Main category: cs.LG

TL;DR: 本研究通过嵌入式方法和大型语言模型自动检测协作计算建模环境中的社会共享学习调节行为，结果显示纯文本嵌入在检测与执行或群体动态相关的SSRL行为方面表现更好，而上下文和多模态特征对规划和反思等结构提供了互补的好处。


<details>
  <summary>Details</summary>
Motivation: 学习分析领域在自动化检测多模态数据中复杂的个人学习过程方面取得了显著进展，但较少关注协作开放式问题解决，该研究旨在扩展预测模型以自动检测协作计算建模环境中的社会共享调节学习（SSRL）行为。

Method: 研究使用基于嵌入的方法，并利用大型语言模型作为摘要工具生成与系统日志对齐的学生对话的任务感知表示。这些摘要结合了仅文本的嵌入、上下文丰富的嵌入以及从日志导出的功能来训练预测模型。

Result: 结果表明，对于与执行或群体动态有关的SSRL行为，例如离题行为或请求帮助，仅文本嵌入通常能够实现更强的性能。相反，情境化和多模态特征为诸如计划和反思之类的构建提供了补充性益处。

Conclusion: 研究发现强调了基于嵌入模型在通过可扩展地检测SSRL行为来扩展学习分析方面的潜力，最终支持教师所重视的协作学习环境中的实时反馈和自适应支架。

Abstract: The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.

</details>


### [43] [When Models Manipulate Manifolds: The Geometry of a Counting Task](https://arxiv.org/abs/2601.04480)
*Wes Gurnee,Emmanuel Ameisen,Isaac Kauvar,Julius Tarng,Adam Pearce,Chris Olah,Joshua Batson*

Main category: cs.LG

TL;DR: 本研究通过机制性地探讨Claude 3.5 Haiku如何完成固定宽度文本中的分行任务，揭示了语言模型在仅接收一系列标记的情况下仍能感知文本视觉属性的方式。研究发现字符计数以低维度弯曲流形表示，并由稀疏特征家族离散化处理，类似于生物定位细胞。准确的预测来自一系列几何变换：标记长度累积成字符计数流形，注意力头扭曲这些流形以估计到行边界的距离，并通过正交排列估计值来决定是否分行。研究结果通过因果干预得到验证，并发现了能够劫持计数机制的视觉错觉。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型只接收一串标记序列作为输入，但它们能够理解文本的某些视觉属性。本文旨在深入探究这一现象背后的机制，特别是Claude 3.5 Haiku是如何实现固定宽度文本内正确分行的过程。

Method: 研究采用了机制性分析的方法，首先识别出字符计数被表征于低维曲面上且由稀疏特征族进行离散化处理的特点；接着，通过观察模型内部对字符长度的累积、注意力机制如何扭曲上述曲面以估算与行边界间的距离，以及最终基于正交排列形成线性决策边界的分行决策过程，来阐明模型的工作原理。此外，还利用因果干预实验和构造特定字符序列引发视觉错觉的方法来验证提出的理论。

Result: 研究表明，早期层展现了丰富的感官处理能力，同时揭示了注意力算法的复杂性。更重要的是，它强调了结合基于特征和几何视角对于提高可解释性的重要性。通过构建特定字符序列成功制造了可以‘劫持’计数机制的视觉错觉，进一步证明了模型内部运作机制的有效性和独特性。

Conclusion: 这项工作不仅展示了语言模型中早期层次所具有的强大感觉处理能力及注意力算法的精妙之处，同时也指出了结合特征基础与几何观点对于增进我们对模型内部运作机制理解的关键作用。

Abstract: Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.

</details>


### [44] [Hybrid Federated Learning for Noise-Robust Training](https://arxiv.org/abs/2601.04483)
*Yongjun Kim,Hyeongjun Park,Hwanjin Kim,Junil Choi*

Main category: cs.LG

TL;DR: 提出了一种混合联邦学习（HFL）框架，通过让每个用户设备传输梯度或logits，并由基站选择每轮更新的权重来结合联邦学习(FL)和联邦蒸馏(FD)的优势。引入了两种方法来利用HFL中的自由度：自适应UE聚类以及基于阻尼牛顿法的自适应权重选择。实验结果表明，在低信噪比条件下，当同时利用这两种自由度时，HFL可以实现更好的测试准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL)和联邦蒸馏(FD)作为分布式学习范式，在增强隐私的同时训练用户设备模型，但它们各自在噪声鲁棒性和学习速度之间存在权衡。为了克服各自的弱点，提出了一个结合两者优点的解决方案。

Method: 设计了一个混合联邦学习(HFL)框架，其中每个用户设备可以选择发送梯度或logits给基站，而基站则负责决定每轮迭代中FL与FD更新的权重。此外，还开发了两种方法来充分利用HFL框架内的自由度：一是使用Jenks优化进行自适应UE聚类；二是采用阻尼牛顿法实现自适应权重选择。

Result: 数值结果表明，在低信噪比环境下，当同时应用上述两种自由度利用策略时，HFL能够达到更高的测试准确率。

Conclusion: 本研究提出的HFL框架有效结合了FL和FD的优点，通过灵活调整UE的数据贡献方式及BS端的更新策略选择，实现了在具有挑战性的通信条件下提高模型性能的目的。

Abstract: Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.

</details>


### [45] [IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation](https://arxiv.org/abs/2601.04498)
*Yinghao Tang,Xueding Liu,Boyuan Zhang,Tingfeng Lan,Yupeng Xie,Jiale Lao,Yiyao Wang,Haoxuan Li,Tingting Gao,Bo Pan,Luoxuan Weng,Xiuqi Huang,Minfeng Zhu,Yingchaojie Feng,Yuyu Luo,Wei Chen*

Main category: cs.LG

TL;DR: 本文提出了IGENBENCH，这是第一个用于评估文本转信息图生成可靠性的基准测试，包含600个经过精心挑选的测试案例，覆盖了30种信息图类型。通过一个自动化的评估框架和多模态大语言模型来验证每个问题，并对10种最先进的T2I模型进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的文本到图像（T2I）模型能够生成美观的图像，但它们在生成信息图方面的可靠性仍不清楚。生成的信息图可能乍一看是正确的，但存在容易被忽视的问题，如数据编码失真或文本内容错误。因此需要一个可靠的评估基准来衡量这些模型的表现。

Method: 设计了一个将可靠性验证分解为基于10种问题类型分类的原子性是非问题的自动化评估框架，并使用多模态大型语言模型(MLLMs)来验证每个问题，从而得出问题级准确性(Q-ACC)和信息图级准确性(I-ACC)。

Result: 系统分析揭示了未来模型开发的关键见解：(i) 三层次性能等级中顶级模型达到Q-ACC 0.90但I-ACC仅为0.49；(ii) 数据相关维度成为普遍瓶颈（例如，数据完整性：0.21）；以及(iii) 所有模型端到端正确性的挑战。

Conclusion: IGENBENCH提供了一个新的基准，用来评估当前及未来T2I模型在生成信息图时的可靠性，发现了现有模型的一些局限性，并指出了改进的方向。

Abstract: Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.

</details>


### [46] [Surface-based Molecular Design with Multi-modal Flow Matching](https://arxiv.org/abs/2601.04506)
*Fang Wu,Zhengyuan Zhou,Shuting Jin,Xiangxiang Zeng,Jure Leskovec,Jinbo Xu*

Main category: cs.LG

TL;DR: 提出了一种名为SurfFlow的新方法，该方法通过考虑分子表面特性来生成和设计肽，从而提高了肽的结合准确性。在PepMerge基准测试中，SurfFlow的表现优于全原子基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管治疗性肽在靶向以前难以成药的结合位点方面显示出潜力，并且深度生成模型的进步使得能够为特定蛋白质受体进行全面的原子肽共设计，但分子表面在蛋白质-蛋白质相互作用中的关键作用尚未得到充分探索。

Method: 研究者们提出了一个名为SurfFlow的全方位肽生成范例，这是一种新颖的基于表面的生成算法，能够全面地共同设计肽的序列、结构和表面。SurfFlow采用多模态条件流匹配（CFM）架构学习表面几何形状和生化特性的分布，以提高肽结合的准确性。

Result: 在综合性的PepMerge基准测试中，SurfFlow在所有指标上都持续优于全原子基线模型。

Conclusion: 这些结果突出了在从头开始的肽发现过程中考虑分子表面的优势，并展示了整合多种蛋白质模式以实现更有效的治疗性肽发现的潜力。

Abstract: Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.

</details>


### [47] [Not All Steps are Informative: On the Linearity of LLMs' RLVR Training](https://arxiv.org/abs/2601.04537)
*Tianle Wang,Zhongyuan Wu,Shenghao Jin,Hao Xu,Wei Chen,Ning Miao*

Main category: cs.LG

TL;DR: 本文发现，在使用可验证奖励的强化学习（RLVR）过程中，大型语言模型（LLM）表现出强烈的线性演化特征。基于这一观察，研究者提出通过权重外推和Logits外推的方法来预测模型未来状态，从而在减少计算成本的同时达到甚至超越标准RL训练的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的RLVR方法虽然能够有效提升LLM的表现，但需要大量的训练步骤，导致高昂的计算成本。研究旨在探索是否可以通过利用训练过程中的线性特性，以更高效的方式获得相似或更好的性能。

Method: 通过对模型权重和输出log-probabilities与RL训练步骤之间关系的研究，发现了两者存在强线性相关性。基于此发现，研究者开发了两种技术：权重外推(Weight Extrapolation)和Logits外推(Logits Extrapolation)，用于从中间检查点预测未来的模型状态，无需继续执行耗时的训练过程。

Result: 实验表明，权重外推能够在大幅减少计算量的情况下产生与标准RL训练相当的结果；而Logits外推不仅实现了这一点，还在所有四个基准测试中表现优于持续进行的RL训练。

Conclusion: 本研究表明，通过利用RLVR过程中出现的线性性质，可以采用外推法作为替代方案来显著降低训练所需计算资源，同时保持甚至提高模型性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.

</details>


### [48] [Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs](https://arxiv.org/abs/2601.04555)
*Shogo Nakayama,Masahiro Okuda*

Main category: cs.LG

TL;DR: 本文提出了一种新的损失函数，该函数基于预测概率分布的熵来估计每个样本的置信度，并应用基于置信度的自适应加权。这种方法即使在低标签条件下也能提高分类准确率并实现更稳定的学习表现。


<details>
  <summary>Details</summary>
Motivation: 传统半监督对比学习方法仅给那些最高预测类别概率超过预定义阈值的样本分配伪标签，然后使用这些选定样本执行监督对比学习。这种做法限制了可用于训练的样本数量。

Method: 研究者们提出了一种新颖的损失函数，它根据预测概率分布的熵评估每个样本的置信度，并实行基于置信度的自适应权重调整。这一方法允许为之前被排除在外的样本也分配伪标签，并且能够以更加合理的方式考虑锚点和正样本的置信度来进行对比学习。

Result: 实验结果表明，所提出的方法提高了分类准确性，在低标签条件下也能达到更稳定的学习效果。

Conclusion: 通过引入基于置信度的自适应加权机制，新方法不仅扩大了可参与训练的样本范围，还增强了模型在有限标注数据下的性能稳定性与分类精度。

Abstract: Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.

</details>


### [49] [A Vision for Multisensory Intelligence: Sensing, Synergy, and Science](https://arxiv.org/abs/2601.04563)
*Paul Pu Liang*

Main category: cs.LG

TL;DR: 本文概述了未来十年多感官人工智能的研究愿景，通过感知、科学和协同三个相互关联的主题推进该领域的发展，旨在连接AI与人类的感官及丰富的生理和社会信号，改变人与AI之间的体验和互动方式。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能在文本、视觉和音频等数字模态方面取得了显著进展，但在模拟人类多感官体验（如触觉、味觉、嗅觉）方面仍存在不足。本文提出了一个多感官人工智能的研究愿景，旨在通过整合更多类型的信号来丰富AI与人类交互的方式。

Method: 论文提出了一个通过感知、科学和协同三个相互关联主题来推动多感官AI发展的框架。其中，“感知”研究关注如何让AI以更丰富的方式捕捉世界；“科学”部分致力于量化多模态异质性和交互作用、开发统一建模架构以及理解跨模态迁移；而“协同”则聚焦于学习不同模态之间以及人与AI之间的协同效应。

Result: 文章不仅提出了多感官AI的研究框架，还介绍了一系列来自MIT Media Lab多感官智能小组的最新项目、资源和演示，展示了当前领域的进步。

Conclusion: 多感官人工智能代表了未来十年内AI发展的一个重要方向，它将通过增强AI对物理世界和人类感官的理解能力，促进人机交互更加自然和谐。

Abstract: Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.

</details>


### [50] [Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation](https://arxiv.org/abs/2601.04572)
*Xiaowei Mao,Huihu Ding,Yan Lin,Tingrui Wu,Shengnan Guo,Dazhuo Qiu,Feiling Fang,Jilin Hu,Huaiyu Wan*

Main category: cs.LG

TL;DR: 本文提出了一种名为FENCE的方法，用于处理时空交通数据中的缺失值问题。该方法通过引入动态反馈机制来调整指导尺度，并根据节点的注意力分数分组计算指导尺度，从而提高了数据填补的准确性。


<details>
  <summary>Details</summary>
Motivation: 在智能交通系统中，填补时空交通数据中的缺失值至关重要。虽然基于分数的扩散模型已经展示了竞争力，但它们通常对时空维度采用统一的指导尺度，这在高缺失率的情况下表现不佳。稀疏观测提供的条件指导不足，导致生成过程偏离了条件观测，降低了填补性能。

Method: 提出了FENCE，一种时空反馈扩散指导方法，旨在自适应地控制填补过程中的指导尺度。首先，FENCE引入了一个动态反馈机制，根据后验似然估计调整指导尺度；当生成值与观测值差异大时增加指导尺度，反之则减少，以防止过度修正。其次，鉴于不同节点和去噪步骤间对观测值的一致性存在差异，FENCE依据注意力分数将节点分组，在集群级别上计算指导尺度，利用时空关联提供更准确的指导。

Result: 实验结果表明，在真实世界交通数据集上，FENCE显著提升了填补准确性。

Conclusion: 通过自适应调整指导尺度并考虑时空相关性，FENCE能够有效提高具有高缺失率的时空交通数据填补质量。

Abstract: Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.
  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.

</details>


### [51] [FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems](https://arxiv.org/abs/2601.04587)
*Quang-Tu Pham,Hoang-Dieu Vu,Dinh-Dat Pham,Hieu H. Pham*

Main category: cs.LG

TL;DR: FedKDX, a federated learning framework, uses Negative Knowledge Distillation (NKD) to improve AI in healthcare. It combines various knowledge transfer methods and achieves better accuracy, faster convergence, and enhanced performance on non-IID data. The solution is suitable for privacy-sensitive medical applications.


<details>
  <summary>Details</summary>
Motivation: The motivation behind FedKDX is to address the limitations of current healthcare AI, particularly by capturing both target and non-target information, thereby improving model generalization. Additionally, it aims to maintain privacy and reduce communication costs in distributed healthcare settings.

Method: FedKDX employs a combination of traditional knowledge distillation, contrastive learning, and Negative Knowledge Distillation (NKD) within a unified architecture. This approach not only enhances the model's ability to generalize but also addresses the statistical heterogeneity found in distributed healthcare data, all while preserving privacy and minimizing communication overheads.

Result: Experiments conducted on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2) show that FedKDX can achieve up to 2.53% higher accuracy compared to state-of-the-art methods, alongside demonstrating faster convergence and superior performance on non-IID data distributions. Theoretical analysis further supports the effectiveness of NKD in tackling statistical heterogeneity.

Conclusion: FedKDX represents a promising advancement in federated learning for healthcare, offering improved accuracy, better handling of non-IID data, and compliance with strict privacy regulations such as HIPAA and GDPR. This makes it a balanced solution for performance and practical implementation in decentralized healthcare environments.

Abstract: This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.

</details>


### [52] [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)
*Akiyoshi Tomihari*

Main category: cs.LG

TL;DR: 本文探讨了强化学习后训练阶段对语言模型的影响，特别是输出多样性减少的现象。通过采用神经切线核(NTK)框架来分析学习动态，发现特征表示的变化有限会导致模型信心的系统性增加，从而解释了输出多样性减少的原因。基于这些发现，提出了一种新的两阶段训练策略——分类器优先强化学习(CF-RL)，该方法在标准RL优化之前优先更新分类器。实验结果支持了理论分析，并展示了CF-RL相较于传统方法的优势。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解强化学习（RL）后训练阶段如何影响现代语言模型的发展，特别是对于提高一致性与推理能力的作用，以及为什么会出现输出多样性减少的现象。

Method: 采用了经验神经切线核(NTK)框架来研究RL后训练的学习动态，并将NTK分解为两个部分以描述RL更新是如何跨训练样本传播的。基于此分析，提出了分类器优先强化学习(CF-RL)这一新颖的两阶段训练策略。

Result: 研究表明，特征表示变化有限是导致RL后训练过程中模型信心增加的主要原因，进而减少了输出多样性。而CF-RL能够有效地加快优化过程并提高模型的信心水平。此外，还发现CF-RL的工作机制不同于监督学习中的先线性探测再微调的方法。

Conclusion: 本研究形式化地阐述了RL后训练的学习动态，并为未来进一步的研究和改进提供了动机。提出的CF-RL策略被证实是一种有效的手段，可以促进模型更快地收敛并保持或提高其性能。

Abstract: Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.

</details>


### [53] [Estimating Causal Effects in Gaussian Linear SCMs with Finite Data](https://arxiv.org/abs/2601.04673)
*Aurghya Maiti,Prateek Jain*

Main category: cs.LG

TL;DR: 本文提出了一种简化的高斯线性结构因果模型（CGL-SCM），通过引入标准化分布的外生变量来解决参数估计问题。基于此模型，作者开发了一种新的基于EM算法的估计方法，可以从有限的观察样本中学习CGL-SCM参数并估计可识别的因果效应。实验结果表明所学模型能够准确恢复因果分布。


<details>
  <summary>Details</summary>
Motivation: 在存在潜在混淆因素的情况下，从观察数据中估计因果效应是因果推理中的一个基本挑战。虽然高斯线性结构因果模型(GL-SCMs)由于其分析上的可处理性而被广泛使用，但参数估计通常因过参数化而变得不可行。为了解决这个问题，并提高从有限数据中估计因果效应的能力，提出了本研究。

Method: 本文介绍了一类名为集中式高斯线性结构因果模型(CGL-SCMs)的新子类，该子类简化了模型并通过假设外生变量遵循标准化分布来保持表达力。此外，还提出了一种新颖的基于EM算法的估计算法，用于从有限观测样本中学习CGL-SCM参数以及估计可识别的因果效应。

Result: 理论分析得到了合成数据和基准因果图上实验的支持，证明了学习到的模型能够精确地再现因果分布。这表明新提出的CGL-SCMs框架及其相关算法在处理实际场景下由有限数据带来的挑战时具有有效性。

Conclusion: 通过引入CGL-SCMs及相应的参数估计方法，本文为从有限观察数据中估计因果效应提供了一个有效解决方案。这一贡献不仅增强了我们对复杂系统中因果关系的理解能力，也为未来研究如何更好地利用有限数据进行准确因果推断奠定了基础。

Abstract: Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.

</details>


### [54] [Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead](https://arxiv.org/abs/2601.04686)
*Oluwatosin Oseni,Shengjie Wang,Jun Zhu,Micah Corah*

Main category: cs.LG

TL;DR: Nightmare Dreamer, a model-based Safe RL algorithm, uses a learned world model to predict and prevent safety violations, achieving high efficiency and nearly zero safety issues on Safety Gymnasium tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitation of Reinforcement Learning (RL) in real-world applications, particularly the lack of sufficient safety guarantees, which hinders its broader adoption especially in critical areas like robotics control.

Method: Nightmare Dreamer employs a model-based approach by learning a world model capable of predicting potential safety violations. It then plans actions that avoid these predicted risks while still aiming to maximize rewards.

Result: On Safety Gymnasium tasks, Nightmare Dreamer demonstrates nearly zero safety violations and shows a significant 20x improvement in efficiency over model-free baselines when using only image observations.

Conclusion: This paper concludes that Nightmare Dreamer effectively addresses safety concerns in RL, making it a promising solution for increasing the applicability of RL in domains requiring high levels of safety, such as robotics control.

Abstract: Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.

</details>


### [55] [Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?](https://arxiv.org/abs/2601.04690)
*Mir Rayat Imtiaz Hossain,Leo Feng,Leonid Sigal,Mohamed Osama Ahmed*

Main category: cs.LG

TL;DR: 本研究提出了一种将从协同过滤中学习到的用户和项目嵌入通过轻量级投影模块映射到大语言模型（LLM）令牌空间的方法，使LLM能够基于这些投影嵌入与文本令牌一起生成推荐。初步结果表明，这种方法能有效利用结构化的用户-项目交互数据，相较于仅使用文本的LLM基线提高了推荐性能，并为传统推荐系统与现代LLM之间的结合提供了一个实用路径。


<details>
  <summary>Details</summary>
Motivation: 当前许多方法在构建基于大型语言模型（LLM）的推荐系统时，往往只依赖于文本语义或以有限的方式（如仅使用用户或项目嵌入）整合协作信号，这导致它们难以处理代表用户历史的多个项目嵌入，同时忽略了更丰富的协作信息。

Method: 提出了一种简单而有效的解决方案，即通过独立的轻量级投影模块将从协同过滤中学到的用户和项目嵌入映射到LLM令牌空间；然后，一个微调后的LLM会根据这些映射后的嵌入以及文本令牌来生成推荐。

Result: 初步结果显示，所提设计能够有效地利用结构化的用户-项目交互数据，并且相对于仅依赖文本的LLM基线，在推荐性能上有所提升。

Conclusion: 这项工作展示了一种结合传统推荐系统与现代LLM的有效方式，通过引入用户和项目嵌入至LLM中，不仅改善了推荐质量还开辟了两领域融合的新途径。

Abstract: Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.

</details>


### [56] [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)
*Maanas Taneja,Purab Shingvi*

Main category: cs.LG

TL;DR: 本文提出并评估了GPU加速的INT8量化方法，用于压缩大型语言模型中的键值缓存，实现了4倍的内存减少且对准确率影响极小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理过程中遇到的一个主要问题是键值缓存造成的显著内存瓶颈，这个问题随着序列长度线性增长，并且经常超过模型权重本身的内存占用。

Method: 研究者们实施并测试了针对KV缓存压缩的GPU加速INT8量化方案，开发了四种CUDA内核变体——朴素型、分块型、粗糙型和向量化型——并在达到10亿元素的实际工作负载规模上进行了基准测试。

Result: 向量化的内核与CPU基线相比最高可达到1,694倍的速度提升，同时保持重构误差低于0.004以及注意力分数误差低于0.1，即使是在8K维头的情况下也是如此。

Conclusion: INT8量化为减少LLM推理时的内存压力提供了一个实用的方法，具有可忽略不计的计算开销（6-58毫秒）并对下游模型行为的影响微乎其微。

Abstract: The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior

</details>


### [57] [Excess Description Length of Learning Generalizable Predictors](https://arxiv.org/abs/2601.04728)
*Elizabeth Donoway,Hailey Joren,Fabien Roger,Jan Leike*

Main category: cs.LG

TL;DR: 本文提出了一种形式化的信息论框架，用于量化微调从训练数据集中提取并写入模型参数的预测结构量。通过定义一个核心数量——超额描述长度（EDL），来衡量使用在线训练模型顺序编码训练标签所需比特数与最终训练模型下剩余编码成本之间的差距。研究结果表明，EDL在期望上是非负的，在无限数据限制下收敛到剩余描述长度，并提供了预期泛化增益的界限。通过一系列玩具模型实验，文章澄清了关于学习中信息的一些常见误解。


<details>
  <summary>Details</summary>
Motivation: 理解微调是激发语言模型的潜在能力还是教授新的能力是一个基本问题。为了评估和保证语言模型的安全性，有必要开发一种方法来量化微调过程中从训练数据集提取以及写入模型参数中的预测结构量。

Method: 作者们开发了一个正式的信息理论框架，引入了“超额描述长度”(Excess Description Length, EDL)作为中心度量指标。EDL通过预序编码定义，用以测量利用逐步训练模型对训练标签进行序列编码所需的位数与最终训练完成后的模型下剩余编码成本间的差异。

Result: 研究表明，EDL在数学期望上非负；当数据量趋向无穷大时，它会趋近于所谓的‘剩余描述长度’；同时，它也能够提供关于预期泛化收益的边界估计。此外，通过几个简化版模型案例，论文进一步阐明了一些关于机器学习中信息处理方面常见的误解。

Conclusion: 所提出的框架为观察到的能力激发与教学表现出定性不同的扩展特征提供了严格的理论基础。

Abstract: Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.

</details>


### [58] [Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams](https://arxiv.org/abs/2601.04741)
*Kota Nakamura,Koki Kawabata,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 本文提出了一种名为TimeCast的动态预测框架，能够适应多传感器数据流中的模式变化，并提供准确的实时未来事件时间预测。该方法具有动态性、实用性和可扩展性，在真实数据集上的实验表明其比现有方法有更高的预测精度和更低的计算时间。


<details>
  <summary>Details</summary>
Motivation: 针对从机器获取的实时传感器数据流，如何持续预测机器故障的发生时间这一问题，研究旨在通过分析多传感器数据流来连续预测未来事件的时间。

Method: 提出了TimeCast，一种为适应数据流中随时间变化的模式而设计的动态预测框架。该方法能够识别不同的时间演变模式（即阶段），并为每个阶段学习独立的模型，从而基于模式的变化做出自适应预测。

Result: 在真实数据集上进行的大量实验表明，TimeCat提供了比最先进方法更高的预测准确性，同时能够在数据流中发现动态变化，并显著减少计算时间。

Conclusion: TimeCast作为一种处理动态性质数据流的有效方案，不仅提高了预测性能，还通过在线更新模型实现了良好的可扩展性。

Abstract: Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.

</details>


### [59] [Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models](https://arxiv.org/abs/2601.04751)
*Luca Lanzilao,Angela Meyer*

Main category: cs.LG

TL;DR: 本研究提出了一种新的时空光伏（PV）功率预测框架，并利用该框架评估了七种日内PV功率临近预报模型的可靠性、准确性和总体性能。这些模型包括基于卫星的深度学习和光流方法以及基于物理的数值天气预报模型，涵盖了确定性和概率性两种形式。研究发现，基于卫星的方法在短期预测中表现优于综合预报系统(IFS-ENS)，特别是在短时间提前期内。SolarSTEPS和SHADECast提供了最准确的SSI和PV功率预测，而SHADECast则提供了最可靠的集合扩展。


<details>
  <summary>Details</summary>
Motivation: 为了提高对光伏电站发电量预测的准确性，特别是考虑时间和空间变化因素的影响，从而为电网调度及能源管理提供更有效的支持。

Method: 通过开发一种新的时空光伏功率预测框架，结合使用基于卫星的深度学习与光流技术以及基于物理原理的数值天气预报模型来进行预测；然后将得到的辐照度场转换成实际的光伏发电量，并与瑞士境内6434个光伏电站的实际生产数据进行比较验证。

Result: 结果表明，在短时间内，基于卫星的方法比综合预报系统(IFS-ENS)表现更好。其中，SolarSTEPS和SHADECast能够提供最精确的地表太阳辐照度(SSI)和光伏功率预测，且SHADECast具有最佳的集合分布。确定性模型IrradianceNet达到了最低的均方根误差，而SolarSTEPS和SHADECast的概率预测则提供了更好的校准不确定性。

Conclusion: 基于卫星的模型显示出较强的鲁棒性和潜在的操作实用性，能够在国家层面上以低于10%的相对误差预测每日总PV发电量，适用于82%的2019-2020年期间的日子。

Abstract: We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.

</details>


### [60] [FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions](https://arxiv.org/abs/2601.04873)
*Elisa Roldan,Kirstie Andrews,Stephen M. Richardson,Reyhaneh Fatahian,Glen Cooper,Rasool Erfani,Tasneem Sabir,Neil D. Reeves*

Main category: cs.LG

TL;DR: 本文提出了一种名为FibreCastML的机器学习框架，该框架能够从常规报告的电纺参数预测完整的纤维直径谱，并提供对过程结构关系的可解释见解。通过使用包含68538个单独纤维直径测量值的数据集训练了七个机器学习模型，非线性模型在多个广泛使用的聚合物上表现出色，溶液浓度被认为是纤维直径分布的主要全球驱动因素。实验验证表明预测与实际测量结果相符良好。


<details>
  <summary>Details</summary>
Motivation: 现有的电纺过程中，虽然已经应用了机器学习来优化工艺，但大多数方法仅能预测平均纤维直径，而忽略了影响支架性能的整个直径分布。为了克服这一限制，研究者们开发了一个新的、关注分布特性的机器学习框架FibreCastML。

Method: 研究人员构建了一个包含1778项研究中提取出的68538个独立纤维直径测量值的大规模元数据集，并利用六个标准处理参数（如溶液浓度、施加电压等）训练了七种不同的机器学习模型。采用嵌套交叉验证和留一研究外折的方法进行训练。为了解释模型，研究者运用了变量重要性分析、SHAP值、相关矩阵以及三维参数图等多种手段。

Result: 非线性模型相比线性基准模型表现更优，在几种广泛应用的生物医学聚合物上达到了决定系数高于0.91的结果。研究发现溶液浓度是影响纤维直径分布的主要因素。此外，跨不同电纺系统的实验验证显示，预测得到的纤维直径分布与实测值高度一致。

Conclusion: FibreCastML框架能够更加准确地预测电纺纤维直径的全分布情况，为电纺支架架构的设计提供了更可靠的数据驱动优化手段。这有助于提高电纺技术在组织工程、药物递送及伤口护理等领域中的应用效果。

Abstract: Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.
  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.
  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.

</details>


### [61] [Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers](https://arxiv.org/abs/2601.04890)
*Maksim Velikanov,Ilyas Chahed,Jingwei Zuo,Dhia Eddine Rhaiem,Younes Belkada,Hakim Hacid*

Main category: cs.LG

TL;DR: 该论文提出了一种通过引入可学习的乘数来优化权重矩阵规模的方法，这种方法可以看作是muP乘数的一种更具有表达力的泛化。实验证明，该方法优于经过良好调整的muP基线，并且减少了乘数调优的计算开销。此外，使用Adam和Muon优化器时，该方法均显示了下游评估中的性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究者们注意到，在大型语言模型预训练过程中，权重衰减（WD）与随机梯度噪声之间的平衡导致权重矩阵W的范数处于一个次优状态。为解决这个问题，本文提出一种新方法。

Method: 研究人员首先向权重矩阵W添加了一个可学习的标量乘数，并发现通过学习得到的比例尺能够更好地适应数据并提高表现。接着，他们进一步提出了解放单行和单列比例尺的想法，通过加入可学习的每行及每列乘数实现这一点。

Result: 实验结果显示，所提出的方法不仅超越了精心调整过的muP基准，还降低了乘数调节过程中的计算负担，并探讨了一些实际问题如前向传递对称性和学习到的乘数随宽度的变化情况。

Conclusion: 总之，这种利用可学习乘数调整权重矩阵规模的新方法，被证明在不同优化器下都能有效提高模型性能。

Abstract: Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.

</details>


### [62] [Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following](https://arxiv.org/abs/2601.04954)
*Yirong Zeng,Yufei Liu,Xiao Ding,Yutai Hou,Yuxian Wang,Haonan Song,Wu Ning,Dandan Tu,Qixun Zhang,Bibo Cai,Yuxiang He,Ting Liu*

Main category: cs.LG

TL;DR: 研究发现，仅使用硬约束训练的模型在指令跟随任务中表现优于混合约束数据集训练的模型。奖励精度而非约束多样性是有效对齐的关键因素。基于这些观察，提出了一种注重奖励精度的数据优化策略，在五个基准测试中表现出色，性能提高了13.4%，同时减少了58%的训练时间。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在挑战关于指令跟随(IF)任务中需要混合硬软约束以实现泛化的普遍共识，通过系统性的实证研究探索真正影响模型性能的因素。

Method: 采用了一系列广泛的实验来比较仅用硬约束与混合约束数据集训练模型的表现差异，并分析了注意力机制的作用以及低召回率导致的问题。基于这些发现，提出了一个优先考虑奖励精度的数据优化方法。

Result: 结果显示，专注于提高奖励精度的方法比追求数据多样性的传统做法更有效，不仅提高了模型性能还显著降低了训练所需时间。

Conclusion: 研究表明，在指令跟随任务中，高精度奖励比约束多样性更重要。提倡从单纯追求数据多样性转向重视奖励精度的新范式。

Abstract: A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\% in performance while achieving a 58\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.

</details>


### [63] [On the Definition and Detection of Cherry-Picking in Counterfactual Explanations](https://arxiv.org/abs/2601.04977)
*James Hinns,Sofie Goethals,Stephan Van der Veeken,Theodoros Evgeniou,David Martens*

Main category: cs.LG

TL;DR: 本文探讨了反事实解释中挑选性解释（cherry-picking）的问题，定义了在给定生成程序和效用函数下的可接受解释空间中的挑选行为，并研究了外部审计者在三种不同访问级别下检测这种操作的可能性。结果显示即使拥有完全的过程访问权限，由于有效反事实的多样性以及解释规格的灵活性，使得故意选择难以被察觉。实验表明，这种变异性通常超过了基于标准反事实质量指标如接近度、可信度和稀疏性的挑选效果，导致挑选出的解释与基准解释在统计上无明显差异。因此，建议应优先考虑可重复性、标准化和过程约束而非事后检测机制，并为算法开发者、解释提供者及审计人员提供了具体建议。


<details>
  <summary>Details</summary>
Motivation: 随着反事实解释被广泛应用于说明模型预测变化所需的输入变更，对于单个实例可能存在许多有效的反事实情况，这为解释提供者留下了选择性呈现解释的空间，可能会突出有利的行为而隐藏揭示问题行为的例子。本文旨在正式定义这一挑选行为，并探索其检测难度及其对信任度的影响。

Method: 通过定义一个由生成过程指定的可接受解释空间和一个效用函数来形式化描述反事实解释中的挑选行为；然后，在三种不同的访问级别下（完全过程访问、部分过程访问、仅解释访问），研究外部审计者检测此类操纵的能力。

Result: 研究表明，在实践中检测挑选性解释是非常有限的。即使是在完全过程访问的情况下，由于有效反事实的数量众多以及解释规范的灵活性，使得故意选取难以区分。实证分析显示，这种变异程度往往超出了根据诸如接近度、合理性及稀疏性等标准反事实质量指标所能测量到的挑选效应，从而让经过挑选的解释与非挑选的解释在统计上变得无法区分。

Conclusion: 鉴于上述发现，本文认为应该更重视可复现性、标准化和程序限制，而不是依赖于事后的检测方法。同时，针对算法开发人员、解释提供者和审核员提出了具体的建议措施。

Abstract: Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.

</details>


### [64] [HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference](https://arxiv.org/abs/2601.05017)
*Xiaopeng Luo,Zexi Tan,Zhuowei Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的填补方法，该方法在一个统一框架内明确建模不同类型特征之间的依赖关系，从而提高了处理缺失值的准确性，并在实验中显示了优于现有技术的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的数据填补方法通常独立处理数值和分类属性，忽略了异构特征之间的重要相互依赖性。为了解决这些限制，需要一种能够同时考虑不同数据类型间依赖关系的新方法。

Method: 提出的方法利用了一个统一框架来明确建模跨类型特征依赖关系，并且利用完整与不完整的实例来保证表格数据中准确一致的填补效果。

Result: 广泛的实验结果表明，所提方法比现有技术表现更优，并显著提升了下游机器学习任务的表现。

Conclusion: 这项研究为现实世界系统中的缺失数据问题提供了一个强大的解决方案，通过改进对跨类型特征依赖性的理解，提高了数据填补的准确性。

Abstract: Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.

</details>


### [65] [A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models](https://arxiv.org/abs/2601.05033)
*Anees Fatima,Mohammad Abdus Salam*

Main category: cs.LG

TL;DR: 本研究通过将外部因素（如工作日、节假日和销售偏差指标）纳入考虑，使用四种机器学习算法（XGBoost、ARIMA、Facebook Prophet 和 SVR）来改进零售和自动售货机领域的需求数量预测。结果表明，结合外部变量的XGBoost模型达到了最低的平均绝对误差22.7，优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 传统的供应链管理需求预测方法往往忽略了天气、节日及设备故障等外部影响因素，导致效率低下。为了解决这一问题，并优化库存管理、减少浪费以及提高顾客满意度，本研究旨在探索机器学习算法在改善零售与自动售货机领域需求预测方面的应用。

Method: 采用了四种机器学习算法：极限梯度提升(XGBoost)、自回归整合移动平均(ARIMA)、Facebook先知(Fb Prophet)和支持向量回归(SVR)，用于预测库存需求。系统地引入了诸如工作日、节假日以及销售偏差指示器等外部因素以提高预测准确性。

Result: XGBoost模型在加入了外部变量后表现最佳，其平均绝对误差(MAE)达到最低值22.7；同时，ARIMAX和Fb Prophet也显示出了显著改进，而SVR的表现则不尽人意。

Conclusion: 研究发现，将外部因素融入需求预测模型中可以大幅度提高预测精度，其中XGBoost被认定为最有效的算法。这项研究表明了一种强大的框架，可用于增强零售和自动售货机系统的库存管理水平。

Abstract: Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.

</details>


### [66] [Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward](https://arxiv.org/abs/2601.05073)
*Jianlong Chen,Daocheng Fu,Shengze Xu,Jiawei Chen,Yuan Feng,Yue Yang,Junchi Yan,Hongyuan Zha,Renqiu Xia*

Main category: cs.LG

TL;DR: 本文提出了一种新的子目标可验证奖励（SGVR）框架，用于解决多模态大语言模型在复杂几何推理中的问题。通过GeoGoal基准测试和基于骨架率的密集奖励机制，实验表明SGVR不仅提高了几何性能，还增强了模型在数学及其他一般推理任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在处理复杂的几何推理时表现不佳，主要是因为基于结果的‘黑箱’监督方法无法区分幸运猜测与严谨推导。

Method: 首先创建了GeoGoal这一基准，它通过严格的形式验证数据引擎将抽象证明转换为可验证的数值子目标；接着提出了子目标可验证奖励（SGVR）框架，该框架利用Skeleton Rate来替代稀疏信号，提供基于子目标完成度的密集奖励。

Result: 实验证明，SGVR能够显著提升模型在几何推理任务上的表现（+9.7%），同时在更广泛的数学(+8.0%)和其他一般推理任务(+2.8%)中也表现出良好的迁移学习效果。

Conclusion: 研究显示，通过引入子目标级别的评估与学习机制，可以有效改进多模态大语言模型在复杂几何推理及其他相关领域的推理质量与准确性。

Abstract: Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because "black box" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.

</details>


### [67] [Exploring Student Expectations and Confidence in Learning Analytics](https://arxiv.org/abs/2601.05082)
*Hayk Asatryan,Basile Tousside,Janis Mohr,Malte Neugebauer,Hildo Bijl,Paul Spiegelberg,Claudia Frohn-Schauf,Jörg Frochte*

Main category: cs.LG

TL;DR: 本研究使用学生学习分析期望问卷（SELAQ）来调查不同学院学生对为学习分析目的处理其数据的期望和信心，通过聚类算法识别出四种类型的学生：热情者、现实主义者、谨慎者和漠不关心者。


<details>
  <summary>Details</summary>
Motivation: 鉴于学习分析在教育系统中日益普及，同时需要遵守隐私立法的要求，研究旨在理解学生对于利用他们的数据进行学习分析的态度与期望。

Method: 采用学生学习分析期望问卷（SELAQ）收集数据，并运用聚类算法对学生群体进行了分类。

Result: 研究结果揭示了四种类别的学生态度：热情者、现实主义者、谨慎者以及漠不关心者。这些发现有助于深入理解学生间对学习分析的不同接受度及批评意见。

Conclusion: 通过对学生关于学习分析的数据处理态度的研究，我们能够更好地理解和优化学习环境，同时也强调了在实施过程中考虑学生个体差异的重要性。

Abstract: Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.

</details>


### [68] [Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning](https://arxiv.org/abs/2601.05134)
*Polina Dolgova,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 提出了一种基于差分隐私的认证遗忘方法，通过在参数空间的正交子空间中分配噪声预算，而不是一次性注入所有噪声，从而在保持原有认证保证的同时减轻了噪声的破坏性影响。实验结果表明该方法在遗忘后显著提高了模型准确性，并且对成员推理攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于差分隐私的认证遗忘方法虽然提供了强有力的保证，但会严重降低模型准确性。

Method: 通过提出一种序列噪声调度的方法，在参数空间的正交子空间中分布噪声预算而非一次全部加入。还扩展了对含噪微调到子空间设置下的分析，证明可以保持相同的(ε,δ)隐私预算。

Result: 在图像分类基准测试中的实证结果显示，所提方法在执行遗忘后大大提升了准确性，同时仍能抵抗成员推理攻击。

Conclusion: 这项研究表明，认证遗忘可以在提供严格保障的同时实现实际应用价值。

Abstract: Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.

</details>


### [69] [An interpretable data-driven approach to optimizing clinical fall risk assessment](https://arxiv.org/abs/2601.05194)
*Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Holley Farley,Kimia Ghobadi*

Main category: cs.LG

TL;DR: 本研究通过数据驱动的建模方法，特别是约束评分优化（CSO）模型，改进了约翰霍普金斯跌倒风险评估工具（JHFRAT）的表现，提高了对高跌倒风险患者的识别能力。尽管黑盒模型如XGBoost在性能指标上更优，但CSO模型显示出了对于风险标签变化更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地将约翰霍普金斯跌倒风险评估工具与额外具有临床意义的度量标准相结合，并通过数据驱动的方法提升其预测准确性。

Method: 采用回顾性队列分析法，针对2022年3月至2023年10月期间来自约翰霍普金斯卫生系统三家医院的54,209例住院病例进行研究。使用约束评分优化(CSO)模型重新调整JHFRAT评分权重，在保持其加性结构和临床阈值的同时提高预测性能。

Result: CSO模型显著提升了预测性能(AUC-ROC=0.91)，相较于原始JHFRAT(AUC-ROC=0.86)每周可额外保护约35位高风险患者。虽然基准黑盒模型(XGBoost)在性能指标上略胜一筹(AUC-ROC=0.94)，但CSO模型展现出更强的风险标签变化适应能力。

Conclusion: 基于证据的方法为医疗系统提供了一个强大的基础，以系统地增强住院患者跌倒预防协议及患者安全措施，通过数据驱动的优化技术促进风险评估和资源分配的有效性。

Abstract: In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.

</details>


### [70] [Optimal Lower Bounds for Online Multicalibration](https://arxiv.org/abs/2601.05245)
*Natalie Collina,Jiuyao Lu,Georgy Noarov,Aaron Roth*

Main category: cs.LG

TL;DR: 本文证明了在线多校准的紧致下界，表明它与边际校准在信息理论上是分离的。对于依赖于上下文和学习者预测的群组函数，证明了一个Ω(T^2/3)的预期多校准误差下界；对于仅依赖于上下文而不依赖于学习者预测的情况，则建立了Ω~(T^2/3)的下界。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在线多校准（相对于边际校准）的基本限制，并通过证明紧致下界来展示两者之间的信息理论差异。

Method: 采用信息论方法分析在线多校准问题，构造特定示例以证明对于不同类型的群组函数，多校准误差的理论下界。

Result: 对于依赖于上下文和预测的群组函数，证明了Ω(T^2/3)的多校准误差下界；对于仅依赖于上下文的情形，利用正交函数系统构建了一族大小为Θ(T)的群组，证明了Ω~(T^2/3)的下界。这些结果与已知上界相匹配，除去了对数因子的影响。

Conclusion: 本研究表明，在线多校准与边际校准之间存在根本性的区别，且对于考虑的不同情况都给出了接近最优的界限。

Abstract: We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.
  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.
  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.

</details>
