{"id": "2602.23598", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23598", "abs": "https://arxiv.org/abs/2602.23598", "authors": ["Md Hasanur Rashid", "Jesun Firoz", "Nathan R. Tallent", "Luanzheng Guo", "Meng Tang", "Dong Dai"], "title": "QoSFlow: Ensuring Service Quality of Distributed Workflows Using Interpretable Sensitivity Models", "comment": "to be published in 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS), 2026", "summary": "With the increasing importance of distributed scientific workflows, there is a critical need to ensure Quality of Service (QoS) constraints, such as minimizing time or limiting execution to resource subsets. However, the unpredictable nature of workflow behavior, even with similar configurations, makes it difficult to provide QoS guarantees. For effective reasoning about QoS scheduling, we introduce QoSFlow, a performance modeling method that partitions a workflow's execution configuration space into regions with similar behavior. Each region groups configurations with comparable execution times according to a given statistical sensitivity, enabling efficient QoS-driven scheduling through analytical reasoning rather than exhaustive testing. Evaluation on three diverse workflows shows that QoSFlow's execution recommendations outperform the best-performing standard heuristic by 27.38%. Empirical validation confirms that QoSFlow's recommended configurations consistently match measured execution outcomes across different QoS constraints."}
{"id": "2602.23758", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23758", "abs": "https://arxiv.org/abs/2602.23758", "authors": ["Dingyu Yang", "Fanyong Kong", "Jie Dai", "Shiyou Qian", "Shuangwei Li", "Jian Cao", "Guangtao Xue", "Gang Chen"], "title": "Hestia: Hyperthread-Level Scheduling for Cloud Microservices with Interference-Aware Attention", "comment": "This paper has been accepted for publication in Design Automation Conference(DAC 2026)", "summary": "Modern cloud servers routinely co-locate multiple latency-sensitive microservice instances to improve resource efficiency. However, the diversity of microservice behaviors, coupled with mutual performance interference under simultaneous multithreading (SMT), makes large-scale placement increasingly complex. Existing interference aware schedulers and isolation techniques rely on coarse core-level profiling or static resource partitioning, leaving asymmetric hyperthread-level heterogeneity and SMT contention dynamics largely unmodeled. We present Hestia, a hyperthread-level, interference-aware scheduling framework powered by self-attention. Through an extensive analysis of production traces encompassing 32,408 instances across 3,132 servers, we identify two dominant contention patterns -- sharing-core (SC) and sharing-socket (SS) -- and reveal strong asymmetry in their impact. Guided by these insights, Hestia incorporates (1) a self-attention-based CPU usage predictor that models SC/SS contention and hardware heterogeneity, and (2) an interference scoring model that estimates pairwise contention risks to guide scheduling decisions. We evaluate Hestia through large-scale simulation and a real production deployment. Hestia reduces the 95th-percentile service latency by up to 80\\%, lowers overall CPU consumption by 2.3\\% under the same workload, and surpasses five state-of-the-art schedulers by up to 30.65\\% across diverse contention scenarios."}
{"id": "2602.23927", "categories": ["cs.DC", "cs.FL", "cs.MA", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23927", "abs": "https://arxiv.org/abs/2602.23927", "authors": ["Laura Bocchi", "Raymond Hu", "Adriana Laura Voinea", "Simon Thompson"], "title": "Mixed Choice in Asynchronous Multiparty Session Types", "comment": null, "summary": "We present a multiparty session type (MST) framework with asynchronous mixed choice (MC). We propose a core construct for MC that allows transient inconsistencies in protocol state between distributed participants, but ensures all participants can always eventually reach a mutually consistent state. We prove the correctness of our system by establishing a progress property and an operational correspondence between global types and distributed local type projections. Based on our theory, we implement a practical toolchain for specifying and validating asynchronous MST protocols featuring MC, and programming compliant gen_statem processes in Erlang/OTP. We test our framework by using our toolchain to specify and reimplement part of the amqp_client of the RabbitMQ broker for Erlang."}
{"id": "2602.23935", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23935", "abs": "https://arxiv.org/abs/2602.23935", "authors": ["Bowen Sun", "Christos D. Antonopoulos", "Evgenia Smirni", "Bin Ren", "Nikolaos Bellas", "Spyros Lalis"], "title": "Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing", "comment": null, "summary": "Serverless computing simplifies cloud deployment but introduces new challenges in managing service latency and carbon emissions. Reducing cold-start latency requires retaining warm function instances, while minimizing carbon emissions favors reclaiming idle resources. This balance is further complicated by time-varying grid carbon intensity and varying workload patterns, under which static keep-alive policies are inefficient. We present LACE-RL, a latency-aware and carbon-efficient management framework that formulates serverless pod retention as a sequential decision problem. LACE-RL uses deep reinforcement learning to dynamically tune keep-alive durations, jointly modeling cold-start probability, function-specific latency costs, and real-time carbon intensity. Using the Huawei Public Cloud Trace, we show that LACE-RL reduces cold starts by 51.69% and idle keep-alive carbon emissions by 77.08% compared to Huawei's static policy, while achieving better latency-carbon trade-offs than state-of-the-art heuristic and single-objective baselines, approaching Oracle performance."}
{"id": "2602.23969", "categories": ["cs.MM", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23969", "abs": "https://arxiv.org/abs/2602.23969", "authors": ["Haoyuan Shi", "Yunxin Li", "Nanhao Deng", "Zhenran Xu", "Xinyu Chen", "Longyue Wang", "Baotian Hu", "Min Zhang"], "title": "MSVBench: Towards Human-Level Evaluation of Multi-Shot Video Generation", "comment": null, "summary": "The evolution of video generation toward complex, multi-shot narratives has exposed a critical deficit in current evaluation methods. Existing benchmarks remain anchored to single-shot paradigms, lacking the comprehensive story assets and cross-shot metrics required to assess long-form coherence and appeal. To bridge this gap, we introduce MSVBench, the first comprehensive benchmark featuring hierarchical scripts and reference images tailored for Multi-Shot Video generation. We propose a hybrid evaluation framework that synergizes the high-level semantic reasoning of Large Multimodal Models (LMMs) with the fine-grained perceptual rigor of domain-specific expert models. Evaluating 20 video generation methods across diverse paradigms, we find that current models--despite strong visual fidelity--primarily behave as visual interpolators rather than true world models. We further validate the reliability of our benchmark by demonstrating a state-of-the-art Spearman's rank correlation of 94.4% with human judgments. Finally, MSVBench extends beyond evaluation by providing a scalable supervisory signal. Fine-tuning a lightweight model on its pipeline-refined reasoning traces yields human-aligned performance comparable to commercial models like Gemini-2.5-Flash."}
{"id": "2602.23469", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.23469", "abs": "https://arxiv.org/abs/2602.23469", "authors": ["Lixi Zhou", "Kanchan Chowdhury", "Lulu Xie", "Jaykumar Tandel", "Hong Guan", "Zhiwei Fan", "Xinwei Fu", "Jia Zou"], "title": "CACTUSDB: Unlock Co-Optimization Opportunities for SQL and AI/ML Inferences", "comment": "Accepted to ICDE 2026 as a full research paper", "summary": "There is a growing demand for supporting inference queries that combine Structured Query Language (SQL) and Artificial Intelligence / Machine Learning (AI/ML) model inferences in database systems, to avoid data denormalization and transfer, facilitate management, and alleviate privacy concerns. Co-optimization techniques for executing inference queries in database systems without accuracy loss fall into four categories: (O1) Relational algebra optimization treating AI/ML models as black-box user-defined functions (UDFs); (O2) Factorized AI/ML inferences; (O3) Tensor-relational transformation; and (O4) General cross-optimization techniques. However, we found none of the existing database systems support all these techniques simultaneously, resulting in suboptimal performance. In this work, we identify two key challenges to address the above problem: (1) the difficulty of unifying all co-optimization techniques that involve disparate data and computation abstractions in one system; and (2) the lack of an optimizer that can effectively explore the exponential search space. To address these challenges, we present CactusDB, a novel system built atop Velox - a high-performance, UDF-centric database engine, open-sourced by Meta. CactusDB features a three-level Intermediate Representations (IR) that supports relational operators, expression operators, and ML functions to enable flexible optimization of arbitrary sub-computations. Additionally, we propose a novel Monte-Carlo Tree Search (MCTS)-based optimizer with query embedding, co-designed with our unique three-level IR, enabling shared and reusable optimization knowledge across different queries. Evaluation of 12 representative inference workloads and 2,000 randomly generated inference queries on well-known datasets, such as MovieLens and TPCx-AI, shows that CactusDB achieves up to 441 times speedup compared to alternative systems."}
{"id": "2602.23368", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23368", "abs": "https://arxiv.org/abs/2602.23368", "authors": ["Shreyas Subramanian", "Adewale Akinfaderin", "Yanyan Zhang", "Ishan Singh", "Mani Khanuja", "Sandeep Singh", "Maira Ladeira Tanke"], "title": "Keyword search is all you need: Achieving RAG-Level Performance without vector databases using agentic tool use", "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) has proven effective for generating accurate, context-based responses based on existing knowledge bases, it presents several challenges including retrieval quality dependencies, integration complexity and cost. Recent advances in agentic-RAG and tool-augmented LLM architectures have introduced alternative approaches to information retrieval and processing. We question how much additional value vector databases and semantic search bring to RAG over simple, agentic keyword search in documents for question-answering. In this study, we conducted a systematic comparison between RAG-based systems and tool-augmented LLM agents, specifically evaluating their retrieval mechanisms and response quality when the agent only has access to basic keyword search tools. Our empirical analysis demonstrates that tool-based keyword search implementations within an agentic framework can attain over $90\\%$ of the performance metrics compared to traditional RAG systems without using a standing vector database. Our approach is simple to implement, cost effective, and is particularly useful in scenarios requiring frequent updates to knowledge bases."}
{"id": "2602.23647", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23647", "abs": "https://arxiv.org/abs/2602.23647", "authors": ["Quanjun Zhang", "Chengyu Gao", "Yu Han", "Ye Shang", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "SGAgent: Suggestion-Guided LLM-Based Multi-Agent Framework for Repository-Level Software Repair", "comment": "23 pages, 3 figures", "summary": "The rapid advancement of Large Language Models (LLMs) has led to the emergence of intelligent agents capable of autonomously interacting with environments and invoking external tools. Recently, agent-based software repair approaches have received widespread attention, as repair agents can automatically analyze and localize bugs, generate patches, and achieve state-of-the-art performance on repository-level benchmarks. However, existing approaches usually adopt a localize-then-fix paradigm, jumping directly from \"where the bug is\" to \"how to fix it\", leaving a fundamental reasoning gap. To this end, we propose SGAgent, a Suggestion-Guided multi-Agent framework for repository-level software repair, which follows a localize-suggest-fix paradigm. SGAgent introduces a suggestion phase to strengthen the transition from localization to repair. The suggester starts from the buggy locations and incrementally retrieves relevant context until it fully understands the bug, and then provides actionable repair suggestions. Moreover, we construct a Knowledge Graph from the target repository and develop a KG-based toolkit to enhance SGAgent's global contextual awareness and repository-level reasoning. Three specialized sub-agents (i.e., localizer, suggester, and fixer) collaborate to achieve automated end-to-end software repair. Experimental results on SWE-Bench show that SGAgent with Claude-3.5 achieves 51.3% repair accuracy, 81.2% file-level and 52.4% function-level localization accuracy with an average cost of $1.48 per instance, outperforming all baselines using the same base model. Furthermore, SGAgent attains 48% accuracy on VUL4J and VJBench for vulnerability repair, demonstrating strong generalization across tasks and programming languages."}
{"id": "2602.23391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23391", "abs": "https://arxiv.org/abs/2602.23391", "authors": ["Nazanin Mohammadi Sepahvand", "Eleni Triantafillou", "Hugo Larochelle", "Doina Precup", "Daniel M. Roy", "Gintare Karolina Dziugaite"], "title": "Detoxifying LLMs via Representation Erasure-Based Preference Optimization", "comment": null, "summary": "Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful \"directions\" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail."}
{"id": "2602.24044", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24044", "abs": "https://arxiv.org/abs/2602.24044", "authors": ["Ferran Agullo", "Joan Oliveras", "Chen Wang", "Alberto Gutierrez-Torre", "Olivier Tardieu", "Alaa Youssef", "Jordi Torres", "Josep Ll. Berral"], "title": "Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving", "comment": "journal extension of the workshop paper titled as \"A data-driven ml approach for maximizing performance in llm-adapter serving\"", "summary": "Large Language Model (LLM) adapters enable low-cost model specialization, but introduce complex caching and scheduling challenges in distributed serving systems where hundreds of adapters must be hosted concurrently. While prior work has largely focused on latency minimization, resource efficiency through throughput maximization remains underexplored. This paper presents a data-driven pipeline that, for a given workload, computes an adapter placement that serves the workload with the minimum number of GPUs while avoiding request starvation and GPU memory errors. To that end, the approach identifies the maximum feasible throughput attainable on each GPU by leveraging accurate performance predictions learned from real serving behavior. The proposed pipeline integrates three components: (i) a Digital Twin (DT) tailored to LLM-adapter serving, (ii) a distilled machine learning (ML) model trained on DT-generated data, and (iii) a greedy placement algorithm that exploits ML-based performance estimates to maximize GPU efficiency. The DT emulates real system dynamics with high fidelity, achieving below 5% throughput estimation error while executing up to 90 times faster than full LLM benchmarking across both predictable and unpredictable workloads. The learned ML models further accelerate performance estimation with marginal accuracy degradation, enabling scalable optimization. Experimental results demonstrate that the pipeline substantially improves GPU efficiency by reducing the number of GPUs required to sustain target workloads. Beyond GPU efficiency, the pipeline can be adapted to alternative objectives, such as latency minimization, highlighting its versatility for future large-scale LLM serving infrastructures."}
{"id": "2602.23571", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.23571", "abs": "https://arxiv.org/abs/2602.23571", "authors": ["Quanqing Xu", "Mingqiang Zhuang", "Chuanhui Yang", "Quanwei Wan", "Fusheng Han", "Fanyu Kong", "Hao Liu", "Hu Xu", "Junyu Ye"], "title": "OceanBase Bacchus: a High-Performance and Scalable Cloud-Native Shared Storage Architecture for Multi-Cloud", "comment": null, "summary": "Although an increasing number of databases now embrace shared-storage architectures, current storage-disaggregated systems have yet to strike an optimal balance between cost and performance. In high-concurrency read/write scenarios, B+-tree-based shared storage struggles to efficiently absorb frequent in-place updates. Existing LSM-tree-backed disaggregated storage designs are hindered by the intricate implementation of cross-node shared-log mechanisms, where no satisfactory solution yet exists.\n  This paper presents OceanBase Bacchus, an LSM-tree architecture tailored for object storage provided by cloud vendors. The system sustains high-performance reads and writes while rendering compute nodes stateless through shared service-oriented PALF (Paxos-backed Append-only Log File system) logging and asynchronous background services. We employ a Shared Block Cache Service to flexibly utilize cache resources. Our design places log synchronization into a shared service, providing a novel solution for log sharing in storage-compute-separated databases. The architecture decouples functionality across modules, enabling elastic scaling where compute, cache, and storage resources can be resized rapidly and independently. Through experimental evaluation using multiple benchmark tests, including SysBench and TPC-H, we confirm that OceanBase Bacchus achieves performance comparable to or superior to that of HBase in OLTP scenarios and significantly outperforms StarRocks in OLAP workloads. Leveraging Bacchus's support for multi-cloud deployment and consistent performance, we not only retain high availability and competitive performance but also achieve substantial reductions in storage costs by 59% in OLTP scenarios and 89% in OLAP scenarios."}
{"id": "2602.23369", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23369", "abs": "https://arxiv.org/abs/2602.23369", "authors": ["Xuanming Cui", "Hong-You Chen", "Hao Yu", "Hao Yuan", "Zihao Wang", "Shlok Kumar Mishra", "Hanchao Yu", "Yonghuan Yang", "Jun Xiao", "Ser-Nam Lim", "Jianpeng Cheng", "Qi Guo", "Xiangjun Fan"], "title": "Reason to Contrast: A Cascaded Multimodal Retrieval Framework", "comment": null, "summary": "Traditional multimodal retrieval systems rely primarily on bi-encoder architectures, where performance is closely tied to embedding dimensionality. Recent work, Think-Then-Embed (TTE), shows that incorporating multimodal reasoning to elicit additional informative tokens before embedding can further improve retrieval. In this paper, we extend this paradigm with TTE-v2, a hybrid multimodal retrieval framework that introduces reasoning-driven performance scaling based on additional input token budget rather than model or embedding size. Our approach augments the initial multimodal retrieval with additional reasoning steps for reranking, enabling more expressive query-candidate interactions at test time. The reranking stage further provides fine-grained supervision for hard negative mining and false negative filtering, creating a feedback loop that effectively strengthens the upstream retriever. This cascaded design delivers substantial test-time improvements based on intermediate reasoning token scaling. Experiments on the MMEB-V2 benchmark demonstrate that TTE-v2-7B achieves a new state-of-the-art accuracy of 75.7%, and that TTE-v2-2B matches or surpasses leading 7B models trained with significantly larger external data. Our results highlight the promise of token-wise scaling as an alternative scaling paradigm for multimodal retrieval."}
{"id": "2602.23736", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23736", "abs": "https://arxiv.org/abs/2602.23736", "authors": ["Ruixiang Qian", "Chunrong Fang", "Zengxu Chen", "Youxin Fu", "Zhenyu Chen"], "title": "Peeling Off the Cocoon: Unveiling Suppressed Golden Seeds for Mutational Greybox Fuzzing", "comment": "Accepted by OOPSLA 2026", "summary": "PoCo is a technique that aims to enhance modern coverage-based seed selection (CSS) techniques (such as afl-cmin) by gradually removing obstacle conditional statements and conducting deeper seed selection."}
{"id": "2602.23400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23400", "abs": "https://arxiv.org/abs/2602.23400", "authors": ["Zezheng Wu", "Rui Wang", "Xinghe Cheng", "Yang Shao", "Qing Yang", "Jiapu Wang", "Jingwei Zhang"], "title": "U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency."}
{"id": "2602.24237", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.24237", "abs": "https://arxiv.org/abs/2602.24237", "authors": ["Harinder Singh"], "title": "nvidia-pcm: A D-Bus-Driven Platform Configuration Manager for OpenBMC Environments", "comment": "7 pages, 1 figure, 10 references", "summary": "GPU-accelerated server platforms that share most of their hardware architecture often require separate firmware images due to minor hardware differences--different component identifiers, thermal profiles, or interconnect topologies. I built nvidia-pcm to eliminate that overhead. nvidia-pcm is a platform configuration manager for NVBMC, NVIDIA's OpenBMC-based firmware distribution, that enables a single firmware image to serve multiple platform variants. At boot, nvidia-pcm queries hardware identity data over D-Bus and exports the correct platform-specific configuration as environment variables. Downstream services read those variables without knowing or caring which hardware variant they are running on. The result is that platform differences are captured entirely in declarative JSON files, not in separate build artifacts. This paper describes the architecture, implementation, and deployment impact of nvidia-pcm, and shares lessons learned from solving the platform-identity problem at a deliberately minimal level of abstraction--prioritizing adoption simplicity over comprehensive hardware modeling."}
{"id": "2602.23999", "categories": ["cs.DB", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23999", "abs": "https://arxiv.org/abs/2602.23999", "authors": ["Jifan Shi", "Jianyang Gao", "James Xia", "Tamás Béla Fehér", "Cheng Long"], "title": "GPU-Native Approximate Nearest Neighbor Search with IVF-RaBitQ: Fast Index Build and Search", "comment": null, "summary": "Approximate nearest neighbor search (ANNS) on GPUs is gaining increasing popularity for modern retrieval and recommendation workloads that operate over massive high-dimensional vectors. Graph-based indexes deliver high recall and throughput but incur heavy build-time and storage costs. In contrast, cluster-based methods build and scale efficiently yet often need many probes for high recall, straining memory bandwidth and compute. Aiming to simultaneously achieve fast index build, high-throughput search, high recall, and low storage requirement for GPUs, we present IVF-RaBitQ (GPU), a GPU-native ANNS solution that integrates the cluster-based method IVF with RaBitQ quantization into an efficient GPU index build/search pipeline. Specifically, for index build, we develop a scalable GPU-native RaBitQ quantization method that enables fast and accurate low-bit encoding at scale. For search, we develop GPU-native distance computation schemes for RaBitQ codes and a fused search kernel to achieve high throughput with high recall. With IVF-RaBitQ implemented and integrated into the NVIDIA cuVS Library, experiments on cuVS Bench across multiple datasets show that IVF-RaBitQ offers a strong performance frontier in recall, throughput, index build time, and storage footprint. For Recall approximately equal to 0.95, IVF-RaBitQ achieves 2.2x higher QPS than the state-of-the-art graph-based method CAGRA, while also constructing indices 7.7x faster on average. Compared to the cluster-based method IVF-PQ, IVF-RaBitQ delivers on average over 2.7x higher throughput while avoiding accessing the raw vectors for reranking."}
{"id": "2602.23371", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23371", "abs": "https://arxiv.org/abs/2602.23371", "authors": ["Rakshita Goel", "S Pranav Kumar", "Anmol Agrawal", "Divyan Poddar", "Pratik Narang", "Dhruv Kumar"], "title": "Domain-Partitioned Hybrid RAG for Legal Reasoning: Toward Modular and Explainable Legal AI for India", "comment": null, "summary": "Legal research in India involves navigating long and heterogeneous documents spanning statutes, constitutional provisions, penal codes, and judicial precedents, where purely keyword-based or embedding-only retrieval systems often fail to support structured legal reasoning. Recent retrieval augmented generation (RAG) approaches improve grounding but struggle with multi-hop reasoning, citation chaining, and cross-domain dependencies inherent to legal texts.\n  We propose a domain partitioned hybrid RAG and Knowledge Graph architecture designed specifically for Indian legal research. The system integrates three specialized RAG pipelines covering Supreme Court case law, statutory and constitutional texts, and the Indian Penal Code, each optimized for domain specific retrieval. To enable relational reasoning beyond semantic similarity, we construct a Neo4j based Legal Knowledge Graph capturing structured relationships among cases, statutes, IPC sections, judges, and citations. An LLM driven agentic orchestrator dynamically routes queries across retrieval modules and the knowledge graph, fusing evidence into grounded and citation aware responses.\n  We evaluate the system using a 40 question synthetic legal question answer benchmark curated from authoritative Indian legal sources and assessed via an LLM as a Judge framework. Results show that the hybrid architecture achieves a 70 percent pass rate, substantially outperforming a RAG only baseline at 37.5 percent, with marked improvements in completeness and legal reasoning quality. These findings demonstrate that combining domain partitioned retrieval with structured relational knowledge provides a scalable and interpretable foundation for advanced legal AI systems in the Indian judicial context."}
{"id": "2602.23866", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23866", "abs": "https://arxiv.org/abs/2602.23866", "authors": ["Ibragim Badertdinov", "Maksim Nekrashevich", "Anton Shevtsov", "Alexander Golubev"], "title": "SWE-rebench V2: Language-Agnostic SWE Task Collection at Scale", "comment": null, "summary": "Software engineering agents (SWE) are improving rapidly, with recent gains largely driven by reinforcement learning (RL). However, RL training is constrained by the scarcity of large-scale task collections with reproducible execution environments and reliable test suites. Although a growing number of benchmarks have emerged, datasets suitable for training remain limited in scale and diversity or often target a limited set of high-resource language ecosystems. We introduce SWE-rebench V2, a language-agnostic automated pipeline for harvesting executable real-world SWE tasks and constructing RL training environments at scale. The pipeline synthesizes repository-specific installation and test procedures via an interactive setup agent, and filters unsound instances using an ensemble of LLM judges, validated against human-verified SWE-bench annotations. Using this pipeline, we construct a dataset of 32,000+ tasks spanning 20 languages and 3,600+ repositories, with pre-built images for reproducible execution. To further scale training data, we additionally release 120,000+ tasks with installation instructions, fail-to-pass tests and rich metadata, where the problem statement is generated based on the original pull request description. We validate the collected instances through a diagnostic study that covers a subset of tasks in five programming languages across seven popular models, and provide instance-level metadata that flags common confounders such as overly restrictive tests and underspecified descriptions. We release the datasets, the collection and execution code, and associated artifacts to enable large-scale training of SWE agents across diverse languages and repositories."}
{"id": "2602.23409", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.23409", "abs": "https://arxiv.org/abs/2602.23409", "authors": ["Michael Poppel", "Jonas Stein", "Sebastian Wölckert", "Markus Baumann", "Claudia Linnhoff-Popien"], "title": "Long Range Frequency Tuning for QML", "comment": null, "summary": "Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876)."}
{"id": "2602.23504", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23504", "abs": "https://arxiv.org/abs/2602.23504", "authors": ["Anik Pramanik", "Murat Kantarcioglu", "Vincent Oria", "Shantanu Sharma"], "title": "FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments", "comment": "This paper has been accepted in ICLR 2026", "summary": "Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy."}
{"id": "2602.24271", "categories": ["cs.DB", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.24271", "abs": "https://arxiv.org/abs/2602.24271", "authors": ["Boram Jung", "Yuliang Li", "Hung-Wei Tseng"], "title": "NSHEDB: Noise-Sensitive Homomorphic Encrypted Database Query Engine", "comment": null, "summary": "Homomorphic encryption (HE) enables computations directly on encrypted data, offering strong cryptographic guarantees for secure and privacy-preserving data storage and query execution. However, despite its theoretical power, practical adoption of HE in database systems remains limited due to extreme cipher-text expansion, memory overhead, and the computational cost of bootstrapping, which resets noise levels for correctness.\n  This paper presents NSHEDB, a secure query processing engine designed to address these challenges at the system architecture level. NSHEDB uses word-level leveled HE (LHE) based on the BFV scheme to minimize ciphertext expansion and avoid costly bootstrapping. It introduces novel techniques for executing equality, range, and aggregation operations using purely homomorphic computation, without transciphering between different HE schemes (e.g., CKKS/BFV/TFHE) or relying on trusted hardware. Additionally, it incorporates a noise-aware query planner to extend computation depth while preserving security guarantees.\n  We implement and evaluate NSHEDB on real-world database workloads (TPC-H) and show that it achieves 20x-V1370x speedup and a 73x storage reduction compared to state-of-the-art HE-based systems, while upholding 128-bit security in a semi-honest model with no key release or trusted components."}
{"id": "2602.23372", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23372", "abs": "https://arxiv.org/abs/2602.23372", "authors": ["Qizhi Wang"], "title": "Democratizing GraphRAG: Linear, CPU-Only Graph Retrieval for Multi-Hop QA", "comment": "13 pages, 14 figures, 26 tables", "summary": "GraphRAG systems improve multi-hop retrieval by modeling structure, but many approaches rely on expensive LLM-based graph construction and GPU-heavy inference. We present SPRIG (Seeded Propagation for Retrieval In Graphs), a CPU-only, linear-time, token-free GraphRAG pipeline that replaces LLM graph building with lightweight NER-driven co-occurrence graphs and uses Personalized PageRank (PPR) for 28% with negligible Recall@10 changes. The results characterize when CPU-friendly graph retrieval helps multi-hop recall and when strong lexical hybrids (RRF) are sufficient, outlining a realistic path to democratizing GraphRAG without token costs or GPU requirements."}
{"id": "2602.23905", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23905", "abs": "https://arxiv.org/abs/2602.23905", "authors": ["Syed Ammar Asdaque", "Imran Haider", "Muhammad Umar Malik", "Maryam Abdul Ghafoor", "Abdul Ali Bangash"], "title": "Novice Developers Produce Larger Review Overhead for Project Maintainers while Vibe Coding", "comment": "Accepted to MSR 2026 Mining Challenge", "summary": "AI coding agents allow software developers to generate code quickly, which raises a practical question for project managers and open source maintainers: can vibe coders with less development experience substitute for expert developers? To explore whether developer experience still matters in AI-assisted development, we study $22,953$ Pull Requests (PRs) from $1,719$ vibe coders in the GitHub repositories of the AIDev dataset. We split vibe coders into lower experience vibe coders ($\\mathit{Exp}_{Low}$) and higher experience vibe coders ($\\mathit{Exp}_{High}$) and compare contribution magnitude and PR acceptance rates across PR categories. We find that $\\mathit{Exp}_{Low}$ submits PRs with larger volume ($2.15\\times$ more commits and $1.47\\times$ more files changed) than $\\mathit{Exp}_{High}$. Moreover, $\\mathit{Exp}_{Low}$ PRs, when compared to $\\mathit{Exp}_{High}$, receive $4.52\\times$ more review comments, and have $31\\%$ lower acceptance rates, and remain open $5.16\\times$ longer before resolution. Our results indicate that low-experienced vibe coders focus on generating more code while shifting verification burden onto reviewers. For practice, project managers may not be able to safely replace experienced developers with low-experience vibe coders without increasing review capacity. Development teams should therefore combine targeted training for novices with adaptive PR review cycles."}
{"id": "2602.23410", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.23410", "abs": "https://arxiv.org/abs/2602.23410", "authors": ["Hanning Guo", "Farah Abdellatif", "Hanwen Bi", "Andrei Galbenus", "Jon. N. Shah", "Abigail Morrison", "Jürgen Dammers"], "title": "Brain-OF: An Omnifunctional Foundation Model for fMRI, EEG and MEG", "comment": null, "summary": "Brain foundation models have achieved remarkable advances across a wide range of neuroscience tasks. However, most existing models are limited to a single functional modality, restricting their ability to exploit complementary spatiotemporal dynamics and the collective data scale across imaging techniques. To address this limitation, we propose Brain-OF, the first omnifunctional brain foundation model jointly pretrained on fMRI, EEG and MEG, capable of handling both unimodal and multimodal inputs within a unified framework. To reconcile heterogeneous spatiotemporal resolutions, we introduce the Any-Resolution Neural Signal Sampler, which projects diverse brain signals into a shared semantic space.To further manage semantic shifts, the Brain-OF backbone integrates DINT attention with a Sparse Mixture of Experts, where shared experts capture modality-invariant representations and routed experts specialize in modality-specific semantics. Furthermore, we propose Masked Temporal-Frequency Modeling, a dual-domain pretraining objective that jointly reconstructs brain signals in both the time and frequency domains. Brain-OF is pretrained on a large-scale corpus comprising around 40 datasets and demonstrates superior performance across diverse downstream tasks, highlighting the benefits of joint multimodal integration and dual-domain pretraining."}
{"id": "2602.23556", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.MA", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23556", "abs": "https://arxiv.org/abs/2602.23556", "authors": ["Aishwarya Sarkar", "Sayan Ghosh", "Nathan Tallent", "Aman Chadha", "Tanya Roosta", "Ali Jannesari"], "title": "Rudder: Steering Prefetching in Distributed GNN Training using LLM Agents", "comment": "Accepted to the 40th ACM International Conference on Supercomputing (ICS 2026)", "summary": "Large-scale Graph Neural Networks (GNNs) are typically trained by sampling a vertex's neighbors to a fixed distance. Because large input graphs are distributed, training requires frequent irregular communication that stalls forward progress. Moreover, fetched data changes with graph, graph distribution, sample and batch parameters, and caching polices. Consequently, any static prefetching method will miss crucial opportunities to adapt to different dynamic conditions. In this paper, we introduce Rudder, a software module embedded in the state-of-the-art AWS DistDGL framework, to autonomously prefetch remote nodes and minimize communication. Rudder's adaptation contrasts with both standard heuristics and traditional ML classifiers. We observe that the generative AI found in contemporary Large Language Models (LLMs) exhibits emergent properties like In-Context Learning (ICL) for zero-shot tasks, with logical multi-step reasoning. We find this behavior well-suited for adaptive control even with substantial undertraining. Evaluations using standard datasets and unseen configurations on the NERSC Perlmutter supercomputer show up to 91% improvement in end-to-end training performance over baseline DistDGL (no prefetching), and an 82% improvement over static prefetching, reducing communication by over 50%. Our code is available at https://github.com/aishwaryyasarkar/rudder-llm-agent."}
{"id": "2602.23374", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23374", "abs": "https://arxiv.org/abs/2602.23374", "authors": ["Weixi Lin"], "title": "Higress-RAG: A Holistic Optimization Framework for Enterprise Retrieval-Augmented Generation via Dual Hybrid Retrieval, Adaptive Routing, and CRAG", "comment": "7 pages,5 figures, our submissions are not yet published", "summary": "The integration of Large Language Models (LLMs) into enterprise knowledge management systems has been catalyzed by the Retrieval-Augmented Generation (RAG) paradigm, which augments parametric memory with non-parametric external data. However, the transition from proof-of-concept to production-grade RAG systems is hindered by three persistent challenges: low retrieval precision for complex queries, high rates of hallucination in the generation phase, and unacceptable latency for real-time applications. This paper presents a comprehensive analysis of the Higress RAG MCP Server, a novel, enterprise-centric architecture designed to resolve these bottlenecks through a \"Full-Link Optimization\" strategy. Built upon the Model Context Protocol (MCP), the system introduces a layered architecture that orchestrates a sophisticated pipeline of Adaptive Routing, Semantic Caching, Hybrid Retrieval, and Corrective RAG (CRAG). We detail the technical implementation of key innovations, including the Higress-Native Splitter for structure-aware data ingestion, the application of Reciprocal Rank Fusion (RRF) for merging dense and sparse retrieval signals, and a 50ms-latency Semantic Caching mechanism with dynamic thresholding. Experimental evaluations on domain-specific Higress technical documentation and blogs verify the system's architectural robustness. The results demonstrate that by optimizing the entire retrieval lifecycle - from pre-retrieval query rewriting to post-retrieval corrective evaluation - the Higress RAG system offers a scalable, hallucination-resistant solution for enterprise AI deployment."}
{"id": "2602.23922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23922", "abs": "https://arxiv.org/abs/2602.23922", "authors": ["Ana Catarina Ribeiro"], "title": "Invariant-Driven Automated Testing", "comment": null, "summary": "Microservice architectures are an emergent technology that builds business logic into a suite of small services. Each microservice runs in its process and the communication is made through lightweight mechanisms, usually HTTP resource API. These architectures are built upon independently deployable and, supposedly, reliable pieces of software that may, or may not, have been developed by the team using it. Nowadays, industries are dangerously migrating into microservice architectures without an effective and automatic process for testing the software being used. Furthermore, current API specification languages are not expressive enough to be used for testing purposes. To solve this problem it is necessary to extend currently broadly used API specification languages. APOSTL is a specification language to annotate APIs specifications based on first-order logic, with some restrictions. It has the purpose of extending the currently used API description languages with properties that can be useful for testing purposes, transforming these description documents into useful testing artefacts. Besides providing information needed for testing an application, APOSTL also provides an API with semantic. This additional information is then leveraged to automate microservice testing. The work developed in this thesis aims to fully automate the microservice testing process. It is achieved by the implementation of PETIT a tool able to test microservices when provided with an OpenAPI Specification document, written in JSON and properly annotated with the previously proposed specification language, APOSTL. The tool is able to analyze microservices independently from the source code availability."}
{"id": "2602.23413", "categories": ["cs.LG", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.23413", "abs": "https://arxiv.org/abs/2602.23413", "authors": ["Shu Liu", "Shubham Agarwal", "Monishwaran Maheswaran", "Mert Cemri", "Zhifei Li", "Qiuyang Mang", "Ashwin Naren", "Ethan Boneh", "Audrey Cheng", "Melissa Z. Pan", "Alexander Du", "Kurt Keutzer", "Alexandros G. Dimakis", "Koushik Sen", "Matei Zaharia", "Ion Stoica"], "title": "EvoX: Meta-Evolution for Automated Discovery", "comment": null, "summary": "Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks."}
{"id": "2602.23798", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23798", "abs": "https://arxiv.org/abs/2602.23798", "authors": ["Tiantong Wang", "Xinyu Yan", "Tiantong Wu", "Yurong Hao", "Yong Jiang", "Fei Huang", "Wei Yang Bryan Lim"], "title": "MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models", "comment": null, "summary": "Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU."}
{"id": "2602.23471", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23471", "abs": "https://arxiv.org/abs/2602.23471", "authors": ["Artur Gimranov", "Viacheslav Yusupov", "Elfat Sabitov", "Tatyana Matveeva", "Anton Lysenko", "Ruslan Israfilov", "Evgeny Frolov"], "title": "Cross-Representation Knowledge Transfer for Improved Sequential Recommendations", "comment": null, "summary": "Transformer architectures, capable of capturing sequential dependencies in the history of user interactions, have become the dominant approach in sequential recommender systems. Despite their success, such models consider sequence elements in isolation, implicitly accounting for the complex relationships between them. Graph neural networks, in contrast, explicitly model these relationships through higher order interactions but are often unable to adequately capture their evolution over time, limiting their use for predicting the next interaction. To fill this gap, we present a new framework that combines transformers and graph neural networks and aligns different representations for solving next-item prediction task. Our solution simultaneously encodes structural dependencies in the interaction graph and tracks their dynamic change. Experimental results on a number of open datasets demonstrate that the proposed framework consistently outperforms both pure sequential and graph approaches in terms of recommendation quality, as well as recent methods that combine both types of signals."}
{"id": "2602.23957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23957", "abs": "https://arxiv.org/abs/2602.23957", "authors": ["Alexander Berndt", "Zoltán Nochta", "Thomas Bach"], "title": "The Vocabulary of Flaky Tests in the Context of SAP HANA", "comment": "Accepted to ESEM IGC 2023", "summary": "Background. Automated test execution is an important activity to gather information about the quality of a software project. So-called flaky tests, however, negatively affect this process. Such tests fail seemingly at random without changes to the code and thus do not provide a clear signal. Previous work proposed to identify flaky tests based on the source code identifiers in the test code. So far, these approaches have not been evaluated in a large-scale industrial setting. Aims. We evaluate approaches to identify flaky tests and their root causes based on source code identifiers in the test code in a large-scale industrial project. Method. First, we replicate previous work by Pinto et al. in the context of SAP HANA. Second, we assess different feature extraction techniques, namely TF-IDF and TF-IDFC-RF. Third, we evaluate CodeBERT and XGBoost as classification models. For a sound comparison, we utilize both the data set from previous work and two data sets from SAP HANA. Results. Our replication shows similar results on the original data set and on one of the SAP HANA data sets. While the original approach yielded an F1-Score of 0.94 on the original data set and 0.92 on the SAP HANA data set, our extensions achieve F1-Scores of 0.96 and 0.99, respectively. The reliance on external data sources is a common root cause for test flakiness in the context of SAP HANA. Conclusions. The vocabulary of a large industrial project seems to be slightly different with respect to the exact terms, but the categories for the terms, such as remote dependencies, are similar to previous empirical findings. However, even with rather large F1-Scores, both finding source code identifiers for flakiness and a black box prediction have limited use in practice as the results are not actionable for developers."}
{"id": "2602.23446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23446", "abs": "https://arxiv.org/abs/2602.23446", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning", "comment": "Proceedings from IEEE CAI 2026, Conference on Artificial Intelligence, 8-10 May, Granada, Spain. 8 Pages, 3 Figures, 7 Tables", "summary": "Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error."}
{"id": "2602.23530", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23530", "abs": "https://arxiv.org/abs/2602.23530", "authors": ["Aditya Gaydhani", "Guangyue Xu", "Dhanush Kamath", "Ankit Singh", "Alex Li"], "title": "Unified Learning-to-Rank for Multi-Channel Retrieval in Large-Scale E-Commerce Search", "comment": null, "summary": "Large-scale e-commerce search must surface a broad set of items from a vast catalog, ranging from bestselling products to new, trending, or seasonal items. Modern systems therefore rely on multiple specialized retrieval channels to surface products, each designed to satisfy a specific objective. A key challenge is how to effectively merge documents from these heterogeneous channels into a single ranked list under strict latency constraints while optimizing for business KPIs such as user conversion. Rank-based fusion methods such as Reciprocal Rank Fusion (RRF) and Weighted Interleaving rely on fixed global channel weights and treat channels independently, failing to account for query-specific channel utility and cross-channel interactions. We observe that multi-channel fusion can be reformulated as a query-dependent learning-to-rank problem over heterogeneous candidate sources. In this paper, we propose a unified ranking model that learns to merge and rank documents from multiple retrieval channels. We formulate the problem as a channel-aware learning-to-rank task that jointly optimizes clicks, add-to-carts, and purchases while incorporating channel-specific objectives. We further incorporate recent user behavioral signals to capture short-term intent shifts that are critical for improving conversion in multi-channel ranking. Our online A/B experiments show that the proposed approach outperforms rank-based fusion methods, leading to a +2.85\\% improvement in user conversion. The model satisfies production latency requirements, achieving a p95 latency of under 50\\,ms, and is deployed on Target.com."}
{"id": "2602.24108", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.24108", "abs": "https://arxiv.org/abs/2602.24108", "authors": ["Yakun Zhang", "Zihan Wang", "Xinzhi Peng", "Zihao Xie", "Xiaodong Wang", "Xutao Li", "Dan Hao", "Lu Zhang", "Yunming Ye"], "title": "Context-Aware Functional Test Generation via Business Logic Extraction and Adaptation", "comment": null, "summary": "Functional testing is essential for verifying that the business logic of mobile applications aligns with user requirements, serving as the primary methodology for quality assurance in software development. Despite its importance, functional testing remains heavily dependent on manual effort due to two core challenges. First, acquiring and reusing complex business logic from unstructured requirements remains difficult, which hinders the understanding of specific functionalities. Second, a significant semantic gap exists when adapting business logic to the diverse GUI environments, which hinders the generation of test cases for specific mobile applications. To address the preceding challenges, we propose LogiDroid, a two-stage approach that generates individual functional test cases by extracting business logic and adapting it to target applications. First, in the Knowledge Retrieval and Fusion stage, we construct a dataset to retrieve relevant cases and extract business logic for the target functionality. Second, in the Context-Aware Test Generation stage, LogiDroid jointly analyzes the extracted business logic and the real-time GUI environment to generate functional test cases. This design allows LogiDroid to accurately understand application semantics and use domain expertise to generate complete test cases with verification assertions. We assess the effectiveness of LogiDroid using two widely-used datasets that cover 28 real-world applications and 190 functional requirements. Experimental results show that LogiDroid successfully tested 40% of functional requirements on the FrUITeR dataset (an improvement of over 48% compared to the state-of-the-art approaches) and 65% on the Lin dataset (an improvement of over 55% compared to the state-of-the-art approaches). These results demonstrate the significant effectiveness of LogiDroid in functional test generation."}
{"id": "2602.23459", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23459", "abs": "https://arxiv.org/abs/2602.23459", "authors": ["Eric V. Strobl"], "title": "Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires", "comment": null, "summary": "Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks."}
{"id": "2602.23620", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23620", "abs": "https://arxiv.org/abs/2602.23620", "authors": ["Gui Ling", "Weiyuan Li", "Yue Jiang", "Wenjun Peng", "Xingxian Liu", "Dongshuai Li", "Fuyu Lv", "Dan Ou", "Haihong Tang"], "title": "Synthetic Data Powers Product Retrieval for Long-tail Knowledge-Intensive Queries in E-commerce Search", "comment": null, "summary": "Product retrieval is the backbone of e-commerce search: for each user query, it identifies a high-recall candidate set from billions of items, laying the foundation for high-quality ranking and user experience. Despite extensive optimization for mainstream queries, existing systems still struggle with long-tail queries, especially knowledge-intensive ones. These queries exhibit diverse linguistic patterns, often lack explicit purchase intent, and require domain-specific knowledge reasoning for accurate interpretation. They also suffer from a shortage of reliable behavioral logs, which makes such queries a persistent challenge for retrieval optimization. To address these issues, we propose an efficient data synthesis framework tailored to retrieval involving long-tail, knowledge-intensive queries. The key idea is to implicitly distill the capabilities of a powerful offline query-rewriting model into an efficient online retrieval system. Leveraging the strong language understanding of LLMs, we train a multi-candidate query rewriting model with multiple reward signals and capture its rewriting capability in well-curated query-product pairs through a powerful offline retrieval pipeline. This design mitigates distributional shift in rewritten queries, which might otherwise limit incremental recall or introduce irrelevant products. Experiments demonstrate that without any additional tricks, simply incorporating this synthetic data into retrieval model training leads to significant improvements. Online Side-By-Side (SBS) human evaluation results indicate a notable enhancement in user search experience."}
{"id": "2602.23927", "categories": ["cs.DC", "cs.FL", "cs.MA", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.23927", "abs": "https://arxiv.org/abs/2602.23927", "authors": ["Laura Bocchi", "Raymond Hu", "Adriana Laura Voinea", "Simon Thompson"], "title": "Mixed Choice in Asynchronous Multiparty Session Types", "comment": null, "summary": "We present a multiparty session type (MST) framework with asynchronous mixed choice (MC). We propose a core construct for MC that allows transient inconsistencies in protocol state between distributed participants, but ensures all participants can always eventually reach a mutually consistent state. We prove the correctness of our system by establishing a progress property and an operational correspondence between global types and distributed local type projections. Based on our theory, we implement a practical toolchain for specifying and validating asynchronous MST protocols featuring MC, and programming compliant gen_statem processes in Erlang/OTP. We test our framework by using our toolchain to specify and reimplement part of the amqp_client of the RabbitMQ broker for Erlang."}
{"id": "2602.23495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23495", "abs": "https://arxiv.org/abs/2602.23495", "authors": ["Yangyi Li", "Mengdi Huai"], "title": "Uncertainty-aware Language Guidance for Concept Bottleneck Models", "comment": null, "summary": "Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods."}
{"id": "2602.23639", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23639", "abs": "https://arxiv.org/abs/2602.23639", "authors": ["Haibo Xing", "Hao Deng", "Lingyu Mu", "Jinxin Hu", "Yu Zhang", "Xiaoyi Zeng", "Jing Zhang"], "title": "Learning to Reflect and Correct: Towards Better Decoding Trajectories for Large-Scale Generative Recommendation", "comment": null, "summary": "Generative Recommendation (GR) has become a promising paradigm for large-scale recommendation systems. However, existing GR models typically perform single-pass decoding without explicit refinement, causing early deviations to accumulate and ultimately degrade recommendation quality. To tackle this problem, we propose GRC, which is, to our knowledge, the first structured reflection-correction framework for GR that extends standard decoding into a Generation-Reflection-Correction (GRC) process. Concretely, GRC introduces a supervised reflection-correction template that decomposes the decoding process into initial draft generation, multi-granular reflection, and reflection-guided correction, thereby enabling structured reflection and correction in the semantic token space. To further explore the enlarged refinement space introduced by the GRC process, we optimize the entire GRC trajectory with GRPO-based reinforcement learning, under a carefully designed reward function with token-level and trajectory-level signals. For efficient online serving, we propose an Entropy-Guided Reflection Scheduling (EGRS) strategy that dynamically allocates more correction budget to high-uncertainty decoding trajectories during beam search. Extensive experiments on real-world datasets show that GRC consistently outperforms six state-of-the-art baselines by up to 15.74%, and online A/B tests demonstrate its substantial practical value in large-scale industrial recommendation, delivering a 1.79% lift in advertising revenue with only modest latency overhead."}
{"id": "2602.23504", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23504", "abs": "https://arxiv.org/abs/2602.23504", "authors": ["Anik Pramanik", "Murat Kantarcioglu", "Vincent Oria", "Shantanu Sharma"], "title": "FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments", "comment": "This paper has been accepted in ICLR 2026", "summary": "Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy."}
{"id": "2602.23665", "categories": ["cs.IR", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.23665", "abs": "https://arxiv.org/abs/2602.23665", "authors": ["Brandon Yee", "Lucas Wang", "Kundana Kommini", "Krishna Sharma"], "title": "Geodesic Semantic Search: Learning Local Riemannian Metrics for Citation Graph Retrieval", "comment": null, "summary": "We present Geodesic Semantic Search (GSS), a retrieval system that learns node-specific Riemannian metrics on citation graphs to enable geometry-aware semantic search. Unlike standard embedding-based retrieval that relies on fixed Euclidean distances, \\gss{} learns a low-rank metric tensor $\\mL_i \\in \\R^{d \\times r}$ at each node, inducing a local positive semi-definite metric $\\mG_i = \\mL_i \\mL_i^\\top + \\eps \\mI$. This parameterization guarantees valid metrics while keeping the model tractable. Retrieval proceeds via multi-source Dijkstra on the learned geodesic distances, followed by Maximal Marginal Relevance reranking and path coherence filtering. On citation prediction benchmarks with 169K papers, \\gss{} achieves 23\\% relative improvement in Recall@20 over SPECTER+FAISS baselines while providing interpretable citation paths. Our hierarchical coarse-to-fine search with k-means pooling reduces computational cost by 4$\\times$ compared to flat geodesic search while maintaining 97\\% retrieval quality. We provide theoretical analysis of when geodesic distances outperform direct similarity, characterize the approximation quality of low-rank metrics, and validate predictions empirically. Code and trained models are available at https://github.com/YCRG-Labs/geodesic-search."}
{"id": "2602.23507", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.23507", "abs": "https://arxiv.org/abs/2602.23507", "authors": ["Diana Shamsutdinova", "Felix Zimmer", "Oyebayo Ridwan Olaniran", "Sarah Markham", "Daniel Stahl", "Gordon Forbes", "Ewan Carr"], "title": "Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package", "comment": "26 pages, 4 figures, 1 table, preprint", "summary": "Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures."}
{"id": "2602.23671", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23671", "abs": "https://arxiv.org/abs/2602.23671", "authors": ["Yufei Ye", "Wei Guo", "Hao Wang", "Luankang Zhang", "Heng Chang", "Hong Zhu", "Yuyang Ye", "Yong Liu", "Defu Lian", "Enhong Chen"], "title": "FuXi-Linear: Unleashing the Power of Linear Attention in Long-term Time-aware Sequential Recommendation", "comment": null, "summary": "Modern recommendation systems primarily rely on attention mechanisms with quadratic complexity, which limits their ability to handle long user sequences and slows down inference. While linear attention is a promising alternative, existing research faces three critical challenges: (1) temporal signals are often overlooked or integrated via naive coupling that causes mutual interference between temporal and semantic signals while neglecting behavioral periodicity; (2) insufficient positional information provided by existing linear frameworks; and (3) a primary focus on short sequences and shallow architectures. To address these issues, we propose FuXi-Linear, a linear-complexity model designed for efficient long-sequence recommendation. Our approach introduces two key components: (1) a Temporal Retention Channel that independently computes periodic attention weights using temporal data, preventing crosstalk between temporal and semantic signals; (2) a Linear Positional Channel that integrates positional information through learnable kernels within linear complexity. Moreover, we demonstrate that FuXi-Linear exhibits a robust power-law scaling property at a thousand-length scale, a characteristic largely unexplored in prior linear recommendation studies. Extensive experiments on sequences of several thousand tokens demonstrate that FuXi-Linear outperforms state-of-the-art models in recommendation quality, while achieving up to 10$\\times$ speedup in the prefill stage and up to 21$\\times$ speedup in the decode stage compared to competitive baselines. Our code has been released in a public repository https://github.com/USTC-StarTeam/fuxi-linear."}
{"id": "2602.23528", "categories": ["cs.LG", "cs.CE", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.23528", "abs": "https://arxiv.org/abs/2602.23528", "authors": ["Yicen Li", "Jose Antonio Lara Benitez", "Ruiyang Hong", "Anastasis Kratsios", "Paul David McNicholas", "Maarten Valentijn de Hoop"], "title": "Neural Operators Can Discover Functional Clusters", "comment": null, "summary": "Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.\n  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory."}
{"id": "2602.23717", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23717", "abs": "https://arxiv.org/abs/2602.23717", "authors": ["Hao Li", "Kedar Bellare", "Siyu Yang", "Sherry Chen", "Liwei He", "Stephanie Moyerman", "Sanjeev Katariya"], "title": "Recommending Search Filters To Improve Conversions At Airbnb", "comment": null, "summary": "Airbnb, a two-sided online marketplace connecting guests and hosts, offers a diverse and unique inventory of accommodations, experiences, and services. Search filters play an important role in helping guests navigate this variety by refining search results to align with their needs. Yet, while search filters are designed to facilitate conversions in online marketplaces, their direct impact on driving conversions remains underexplored in the existing literature.\n  This paper bridges this gap by presenting a novel application of machine learning techniques to recommend search filters aimed at improving booking conversions. We introduce a modeling framework that directly targets lower-funnel conversions (bookings) by recommending intermediate tools, i.e. search filters. Leveraging the framework, we designed and built the filter recommendation system at Airbnb from the ground up, addressing challenges like cold start and stringent serving requirements.\n  The filter recommendation system we developed has been successfully deployed at Airbnb, powering multiple user interfaces and driving incremental booking conversion lifts, as validated through online A/B testing. An ablation study further validates the effectiveness of our approach and key design choices. By focusing on conversion-oriented filter recommendations, our work ensures that search filters serve their ultimate purpose at Airbnb - helping guests find and book their ideal accommodations."}
{"id": "2602.23529", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23529", "abs": "https://arxiv.org/abs/2602.23529", "authors": ["Martin Černý", "David Sychrovský", "Filip Úradník", "Jakub Černý"], "title": "Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning", "comment": null, "summary": "Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios."}
{"id": "2602.23766", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23766", "abs": "https://arxiv.org/abs/2602.23766", "authors": ["Zheng Dou", "Zhao Zhang", "Deqing Wang", "Yikun Ban", "Fuzhen Zhuang"], "title": "UniFAR: A Unified Facet-Aware Retrieval Framework for Scientific Documents", "comment": null, "summary": "Existing scientific document retrieval (SDR) methods primarily rely on document-centric representations learned from inter-document relationships for document-document (doc-doc) retrieval. However, the rise of LLMs and RAG has shifted SDR toward question-driven retrieval, where documents are retrieved in response to natural-language questions (q-doc). This change has led to systematic mismatches between document-centric models and question-driven retrieval, including (1) input granularity (long documents vs. short questions), (2) semantic focus (scientific discourse structure vs. specific question intent), and (3) training signals (citation-based similarity vs. question-oriented relevance). To this end, we propose UniFAR, a Unified Facet-Aware Retrieval framework to jointly support doc-doc and q-doc SDR within a single architecture. UniFAR reconciles granularity differences through adaptive multi-granularity aggregation, aligns document structure with question intent via learnable facet anchors, and unifies doc-doc and q-doc supervision through joint training. Experimental results show that UniFAR consistently outperforms prior methods across multiple retrieval tasks and base models, confirming its effectiveness and generality."}
{"id": "2602.23556", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.MA", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.23556", "abs": "https://arxiv.org/abs/2602.23556", "authors": ["Aishwarya Sarkar", "Sayan Ghosh", "Nathan Tallent", "Aman Chadha", "Tanya Roosta", "Ali Jannesari"], "title": "Rudder: Steering Prefetching in Distributed GNN Training using LLM Agents", "comment": "Accepted to the 40th ACM International Conference on Supercomputing (ICS 2026)", "summary": "Large-scale Graph Neural Networks (GNNs) are typically trained by sampling a vertex's neighbors to a fixed distance. Because large input graphs are distributed, training requires frequent irregular communication that stalls forward progress. Moreover, fetched data changes with graph, graph distribution, sample and batch parameters, and caching polices. Consequently, any static prefetching method will miss crucial opportunities to adapt to different dynamic conditions. In this paper, we introduce Rudder, a software module embedded in the state-of-the-art AWS DistDGL framework, to autonomously prefetch remote nodes and minimize communication. Rudder's adaptation contrasts with both standard heuristics and traditional ML classifiers. We observe that the generative AI found in contemporary Large Language Models (LLMs) exhibits emergent properties like In-Context Learning (ICL) for zero-shot tasks, with logical multi-step reasoning. We find this behavior well-suited for adaptive control even with substantial undertraining. Evaluations using standard datasets and unseen configurations on the NERSC Perlmutter supercomputer show up to 91% improvement in end-to-end training performance over baseline DistDGL (no prefetching), and an 82% improvement over static prefetching, reducing communication by over 50%. Our code is available at https://github.com/aishwaryyasarkar/rudder-llm-agent."}
{"id": "2602.23949", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23949", "abs": "https://arxiv.org/abs/2602.23949", "authors": ["Guy Hadad", "Shadi Iskander", "Oren Kalinsky", "Sofia Tolmach", "Ran Levy", "Haggai Roitman"], "title": "HotelQuEST: Balancing Quality and Efficiency in Agentic Search", "comment": "To be published in EACL 2026", "summary": "Agentic search has emerged as a promising paradigm for adaptive retrieval systems powered by large language models (LLMs). However, existing benchmarks primarily focus on quality, overlooking efficiency factors that are critical for real-world deployment. Moreover, real-world user queries often contain underspecified preferences, a challenge that remains largely underexplored in current agentic search evaluation. As a result, many agentic search systems remain impractical despite their impressive performance. In this work, we introduce HotelQuEST, a benchmark comprising 214 hotel search queries that range from simple factual requests to complex queries, enabling evaluation across the full spectrum of query difficulty. We further address the challenge of evaluating underspecified user preferences by collecting clarifications that make annotators' implicit preferences explicit for evaluation. We find that LLM-based agents achieve higher accuracy than traditional retrievers, but at substantially higher costs due to redundant tool calls and suboptimal routing that fails to match query complexity to model capability. Our analysis exposes inefficiencies in current agentic search systems and demonstrates substantial potential for cost-aware optimization."}
{"id": "2602.23565", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.23565", "abs": "https://arxiv.org/abs/2602.23565", "authors": ["Adhyyan Narang", "Sarah Dean", "Lillian J Ratliff", "Maryam Fazel"], "title": "Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing", "comment": null, "summary": "In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the \"local\" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to \"probe\" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets."}
{"id": "2602.23964", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23964", "abs": "https://arxiv.org/abs/2602.23964", "authors": ["Zhiguo Chen", "Guohao Sun", "Yiming Qiu", "Xingzhi Yao", "Mingming Li", "Huimu Wang", "Yangqi Zhang", "Songlin Wang", "Sulong Xu"], "title": "RAD-DPO: Robust Adaptive Denoising Direct Preference Optimization for Generative Retrieval in E-commerce", "comment": null, "summary": "Generative Retrieval (GR) has emerged as a powerful paradigm in e-commerce search, retrieving items via autoregressive decoding of Semantic IDs (SIDs). However, aligning GR with complex user preferences remains challenging. While Direct Preference Optimization (DPO) offers an efficient alignment solution, its direct application to structured SIDs suffers from three limitations: (i) it penalizes shared hierarchical prefixes, causing gradient conflicts; (ii) it is vulnerable to noisy pseudo-negatives from implicit feedback; and (iii) in multi-label queries with multiple relevant items, it exacerbates a probability \"squeezing effect\" among valid candidates. To address these issues, we propose RAD-DPO, which introduces token-level gradient detachment to protect prefix structures, similarity-based dynamic reward weighting to mitigate label noise, and a multi-label global contrastive objective integrated with global SFT loss to explicitly expand positive coverage. Extensive offline experiments and online A/B testing on a large-scale e-commerce platform demonstrate significant improvements in ranking quality and training efficiency."}
{"id": "2602.23566", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23566", "abs": "https://arxiv.org/abs/2602.23566", "authors": ["Asiri Wijesinghe", "Sevvandi Kandanaarachchi", "Daniel M. Steinberg", "Cheng Soon Ong"], "title": "Flowette: Flow Matching with Graphette Priors for Graph Generation", "comment": "37 Pages", "summary": "We study generative modeling of graphs with recurring subgraph motifs. We propose Flowette, a continuous flow matching framework, that employs a graph neural network based transformer to learn a velocity field defined over graph representations with node and edge attributes. Our model preserves topology through optimal transport based coupling, and long-range structural dependencies through regularisation. To incorporate domain driven structural priors, we introduce graphettes, a new probabilistic family of graph structure models that generalize graphons via controlled structural edits for motifs like rings, stars and trees. We theoretically analyze the coupling, invariance, and structural properties of the proposed framework, and empirically evaluate it on synthetic and small-molecule graph generation tasks. Flowette demonstrates consistent improvements, highlighting the effectiveness of combining structural priors with flow-based training for modeling complex graph distributions."}
{"id": "2602.23978", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23978", "abs": "https://arxiv.org/abs/2602.23978", "authors": ["Huimu Wang", "Xingzhi Yao", "Yiming Qiu", "Qinghong Zhang", "Haotian Wang", "Yufan Cui", "Songlin Wang", "Sulong Xu", "Mingming Li"], "title": "Towards Efficient and Generalizable Retrieval: Adaptive Semantic Quantization and Residual Knowledge Transfer", "comment": null, "summary": "While semantic ID-based generative retrieval enables efficient end-to-end modeling in industrial applications, these methods face a persistent trade-off: head items are susceptible to ID collisions that negatively impact downstream tasks, whereas data-sparse tail items, including cold-start items, exhibit limited generalization. To address this issue, we propose the Anchored Curriculum with Sequential Adaptive Quantization (SA^2CRQ) framework. The framework introduces Sequential Adaptive Residual Quantization (SARQ) to dynamically allocate code lengths based on item path entropy, assigning longer, discriminative IDs to head items and shorter, generalizable IDs to tail items. To mitigate data sparsity, the Anchored Curriculum Residual Quantization (ACRQ) component utilizes a frozen semantic manifold learned from head items to regularize and accelerate the representation learning of tail items. Experimental results from a large-scale industrial search system and multiple public datasets indicate that SA^2CRQ yields consistent improvements over existing baselines, particularly in cold-start retrieval scenarios."}
{"id": "2602.23578", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23578", "abs": "https://arxiv.org/abs/2602.23578", "authors": ["Junghoon Justin Park", "Maria Pak", "Sebin Lee", "Samuel Yen-Chi Chen", "Shinjae Yoo", "Huan-Hsin Tseng", "Jiook Cha"], "title": "Hybrid Quantum Temporal Convolutional Networks", "comment": null, "summary": "Quantum machine learning models for sequential data face scalability challenges with complex multivariate signals. We introduce the Hybrid Quantum Temporal Convolutional Network (HQTCN), which combines classical temporal windowing with a quantum convolutional neural network core. By applying a shared quantum circuit across temporal windows, HQTCN captures long-range dependencies while achieving significant parameter reduction. Evaluated on synthetic NARMA sequences and high-dimensional EEG time-series, HQTCN performs competitively with classical baselines on univariate data and outperforms all baselines on multivariate tasks. The model demonstrates particular strength under data-limited conditions, maintaining high performance with substantially fewer parameters than conventional approaches. These results establish HQTCN as a parameter-efficient approach for multivariate time-series analysis."}
{"id": "2602.23982", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23982", "abs": "https://arxiv.org/abs/2602.23982", "authors": ["Minh Hieu Nguyen"], "title": "Robust Aggregation for Federated Sequential Recommendation with Sparse and Poisoned Data", "comment": null, "summary": "Federated sequential recommendation distributes model training across user devices so that behavioural data remains local, reducing privacy risks. Yet, this setting introduces two intertwined difficulties. On the one hand, individual clients typically contribute only short and highly sparse interaction sequences, limiting the reliability of learned user representations. On the other hand, the federated optimisation process is vulnerable to malicious or corrupted client updates, where poisoned gradients can significantly distort the global model. These challenges are particularly severe in sequential recommendation, where temporal dynamics further complicate signal aggregation. To address this problem, we propose a robust aggregation framework tailored for federated sequential recommendation under sparse and adversarial conditions. Instead of relying on standard averaging, our method introduces a defence-aware aggregation mechanism that identifies and down-weights unreliable client updates while preserving informative signals from sparse but benign participants. The framework incorporates representation-level constraints to stabilise user and item embeddings, preventing poisoned or anomalous contributions from dominating the global parameter space. In addition, we integrate sequence-aware regularisation to maintain temporal coherence in user modelling despite limited local observations."}
{"id": "2602.23581", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23581", "abs": "https://arxiv.org/abs/2602.23581", "authors": ["Xiang Ao"], "title": "SDMixer: Sparse Dual-Mixer for Time Series Forecasting", "comment": "12pages,2 figures", "summary": "Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer"}
{"id": "2602.24067", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24067", "abs": "https://arxiv.org/abs/2602.24067", "authors": ["Thom Vaughan", "Pedro Ortiz Suarez"], "title": "Colour Contrast on the Web: A WCAG 2.1 Level AA Compliance Audit of Common Crawl's Top 500 Domains", "comment": "8 pages, 4 tables. Companion website and reproducible analysis code available at https://thunderpoot.github.io/wcag-audit/ and https://github.com/thunderpoot/wcag-audit", "summary": "We present a large-scale automated audit of WCAG 2.1/2.2 Level AA colour contrast compliance across the 500 most frequently crawled registered domains in Common Crawl's CC-MAIN-2026-08 February 2026 crawl archive. Rather than conducting a live crawl, all page content was sourced from Common Crawl's open WARC archives, ensuring reproducibility and eliminating any load on target web servers. Our static CSS analysis of 240 homepages identified 4,327 unique foreground/background colour pairings, of which 1,771 (40.9%) failed to meet the 4.5:1 contrast ratio threshold for normal text. The median per-site pass rate was 62.7%, with 20.4% of sites achieving full compliance across all detected colour pairings. These findings suggest that colour contrast remains a widespread accessibility barrier on the most prominent websites, with significant variation across domain categories."}
{"id": "2602.23599", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23599", "abs": "https://arxiv.org/abs/2602.23599", "authors": ["Dang Sy Duy", "Nguyen Duy Chien", "Kapil Dev", "Jeff Nijsse"], "title": "Normalisation and Initialisation Strategies for Graph Neural Networks in Blockchain Anomaly Detection", "comment": "14 pages, 5 figures", "summary": "Graph neural networks (GNNs) offer a principled approach to financial fraud detection by jointly learning from node features and transaction graph topology. However, their effectiveness on real-world anti-money laundering (AML) benchmarks depends critically on training practices such as specifically weight initialisation and normalisation that remain underexplored. We present a systematic ablation of initialisation and normalisation strategies across three GNN architectures (GCN, GAT, and GraphSAGE) on the Elliptic Bitcoin dataset. Our experiments reveal that initialisation and normalisation are architecture-dependent: GraphSAGE achieves the strongest performance with Xavier initialisation alone, GAT benefits most from combining GraphNorm with Xavier initialisation, while GCN shows limited sensitivity to these modifications. These findings offer practical, architecture-specific guidance for deploying GNNs in AML pipelines for datasets with severe class imbalance. We release a reproducible experimental framework with temporal data splits, seeded runs, and full ablation results."}
{"id": "2602.24125", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24125", "abs": "https://arxiv.org/abs/2602.24125", "authors": ["Rohit Chivukula", "T. Jaya Lakshmi", "Hemlata Sharma", "C. H. S. N. P. Sairam Rallabandi"], "title": "Recommendation Algorithms: A Comparative Study in Movie Domain", "comment": null, "summary": "Intelligent recommendation systems have clearly increased the revenue of well-known e-commerce firms. Users receive product recommendations from recommendation systems. Cinematic recommendations are made to users by a movie recommendation system. There have been numerous approaches to the problem of recommendation in the literature. It is viewed as a regression task in this research. A regression model was built using novel properties extracted from the dataset and used as features in the model. For experimentation, the Netflix challenge dataset has been used. Video streaming service Netflix is a popular choice for many. Customers' prior viewing habits are taken into account when Netflix makes movie recommendations to them. An exploratory data analysis on the Netflix dataset was conducted to gain insights into user rating behaviour and movie characteristics. Various kinds of features, including aggregating, Matrix Factorization (MF) based, and user and movie similarity based, have been extracted in the subsequent stages. In addition to a feature in the XGBoost regression algorithm, the K-Nearest Neighbors and MF algorithms from Python's Surprise library are used for recommendations. Based on Root Mean Square Error (RMSE), MF-based algorithms have provided the best recommendations."}
{"id": "2602.23614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23614", "abs": "https://arxiv.org/abs/2602.23614", "authors": ["Kejing Yin", "Haizhou Xu", "Wenfang Yao", "Chen Liu", "Zijie Chen", "Yui Haang Cheung", "William K. Cheung", "Jing Qin"], "title": "When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion", "comment": null, "summary": "Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench."}
{"id": "2602.24229", "categories": ["cs.IR", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.24229", "abs": "https://arxiv.org/abs/2602.24229", "authors": ["Włodzimierz Lewoniewski", "Milena Stróżyna", "Izabela Czumałowska", "Elżbieta Lewańska"], "title": "Science Fiction and Fantasy in Wikipedia: Exploring Structural and Semantic Cues", "comment": "Supplementary materials: https://data.lewoniewski.info/fantasy/", "summary": "Identifying which Wikipedia articles are related to science fiction, fantasy, or their hybrids is challenging because genre boundaries are porous and frequently overlap. Wikipedia nonetheless offers machine-readable structure beyond text, including categories, internal links (wikilinks), and statements if corresponding Wikidata items. However, each of these signals reflects community conventions and can be biased or incomplete. This study examines structural and semantic features of Wikipedia articles that can be used to identify content related to science fiction and fantasy (SF/F)."}
{"id": "2602.23630", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23630", "abs": "https://arxiv.org/abs/2602.23630", "authors": ["Zhongyi Pei", "Zhiyao Cen", "Yipeng Huang", "Chen Wang", "Lin Liu", "Philip Yu", "Mingsheng Long"], "title": "BTTackler: A Diagnosis-based Framework for Efficient Deep Learning Hyperparameter Optimization", "comment": null, "summary": "Hyperparameter optimization (HPO) is known to be costly in deep learning, especially when leveraging automated approaches. Most of the existing automated HPO methods are accuracy-based, i.e., accuracy metrics are used to guide the trials of different hyperparameter configurations amongst a specific search space. However, many trials may encounter severe training problems, such as vanishing gradients and insufficient convergence, which can hardly be reflected by accuracy metrics in the early stages of the training and often result in poor performance. This leads to an inefficient optimization trajectory because the bad trials occupy considerable computation resources and reduce the probability of finding excellent hyperparameter configurations within a time limitation. In this paper, we propose \\textbf{Bad Trial Tackler (BTTackler)}, a novel HPO framework that introduces training diagnosis to identify training problems automatically and hence tackles bad trials. BTTackler diagnoses each trial by calculating a set of carefully designed quantified indicators and triggers early termination if any training problems are detected. Evaluations are performed on representative HPO tasks consisting of three classical deep neural networks (DNN) and four widely used HPO methods. To better quantify the effectiveness of an automated HPO method, we propose two new measurements based on accuracy and time consumption. Results show the advantage of BTTackler on two-fold: (1) it reduces 40.33\\% of time consumption to achieve the same accuracy comparable to baseline methods on average and (2) it conducts 44.5\\% more top-10 trials than baseline methods on average within a given time budget. We also released an open-source Python library that allows users to easily apply BTTackler to automated HPO processes with minimal code changes."}
{"id": "2602.24241", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24241", "abs": "https://arxiv.org/abs/2602.24241", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "UXSim: Towards a Hybrid User Search Simulation", "comment": null, "summary": "Simulating nuanced user experiences within complex interactive search systems poses distinct challenge for traditional methodologies, which often rely on static user proxies or, more recently, on standalone large language model (LLM) agents that may lack deep, verifiable grounding. The true dynamism and personalization inherent in human-computer interaction demand a more integrated approach. This work introduces UXSim, a novel framework that integrates both approaches. It leverages grounded data from traditional simulators to inform and constrain the reasoning of an adaptive LLM agent. This synthesis enables more accurate and dynamic simulations of user behavior while also providing a pathway for the explainable validation of the underlying cognitive processes."}
{"id": "2602.23633", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23633", "abs": "https://arxiv.org/abs/2602.23633", "authors": ["Yubo Zhou", "Luo Luo", "Guang Dai", "Haishan Ye"], "title": "On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation", "comment": null, "summary": "Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $κ$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $ε$-stationary point with an oracle complexity of $\\mathcal{O}(κ^7 ε^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\\mathcal{O}(ε^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $κ$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks."}
{"id": "2602.24265", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.24265", "abs": "https://arxiv.org/abs/2602.24265", "authors": ["Saber Zerhoudi", "Michael Granitzer"], "title": "Beyond the Click: A Framework for Inferring Cognitive Traces in Search", "comment": null, "summary": "User simulators are essential for evaluating search systems, but they primarily copy user actions without understanding the underlying thought process. This gap exists since large-scale interaction logs record what users do, but not what they might be thinking or feeling, such as confusion or satisfaction. To solve this problem, we present a framework to infer cognitive traces from behavior logs. Our method uses a multi-agent system grounded in Information Foraging Theory (IFT) and human expert judgment. These traces improve model performance on tasks like forecasting session outcomes and user struggle recovery. We release a collection of annotations for several public datasets, including AOL and Stack Overflow, and an open-source tool that allows researchers to apply our method to their own data. This work provides the tools and data needed to build more human-like user simulators and to assess retrieval systems on user-oriented dimensions of performance."}
{"id": "2602.23636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23636", "abs": "https://arxiv.org/abs/2602.23636", "authors": ["Zhihao Ding", "Jinming Li", "Ze Lu", "Jieming Shi"], "title": "FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation", "comment": null, "summary": "Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility."}
{"id": "2602.24277", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24277", "abs": "https://arxiv.org/abs/2602.24277", "authors": ["Dake Zhang", "Mark D. Smucker", "Charles L. A. Clarke"], "title": "Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment", "comment": null, "summary": "Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $τ= 0.678$ for Task 1 and $τ= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation."}
{"id": "2602.23638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23638", "abs": "https://arxiv.org/abs/2602.23638", "authors": ["Haoran Zhang", "Dongjun Kim", "Seohyeon Cha", "Haris Vikalo"], "title": "FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA", "comment": "preprint", "summary": "Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks."}
{"id": "2602.23999", "categories": ["cs.DB", "cs.DS", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.23999", "abs": "https://arxiv.org/abs/2602.23999", "authors": ["Jifan Shi", "Jianyang Gao", "James Xia", "Tamás Béla Fehér", "Cheng Long"], "title": "GPU-Native Approximate Nearest Neighbor Search with IVF-RaBitQ: Fast Index Build and Search", "comment": null, "summary": "Approximate nearest neighbor search (ANNS) on GPUs is gaining increasing popularity for modern retrieval and recommendation workloads that operate over massive high-dimensional vectors. Graph-based indexes deliver high recall and throughput but incur heavy build-time and storage costs. In contrast, cluster-based methods build and scale efficiently yet often need many probes for high recall, straining memory bandwidth and compute. Aiming to simultaneously achieve fast index build, high-throughput search, high recall, and low storage requirement for GPUs, we present IVF-RaBitQ (GPU), a GPU-native ANNS solution that integrates the cluster-based method IVF with RaBitQ quantization into an efficient GPU index build/search pipeline. Specifically, for index build, we develop a scalable GPU-native RaBitQ quantization method that enables fast and accurate low-bit encoding at scale. For search, we develop GPU-native distance computation schemes for RaBitQ codes and a fused search kernel to achieve high throughput with high recall. With IVF-RaBitQ implemented and integrated into the NVIDIA cuVS Library, experiments on cuVS Bench across multiple datasets show that IVF-RaBitQ offers a strong performance frontier in recall, throughput, index build time, and storage footprint. For Recall approximately equal to 0.95, IVF-RaBitQ achieves 2.2x higher QPS than the state-of-the-art graph-based method CAGRA, while also constructing indices 7.7x faster on average. Compared to the cluster-based method IVF-PQ, IVF-RaBitQ delivers on average over 2.7x higher throughput while avoiding accessing the raw vectors for reranking."}
{"id": "2602.23662", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23662", "abs": "https://arxiv.org/abs/2602.23662", "authors": ["Kohei Obata", "Zheng Chen", "Yasuko Matsubara", "Lingwei Zhu", "Yasushi Sakurai"], "title": "Selective Denoising Diffusion Model for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD."}
{"id": "2602.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23663", "abs": "https://arxiv.org/abs/2602.23663", "authors": ["Kohei Obata", "Taichi Murayama", "Zheng Chen", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning", "comment": null, "summary": "Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST."}
{"id": "2602.23696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23696", "abs": "https://arxiv.org/abs/2602.23696", "authors": ["Yongzhong Xu"], "title": "Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training", "comment": "18 pages, 4 figures", "summary": "We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone."}
{"id": "2602.23737", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23737", "abs": "https://arxiv.org/abs/2602.23737", "authors": ["Hanping Zhang", "Yuhong Guo"], "title": "Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning", "comment": null, "summary": "Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts."}
{"id": "2602.23761", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23761", "abs": "https://arxiv.org/abs/2602.23761", "authors": ["Yuyu Geng", "Lei Sun", "Yao Gao", "Xinxin Hu", "Zhonghua Yi", "Xiaolong Qian", "Weijian Hu", "Jian Bai", "Kaiwei Wang"], "title": "OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design", "comment": null, "summary": "Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method."}
{"id": "2602.23770", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23770", "abs": "https://arxiv.org/abs/2602.23770", "authors": ["Chenxing Lin", "Xinhui Gao", "Haipeng Zhang", "Xinran Li", "Haitao Wang", "Songzhu Mei", "Chenglu Wen", "Weiquan Liu", "Siqi Shen", "Cheng Wang"], "title": "MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning", "comment": "ICLR2026", "summary": "Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings."}
{"id": "2602.23784", "categories": ["cs.LG", "cs.AI", "q-fin.CP", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2602.23784", "abs": "https://arxiv.org/abs/2602.23784", "authors": ["Maxime Kawawa-Beaudan", "Srijan Sood", "Kassiani Papasotiriou", "Daniel Borrajo", "Manuela Veloso"], "title": "TradeFM: A Generative Foundation Model for Trade-flow and Market Microstructure", "comment": "29 pages, 17 figures, 6 tables. Preprint", "summary": "Foundation models have transformed domains from language to genomics by learning general-purpose representations from large-scale, heterogeneous data. We introduce TradeFM, a 524M-parameter generative Transformer that brings this paradigm to market microstructure, learning directly from billions of trade events across >9K equities. To enable cross-asset generalization, we develop scale-invariant features and a universal tokenization scheme that map the heterogeneous, multi-modal event stream of order flow into a unified discrete sequence -- eliminating asset-specific calibration. Integrated with a deterministic market simulator, TradeFM-generated rollouts reproduce key stylized facts of financial returns, including heavy tails, volatility clustering, and absence of return autocorrelation. Quantitatively, TradeFM achieves 2-3x lower distributional error than Compound Hawkes baselines and generalizes zero-shot to geographically out-of-distribution APAC markets with moderate perplexity degradation. Together, these results suggest that scale-invariant trade representations capture transferable structure in market microstructure, opening a path toward synthetic data generation, stress testing, and learning-based trading agents."}
{"id": "2602.23785", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23785", "abs": "https://arxiv.org/abs/2602.23785", "authors": ["Zhiwei Han", "Stefan Matthes", "Hao Shen"], "title": "Provable Subspace Identification of Nonlinear Multi-view CCA", "comment": null, "summary": "We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \\geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions."}
{"id": "2602.23789", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23789", "abs": "https://arxiv.org/abs/2602.23789", "authors": ["Aleksandr Ananikian", "Daniil Drozdov", "Konstantin Yakovlev"], "title": "UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding", "comment": null, "summary": "The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\\unicode{x2013}$ a milestone reached for the first time by a learnable solver."}
{"id": "2602.23795", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23795", "abs": "https://arxiv.org/abs/2602.23795", "authors": ["Wenwu Tang", "Dong Wang", "Lothar Thiele", "Olga Saukh"], "title": "GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks", "comment": "Conference on Parsimony and Learning (CPAL)", "summary": "Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL."}
{"id": "2602.23798", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.23798", "abs": "https://arxiv.org/abs/2602.23798", "authors": ["Tiantong Wang", "Xinyu Yan", "Tiantong Wu", "Yurong Hao", "Yong Jiang", "Fei Huang", "Wei Yang Bryan Lim"], "title": "MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models", "comment": null, "summary": "Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU."}
{"id": "2602.23804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23804", "abs": "https://arxiv.org/abs/2602.23804", "authors": ["Andreas Kernbach", "Amr Elsheikh", "Nicolas Grupp", "René Nagel", "Marco F. Huber"], "title": "Actor-Critic Pretraining for Proximal Policy Optimization", "comment": null, "summary": "Reinforcement learning (RL) actor-critic algorithms enable autonomous learning but often require a large number of environment interactions, which limits their applicability in robotics. Leveraging expert data can reduce the number of required environment interactions. A common approach is actor pretraining, where the actor network is initialized via behavioral cloning on expert demonstrations and subsequently fine-tuned with RL. In contrast, the initialization of the critic network has received little attention, despite its central role in policy optimization. This paper proposes a pretraining approach for actor-critic algorithms like Proximal Policy Optimization (PPO) that uses expert demonstrations to initialize both networks. The actor is pretrained via behavioral cloning, while the critic is pretrained using returns obtained from rollouts of the pretrained policy. The approach is evaluated on 15 simulated robotic manipulation and locomotion tasks. Experimental results show that actor-critic pretraining improves sample efficiency by 86.1% on average compared to no pretraining and by 30.9% to actor-only pretraining."}
{"id": "2602.23811", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23811", "abs": "https://arxiv.org/abs/2602.23811", "authors": ["Xiang Li", "Nan Jiang", "Yuheng Zhang"], "title": "Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies", "comment": null, "summary": "We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning."}
{"id": "2602.23816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23816", "abs": "https://arxiv.org/abs/2602.23816", "authors": ["George Papadopoulos", "George A. Vouros"], "title": "Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective", "comment": "Accepted for publication at AAMAS 2026", "summary": "Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise\" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits."}
{"id": "2602.23824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23824", "abs": "https://arxiv.org/abs/2602.23824", "authors": ["Pavlin G. Poličar", "Dalibor Stanimirović", "Blaž Zupan"], "title": "Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach", "comment": null, "summary": "Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference."}
{"id": "2602.23827", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23827", "abs": "https://arxiv.org/abs/2602.23827", "authors": ["Junkang Liu", "Fanhua Shang", "Yuxuan Tian", "Hongying Liu", "Yuanyuan Liu"], "title": "FedNSAM:Consistency of Local and Global Flatness for Federated Learning", "comment": null, "summary": "In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \\textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \\textbf{flatness distance}, we propose a novel \\textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \\textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \\textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM."}
{"id": "2602.23852", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.23852", "abs": "https://arxiv.org/abs/2602.23852", "authors": ["Zhaowen Wang", "Dongdong Zhou", "Qi Xu", "Fengyu Cong", "Mohammad Al-Sa'd", "Jenni Raitoharju"], "title": "ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring", "comment": "Accepted to ICASSP 2026", "summary": "Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET."}
{"id": "2602.23880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23880", "abs": "https://arxiv.org/abs/2602.23880", "authors": ["Zhang Wan", "Tingting Mu", "Samuel Kaski"], "title": "A Theory of Random Graph Shift in Truncated-Spectrum vRKHS", "comment": null, "summary": "This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations."}
{"id": "2602.23881", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.23881", "abs": "https://arxiv.org/abs/2602.23881", "authors": ["Alexander Samarin", "Sergei Krutikov", "Anton Shevtsov", "Sergei Skvortsov", "Filipp Fisin", "Alexander Golubev"], "title": "LK Losses: Direct Acceptance Rate Optimization for Speculative Decoding", "comment": null, "summary": "Speculative decoding accelerates autoregressive large language model (LLM) inference by using a lightweight draft model to propose candidate tokens that are then verified in parallel by the target model. The speedup is significantly determined by the acceptance rate, yet standard training minimizes Kullback-Leibler (KL) divergence as a proxy objective. While KL divergence and acceptance rate share the same global optimum, small draft models, having limited capacity, typically converge to suboptimal solutions where minimizing KL does not guarantee maximizing acceptance rate. To address this issue, we propose LK losses, special training objectives that directly target acceptance rate. Comprehensive experiments across four draft architectures and six target models, ranging from 8B to 685B parameters, demonstrate consistent improvements in acceptance metrics across all configurations compared to the standard KL-based training. We evaluate our approach on general, coding and math domains and report gains of up to 8-10% in average acceptance length. LK losses are easy to implement, introduce no computational overhead and can be directly integrated into any existing speculator training framework, making them a compelling alternative to the existing draft training objectives."}
{"id": "2602.23947", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23947", "abs": "https://arxiv.org/abs/2602.23947", "authors": ["Oscar Hill", "Mateo Espinosa Zarlenga", "Mateja Jamnik"], "title": "Hierarchical Concept-based Interpretable Models", "comment": "Published as a conference paper at ICLR 2026", "summary": "Modern deep neural networks remain challenging to interpret due to the opacity of their latent representations, impeding model understanding, debugging, and debiasing. Concept Embedding Models (CEMs) address this by mapping inputs to human-interpretable concept representations from which tasks can be predicted. Yet, CEMs fail to represent inter-concept relationships and require concept annotations at different granularities during training, limiting their applicability. In this paper, we introduce Hierarchical Concept Embedding Models (HiCEMs), a new family of CEMs that explicitly model concept relationships through hierarchical structures. To enable HiCEMs in real-world settings, we propose Concept Splitting, a method for automatically discovering finer-grained sub-concepts from a pretrained CEM's embedding space without requiring additional annotations. This allows HiCEMs to generate fine-grained explanations from limited concept labels, reducing annotation burdens. Our evaluation across multiple datasets, including a user study and experiments on PseudoKitchens, a newly proposed concept-based dataset of 3D kitchen renders, demonstrates that (1) Concept Splitting discovers human-interpretable sub-concepts absent during training that can be used to train highly accurate HiCEMs, and (2) HiCEMs enable powerful test-time concept interventions at different granularities, leading to improved task accuracy."}
{"id": "2602.23968", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23968", "abs": "https://arxiv.org/abs/2602.23968", "authors": ["David Fox", "Sam Bowyer", "Song Liu", "Laurence Aitchison", "Raul Santos-Rodriguez", "Mengyue Yang"], "title": "Learning Generation Orders for Masked Discrete Diffusion Models via Variational Inference", "comment": "12 pages, 1 figure", "summary": "Masked discrete diffusion models (MDMs) are a promising new approach to generative modelling, offering the ability for parallel token generation and therefore greater efficiency than autoregressive counterparts. However, achieving an optimal balance between parallel generation and sample quality remains an open problem. Current approaches primarily address this issue through fixed, heuristic parallel sampling methods. There exist some recent learning based approaches to this problem, but its formulation from the perspective of variational inference remains underexplored. In this work, we propose a variational inference framework for learning parallel generation orders for MDMs. As part of our method, we propose a parameterisation for the approximate posterior of generation orders which facilitates parallelism and efficient sampling during training. Using this method, we conduct preliminary experiments on the GSM8K dataset, where our method performs competitively against heuristic sampling strategies in the regime of highly parallel generation. For example, our method achieves 33.1\\% accuracy with an average of only only 4 generation steps, compared to 23.7-29.0\\% accuracy achieved by standard competitor methods in the same number of steps. We believe further experiments and analysis of the method will yield valuable insights into the problem of parallel generation with MDMs."}
{"id": "2602.23981", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23981", "abs": "https://arxiv.org/abs/2602.23981", "authors": ["Xianglong Shi", "Ziheng Chen", "Yunhan Jiang", "Nicu Sebe"], "title": "Intrinsic Lorentz Neural Network", "comment": "Published in ICLR 2026", "summary": "Real-world data frequently exhibit latent hierarchical structures, which can be naturally represented by hyperbolic geometry. Although recent hyperbolic neural networks have demonstrated promising results, many existing architectures remain partially intrinsic, mixing Euclidean operations with hyperbolic ones or relying on extrinsic parameterizations. To address it, we propose the \\emph{Intrinsic Lorentz Neural Network} (ILNN), a fully intrinsic hyperbolic architecture that conducts all computations within the Lorentz model. At its core, the network introduces a novel \\emph{point-to-hyperplane} fully connected layer (FC), replacing traditional Euclidean affine logits with closed-form hyperbolic distances from features to learned Lorentz hyperplanes, thereby ensuring that the resulting geometric decision functions respect the inherent curvature. Around this fundamental layer, we design intrinsic modules: GyroLBN, a Lorentz batch normalization that couples gyro-centering with gyro-scaling, consistently outperforming both LBN and GyroBN while reducing training time. We additionally proposed a gyro-additive bias for the FC output, a Lorentz patch-concatenation operator that aligns the expected log-radius across feature blocks via a digamma-based scale, and a Lorentz dropout layer. Extensive experiments conducted on CIFAR-10/100 and two genomic benchmarks (TEB and GUE) illustrate that ILNN achieves state-of-the-art performance and computational cost among hyperbolic models and consistently surpasses strong Euclidean baselines. The code is available at \\href{https://github.com/Longchentong/ILNN}{\\textcolor{magenta}{this url}}."}
{"id": "2602.23994", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23994", "abs": "https://arxiv.org/abs/2602.23994", "authors": ["Vrushank Ahire", "Yogesh Kumar", "Anouck Girard", "M. A. Ganaie"], "title": "MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening", "comment": null, "summary": "Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference."}
{"id": "2602.23997", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.23997", "abs": "https://arxiv.org/abs/2602.23997", "authors": ["Florent Delgrange"], "title": "Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments", "comment": "AAMAS 2026, Blue Sky Idea Track. 4 pages, 1 Figure", "summary": "The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt."}
{"id": "2602.24012", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.24012", "abs": "https://arxiv.org/abs/2602.24012", "authors": ["Roy Betser", "Eyal Gofer", "Meir Yossef Levi", "Guy Gilboa"], "title": "InfoNCE Induces Gaussian Distribution", "comment": "Accepted to ICLR 2026, Oral", "summary": "Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning."}
{"id": "2602.24040", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.24040", "abs": "https://arxiv.org/abs/2602.24040", "authors": ["Daniel Yang", "Samuel Stante", "Florian Redhardt", "Lena Libon", "Parnian Kassraie", "Ido Hakimi", "Barna Pásztor", "Andreas Krause"], "title": "RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models", "comment": null, "summary": "Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq."}
{"id": "2602.24066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24066", "abs": "https://arxiv.org/abs/2602.24066", "authors": ["Tobias Nygaard"], "title": "pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures", "comment": null, "summary": "Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost."}
{"id": "2602.24069", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.24069", "abs": "https://arxiv.org/abs/2602.24069", "authors": ["Ryan DeWolfe"], "title": "Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding", "comment": "13 pages, 6 figures", "summary": "Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm."}
{"id": "2602.24081", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24081", "abs": "https://arxiv.org/abs/2602.24081", "authors": ["Viet Bac Nguyen", "Phuong Thai Nguyen"], "title": "Adaptive Correlation-Weighted Intrinsic Rewards for Reinforcement Learning", "comment": null, "summary": "We propose ACWI (Adaptive Correlation Weighted Intrinsic), an adaptive intrinsic reward scaling framework designed to dynamically balance intrinsic and extrinsic rewards for improved exploration in sparse reward reinforcement learning. Unlike conventional approaches that rely on manually tuned scalar coefficients, which often result in unstable or suboptimal performance across tasks, ACWI learns a state dependent scaling coefficient online. Specifically, ACWI introduces a lightweight Beta Network that predicts the intrinsic reward weight directly from the agent state through an encoder based architecture. The scaling mechanism is optimized using a correlation based objective that encourages alignment between the weighted intrinsic rewards and discounted future extrinsic returns. This formulation enables task adaptive exploration incentives while preserving computational efficiency and training stability. We evaluate ACWI on a suite of sparse reward environments in MiniGrid. Experimental results demonstrate that ACWI consistently improves sample efficiency and learning stability compared to fixed intrinsic reward baselines, achieving superior performance with minimal computational overhead."}
{"id": "2602.24083", "categories": ["cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24083", "abs": "https://arxiv.org/abs/2602.24083", "authors": ["Xinlong Du", "Harsha Honnappa", "Vinayak Rao"], "title": "Neural Diffusion Intensity Models for Point Process Data", "comment": null, "summary": "Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods."}
{"id": "2602.24115", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24115", "abs": "https://arxiv.org/abs/2602.24115", "authors": ["Zhizhou He", "Yang Luo", "Xinkai Liu", "Mahdi Boloursaz Mashhadi", "Mohammad Shojafar", "Merouane Debbah", "Rahim Tafazolli"], "title": "Agentic AI-RAN: Enabling Intent-Driven, Explainable and Self-Evolving Open RAN Intelligence", "comment": "9 pages, 4 figures", "summary": "Open RAN (O-RAN) exposes rich control and telemetry interfaces across the Non-RT RIC, Near-RT RIC, and distributed units, but also makes it harder to operate multi-tenant, multi-objective RANs in a safe and auditable manner. In parallel, agentic AI systems with explicit planning, tool use, memory, and self-management offer a natural way to structure long-lived control loops. This article surveys how such agentic controllers can be brought into O-RAN: we review the O-RAN architecture, contrast agentic controllers with conventional ML/RL xApps, and organise the task landscape around three clusters: network slice life-cycle, radio resource management (RRM) closed loops, and cross-cutting security, privacy, and compliance. We then introduce a small set of agentic primitives (Plan-Act-Observe-Reflect, skills as tool use, memory and evidence, and self-management gates) and show, in a multi-cell O-RAN simulation, how they improve slice life-cycle and RRM performance compared to conventional baselines and ablations that remove individual primitives. Security, privacy, and compliance are discussed as architectural constraints and open challenges for standards-aligned deployments. This framework achieves an average 8.83\\% reduction in resource usage across three classic network slices."}
{"id": "2602.24146", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24146", "abs": "https://arxiv.org/abs/2602.24146", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Learning with a Budget: Identifying the Best Arm with Resource Constraints", "comment": "A preliminary version of this work, titled 'Best Arm Identification with Resource Constraints,' was presented at the 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024). This manuscript extends the original conference paper by providing improved theoretical results and more generalized conclusions, aiming for future journal submission. arXiv admin note: substantial text overlap with arXiv:2402.19090", "summary": "In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \\textit{effective consumption measure"}
{"id": "2602.24149", "categories": ["cs.LG", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2602.24149", "abs": "https://arxiv.org/abs/2602.24149", "authors": ["Daniel S. Berman", "Brian Merritt", "Stanley Ta", "Dana Udwin", "Amanda Ernlund", "Jeremy Ratcliff", "Vijay Narayan"], "title": "What You Read is What You Classify: Highlighting Attributions to Text and Text-Like Inputs", "comment": "17 pages, 8 figures", "summary": "At present, there are no easily understood explainable artificial intelligence (AI) methods for discrete token inputs, like text. Most explainable AI techniques do not extend well to token sequences, where both local and global features matter, because state-of-the-art models, like transformers, tend to focus on global connections. Therefore, existing explainable AI algorithms fail by (i) identifying disparate tokens of importance, or (ii) assigning a large number of tokens a low value of importance. This method for explainable AI for tokens-based classifiers generalizes a mask-based explainable AI algorithm for images. It starts with an Explainer neural network that is trained to create masks to hide information not relevant for classification. Then, the Hadamard product of the mask and the continuous values of the classifier's embedding layer is taken and passed through the classifier, changing the magnitude of the embedding vector but keeping the orientation unchanged. The Explainer is trained for a taxonomic classifier for nucleotide sequences and it is shown that the masked segments are less relevant to classification than the unmasked ones. This method focused on the importance the token as a whole (i.e., a segment of the input sequence), producing a human-readable explanation."}
{"id": "2602.24178", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.24178", "abs": "https://arxiv.org/abs/2602.24178", "authors": ["Adam R. Klivans", "Konstantinos Stavropoulos", "Arsen Vasilyan"], "title": "Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension", "comment": "30 pages", "summary": "Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.\n  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result."}
{"id": "2602.24182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24182", "abs": "https://arxiv.org/abs/2602.24182", "authors": ["Sikata Sengupta", "Guangyi Liu", "Omer Gottesman", "Joseph W Durham", "Michael Kearns", "Aaron Roth", "Michael Caldara"], "title": "Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers", "comment": null, "summary": "Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems."}
{"id": "2602.24201", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24201", "abs": "https://arxiv.org/abs/2602.24201", "authors": ["Egor Antipov", "Alessandro Palma", "Lorenzo Consoli", "Stephan Günnemann", "Andrea Dittadi", "Fabian J. Theis"], "title": "Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics", "comment": null, "summary": "Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation."}
{"id": "2602.24207", "categories": ["cs.LG", "cs.CY", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.24207", "abs": "https://arxiv.org/abs/2602.24207", "authors": ["Gabriele Farina", "Juan Carlos Perdomo"], "title": "The Stability of Online Algorithms in Performative Prediction", "comment": null, "summary": "The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity."}
{"id": "2602.24209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.24209", "abs": "https://arxiv.org/abs/2602.24209", "authors": ["Mohsen Tajgardan", "Atena Shiranzaei", "Mahdi Rabbani", "Reza Khoshkangini", "Mahtab Jamali"], "title": "An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks", "comment": null, "summary": "Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments."}
{"id": "2602.24220", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.24220", "abs": "https://arxiv.org/abs/2602.24220", "authors": ["Miras Seilkhan", "Adilbek Taizhanov"], "title": "Comparing Classical and Quantum Variational Classifiers on the XOR Problem", "comment": "32 pages, 17 figures. Code and experiment scripts available at https://github.com/mseilkhan/XOR-research-Quantum-ML-vs-Classic", "summary": "Quantum machine learning applies principles such as superposition and entanglement to data processing and optimization. Variational quantum models operate on qubits in high-dimensional Hilbert spaces and provide an alternative approach to model expressivity. We compare classical models and a variational quantum classifier on the XOR problem. Logistic regression, a one-hidden-layer multilayer perceptron, and a two-qubit variational quantum classifier with circuit depths 1 and 2 are evaluated on synthetic XOR datasets with varying Gaussian noise and sample sizes using accuracy and binary cross-entropy.\n  Performance is determined primarily by model expressivity. Logistic regression and the depth-1 quantum circuit fail to represent XOR reliably, whereas the multilayer perceptron and the depth-2 quantum circuit achieve perfect test accuracy under representative conditions. Robustness analyses across noise levels, dataset sizes, and random seeds confirm that circuit depth is decisive for quantum performance on this task. Despite matching accuracy, the multilayer perceptron achieves lower binary cross-entropy and substantially shorter training time. Hardware execution preserves the global XOR structure but introduces structured deviations in the decision function. Overall, deeper variational quantum classifiers can match classical neural networks in accuracy on low-dimensional XOR benchmarks, but no clear empirical advantage in robustness or efficiency is observed in the examined settings."}
{"id": "2602.24231", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24231", "abs": "https://arxiv.org/abs/2602.24231", "authors": ["Hongrui Xie", "Junyu Cao", "Kan Xu"], "title": "Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference", "comment": "30 pages, 3 figure, AISTATS 2026 accepted paper", "summary": "In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making."}
{"id": "2602.23471", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.23471", "abs": "https://arxiv.org/abs/2602.23471", "authors": ["Artur Gimranov", "Viacheslav Yusupov", "Elfat Sabitov", "Tatyana Matveeva", "Anton Lysenko", "Ruslan Israfilov", "Evgeny Frolov"], "title": "Cross-Representation Knowledge Transfer for Improved Sequential Recommendations", "comment": null, "summary": "Transformer architectures, capable of capturing sequential dependencies in the history of user interactions, have become the dominant approach in sequential recommender systems. Despite their success, such models consider sequence elements in isolation, implicitly accounting for the complex relationships between them. Graph neural networks, in contrast, explicitly model these relationships through higher order interactions but are often unable to adequately capture their evolution over time, limiting their use for predicting the next interaction. To fill this gap, we present a new framework that combines transformers and graph neural networks and aligns different representations for solving next-item prediction task. Our solution simultaneously encodes structural dependencies in the interaction graph and tracks their dynamic change. Experimental results on a number of open datasets demonstrate that the proposed framework consistently outperforms both pure sequential and graph approaches in terms of recommendation quality, as well as recent methods that combine both types of signals."}
{"id": "2602.23665", "categories": ["cs.IR", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.23665", "abs": "https://arxiv.org/abs/2602.23665", "authors": ["Brandon Yee", "Lucas Wang", "Kundana Kommini", "Krishna Sharma"], "title": "Geodesic Semantic Search: Learning Local Riemannian Metrics for Citation Graph Retrieval", "comment": null, "summary": "We present Geodesic Semantic Search (GSS), a retrieval system that learns node-specific Riemannian metrics on citation graphs to enable geometry-aware semantic search. Unlike standard embedding-based retrieval that relies on fixed Euclidean distances, \\gss{} learns a low-rank metric tensor $\\mL_i \\in \\R^{d \\times r}$ at each node, inducing a local positive semi-definite metric $\\mG_i = \\mL_i \\mL_i^\\top + \\eps \\mI$. This parameterization guarantees valid metrics while keeping the model tractable. Retrieval proceeds via multi-source Dijkstra on the learned geodesic distances, followed by Maximal Marginal Relevance reranking and path coherence filtering. On citation prediction benchmarks with 169K papers, \\gss{} achieves 23\\% relative improvement in Recall@20 over SPECTER+FAISS baselines while providing interpretable citation paths. Our hierarchical coarse-to-fine search with k-means pooling reduces computational cost by 4$\\times$ compared to flat geodesic search while maintaining 97\\% retrieval quality. We provide theoretical analysis of when geodesic distances outperform direct similarity, characterize the approximation quality of low-rank metrics, and validate predictions empirically. Code and trained models are available at https://github.com/YCRG-Labs/geodesic-search."}
{"id": "2602.24044", "categories": ["cs.DC", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.24044", "abs": "https://arxiv.org/abs/2602.24044", "authors": ["Ferran Agullo", "Joan Oliveras", "Chen Wang", "Alberto Gutierrez-Torre", "Olivier Tardieu", "Alaa Youssef", "Jordi Torres", "Josep Ll. Berral"], "title": "Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving", "comment": "journal extension of the workshop paper titled as \"A data-driven ml approach for maximizing performance in llm-adapter serving\"", "summary": "Large Language Model (LLM) adapters enable low-cost model specialization, but introduce complex caching and scheduling challenges in distributed serving systems where hundreds of adapters must be hosted concurrently. While prior work has largely focused on latency minimization, resource efficiency through throughput maximization remains underexplored. This paper presents a data-driven pipeline that, for a given workload, computes an adapter placement that serves the workload with the minimum number of GPUs while avoiding request starvation and GPU memory errors. To that end, the approach identifies the maximum feasible throughput attainable on each GPU by leveraging accurate performance predictions learned from real serving behavior. The proposed pipeline integrates three components: (i) a Digital Twin (DT) tailored to LLM-adapter serving, (ii) a distilled machine learning (ML) model trained on DT-generated data, and (iii) a greedy placement algorithm that exploits ML-based performance estimates to maximize GPU efficiency. The DT emulates real system dynamics with high fidelity, achieving below 5% throughput estimation error while executing up to 90 times faster than full LLM benchmarking across both predictable and unpredictable workloads. The learned ML models further accelerate performance estimation with marginal accuracy degradation, enabling scalable optimization. Experimental results demonstrate that the pipeline substantially improves GPU efficiency by reducing the number of GPUs required to sustain target workloads. Beyond GPU efficiency, the pipeline can be adapted to alternative objectives, such as latency minimization, highlighting its versatility for future large-scale LLM serving infrastructures."}
