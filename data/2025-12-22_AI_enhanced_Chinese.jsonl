{"id": "2512.17108", "categories": ["cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.17108", "abs": "https://arxiv.org/abs/2512.17108", "authors": ["Kunjal Panchal", "Saayan Mitra", "Somdeb Sarkhel", "Haoliang Wang", "Ishita Dasgupta", "Gang Wu", "Hui Guan"], "title": "Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse", "comment": null, "summary": "Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-device system that restructures video-language pipelines for fast and efficient execution. Atom decomposes a billion-parameter model into reusable modules, such as the visual encoder and language decoder, and reuses them across subtasks like captioning, reasoning, and indexing. This reuse-centric design eliminates repeated model loading and enables parallel execution, reducing end-to-end latency without sacrificing performance. On commodity smartphones, Atom achieves 27--33% faster execution compared to non-reuse baselines, with only marginal performance drop ($\\leq$ 2.3 Recall@1 in retrieval, $\\leq$ 1.5 CIDEr in captioning). These results position Atom as a practical, scalable approach for efficient video-language understanding on edge devices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAtom\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u5c06\u5927\u89c4\u6a21\u89c6\u9891-\u8bed\u8a00\u6a21\u578b\u5206\u89e3\u4e3a\u53ef\u91cd\u7528\u6a21\u5757\u5e76\u5728\u884c\u6267\u884c\uff0c\u5b9e\u73b0\u4e86\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u9ad8\u6548\u5feb\u901f\u5730\u5904\u7406\u89c6\u9891-\u8bed\u8a00\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u89c6\u9891-\u8bed\u8a00\u6a21\u578b\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u591a\u9636\u6bb5\u7ba1\u9053\u6267\u884c\u6548\u7387\u4f4e\u4e0b\uff0c\u5b58\u5728\u7740\u5197\u4f59\u6a21\u578b\u52a0\u8f7d\u548c\u6267\u884c\u788e\u7247\u5316\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Atom\u7cfb\u7edf\uff0c\u5b83\u80fd\u591f\u5c06\u4e00\u4e2a\u62e5\u6709\u6570\u5341\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u5206\u89e3\u6210\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u7ec4\u4ef6\uff08\u5982\u89c6\u89c9\u7f16\u7801\u5668\u548c\u8bed\u8a00\u89e3\u7801\u5668\uff09\uff0c\u5e76\u5728\u8bf8\u5982\u5b57\u5e55\u3001\u63a8\u7406\u548c\u7d22\u5f15\u7b49\u5b50\u4efb\u52a1\u4e4b\u95f4\u91cd\u7528\u8fd9\u4e9b\u7ec4\u4ef6\u3002\u6b64\u8bbe\u8ba1\u51cf\u5c11\u4e86\u91cd\u590d\u6a21\u578b\u52a0\u8f7d\uff0c\u5e76\u652f\u6301\u5e76\u884c\u6267\u884c\u4ee5\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "result": "\u5728\u666e\u901a\u667a\u80fd\u624b\u673a\u4e0a\uff0c\u4e0e\u4e0d\u91c7\u7528\u91cd\u7528\u673a\u5236\u7684\u57fa\u7840\u65b9\u6848\u76f8\u6bd4\uff0cAtom\u5b9e\u73b0\u4e8627-33%\u7684\u66f4\u5feb\u6267\u884c\u901f\u5ea6\uff0c\u540c\u65f6\u6027\u80fd\u4e0b\u964d\u5fae\u4e4e\u5176\u5fae\uff08\u68c0\u7d22Recall@1\u4e0d\u8d85\u8fc72.3%\uff0c\u5b57\u5e55CIDEr\u4e0d\u8d85\u8fc71.5%\uff09\u3002", "conclusion": "Atom\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u63d0\u4f9b\u9ad8\u6548\u7684\u89c6\u9891-\u8bed\u8a00\u7406\u89e3\u670d\u52a1\uff0c\u5c55\u793a\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u800c\u4e0d\u660e\u663e\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2512.17015", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17015", "abs": "https://arxiv.org/abs/2512.17015", "authors": ["Domenico De Gioia", "Claudio Pomo", "Ludovico Boratto", "Tommaso Di Noia"], "title": "A Reproducible and Fair Evaluation of Partition-aware Collaborative Filtering", "comment": "accepted at ECIR 2026 reproducibility track", "summary": "Similarity-based collaborative filtering (CF) models have long demonstrated strong offline performance and conceptual simplicity. However, their scalability is limited by the quadratic cost of maintaining dense item-item similarity matrices. Partitioning-based paradigms have recently emerged as an effective strategy for balancing effectiveness and efficiency, enabling models to learn local similarities within coherent subgraphs while maintaining a limited global context. In this work, we focus on the Fine-tuning Partition-aware Similarity Refinement (FPSR) framework, a prominent representative of this family, as well as its extension, FPSR+. Reproducible evaluation of partition-aware collaborative filtering remains challenging, as prior FPSR/FPSR+ reports often rely on splits of unclear provenance and omit some similarity-based baselines, thereby complicating fair comparison. We present a transparent, fully reproducible benchmark of FPSR and FPSR+. Based on our results, the family of FPSR models does not consistently perform at the highest level. Overall, it remains competitive, validates its design choices, and shows significant advantages in long-tail scenarios. This highlights the accuracy-coverage trade-offs resulting from partitioning, global components, and hub design. Our investigation clarifies when partition-aware similarity modeling is most beneficial and offers actionable guidance for scalable recommender system design under reproducible protocols.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\uff0c\u7279\u522b\u662f\u7ec6\u8c03\u5206\u533a\u611f\u77e5\u76f8\u4f3c\u6027\u7ec6\u5316\uff08FPSR\uff09\u6846\u67b6\u53ca\u5176\u6269\u5c55\u7248\u672cFPSR+\u3002\u901a\u8fc7\u900f\u660e\u4e14\u5b8c\u5168\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5c3d\u7ba1FPSR\u6a21\u578b\u5728\u67d0\u4e9b\u957f\u5c3e\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5176\u6574\u4f53\u8868\u73b0\u5e76\u4e0d\u603b\u662f\u6700\u4f73\u3002\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5206\u533a\u3001\u5168\u5c40\u7ec4\u4ef6\u548c\u4e2d\u5fc3\u8bbe\u8ba1\u4e4b\u95f4\u7684\u51c6\u786e\u6027-\u8986\u76d6\u7387\u6743\u8861\uff0c\u5e76\u4e3a\u53ef\u6269\u5c55\u63a8\u8350\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u867d\u7136\u79bb\u7ebf\u6027\u80fd\u4f18\u5f02\u4e14\u6982\u5ff5\u7b80\u5355\uff0c\u4f46\u56e0\u7ef4\u62a4\u5bc6\u96c6\u9879\u76ee-\u9879\u76ee\u76f8\u4f3c\u77e9\u9635\u7684\u6210\u672c\u800c\u53d7\u9650\u4e8e\u53ef\u6269\u5c55\u6027\u3002\u6700\u8fd1\u51fa\u73b0\u7684\u5206\u533a\u8303\u5f0f\u80fd\u591f\u5728\u4fdd\u6301\u6709\u9650\u7684\u5168\u5c40\u4e0a\u4e0b\u6587\u7684\u540c\u65f6\u5b66\u4e60\u5c40\u90e8\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u6709\u6548\u5e73\u8861\u6548\u7387\u4e0e\u6548\u679c\u3002\u7136\u800c\uff0c\u5148\u524d\u5173\u4e8eFPSR/FPSR+\u7684\u7814\u7a76\u62a5\u544a\u5f80\u5f80\u4f9d\u8d56\u4e8e\u6765\u6e90\u4e0d\u660e\u7684\u6570\u636e\u5206\u5272\uff0c\u5e76\u7701\u7565\u4e86\u4e00\u4e9b\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u57fa\u7ebf\u6bd4\u8f83\uff0c\u4f7f\u5f97\u516c\u5e73\u5bf9\u6bd4\u53d8\u5f97\u590d\u6742\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u900f\u660e\u4e14\u5b8c\u5168\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86Fine-tuning Partition-aware Similarity Refinement (FPSR) \u6846\u67b6\u53ca\u5b83\u7684\u6269\u5c55\u7248 FPSR+ \u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\u3002\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u900f\u660e\u4e14\u5b8c\u5168\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u73af\u5883\uff0c\u5bf9FPSR\u548cFPSR+\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1FPSR\u7cfb\u5217\u6a21\u578b\u5e76\u975e\u59cb\u7ec8\u5904\u4e8e\u6700\u9ad8\u6c34\u5e73\u7684\u8868\u73b0\uff0c\u4f46\u5728\u603b\u4f53\u4e0a\u4ecd\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u8bbe\u8ba1\u7406\u5ff5\uff0c\u5728\u957f\u5c3e\u573a\u666f\u4e0b\u5c24\u5176\u5c55\u73b0\u51fa\u663e\u8457\u7684\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u7a81\u51fa\u4e86\u7531\u4e8e\u5212\u5206\u3001\u5168\u5c40\u5143\u7d20\u4ee5\u53ca\u67a2\u7ebd\u8bbe\u8ba1\u6240\u5bfc\u81f4\u7684\u51c6\u786e\u5ea6-\u8986\u76d6\u8303\u56f4\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "conclusion": "FPSR\u6a21\u578b\u5bb6\u65cf\u5728\u957f\u5c3e\u573a\u666f\u4e0b\u7684\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0c\u540c\u65f6\u6574\u4f53\u4e0a\u4e5f\u4fdd\u6301\u7740\u7ade\u4e89\u529b\u3002\u8fd9\u9879\u7814\u7a76\u660e\u786e\u4e86\u5206\u533a\u611f\u77e5\u76f8\u4f3c\u6027\u5efa\u6a21\u6700\u6709\u5229\u7684\u60c5\u51b5\uff0c\u5e76\u4e3a\u9075\u5faa\u53ef\u590d\u73b0\u534f\u8bae\u7684\u53ef\u6269\u5c55\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002"}}
{"id": "2512.17429", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17429", "abs": "https://arxiv.org/abs/2512.17429", "authors": ["Kyriakos Psarakis"], "title": "Democratizing Scalable Cloud Applications: Transactional Stateful Functions on Streaming Dataflows", "comment": "PhD Dissertation at TU Delft", "summary": "Web applications underpin much of modern digital life, yet building scalable and consistent cloud applications remains difficult, requiring expertise across cloud computing, distributed systems, databases, and software engineering. These demands restrict development to a small number of highly specialized engineers. This thesis aims to democratize cloud application development by addressing three challenges: programmability, high-performance fault-tolerant serializable transactions, and serverless semantics.\n  The thesis identifies strong parallels between cloud applications and the streaming dataflow execution model. It first explores this connection through T-Statefun, a transactional extension of Apache Flink Statefun, demonstrating that dataflow systems can support transactional cloud applications via a stateful functions-as-a-service API. However, this approach revealed significant limitations in programmability and performance.\n  To overcome these issues, the thesis introduces Stateflow, a high-level object-oriented programming model that compiles applications into stateful dataflow graphs with minimal boilerplate. Building on this model, the thesis presents Styx, a distributed streaming dataflow engine that provides deterministic, multi-partition, serializable transactions with strong fault tolerance guarantees. Styx eliminates explicit transaction failure handling and significantly outperforms state-of-the-art systems.\n  Finally, the thesis extends Styx with transactional state migration to support elasticity under dynamic workloads.", "AI": {"tldr": "\u672c\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u89e3\u51b3\u53ef\u7f16\u7a0b\u6027\u3001\u9ad8\u6027\u80fd\u5bb9\u9519\u53ef\u5e8f\u5217\u5316\u4e8b\u52a1\u548c\u65e0\u670d\u52a1\u5668\u8bed\u4e49\u8fd9\u4e09\u4e2a\u6311\u6218\uff0c\u4f7f\u4e91\u5e94\u7528\u7a0b\u5e8f\u5f00\u53d1\u6c11\u4e3b\u5316\u3002\u9996\u5148\u901a\u8fc7T-Statefun\u63a2\u7d22\u4e86\u4e91\u5e94\u7528\u4e0e\u6570\u636e\u6d41\u6267\u884c\u6a21\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4f46\u53d1\u73b0\u8be5\u65b9\u6cd5\u5728\u53ef\u7f16\u7a0b\u6027\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u663e\u8457\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4e86Stateflow\uff0c\u8fd9\u662f\u4e00\u79cd\u9ad8\u7ea7\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u6b64\u6a21\u578b\u63a8\u51fa\u4e86Styx\uff0c\u4e00\u79cd\u5206\u5e03\u5f0f\u6d41\u6570\u636e\u6d41\u5f15\u64ce\uff0c\u63d0\u4f9b\u5177\u6709\u5f3a\u5bb9\u9519\u4fdd\u8bc1\u7684\u786e\u5b9a\u6027\u3001\u591a\u5206\u533a\u3001\u53ef\u5e8f\u5217\u5316\u4e8b\u52a1\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5f15\u5165\u4e8b\u52a1\u72b6\u6001\u8fc1\u79fb\u4ee5\u652f\u6301\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u5f39\u6027\u6269\u5c55\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86Styx\u7684\u529f\u80fd\u3002", "motivation": "\u5c3d\u7ba1Web\u5e94\u7528\u7a0b\u5e8f\u652f\u6491\u4e86\u73b0\u4ee3\u6570\u5b57\u751f\u6d3b\u7684\u5f88\u591a\u65b9\u9762\uff0c\u4f46\u6784\u5efa\u53ef\u6269\u5c55\u4e14\u4e00\u81f4\u6027\u7684\u4e91\u5e94\u7528\u7a0b\u5e8f\u4ecd\u7136\u5f88\u56f0\u96be\uff0c\u9700\u8981\u8de8\u4e91\u8ba1\u7b97\u3001\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u6570\u636e\u5e93\u548c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002\u8fd9\u4e9b\u8981\u6c42\u5c06\u5f00\u53d1\u9650\u5236\u5728\u5c11\u6570\u9ad8\u5ea6\u4e13\u4e1a\u5316\u7684\u5de5\u7a0b\u5e08\u624b\u4e2d\u3002\u56e0\u6b64\uff0c\u672c\u8bba\u6587\u7684\u76ee\u6807\u662f\u901a\u8fc7\u89e3\u51b3\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff08\u53ef\u7f16\u7a0b\u6027\u3001\u9ad8\u6027\u80fd\u5bb9\u9519\u53ef\u5e8f\u5217\u5316\u4e8b\u52a1\u4ee5\u53ca\u65e0\u670d\u52a1\u5668\u8bed\u4e49\uff09\u6765\u8ba9\u66f4\u5e7f\u6cdb\u7684\u5f00\u53d1\u8005\u80fd\u591f\u53c2\u4e0e\u4e91\u5e94\u7528\u7a0b\u5e8f\u5f00\u53d1\u3002", "method": "\u8bba\u6587\u9996\u5148\u901a\u8fc7\u4e00\u4e2a\u540d\u4e3aT-Statefun\u7684\u5b9e\u9a8c\u9879\u76ee\u63a2\u7d22\u4e86\u4e91\u5e94\u7528\u4e0e\u6570\u636e\u6d41\u6267\u884c\u6a21\u578b\u4e4b\u95f4\u5b58\u5728\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u8be5\u9879\u76ee\u662f\u5bf9Apache Flink Statefun\u7684\u4e00\u4e2a\u4e8b\u52a1\u6027\u6269\u5c55\u3002\u867d\u7136\u8fd9\u79cd\u65b9\u6cd5\u5c55\u793a\u4e86\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u5176\u5728\u53ef\u7f16\u7a0b\u6027\u548c\u6027\u80fd\u4e0a\u7684\u5c40\u9650\u6027\u3002\n\u968f\u540e\uff0c\u4e3a\u4e86\u514b\u670d\u4e0a\u8ff0\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u7ea7\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u6a21\u578b\u2014\u2014Stateflow\uff0c\u5b83\u80fd\u4ee5\u6700\u5c11\u7684\u6837\u677f\u4ee3\u7801\u5c06\u5e94\u7528\u7a0b\u5e8f\u7f16\u8bd1\u6210\u6709\u72b6\u6001\u7684\u6570\u636e\u6d41\u56fe\u3002\n\u57fa\u4e8eStateflow\u6a21\u578b\u4e4b\u4e0a\uff0c\u53c8\u8bbe\u8ba1\u5b9e\u73b0\u4e86Styx\uff0c\u8fd9\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u5f15\u64ce\uff0c\u80fd\u591f\u63d0\u4f9b\u5177\u5907\u5f3a\u5927\u5bb9\u9519\u80fd\u529b\u4fdd\u969c\u7684\u786e\u5b9a\u6027\u3001\u591a\u5206\u533a\u53ef\u5e8f\u5217\u5316\u4e8b\u52a1\u5904\u7406\u529f\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5bf9Styx\u8fdb\u884c\u6269\u5c55\u589e\u52a0\u4e86\u5bf9\u4e8b\u52a1\u72b6\u6001\u8fc1\u79fb\u7684\u652f\u6301\uff0c\u4ece\u800c\u80fd\u591f\u5728\u9762\u5bf9\u52a8\u6001\u53d8\u5316\u7684\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u5f39\u6027\u9002\u5e94\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5f15\u5165Stateflow\u53ca\u540e\u7eed\u53d1\u5c55\u7684Styx\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u5927\u5927\u7b80\u5316\u4e86\u6784\u5efa\u590d\u6742\u4e91\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b\uff0c\u540c\u65f6\u4e5f\u663e\u8457\u63d0\u9ad8\u4e86\u6b64\u7c7b\u5e94\u7528\u5728\u6267\u884c\u4e8b\u52a1\u64cd\u4f5c\u65f6\u7684\u8868\u73b0\u3002\u7279\u522b\u662f\uff0cStyx\u63d0\u4f9b\u7684\u786e\u5b9a\u6027\u3001\u591a\u5206\u533a\u53ef\u5e8f\u5217\u5316\u4e8b\u52a1\u5904\u7406\u80fd\u529b\uff0c\u5728\u786e\u4fdd\u6570\u636e\u4e00\u81f4\u6027\u7684\u540c\u65f6\u4e5f\u8fbe\u5230\u4e86\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u52a0\u5165\u4e8b\u52a1\u72b6\u6001\u8fc1\u79fb\u673a\u5236\u540e\uff0c\u4f7f\u5f97\u6574\u4e2a\u7cfb\u7edf\u5bf9\u4e8e\u4e0d\u540c\u89c4\u6a21\u548c\u7c7b\u578b\u7684\u5de5\u4f5c\u8d1f\u8f7d\u90fd\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u6210\u529f\u5730\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u6570\u636e\u6d41\u6267\u884c\u6a21\u578b\u6765\u6539\u5584\u4e91\u5e94\u7528\u7a0b\u5e8f\u5f00\u53d1\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u63d0\u51fa\u521b\u65b0\u6027\u7684Stateflow\u7f16\u7a0b\u6a21\u578b\u4e0eStyx\u6267\u884c\u5f15\u64ce\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u8bba\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u9886\u57df\u5185\u5b58\u5728\u7684\u53ef\u7f16\u7a0b\u6027\u5dee\u3001\u6027\u80fd\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u6700\u7ec8\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6848\u4e0d\u4ec5\u80fd\u591f\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u540c\u65f6\u8fd8\u80fd\u786e\u4fdd\u5e94\u7528\u7a0b\u5e8f\u5177\u5907\u4f18\u79c0\u7684\u4e8b\u52a1\u5904\u7406\u80fd\u529b\u548c\u4f38\u7f29\u6027\u3002"}}
{"id": "2512.16928", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.16928", "abs": "https://arxiv.org/abs/2512.16928", "authors": ["Kwangjun Ahn", "Noah Amsel", "John Langford"], "title": "Dion2: A Simple Method to Shrink Matrix in Muon", "comment": "https://github.com/microsoft/dion/", "summary": "The Muon optimizer enjoys strong empirical performance and theoretical grounding. However, the super-linear cost of its orthonormalization step introduces increasing overhead with scale. To alleviate this cost, several works have attempted to reduce the size of the matrix entering the orthonormalization step. We introduce Dion2, a much simpler method for shrinking the matrix involved in Muon's computation compared to prior approaches. At a high level, Dion2 selects a fraction of rows or columns at each iteration and orthonormalizes only those. This sampling procedure makes the update sparse, reducing both computation and communication costs which in turn improves the scalability of Muon.", "AI": {"tldr": "Dion2 is a new, simpler method that reduces the computational and communication costs of the Muon optimizer by selectively orthonormalizing only a fraction of rows or columns at each iteration, thus improving scalability.", "motivation": "The motivation behind this paper is to address the increasing overhead caused by the super-linear cost of the orthonormalization step in the Muon optimizer, which becomes more pronounced as the scale increases. Previous attempts to reduce this cost have involved reducing the size of the matrix entering the orthonormalization step, but the authors propose a simpler and more efficient solution with Dion2.", "method": "The method proposed in the paper, named Dion2, involves selecting only a portion of the rows or columns for orthonormalization at each iteration, rather than processing the entire matrix. This selective orthonormalization process leads to sparser updates, thereby lowering both the computation and communication costs associated with the Muon's orthonormalization step.", "result": "The result of applying Dion2 is a reduction in the overall costs related to orthonormalization, making the Muon optimizer more scalable and efficient, especially at larger scales where the original super-linear cost would become prohibitive.", "conclusion": "In conclusion, the paper introduces Dion2 as an effective and simple approach to improve the scalability of the Muon optimizer by decreasing the orthonormalization step's overhead through selective sampling, leading to a more efficient use of computational resources."}}
{"id": "2512.16926", "categories": ["cs.DC", "cs.OS", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.16926", "abs": "https://arxiv.org/abs/2512.16926", "authors": ["Oren Bell", "Harun Teper", "Mario G\u00fcnzel", "Chris Gill", "Jian-Jia Chen"], "title": "Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor", "comment": "18 pages, 5 figure", "summary": "This paper addresses limitations of current scheduling methods in the Robot Operating System (ROS)2, focusing on scheduling tasks beyond simple chains and analyzing arbitrary Directed Acyclic Graphs (DAGs). While previous research has focused mostly on chain-based scheduling with ad-hoc response time analyses, we propose a novel approach using the events executor to implement fixed-job-level-priority schedulers for arbitrary ROS2 graphs on uniprocessor systems. We demonstrate that ROS 2 applications can be abstracted as forests of trees, enabling the mapping of ROS 2 applications to traditional real-time DAG task models. Our usage of the events executor requires a special implementation of the events queue and a communication middleware that supports LIFO-ordered message delivery, features not yet standard in ROS2. We show that our implementation generates the same schedules as a conventional fixed-priority DAG task scheduler, in spite of lacking access to the precedence information that usually is required. This further closes the gap between established real-time systems theory and ROS2 scheduling analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e8b\u4ef6\u6267\u884c\u5668\u5728\u5355\u5904\u7406\u5668\u7cfb\u7edf\u4e0a\u4e3aROS2\u4e2d\u7684\u4efb\u610f\u6709\u5411\u65e0\u73af\u56fe(DAG)\u5b9e\u73b0\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u522b\u4f18\u5148\u7ea7\u8c03\u5ea6\u3002\u901a\u8fc7\u5c06ROS2\u5e94\u7528\u62bd\u8c61\u6210\u6811\u7684\u68ee\u6797\uff0c\u53ef\u4ee5\u5c06\u5176\u6620\u5c04\u5230\u4f20\u7edf\u7684\u5b9e\u65f6DAG\u4efb\u52a1\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u6240\u63d0\u5b9e\u73b0\u4e0e\u4f20\u7edf\u56fa\u5b9a\u4f18\u5148\u7ea7DAG\u4efb\u52a1\u8c03\u5ea6\u5668\u751f\u6210\u76f8\u540c\u7684\u8c03\u5ea6\u7ed3\u679c\u3002", "motivation": "\u5f53\u524dROS2\u4e2d\u7684\u8c03\u5ea6\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u7b80\u5355\u7684\u94fe\u5f0f\u4efb\u52a1\u8c03\u5ea6\u548c\u7279\u5b9a\u54cd\u5e94\u65f6\u95f4\u5206\u6790\u4e0a\u3002\u5bf9\u4e8e\u66f4\u590d\u6742\u7684\u3001\u4efb\u610f\u7684DAG\u7ed3\u6784\u7684\u4efb\u52a1\u8c03\u5ea6\u652f\u6301\u4e0d\u8db3\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u4e8b\u4ef6\u6267\u884c\u5668\u6765\u5b9e\u73b0\u9488\u5bf9ROS2\u4e2d\u4efb\u610fDAG\u7684\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u522b\u4f18\u5148\u7ea7\u8c03\u5ea6\u7b56\u7565\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u9700\u8981\u5bf9\u4e8b\u4ef6\u961f\u5217\u8fdb\u884c\u7279\u6b8a\u8bbe\u8ba1\uff0c\u5e76\u91c7\u7528\u652f\u6301LIFO\u6d88\u606f\u4f20\u9012\u987a\u5e8f\u7684\u901a\u4fe1\u4e2d\u95f4\u4ef6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u8fd8\u5c06ROS2\u5e94\u7528\u7a0b\u5e8f\u62bd\u8c61\u4e3a\u6811\u72b6\u7ed3\u6784\u7ec4\u6210\u7684\u68ee\u6797\uff0c\u4ee5\u4fc3\u8fdb\u5176\u5411\u4f20\u7edf\u5b9e\u65f6DAG\u4efb\u52a1\u6a21\u578b\u8f6c\u6362\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u7f3a\u4e4f\u901a\u5e38\u6240\u9700\u7684\u4f18\u5148\u7ea7\u4fe1\u606f\uff0c\u6240\u63d0\u51fa\u7684\u5b9e\u73b0\u4e5f\u80fd\u751f\u6210\u4e0e\u6807\u51c6\u56fa\u5b9a\u4f18\u5148\u7ea7DAG\u4efb\u52a1\u8c03\u5ea6\u5668\u76f8\u540c\u7684\u7ed3\u679c\u3002\u8fd9\u6709\u52a9\u4e8e\u7f29\u5c0f\u73b0\u6709\u5b9e\u65f6\u7cfb\u7edf\u7406\u8bba\u4e0eROS2\u8c03\u5ea6\u5206\u6790\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3ROS2\u4e2d\u590d\u6742DAG\u7ed3\u6784\u4efb\u52a1\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u4e8b\u4ef6\u6267\u884c\u5668\u7684\u65b0\u8c03\u5ea6\u673a\u5236\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8c03\u5ea6\u7075\u6d3b\u6027\u8fd8\u4fdd\u6301\u4e86\u4e0e\u7ecf\u5178\u5b9e\u65f6\u8c03\u5ea6\u6280\u672f\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.17027", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17027", "abs": "https://arxiv.org/abs/2512.17027", "authors": ["Erica Coppolillo", "Simone Mungari"], "title": "Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations", "comment": null, "summary": "Encyclopedic knowledge platforms are key gateways through which users explore information online. The recent release of Grokipedia, a fully AI-generated encyclopedia, introduces a new alternative to traditional, well-established platforms like Wikipedia. In this context, search engine mechanisms play an important role in guiding users exploratory paths, yet their behavior across different encyclopedic systems remains underexplored. In this work, we address this gap by providing the first comparative analysis of search engine in Wikipedia and Grokipedia.\n  Using nearly 10,000 neutral English words and their substrings as queries, we collect over 70,000 search engine results and examine their semantic alignment, overlap, and topical structure. We find that both platforms frequently generate results that are weakly related to the original query and, in many cases, surface unexpected content starting from innocuous queries. Despite these shared properties, the two systems often produce substantially different recommendation sets for the same query. Through topical annotation and trajectory analysis, we further identify systematic differences in how content categories are surfaced and how search engine results evolve over multiple stages of exploration.\n  Overall, our findings show that unexpected search engine outcomes are a common feature of both the platforms, even though they exhibit discrepancies in terms of topical distribution and query suggestions.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u6bd4\u5206\u6790\u4e86\u7ef4\u57fa\u767e\u79d1\u548cGrokipedia\u8fd9\u4e24\u4e2a\u767e\u79d1\u5e73\u53f0\u7684\u641c\u7d22\u5f15\u64ce\u673a\u5236\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u641c\u7d22\u7ed3\u679c\u7684\u76f8\u5173\u6027\u3001\u4e3b\u9898\u5206\u5e03\u53ca\u63a2\u7d22\u8def\u5f84\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5b8c\u5168\u7531AI\u751f\u6210\u7684\u767e\u79d1\u5168\u4e66Grokipedia\u7684\u51fa\u73b0\uff0c\u5bf9\u4e8e\u4e0d\u540c\u767e\u79d1\u7cfb\u7edf\u4e2d\u641c\u7d22\u5f15\u64ce\u884c\u4e3a\u7684\u7814\u7a76\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u5bf9Wikipedia\u548cGrokipedia\u4e4b\u95f4\u641c\u7d22\u5f15\u64ce\u673a\u5236\u7684\u9996\u6b21\u6bd4\u8f83\u5206\u6790\u3002", "method": "\u7814\u7a76\u8005\u4f7f\u7528\u8fd110,000\u4e2a\u4e2d\u7acb\u82f1\u6587\u5355\u8bcd\u53ca\u5176\u5b50\u4e32\u4f5c\u4e3a\u67e5\u8be2\u6761\u4ef6\uff0c\u6536\u96c6\u8d85\u8fc770,000\u6761\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\uff0c\u5e76\u68c0\u67e5\u8fd9\u4e9b\u7ed3\u679c\u7684\u610f\u4e49\u4e00\u81f4\u6027\u3001\u91cd\u53e0\u5ea6\u4ee5\u53ca\u4e3b\u9898\u7ed3\u6784\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e24\u4e2a\u5e73\u53f0\u7ecf\u5e38\u4ea7\u751f\u4e0e\u539f\u59cb\u67e5\u8be2\u5173\u8054\u8f83\u5f31\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u4ece\u65e0\u5bb3\u67e5\u8be2\u5f00\u59cb\u53ef\u80fd\u4f1a\u51fa\u73b0\u610f\u5916\u5185\u5bb9\uff1b\u5c3d\u7ba1\u5982\u6b64\uff0c\u9488\u5bf9\u76f8\u540c\u7684\u67e5\u8be2\uff0c\u4e24\u7cfb\u7edf\u4ea7\u751f\u7684\u63a8\u8350\u96c6\u5408\u5374\u5927\u76f8\u5f84\u5ead\u3002\u901a\u8fc7\u4e3b\u9898\u6ce8\u91ca\u548c\u8f68\u8ff9\u5206\u6790\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u5185\u5bb9\u7c7b\u522b\u6d6e\u73b0\u65b9\u5f0f\u53ca\u591a\u9636\u6bb5\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u6f14\u53d8\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\u3002", "conclusion": "\u603b\u7684\u6765\u8bf4\uff0c\u7814\u7a76\u663e\u793a\u610f\u5916\u7684\u641c\u7d22\u5f15\u64ce\u8f93\u51fa\u662f\u4e24\u4e2a\u5e73\u53f0\u5171\u6709\u7684\u7279\u5f81\uff0c\u4f46\u5b83\u4eec\u5728\u4e3b\u9898\u5206\u5e03\u548c\u67e5\u8be2\u5efa\u8bae\u65b9\u9762\u8868\u73b0\u51fa\u4e0d\u4e00\u81f4\u4e4b\u5904\u3002"}}
{"id": "2512.16929", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16929", "abs": "https://arxiv.org/abs/2512.16929", "authors": ["Pranesh Sathish Kumar"], "title": "BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control", "comment": "12 pages, 8 figures", "summary": "Affordable upper-limb prostheses often lack intuitive control systems, limiting functionality and accessibility for amputees in low-resource settings. This project presents a low-cost, dual-mode neuro-muscular control system integrating electroencephalography (EEG) and electromyography (EMG) to enable real-time, multi-degree-of-freedom control of a prosthetic arm. EEG signals are acquired using the NeuroSky MindWave Mobile 2 and transmitted via ThinkGear Bluetooth packets to an ESP32 microcontroller running a lightweight classification model. The model was trained on 1500 seconds of recorded EEG data using a 6-frame sliding window with low-pass filtering, excluding poor-signal samples and using a 70/20/10 training--validation--test split. The classifier detects strong blink events, which toggle the hand between open and closed states. EMG signals are acquired using a MyoWare 2.0 sensor and SparkFun wireless shield and transmitted to a second ESP32, which performs threshold-based detection. Three activation bands (rest: 0--T1; extension: T1--T2; contraction: greater than T2) enable intuitive elbow control, with movement triggered only after eight consecutive frames in a movement class to improve stability. The EEG-controlled ESP32 actuates four finger servos, while the EMG-controlled ESP32 drives two elbow servos. A functional prototype was constructed using low-cost materials (total cost approximately 240 dollars), with most expense attributed to the commercial EEG headset. Future work includes transitioning to a 3D-printed chassis, integrating auto-regressive models to reduce EMG latency, and upgrading servo torque for improved load capacity and grip strength. This system demonstrates a feasible pathway to low-cost, biologically intuitive prosthetic control suitable for underserved and global health applications.", "AI": {"tldr": "\u672c\u9879\u76ee\u5f00\u53d1\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u53cc\u6a21\u5f0f\u795e\u7ecf\u808c\u8089\u63a7\u5236\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u8111\u7535\u56fe\uff08EEG\uff09\u548c\u808c\u7535\u56fe\uff08EMG\uff09\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u5047\u80a2\u624b\u81c2\u7684\u5b9e\u65f6\u591a\u81ea\u7531\u5ea6\u63a7\u5236\u3002\u901a\u8fc7\u4f7f\u7528\u7ecf\u6d4e\u5b9e\u60e0\u7684\u6750\u6599\u548c\u6280\u672f\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u4e3a\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u7684\u622a\u80a2\u8005\u63d0\u4f9b\u76f4\u89c2\u4e14\u529f\u80fd\u6027\u7684\u5047\u80a2\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u7531\u4e8e\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\uff0c\u4e0a\u80a2\u5047\u4f53\u5f80\u5f80\u7f3a\u4e4f\u76f4\u89c2\u7684\u63a7\u5236\u7cfb\u7edf\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u529f\u80fd\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002\u56e0\u6b64\uff0c\u8be5\u9879\u76ee\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u76f4\u89c2\u63a7\u5236\u7684\u5047\u80a2\u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3\u4f4e\u6536\u5165\u5730\u533a\u622a\u80a2\u8005\u7684\u9700\u6c42\u3002", "method": "\u9879\u76ee\u91c7\u7528\u4e86\u4e00\u4e2a\u7ed3\u5408\u4e86\u8111\u7535\u56fe(EEG)\u4e0e\u808c\u7535\u56fe(EMG)\u7684\u53cc\u6a21\u6001\u795e\u7ecf-\u808c\u8089\u63a7\u5236\u7cfb\u7edf\u3002EEG\u4fe1\u53f7\u901a\u8fc7NeuroSky MindWave Mobile 2\u8bbe\u5907\u91c7\u96c6\uff0c\u5e76\u901a\u8fc7\u84dd\u7259\u4f20\u8f93\u7ed9ESP32\u5fae\u63a7\u5236\u5668\u8fdb\u884c\u5904\u7406\u3002\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5206\u7c7b\u6a21\u578b\u88ab\u8bad\u7ec3\u6765\u8bc6\u522b\u5f3a\u7728\u773c\u4e8b\u4ef6\uff0c\u4ee5\u6b64\u4f5c\u4e3a\u5f00\u5173\u624b\u90e8\u72b6\u6001\u7684\u89e6\u53d1\u5668\u3002\u540c\u65f6\uff0cEMG\u4fe1\u53f7\u5219\u7531MyoWare 2.0\u4f20\u611f\u5668\u83b7\u53d6\u5e76\u901a\u8fc7\u65e0\u7ebf\u6a21\u5757\u53d1\u9001\u5230\u53e6\u4e00\u4e2aESP32\uff0c\u8be5\u5fae\u63a7\u5236\u5668\u6839\u636e\u9608\u503c\u68c0\u6d4b\u6765\u533a\u5206\u4e0d\u540c\u7684\u808c\u8089\u6d3b\u52a8\u9636\u6bb5\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u529f\u80fd\u6027\u539f\u578b\uff0c\u5176\u603b\u6210\u672c\u7ea6\u4e3a240\u7f8e\u5143\uff0c\u4e3b\u8981\u5f00\u652f\u6765\u81ea\u5546\u4e1aEEG\u5934\u6234\u8bbe\u5907\u3002\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u4f4e\u6210\u672c\u6750\u6599\u521b\u5efa\u51fa\u751f\u7269\u76f4\u89c9\u5f0f\u7684\u5047\u80a2\u63a7\u5236\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u670d\u52a1\u4e0d\u8db3\u5730\u533a\u53ca\u5168\u7403\u5065\u5eb7\u5e94\u7528\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u7ed3\u5408\u4e86EEG\u548cEMG\u7684\u4f4e\u6210\u672c\u53cc\u6a21\u5f0f\u63a7\u5236\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u5047\u80a2\u624b\u81c2\u7684\u53ef\u63a7\u6027\u548c\u81ea\u7136\u6027\uff0c\u5c24\u5176\u9002\u5408\u4e8e\u8d44\u6e90\u532e\u4e4f\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u96c6\u4e2d\u5728\u8fdb\u4e00\u6b65\u964d\u4f4e\u6210\u672c\u3001\u6539\u8fdb\u8bbe\u8ba1\u4ee5\u53ca\u63d0\u5347\u6027\u80fd\u7b49\u65b9\u9762\u3002"}}
{"id": "2512.17023", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17023", "abs": "https://arxiv.org/abs/2512.17023", "authors": ["Patrick Diehl", "Noujoud Nader", "Deepti Gupta"], "title": "LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation", "comment": null, "summary": "Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is still complex. Recently, Large Language Models (LLMs) have shown promise in automating code generation, but their effectiveness in producing correct and efficient HPC code is not well understood. In this work, we systematically evaluate leading LLMs including ChatGPT 4 and 5, Claude, and LLaMA on the task of generating C++ implementations of the Mandelbrot set using shared-memory, directive-based, and distributed-memory paradigms. Each generated program is compiled and executed with GCC 11.5.0 to assess its correctness, robustness, and scalability. Results show that ChatGPT-4 and ChatGPT-5 achieve strong syntactic precision and scalable performance.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u5305\u62ecChatGPT-4\u548c5\u3001Claude\u53caLLaMA\u5728\u5185\u7684\u9886\u5148\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u4f7f\u7528\u5171\u4eab\u5185\u5b58\u3001\u6307\u4ee4\u5f0f\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u8303\u5f0f\u7684C++\u5b9e\u73b0\u7684Mandelbrot\u96c6\u5408\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0cChatGPT-4\u548c5\u5728\u8bed\u6cd5\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3C++\u6807\u51c6\u548c\u50cfOpenMP\u4e0eMPI\u8fd9\u6837\u7684\u6846\u67b6\u5df2\u7ecf\u7b80\u5316\u4e86\u5e76\u884c\u7f16\u7a0b\uff0c\u4f46\u638c\u63e1\u8fd9\u4e9b\u8303\u5f0f\u4f9d\u7136\u590d\u6742\u3002\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u4e0a\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5bf9\u4e8e\u5b83\u4eec\u751f\u6210\u6b63\u786e\u7684\u9ad8\u6548HPC\u4ee3\u7801\u7684\u6709\u6548\u6027\u5c1a\u672a\u5145\u5206\u7406\u89e3\u3002", "method": "\u7814\u7a76\u8005\u4eec\u9009\u62e9\u4e86\u51e0\u4e2a\u9886\u5148\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5982ChatGPT 4\u548c5\u3001Claude\u4ee5\u53caLLaMA\uff0c\u5e76\u8ba9\u5b83\u4eec\u5b8c\u6210\u4e00\u9879\u7279\u5b9a\u7684\u4efb\u52a1\uff1a\u5229\u7528\u5171\u4eab\u5185\u5b58\u3001\u57fa\u4e8e\u6307\u4ee4\u7684\u65b9\u6cd5\u4ee5\u53ca\u5206\u5e03\u5f0f\u5185\u5b58\u8303\u5f0f\u6765\u751f\u6210\u8ba1\u7b97Mandelbrot\u96c6\u5408\u7684C++\u7a0b\u5e8f\u3002\u6bcf\u4e2a\u7531\u6a21\u578b\u751f\u6210\u7684\u7a0b\u5e8f\u968f\u540e\u88ab\u7f16\u8bd1\u5e76\u7528GCC 11.5.0\u7248\u672c\u6267\u884c\uff0c\u4ee5\u6d4b\u8bd5\u5176\u6b63\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChatGPT-4\u548cChatGPT-5\u5728\u751f\u6210\u5177\u6709\u9ad8\u8bed\u6cd5\u51c6\u786e\u6027\u4e14\u80fd\u5c55\u73b0\u826f\u597d\u53ef\u6269\u5c55\u6027\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u4ee3\u7801\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u751f\u6210\u9075\u5faa\u7279\u5b9a\u5e76\u884c\u7f16\u7a0b\u6a21\u5f0f\u7684C++\u4ee3\u7801\u65b9\u9762\uff0c\u67d0\u4e9b\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7279\u522b\u662fChatGPT-4\u548c5\u80fd\u591f\u63d0\u4f9b\u65e2\u7cbe\u786e\u53c8\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e3a\u672a\u6765\u901a\u8fc7AI\u8f85\u52a9\u5f00\u53d1\u9ad8\u8d28\u91cf\u5e76\u884c\u8f6f\u4ef6\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.17334", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17334", "abs": "https://arxiv.org/abs/2512.17334", "authors": ["Zhi Ma", "Cheng Wen", "Zhexin Su", "Xiao Liang", "Cong Tian", "Shengchao Qin", "Mengfei Yang"], "title": "Bridging Natural Language and Formal Specification--Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs", "comment": null, "summary": "Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to industrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT-4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose Req2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. Req2LTL leverages LLMs for semantic decomposition and combines them with deterministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that Req2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, significantly outperforming existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReq2LTL\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3aOnionL\u7684\u5206\u5c42\u4e2d\u95f4\u8868\u793a\u5f62\u5f0f\u8fde\u63a5\u81ea\u7136\u8bed\u8a00(NL)\u548c\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91(LTL)\uff0c\u4ee5\u89e3\u51b3\u5c06\u8f6f\u4ef6\u9700\u6c42\u4ece\u81ea\u7136\u8bed\u8a00\u81ea\u52a8\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u89c4\u683c\u8bf4\u660e\u7684\u6311\u6218\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u4e2d\uff0c\u81ea\u52a8\u5316\u5730\u5c06\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u8f6f\u4ef6\u9700\u6c42\u8f6c\u5316\u4e3a\u6b63\u5f0f\u89c4\u8303\u662f\u6269\u5c55\u5f62\u5f0f\u9a8c\u8bc1\u5b9e\u8df5\u5230\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\uff0c\u65e0\u8bba\u662f\u57fa\u4e8e\u89c4\u5219\u8fd8\u662f\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u90fd\u9762\u4e34\u91cd\u5927\u5c40\u9650\u6027\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c3d\u7ba1\u5728\u8bed\u4e49\u63d0\u53d6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u5de5\u4e1a\u9700\u6c42\u7684\u590d\u6742\u6027\u3001\u6a21\u7cca\u6027\u548c\u903b\u8f91\u6df1\u5ea6\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86Req2LTL\uff0c\u8fd9\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3aOnionL\u7684\u5206\u5c42\u4e2d\u4ecb\u8868\u793a\u6765\u6865\u63a5\u81ea\u7136\u8bed\u8a00\u4e0e\u7ebf\u6027\u65f6\u95f4\u903b\u8f91\uff08LTL\uff09\u3002\u6b64\u6846\u67b6\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5206\u89e3\uff0c\u5e76\u7ed3\u5408\u786e\u5b9a\u6027\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5408\u6210\u4ee5\u4fdd\u8bc1\u8bed\u6cd5\u6b63\u786e\u6027\u548c\u8bed\u4e49\u5fe0\u5b9e\u5ea6\u3002", "result": "\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff0cReq2LTL\u5728\u5b9e\u9645\u822a\u7a7a\u822a\u5929\u8981\u6c42\u4e0a\u5b9e\u73b0\u4e8688.4%\u7684\u8bed\u4e49\u51c6\u786e\u7387\u548c100%\u7684\u53e5\u6cd5\u6b63\u786e\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Req2LTL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5c06\u81ea\u7136\u8bed\u8a00\u8f6f\u4ef6\u9700\u6c42\u8f6c\u6362\u6210\u5f62\u5f0f\u5316\u89c4\u683c\u8bf4\u660e\u7684\u96be\u9898\uff0c\u5c24\u5176\u5bf9\u4e8e\u590d\u6742\u4e14\u903b\u8f91\u6027\u5f3a\u7684\u5b9e\u9645\u5de5\u4e1a\u9700\u6c42\u5c55\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.17164", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17164", "abs": "https://arxiv.org/abs/2512.17164", "authors": ["Yu Yang", "Feng Tian", "Ping Chen"], "title": "TCDE: Topic-Centric Dual Expansion of Queries and Documents with Large Language Models for Information Retrieval", "comment": null, "summary": "Query Expansion (QE) enriches queries and Document Expansion (DE) enriches documents, and these two techniques are often applied separately. However, such separate application may lead to semantic misalignment between the expanded queries (or documents) and their relevant documents (or queries). To address this serious issue, we propose TCDE, a dual expansion strategy that leverages large language models (LLMs) for topic-centric enrichment on both queries and documents. In TCDE, we design two distinct prompt templates for processing each query and document. On the query side, an LLM is guided to identify distinct sub-topics within each query and generate a focused pseudo-document for each sub-topic. On the document side, an LLM is guided to distill each document into a set of core topic sentences. The resulting outputs are used to expand the original query and document. This topic-centric dual expansion process establishes semantic bridges between queries and their relevant documents, enabling better alignment for downstream retrieval models. Experiments on two challenging benchmarks, TREC Deep Learning and BEIR, demonstrate that TCDE achieves substantial improvements over strong state-of-the-art expansion baselines. In particular, on dense retrieval tasks, it outperforms several state-of-the-art methods, with a relative improvement of 2.8\\% in NDCG@10 on the SciFact dataset. Experimental results validate the effectiveness of our topic-centric and dual expansion strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86TCDE\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u9898\u4e2d\u5fc3\u53cc\u91cd\u6269\u5c55\u7b56\u7565\uff0c\u7528\u4e8e\u540c\u65f6\u4e30\u5bcc\u67e5\u8be2\u548c\u6587\u6863\u3002\u901a\u8fc7\u8bbe\u8ba1\u4e0d\u540c\u7684\u63d0\u793a\u6a21\u677f\u6765\u5904\u7406\u6bcf\u4e2a\u67e5\u8be2\u548c\u6587\u6863\uff0c\u4ece\u800c\u5728\u67e5\u8be2\u548c\u76f8\u5173\u6587\u6863\u4e4b\u95f4\u5efa\u7acb\u8bed\u4e49\u6865\u6881\uff0c\u63d0\u9ad8\u4e0b\u6e38\u68c0\u7d22\u6a21\u578b\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u5bc6\u96c6\u68c0\u7d22\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u4e00\u4e9b\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u67e5\u8be2\u6269\u5c55\uff08QE\uff09\u548c\u6587\u6863\u6269\u5c55\uff08DE\uff09\u6280\u672f\u901a\u5e38\u662f\u5206\u5f00\u5e94\u7528\u7684\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6269\u5c55\u540e\u7684\u67e5\u8be2\u6216\u6587\u6863\u4e0e\u5176\u76f8\u5173\u7684\u6587\u6863\u6216\u67e5\u8be2\u4e4b\u95f4\u51fa\u73b0\u8bed\u4e49\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u6269\u5c55\u7b56\u7565\u2014\u2014TCDE\uff0c\u65e8\u5728\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u67e5\u8be2\u548c\u6587\u6863\u8fdb\u884c\u4e3b\u9898\u4e3a\u4e2d\u5fc3\u7684\u4e30\u5bcc\u5904\u7406\uff0c\u4ee5\u6539\u5584\u5b83\u4eec\u4e4b\u95f4\u7684\u8bed\u4e49\u5bf9\u9f50\u5ea6\u3002", "method": "TCDE\u91c7\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u6a21\u677f\u5206\u522b\u5904\u7406\u67e5\u8be2\u4e0e\u6587\u6863\uff1a\u5bf9\u4e8e\u67e5\u8be2\uff0c\u5f15\u5bfcLLM\u8bc6\u522b\u6bcf\u4e2a\u67e5\u8be2\u4e2d\u7684\u4e0d\u540c\u5b50\u4e3b\u9898\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u5b50\u4e3b\u9898\u751f\u6210\u4e00\u4e2a\u4e13\u6ce8\u7684\u4f2a\u6587\u6863\uff1b\u5bf9\u4e8e\u6587\u6863\uff0c\u5219\u662f\u6307\u5bfcLLM\u63d0\u70bc\u51fa\u6bcf\u7bc7\u6587\u6863\u7684\u6838\u5fc3\u4e3b\u9898\u53e5\u3002\u6700\u7ec8\uff0c\u5c06\u8fd9\u4e9b\u8f93\u51fa\u7528\u6765\u6269\u5c55\u539f\u59cb\u67e5\u8be2\u548c\u6587\u6863\uff0c\u4ee5\u6b64\u5efa\u7acb\u67e5\u8be2\u4e0e\u5176\u76f8\u5173\u6587\u6863\u95f4\u7684\u8bed\u4e49\u8054\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728TREC Deep Learning\u548cBEIR\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTCDE\u76f8\u8f83\u4e8e\u5f3a\u5927\u7684\u73b0\u6709\u6269\u5c55\u57fa\u7ebf\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u3002\u7279\u522b\u5730\uff0c\u5728SciFact\u6570\u636e\u96c6\u4e0a\u7684\u5bc6\u96c6\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0cNDCG@10\u6307\u6807\u76f8\u5bf9\u63d0\u9ad8\u4e862.8%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u4e3b\u9898\u7684\u53cc\u6269\u5c55\u7b56\u7565TCDE\u80fd\u591f\u6709\u6548\u5730\u589e\u5f3a\u67e5\u8be2\u4e0e\u6587\u6863\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u8fdb\u800c\u63d0\u5347\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6b64\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u89e3\u51b3\u5bc6\u96c6\u68c0\u7d22\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u4f18\u4e8e\u591a\u79cd\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.17077", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17077", "abs": "https://arxiv.org/abs/2512.17077", "authors": ["Jiakun Fan", "Yanglin Zhang", "Xiangchen Li", "Dimitrios S. Nikolopoulos"], "title": "Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addresses the unique memory dynamics of diffusion processes in production. We identify a critical \"memory footprint crisis\" specific to dLLMs, driven by monolithic logit tensors and the severe resource oscillation between compute-bound \"Refresh\" phases and bandwidth-bound \"Reuse\" phases. To bridge this gap, we present dLLM-Serve, an efficient dLLM serving system that co-optimizes memory footprint, computational scheduling, and generation quality. dLLM-Serve introduces Logit-Aware Activation Budgeting to decompose transient tensor peaks, a Phase-Multiplexed Scheduler to interleave heterogeneous request phases, and Head-Centric Sparse Attention to decouple logical sparsity from physical storage. We evaluate dLLM-Serve on diverse workloads (LiveBench, Burst, OSC) and GPUs (RTX 4090, L40S). Relative to the state-of-the-art baseline, dLLM-Serve improves throughput by 1.61$\\times$-1.81$\\times$ on the consumer-grade RTX 4090 and 1.60$\\times$-1.74$\\times$ on the server-grade NVIDIA L40S, while reducing tail latency by nearly 4$\\times$ under heavy contention. dLLM-Serve establishes the first blueprint for scalable dLLM inference, converting theoretical algorithmic sparsity into tangible wall-clock acceleration across heterogeneous hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fadLLM-Serve\uff0c\u4e00\u4e2a\u9ad8\u6548\u7684\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u5360\u7528\u3001\u8ba1\u7b97\u8c03\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u6765\u89e3\u51b3dLLMs\u7279\u6709\u7684\u201c\u5185\u5b58\u5360\u7528\u5371\u673a\u201d\u3002dLLM-Serve\u5728\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u548cGPU\u4e0a\u5747\u8868\u73b0\u51fa\u663e\u8457\u7684\u541e\u5410\u91cf\u63d0\u5347\u548c\u5c3e\u90e8\u5ef6\u8fdf\u51cf\u5c11\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u7684\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5185\u6838\u7ea7\u4f18\u5316\u800c\u7f3a\u4e4f\u5168\u9762\u7684\u670d\u52a1\u6846\u67b6\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u8fd9\u4e9b\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u9762\u4e34\u7684\u72ec\u7279\u5185\u5b58\u52a8\u6001\u6311\u6218\uff0c\u5305\u62ec\u7531\u5355\u4f53logit\u5f20\u91cf\u5bfc\u81f4\u7684\u5927\u5185\u5b58\u5360\u7528\u4ee5\u53ca\u8ba1\u7b97\u5bc6\u96c6\u578b\u2018\u5237\u65b0\u2019\u9636\u6bb5\u4e0e\u5e26\u5bbd\u53d7\u9650\u578b\u2018\u91cd\u7528\u2019\u9636\u6bb5\u4e4b\u95f4\u8d44\u6e90\u6ce2\u52a8\u5267\u70c8\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86dLLM-Serve\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3adLLMs\u8bbe\u8ba1\u7684\u670d\u52a1\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u5f15\u5165Logit-Aware\u6fc0\u6d3b\u9884\u7b97\u5206\u914d\u3001\u76f8\u4f4d\u591a\u8def\u590d\u7528\u8c03\u5ea6\u5668\u4ee5\u53ca\u5934\u4e2d\u5fc3\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6765\u5171\u540c\u4f18\u5316\u5185\u5b58\u5360\u7528\u3001\u8ba1\u7b97\u8c03\u5ea6\u53ca\u751f\u6210\u8d28\u91cf\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u4efb\u52a1\u8d1f\u8f7d\uff08\u5982LiveBench, Burst, OSC\uff09\u548c\u4e0d\u540c\u7684GPU\u578b\u53f7\uff08RTX 4090, L40S\uff09\u6d4b\u8bd5\u4e2d\uff0cdLLM-Serve\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u57fa\u51c6\uff0c\u5728\u6d88\u8d39\u7ea7RTX 4090 GPU\u4e0a\u7684\u541e\u5410\u91cf\u63d0\u9ad8\u4e861.61\u500d\u81f31.81\u500d\uff0c\u5728\u670d\u52a1\u5668\u7ea7NVIDIA L40S GPU\u4e0a\u63d0\u9ad8\u4e861.60\u500d\u81f31.74\u500d\uff0c\u5e76\u4e14\u5728\u9ad8\u7ade\u4e89\u6761\u4ef6\u4e0b\u51cf\u5c11\u4e86\u63a5\u8fd14\u500d\u7684\u5c3e\u90e8\u5ef6\u8fdf\u3002", "conclusion": "dLLM-Serve\u4e3a\u53ef\u6269\u5c55\u7684dLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u84dd\u56fe\uff0c\u6210\u529f\u5730\u5c06\u7406\u8bba\u4e0a\u7684\u7b97\u6cd5\u7a00\u758f\u6027\u8f6c\u5316\u4e3a\u8de8\u5f02\u6784\u786c\u4ef6\u7684\u5b9e\u9645\u52a0\u901f\u6548\u679c\u3002"}}
{"id": "2512.17363", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17363", "abs": "https://arxiv.org/abs/2512.17363", "authors": ["Yuqing Niu", "Jieke Shi", "Ruidong Han", "Ye Liu", "Chengyan Ma", "Yunbo Lyu", "David Lo"], "title": "What You Trust Is Insecure: Demystifying How Developers (Mis)Use Trusted Execution Environments in Practice", "comment": "Accepted by the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026), 13 Pages", "summary": "Trusted Execution Environments (TEEs), such as Intel SGX and ARM TrustZone, provide isolated regions of CPU and memory for secure computation and are increasingly used to protect sensitive data and code across diverse application domains. However, little is known about how developers actually use TEEs in practice. This paper presents the first large-scale empirical study of real-world TEE applications. We collected and analyzed 241 open-source projects from GitHub that utilize the two most widely-adopted TEEs, Intel SGX and ARM TrustZone. By combining manual inspection with customized static analysis scripts, we examined their adoption contexts, usage patterns, and development practices across three phases. First, we categorized the projects into 8 application domains and identified trends in TEE adoption over time. We found that the dominant use case is IoT device security (30%), which contrasts sharply with prior academic focus on blockchain and cryptographic systems (7%), while AI model protection (12%) is rapidly emerging as a growing domain. Second, we analyzed how TEEs are integrated into software and observed that 32.4% of the projects reimplement cryptographic functionalities instead of using official SDK APIs, suggesting that current SDKs may have limited usability and portability to meet developers' practical needs. Third, we examined security practices through manual inspection and found that 25.3% (61 of 241) of the projects exhibit insecure coding behaviors when using TEEs, such as hardcoded secrets and missing input validation, which undermine their intended security guarantees. Our findings have important implications for improving the usability of TEE SDKs and supporting developers in trusted software development.", "AI": {"tldr": "\u672c\u6587\u8fdb\u884c\u4e86\u9996\u6b21\u5927\u89c4\u6a21\u7684\u5b9e\u9645TEE\u5e94\u7528\u7a0b\u5e8f\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86241\u4e2a\u4f7f\u7528Intel SGX\u548cARM TrustZone\u7684\u5f00\u6e90\u9879\u76ee\u3002\u7814\u7a76\u53d1\u73b0\u7269\u8054\u7f51\u8bbe\u5907\u5b89\u5168\u662f\u4e3b\u8981\u7684\u5e94\u7528\u9886\u57df\uff0c\u5176\u6b21\u662f\u5feb\u901f\u53d1\u5c55\u7684AI\u6a21\u578b\u4fdd\u62a4\u3002\u6b64\u5916\uff0c\u8d85\u8fc730%\u7684\u9879\u76ee\u91cd\u65b0\u5b9e\u73b0\u4e86\u52a0\u5bc6\u529f\u80fd\u800c\u4e0d\u662f\u4f7f\u7528\u5b98\u65b9SDK API\uff0c\u800c\u8fd1\u56db\u5206\u4e4b\u4e00\u7684\u9879\u76ee\u5b58\u5728\u4e0d\u5b89\u5168\u7684\u7f16\u7801\u884c\u4e3a\u3002", "motivation": "\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEEs)\u5982Intel SGX\u548cARM TrustZone\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4fdd\u62a4\u654f\u611f\u6570\u636e\u548c\u4ee3\u7801\uff0c\u4f46\u5f00\u53d1\u8005\u5982\u4f55\u5b9e\u9645\u8fd0\u7528\u8fd9\u4e9b\u6280\u672f\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e86GitHub\u4e0a\u5229\u7528Intel SGX\u548cARM TrustZone\u7684241\u4e2a\u5f00\u6e90\u9879\u76ee\u3002\u901a\u8fc7\u7ed3\u5408\u624b\u52a8\u68c0\u67e5\u4e0e\u5b9a\u5236\u7684\u9759\u6001\u5206\u6790\u811a\u672c\uff0c\u8003\u5bdf\u4e86\u5b83\u4eec\u5728\u4e09\u4e2a\u4e0d\u540c\u9636\u6bb5\u7684\u91c7\u7528\u80cc\u666f\u3001\u4f7f\u7528\u6a21\u5f0f\u53ca\u5f00\u53d1\u5b9e\u8df5\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u7269\u8054\u7f51\u8bbe\u5907\u5b89\u5168\u662f\u6700\u4e3b\u8981\u7684\u5e94\u7528\u573a\u666f\uff08\u536030%\uff09\uff0c\u4e0e\u4e4b\u524d\u5b66\u672f\u754c\u5bf9\u533a\u5757\u94fe\u548c\u5bc6\u7801\u7cfb\u7edf\uff087%\uff09\u7684\u5173\u6ce8\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff1b\u540c\u65f6\uff0cAI\u6a21\u578b\u4fdd\u62a4\uff0812%\uff09\u6b63\u5728\u6210\u4e3a\u4e00\u4e2a\u5feb\u901f\u589e\u957f\u7684\u65b0\u9886\u57df\u3002\u6b64\u5916\uff0c\u670932.4%\u7684\u9879\u76ee\u9009\u62e9\u91cd\u65b0\u5b9e\u73b0\u52a0\u5bc6\u529f\u80fd\u800c\u975e\u76f4\u63a5\u4f7f\u7528\u5b98\u65b9SDK\u63d0\u4f9b\u7684API\uff0c\u8fd9\u8868\u660e\u5f53\u524dSDK\u53ef\u80fd\u5728\u53ef\u7528\u6027\u548c\u53ef\u79fb\u690d\u6027\u65b9\u9762\u65e0\u6cd5\u5145\u5206\u6ee1\u8db3\u5f00\u53d1\u8005\u9700\u6c42\u3002\u53e6\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b025.3%\uff08\u517161\u4e2a\u9879\u76ee\uff09\u5b58\u5728\u4e0d\u5b89\u5168\u7684\u7f16\u7a0b\u4e60\u60ef\uff0c\u6bd4\u5982\u786c\u7f16\u7801\u5bc6\u94a5\u4ee5\u53ca\u7f3a\u5c11\u8f93\u5165\u9a8c\u8bc1\u7b49\uff0c\u8fd9\u4e9b\u90fd\u524a\u5f31\u4e86TEE\u5e94\u6709\u7684\u5b89\u5168\u4fdd\u969c\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u7684\u7ed3\u679c\u5bf9\u4e8e\u63d0\u9ad8TEE SDK\u7684\u53ef\u7528\u6027\u4ee5\u53ca\u652f\u6301\u5f00\u53d1\u4eba\u5458\u8fdb\u884c\u53d7\u4fe1\u8f6f\u4ef6\u5f00\u53d1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.17277", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17277", "abs": "https://arxiv.org/abs/2512.17277", "authors": ["Saeed Ebrahimi", "Weijie Jiang", "Jaewon Yang", "Olafur Gudmundsson", "Yucheng Tu", "Huizhong Duan"], "title": "Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest", "comment": "Submitted to the WWW'26", "summary": "Pinterest is a leading visual discovery platform where recommender systems (RecSys) are key to delivering relevant, engaging, and fresh content to our users. In this paper, we study the problem of improving RecSys model predictions for cold-start (CS) items, which appear infrequently in the training data. Although this problem is well-studied in academia, few studies have addressed its root causes effectively at the scale of a platform like Pinterest. By investigating live traffic data, we identified several challenges of the CS problem and developed a corresponding solution for each: First, industrial-scale RecSys models must operate under tight computational constraints. Since CS items are a minority, any related improvements must be highly cost-efficient. To address this, our solutions were designed to be lightweight, collectively increasing the total parameters by only 5%. Second, CS items are represented only by non-historical (e.g., content or attribute) features, which models often treat as less important. To elevate their significance, we introduce a residual connection for the non-historical features. Third, CS items tend to receive lower prediction scores compared to non-CS items, reducing their likelihood of being surfaced. We mitigate this by incorporating a score regularization term into the model. Fourth, the labels associated with CS items are sparse, making it difficult for the model to learn from them. We apply the manifold mixup technique to address this data sparsity. Implemented together, our methods increased fresh content engagement at Pinterest by 10% without negatively impacting overall engagement and cost, and have been deployed to serve over 570 million users on Pinterest.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u6539\u8fdb\u51b7\u542f\u52a8\u9879\u76ee\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u9884\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3001\u975e\u5386\u53f2\u7279\u5f81\u7684\u6b8b\u5dee\u8fde\u63a5\u3001\u9884\u6d4b\u5206\u6570\u7684\u6b63\u5219\u5316\u4ee5\u53ca\u5229\u7528manifold mixup\u6280\u672f\u6765\u89e3\u51b3\u6807\u7b7e\u7a00\u758f\u6027\u95ee\u9898\uff0c\u6700\u7ec8\u4f7f\u65b0\u9c9c\u5185\u5bb9\u7684\u53c2\u4e0e\u5ea6\u63d0\u9ad8\u4e8610%\uff0c\u5e76\u5df2\u90e8\u7f72\u670d\u52a1\u4e8e\u8d85\u8fc75.7\u4ebf\u7528\u6237\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3Pinterest\u5e73\u53f0\u4e0a\u51b7\u542f\u52a8\uff08CS\uff09\u9879\u76ee\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u51fa\u73b0\u9891\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u76f8\u5173\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u540c\u65f6\u4fdd\u8bc1\u89e3\u51b3\u65b9\u6848\u7684\u6210\u672c\u6548\u76ca\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5b9e\u9645\u6d41\u91cf\u6570\u636e\u8bc6\u522b\u51fa\u51b7\u542f\u52a8\u9879\u76ee\u7684\u6311\u6218\uff0c\u5e76\u9488\u5bf9\u6bcf\u4e2a\u6311\u6218\u5f00\u53d1\u4e86\u89e3\u51b3\u65b9\u6848\uff1a\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u4ee5\u9002\u5e94\u8ba1\u7b97\u9650\u5236\uff1b\u5f15\u5165\u975e\u5386\u53f2\u7279\u5f81\u7684\u6b8b\u5dee\u8fde\u63a5\u63d0\u5347\u5176\u91cd\u8981\u6027\uff1b\u52a0\u5165\u8bc4\u5206\u6b63\u5219\u5316\u9879\u51cf\u5c11CS\u9879\u76ee\u5f97\u5206\u504f\u4f4e\u7684\u95ee\u9898\uff1b\u5e94\u7528manifold mixup\u6280\u672f\u5904\u7406\u6570\u636e\u7a00\u758f\u6027\u95ee\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5171\u540c\u4f5c\u7528\u4e0b\uff0cPinterest\u7684\u65b0\u9c9c\u5185\u5bb9\u53c2\u4e0e\u5ea6\u63d0\u9ad8\u4e8610%\uff0c\u4e14\u672a\u5bf9\u6574\u4f53\u53c2\u4e0e\u5ea6\u53ca\u6210\u672c\u9020\u6210\u8d1f\u9762\u5f71\u54cd\u3002\u8fd9\u4e9b\u6539\u8fdb\u63aa\u65bd\u5df2\u88ab\u90e8\u7f72\uff0c\u670d\u52a1\u4e8e\u8d85\u8fc75.7\u4ebf\u7528\u6237\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u89c6\u89c9\u53d1\u73b0\u5e73\u53f0\u5982Pinterest\u4e0a\u51b7\u542f\u52a8\u9879\u76ee\u9762\u4e34\u7684\u51e0\u4e2a\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u9488\u5bf9\u6027\u5f3a\u3001\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.17264", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17264", "abs": "https://arxiv.org/abs/2512.17264", "authors": ["Yuming Xu", "Qianxi Zhang", "Qi Chen", "Baotong Lu", "Menghao Li", "Philip Adams", "Mingqin Li", "Zengzhong Li", "Jing Liu", "Cheng Li", "Fan Yang"], "title": "Scalable Distributed Vector Search via Accuracy Preserving Index Construction", "comment": null, "summary": "Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it identifies a balanced partition granularity that avoids read-cost explosion. Second, it introduces an accuracy-preserving recursive construction that builds a multi-level index with predictable search cost and stable accuracy. In experiments with up to 8 billion vectors across 46 nodes, SPIRE achieves high scalability and up to 9.64X higher throughput than state-of-the-art systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPIRE\u7684\u53ef\u6269\u5c55\u5411\u91cf\u7d22\u5f15\uff0c\u901a\u8fc7\u5e73\u8861\u5206\u533a\u7c92\u5ea6\u548c\u4fdd\u6301\u51c6\u786e\u6027\u7684\u9012\u5f52\u6784\u5efa\u65b9\u6cd5\uff0c\u5728\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u6bd4\u73b0\u6709\u7cfb\u7edf\u9ad8\u8fbe9.64\u500d\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u5e03\u5f0f\u7d22\u5f15\u8bbe\u8ba1\u96be\u4ee5\u5728\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6570\u5341\u4ebf\u7ea7\u522b\u7684\u5411\u91cf\u65f6\u3002", "method": "SPIRE\u57fa\u4e8e\u4e24\u4e2a\u4e3b\u8981\u8bbe\u8ba1\u51b3\u7b56\uff1a\u786e\u5b9a\u4e00\u79cd\u907f\u514d\u8bfb\u53d6\u6210\u672c\u6fc0\u589e\u7684\u5e73\u8861\u5206\u533a\u7c92\u5ea6\uff1b\u5f15\u5165\u4e00\u79cd\u4fdd\u6301\u51c6\u786e\u6027\u7684\u9012\u5f52\u6784\u5efa\u65b9\u6cd5\uff0c\u521b\u5efa\u5177\u6709\u53ef\u9884\u6d4b\u641c\u7d22\u6210\u672c\u548c\u7a33\u5b9a\u51c6\u786e\u6027\u7684\u591a\u7ea7\u7d22\u5f15\u3002", "result": "\u5728\u5305\u542b\u591a\u8fbe80\u4ebf\u4e2a\u5411\u91cf\u53ca\u6a2a\u8de846\u4e2a\u8282\u70b9\u7684\u5b9e\u9a8c\u4e2d\uff0cSPIRE\u5c55\u793a\u4e86\u51fa\u8272\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4e14\u76f8\u6bd4\u6700\u5148\u8fdb\u7cfb\u7edf\u5b9e\u73b0\u4e86\u6700\u9ad8\u8fbe9.64\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "SPIRE\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u53ef\u6269\u5c55\u5411\u91cf\u7d22\u5f15\u65b9\u6848\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5411\u91cf\u68c0\u7d22\u573a\u666f\u4e0b\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u4e3aANNS\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u9009\u62e9\u3002"}}
{"id": "2512.17389", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.17389", "abs": "https://arxiv.org/abs/2512.17389", "authors": ["Guangneng Hu"], "title": "The Mental World of Large Language Models in Recommendation: A Benchmark on Association, Personalization, and Knowledgeability", "comment": "21 pages, 13 figures, 27 tables, submission to KDD 2025", "summary": "Large language models (LLMs) have shown potential in recommendation systems (RecSys) by using them as either knowledge enhancer or zero-shot ranker. A key challenge lies in the large semantic gap between LLMs and RecSys where the former internalizes language world knowledge while the latter captures personalized world of behaviors. Unfortunately, the research community lacks a comprehensive benchmark that evaluates the LLMs over their limitations and boundaries in RecSys so that we can draw a confident conclusion. To investigate this, we propose a benchmark named LRWorld containing over 38K high-quality samples and 23M tokens carefully compiled and generated from widely used public recommendation datasets. LRWorld categorizes the mental world of LLMs in RecSys as three main scales (association, personalization, and knowledgeability) spanned by ten factors with 31 measures (tasks). Based on LRWorld, comprehensive experiments on dozens of LLMs show that they are still not well capturing the deep neural personalized embeddings but can achieve good results on shallow memory-based item-item similarity. They are also good at perceiving item entity relations, entity hierarchical taxonomies, and item-item association rules when inferring user interests. Furthermore, LLMs show a promising ability in multimodal knowledge reasoning (movie poster and product image) and robustness to noisy profiles. None of them show consistently good performance over the ten factors. Model sizes, position bias, and more are ablated.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLRWorld\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u8350\u7cfb\u7edf\uff08RecSys\uff09\u4e2d\u7684\u5c40\u9650\u6027\u548c\u8fb9\u754c\u3002\u57fa\u4e8e\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u6570\u5341\u79cdLLMs\u8fdb\u884c\u4e86\u7efc\u5408\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u5728\u6d45\u5c42\u57fa\u4e8e\u8bb0\u5fc6\u7684\u9879\u76ee-\u9879\u76ee\u76f8\u4f3c\u6027\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6355\u6349\u6df1\u5c42\u795e\u7ecf\u4e2a\u6027\u5316\u5d4c\u5165\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002\u6b64\u5916\uff0cLLMs\u5728\u591a\u6a21\u6001\u77e5\u8bc6\u63a8\u7406\u548c\u5bf9\u566a\u58f0\u6982\u51b5\u7684\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u63a8\u8350\u7cfb\u7edf\u7684\u77e5\u8bc6\u589e\u5f3a\u5668\u6216\u96f6\u6837\u672c\u6392\u540d\u5668\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u7740\u5de8\u5927\u7684\u8bed\u4e49\u5dee\u8ddd\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e76\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u8bc4\u4f30LLMs\u5728RecSys\u4e2d\u5c40\u9650\u6027\u548c\u8fb9\u754c\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u51fa\u4e86LRWorld\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc738,000\u4e2a\u9ad8\u8d28\u91cf\u6837\u672c\u548c2300\u4e07\u4e2a\u4ee4\u724c\u7684\u57fa\u51c6\u6d4b\u8bd5LRWorld\uff0c\u8fd9\u4e9b\u6570\u636e\u662f\u4ece\u5e7f\u6cdb\u4f7f\u7528\u7684\u516c\u5171\u63a8\u8350\u6570\u636e\u96c6\u4e2d\u7cbe\u5fc3\u7f16\u8bd1\u751f\u6210\u7684\u3002LRWorld\u5c06LLMs\u5728RecSys\u4e2d\u7684\u5fc3\u667a\u4e16\u754c\u5206\u7c7b\u4e3a\u4e09\u4e2a\u4e3b\u8981\u5c3a\u5ea6\uff08\u5173\u8054\u3001\u4e2a\u6027\u5316\u3001\u77e5\u8bc6\u80fd\u529b\uff09\uff0c\u5e76\u7531\u5341\u4e2a\u56e0\u7d20\u901a\u8fc731\u9879\u6307\u6807\uff08\u4efb\u52a1\uff09\u8fdb\u884c\u8861\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLLMs\u80fd\u591f\u5f88\u597d\u5730\u5904\u7406\u6d45\u5c42\u57fa\u4e8e\u8bb0\u5fc6\u7684\u9879\u76ee-\u9879\u76ee\u76f8\u4f3c\u6027\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8e\u6df1\u5c42\u795e\u7ecf\u4e2a\u6027\u5316\u5d4c\u5165\u7684\u7406\u89e3\u4e0d\u591f\u5145\u5206\u3002\u540c\u65f6\uff0c\u5728\u611f\u77e5\u9879\u76ee\u5b9e\u4f53\u5173\u7cfb\u3001\u5b9e\u4f53\u5c42\u6b21\u5206\u7c7b\u6cd5\u4ee5\u53ca\u63a8\u65ad\u7528\u6237\u5174\u8da3\u65f6\u7684\u9879\u76ee-\u9879\u76ee\u5173\u8054\u89c4\u5219\u65b9\u9762\u8868\u73b0\u8f83\u597d\u3002\u6b64\u5916\uff0cLLMs\u5728\u591a\u6a21\u6001\u77e5\u8bc6\u63a8\u7406\uff08\u5982\u7535\u5f71\u6d77\u62a5\u548c\u4ea7\u54c1\u56fe\u7247\uff09\u53ca\u5e94\u5bf9\u5608\u6742\u8d44\u6599\u65b9\u9762\u663e\u793a\u51fa\u4e86\u826f\u597d\u7684\u524d\u666f\u3002\u7136\u800c\uff0c\u6ca1\u6709\u4efb\u4f55\u4e00\u79cd\u6a21\u578b\u5728\u8fd9\u5341\u4e2a\u56e0\u7d20\u4e0a\u90fd\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u67d0\u4e9bRecSys\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u6d45\u5c42\u9879\u76ee-\u9879\u76ee\u76f8\u4f3c\u6027\u548c\u591a\u6a21\u6001\u77e5\u8bc6\u63a8\u7406\u65b9\u9762\uff0c\u4f46\u5b83\u4eec\u5bf9\u4e8e\u6df1\u5c42\u4e2a\u6027\u5316\u7279\u5f81\u7684\u7406\u89e3\u4ecd\u6709\u5f85\u63d0\u9ad8\u3002LRWorld\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002"}}
{"id": "2512.16967", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16967", "abs": "https://arxiv.org/abs/2512.16967", "authors": ["Marcelo Cerda Castillo"], "title": "Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes", "comment": "12 pages, 5 tables, 1 figure. Uses publicly available METAR surface observations and TAF forecast data for benchmarking", "summary": "Short-term prediction (nowcasting) of low-visibility and precipitation events is critical for aviation safety and operational efficiency. Current operational approaches rely on computationally intensive numerical weather prediction guidance and human-issued TAF products, which often exhibit conservative biases and limited temporal resolution. This study presents a lightweight gradient boosting framework (XGBoost) trained exclusively on surface observation data (METAR) and enhanced through physics-guided feature engineering based on thermodynamic principles. The framework is evaluated across 11 international airports representing distinct climatic regimes (including SCEL, KJFK, KORD, KDEN, SBGR, and VIDP) using historical data from 2000 to 2024. Results suggest that the model successfully captures underlying local physical processes without manual configuration. In a blind comparative evaluation against operational TAF forecasts, the automated model achieved substantially higher detection rates at tactical horizons (3 hours), with a 2.5 to 4.0 times improvement in recall while reducing false alarms. Furthermore, SHAP analysis reveals that the model performs an implicit reconstruction of local physical drivers (advection, radiation, and subsidence), providing actionable explainability for operational situational awareness.\n  Keywords: aviation meteorology; physics-guided machine learning; explainable artificial intelligence; lightweight machine learning; nowcasting; METAR; TAF verification; edge computing", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u5f15\u5bfc\u7279\u5f81\u5de5\u7a0b\u7684\u8f7b\u91cf\u7ea7\u68af\u5ea6\u63d0\u5347\u6846\u67b6\uff08XGBoost\uff09\uff0c\u4ec5\u4f7f\u7528\u5730\u9762\u89c2\u6d4b\u6570\u636e\uff08METAR\uff09\u6765\u9884\u6d4b\u4f4e\u80fd\u89c1\u5ea6\u548c\u964d\u6c34\u4e8b\u4ef6\u3002\u8be5\u6a21\u578b\u572811\u4e2a\u56fd\u9645\u673a\u573a\u7684\u5386\u53f2\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684TAF\u9884\u62a5\uff0c\u5728\u6218\u672f\u65f6\u95f4\u5c3a\u5ea6\uff083\u5c0f\u65f6\uff09\u5185\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u68c0\u6d4b\u7387\uff0c\u5e76\u51cf\u5c11\u4e86\u8bef\u62a5\u3002\u6b64\u5916\uff0c\u901a\u8fc7SHAP\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u80fd\u591f\u9690\u5f0f\u91cd\u5efa\u5c40\u90e8\u7269\u7406\u9a71\u52a8\u56e0\u7d20\uff0c\u5982\u5e73\u6d41\u3001\u8f90\u5c04\u548c\u4e0b\u6c89\uff0c\u4e3a\u64cd\u4f5c\u60c5\u666f\u610f\u8bc6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u822a\u7a7a\u6c14\u8c61\u9884\u62a5\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\u6307\u5bfc\u548c\u4eba\u5de5\u53d1\u5e03\u7684TAF\u4ea7\u54c1\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u5b58\u5728\u4fdd\u5b88\u504f\u5dee\u4e14\u65f6\u95f4\u5206\u8fa8\u7387\u6709\u9650\u3002\u4e3a\u4e86\u63d0\u9ad8\u822a\u7a7a\u5b89\u5168\u6027\u548c\u8fd0\u8425\u6548\u7387\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u66f4\u52a0\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u77ed\u671f\u5929\u6c14\u4e8b\u4ef6\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u68af\u5ea6\u63d0\u5347\u6846\u67b6XGBoost\uff0c\u4ec5\u57fa\u4e8e\u8868\u9762\u89c2\u6d4b\u6570\u636e\uff08METAR\uff09\u5e76\u901a\u8fc7\u57fa\u4e8e\u70ed\u529b\u5b66\u539f\u7406\u7684\u7269\u7406\u5f15\u5bfc\u7279\u5f81\u5de5\u7a0b\u8fdb\u884c\u589e\u5f3a\u3002\u8be5\u6846\u67b6\u5728\u5168\u7403\u4ee3\u8868\u4e0d\u540c\u6c14\u5019\u533a\u768411\u4e2a\u56fd\u9645\u673a\u573a\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5229\u7528\u4ece2000\u5e74\u81f32024\u5e74\u7684\u5386\u53f2\u6570\u636e\u6765\u8bad\u7ec3\u4e0e\u9a8c\u8bc1\u6a21\u578b\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u81ea\u52a8\u5316\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u9700\u8981\u624b\u52a8\u914d\u7f6e\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u6355\u6349\u5230\u672c\u5730\u7269\u7406\u8fc7\u7a0b\u3002\u76f8\u8f83\u4e8e\u73b0\u6709\u7684TAF\u9884\u62a5\uff0c\u57283\u5c0f\u65f6\u7684\u65f6\u95f4\u8303\u56f4\u5185\uff0c\u65b0\u6a21\u578b\u7684\u53ec\u56de\u7387\u63d0\u9ad8\u4e862.5\u81f34.0\u500d\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9519\u8bef\u8b66\u62a5\u7684\u6570\u91cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u7269\u7406\u5f15\u5bfc\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4f4e\u80fd\u89c1\u5ea6\u53ca\u964d\u6c34\u4e8b\u4ef6\u7684\u77ed\u671f\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u901a\u8fc7\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u7279\u6027\u589e\u5f3a\u4e86\u64cd\u4f5c\u5458\u7684\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u5bf9\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.17506", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17506", "abs": "https://arxiv.org/abs/2512.17506", "authors": ["Brienna M. Larrick", "L. Philip Schumm", "Mingfei Shao", "Craig Barnes", "Anthony Juehne", "Hara Prasad Juvvla", "Michael B. Kranz", "Michael Lukowski", "Clint Malson", "Jessica N. Mazerik", "Christopher G. Meyer", "Jawad Qureshi", "Erin Spaniol", "Andrea Tentner", "Alexander VanTol", "Peter Vassilatos", "Sara Volk de Garcia", "Robert L. Grossman"], "title": "The HEAL Data Platform", "comment": "12 pages, 3 figures", "summary": "Objective: The objective was to develop a cloud-based, federated system to serve as a single point of search, discovery and analysis for data generated under the NIH Helping to End Addiction Long-term (HEAL) Initiative.\n  Materials and methods: The HEAL Data Platform is built on the open source Gen3 platform, utilizing a small set of framework services and exposed APIs to interoperate with both NIH and non-NIH data repositories. Framework services include those for authentication and authorization, creating persistent identifiers for data objects, and adding and updating metadata.\n  Results: The HEAL Data Platform serves as a single point of discovery of over one thousand studies funded under the HEAL Initiative. With hundreds of users per month, the HEAL Data Platform provides rich metadata and interoperates with data repositories and commons to provide access to shared datasets. Secure, cloud-based compute environments that are integrated with STRIDES facilitate secondary analysis of HEAL data. The HEAL Data Platform currently interoperates with nineteen data repositories.\n  Discussion: Studies funded under the HEAL Initiative generate a wide variety of data types, which are deposited across multiple NIH and third-party data repositories. The mesh architecture of the HEAL Data Platform provides a single point of discovery of these data resources, accelerating and facilitating secondary use.\n  Conclusion: The HEAL Data Platform enables search, discovery, and analysis of data that are deposited in connected data repositories and commons. By ensuring that these data are fully Findable, Accessible, Interoperable and Reusable (FAIR), the HEAL Data Platform maximizes the value of data generated under the HEAL Initiative.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e91\u7684\u8054\u5408\u7cfb\u7edf\uff0c\u5373HEAL\u6570\u636e\u5e73\u53f0\uff0c\u4f5c\u4e3aNIH HEAL\u8ba1\u5212\u4e0b\u751f\u6210\u6570\u636e\u7684\u5355\u4e00\u641c\u7d22\u3001\u53d1\u73b0\u548c\u5206\u6790\u70b9\u3002", "motivation": "\u4e3a\u4e86\u6784\u5efa\u4e00\u4e2a\u5355\u4e00\u7684\u641c\u7d22\u3001\u53d1\u73b0\u548c\u5206\u6790\u70b9\uff0c\u4ee5\u670d\u52a1\u4e8eNIH HEAL\u5021\u8bae\u4e0b\u4ea7\u751f\u7684\u6570\u636e\u3002", "method": "HEAL\u6570\u636e\u5e73\u53f0\u5efa\u7acb\u5728\u5f00\u6e90Gen3\u5e73\u53f0\u4e0a\uff0c\u5229\u7528\u5c11\u91cf\u6846\u67b6\u670d\u52a1\u548c\u516c\u5f00API\u4e0eNIH\u5185\u5916\u7684\u6570\u636e\u5b58\u50a8\u5e93\u8fdb\u884c\u4e92\u64cd\u4f5c\u3002\u8fd9\u4e9b\u670d\u52a1\u5305\u62ec\u8eab\u4efd\u9a8c\u8bc1\u548c\u6388\u6743\u3001\u4e3a\u6570\u636e\u5bf9\u8c61\u521b\u5efa\u6301\u4e45\u6807\u8bc6\u7b26\u4ee5\u53ca\u6dfb\u52a0\u548c\u66f4\u65b0\u5143\u6570\u636e\u3002", "result": "HEAL\u6570\u636e\u5e73\u53f0\u5df2\u6210\u4e3a\u8d85\u8fc7\u4e00\u5343\u4e2aHEAL\u5021\u8bae\u8d44\u52a9\u7684\u7814\u7a76\u9879\u76ee\u7684\u5355\u4e00\u53d1\u73b0\u70b9\uff0c\u5e76\u4e14\u6bcf\u4e2a\u6708\u6709\u6570\u767e\u540d\u7528\u6237\u4f7f\u7528\u3002\u5b83\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5143\u6570\u636e\u5e76\u4e0e\u6570\u636e\u5b58\u50a8\u5e93\u548c\u516c\u5171\u5e73\u53f0\u4e92\u64cd\u4f5c\uff0c\u4ee5\u63d0\u4f9b\u5bf9\u5171\u4eab\u6570\u636e\u96c6\u7684\u8bbf\u95ee\u3002\u5b89\u5168\u7684\u57fa\u4e8e\u4e91\u7684\u8ba1\u7b97\u73af\u5883\u901a\u8fc7STRIDES\u96c6\u6210\u4fc3\u8fdb\u4e86HEAL\u6570\u636e\u7684\u4e8c\u6b21\u5206\u6790\u3002\u76ee\u524d\uff0c\u8be5\u5e73\u53f0\u4e0e\u5341\u4e5d\u4e2a\u6570\u636e\u5b58\u50a8\u5e93\u4e92\u64cd\u4f5c\u3002", "conclusion": "HEAL\u6570\u636e\u5e73\u53f0\u5b9e\u73b0\u4e86\u8fde\u63a5\u6570\u636e\u5b58\u50a8\u5e93\u548c\u516c\u5171\u5e73\u53f0\u4e2d\u5b58\u653e\u7684\u6570\u636e\u7684\u641c\u7d22\u3001\u53d1\u73b0\u548c\u5206\u6790\u3002\u901a\u8fc7\u786e\u4fdd\u8fd9\u4e9b\u6570\u636e\u5b8c\u5168\u53ef\u67e5\u627e\u3001\u53ef\u8bbf\u95ee\u3001\u53ef\u4e92\u64cd\u4f5c\u548c\u53ef\u91cd\u7528\uff08FAIR\uff09\uff0cHEAL\u6570\u636e\u5e73\u53f0\u6700\u5927\u5316\u4e86HEAL\u5021\u8bae\u4e0b\u751f\u6210\u7684\u6570\u636e\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.17387", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17387", "abs": "https://arxiv.org/abs/2512.17387", "authors": ["Sravani Gunnu", "Shanmukha Guttula", "Hima Patel"], "title": "CIFE: Code Instruction-Following Evaluation", "comment": "20 pages, 22 figures, 2 tables", "summary": "Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b1000\u4e2aPython\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u6bcf\u4e2a\u4efb\u52a1\u5e73\u5747\u67097\u4e2a\u5f00\u53d1\u8005\u6307\u5b9a\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u8986\u76d6\u4e8613\u4e2a\u7c7b\u522b\u3002\u901a\u8fc7\u65b0\u7684C2A\u8bc4\u5206\u6765\u8861\u91cf\u6a21\u578b\u5728\u6b63\u786e\u6027\u548c\u7ea6\u675f\u9075\u5b88\u65b9\u9762\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u6700\u5f3a\u7684\u6a21\u578b\u5728\u4e25\u683c\u9075\u5b88\u7ea6\u675f\u65b9\u9762\u4e5f\u53ea\u8fbe\u5230\u4e8639-66%\u7684\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u4e3b\u8981\u901a\u8fc7\u6d4b\u8bd5\u7528\u4f8b\u6267\u884c\u6765\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u6027\uff0c\u4f46\u5bf9\u6a21\u578b\u662f\u5426\u9075\u5faa\u5982\u9c81\u68d2\u6027\u3001\u683c\u5f0f\u5316\u548c\u5b89\u5168\u6027\u7b49\u663e\u5f0f\u8981\u6c42\u7684\u5173\u6ce8\u4e0d\u591f\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u80fd\u5168\u9762\u8bc4\u4ef7\u6a21\u578b\u9075\u5b88\u5f00\u53d1\u8005\u6307\u5b9a\u7ea6\u675f\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u75311000\u4e2aPython\u4efb\u52a1\u7ec4\u6210\u7684\u57fa\u51c6\uff0c\u8fd9\u4e9b\u4efb\u52a1\u4e0e\u901a\u8fc7\u56db\u9636\u6bb5\u4eba\u673a\u534f\u4f5c\u6d41\u7a0b\u7b56\u5212\u51fa\u7684\u5f00\u53d1\u8005\u6307\u5b9a\u7ea6\u675f\u76f8\u5339\u914d\u3002\u7136\u540e\u4f7f\u7528\u4e92\u8865\u7684\u9075\u4ece\u5ea6\u6307\u6807\u8bc4\u4f30\u4e8614\u4e2a\u5f00\u6e90\u53ca\u95ed\u6e90\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7efc\u5408\u8bc4\u5206\u6807\u51c6\u2014\u2014C2A\u5206\u6570\uff0c\u7528\u6765\u540c\u65f6\u6355\u6349\u6b63\u786e\u6027\u548c\u7ea6\u675f\u7b26\u5408\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u90e8\u5206\u9075\u5b88\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\uff0c\u5f3a\u6a21\u578b\u53ef\u4ee5\u8fbe\u5230\u8d85\u8fc790%\u7684\u4f9d\u4ece\u7387\uff1b\u7136\u800c\uff0c\u5f53\u8003\u8651\u4e25\u683c\u7684\u7ea6\u675f\u9075\u5b88\u65f6\uff0c\u6240\u6709\u6a21\u578b\u7684\u8868\u73b0\u90fd\u4e0b\u964d\u5230\u4e8639%-66%\u4e4b\u95f4\u3002\u8fd9\u8868\u660e\u5c3d\u7ba1\u6a21\u578b\u80fd\u591f\u8f83\u597d\u5730\u6ee1\u8db3\u57fa\u672c\u7684\u529f\u80fd\u9700\u6c42\uff0c\u4f46\u5728\u5b8c\u5168\u7b26\u5408\u5f00\u53d1\u8005\u610f\u56fe\u65b9\u9762\u4ecd\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\u3002", "conclusion": "\u53ef\u9760\u7684\u4ee3\u7801\u751f\u6210\u4e0d\u4ec5\u9700\u8981\u4fdd\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\uff0c\u8fd8\u9700\u8981\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u4e00\u81f4\u5730\u9075\u5b88\u5f00\u53d1\u8005\u7684\u610f\u56fe\u3002\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u51c6\u548cC2A\u8bc4\u5206\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u8fd9\u4e24\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2512.17442", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17442", "abs": "https://arxiv.org/abs/2512.17442", "authors": ["Jan Hutter", "Hua Chang Bakker", "Stan Fris", "Madelon Bernardy", "Yuanna Liu"], "title": "A Systematic Reproducibility Study of BSARec for Sequential Recommendation", "comment": "Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy contributed equally to this work", "summary": "In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86BSARec\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6dfb\u52a0\u9891\u7387\u5c42\u6765\u589e\u5f3a\u5bf9\u9ad8\u9891\u4fe1\u53f7\u7684\u6355\u6349\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eBSARec\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u7528\u6237\u5386\u53f2\u9891\u7387\u7684\u65b0\u6307\u6807\u4ee5\u8bc4\u4f30\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff0c\u53d1\u73b0\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u76f8\u8f83\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u4ec5\u6709\u8f7b\u5fae\u6539\u8fdb\uff0c\u800c\u7b80\u5355\u7684\u6b8b\u5dee\u8fde\u63a5\u6548\u679c\u4e5f\u4e0d\u900a\u8272\u3002\u6700\u540e\uff0c\u63a2\u8ba8\u4e86\u586b\u5145\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u6307\u51fa\u975e\u5e38\u6570\u586b\u5145\u80fd\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u6027\u80fd\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4f5c\u4e3a\u57fa\u4e8eTransformer\u6a21\u578b\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u8d77\u5230\u4e86\u4f4e\u901a\u6ee4\u6ce2\u5668\u7684\u4f5c\u7528\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u6355\u6349\u53cd\u6620\u77ed\u671f\u7528\u6237\u5174\u8da3\u7684\u9ad8\u9891\u4fe1\u53f7\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0cBSARec\u5f15\u5165\u4e86\u4e00\u4e2a\u9891\u7387\u5c42\u6765\u91cd\u7f29\u653e\u9ad8\u9891\u6210\u5206\u3002\u7136\u800c\uff0cBSARec\u7684\u6574\u4f53\u6709\u6548\u6027\u53ca\u5176\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\u7684\u5177\u4f53\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u9a8c\u8bc1\u3002", "method": "\u672c\u6587\u9996\u5148\u91cd\u73b0\u4e86BSARec\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u3002\u4e3a\u4e86\u5b9e\u8bc1BSARec\u662f\u5426\u63d0\u9ad8\u4e86\u5bf9\u9ad8\u9891\u4fe1\u53f7\u7684\u5904\u7406\u80fd\u529b\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u5ea6\u91cf\u7528\u6237\u5386\u53f2\u9891\u7387\u7684\u65b9\u6cd5\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u8bc4\u4f30\u4e86\u5404\u79cd\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u5bf9\u6bd4\u4e86\u51e0\u79cd\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff08\u5305\u62ec\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u548c\u5085\u91cc\u53f6\u53d8\u6362\uff09\u4ee5\u53ca\u7b80\u5355\u6b8b\u5dee\u8fde\u63a5\u7684\u6548\u679c\u3002\u6700\u540e\uff0c\u63a2\u7d22\u4e86\u4e0d\u540c\u586b\u5145\u7b56\u7565\u5bf9\u4e8e\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cBSARec\u786e\u5b9e\u5728\u4e00\u4e9b\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u3002\u5173\u4e8e\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6280\u672f\u7684\u6bd4\u8f83\u663e\u793a\uff0c\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u4e0e\u5085\u91cc\u53f6\u53d8\u6362\u76f8\u6bd4\u4ec5\u5e26\u6765\u5fae\u5c0f\u6539\u8fdb\uff0c\u540c\u65f6\u8fd9\u4e9bDSP\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u7b80\u5355\u7684\u6b8b\u5dee\u8fde\u63a5\u6ca1\u6709\u660e\u663e\u4f18\u52bf\u3002\u53e6\u5916\uff0c\u7814\u7a76\u53d1\u73b0\u91c7\u7528\u975e\u5e38\u6570\u586b\u5145\u53ef\u4ee5\u5927\u5927\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u800c\u5e38\u6570\u586b\u5145\u5219\u4f1a\u59a8\u788d\u9891\u7387\u8c03\u6574\u5668\u6355\u6349\u9ad8\u9891\u4fe1\u53f7\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u9a8c\u8bc1\u4e86BSARec\u5728\u6539\u5584\u5e8f\u5217\u63a8\u8350\u4efb\u52a1\u4e2d\u6355\u6349\u9ad8\u9891\u4fe1\u53f7\u65b9\u9762\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u4e0d\u540c\u7ec4\u4ef6\u548c\u6280\u672f\u9009\u62e9\u5bf9\u4e8e\u6700\u7ec8\u6027\u80fd\u7684\u5f71\u54cd\u3002\u7279\u522b\u662f\u5f3a\u8c03\u4e86\u5408\u9002\u586b\u5145\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u6307\u51fa\u4e86\u672a\u6765\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u65b9\u5411\u3002"}}
{"id": "2512.17008", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17008", "abs": "https://arxiv.org/abs/2512.17008", "authors": ["Junbo Li", "Peng Zhou", "Rui Meng", "Meet P. Vadera", "Lihong Li", "Yang Li"], "title": "Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs", "comment": null, "summary": "Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments. However, directly applying the widely used Group Relative Policy Optimization (GRPO) algorithm to multi-turn tasks exposes notable limitations, particularly in scenarios requiring long-horizon reasoning. To address these challenges, we investigate more stable and effective advantage estimation strategies, especially for multi-turn settings. We first explore Proximal Policy Optimization (PPO) as an alternative and find it to be more robust than GRPO. To further enhance PPO in multi-turn scenarios, we introduce turn-PPO, a variant that operates on a turn-level MDP formulation, as opposed to the commonly used token-level MDP. Our results on the WebShop and Sokoban datasets demonstrate the effectiveness of turn-PPO, both with and without long reasoning components.", "AI": {"tldr": "\u7814\u7a76\u8005\u4eec\u53d1\u73b0\u76f4\u63a5\u5c06\u5e38\u7528\u7684GRPO\u7b97\u6cd5\u5e94\u7528\u4e8e\u591a\u8f6e\u6b21\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u957f\u671f\u63a8\u7406\u7684\u573a\u666f\u4e0b\u3002\u4e3a\u6b64\uff0c\u4ed6\u4eec\u63a2\u7d22\u4e86\u66f4\u7a33\u5b9a\u6709\u6548\u7684\u4f18\u52bf\u4f30\u8ba1\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u4e86turn-PPO\uff0c\u4e00\u79cd\u57fa\u4e8e\u56de\u5408\u7ea7MDP\u800c\u975e\u901a\u5e38\u7684\u4ee4\u724c\u7ea7MDP\u7684\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65e0\u8bba\u662f\u5426\u52a0\u5165\u957f\u671f\u63a8\u7406\u7ec4\u4ef6\uff0cturn-PPO\u5728WebShop\u548cSokoban\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u7684GRPO\u7b97\u6cd5\u5728\u5904\u7406\u9700\u8981\u957f\u65f6\u95f4\u8de8\u5ea6\u63a8\u7406\u7684\u591a\u8f6e\u6b21\u4efb\u52a1\u65f6\u66b4\u9732\u51fa\u663e\u8457\u7684\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u5bfb\u627e\u66f4\u52a0\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u60c5\u51b5\u3002", "method": "\u9996\u5148\u5c1d\u8bd5\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u89c2\u5bdf\u5230\u5176\u76f8\u6bd4GRPO\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff1b\u63a5\u7740\uff0c\u4e3a\u63d0\u9ad8PPO\u5728\u591a\u8f6e\u6b21\u60c5\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aturn-PPO\u7684\u65b0\u53d8\u4f53\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u56de\u5408\u7ea7\u522b\u800c\u975e\u5355\u4e2a\u6807\u8bb0\u7ea7\u522b\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u3002", "result": "\u901a\u8fc7WebShop\u548cSokoban\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8bc1\u660e\u4e86turn-PPO\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u662f\u5728\u6ca1\u6709\u989d\u5916\u957f\u671f\u63a8\u7406\u673a\u5236\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u9762\u5bf9\u9700\u8981\u8fdb\u884c\u957f\u5468\u671f\u601d\u8003\u7684\u4efb\u52a1\u65f6\uff0c\u91c7\u7528\u5982turn-PPO\u8fd9\u6837\u57fa\u4e8e\u56de\u5408\u7ea7\u522bMDP\u8bbe\u8ba1\u7684\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u4f18\u4e8e\u4f20\u7edfGRPO\u7b97\u6cd5\u7684\u8868\u73b0\u3002"}}
{"id": "2512.17574", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17574", "abs": "https://arxiv.org/abs/2512.17574", "authors": ["Lingxiao Zhao", "Haoran Zhou", "Yuezhi Che", "Dazhao Cheng"], "title": "Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing", "comment": null, "summary": "Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.\n  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\\times$ more requests or enforce 1.5$\\times$ tighter SLOs, while achieving up to 4.4$\\times$ higher throughput compared to state-of-the-art systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFlashCodec\u548cUnifiedServe\u4e24\u79cd\u8bbe\u8ba1\uff0c\u5171\u540c\u4f18\u5316\u7aef\u5230\u7aef\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLMs)\u6d41\u6c34\u7ebf\u3002FlashCodec\u901a\u8fc7\u534f\u4f5c\u5f0f\u591aGPU\u89c6\u9891\u89e3\u7801\u52a0\u901f\u4e86\u591a\u6a21\u6001\u9884\u5904\u7406\u9636\u6bb5\uff0c\u800cUnifiedServe\u5219\u901a\u8fc7\u903b\u8f91\u4e0a\u5206\u79bb\u89c6\u89c9\u5230\u6587\u672c\u53ca\u63a8\u7406\u9636\u6bb5\u7684\u6267\u884c\u4ee5\u6d88\u9664\u9636\u6bb5\u95f4\u963b\u585e\uff0c\u5e76\u7269\u7406\u5171\u4eabGPU\u8d44\u6e90\u6765\u6700\u5927\u5316GPU\u7cfb\u7edf\u5229\u7528\u7387\u3002\u8fd9\u4e9b\u6539\u8fdb\u4f7f\u5f97\u6846\u67b6\u80fd\u591f\u5904\u7406\u591a\u8fbe3.0\u500d\u7684\u8bf7\u6c42\u6216\u5b9e\u73b01.5\u500d\u66f4\u4e25\u683c\u7684SLO\uff0c\u540c\u65f6\u8fbe\u5230\u6700\u9ad84.4\u500d\u4e8e\u73b0\u6709\u7cfb\u7edf\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u589e\u5f3a\u80fd\u529b\u7684\u540c\u65f6\u5f15\u5165\u4e86\u663e\u8457\u7684\u7cfb\u7edf\u74f6\u9888\uff0c\u5305\u62ec\u591a\u6a21\u6001\u9884\u5904\u7406\u5c24\u5176\u662f\u89c6\u9891\u89e3\u7801\u5bfc\u81f4\u7684\u65f6\u95f4\u81f3\u9996\u4e2a\u4ee4\u724c\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u8f83\u957f\u3001\u89c6\u89c9\u7f16\u7801\u5668\u4f5c\u4e3a\u72ec\u7acb\u4e14\u8ba1\u7b97\u5bc6\u96c6\u578b\u9636\u6bb5\u65e0\u6cd5\u4e0eLLM\u9884\u586b\u5145\u6216\u89e3\u7801\u5171\u6279\u5904\u7406\u7b49\u95ee\u9898\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u6574\u4f53\u541e\u5410\u91cf\u5e76\u589e\u52a0\u4e86\u4ee4\u724c\u751f\u6210\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u4e86FlashCodec\u548cUnifiedServe\u4e24\u79cd\u4e92\u8865\u8bbe\u8ba1\u65b9\u6848\uff1aFlashCodec\u5229\u7528\u534f\u4f5c\u5f0f\u7684\u591aGPU\u89c6\u9891\u89e3\u7801\u6280\u672f\u6765\u51cf\u5c11\u89e3\u7801\u5ef6\u8fdf\uff1bUnifiedServe\u5219\u901a\u8fc7\u903b\u8f91\u4e0a\u5206\u79bb\u89c6\u89c9\u5230\u6587\u672c\u8f6c\u6362\u4e0e\u63a8\u7406\u9636\u6bb5\u7684\u6267\u884c\u6d41\u7a0b\u6765\u6d88\u9664\u9636\u6bb5\u95f4\u7684\u963b\u585e\u73b0\u8c61\uff0c\u540c\u65f6\u7269\u7406\u4e0a\u5171\u4eabGPU\u8d44\u6e90\u4ee5\u63d0\u9ad8GPU\u4f7f\u7528\u6548\u7387\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u670d\u52a1\u591a\u8fbe3.0\u500d\u7684\u8bf7\u6c42\u91cf\u6216\u5b9e\u65bd1.5\u500d\u66f4\u52a0\u4e25\u683c\u7684SLOs\uff0c\u5e76\u4e14\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u53ef\u5b9e\u73b0\u9ad8\u8fbe4.4\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7FlashCodec\u548cUnifiedServe\u8054\u5408\u4f18\u5316\u7aef\u5230\u7aefMLLM\u6d41\u6c34\u7ebf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u9884\u5904\u7406\u548c\u89c6\u89c9\u7f16\u7801\u5f15\u5165\u7684\u74f6\u9888\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\u548c\u670d\u52a1\u6c34\u5e73\u76ee\u6807(SLOs)\u3002"}}
{"id": "2512.17419", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17419", "abs": "https://arxiv.org/abs/2512.17419", "authors": ["Lilin Wang", "Lucas Ramalho", "Alan Celestino", "Phuc Anthony Pham", "Yu Liu", "Umang Kumar Sinha", "Andres Portillo", "Onassis Osunwa", "Gabriel Maduekwe"], "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories", "comment": null, "summary": "Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.", "AI": {"tldr": "SWE-Bench++\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5f00\u6e90GitHub\u9879\u76ee\u4e2d\u751f\u6210\u4ee3\u7801\u4efb\u52a1\uff0c\u652f\u630111\u79cd\u8bed\u8a00\u7684bug\u4fee\u590d\u548c\u529f\u80fd\u8bf7\u6c42\u3002\u5b83\u901a\u8fc7\u56db\u4e2a\u9636\u6bb5\u5c06GitHub\u7684pull requests\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u4efb\u52a1\uff0c\u5e76\u4e14\u80fd\u591f\u5c06\u5f3a\u6a21\u578b\u5931\u8d25\u7684\u5b9e\u4f8b\u8f6c\u5316\u4e3a\u8bad\u7ec3\u8f68\u8ff9\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e86\u5f53\u524d\u6700\u5f3a\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u5fae\u8c03SWE-Bench++\u6570\u636e\u96c6\u5bf9\u4e8e\u63d0\u5347SWE-bench\u591a\u8bed\u8a00\u57fa\u51c6\u6027\u80fd\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5982SWE-bench\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5904\u7406\u4ed3\u5e93\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5305\u62ec\u624b\u52a8\u7ba1\u7406\u3001\u9759\u6001\u6570\u636e\u96c6\u4ee5\u53ca\u5bf9Python\u4e3a\u57fa\u7840\u7684bug\u4fee\u590d\u7684\u5173\u6ce8\u3002SWE-Bench++\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u81ea\u52a8\u751f\u6210\u5e76\u4e14\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SWE-Bench++\u91c7\u7528\u81ea\u52a8\u5316\u6d41\u7a0b\u4ece\u6d3b\u8dc3\u7684GitHub pull requests\u4e2d\u6536\u96c6\u5b9e\u9645\u53d1\u751f\u7684bug\u4fee\u590d\u548c\u65b0\u529f\u80fd\u6dfb\u52a0\u6848\u4f8b\uff0c\u8986\u76d611\u79cd\u4e0d\u540c\u7684\u7f16\u7a0b\u8bed\u8a00\u3002\u6574\u4e2a\u8fc7\u7a0b\u5206\u4e3a\u7a0b\u5e8f\u5316\u83b7\u53d6\u3001\u73af\u5883\u5408\u6210\u3001\u6d4b\u8bd5\u9884\u8a00\u63d0\u53d6\u53ca\u8d28\u91cf\u4fdd\u8bc1\u56db\u6b65\uff0c\u53e6\u5916\u8fd8\u5305\u542b\u4e00\u4e2a\u57fa\u4e8e\u63d0\u793a\u7684\u8f68\u8ff9\u5408\u6210\u6b65\u9aa4\u6765\u8f6c\u5316\u96be\u4ee5\u88ab\u73b0\u6709\u6a21\u578b\u89e3\u51b3\u7684\u95ee\u9898\u5b9e\u4f8b\u3002", "result": "SWE-Bench++\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u6765\u81ea3,971\u4e2a\u4ed3\u5e93\u517111,133\u4e2a\u5b9e\u4f8b\u7684\u521d\u59cb\u57fa\u51c6\u3002\u5728\u5176\u4e2d\u9009\u53d6\u76841,782\u4e2a\u5b9e\u4f8b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u663e\u793a\uff0c\u4e0d\u540c\u5148\u8fdb\u6a21\u578b\u7684\u6027\u80fd\u5982\u4e0b\uff1aclaude-sonnet-4.5\u8fbe36.20% pass@10\uff0cgpt-5-2025-08-07 34.57%\uff0cgemini/gemini-2.5-pro 24.92%\uff0cgpt-4o 16.89%\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8868\u660e\u4f7f\u7528SWE-Bench++\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u53ef\u4ee5\u63d0\u9ad8SWE-bench\u591a\u8bed\u8a00\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "SWE-Bench++\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u591a\u8bed\u8a00\u7684\u652f\u6301\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4ef7\u548c\u6539\u8fdb\u9488\u5bf9\u4ed3\u5e93\u7ea7\u522b\u4ee3\u7801\u751f\u6210\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002\u5176\u4e0d\u4ec5\u80fd\u591f\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u7684\u7f16\u7801\u4efb\u52a1\uff0c\u800c\u4e14\u8fd8\u80fd\u5e2e\u52a9\u63d0\u5347\u73b0\u6709\u6a21\u578b\u5904\u7406\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2512.17455", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17455", "abs": "https://arxiv.org/abs/2512.17455", "authors": ["Ronnie de Souza Santos", "Italo Santos", "Maria Teresa Baldassarre", "Cleyton Magalhaes", "Mairieli Wessel"], "title": "An Investigation on How AI-Generated Responses Affect SoftwareEngineering Surveys", "comment": null, "summary": "Survey research is a fundamental empirical method in software engineering, enabling the systematic collection of data on professional practices, perceptions, and experiences. However, recent advances in large language models (LLMs) have introduced new risks to survey integrity, as participants can use generative tools to fabricate or manipulate their responses. This study explores how LLMs are being misused in software engineering surveys and investigates the methodological implications of such behavior for data authenticity, validity, and research integrity. We collected data from two survey deployments conducted in 2025 through the Prolific platform and analyzed the content of participants' answers to identify irregular or falsified responses. A subset of responses suspected of being AI generated was examined through qualitative pattern inspection, narrative characterization, and automated detection using the Scribbr AI Detector. The analysis revealed recurring structural patterns in 49 survey responses indicating synthetic authorship, including repetitive sequencing, uniform phrasing, and superficial personalization. These false narratives mimicked coherent reasoning while concealing fabricated content, undermining construct, internal, and external validity. Our study identifies data authenticity as an emerging dimension of validity in software engineering surveys. We emphasize that reliable evidence now requires combining automated and interpretive verification procedures, transparent reporting, and community standards to detect and prevent AI generated responses, thereby protecting the credibility of surveys in software engineering.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u4e2d\u7684\u6ee5\u7528\u60c5\u51b5\u53ca\u5176\u5bf9\u6570\u636e\u771f\u5b9e\u6027\u3001\u6709\u6548\u6027\u548c\u7814\u7a76\u5b8c\u6574\u6027\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u5206\u67902025\u5e74\u4e24\u6b21\u8c03\u67e5\u6536\u96c6\u7684\u6570\u636e\uff0c\u53d1\u73b049\u4efd\u8c03\u67e5\u56de\u590d\u4e2d\u5b58\u5728\u5408\u6210\u4f5c\u8005\u7684\u8ff9\u8c61\uff0c\u5982\u91cd\u590d\u5e8f\u5217\u3001\u7edf\u4e00\u63aa\u8f9e\u548c\u8868\u9762\u4e2a\u6027\u5316\u7b49\u6a21\u5f0f\u3002\u8fd9\u8868\u660e\u9700\u8981\u7ed3\u5408\u81ea\u52a8\u5316\u4e0e\u89e3\u91ca\u6027\u9a8c\u8bc1\u7a0b\u5e8f\u3001\u900f\u660e\u62a5\u544a\u53ca\u793e\u533a\u6807\u51c6\u6765\u68c0\u6d4b\u5e76\u9632\u6b62AI\u751f\u6210\u7684\u56de\u7b54\uff0c\u4ee5\u7ef4\u62a4\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5185\u8c03\u67e5\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\uff0c\u53c2\u4e0e\u8005\u53ef\u4ee5\u4f7f\u7528\u751f\u6210\u5de5\u5177\u4f2a\u9020\u6216\u64cd\u7eb5\u5176\u56de\u7b54\uff0c\u8fd9\u5bf9\u8c03\u67e5\u7684\u5b8c\u6574\u6027\u6784\u6210\u4e86\u65b0\u7684\u5a01\u80c1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u4e9b\u6a21\u578b\u5982\u4f55\u88ab\u9519\u8bef\u5730\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\uff0c\u5e76\u7814\u7a76\u8fd9\u79cd\u884c\u4e3a\u5bf9\u6570\u636e\u771f\u5b9e\u6027\u3001\u6709\u6548\u6027\u4ee5\u53ca\u7814\u7a76\u8bda\u4fe1\u7684\u65b9\u6cd5\u8bba\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7Prolific\u5e73\u53f0\u57282025\u5e74\u8fdb\u884c\u4e86\u4e24\u6b21\u8c03\u67e5\u90e8\u7f72\uff0c\u5e76\u5206\u6790\u4e86\u53c2\u4e0e\u8005\u7b54\u6848\u7684\u5185\u5bb9\u4ee5\u8bc6\u522b\u5f02\u5e38\u6216\u865a\u5047\u56de\u5e94\u3002\u5bf9\u4e8e\u7591\u4f3c\u7531AI\u751f\u6210\u7684\u4e00\u7ec4\u56de\u5e94\uff0c\u91c7\u7528\u5b9a\u6027\u6a21\u5f0f\u68c0\u67e5\u3001\u53d9\u8ff0\u7279\u5f81\u5316\u4ee5\u53caScribbr AI\u68c0\u6d4b\u5668\u8fdb\u884c\u81ea\u52a8\u68c0\u6d4b\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u572849\u4e2a\u8c03\u67e5\u56de\u5e94\u4e2d\u53d1\u73b0\u4e86\u6307\u793a\u5408\u6210\u4f5c\u8005\u8eab\u4efd\u7684\u91cd\u590d\u51fa\u73b0\u7ed3\u6784\u6a21\u5f0f\uff0c\u5305\u62ec\u91cd\u590d\u5e8f\u5217\u3001\u7edf\u4e00\u63aa\u8f9e\u548c\u8868\u9762\u4e2a\u6027\u5316\u3002\u8fd9\u4e9b\u865a\u5047\u53d9\u8ff0\u6a21\u4eff\u8fde\u8d2f\u63a8\u7406\u7684\u540c\u65f6\u9690\u85cf\u4e86\u4f2a\u9020\u5185\u5bb9\uff0c\u635f\u5bb3\u4e86\u5efa\u6784\u6548\u5ea6\u3001\u5185\u90e8\u6548\u5ea6\u548c\u5916\u90e8\u6548\u5ea6\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\uff0c\u6570\u636e\u771f\u5b9e\u6027\u662f\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u4e2d\u65b0\u51fa\u73b0\u7684\u6709\u6548\u6027\u7ef4\u5ea6\u3002\u4e3a\u786e\u4fdd\u53ef\u9760\u8bc1\u636e\uff0c\u73b0\u5728\u9700\u8981\u7ed3\u5408\u81ea\u52a8\u5316\u4e0e\u89e3\u91ca\u6027\u9a8c\u8bc1\u7a0b\u5e8f\u3001\u900f\u660e\u62a5\u544a\u4ee5\u53ca\u793e\u533a\u6807\u51c6\u6765\u68c0\u6d4b\u5e76\u9884\u9632AI\u751f\u6210\u7684\u54cd\u5e94\uff0c\u4ece\u800c\u4fdd\u62a4\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.17733", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17733", "abs": "https://arxiv.org/abs/2512.17733", "authors": ["Jingmao Zhang", "Zhiting Zhao", "Yunqi Lin", "Jianghong Ma", "Tianjun Wei", "Haijun Zhang", "Xiaofeng Zhang"], "title": "Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure", "comment": null, "summary": "Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.", "AI": {"tldr": "\u63d0\u51faCadence\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u53bb\u6df7\u6dc6\u5171\u8d2d\u5173\u7cfb\u548c\u53cd\u4e8b\u5b9e\u66dd\u5149\u6765\u589e\u5f3a\u63a8\u8350\u7cfb\u7edf\u7684\u591a\u6837\u6027\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7269\u54c1\u95f4\u5173\u7cfb\u7684\u63a8\u8350\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u7269\u54c1\u6d41\u884c\u5ea6\u504f\u5dee\u548c\u7528\u6237\u5c5e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u7f3a\u4e4f\u5bf9\u63a8\u8350\u591a\u6837\u6027\u7684\u5173\u6ce8\u4ee5\u53ca\u56e0\u679c\u89c6\u89d2\u548c\u7406\u8bba\u57fa\u7840\u7684\u7814\u7a76\u3002", "method": "1. \u8ba1\u7b97\u6392\u9664\u4e86\u7269\u54c1\u6d41\u884c\u5ea6\u548c\u7528\u6237\u5c5e\u6027\u5f71\u54cd\u540e\u7684\u65e0\u504f\u4e0d\u5bf9\u79f0\u5171\u8d2d\u5173\u7cfb\uff08UACR\uff09\uff0c\u6784\u5efa\u53bb\u6df7\u6dc6\u7684\u6709\u5411\u7269\u54c1\u56fe\uff0c\u5e76\u4f7f\u7528\u805a\u5408\u673a\u5236\u4f18\u5316\u5d4c\u5165\u3002\n2. \u5229\u7528UACR\u8bc6\u522b\u51fa\u4e0e\u7528\u6237\u5df2\u4ea4\u4e92\u8fc7\u7684\u7269\u54c1\u5177\u6709\u5f3a\u70c8\u56e0\u679c\u76f8\u5173\u6027\u4f46\u5c1a\u672a\u88ab\u63a5\u89e6\u8fc7\u7684\u591a\u6837\u5316\u7c7b\u522b\u7269\u54c1\u3002\n3. \u6a21\u62df\u8fd9\u4e9b\u7269\u54c1\u5728\u9ad8\u66dd\u5149\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u4ece\u800c\u5927\u5e45\u63d0\u9ad8\u63a8\u8350\u591a\u6837\u6027\u7684\u540c\u65f6\u4fdd\u6301\u76f8\u5173\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u591a\u6837\u6027\u6a21\u578b\uff0c\u5e76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3001\u53ef\u8fc1\u79fb\u6027\u548c\u6548\u7387\u3002", "conclusion": "Cadence\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u591a\u6837\u6027\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u53bb\u9664\u5171\u8d2d\u5173\u7cfb\u4e2d\u7684\u504f\u5dee\u56e0\u7d20\uff0c\u5e76\u91c7\u7528\u56e0\u679c\u63a8\u65ad\u6765\u53d1\u73b0\u66f4\u591a\u6837\u5316\u7684\u63a8\u8350\u9009\u9879\u3002"}}
{"id": "2512.17051", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17051", "abs": "https://arxiv.org/abs/2512.17051", "authors": ["Haoye Lu", "Yaoliang Yu", "Darren Ho"], "title": "SFBD-OMNI: Bridge models for lossy measurement restoration with limited clean samples", "comment": null, "summary": "In many real-world scenarios, obtaining fully observed samples is prohibitively expensive or even infeasible, while partial and noisy observations are comparatively easy to collect. In this work, we study distribution restoration with abundant noisy samples, assuming the corruption process is available as a black-box generator. We show that this task can be framed as a one-sided entropic optimal transport problem and solved via an EM-like algorithm. We further provide a test criterion to determine whether the true underlying distribution is recoverable under per-sample information loss, and show that in otherwise unrecoverable cases, a small number of clean samples can render the distribution largely recoverable. Building on these insights, we introduce SFBD-OMNI, a bridge model-based framework that maps corrupted sample distributions to the ground-truth distribution. Our method generalizes Stochastic Forward-Backward Deconvolution (SFBD; Lu et al., 2025) to handle arbitrary measurement models beyond Gaussian corruption. Experiments across benchmark datasets and diverse measurement settings demonstrate significant improvements in both qualitative and quantitative performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5927\u91cf\u566a\u58f0\u6837\u672c\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u6062\u590d\u539f\u59cb\u5206\u5e03\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u8fb9\u71b5\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u7684\u89e3\u51b3\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86SFBD-OMNI\u6a21\u578b\u6765\u5b9e\u73b0\u4ece\u88ab\u6c61\u67d3\u6837\u672c\u5230\u771f\u5b9e\u5206\u5e03\u7684\u6620\u5c04\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6761\u4ef6\u4e0b\u5747\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u83b7\u53d6\u5b8c\u5168\u89c2\u6d4b\u6837\u672c\u6210\u672c\u9ad8\u6602\u751a\u81f3\u4e0d\u53ef\u884c\uff0c\u800c\u90e8\u5206\u548c\u5e26\u6709\u566a\u97f3\u7684\u89c2\u5bdf\u76f8\u5bf9\u5bb9\u6613\u6536\u96c6\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5229\u7528\u4e30\u5bcc\u7684\u566a\u58f0\u6837\u672c\u6765\u6062\u590d\u771f\u5b9e\u7684\u5e95\u5c42\u6570\u636e\u5206\u5e03\u3002", "method": "\u4f5c\u8005\u5c06\u8fd9\u4e2a\u95ee\u9898\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5355\u8fb9\u71b5\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u7c7b\u4f3c\u4e8eEM\u7b97\u6cd5\u7684\u65b9\u6cd5\u6c42\u89e3\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d4b\u8bd5\u6807\u51c6\u6765\u5224\u65ad\u7ed9\u5b9a\u6bcf\u6837\u672c\u4fe1\u606f\u635f\u5931\u60c5\u51b5\u4e0b\u662f\u5426\u80fd\u591f\u6062\u590d\u771f\u5b9e\u7684\u5206\u5e03\uff0c\u5e76\u4e14\u6307\u51fa\u5c11\u91cf\u5e72\u51c0\u6837\u672c\u53ef\u4ee5\u5927\u5927\u63d0\u9ad8\u6062\u590d\u7684\u53ef\u80fd\u6027\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86SFBD-OMNI\u6846\u67b6\uff0c\u5b83\u6269\u5c55\u4e86Stochastic Forward-Backward Deconvolution\u6280\u672f\u4ee5\u9002\u5e94\u66f4\u5e7f\u6cdb\u7684\u6d4b\u91cf\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4ee5\u53ca\u4e0d\u540c\u7c7b\u578b\u7684\u6d4b\u91cf\u8bbe\u7f6e\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u6280\u672f\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u8868\u73b0\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u4ece\u5927\u91cf\u7684\u566a\u58f0\u6837\u672c\u4e2d\u6062\u590d\u539f\u59cb\u7684\u6570\u636e\u5206\u5e03\uff0c\u5373\u4f7f\u662f\u5728\u4f20\u7edf\u610f\u4e49\u4e0a\u88ab\u8ba4\u4e3a\u65e0\u6cd5\u6062\u590d\u7684\u60c5\u5f62\u4e0b\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u6709\u5c11\u91cf\u65e0\u566a\u58f0\u6837\u672c\u8f85\u52a9\u65f6\u3002"}}
{"id": "2512.17460", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17460", "abs": "https://arxiv.org/abs/2512.17460", "authors": ["Emmanuel Charleson Dapaah", "Jens Grabowski"], "title": "When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction", "comment": null, "summary": "Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.\n  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.\n  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u4e86\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b(SDP)\u4e2d\u540c\u65f6\u51fa\u73b0\u7684\u4e94\u4e2a\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff08\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u7c7b\u522b\u91cd\u53e0\u3001\u65e0\u5173\u7279\u5f81\u3001\u5c5e\u6027\u566a\u58f0\u548c\u5f02\u5e38\u503c\uff09\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u95ee\u9898\u666e\u904d\u5171\u5b58\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u4e00\u4e2a\u6027\u80fd-\u7a33\u5065\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5355\u72ec\u8003\u8651\u5982\u7c7b\u522b\u4e0d\u5e73\u8861\u6216\u7279\u5f81\u4e0d\u76f8\u5173\u7b49\u5355\u4e00\u95ee\u9898\uff0c\u800c\u5ffd\u89c6\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6570\u636e\u95ee\u9898\u901a\u5e38\u662f\u5171\u5b58\u5e76\u76f8\u4e92\u5f71\u54cd\u7684\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8054\u5408\u5206\u6790\u6765\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u610f\u8bc6\u7406\u89e3\uff0c\u4e86\u89e3\u8d28\u91cf\u95ee\u9898\u662f\u5982\u4f55\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u7684\u3002", "method": "\u4f7f\u7528\u89e3\u91ca\u589e\u5f3a\u673a\u5668\u4e0e\u5206\u5c42\u4ea4\u4e92\u5206\u6790\u65b9\u6cd5\uff0c\u5728374\u4e2a\u6570\u636e\u96c6\u4e0a\u9488\u5bf9\u4e94\u79cd\u4e0d\u540c\u7684\u5206\u7c7b\u5668\uff0c\u540c\u65f6\u8003\u5bdf\u4e94\u4e2a\u5171\u5b58\u7684\u6570\u636e\u8d28\u91cf\u95ee\u9898\u3002\u91c7\u7528\u9ed8\u8ba4\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7684\u76f4\u63a5\u53ca\u6761\u4ef6\u6548\u5e94\u91cf\u5316\u6280\u672f\u6765\u8fdb\u884c\u5206\u6790\u3002", "result": "\u51e0\u4e4e\u6240\u6709\u6570\u636e\u96c6\u4e2d\u90fd\u5b58\u5728\u81f3\u5c11\u4e00\u79cd\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff1b\u7c7b\u522b\u91cd\u53e0\u662f\u6700\u5177\u7834\u574f\u6027\u7684\u95ee\u9898\u4e4b\u4e00\uff1b\u53d1\u73b0\u4e86\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5f02\u5e38\u503c\u53cd\u800c\u80fd\u63d0\u9ad8\u6027\u80fd\u7684\u73b0\u8c61\uff1b\u6307\u51fa\u4e86\u6027\u80fd\u4e0e\u7a33\u5065\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0cSDP\u9886\u57df\u9700\u8981\u4ece\u5b64\u7acb\u5730\u770b\u5f85\u5355\u4e2a\u95ee\u9898\u8f6c\u5411\u7efc\u5408\u8003\u8651\u591a\u4e2a\u56e0\u7d20\u5171\u540c\u4f5c\u7528\u4e8e\u6a21\u578b\u6548\u679c\u7684\u65b9\u5f0f\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u6839\u636e\u5177\u4f53\u60c5\u5883\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.17352", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17352", "abs": "https://arxiv.org/abs/2512.17352", "authors": ["Ivan Kralj", "Lodovico Giaretta", "Gordan Je\u017ei\u0107", "Ivana Podnar \u017darko", "\u0160ar\u016bnas Girdzijauskas"], "title": "Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs", "comment": "19 pages, 6 figures, 5 tables, journal", "summary": "Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u526a\u679d\u7b97\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11ST-GNNs\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u8282\u70b9\uff08\u4e91\u7c92\uff09\u90e8\u7f72\u65f6\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u65b0\u7684\u5ea6\u91cf\u6807\u51c6SEPA\u6765\u8861\u91cf\u5bf9\u4ea4\u901a\u7a81\u53d1\u60c5\u51b5\u7684\u54cd\u5e94\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u4e0d\u727a\u7272\u5173\u952e\u4ea4\u901a\u4e8b\u4ef6\u54cd\u5e94\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3Spatio-Temporal Graph Neural Networks (ST-GNNs) \u5728\u5904\u7406\u6765\u81ea\u5730\u7406\u5206\u5e03\u4f20\u611f\u5668\u7684\u9ad8\u9891\u7387\u6570\u636e\u6d41\u65f6\u9047\u5230\u7684\u95ee\u9898\uff0c\u5373\u5f53\u5b83\u4eec\u88ab\u90e8\u7f72\u4e8e\u8fb9\u7f18\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u8282\u70b9\u4e0a\u65f6\u4ea7\u751f\u7684\u5927\u91cf\u901a\u4fe1\u5f00\u9500\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u8fc7\u6ee4\u5197\u4f59\u90bb\u5c45\u7279\u5f81\u7684\u81ea\u9002\u5e94\u526a\u679d\u7b97\u6cd5\uff0c\u540c\u65f6\u4fdd\u7559\u7528\u4e8e\u9884\u6d4b\u7684\u6700\u6709\u4fe1\u606f\u91cf\u7684\u7a7a\u95f4\u4e0a\u4e0b\u6587\u3002\u6b64\u7b97\u6cd5\u6839\u636e\u6700\u8fd1\u7684\u6a21\u578b\u6027\u80fd\u8c03\u6574\u526a\u679d\u7387\uff0c\u4f7f\u6bcf\u4e2a\u4e91\u7c92\u80fd\u591f\u4e13\u6ce8\u4e8e\u7ecf\u5386\u6d41\u91cf\u53d8\u5316\u7684\u533a\u57df\u800c\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u5728\u6240\u6709\u5728\u7ebf\u534a\u5206\u6563\u8bbe\u7f6e\u4e2d\uff0c\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u526a\u679d\u7b97\u6cd5\u80fd\u591f\u5728\u7ef4\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u57fa\u7840\u4e0a\u5927\u5e45\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u5e76\u4e14\u65b0\u63d0\u51fa\u7684SEPA\u6307\u6807\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u7cfb\u7edf\u5bf9\u4e8e\u52a8\u6001\u548c\u4e0d\u89c4\u5219\u4ea4\u901a\u72b6\u51b5\u7684\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u81ea\u9002\u5e94\u526a\u679d\u7b97\u6cd5\u4e0eSEPA\u8bc4\u4ef7\u6307\u6807\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u5bf9\u5173\u952e\u4ea4\u901a\u4e8b\u4ef6\u54cd\u5e94\u6027\u7684\u6761\u4ef6\u4e0b\u6709\u6548\u51cf\u5c11\u901a\u4fe1\u6d88\u8017\u3002"}}
{"id": "2512.17058", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17058", "abs": "https://arxiv.org/abs/2512.17058", "authors": ["Vladimir G. Pestov"], "title": "Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. III", "comment": "12 pages, latex with ESAIM P&S macros", "summary": "We prove the last remaining implication allowing to claim the equivalence of the following conditions for a complete separable metric space $X$:\n  (1) The $k$-nearest neighbour classifier is (weakly) universally consistent in $X$, (2) The strong Lebesgue--Besicovitch differentiation property holds in $X$ for every locally finite Borel measure, (3) $X$ is sigma-finite dimensional in the sense of Nagata.\n  The equivalence (2)$\\iff$(3) was announced by Preiss (1983), while a detailed proof of the implication (3)$\\Rightarrow$(2) has appeared in Assouad and Quentin de Gromard (2006). The implication (2)$\\Rightarrow$(1) was established by C\u00e9rou and Guyader (2006). We prove the implication (1)$\\Rightarrow$(3). The result was conjectured in the first article in the series (Collins, Kumari, Pestov 2020), and here we also correct a wrong claim made in the second article (Kumari and Pestov 2024).", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u5b8c\u5907\u53ef\u5206\u5ea6\u91cf\u7a7a\u95f4X\u4e2d\uff0ck-\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u4e00\u81f4\u6027\u4e0e\u5f3a\u52d2\u8d1d\u683c-\u8d1d\u897f\u79d1\u7ef4\u5947\u5fae\u5206\u6027\u8d28\u53caNagata\u610f\u4e49\u4e0b\u7684sigma-\u6709\u9650\u7ef4\u6027\u8d28\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u4e3a\u4e86\u8bc1\u660e\u5728\u5b8c\u5907\u53ef\u5206\u79bb\u5ea6\u91cf\u7a7a\u95f4X\u4e2d\uff0ck-\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\uff08\u5f31\uff09\u666e\u904d\u4e00\u81f4\u6027\u3001\u5f3a\u52d2\u8d1d\u683c-\u8d1d\u897f\u79d1\u7ef4\u5947\u5fae\u5206\u6027\u8d28\u5bf9\u6bcf\u4e2a\u5c40\u90e8\u6709\u9650Borel\u6d4b\u5ea6\u6210\u7acb\u4ee5\u53caX\u662fNagata\u610f\u4e49\u4e0a\u7684sigma-\u6709\u9650\u7ef4\u8fd9\u4e09\u8005\u95f4\u7684\u7b49\u4ef7\u6027\uff0c\u586b\u8865\u4e86\u6700\u540e\u4e00\u4e2a\u672a\u88ab\u8bc1\u5b9e\u7684\u63a8\u8bba\uff08\u5373\u4ece\u6761\u4ef6(1)\u5230\u6761\u4ef6(3)\u7684\u63a8\u5bfc\uff09\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5206\u6790\u548c\u62d3\u6251\u5b66\u7684\u65b9\u6cd5\uff0c\u4f5c\u8005\u4eec\u9a8c\u8bc1\u4e86k-\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u7684\u4e00\u81f4\u6027\u53ef\u4ee5\u63a8\u51faNagata\u610f\u4e49\u4e0a\u7a7a\u95f4\u7684sigma-\u6709\u9650\u7ef4\u6027\u8d28\u3002", "result": "\u6210\u529f\u5730\u8bc1\u660e\u4e86\u5f53k-\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u5728\u7a7a\u95f4X\u4e2d\u662f\uff08\u5f31\uff09\u666e\u904d\u4e00\u81f4\u65f6\uff0c\u8be5\u7a7a\u95f4X\u5fc5\u7136\u662fNagota\u610f\u4e49\u4e0a\u7684sigma-\u6709\u9650\u7ef4\u3002\u6b64\u5916\uff0c\u7ea0\u6b63\u4e86\u4e4b\u524d\u6587\u7ae0\u4e2d\u7684\u9519\u8bef\u4e3b\u5f20\u3002", "conclusion": "\u5b8c\u6210\u4e86\u5bf9\u4e8ek-\u6700\u8fd1\u90bb\u5206\u7c7b\u5668\u4e00\u81f4\u6027\u4e0e\u5176\u5b83\u4e24\u4e2a\u5c5e\u6027\u95f4\u7b49\u4ef7\u6027\u7684\u6700\u540e\u4e00\u6b65\u8bc1\u660e\uff0c\u4ece\u800c\u5efa\u7acb\u4e86\u8fd9\u4e09\u4e2a\u5c5e\u6027\u4e4b\u95f4\u7684\u5b8c\u6574\u7b49\u4ef7\u94fe\u3002"}}
{"id": "2512.17540", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17540", "abs": "https://arxiv.org/abs/2512.17540", "authors": ["Kai Wang", "Bingcheng Mao", "Shuai Jia", "Yujie Ding", "Dongming Han", "Tianyi Ma", "Bin Cao"], "title": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review", "comment": null, "summary": "Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate-a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u8303\u7684\u4ee3\u7801\u5ba1\u67e5\u6846\u67b6SGCR\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u663e\u5f0f\u8def\u5f84\u548c\u9690\u5f0f\u8def\u5f84\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u53ef\u9760\u6027\u3001\u76f8\u5173\u6027\u548c\u53ef\u63a7\u6027\u3002\u5728\u5b9e\u9645\u5de5\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u540e\uff0c\u5f00\u53d1\u4eba\u5458\u91c7\u7eb3\u5efa\u8bae\u7684\u6bd4\u4f8b\u8fbe\u5230\u4e8642%\uff0c\u76f8\u6bd4\u57fa\u7ebfLLM\u63d0\u9ad8\u4e8690.9%\u3002", "motivation": "\u5c3d\u7ba1\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u5ba1\u67e5\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u53ef\u9760\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u548c\u63a7\u5236\u6027\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u89c4\u8303\u7684\u4ee3\u7801\u5ba1\u67e5\u65b9\u6cd5\uff08SGCR\uff09\u3002", "method": "SGCR\u6846\u67b6\u91c7\u7528\u4e86\u53cc\u8def\u5f84\u67b6\u6784\uff1a\u663e\u5f0f\u8def\u5f84\u786e\u4fdd\u9075\u5faa\u4ece\u4eba\u7c7b\u7f16\u5199\u7684\u89c4\u8303\u4e2d\u63d0\u53d6\u7684\u9884\u5b9a\u4e49\u89c4\u5219\uff1b\u800c\u9690\u5f0f\u8def\u5f84\u5219\u63a2\u7d22\u5e76\u9a8c\u8bc1\u8d85\u51fa\u8fd9\u4e9b\u89c4\u5219\u7684\u95ee\u9898\u3002", "result": "\u5f53SGCR\u88ab\u5e94\u7528\u4e8eHiThink Research\u7684\u5b9e\u9645\u5de5\u4e1a\u73af\u5883\u4e2d\u65f6\uff0c\u5176\u5efa\u8bae\u7684\u91c7\u7eb3\u7387\u8fbe\u5230\u4e8642%\uff0c\u76f8\u8f83\u4e8e\u57fa\u7840\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0822%\uff09\u63d0\u9ad8\u4e8690.9%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u89c4\u8303\u7684\u65b9\u6cd5\u662f\u8fde\u63a5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u80fd\u529b\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u4e25\u683c\u53ef\u9760\u6027\u8981\u6c42\u4e4b\u95f4\u5dee\u8ddd\u7684\u6709\u6548\u8303\u4f8b\u3002"}}
{"id": "2512.17073", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17073", "abs": "https://arxiv.org/abs/2512.17073", "authors": ["Zhenyu Liu", "Yunzhen Liu", "Zehao Fan", "Garrett Gagnon", "Yayue Hou", "Nan Wu", "Yangwook Kang", "Liu Liu"], "title": "Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation", "comment": null, "summary": "Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degrades accuracy under aggressive compression by ignoring expert heterogeneity. We present Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation, which performs router-guided precision restoration using precomputed low-rank compensators. At inference time, our method transfers compact low-rank factors with Top-n (n<k) experts per token and applies compensation to them, keeping others low-bit. Integrated with offloading on GPU and GPU-NDP systems, our method delivers a superior bandwidth-accuracy trade-off and improved throughput.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u5bbd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u4f4e\u79e9\u8865\u507f\u5b9e\u73b0\u4e86\u8def\u7531\u5f15\u5bfc\u7684\u7cbe\u5ea6\u6062\u590d\uff0c\u5728\u4fdd\u6301\u5176\u4ed6\u90e8\u5206\u4f4e\u4f4d\u7684\u540c\u65f6\uff0c\u4ec5\u5bf9Top-n\u4e13\u5bb6\u8fdb\u884c\u8865\u507f\u3002\u8be5\u65b9\u6cd5\u5728GPU\u548cGPU-NDP\u7cfb\u7edf\u4e0a\u4e0e\u5378\u8f7d\u96c6\u6210\u65f6\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5e26\u5bbd-\u51c6\u786e\u6027\u6743\u8861\u53ca\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "Mixture-of-Experts (MoE) \u6a21\u578b\u867d\u7136\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u6765\u589e\u52a0\u5bb9\u91cf\uff0c\u4f46\u7ed9\u5185\u5b58\u548c\u5e26\u5bbd\u5e26\u6765\u4e86\u538b\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u79bb\u7ebf\u52a0\u8f7d\u7684\u65b9\u6cd5\u4ee5\u51cf\u8f7bGPU\u5185\u5b58\u8d1f\u62c5\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u4e0d\u89c4\u5219\u7684\u6570\u636e\u4f20\u8f93\u4ece\u800c\u4f7f\u63a8\u7406\u8fc7\u7a0b\u53d7\u5230I/O\u9650\u5236\u3002\u9759\u6001\u5747\u5300\u91cf\u5316\u867d\u80fd\u51cf\u5c11\u6d41\u91cf\uff0c\u4f46\u5728\u6fc0\u8fdb\u538b\u7f29\u4e0b\u4f1a\u5ffd\u7565\u4e13\u5bb6\u95f4\u7684\u5f02\u8d28\u6027\u4ece\u800c\u964d\u4f4e\u7cbe\u5ea6\u3002\u57fa\u4e8e\u4ee5\u4e0a\u80cc\u666f\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u5229\u7528\u5e26\u5bbd\u53c8\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aBandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u9884\u8ba1\u7b97\u7684\u4f4e\u79e9\u8865\u507f\u5668\u6765\u8fdb\u884c\u8def\u7531\u5668\u5f15\u5bfc\u4e0b\u7684\u7cbe\u5ea6\u6062\u590d\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u672c\u65b9\u6cd5\u53ea\u4f20\u8f93\u7d27\u51d1\u7684\u4f4e\u79e9\u56e0\u5b50\uff0c\u5e76\u9488\u5bf9\u6bcf\u4e2atoken\u9009\u62e9\u51faTop-n\uff08n<k\uff09\u4e2a\u4e13\u5bb6\u5e94\u7528\u8865\u507f\uff0c\u800c\u5176\u4ed6\u90e8\u5206\u5219\u4fdd\u6301\u4f4e\u4f4d\u5b58\u50a8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u4e0eGPU\u4ee5\u53caGPU-NDP\u7cfb\u7edf\u7684\u5378\u8f7d\u6280\u672f\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u4f18\u7684\u5e26\u5bbd-\u51c6\u786e\u6027\u5e73\u8861\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u5904\u7406\u901f\u5ea6\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0c\u672c\u6587\u63d0\u51fa\u7684\u5e26\u5bbd\u9ad8\u6548\u81ea\u9002\u5e94\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u4f4e\u79e9\u8865\u507f\u673a\u5236\u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e0d\u4ec5\u51cf\u5c11\u4e86\u6570\u636e\u4f20\u8f93\u9700\u6c42\u8fd8\u7ef4\u6301\u4e86\u8f83\u9ad8\u7684\u6a21\u578b\u6027\u80fd\uff0c\u5bf9\u4e8e\u9700\u8981\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\u7684\u5e94\u7528\u573a\u666f\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.17710", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17710", "abs": "https://arxiv.org/abs/2512.17710", "authors": ["Martin Rosso", "Muhammad Asad Jahangir Jaffar", "Alessandro Brighente", "Mauro Conti"], "title": "A Practical Solution to Systematically Monitor Inconsistencies in SBOM-based Vulnerability Scanners", "comment": "to be published in the proceedings of The 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)", "summary": "Software Bill of Materials (SBOM) provides new opportunities for automated vulnerability identification in software products. While the industry is adopting SBOM-based Vulnerability Scanning (SVS) to identify vulnerabilities, we increasingly observe inconsistencies and unexpected behavior, that result in false negatives and silent failures. In this work, we present the background necessary to understand the underlying complexity of SVS and introduce SVS-TEST, a method and tool to analyze the capability, maturity, and failure conditions of SVS-tools in real-world scenarios. We showcase the utility of SVS-TEST in a case study evaluating seven real-world SVS-tools using 16 precisely crafted SBOMs and their respective ground truth. Our results unveil significant differences in the reliability and error handling of SVS-tools; multiple SVS-tools silently fail on valid input SBOMs, creating a false sense of security. We conclude our work by highlighting implications for researchers and practitioners, including how organizations and developers of SVS-tools can utilize SVS-TEST to monitor SVS capability and maturity. All results and research artifacts are made publicly available and all findings were disclosed to the SVS-tool developers ahead of time.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSVS-TEST\u7684\u65b9\u6cd5\u548c\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u57fa\u4e8e\u8f6f\u4ef6\u7269\u6599\u6e05\u5355\uff08SBOM\uff09\u7684\u6f0f\u6d1e\u626b\u63cf\u5de5\u5177\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3001\u6210\u719f\u5ea6\u4ee5\u53ca\u5931\u8d25\u60c5\u51b5\u3002\u901a\u8fc7\u4f7f\u7528\u7cbe\u5fc3\u5236\u4f5c\u7684SBOM\u6587\u4ef6\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0\u4e0d\u540c\u6f0f\u6d1e\u626b\u63cf\u5de5\u5177\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u4e14\u67d0\u4e9b\u5de5\u5177\u5728\u6709\u6548\u8f93\u5165\u4e0b\u4f1a\u65e0\u58f0\u5931\u8d25\uff0c\u7ed9\u7528\u6237\u5e26\u6765\u865a\u5047\u7684\u5b89\u5168\u611f\u3002", "motivation": "\u968f\u7740\u884c\u4e1a\u91c7\u7528\u57fa\u4e8eSBOM\u7684\u6f0f\u6d1e\u626b\u63cf(SVS)\u6765\u8bc6\u522b\u8f6f\u4ef6\u4ea7\u54c1\u4e2d\u7684\u6f0f\u6d1e\uff0c\u89c2\u5bdf\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u4e00\u81f4\u6027\u95ee\u9898\u548c\u610f\u5916\u884c\u4e3a\u5bfc\u81f4\u4e86\u6f0f\u62a5\u548c\u9759\u9ed8\u6545\u969c\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3SVS\u7684\u590d\u6742\u6027\u5e76\u8bc4\u4f30SVS\u5de5\u5177\u7684\u80fd\u529b\u4e0e\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u548c\u5de5\u5177SVS-TEST\uff0c\u7528\u6765\u5206\u6790SVS\u5de5\u5177\u5728\u771f\u5b9e\u4e16\u754c\u60c5\u5883\u4e0b\u7684\u80fd\u529b\u3001\u6210\u719f\u5ea6\u53ca\u53ef\u80fd\u9047\u5230\u7684\u95ee\u9898\u3002\u901a\u8fc7\u4e00\u4e2a\u5305\u542b16\u4e2a\u7cbe\u786e\u6784\u5efa\u7684SBOM\u53ca\u5176\u5bf9\u5e94\u57fa\u51c6\u7684\u771f\u5b9e\u60c5\u51b5\u6848\u4f8b\u7814\u7a76\uff0c\u5bf97\u79cd\u4e0d\u540c\u7684SVS\u5de5\u5177\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86SVS\u5de5\u5177\u4e4b\u95f4\u5728\u53ef\u9760\u6027\u548c\u9519\u8bef\u5904\u7406\u65b9\u9762\u7684\u91cd\u5927\u5dee\u5f02\uff1b\u591a\u4e2aSVS\u5de5\u5177\u5bf9\u4e8e\u6709\u6548\u7684\u8f93\u5165SBOM\u6587\u4ef6\u4f1a\u51fa\u73b0\u65e0\u58f0\u5931\u8d25\u7684\u60c5\u51b5\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4e00\u79cd\u865a\u5047\u7684\u5b89\u5168\u611f\u3002", "conclusion": "\u5f3a\u8c03\u4e86SVS-TEST\u5bf9\u4e8e\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u7684\u91cd\u8981\u6027\uff0c\u5305\u62ec\u7ec4\u7ec7\u548cSVS\u5de5\u5177\u5f00\u53d1\u8005\u5982\u4f55\u5229\u7528\u8be5\u5de5\u5177\u76d1\u63a7SVS\u7684\u529f\u80fd\u4e0e\u6210\u719f\u5ea6\u3002\u6240\u6709\u7814\u7a76\u6210\u679c\u548c\u76f8\u5173\u8d44\u6599\u5747\u516c\u5f00\u63d0\u4f9b\uff0c\u5e76\u5df2\u63d0\u524d\u5411SVS\u5de5\u5177\u5f00\u53d1\u8005\u62ab\u9732\u4e86\u6240\u6709\u53d1\u73b0\u3002"}}
{"id": "2512.17079", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17079", "abs": "https://arxiv.org/abs/2512.17079", "authors": ["Saraswathy Amjith", "Mihika Dusad", "Neha Muramalla", "Shweta Shah"], "title": "Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?", "comment": null, "summary": "Chain-of-thought (CoT) prompting has become central to mathematical reasoning in large language models, yet models remain brittle to early errors: a single arithmetic slip or unjustified inference typically propagates uncorrected to an incorrect final answer. We investigate whether training on intentionally flawed reasoning traces can teach models to detect and recover from such errors without degrading standard problem-solving ability. Using competition-level problems from MATH-lighteval, we generate CoT prefixes containing exactly one controlled error, either a calculation error (sign flips, dropped terms) or a reasoning error (misapplied rules, unjustified logical steps), and fine-tune Qwen3-4B with GRPO using a binary final-answer reward. Our Mixed-CoT-RL model matches standard RL on clean problems (41% vs 41%) while substantially outperforming it on problems prefilled with flawed reasoning (24% vs 19%). Notably, clean-only RL fine-tuning degrades robustness below the untuned baseline 19% vs. 20%), indicating that conventional training increases susceptibility to misleading prefills. Among error types, training on reasoning errors yields greater robustness gains than calculation errors alone, with mixed training performing best. These findings demonstrate that exposure to flawed traces during training can improve error-recovery behavior without sacrificing accuracy, suggesting a path toward more robust mathematical reasoning in LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u542b\u6709\u6545\u610f\u9519\u8bef\u7684\u63a8\u7406\u94fe\uff08CoT\uff09\u524d\u7f00\uff0c\u80fd\u5426\u6559\u4f1a\u6a21\u578b\u68c0\u6d4b\u5e76\u4ece\u8fd9\u4e9b\u9519\u8bef\u4e2d\u6062\u590d\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u5176\u6807\u51c6\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u6df7\u5408CoT-RL\u6a21\u578b\u4e0d\u4ec5\u5728\u5e72\u51c0\u7684\u95ee\u9898\u4e0a\u4fdd\u6301\u4e86\u4e0e\u6807\u51c6RL\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u5728\u88ab\u9884\u586b\u5145\u6709\u7f3a\u9677\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u4e5f\u663e\u8457\u4f18\u4e8e\u6807\u51c6RL\uff0c\u5e76\u4e14\u66b4\u9732\u4e8e\u6709\u7f3a\u9677\u7684\u8ffd\u8e2a\u8bad\u7ec3\u4e2d\u53ef\u4ee5\u63d0\u9ad8\u9519\u8bef\u6062\u590d\u884c\u4e3a\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\uff0c\u4e3a\u5b9e\u73b0LLM\u4e2d\u66f4\u7a33\u5065\u7684\u6570\u5b66\u63a8\u7406\u6307\u51fa\u4e86\u4e00\u4e2a\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u5df2\u7ecf\u6210\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u6570\u5b66\u63a8\u7406\u7684\u6838\u5fc3\uff0c\u4f46\u6a21\u578b\u5bf9\u4e8e\u65e9\u671f\u9519\u8bef\u4ecd\u7136\u975e\u5e38\u8106\u5f31\uff1a\u5355\u4e2a\u7b97\u672f\u5931\u8bef\u6216\u65e0\u6839\u636e\u7684\u63a8\u65ad\u901a\u5e38\u4f1a\u4e0d\u53d7\u7ea0\u6b63\u5730\u4f20\u64ad\u5230\u6700\u7ec8\u7b54\u6848\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u8bc6\u522b\u548c\u4ece\u8fd9\u7c7b\u9519\u8bef\u4e2d\u6062\u590d\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u800c\u4e0d\u4f1a\u964d\u4f4e\u5176\u5e38\u89c4\u89e3\u9898\u80fd\u529b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u6765\u81eaMATH-lighteval\u7ade\u8d5b\u7ea7\u522b\u7684\u95ee\u9898\uff0c\u751f\u6210\u4e86\u6070\u597d\u5305\u542b\u4e00\u4e2a\u53d7\u63a7\u9519\u8bef\u7684CoT\u524d\u7f00\uff0c\u8fd9\u4e9b\u9519\u8bef\u53ef\u80fd\u662f\u8ba1\u7b97\u9519\u8bef\uff08\u5982\u7b26\u53f7\u7ffb\u8f6c\u3001\u9057\u6f0f\u9879\uff09\u6216\u8005\u662f\u63a8\u7406\u9519\u8bef\uff08\u5982\u8bef\u7528\u89c4\u5219\u3001\u65e0\u6839\u636e\u903b\u8f91\u6b65\u9aa4\uff09\u3002\u7136\u540e\u4f7f\u7528\u4e8c\u5143\u6700\u7ec8\u7b54\u6848\u5956\u52b1\u5bf9Qwen3-4B\u8fdb\u884c\u4e86GRPO\u5fae\u8c03\u3002", "result": "Mixed-CoT-RL\u6a21\u578b\u5728\u6e05\u6d01\u95ee\u9898\u4e0a\u4e0e\u6807\u51c6RL\u8868\u73b0\u76f8\u5f53(41% vs 41%)\uff0c\u800c\u5728\u9884\u5148\u586b\u5145\u6709\u7f3a\u9677\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u5219\u660e\u663e\u4f18\u4e8e\u540e\u8005(24% vs 19%)\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4ec5\u8fdb\u884c\u6e05\u6d01\u95ee\u9898\u7684RL\u5fae\u8c03\u4f1a\u4f7f\u9c81\u68d2\u6027\u4e0b\u964d\u81f3\u672a\u7ecf\u8c03\u6574\u57fa\u7ebf\u4ee5\u4e0b(19% vs. 20%)\uff0c\u8fd9\u8868\u660e\u4f20\u7edf\u8bad\u7ec3\u65b9\u6cd5\u589e\u52a0\u4e86\u5bf9\u8bef\u5bfc\u6027\u9884\u586b\u5145\u7684\u654f\u611f\u5ea6\u3002\u5728\u5404\u79cd\u9519\u8bef\u7c7b\u578b\u4e2d\uff0c\u9488\u5bf9\u63a8\u7406\u9519\u8bef\u7684\u8bad\u7ec3\u6bd4\u5355\u72ec\u9488\u5bf9\u8ba1\u7b97\u9519\u8bef\u7684\u8bad\u7ec3\u80fd\u5e26\u6765\u66f4\u5927\u7684\u9c81\u68d2\u6027\u63d0\u5347\uff0c\u800c\u6df7\u5408\u8bad\u7ec3\u6548\u679c\u6700\u4f73\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u671f\u95f4\u66b4\u9732\u4e8e\u5b58\u5728\u7f3a\u9677\u7684\u8ffd\u8e2a\u53ef\u4ee5\u5e2e\u52a9\u6539\u8fdb\u6a21\u578b\u7684\u9519\u8bef\u6062\u590d\u884c\u4e3a\uff0c\u540c\u65f6\u4e0d\u4f1a\u727a\u7272\u51c6\u786e\u6027\uff0c\u4ece\u800c\u4e3a\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u53ef\u80fd\u9014\u5f84\u3002"}}
{"id": "2512.17814", "categories": ["cs.SE", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.17814", "abs": "https://arxiv.org/abs/2512.17814", "authors": ["Rolf Drechsler", "Qian Liu"], "title": "LLM-based Behaviour Driven Development for Hardware Design", "comment": "7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025", "summary": "Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6280\u672f\u6765\u652f\u6301\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\uff08BDD\uff09\uff0c\u4ee5\u671f\u81ea\u52a8\u5316\u4ece\u6587\u672c\u89c4\u8303\u4e2d\u63a8\u5bfc\u51fa\u7cbe\u786e\u884c\u4e3a\u573a\u666f\u7684\u8fc7\u7a0b\u3002", "motivation": "\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u662f\u786c\u4ef6\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u6d3b\u52a8\uff0c\u4f46\u968f\u7740\u7cfb\u7edf\u89c4\u6a21\u7684\u589e\u957f\u5176\u590d\u6742\u6027\u4e5f\u663e\u8457\u589e\u52a0\u3002\u867d\u7136\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5df2\u7ecf\u8bc1\u660e\u6709\u6548\uff0c\u4f46\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u5c1a\u672a\u5e7f\u6cdb\u5e94\u7528\uff0c\u90e8\u5206\u539f\u56e0\u662f\u9700\u8981\u624b\u52a8\u4ece\u6587\u672c\u89c4\u8303\u4e2d\u63d0\u53d6\u7cbe\u786e\u7684\u884c\u4e3a\u573a\u666f\u3002\u6700\u8fd1\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u7684\u8fdb\u5c55\u4e3a\u81ea\u52a8\u5b8c\u6210\u8fd9\u4e00\u6b65\u9aa4\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6280\u672f\u624b\u6bb5\uff0c\u65e8\u5728\u63a2\u7d22\u8fd9\u4e9b\u6280\u672f\u5982\u4f55\u80fd\u591f\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u65b9\u6cd5\u3002", "result": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u884c\u4e3a\u573a\u666f\u7684\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u64cd\u4f5c\u7684\u9700\u6c42\uff0c\u5e76\u53ef\u80fd\u63d0\u9ad8\u786c\u4ef6\u8bbe\u8ba1\u8fc7\u7a0b\u4e2dBDD\u7684\u5e94\u7528\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e8e\u786c\u4ef6\u8bbe\u8ba1\u7684\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u91cf\uff0c\u4ece\u800c\u4fc3\u8fdbBDD\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u7684\u91c7\u7eb3\u4e0e\u5b9e\u65bd\u3002"}}
{"id": "2512.17091", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.17091", "abs": "https://arxiv.org/abs/2512.17091", "authors": ["Toshiaki Hori", "Jonathan DeCastro", "Deepak Gopinath", "Avinash Balachandran", "Guy Rosman"], "title": "Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making", "comment": "23 pages, 8 figures. Under review", "summary": "We propose a new approach for solving planning problems with a hierarchical structure, fusing reinforcement learning and MPC planning. Our formulation tightly and elegantly couples the two planning paradigms. It leverages reinforcement learning actions to inform the MPPI sampler, and adaptively aggregates MPPI samples to inform the value estimation. The resulting adaptive process leverages further MPPI exploration where value estimates are uncertain, and improves training robustness and the overall resulting policies. This results in a robust planning approach that can handle complex planning problems and easily adapts to different applications, as demonstrated over several domains, including race driving, modified Acrobot, and Lunar Lander with added obstacles. Our results in these domains show better data efficiency and overall performance in terms of both rewards and task success, with up to a 72% increase in success rate compared to existing approaches, as well as accelerated convergence (x2.1) compared to non-adaptive sampling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5f3a\u5316\u5b66\u4e60\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6765\u89e3\u51b3\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u89c4\u5212\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7684\u52a8\u4f5c\u6307\u5bfcMPPI\u91c7\u6837\u5668\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u805a\u5408MPPI\u6837\u672c\u4ee5\u4f30\u8ba1\u4ef7\u503c\u3002\u8fd9\u79cd\u81ea\u9002\u5e94\u8fc7\u7a0b\u5728\u4ef7\u503c\u4f30\u8ba1\u4e0d\u786e\u5b9a\u7684\u5730\u65b9\u589e\u52a0\u4e86\u63a2\u7d22\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5065\u6027\u548c\u7b56\u7565\u6548\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u65b0\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u3001\u4efb\u52a1\u6210\u529f\u7387\u7b49\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u6210\u529f\u7387\u8fbe\u523072%\u7684\u589e\u957f\uff0c\u4e14\u76f8\u8f83\u4e8e\u975e\u81ea\u9002\u5e94\u91c7\u6837\u6536\u655b\u901f\u5ea6\u63d0\u9ad8\u4e862.1\u500d\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u590d\u6742\u7684\u89c4\u5212\u95ee\u9898\u5e76\u63d0\u9ad8\u5bf9\u4e0d\u540c\u5e94\u7528\u7684\u9002\u5e94\u6027\uff0c\u672c\u6587\u65e8\u5728\u878d\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u4e24\u79cd\u89c4\u5212\u8303\u5f0f\u7684\u4f18\u52bf\uff0c\u5f00\u53d1\u51fa\u4e00\u79cd\u66f4\u52a0\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u89c4\u5212\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e0e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7d27\u5bc6\u7ed3\u5408\u3002\u6b64\u65b9\u6cd5\u5229\u7528\u6765\u81eaRL\u7684\u52a8\u4f5c\u4fe1\u606f\u6765\u6307\u5f15\u968f\u673a\u8def\u5f84\u79ef\u5206\uff08MPPI\uff09\u91c7\u6837\u5668\u7684\u5de5\u4f5c\uff1b\u540c\u65f6\uff0c\u57fa\u4e8eMPPI\u4ea7\u751f\u7684\u6837\u672c\u81ea\u9002\u5e94\u5730\u66f4\u65b0\u4ef7\u503c\u8bc4\u4f30\u3002\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u5f53\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u4ef7\u503c\u4f30\u8ba1\u65f6\u4f1a\u8fdb\u4e00\u6b65\u4fc3\u8fdbMPPI\u7684\u63a2\u7d22\u6d3b\u52a8\uff0c\u4ee5\u6b64\u589e\u5f3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u8d5b\u8f66\u9a7e\u9a76\u3001\u6539\u826f\u7248Acrobot\u53ca\u589e\u52a0\u969c\u788d\u7269\u540e\u7684\u6708\u7403\u7740\u9646\u5668\u7b49\u591a\u4e2a\u9886\u57df\u7684\u6d4b\u8bd5\u8bc1\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6570\u636e\u4f7f\u7528\u6548\u7387\u3001\u5956\u52b1\u83b7\u53d6\u91cf\u4ee5\u53ca\u4efb\u52a1\u5b8c\u6210\u6210\u529f\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u7279\u522b\u662f\u5728\u6210\u529f\u7387\u4e0a\u89c2\u5bdf\u5230\u4e86\u9ad8\u8fbe72%\u7684\u589e\u957f\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u4e0d\u4f7f\u7528\u81ea\u9002\u5e94\u91c7\u6837\u7684\u60c5\u51b5\uff0c\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u63d0\u5347\u4e86\u7ea62.1\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u65b0\u9896\u89c4\u5212\u65b9\u6848\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u5904\u7406\u590d\u6742\u591a\u53d8\u7684\u4efb\u52a1\u60c5\u5883\uff0c\u800c\u4e14\u5177\u5907\u826f\u597d\u7684\u8de8\u9886\u57df\u8fc1\u79fb\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u8868\u73b0\u3002"}}
{"id": "2512.17111", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17111", "abs": "https://arxiv.org/abs/2512.17111", "authors": ["Anjali Sarawgi", "Esteban Garces Arias", "Christof Zotter"], "title": "Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts", "comment": "Under review", "summary": "This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve recognition accuracy. Our best model achieves a Character Error Rate (CER) of 4.9\\%. In addition, we implement and evaluate decoding strategies and analyze token-level confusions to better understand model behaviour and error patterns. While the dataset we used for evaluation is confidential, we release our training code, model configurations, and evaluation scripts to support further research in HTR for low-resource historical scripts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u8bc6\u522b\u5386\u53f2\u60a0\u4e45\u4f46\u8d44\u6e90\u8f83\u5c11\u7684\u53e4\u5c3c\u6cca\u5c14\u8bed\u624b\u5199\u6587\u672c\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u901a\u8fc7\u63a2\u7d22\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u548c\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u6280\u672f\u6765\u63d0\u9ad8\u8bc6\u522b\u51c6\u786e\u6027\u3002\u6700\u4f73\u6a21\u578b\u8fbe\u5230\u4e864.9%\u7684\u6587\u5b57\u9519\u8bef\u7387\uff0c\u5e76\u4e14\u6211\u4eec\u516c\u5f00\u4e86\u8bad\u7ec3\u4ee3\u7801\u3001\u6a21\u578b\u914d\u7f6e\u548c\u8bc4\u4f30\u811a\u672c\u4ee5\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u5386\u53f2\u624b\u7a3f\u7684HTR\u7814\u7a76\u3002", "motivation": "\u9488\u5bf9\u53e4\u5c3c\u6cca\u5c14\u8bed\u8fd9\u4e00\u5177\u6709\u5386\u53f2\u610f\u4e49\u4f46\u8d44\u6e90\u532e\u4e4f\u7684\u8bed\u8a00\uff0c\u5f00\u53d1\u4e00\u5957\u6709\u6548\u7684\u624b\u5199\u6587\u672c\u8bc6\u522b\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u884c\u7ea7\u8f6c\u5f55\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u4ee5\u53ca\u6570\u636e\u96c6\u4e2d\u6280\u672f\u5bf9\u624b\u5199\u6587\u672c\u8bc6\u522b\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002\u6b64\u5916\u8fd8\u5b9e\u73b0\u4e86\u8bd1\u7801\u7b56\u7565\u5e76\u5bf9\u6807\u8bb0\u7ea7\u522b\u6df7\u6dc6\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u4e0e\u9519\u8bef\u6a21\u5f0f\u3002", "result": "\u6700\u597d\u7684\u6a21\u578b\u5728\u5b57\u7b26\u9519\u8bef\u7387(CER)\u65b9\u9762\u8fbe\u5230\u4e864.9%\u7684\u6210\u7ee9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f4e\u8d44\u6e90\u5386\u53f2\u624b\u7a3f\u7684\u624b\u5199\u6587\u672c\u8bc6\u522b\u5f00\u8f9f\u4e86\u65b0\u7684\u9053\u8def\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u76f8\u5173\u8d44\u6e90\u652f\u6301\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u5de5\u4f5c\u3002"}}
{"id": "2512.17121", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17121", "abs": "https://arxiv.org/abs/2512.17121", "authors": ["Jasmine Vu", "Shivanand Sheshappanavar"], "title": "The Effect of Negation on CLIP in Medical Imaging: Limitations of Contrastive Language-Image Pretraining", "comment": "10 pages, 7 figures, submitted to WACV Pixels to Patients Workshop", "summary": "Large vision-language models like CLIP are increasingly used in medical imaging tasks due to their ability to align images and text without the need for extensive labeled data. This makes them particularly useful for applications like image retrieval, report generation, and classification in clinical settings. A potential issue to this approach is that CLIP-based models often under perform when interpreting negated phrases, which is especially problematic in the context of medical diagnosing. In this study, we evaluate the Stanford AIMI CheXagent model on its ability to correctly retrieve chest X-ray images using prompts with and without negation. The goal of this project is to understand where this model fails and then use it as a base model to improve its retrieval accuracy by fine tuning methods outlined in previous work. Results from this study show improvement in handling of negation in the CLIP model with a slight decrease in accuracy of positive prompt evaluation. Alongside retrieval accuracy, we examined internal model behavior through token attribution, t-SNE projection, and attention-head ablation to better characterize how each fine tuning approach reshaped the text encoders representation of negated clinical language. Through this work, we hope to better understand the internal behavior of CLIP and improve its handling of negation using clinically relevant language for improving its reliability in medical AI devices.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u5e76\u6539\u8fdb\u4e86Stanford AIMI CheXagent\u6a21\u578b\u5728\u5904\u7406\u542b\u6709\u5426\u5b9a\u8bcd\u7684\u63d0\u793a\u65f6\u68c0\u7d22\u80f8\u90e8X\u5149\u56fe\u50cf\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u5fae\u8c03\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u5426\u5b9a\u53e5\u7684\u5904\u7406\u80fd\u529b\uff0c\u5c3d\u7ba1\u8fd9\u7565\u5fae\u964d\u4f4e\u4e86\u6b63\u9762\u63d0\u793a\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u9274\u4e8e\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5982CLIP\u5728\u533b\u7597\u5f71\u50cf\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u5b83\u4eec\u5728\u89e3\u91ca\u5426\u5b9a\u77ed\u8bed\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u533b\u5b66\u8bca\u65ad\u4e2d\u8fd9\u662f\u4e00\u4e2a\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u6a21\u578b\u5728\u54ea\u65b9\u9762\u5931\u8d25\uff0c\u5e76\u57fa\u4e8e\u6b64\u6539\u8fdb\u5176\u68c0\u7d22\u51c6\u786e\u7387\u3002", "method": "\u4f7f\u7528Stanford AIMI CheXagent\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5206\u522b\u7528\u5305\u542b\u548c\u4e0d\u5305\u542b\u5426\u5b9a\u7684\u63d0\u793a\u6765\u68c0\u7d22\u80f8\u90e8X\u5149\u56fe\u50cf\u3002\u91c7\u7528\u4e4b\u524d\u5de5\u4f5c\u4e2d\u63d0\u51fa\u7684\u5fae\u8c03\u65b9\u6cd5\u6765\u63d0\u9ad8\u6a21\u578b\u5bf9\u5426\u5b9a\u53e5\u7684\u7406\u89e3\u80fd\u529b\u3002\u540c\u65f6\uff0c\u901a\u8fc7token\u5f52\u5c5e\u3001t-SNE\u6295\u5f71\u4ee5\u53ca\u6ce8\u610f\u529b\u5934\u6d88\u878d\u7b49\u624b\u6bb5\u68c0\u67e5\u6a21\u578b\u5185\u90e8\u884c\u4e3a\u53d8\u5316\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5904\u7406\u5426\u5b9a\u53e5\u65b9\u9762\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u5bf9\u6b63\u9762\u63d0\u793a\u7684\u8bc4\u4ef7\u51c6\u786e\u6027\u7565\u6709\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u8fd8\u89c2\u5bdf\u5230\u4e86\u4e0d\u540c\u5fae\u8c03\u65b9\u6cd5\u5982\u4f55\u6539\u53d8\u6587\u672c\u7f16\u7801\u5668\u5bf9\u4e8e\u4e34\u5e8a\u5426\u5b9a\u8bed\u8a00\u7684\u8868\u73b0\u5f62\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u9879\u5de5\u4f5c\uff0c\u6211\u4eec\u5e0c\u671b\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3CLIP\u6a21\u578b\u7684\u5185\u90e8\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u5176\u5bf9\u4e34\u5e8a\u76f8\u5173\u8bed\u8a00\u4e2d\u5426\u5b9a\u53e5\u7684\u5904\u7406\u80fd\u529b\u6765\u63d0\u9ad8\u5176\u5728\u533b\u7597AI\u8bbe\u5907\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.17131", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17131", "abs": "https://arxiv.org/abs/2512.17131", "authors": ["Aaron Defazio", "Konstantin Mishchenko", "Parameswaran Raman", "Hao-Jun Michael Shi", "Lin Xiao"], "title": "Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs", "comment": null, "summary": "We propose Generalized Primal Averaging (GPA), an extension of Nesterov's method in its primal averaging formulation that addresses key limitations of recent averaging-based optimizers such as single-worker DiLoCo and Schedule-Free (SF) in the non-distributed setting. These two recent algorithmic approaches improve the performance of base optimizers, such as AdamW, through different iterate averaging strategies. Schedule-Free explicitly maintains a uniform average of past weights, while single-worker DiLoCo performs implicit averaging by periodically aggregating trajectories, called pseudo-gradients, to update the model parameters. However, single-worker DiLoCo's periodic averaging introduces a two-loop structure, increasing its memory requirements and number of hyperparameters. GPA overcomes these limitations by decoupling the interpolation constant in the primal averaging formulation of Nesterov. This decoupling enables GPA to smoothly average iterates at every step, generalizing and improving upon single-worker DiLoCo. Empirically, GPA consistently outperforms single-worker DiLoCo while removing the two-loop structure, simplifying hyperparameter tuning, and reducing its memory overhead to a single additional buffer. On the Llama-160M model, GPA provides a 24.22% speedup in terms of steps to reach the baseline (AdamW's) validation loss. Likewise, GPA achieves speedups of 12% and 27% on small and large batch setups, respectively, to attain AdamW's validation accuracy on the ImageNet ViT workload. Furthermore, we prove that for any base optimizer with regret bounded by $O(\\sqrt{T})$, where $T$ is the number of iterations, GPA can match or exceed the convergence guarantee of the original optimizer, depending on the choice of interpolation constants.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5e7f\u4e49\u539f\u59cb\u5e73\u5747\uff08GPA\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u6539\u8fdb\u7684Nesterov\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u975e\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e0b\u5355\u5de5DiLoCo\u548c\u65e0\u8c03\u5ea6\uff08SF\uff09\u7b49\u57fa\u4e8e\u5e73\u5747\u4f18\u5316\u5668\u7684\u5173\u952e\u5c40\u9650\u6027\u3002GPA\u901a\u8fc7\u5728\u6bcf\u4e00\u6b65\u5e73\u6ed1\u5730\u5e73\u5747\u8fed\u4ee3\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4ece\u800c\u7b80\u5316\u4e86\u8d85\u53c2\u6570\u8c03\u6574\u5e76\u51cf\u5c11\u4e86\u5185\u5b58\u5f00\u9500\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGPA\u5728\u8fbe\u5230\u57fa\u51c6\u9a8c\u8bc1\u635f\u5931\u65b9\u9762\u6bd4\u5355\u5de5DiLoCo\u66f4\u5feb\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4efb\u4f55\u5177\u6709O(\u221aT)\u540e\u6094\u754c\u7684\u57fa\u672c\u4f18\u5316\u5668\uff0cGPA\u80fd\u591f\u5339\u914d\u6216\u8d85\u8d8a\u5176\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5e73\u5747\u7684\u4f18\u5316\u5668\u5982\u5355\u5de5DiLoCo\u548c\u65e0\u8c03\u5ea6(SF)\u5b58\u5728\u4e00\u4e9b\u5173\u952e\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u5355\u5de5DiLoCo\u5468\u671f\u6027\u5e73\u5747\u5f15\u5165\u4e86\u53cc\u5faa\u73af\u7ed3\u6784\uff0c\u589e\u52a0\u4e86\u5185\u5b58\u9700\u6c42\u548c\u8d85\u53c2\u6570\u6570\u91cf\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6269\u5c55Nesterov\u65b9\u6cd5\u7684\u539f\u59cb\u5e73\u5747\u5f62\u5f0f\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u2014\u2014\u5e7f\u4e49\u539f\u59cb\u5e73\u5747\uff08GPA\uff09\u3002", "method": "GPA\u901a\u8fc7\u5bf9Nesterov\u65b9\u6cd5\u4e2d\u7684\u63d2\u503c\u5e38\u6570\u8fdb\u884c\u89e3\u8026\uff0c\u5b9e\u73b0\u4e86\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u5e73\u6ed1\u5730\u5e73\u5747\u6a21\u578b\u66f4\u65b0\uff0c\u4ece\u800c\u6539\u5584\u5e76\u63a8\u5e7f\u4e86\u5355\u5de5DiLoCo\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u9700\u8981\u53cc\u5faa\u73af\u7ed3\u6784\u7684\u9700\u6c42\uff0c\u7b80\u5316\u4e86\u8d85\u53c2\u6570\u8c03\u4f18\u8fc7\u7a0b\uff0c\u5e76\u5c06\u989d\u5916\u7684\u5185\u5b58\u5f00\u9500\u51cf\u5c11\u5230\u4e86\u53ea\u6709\u4e00\u4e2a\u7f13\u51b2\u533a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728Llama-160M\u6a21\u578b\u4e0a\uff0cGPA\u76f8\u6bd4AdamW\u8fbe\u5230\u4e86\u9a8c\u8bc1\u635f\u5931\u57fa\u7ebf\u6240\u9700\u6b65\u9aa4\u7684\u901f\u5ea6\u63d0\u5347\u4e8624.22%\uff1b\u5728ImageNet ViT\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u9488\u5bf9\u5c0f\u6279\u91cf\u548c\u5927\u6279\u91cf\u8bbe\u7f6e\uff0c\u5206\u522b\u5b9e\u73b0\u4e86\u76f8\u5bf9\u4e8eAdamW 12% \u548c 27% \u7684\u52a0\u901f\u3002\u6b64\u5916\uff0c\u7406\u8bba\u5206\u6790\u8bc1\u660e\uff0c\u5bf9\u4e8e\u4efb\u4e00\u5177\u6709O(\u221aT)\u540e\u6094\u754c\u7684\u57fa\u672c\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u63d2\u503c\u5e38\u6570\uff0cGPA\u80fd\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u539f\u4f18\u5316\u5668\u7684\u6536\u655b\u4fdd\u969c\u3002", "conclusion": "GPA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u6536\u655b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u5e73\u5747\u4f18\u5316\u6280\u672f\u5b58\u5728\u7684\u590d\u6742\u6027\u548c\u6548\u7387\u95ee\u9898\u3002\u5b83\u4e0d\u4ec5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fd8\u4e3a\u7406\u89e3\u53ca\u8fdb\u4e00\u6b65\u5f00\u53d1\u9ad8\u6548\u4f18\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2512.17257", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17257", "abs": "https://arxiv.org/abs/2512.17257", "authors": ["Iason Kyriakopoulos", "Yannis Theodoridis"], "title": "Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods", "comment": "18 pages, 2 figures, 5 tables", "summary": "With the growing popularity of electric vehicles as a means of addressing climate change, concerns have emerged regarding their impact on electric grid management. As a result, predicting EV charging demand has become a timely and important research problem. While substantial research has addressed energy load forecasting in transportation, relatively few studies systematically compare multiple forecasting methods across different temporal horizons and spatial aggregation levels in diverse urban settings. This work investigates the effectiveness of five time series forecasting models, ranging from traditional statistical approaches to machine learning and deep learning methods. Forecasting performance is evaluated for short-, mid-, and long-term horizons (on the order of minutes, hours, and days, respectively), and across spatial scales ranging from individual charging stations to regional and city-level aggregations. The analysis is conducted on four publicly available real-world datasets, with results reported independently for each dataset. To the best of our knowledge, this is the first work to systematically evaluate EV charging demand forecasting across such a wide range of temporal horizons and spatial aggregation levels using multiple real-world datasets.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\uff08\u4ece\u51e0\u5206\u949f\u5230\u51e0\u5929\uff09\u548c\u7a7a\u95f4\u805a\u5408\u6c34\u5e73\uff08\u4ece\u5355\u4e2a\u5145\u7535\u7ad9\u5230\u533a\u57df\u548c\u57ce\u5e02\u7ea7\u522b\uff09\u4e0a\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u9884\u6d4b\u6548\u679c\uff0c\u4f7f\u7528\u4e86\u56db\u4e2a\u516c\u5f00\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u4f5c\u4e3a\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u624b\u6bb5\u7684\u65e5\u76ca\u6d41\u884c\uff0c\u5bf9\u5b83\u4eec\u53ef\u80fd\u7ed9\u7535\u7f51\u7ba1\u7406\u5e26\u6765\u7684\u5f71\u54cd\u4ea7\u751f\u4e86\u62c5\u5fe7\u3002\u56e0\u6b64\uff0c\u9884\u6d4b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u6210\u4e3a\u4e86\u4e00\u4e2a\u53ca\u65f6\u4e14\u91cd\u8981\u7684\u7814\u7a76\u95ee\u9898\u3002\u7136\u800c\uff0c\u5728\u4ea4\u901a\u80fd\u6e90\u8d1f\u8377\u9884\u6d4b\u9886\u57df\u867d\u7136\u5df2\u6709\u5927\u91cf\u7814\u7a76\uff0c\u4f46\u7cfb\u7edf\u6027\u5730\u6bd4\u8f83\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u548c\u7a7a\u95f4\u805a\u5408\u6c34\u5e73\u4e0b\u591a\u79cd\u9884\u6d4b\u65b9\u6cd5\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u4e94\u79cd\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u5305\u62ec\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u3001\u673a\u5668\u5b66\u4e60\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u9488\u5bf9\u77ed\u3001\u4e2d\u3001\u957f\u671f\uff08\u5206\u522b\u5bf9\u5e94\u5206\u949f\u7ea7\u3001\u5c0f\u65f6\u7ea7\u548c\u5929\u6570\u7ea7\uff09\u7684\u65f6\u95f4\u8303\u56f4\u53ca\u4ece\u5355\u72ec\u5145\u7535\u6869\u5230\u533a\u57df\u4e43\u81f3\u57ce\u5e02\u7ea7\u522b\u7684\u7a7a\u95f4\u5c3a\u5ea6\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002\u7814\u7a76\u57fa\u4e8e\u56db\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u5f00\u5c55\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u6570\u636e\u96c6\u72ec\u7acb\u62a5\u544a\u7ed3\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u8303\u56f4\u548c\u7a7a\u95f4\u5c3a\u5ea6\u4e0a\uff0c\u5404\u6a21\u578b\u5bf9\u4e8e\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u7684\u9884\u6d4b\u80fd\u529b\u5b58\u5728\u5dee\u5f02\u3002\u8fd9\u662f\u9996\u6b21\u5c1d\u8bd5\u4f7f\u7528\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u6765\u5168\u9762\u8bc4\u4ef7\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\uff0c\u672c\u6587\u63ed\u793a\u4e86\u4e0d\u540c\u9884\u6d4b\u6a21\u578b\u5728\u5904\u7406\u591a\u6837\u5316\u7684\u65f6\u7a7a\u6761\u4ef6\u4e0b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u65f6\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2512.17270", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17270", "abs": "https://arxiv.org/abs/2512.17270", "authors": ["Yongqi Li", "Hao Lang", "Fei Huang", "Tieyun Qian", "Yongbin Li"], "title": "Understanding Generalization in Role-Playing Models via Information Theory", "comment": null, "summary": "Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u5ea6\u91cfR-EMID\uff0c\u7528\u4e8e\u4ee5\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u8861\u91cf\u89d2\u8272\u626e\u6f14\u6a21\u578b\uff08RPM\uff09\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u901a\u8fc7\u5171\u8fdb\u5316\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u63d0\u9ad8\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u6982\u7387\u7684\u4f30\u8ba1\uff0c\u4ece\u800c\u589e\u5f3aRPM\u5728\u9762\u5bf9\u7528\u6237\u3001\u89d2\u8272\u548c\u5bf9\u8bdd\u7ec4\u5408\u53d8\u5316\u65f6\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u65e0\u6cd5\u5bf9\u5bfc\u81f4\u89d2\u8272\u626e\u6f14\u6a21\u578b\uff08RPM\uff09\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u8868\u73b0\u4e0d\u4f73\u7684\u5404\u79cd\u5206\u5e03\u504f\u79fb\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u8bca\u65ad\uff0c\u7f3a\u4e4f\u6b63\u5f0f\u6846\u67b6\u6765\u63cf\u8ff0RPM\u7684\u6cdb\u5316\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u4e86\u540d\u4e3aR-EMID\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\u6807\u51c6\uff1b\u63a8\u5bfc\u4e86R-EMID\u7684\u4e0a\u9650\uff0c\u4ee5\u9884\u6d4b\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6cdb\u5316\u8868\u73b0\uff1b\u63d0\u51fa\u4e86\u4e00\u4e2a\u5171\u540c\u8fdb\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4ee5\u9002\u5e94\u6027\u5730\u5efa\u6a21\u7528\u6237\u3001\u89d2\u8272\u4e0e\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8fdb\u800c\u6539\u8fdb\u5bf9\u8bdd\u54cd\u5e94\u751f\u6210\u6982\u7387\u7684\u4f30\u8ba1\u3002", "result": "\u4f7f\u7528R-EMID\u8bc4\u4f30\u4e0d\u540cRPMs\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u53d1\u73b0\u7528\u6237\u504f\u79fb\u662f\u6240\u6709\u504f\u79fb\u4e2d\u98ce\u9669\u6700\u9ad8\u7684\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u662f\u5728\u589e\u5f3aRPM\u6cdb\u5316\u65b9\u9762\u6700\u6709\u6548\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3\u53ca\u6539\u5584\u89d2\u8272\u626e\u6f14\u6a21\u578b\u5728\u9762\u5bf9\u4e0d\u540c\u7c7b\u578b\u5206\u5e03\u504f\u79fb\u65f6\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2512.17276", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17276", "abs": "https://arxiv.org/abs/2512.17276", "authors": ["Alireza Moayedikia", "Sara Fin"], "title": "Alzheimer's Disease Brain Network Mining", "comment": null, "summary": "Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneous Alzheimer's Disease (MATCH-AD), a semi supervised framework that integrates deep representation learning, graph-based label propagation, and optimal transport theory to address this limitation. The framework leverages manifold structure in neuroimaging data to propagate diagnostic information from limited labeled samples to larger unlabeled populations, while using Wasserstein distances to quantify disease progression between cognitive states. Evaluated on nearly five thousand subjects from the National Alzheimer's Coordinating Center, encompassing structural MRI measurements from hundreds of brain regions, cerebrospinal fluid biomarkers, and clinical variables MATCHAD achieves near-perfect diagnostic accuracy despite ground truth labels for less than one-third of subjects. The framework substantially outperforms all baseline methods, achieving kappa indicating almost perfect agreement compared to weak agreement for the best baseline, a qualitative transformation in diagnostic reliability. Performance remains clinically useful even under severe label scarcity, and we provide theoretical convergence guarantees with proven bounds on label propagation error and transport stability. These results demonstrate that principled semi-supervised learning can unlock the diagnostic potential of the vast repositories of partially annotated neuroimaging data accumulating worldwide, substantially reducing annotation burden while maintaining accuracy suitable for clinical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u76d1\u7763\u6846\u67b6MATCH-AD\uff0c\u901a\u8fc7\u6df1\u5ea6\u8868\u5f81\u5b66\u4e60\u3001\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u548c\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u6765\u63d0\u9ad8\u963f\u5c14\u8328\u6d77\u9ed8\u75c5(AD)\u8bca\u65ad\u7684\u51c6\u786e\u6027\u3002\u5373\u4f7f\u5728\u6807\u7b7e\u6570\u636e\u975e\u5e38\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u6846\u67b6\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u8bca\u65ad\u7cbe\u5ea6\uff0c\u5e76\u4e14\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4e34\u5e8a\u8bc4\u4f30\u5bf9\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u6765\u8bf4\u65e2\u6602\u8d35\u53c8\u5177\u6709\u4fb5\u5165\u6027\uff0c\u5bfc\u81f4\u53ea\u6709\u5c11\u91cf\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u62e5\u6709\u771f\u5b9e\u6807\u7b7e\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u65b0\u7684\u65b9\u6cd5\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u8fd9\u4e9b\u6709\u9650\u7684\u6570\u636e\u6765\u8fdb\u884c\u51c6\u786e\u7684\u8bca\u65ad\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aMATCH-AD\u7684\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86\u6df1\u5ea6\u8868\u793a\u5b66\u4e60\u3001\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u4ee5\u53ca\u6700\u4f18\u4f20\u8f93\u7406\u8bba\uff0c\u65e8\u5728\u4ece\u6709\u9650\u7684\u5df2\u6807\u8bb0\u6837\u672c\u4e2d\u63a8\u65ad\u51fa\u66f4\u5e7f\u6cdb\u672a\u6807\u8bb0\u7fa4\u4f53\u7684\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528Wasserstein\u8ddd\u79bb\u6765\u91cf\u5316\u4e0d\u540c\u8ba4\u77e5\u72b6\u6001\u95f4\u7684\u75be\u75c5\u8fdb\u5c55\u7a0b\u5ea6\u3002", "result": "\u5728\u8fd1\u4e94\u5343\u540d\u6765\u81ea\u56fd\u5bb6\u963f\u5c14\u8328\u6d77\u9ed8\u6c0f\u75c7\u534f\u8c03\u4e2d\u5fc3\u7684\u53d7\u8bd5\u8005\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5176\u4e2d\u5305\u62ec\u6570\u767e\u4e2a\u5927\u8111\u533a\u57df\u7684\u7ed3\u6784MRI\u6d4b\u91cf\u3001\u8111\u810a\u6db2\u751f\u7269\u6807\u5fd7\u7269\u53ca\u4e34\u5e8a\u53d8\u91cf\uff0c\u7ed3\u679c\u663e\u793aMATCH-AD\u8fbe\u5230\u4e86\u51e0\u4e4e\u5b8c\u7f8e\u7684\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u5373\u4fbf\u662f\u5728\u5c11\u4e8e\u4e09\u5206\u4e4b\u4e00\u7684\u53d7\u8bd5\u8005\u6709\u771f\u5b9e\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u3002\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u8868\u73b0\u51fa\u8272\uff0c\u5728\u6807\u7b7e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u4f9d\u7136\u4fdd\u6301\u4e86\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u539f\u5219\u6027\u7684\u534a\u76d1\u7763\u5b66\u4e60\u80fd\u591f\u91ca\u653e\u5168\u7403\u8303\u56f4\u5185\u79ef\u7d2f\u7684\u5927\u91cf\u90e8\u5206\u6ce8\u91ca\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u7684\u8bca\u65ad\u6f5c\u529b\uff0c\u5927\u5927\u51cf\u8f7b\u4e86\u6807\u6ce8\u8d1f\u62c5\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2512.17325", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17325", "abs": "https://arxiv.org/abs/2512.17325", "authors": ["Chaeha Kim"], "title": "Task Schema and Binding: A Double Dissociation Study of In-Context Learning", "comment": "20pages, 2figures", "summary": "We provide causal mechanistic validation that in-context learning (ICL) decomposes into two separable mechanisms: Task Schema (abstract task type recognition) and Binding (specific input-output associations). Through activation patching experiments across 9 models from 7 Transformer families plus Mamba (370M-13B parameters), we establish three key findings:\n  1. Double dissociation: Task Schema transfers at 100% via late MLP patching; Binding transfers at 62% via residual stream patching -- proving separable mechanisms\n  2. Prior-Schema trade-off: Schema reliance inversely correlates with prior knowledge (Spearman rho = -0.596, p < 0.001, N=28 task-model pairs)\n  3. Architecture generality: The mechanism operates across all tested architectures including the non-Transformer Mamba\n  These findings offer a mechanistic account of the ICL puzzle that contrasts with prior views treating ICL as a monolithic mechanism (whether retrieval-based, gradient descent-like, or purely Bayesian). By establishing that Schema and Binding are neurally dissociable -- not merely behavioral modes -- we provide causal evidence for dual-process theories of ICL. Models rely on Task Schema when prior knowledge is absent, but prior knowledge interferes through attentional mis-routing (72.7% recency bias) rather than direct output competition (0%). This explains why arbitrary mappings succeed (zero prior leads to full Schema reliance) while factual overrides fail -- and reveals that the true bottleneck is attentional, not output-level. Practical implications: Understanding these dual mechanisms enables more efficient prompt engineering -- reliable schema transfer reduces required demonstrations for novel tasks, while prior-aware design can mitigate the 38% binding failure rate in high-prior scenarios, improving ICL system reliability in production deployments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u56e0\u679c\u673a\u5236\u9a8c\u8bc1\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u53ef\u4ee5\u5206\u89e3\u4e3a\u4e24\u4e2a\u53ef\u5206\u79bb\u7684\u673a\u5236\uff1a\u4efb\u52a1\u6a21\u5f0f\uff08\u62bd\u8c61\u4efb\u52a1\u7c7b\u578b\u8bc6\u522b\uff09\u548c\u7ed1\u5b9a\uff08\u7279\u5b9a\u8f93\u5165-\u8f93\u51fa\u5173\u8054\uff09\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8fd9\u4e24\u4e2a\u673a\u5236\u5728\u795e\u7ecf\u4e0a\u662f\u53ef\u5206\u79bb\u7684\uff0c\u5e76\u4e14\u6a21\u578b\u4f9d\u8d56\u4e8e\u4efb\u52a1\u6a21\u5f0f\u8fd8\u662f\u5148\u524d\u77e5\u8bc6\u53d6\u51b3\u4e8e\u5177\u4f53\u60c5\u51b5\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u63d0\u9ad8ICCL\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6fc0\u6d3b\u4fee\u8865\u5b9e\u9a8c\u6765\u63a2\u7a76\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u7684\u5177\u4f53\u8fd0\u4f5c\u673a\u5236\uff0c\u4ee5\u89e3\u51b3\u8fc7\u53bb\u5c06ICL\u89c6\u4e3a\u5355\u4e00\u673a\u5236\u7684\u770b\u6cd5\u6240\u5e26\u6765\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5bf99\u4e2a\u6765\u81ea7\u79cdTransformer\u5bb6\u65cf\u52a0\u4e0aMamba\uff08\u53c2\u6570\u8303\u56f43.7\u4ebf\u5230130\u4ebf\uff09\u7684\u6a21\u578b\u8fdb\u884c\u6fc0\u6d3b\u4fee\u8865\u5b9e\u9a8c\uff0c\u7814\u7a76\u4eba\u5458\u9a8c\u8bc1\u4e86\u4efb\u52a1\u6a21\u5f0f\u548c\u7ed1\u5b9a\u4f5c\u4e3aICL\u4e24\u4e2a\u53ef\u5206\u79bb\u673a\u5236\u7684\u5b58\u5728\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u4e09\u4e2a\u5173\u952e\u70b9\uff1a1) \u4efb\u52a1\u6a21\u5f0f\u4e0e\u7ed1\u5b9a\u4e4b\u95f4\u5b58\u5728\u53cc\u91cd\u5206\u79bb\u73b0\u8c61\uff1b2) \u6a21\u5f0f\u4f9d\u8d56\u6027\u4e0e\u5148\u9a8c\u77e5\u8bc6\u5448\u8d1f\u76f8\u5173\u5173\u7cfb\uff1b3) \u6240\u8ff0\u673a\u5236\u9002\u7528\u4e8e\u6240\u6709\u6d4b\u8bd5\u8fc7\u7684\u67b6\u6784\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3ICL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u5373\u5b83\u662f\u7531\u4efb\u52a1\u6a21\u5f0f\u548c\u7ed1\u5b9a\u8fd9\u4e24\u79cd\u72ec\u7acb\u4f46\u76f8\u4e92\u4f5c\u7528\u7684\u673a\u5236\u7ec4\u6210\u7684\u3002\u8fd9\u79cd\u7406\u89e3\u6709\u52a9\u4e8e\u6539\u5584\u63d0\u793a\u5de5\u7a0b\u6548\u7387\u5e76\u63d0\u9ad8ICL\u7cfb\u7edf\u5728\u9ad8\u5148\u9a8c\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.17367", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17367", "abs": "https://arxiv.org/abs/2512.17367", "authors": ["Yidong Chai", "Yi Liu", "Mohammadreza Ebrahimi", "Weifeng Li", "Balaji Padmanabhan"], "title": "Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach", "comment": null, "summary": "Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evade detection. Enhancing adversarial robustness is therefore essential, requiring detectors that can defend against diverse attacks (generalizability) while maintaining high overall accuracy. However, simultaneously achieving both optimal generalizability and accuracy is challenging. Following the computational design science paradigm, this study takes a sequential approach that first proposes a novel framework (Large Language Model-based Sample Generation and Aggregation, LLM-SGA) by identifying the key invariances of textual adversarial attacks and leveraging them to ensure that a detector instantiated within the framework has strong generalizability. Second, we instantiate our detector (Adversarially Robust Harmful Online Content Detector, ARHOCD) with three novel design components to improve detection accuracy: (1) an ensemble of multiple base detectors that exploits their complementary strengths; (2) a novel weight assignment method that dynamically adjusts weights based on each sample's predictability and each base detector's capability, with weights initialized using domain knowledge and updated via Bayesian inference; and (3) a novel adversarial training strategy that iteratively optimizes both the base detectors and the weight assignor. We addressed several limitations of existing adversarial robustness enhancement research and empirically evaluated ARHOCD across three datasets spanning hate speech, rumor, and extremist content. Results show that ARHOCD offers strong generalizability and improves detection accuracy under adversarial conditions.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6LLM-SGA\u548c\u68c0\u6d4b\u5668ARHOCD\uff0c\u4ee5\u589e\u5f3a\u5bf9\u6297\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u57fa\u7840\u68c0\u6d4b\u5668\u3001\u52a8\u6001\u8c03\u6574\u6743\u91cd\u7684\u65b9\u6cd5\u4ee5\u53ca\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff0cARHOCD\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6539\u8fdb\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u53d7\u5230\u8bf8\u5982\u4ec7\u6068\u8a00\u8bba\u3001\u9519\u8bef\u4fe1\u606f\u548c\u6781\u7aef\u4e3b\u4e49\u8a00\u8bba\u7b49\u6709\u5bb3\u5185\u5bb9\u7684\u5f71\u54cd\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u6a21\u578b\u88ab\u5e7f\u6cdb\u7528\u4e8e\u68c0\u6d4b\u8fd9\u4e9b\u5185\u5bb9\uff0c\u4f46\u5b83\u4eec\u5f88\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\u3002\u56e0\u6b64\uff0c\u63d0\u9ad8\u5bf9\u6297\u6027\u9c81\u68d2\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u610f\u5473\u7740\u68c0\u6d4b\u5668\u9700\u8981\u80fd\u591f\u62b5\u5fa1\u5404\u79cd\u653b\u51fb\uff08\u6cdb\u5316\u80fd\u529b\uff09\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002\u7136\u800c\uff0c\u540c\u65f6\u5b9e\u73b0\u6700\u4f73\u6cdb\u5316\u80fd\u529b\u548c\u51c6\u786e\u6027\u662f\u5177\u6709\u6311\u6218\u6027\u7684\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLLM-SGA\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u6587\u672c\u5bf9\u6297\u653b\u51fb\u7684\u5173\u952e\u4e0d\u53d8\u91cf\u5e76\u5229\u7528\u5b83\u4eec\u6765\u786e\u4fdd\u57fa\u4e8e\u6b64\u6846\u67b6\u5b9e\u4f8b\u5316\u7684\u68c0\u6d4b\u5668\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5176\u6b21\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aARHOCD\u7684\u68c0\u6d4b\u5668\uff0c\u5b83\u5305\u542b\u4e09\u4e2a\u521b\u65b0\u8bbe\u8ba1\u7ec4\u4ef6\uff1a(1) \u4e00\u4e2a\u96c6\u5408\u4e86\u591a\u4e2a\u57fa\u7840\u68c0\u6d4b\u5668\u7684\u7cfb\u7edf\uff0c\u5229\u7528\u5b83\u4eec\u4e92\u8865\u7684\u4f18\u52bf\uff1b(2) \u4e00\u79cd\u65b0\u578b\u6743\u91cd\u5206\u914d\u65b9\u6cd5\uff0c\u6839\u636e\u6bcf\u4e2a\u6837\u672c\u7684\u53ef\u9884\u6d4b\u6027\u548c\u6bcf\u4e2a\u57fa\u7840\u68c0\u6d4b\u5668\u7684\u80fd\u529b\u52a8\u6001\u8c03\u6574\u6743\u91cd\uff0c\u5e76\u4f7f\u7528\u9886\u57df\u77e5\u8bc6\u521d\u59cb\u5316\u6743\u91cd\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u66f4\u65b0\uff1b(3) \u4e00\u79cd\u65b0\u7684\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff0c\u8fed\u4ee3\u4f18\u5316\u57fa\u7840\u68c0\u6d4b\u5668\u548c\u6743\u91cd\u5206\u914d\u8005\u3002", "result": "ARHOCD\u5728\u6db5\u76d6\u4ec7\u6068\u8a00\u8bba\u3001\u8c23\u8a00\u53ca\u6781\u7aef\u5185\u5bb9\u7684\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0cARHOCD\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u4e5f\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u5ea6\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u6297\u9c81\u68d2\u6027\u589e\u5f3a\u7814\u7a76\u4e2d\u7684\u51e0\u4e2a\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684ARHOCD\u68c0\u6d4b\u5668\u5728\u9762\u5bf9\u6076\u610f\u7528\u6237\u8bd5\u56fe\u7ed5\u8fc7\u68c0\u6d4b\u65f6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.17375", "categories": ["cs.LG", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17375", "abs": "https://arxiv.org/abs/2512.17375", "authors": ["Tung-Ling Li", "Yuhao Wu", "Hongliang Liu"], "title": "AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens", "comment": null, "summary": "Reward models and LLM-as-a-Judge systems are central to modern post-training pipelines such as RLHF, DPO, and RLAIF, where they provide scalar feedback and binary decisions that guide model selection and RL-based fine-tuning. We show that these judge systems exhibit a recurring vulnerability: short sequences of low-perplexity control tokens can flip many binary evaluations from correct ``No'' judgments to incorrect ``Yes'' judgments by steering the last-layer logit gap. These control tokens are patterns that a policy model could plausibly generate during post-training, and thus represent realistic reward-hacking risks rather than worst-case adversarial strings. Our method, AdvJudge-Zero, uses the model's next-token distribution and beam-search exploration to discover diverse control-token sequences from scratch, and our analysis shows that the induced hidden-state perturbations concentrate in a low-rank ``soft mode'' that is anti-aligned with the judge's refusal direction. Empirically, these tokens cause very high false positive rates when large open-weight and specialized judge models score incorrect answers on math and reasoning benchmarks. Finally, we show that LoRA-based adversarial training on small sets of control-token-augmented examples can markedly reduce these false positives while preserving evaluation quality.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u5956\u52b1\u6a21\u578b\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u7cfb\u7edf\u5728\u8bf8\u5982RLHF\u3001DPO\u548cRLAIF\u7b49\u73b0\u4ee3\u540e\u8bad\u7ec3\u7ba1\u9053\u4e2d\u7684\u4e00\u4e2a\u5e38\u89c1\u8106\u5f31\u6027\uff1a\u77ed\u5e8f\u5217\u7684\u4f4e\u56f0\u60d1\u5ea6\u63a7\u5236\u6807\u8bb0\u53ef\u4ee5\u64cd\u7eb5\u8bb8\u591a\u4e8c\u5143\u8bc4\u4f30\uff0c\u4ece\u6b63\u786e\u7684\u201c\u5426\u201d\u5224\u65ad\u8f6c\u4e3a\u9519\u8bef\u7684\u201c\u662f\u201d\u5224\u65ad\u3002\u901a\u8fc7\u4f7f\u7528AdvJudge-Zero\u65b9\u6cd5\u53d1\u73b0\u8fd9\u4e9b\u63a7\u5236\u6807\u8bb0\uff0c\u5e76\u6307\u51fa\u5b83\u4eec\u5728\u9690\u85cf\u72b6\u6001\u6270\u52a8\u4e2d\u96c6\u4e2d\u4e8e\u4e0e\u8bc4\u5224\u62d2\u7edd\u65b9\u5411\u76f8\u53cd\u7684\u4f4e\u79e9\u2018\u8f6f\u6a21\u5f0f\u2019\u3002\u6b64\u5916\uff0c\u5b9e\u8bc1\u663e\u793a\u8fd9\u4e9b\u6807\u8bb0\u4f1a\u5bfc\u81f4\u9ad8\u8bef\u62a5\u7387\uff0c\u800c\u57fa\u4e8eLoRA\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u80fd\u591f\u663e\u8457\u51cf\u5c11\u8bef\u62a5\u540c\u65f6\u4fdd\u6301\u8bc4\u4f30\u8d28\u91cf\u3002", "motivation": "\u8be5\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5956\u52b1\u6a21\u578b\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u4e00\u4e2a\u6f5c\u5728\u6f0f\u6d1e\uff0c\u5373\u901a\u8fc7\u63d2\u5165\u7279\u5b9a\u7684\u63a7\u5236\u6807\u8bb0\u6765\u64cd\u63a7\u6a21\u578b\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4ece\u800c\u5f71\u54cd\u57fa\u4e8e\u6b64\u53cd\u9988\u8fdb\u884c\u7684\u6a21\u578b\u9009\u62e9\u548c\u5fae\u8c03\u3002\u8fd9\u79cd\u64cd\u4f5c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u6b63\u786e\u7684\u5224\u65ad\u7ed3\u679c\uff0c\u5bf9\u4f9d\u8d56\u8fd9\u7c7b\u7cfb\u7edf\u7684\u5e94\u7528\u6784\u6210\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdvJudge-Zero\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u6a21\u578b\u7684\u4e0b\u4e00\u4e2atoken\u5206\u5e03\u548c\u675f\u641c\u7d22\u63a2\u7d22\u6280\u672f\uff0c\u4ece\u96f6\u5f00\u59cb\u53d1\u73b0\u591a\u6837\u5316\u7684\u63a7\u5236\u6807\u8bb0\u5e8f\u5217\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u8fd9\u4e9b\u6807\u8bb0\u5982\u4f55\u901a\u8fc7\u8bf1\u5bfc\u9690\u85cf\u72b6\u6001\u7684\u5c0f\u6270\u52a8\uff0c\u5728\u6700\u540e\u4e00\u5c42logit\u5dee\u8ddd\u4e0a\u4ea7\u751f\u5f71\u54cd\uff0c\u4fc3\u4f7f\u539f\u672c\u5e94\u4e3a\u201c\u5426\u201d\u7684\u5224\u65ad\u8f6c\u5411\u201c\u662f\u201d\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7AdvJudge-Zero\u65b9\u6cd5\u627e\u5230\u7684\u63a7\u5236\u6807\u8bb0\u786e\u5b9e\u80fd\u591f\u4ee5\u9ad8\u6982\u7387\u5bfc\u81f4\u9519\u8bef\u7684\u6b63\u9762\u8bc4\u4ef7\uff0c\u5c24\u5176\u662f\u5728\u6570\u5b66\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u3002\u53e6\u5916\uff0c\u5b9e\u9a8c\u8fd8\u8868\u660e\uff0c\u91c7\u7528\u57fa\u4e8eLoRA\u7684\u5c0f\u89c4\u6a21\u5bf9\u6297\u6027\u8bad\u7ec3\u53ef\u4ee5\u5728\u4fdd\u7559\u8bc4\u4f30\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u7531\u63a7\u5236\u6807\u8bb0\u5f15\u8d77\u7684\u8bef\u62a5\u7387\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u5f53\u524d\u4f7f\u7528\u7684\u5956\u52b1\u6a21\u578b\u53caLLM\u8bc4\u5224\u7cfb\u7edf\u9762\u5bf9\u7279\u5b9a\u63a7\u5236\u6807\u8bb0\u65f6\u5b58\u5728\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u68c0\u6d4b\u5e76\u7f13\u89e3\u6b64\u7c7b\u98ce\u9669\u7684\u65b9\u6cd5\u8bba\u3002\u8fd9\u4e3a\u8fdb\u4e00\u6b65\u63d0\u9ad8AI\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.17409", "categories": ["cs.LG", "stat.AP", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17409", "abs": "https://arxiv.org/abs/2512.17409", "authors": ["Dishantkumar Sutariya", "Eike Petersen"], "title": "meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis", "comment": null, "summary": "Analyzing machine learning model performance stratified by patient and recording properties is becoming the accepted norm and often yields crucial insights about important model failure modes. Performing such analyses in a statistically rigorous manner is non-trivial, however. Appropriate performance metrics must be selected that allow for valid comparisons between groups of different sample sizes and base rates; metric uncertainty must be determined and multiple comparisons be corrected for, in order to assess whether any observed differences may be purely due to chance; and in the case of intersectional analyses, mechanisms must be implemented to find the most `interesting' subgroups within combinatorially many subgroup combinations. We here present a statistical toolbox that addresses these challenges and enables practitioners to easily yet rigorously assess their models for potential subgroup performance disparities. While broadly applicable, the toolbox is specifically designed for medical imaging applications. The analyses provided by the toolbox are illustrated in two case studies, one in skin lesion malignancy classification on the ISIC2020 dataset and one in chest X-ray-based disease classification on the MIMIC-CXR dataset.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7edf\u8ba1\u5de5\u5177\u7bb1\uff0c\u65e8\u5728\u5e2e\u52a9\u4ece\u4e1a\u8005\u4ee5\u4e25\u8c28\u7684\u65b9\u5f0f\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u60a3\u8005\u548c\u8bb0\u5f55\u5c5e\u6027\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002\u8be5\u5de5\u5177\u7bb1\u7279\u522b\u9002\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5206\u6790\u80fd\u529b\uff1a\u4e00\u4e2a\u662f\u57fa\u4e8eISIC2020\u6570\u636e\u96c6\u7684\u76ae\u80a4\u75c5\u53d8\u6076\u6027\u5206\u7c7b\uff0c\u53e6\u4e00\u4e2a\u662f\u57fa\u4e8eMIMIC-CXR\u6570\u636e\u96c6\u7684\u80f8\u90e8X\u5149\u75be\u75c5\u5206\u7c7b\u3002", "motivation": "\u4f5c\u8005\u6307\u51fa\uff0c\u5728\u4e0d\u540c\u7684\u60a3\u8005\u53ca\u8bb0\u5f55\u7279\u6027\u4e0b\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8868\u73b0\u8fdb\u884c\u5206\u5c42\u5206\u6790\u5df2\u7ecf\u6210\u4e3a\u5171\u8bc6\uff0c\u8fd9\u901a\u5e38\u80fd\u63ed\u793a\u5173\u4e8e\u6a21\u578b\u5931\u8d25\u6a21\u5f0f\u7684\u5173\u952e\u89c1\u89e3\u3002\u7136\u800c\uff0c\u4ee5\u7edf\u8ba1\u5b66\u4e0a\u4e25\u683c\u7684\u65b9\u6cd5\u6267\u884c\u8fd9\u79cd\u5206\u6790\u5e76\u4e0d\u7b80\u5355\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3001\u4fbf\u4e8e\u4f7f\u7528\u8005\u4e25\u8c28\u5730\u8bc4\u4f30\u6a21\u578b\u6f5c\u5728\u5b50\u7fa4\u8868\u73b0\u5dee\u5f02\u7684\u7edf\u8ba1\u5de5\u5177\u7bb1\u663e\u5f97\u5341\u5206\u5fc5\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u7edf\u8ba1\u5de5\u5177\u7bb1\uff0c\u5b83\u5141\u8bb8\u9009\u62e9\u5408\u9002\u7684\u6027\u80fd\u6307\u6807\u6765\u6bd4\u8f83\u4e0d\u540c\u6837\u672c\u5927\u5c0f\u548c\u57fa\u7840\u6bd4\u7387\u4e4b\u95f4\u7684\u7ec4\u522b\uff1b\u786e\u5b9a\u5ea6\u91cf\u4e0d\u786e\u5b9a\u6027\u5e76\u5bf9\u591a\u91cd\u6bd4\u8f83\u8fdb\u884c\u6821\u6b63\uff0c\u4ee5\u4fbf\u5224\u65ad\u89c2\u5bdf\u5230\u7684\u4efb\u4f55\u5dee\u5f02\u662f\u5426\u4ec5\u4ec5\u662f\u5076\u7136\u9020\u6210\u7684\uff1b\u5bf9\u4e8e\u4ea4\u53c9\u5206\u6790\uff0c\u5b9e\u73b0\u673a\u5236\u4ee5\u5728\u7ec4\u5408\u4f17\u591a\u7684\u5b50\u7ec4\u4e2d\u627e\u5230\u6700\u2018\u6709\u8da3\u2019\u7684\u5b50\u7ec4\u3002", "result": "\u8fd9\u4e2a\u7edf\u8ba1\u5de5\u5177\u7bb1\u4e3a\u533b\u7597\u6210\u50cf\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u652f\u6301\uff0c\u901a\u8fc7\u4e24\u4e2a\u5177\u4f53\u7684\u6848\u4f8b\u7814\u7a76\u2014\u2014ISIC2020\u6570\u636e\u96c6\u4e0a\u7684\u76ae\u80a4\u75c5\u53d8\u6076\u6027\u5206\u7c7b\u4ee5\u53caMIMIC-CXR\u6570\u636e\u96c6\u4e0a\u7684\u80f8\u90e8X\u5c04\u7ebf\u75be\u75c5\u5206\u7c7b\u2014\u2014\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u8be5\u5de5\u5177\u7bb1\u8fdb\u884c\u5206\u6790\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7edf\u8ba1\u5de5\u5177\u7bb1\u80fd\u591f\u6709\u6548\u5730\u5e2e\u52a9\u4ece\u4e1a\u8005\u5728\u590d\u6742\u7684\u5b9e\u9645\u573a\u666f\u4e2d\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7279\u522b\u662f\u9488\u5bf9\u533b\u5b66\u5f71\u50cf\u9886\u57df\u5185\u7684\u5e94\u7528\u3002"}}
{"id": "2512.17444", "categories": ["cs.LG", "cs.AI", "cs.NE", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.17444", "abs": "https://arxiv.org/abs/2512.17444", "authors": ["Javier Gonzalez-Ruiz", "Carlos Rodriguez-Pardo", "Iacopo Savelli", "Alice Di Bella", "Massimo Tavoni"], "title": "Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning", "comment": "Accepted to Energy and AI. Code available in https://github.com/jjgonzalez2491/MARLEY_V1", "summary": "Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u6349\u8131\u78b3\u80fd\u6e90\u7cfb\u7edf\u7684\u5173\u952e\u7279\u5f81\uff0c\u5e76\u5728\u4e0d\u540c\u7ade\u4e89\u6c34\u5e73\u3001\u5e02\u573a\u8bbe\u8ba1\u548c\u653f\u7b56\u60c5\u666f\u4e0b\u5e94\u7528\u4e8e\u7b80\u5316\u7684\u610f\u5927\u5229\u7535\u529b\u7cfb\u7edf\u4e2d\uff0c\u7ed3\u679c\u7a81\u51fa\u4e86\u5e02\u573a\u8bbe\u8ba1\u5bf9\u4e8e\u7535\u529b\u90e8\u95e8\u8131\u78b3\u548c\u907f\u514d\u4ef7\u683c\u6ce2\u52a8\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u51b3\u7b56\u8005\u548c\u5176\u4ed6\u5229\u76ca\u76f8\u5173\u8005\u8bbe\u8ba1\u3001\u6d4b\u8bd5\u548c\u8bc4\u4f30\u957f\u671f\u5e02\u573a\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u5de5\u5177\u6765\u4fc3\u8fdb\u7535\u529b\u7cfb\u7edf\u7684\u8131\u78b3\u8fc7\u7a0b\u3002", "method": "\u91c7\u7528\u72ec\u7acb\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u5e7f\u6cdb\u7684\u8d85\u53c2\u6570\u641c\u7d22\u786e\u4fdd\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u4ea7\u751f\u4e0e\u7ade\u4e89\u884c\u4e3a\u4e00\u81f4\u7684\u5e02\u573a\u7ed3\u679c\u3002", "result": "\u8be5\u6a21\u578b\u5728\u7b80\u5316\u7684\u610f\u5927\u5229\u7535\u529b\u7cfb\u7edf\u7248\u672c\u4e0a\u8fdb\u884c\u4e86\u5e94\u7528\u548c\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u5e02\u573a\u8bbe\u8ba1\u5728\u7535\u529b\u90e8\u95e8\u8131\u78b3\u53ca\u907f\u514d\u4ef7\u683c\u6ce2\u52a8\u65b9\u9762\u626e\u6f14\u7740\u5173\u952e\u89d2\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u8bc4\u4f30\u591a\u79cd\u653f\u7b56\u548c\u5e02\u573a\u673a\u5236\u540c\u65f6\u4ea4\u4e92\u4f5c\u7528\u4e0b\u7684\u957f\u671f\u7535\u529b\u5e02\u573a\uff0c\u5176\u4e2d\u5e02\u573a\u4e3b\u4f53\u5bf9\u8131\u78b3\u8def\u5f84\u505a\u51fa\u54cd\u5e94\u5e76\u8fdb\u884c\u9002\u5e94\u3002"}}
{"id": "2512.17452", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17452", "abs": "https://arxiv.org/abs/2512.17452", "authors": ["Yen-Chieh Huang", "Rui Fang", "Ming-Syan Chen", "Pi-Cheng Hsiu"], "title": "Learning What to Write: Write-Gated KV for Efficient Long-Context Inference", "comment": null, "summary": "Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWrite-Gated KV\u7684\u8f7b\u91cf\u7ea7\u673a\u5236\uff0c\u901a\u8fc7\u5b66\u4e60\u9884\u6d4b\u8fdb\u5165\u7f13\u5b58\u524d\u7684token\u6548\u7528\uff0c\u4ee5\u51cf\u5c11\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u4f7f\u7528\u548c\u52a0\u901f\u9884\u586b\u5145\u53ca\u89e3\u7801\u8fc7\u7a0b\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53d7\u9650\u4e8e\u4e8c\u6b21\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u4ee5\u53ca\u7ebf\u6027KV\u7f13\u5b58\u589e\u957f\u7684\u95ee\u9898\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u672a\u80fd\u89e3\u51b3\u6839\u672c\u95ee\u9898\uff1a\u5373\u5bf9\u6301\u4e45\u5185\u5b58\u7684\u65e0\u5dee\u522b\u5199\u5165\u5e26\u6765\u7684\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f5c\u8005\u5c06KV\u7f13\u5b58\u7ba1\u7406\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u56e0\u679c\u7cfb\u7edf\uff0c\u5305\u62ec\u4e09\u4e2a\u57fa\u672c\u64cd\u4f5c\uff1aKV\u51c6\u5165\u3001\u9009\u62e9\u4e0e\u6dd8\u6c70\uff0c\u5e76\u901a\u8fc7Write-Gated KV\u5b9e\u73b0KV\u51c6\u5165\uff0c\u8be5\u673a\u5236\u80fd\u591f\u5b66\u4e60\u9884\u6d4b\u6bcf\u4e2atoken\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u907f\u514d\u4f4e\u6548\u72b6\u6001\u8fc7\u65e9\u8fdb\u5165\u7f13\u5b58\uff0c\u4fdd\u6301\u5168\u5c40\u7f13\u5b58\u7d27\u51d1\u7684\u540c\u65f6\u7ef4\u62a4\u5c40\u90e8\u6ed1\u52a8\u7a97\u53e3\u5185\u7684\u7f13\u5b58\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5728Llama\u6a21\u578b\u4e0a\u5e94\u7528Write-Gated KV\u53ef\u4ee5\u964d\u4f4e46-57%\u7684\u5185\u5b58\u6d88\u8017\uff0c\u540c\u65f6\u5206\u522b\u63d0\u9ad8\u4e863.03-3.45\u500d\u7684\u9884\u586b\u5145\u901f\u5ea6\u548c1.89-2.56\u500d\u7684\u89e3\u7801\u901f\u5ea6\uff0c\u4e14\u51e0\u4e4e\u6ca1\u6709\u51c6\u786e\u6027\u635f\u5931\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u80fd\u517c\u5bb9FlashAttention\u548c\u5206\u9875KV\u7cfb\u7edf\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5b66\u4e60\u51b3\u5b9a\u54ea\u4e9b\u5185\u5bb9\u5e94\u8be5\u88ab\u5199\u5165KV\u7f13\u5b58\u662f\u4e00\u79cd\u65e2\u5b9e\u7528\u53c8\u5177\u6709\u539f\u5219\u6027\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u6548\u7387\u3002"}}
{"id": "2512.17527", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17527", "abs": "https://arxiv.org/abs/2512.17527", "authors": ["Muhammad Haris Khan"], "title": "SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals", "comment": null, "summary": "Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate \"never-before-seen\" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSafeBench-Seq\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u86cb\u767d\u8d28\u5e8f\u5217\u7ea7\u522b\u7684\u98ce\u9669\u7b5b\u67e5\u3002\u5b83\u4ec5\u4f7f\u7528\u516c\u5171\u6570\u636e\u6784\u5efa\uff0c\u5e76\u901a\u8fc7\u540c\u6e90\u6027\u805a\u7c7b\u6765\u6a21\u62df\u524d\u6240\u672a\u89c1\u7684\u5a01\u80c1\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u7ebf\u6027\u6a21\u578b\u5728\u7ecf\u8fc7\u6821\u51c6\u540e\u8868\u73b0\u51fa\u8f83\u597d\u7684\u6821\u51c6\u6027\u80fd\uff0c\u800c\u6811\u96c6\u6210\u65b9\u6cd5\u5219\u6709\u7565\u9ad8\u7684Brier\u5f97\u5206\u548cECE\u3002\u8be5\u5de5\u5177\u53ea\u4f9d\u8d56CPU\u8fd0\u884c\uff0c\u4e14\u4e0d\u4f1a\u5206\u53d1\u5371\u9669\u5e8f\u5217\u3002", "motivation": "\u9488\u5bf9\u86cb\u767d\u8d28\u8bbe\u8ba1\u7684\u57fa\u7840\u6a21\u578b\u5e26\u6765\u4e86\u5177\u4f53\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\uff0c\u4f46\u793e\u533a\u7f3a\u4e4f\u4e00\u4e2a\u7b80\u5355\u3001\u53ef\u91cd\u590d\u7684\u5e8f\u5217\u7ea7\u522b\u98ce\u9669\u7b5b\u67e5\u57fa\u7ebf\uff0c\u8be5\u57fa\u7ebf\u5e94\u8be5\u80fd\u591f\u5728\u540c\u6e90\u63a7\u5236\u4e0b\u8fdb\u884c\u660e\u786e\u8bc4\u4f30\uff0c\u5e76\u80fd\u5728\u666e\u901aCPU\u4e0a\u8fd0\u884c\u3002", "method": "\u5f00\u53d1\u4e86SafeBench-Seq\uff0c\u8fd9\u662f\u4e00\u4e2a\u4ec5\u57fa\u4e8e\u5143\u6570\u636e\u7684\u3001\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u5206\u7c7b\u5668\uff0c\u5b8c\u5168\u7531\u516c\u5f00\u6570\u636e\uff08SafeProtein\u5371\u5bb3\u6570\u636e\u96c6\u548cUniProt\u826f\u6027\u6837\u672c\uff09\u53ca\u53ef\u89e3\u91ca\u7279\u5f81\uff08\u5168\u5c40\u7269\u7406\u5316\u5b66\u63cf\u8ff0\u7b26\u548c\u6c28\u57fa\u9178\u7ec4\u6210\uff09\u6784\u5efa\u800c\u6210\u3002\u4e3a\u4e86\u6a21\u62df\u2018\u4ece\u672a\u89c1\u8fc7\u2019\u7684\u5a01\u80c1\uff0c\u7814\u7a76\u8005\u5bf9\u5408\u5e76\u7684\u6570\u636e\u96c6\u8fdb\u884c\u4e86<=40%\u540c\u4e00\u6027\u7684\u540c\u6e90\u805a\u7c7b\uff0c\u5e76\u6267\u884c\u4e86\u805a\u7c7b\u7ea7\u522b\u7684\u4fdd\u7559\uff08\u8bad\u7ec3/\u6d4b\u8bd5\u95f4\u65e0\u805a\u7c7b\u91cd\u53e0\uff09\u3002", "result": "\u968f\u673a\u5212\u5206\u76f8\u5bf9\u4e8e\u540c\u6e90\u805a\u7c7b\u8bc4\u4f30\u663e\u8457\u9ad8\u4f30\u4e86\u7a33\u5065\u6027\uff1b\u7ecf\u8fc7\u6821\u51c6\u540e\u7684\u7ebf\u6027\u6a21\u578b\u663e\u793a\u51fa\u76f8\u5bf9\u8f83\u597d\u7684\u6821\u51c6\u6548\u679c\uff0c\u800c\u6811\u96c6\u6210\u65b9\u6cd5\u4fdd\u6301\u4e86\u7a0d\u9ad8\u7684Brier\u5f97\u5206/ECE\u3002", "conclusion": "SafeBench-Seq\u4e3a\u86cb\u767d\u8d28\u5e8f\u5217\u7ea7\u522b\u7684\u98ce\u9669\u7b5b\u67e5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ec5\u57fa\u4e8eCPU\u3001\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4e25\u683c\u8bc4\u4f30\u800c\u4e0d\u5206\u53d1\u6709\u5bb3\u5e8f\u5217\u3002"}}
{"id": "2512.17531", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17531", "abs": "https://arxiv.org/abs/2512.17531", "authors": ["Salar Beigzad"], "title": "NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks", "comment": "Conference paper, IEEE, 2025", "summary": "The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independently without leveraging collective learning dynamics. This isolation constrains representational coordination and limits convergence efficiency in deeper architectures. This paper introduces Collaborative Forward-Forward (CFF) learning, extending the original algorithm through inter-layer cooperation mechanisms that preserve forward-only computation while enabling global context integration. Our framework implements two collaborative paradigms: Fixed CFF (F-CFF) with constant inter-layer coupling and Adaptive CFF (A-CFF) with learnable collaboration parameters that evolve during training. The collaborative goodness function incorporates weighted contributions from all layers, enabling coordinated feature learning while maintaining memory efficiency and biological plausibility. Comprehensive evaluation on MNIST and Fashion-MNIST demonstrates significant performance improvements over baseline Forward-Forward implementations. These findings establish inter-layer collaboration as a fundamental enhancement to Forward-Forward learning, with immediate applicability to neuromorphic computing architectures and energy-constrained AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u534f\u4f5c\u524d\u5411-\u524d\u5411\uff08CFF\uff09\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c42\u95f4\u5408\u4f5c\u673a\u5236\u6539\u8fdb\u4e86\u539f\u6709\u7684\u524d\u5411-\u524d\u5411\u7b97\u6cd5\uff0c\u589e\u5f3a\u4e86\u8868\u5f81\u534f\u8c03\u6027\u548c\u6536\u655b\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728MNIST\u548cFashion-MNIST\u6570\u636e\u96c6\u4e0a\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u524d\u5411-\u524d\u5411\u5b9e\u73b0\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u524d\u5411-\u524d\u5411\u7b97\u6cd5\u5728\u6df1\u5c42\u67b6\u6784\u4e2d\u56e0\u5c42\u95f4\u9694\u79bb\u800c\u9650\u5236\u4e86\u8868\u793a\u534f\u8c03\u6027\u5e76\u964d\u4f4e\u4e86\u6536\u655b\u6548\u7387\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u4fdd\u6301\u4ec5\u524d\u5411\u8ba1\u7b97\u7684\u540c\u65f6\u5141\u8bb8\u5168\u5c40\u4e0a\u4e0b\u6587\u96c6\u6210\uff0c\u63d0\u51fa\u4e86\u534f\u4f5c\u524d\u5411-\u524d\u5411\uff08CFF\uff09\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u5f15\u5165\u4e86\u4e24\u79cd\u534f\u4f5c\u8303\u5f0f\uff1a\u5177\u6709\u6052\u5b9a\u5c42\u95f4\u8026\u5408\u7684\u56fa\u5b9aCFF\uff08F-CFF\uff09\u548c\u5177\u6709\u53ef\u5b66\u4e60\u534f\u4f5c\u53c2\u6570\u7684\u81ea\u9002\u5e94CFF\uff08A-CFF\uff09\uff0c\u8fd9\u4e9b\u53c2\u6570\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6f14\u5316\u3002\u534f\u4f5c\u826f\u597d\u51fd\u6570\u7ed3\u5408\u4e86\u6240\u6709\u5c42\u7684\u52a0\u6743\u8d21\u732e\uff0c\u4fc3\u8fdb\u4e86\u7279\u5f81\u5b66\u4e60\u7684\u534f\u8c03\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5185\u5b58\u6548\u7387\u548c\u751f\u7269\u5408\u7406\u6027\u3002", "result": "\u5728MNIST\u548cFashion-MNIST\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u57fa\u7840\u7684\u524d\u5411-\u524d\u5411\u5b9e\u73b0\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u5c42\u95f4\u5408\u4f5c\u88ab\u786e\u7acb\u4e3a\u524d\u5411-\u524d\u5411\u5b66\u4e60\u7684\u4e00\u4e2a\u57fa\u672c\u589e\u5f3a\uff0c\u5bf9\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u67b6\u6784\u548c\u80fd\u6e90\u53d7\u9650\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5177\u6709\u76f4\u63a5\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.17569", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.17569", "abs": "https://arxiv.org/abs/2512.17569", "authors": ["Xietao Wang Lin", "Juan Ungredda", "Max Butler", "James Town", "Alma Rahat", "Hemant Singh", "Juergen Branke"], "title": "Bayesian Optimisation: Which Constraints Matter?", "comment": null, "summary": "Bayesian optimisation has proven to be a powerful tool for expensive global black-box optimisation problems. In this paper, we propose new Bayesian optimisation variants of the popular Knowledge Gradient acquisition functions for problems with \\emph{decoupled} black-box constraints, in which subsets of the objective and constraint functions may be evaluated independently. In particular, our methods aim to take into account that often only a handful of the constraints may be binding at the optimum, and hence we should evaluate only relevant constraints when trying to optimise a function. We empirically benchmark these methods against existing methods and demonstrate their superiority over the state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u89e3\u8026\u7684\u9ed1\u7bb1\u7ea6\u675f\u95ee\u9898\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5e76\u4ec5\u8bc4\u4f30\u4e0e\u6700\u4f18\u89e3\u76f8\u5173\u7684\u7ea6\u675f\u6761\u4ef6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5177\u6709\u89e3\u8026\u9ed1\u7bb1\u7ea6\u675f\u7684\u6602\u8d35\u5168\u5c40\u9ed1\u7bb1\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4f18\u5316\u6548\u7387\uff0c\u7279\u522b\u662f\u5f53\u53ea\u6709\u5c11\u6570\u7ea6\u675f\u5728\u6700\u4f18\u89e3\u5904\u662f\u7d27\u7ea6\u675f\u65f6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u53d8\u4f53\uff0c\u57fa\u4e8e\u77e5\u8bc6\u68af\u5ea6\u83b7\u53d6\u51fd\u6570\uff0c\u4e13\u95e8\u9488\u5bf9\u89e3\u8026\u9ed1\u7bb1\u7ea6\u675f\u95ee\u9898\u8bbe\u8ba1\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6280\u672f\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u7406\u89e3\u8026\u9ed1\u7bb1\u7ea6\u675f\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u53ea\u6709\u90e8\u5206\u7ea6\u675f\u5bf9\u6700\u4f18\u89e3\u6709\u5f71\u54cd\u7684\u60c5\u51b5\u4e0b\uff0c\u8868\u73b0\u51fa\u4e86\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u6c34\u5e73\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.17570", "categories": ["cs.LG", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.17570", "abs": "https://arxiv.org/abs/2512.17570", "authors": ["Yikang Yue", "Yishu Yin", "Xuehai Qian"], "title": "GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping", "comment": null, "summary": "SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684SSD\u5378\u8f7d\u8bad\u7ec3\u7cfb\u7edfGreedySnake\uff0c\u91c7\u7528\u5782\u76f4\u8c03\u5ea6\u7b56\u7565\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u541e\u5410\u91cf\u5e76\u51cf\u5c11\u6279\u5904\u7406\u5927\u5c0f\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u5728A100 GPU\u4e0a\u5bf9GPT-65B\u548cGPT-175B\u6a21\u578b\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u76f8\u6bd4ZeRO-Infinity\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bad\u7ec3\u66f4\u5177\u6210\u672c\u6548\u76ca\uff0c\u6587\u7ae0\u57fa\u4e8e\u5fae\u6279\u91cf\u68af\u5ea6\u7d2f\u79ef\u63d0\u51fa\u4e86GreedySnake\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u8c03\u5ea6\u7b56\u7565\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u4e14\u66f4\u63a5\u8fd1\u7406\u60f3\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u9884\u6d4b\u3002", "method": "GreedySnake\u7cfb\u7edf\u91c7\u7528\u4e86\u5782\u76f4\u8c03\u5ea6\u65b9\u6cd5\uff0c\u5373\u5148\u6267\u884c\u5b8c\u4e00\u5c42\u5185\u6240\u6709\u5fae\u6279\u6b21\u540e\u518d\u8fdb\u884c\u4e0b\u4e00\u5c42\uff0c\u4e0e\u6c34\u5e73\u8c03\u5ea6\u65b9\u5f0f\u5f62\u6210\u5bf9\u6bd4\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u91cd\u53e0\u90e8\u5206\u4f18\u5316\u6b65\u9aa4\u4e0e\u4e0b\u4e00\u6b21\u8fed\u4ee3\u7684\u524d\u5411\u4f20\u9012\u6765\u8fdb\u4e00\u6b65\u7f13\u89e3I/O\u74f6\u9888\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f7f\u7528A100 GPUs\u65f6\uff0c\u5bf9\u4e8eGPT-65B\u6a21\u578b\uff0cGreedySnake\u76f8\u8f83\u4e8eZeRO-Infinity\u5b9e\u73b0\u4e86\u5355GPU 1.96\u500d\u30014 GPUs 1.93\u500d\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u589e\u957f\uff1b\u800c\u5bf9\u4e8eGPT-175B\u6a21\u578b\uff0c\u5219\u662f\u5728\u5355GPU\u4e0a\u8fbe\u5230\u4e862.53\u500d\u7684\u589e\u957f\u3002", "conclusion": "GreedySnake\u5c55\u793a\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u589e\u5f3aLLM\u8bad\u7ec3\u8fc7\u7a0b\u6027\u4ef7\u6bd4\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u521b\u65b0\u6027\u7684\u5782\u76f4\u8c03\u5ea6\u673a\u5236\u4ee5\u53ca\u4f18\u5316\u6b65\u9aa4\u95f4\u7684\u91cd\u53e0\u5904\u7406\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u540c\u65f6\u51cf\u5c11\u4e86\u6240\u9700\u7684\u6279\u5904\u7406\u89c4\u6a21\u3002"}}
{"id": "2512.17598", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17598", "abs": "https://arxiv.org/abs/2512.17598", "authors": ["Guner Dilsad Er", "Sebastian Trimpe", "Michael Muehlebach"], "title": "A Systems-Theoretic View on the Convergence of Algorithms under Disturbances", "comment": null, "summary": "Algorithms increasingly operate within complex physical, social, and engineering systems where they are exposed to disturbances, noise, and interconnections with other dynamical systems. This article extends known convergence guarantees of an algorithm operating in isolation (i.e., without disturbances) and systematically derives stability bounds and convergence rates in the presence of such disturbances. By leveraging converse Lyapunov theorems, we derive key inequalities that quantify the impact of disturbances. We further demonstrate how our result can be utilized to assess the effects of disturbances on algorithmic performance in a wide variety of applications, including communication constraints in distributed learning, sensitivity in machine learning generalization, and intentional noise injection for privacy. This underpins the role of our result as a unifying tool for algorithm analysis in the presence of noise, disturbances, and interconnections with other dynamical systems.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u7b97\u6cd5\u5728\u5b64\u7acb\u8fd0\u884c\u65f6\u7684\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u5e76\u63a8\u5bfc\u51fa\u5728\u5b58\u5728\u5e72\u6270\u60c5\u51b5\u4e0b\u7684\u7a33\u5b9a\u6027\u8fb9\u754c\u548c\u6536\u655b\u901f\u5ea6\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5de5\u5177\u6765\u5206\u6790\u5b58\u5728\u566a\u58f0\u3001\u5e72\u6270\u548c\u5176\u4ed6\u52a8\u6001\u7cfb\u7edf\u76f8\u4e92\u4f5c\u7528\u60c5\u51b5\u4e0b\u7684\u7b97\u6cd5\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u7b97\u6cd5\u8d8a\u6765\u8d8a\u591a\u5730\u5728\u590d\u6742\u7684\u7269\u7406\u3001\u793e\u4f1a\u548c\u5de5\u7a0b\u7cfb\u7edf\u4e2d\u8fd0\u884c\uff0c\u5b83\u4eec\u9762\u4e34\u5e72\u6270\u3001\u566a\u58f0\u4ee5\u53ca\u4e0e\u5176\u4ed6\u52a8\u6001\u7cfb\u7edf\u7684\u76f8\u4e92\u8fde\u901a\u7b49\u95ee\u9898\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u8fd9\u4e9b\u5916\u90e8\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u5e76\u4e3a\u7b97\u6cd5\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5229\u7528\u9006\u5411Lyapunov\u5b9a\u7406\uff0c\u7814\u7a76\u4eba\u5458\u5f97\u51fa\u4e86\u91cf\u5316\u5e72\u6270\u5f71\u54cd\u7684\u5173\u952e\u4e0d\u7b49\u5f0f\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5bf9\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u5e72\u6270\u5bf9\u7b97\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6210\u529f\u5730\u63a8\u5bfc\u51fa\u4e86\u5728\u5b58\u5728\u5404\u79cd\u7c7b\u578b\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u754c\u9650\u4e0e\u6536\u655b\u7387\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u591a\u79cd\u60c5\u5883\uff0c\u6bd4\u5982\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u9650\u5236\u3001\u673a\u5668\u5b66\u4e60\u6cdb\u5316\u4e2d\u7684\u654f\u611f\u6027\u95ee\u9898\u53ca\u4e3a\u4e86\u9690\u79c1\u4fdd\u62a4\u800c\u6545\u610f\u52a0\u5165\u7684\u566a\u58f0\u7b49\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u8bba\u6765\u5206\u6790\u7b97\u6cd5\u5728\u9762\u5bf9\u566a\u58f0\u3001\u5e72\u6270\u4ee5\u53ca\u5176\u4ed6\u52a8\u6001\u7cfb\u7edf\u4e92\u52a8\u65f6\u7684\u884c\u4e3a\uff0c\u4e3a\u7406\u89e3\u548c\u6539\u5584\u590d\u6742\u7cfb\u7edf\u5185\u7b97\u6cd5\u7684\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u5de5\u5177\u3002"}}
{"id": "2512.17636", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17636", "abs": "https://arxiv.org/abs/2512.17636", "authors": ["Mingyu Su", "Jian Guan", "Yuxian Gu", "Minlie Huang", "Hongning Wang"], "title": "Trust-Region Adaptive Policy Optimization", "comment": null, "summary": "Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\\textbf{T}rust-\\textbf{R}egion \\textbf{A}daptive \\textbf{P}olicy \\textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u6846\u67b6TRAPO\uff0c\u65e8\u5728\u901a\u8fc7\u4ea4\u9519\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\uff0c\u5728\u6bcf\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\u4e2d\u4f18\u5316\u4e13\u5bb6\u524d\u7f00\u4e0a\u7684SFT\u635f\u5931\u4ee5\u53ca\u6a21\u578b\u81ea\u8eab\u5b8c\u6210\u90e8\u5206\u7684RL\u635f\u5931\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTRAPO\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u4f18\u4e8e\u6807\u51c6\u65b9\u6cd5\u548c\u5176\u4ed6\u6700\u65b0\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u4e24\u9636\u6bb5\u7ba1\u9053\uff08\u5148\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u518d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff09\u5b58\u5728\u5173\u952e\u4e0d\u4e00\u81f4\u95ee\u9898\uff1a\u76d1\u7763\u5fae\u8c03\u9650\u5236\u4e86\u63a2\u7d22\u5e76\u5bfc\u81f4\u9057\u5fd8\uff0c\u8fd9\u524a\u5f31\u4e86\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u6548\u679c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u4f4e\u6548\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86TRAPO\u6846\u67b6\u3002", "method": "TRAPO\u662f\u4e00\u79cd\u5c06\u76d1\u7763\u5fae\u8c03\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5728\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u4e2d\u540c\u65f6\u4f18\u5316\u76d1\u7763\u5fae\u8c03\u635f\u5931\uff08\u57fa\u4e8e\u4e13\u5bb6\u63d0\u4f9b\u7684\u524d\u7f00\uff09\u548c\u5f3a\u5316\u5b66\u4e60\u635f\u5931\uff08\u57fa\u4e8e\u6a21\u578b\u751f\u6210\u7684\u90e8\u5206\uff09\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u8fd8\u5f15\u5165\u4e86\u4fe1\u4efb\u533a\u57df\u76d1\u7763\u5fae\u8c03(TrSFT)\uff0c\u5b83\u5728\u4fe1\u4efb\u533a\u57df\u5185\u6700\u5c0f\u5316\u6b63\u5411KL\u6563\u5ea6\uff0c\u4f46\u5728\u8be5\u533a\u57df\u5916\u51cf\u5f31\u4f18\u5316\u529b\u5ea6\uff0c\u6709\u6548\u5730\u8f6c\u5411\u53cd\u5411KL\u6563\u5ea6\uff0c\u4ea7\u751f\u6709\u5229\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7a33\u5b9a\u66f4\u65b0\u3002\u4e00\u4e2a\u81ea\u9002\u5e94\u524d\u7f00\u9009\u62e9\u673a\u5236\u8fdb\u4e00\u6b65\u6839\u636e\u6d4b\u91cf\u5230\u7684\u6709\u6548\u6027\u5206\u914d\u4e13\u5bb6\u6307\u5bfc\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTRAPO\u7684\u8868\u73b0\u4e0d\u4ec5\u4f18\u4e8e\u4f20\u7edf\u7684\u76d1\u7763\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u4ee5\u53ca\u76d1\u7763\u5fae\u8c03\u540e\u63a5\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e5f\u8d85\u8d8a\u4e86\u4e00\u4e9b\u6700\u65b0\u7684\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "TRAPO\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u76d1\u7763\u4e0e\u81ea\u6211\u63a2\u7d22\u7684\u4f18\u52bf\uff0c\u4e3a\u6539\u5584\u6a21\u578b\u6027\u80fd\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2512.17671", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.17671", "abs": "https://arxiv.org/abs/2512.17671", "authors": ["Yuriy N. Bakhvalov"], "title": "Polyharmonic Cascade", "comment": "Part 3 of 4 in the \"Polyharmonic Cascade\" cycle. Proposes a non-SGD training method based on global linear solvers. Previous papers: arXiv:2512.12731, arXiv.2512.16718. Source code is available at: https://github.com/xolod7/polyharmonic-cascade", "summary": "This paper presents a deep machine learning architecture, the \"polyharmonic cascade\" -- a sequence of packages of polyharmonic splines, where each layer is rigorously derived from the theory of random functions and the principles of indifference. This makes it possible to approximate nonlinear functions of arbitrary complexity while preserving global smoothness and a probabilistic interpretation. For the polyharmonic cascade, a training method alternative to gradient descent is proposed: instead of directly optimizing the coefficients, one solves a single global linear system on each batch with respect to the function values at fixed \"constellations\" of nodes. This yields synchronized updates of all layers, preserves the probabilistic interpretation of individual layers and theoretical consistency with the original model, and scales well: all computations reduce to 2D matrix operations efficiently executed on a GPU. Fast learning without overfitting on MNIST is demonstrated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u673a\u5668\u5b66\u4e60\u67b6\u6784\u2014\u2014'\u591a\u8c03\u548c\u7ea7\u8054'\uff0c\u5b83\u80fd\u591f\u8fd1\u4f3c\u4efb\u610f\u590d\u6742\u5ea6\u7684\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u5e76\u4fdd\u6301\u5168\u5c40\u5e73\u6ed1\u6027\u548c\u6982\u7387\u89e3\u91ca\u3002\u4e0e\u4f20\u7edf\u7684\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u65b9\u6cd5\u4e0d\u540c\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u89e3\u51b3\u6bcf\u4e2a\u6279\u6b21\u4e0a\u7684\u5355\u4e2a\u5168\u5c40\u7ebf\u6027\u7cfb\u7edf\u6765\u66f4\u65b0\u6240\u6709\u5c42\uff0c\u4ece\u800c\u540c\u6b65\u66f4\u65b0\u6240\u6709\u5c42\uff0c\u540c\u65f6\u4fdd\u6301\u5404\u5c42\u7684\u6982\u7387\u89e3\u91ca\u548c\u7406\u8bba\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728MNIST\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u5feb\u901f\u5b66\u4e60\u4e14\u4e0d\u8fc7\u62df\u5408\u3002", "motivation": "\u4e3a\u4e86\u80fd\u591f\u8fd1\u4f3c\u4efb\u610f\u590d\u6742\u5ea6\u7684\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u8fd9\u4e9b\u51fd\u6570\u7684\u5168\u5c40\u5e73\u6ed1\u7279\u6027\u548c\u63d0\u4f9b\u4e00\u4e2a\u6982\u7387\u89e3\u91ca\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u591a\u8c03\u548c\u7ea7\u8054\u8fd9\u4e00\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u9488\u5bf9\u8fd9\u79cd\u65b0\u578b\u67b6\u6784\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4e0d\u540c\u4e8e\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u6cd5\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u7684\u540c\u65f6\u907f\u514d\u8fc7\u62df\u5408\u73b0\u8c61\u3002", "method": "\u591a\u8c03\u548c\u7ea7\u8054\u662f\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u51fd\u6570\u7406\u8bba\u53ca\u65e0\u5dee\u522b\u539f\u5219\u4e25\u683c\u63a8\u5bfc\u800c\u6765\u7684\u6df1\u5c42\u7ed3\u6784\uff0c\u7531\u4e00\u7cfb\u5217\u591a\u8c03\u548c\u6837\u6761\u5305\u7ec4\u6210\u3002\u5bf9\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u66ff\u4ee3\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\uff1a\u4e0d\u662f\u76f4\u63a5\u4f18\u5316\u7cfb\u6570\uff0c\u800c\u662f\u9488\u5bf9\u56fa\u5b9a\u8282\u70b9'\u661f\u5ea7'\u5904\u7684\u51fd\u6570\u503c\uff0c\u5728\u6bcf\u6279\u6837\u672c\u4e0a\u6c42\u89e3\u4e00\u4e2a\u5168\u5c40\u7ebf\u6027\u7cfb\u7edf\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u6240\u6709\u5c42\u7ea7\u540c\u6b65\u66f4\u65b0\uff0c\u4fdd\u7559\u4e86\u4e2a\u4f53\u5c42\u7684\u6982\u7387\u89e3\u91ca\u4ee5\u53ca\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u7406\u8bba\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f7f\u7528\u63d0\u51fa\u7684\u591a\u8c03\u548c\u7ea7\u8054\u67b6\u6784\u53ca\u76f8\u5e94\u8bad\u7ec3\u65b9\u6cd5\u540e\uff0c\u80fd\u591f\u5728MNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5feb\u901f\u5b66\u4e60\uff0c\u5e76\u4e14\u6ca1\u6709\u51fa\u73b0\u8fc7\u62df\u5408\u7684\u73b0\u8c61\u3002", "conclusion": "\u591a\u8c03\u548c\u7ea7\u8054\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u903c\u8fd1\u4efb\u610f\u590d\u6742\u7684\u975e\u7ebf\u6027\u51fd\u6570\uff0c\u800c\u4e14\u901a\u8fc7\u5176\u72ec\u7279\u7684\u8bad\u7ec3\u673a\u5236\uff0c\u786e\u4fdd\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2512.17678", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17678", "abs": "https://arxiv.org/abs/2512.17678", "authors": ["Daphn\u00e9 Chopard", "Jorge da Silva Gon\u00e7alves", "Irene Cannistraci", "Thomas M. Sutter", "Julia E. Vogt"], "title": "You Only Train Once: Differentiable Subset Selection for Omics Data", "comment": null, "summary": "Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aYOTO\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u8bc6\u522b\u79bb\u6563\u57fa\u56e0\u5b50\u96c6\u5e76\u8fdb\u884c\u9884\u6d4b\uff0c\u901a\u8fc7\u7a00\u758f\u6027\u5f3a\u5236\u6267\u884c\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u8bbe\u8ba1\uff0c\u4f7f\u5f97\u6240\u9009\u57fa\u56e0\u76f4\u63a5\u53c2\u4e0e\u63a8\u65ad\uff0c\u5e76\u4e14\u5728\u76f8\u5173\u76ee\u6807\u4e4b\u95f4\u5b66\u4e60\u5171\u4eab\u8868\u793a\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u4fc3\u8fdb\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3002", "motivation": "\u4ece\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u6570\u636e\u4e2d\u9009\u62e9\u7d27\u51d1\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u57fa\u56e0\u5b50\u96c6\u5bf9\u4e8e\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3001\u63d0\u9ad8\u89e3\u91ca\u6027\u548c\u6210\u672c\u6548\u76ca\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u8981\u4e48\u4f5c\u4e3a\u591a\u9636\u6bb5\u7ba1\u9053\u8fd0\u884c\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u4e8b\u540e\u7279\u5f81\u5f52\u56e0\uff0c\u8fd9\u5bfc\u81f4\u9009\u62e9\u4e0e\u9884\u6d4b\u4e4b\u95f4\u7684\u8054\u7cfb\u8f83\u5f31\u3002", "method": "YOTO\uff08you only train once\uff09\u662f\u4e00\u79cd\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5728\u5355\u4e00\u53ef\u5fae\u67b6\u6784\u5185\u8054\u5408\u8bc6\u522b\u79bb\u6563\u57fa\u56e0\u5b50\u96c6\u5e76\u6267\u884c\u9884\u6d4b\u4efb\u52a1\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u9884\u6d4b\u4efb\u52a1\u76f4\u63a5\u6307\u5bfc\u54ea\u4e9b\u57fa\u56e0\u88ab\u9009\u62e9\uff0c\u800c\u6240\u5b66\u5f97\u7684\u5b50\u96c6\u53cd\u8fc7\u6765\u5851\u9020\u9884\u6d4b\u8868\u793a\u3002\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u8bbe\u8ba1\uff0c\u6a21\u578b\u80fd\u591f\u5728\u76f8\u5173\u76ee\u6807\u95f4\u5b66\u4e60\u5171\u4eab\u8868\u793a\uff0c\u5141\u8bb8\u90e8\u5206\u6807\u8bb0\u7684\u6570\u636e\u96c6\u76f8\u4e92\u63d0\u4f9b\u4fe1\u606f\uff0c\u5e76\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6b65\u9aa4\u5373\u53ef\u8de8\u4efb\u52a1\u53d1\u73b0\u901a\u7528\u57fa\u56e0\u5b50\u96c6\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u4e2a\u4ee3\u8868\u6027\u7684\u5355\u7ec6\u80deRNA-seq\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aYOTO\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u7a00\u758f\u6027\u3001\u7aef\u5230\u7aef\u53ca\u591a\u4efb\u52a1\u57fa\u56e0\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u4ea7\u751f\u4e86\u7d27\u51d1\u4e14\u6709\u610f\u4e49\u7684\u57fa\u56e0\u5b50\u96c6\uff0c\u4fc3\u8fdb\u4e86\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u548c\u5355\u7ec6\u80de\u5206\u6790\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2512.17720", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17720", "abs": "https://arxiv.org/abs/2512.17720", "authors": ["Joanna Sliwa", "Frank Schneider", "Philipp Hennig", "Jose Miguel Hernandez-Lobato"], "title": "Mitigating Forgetting in Low Rank Adaptation", "comment": null, "summary": "Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), enable fast specialization of large pre-trained models to different downstream applications. However, this process often leads to catastrophic forgetting of the model's prior domain knowledge. We address this issue with LaLoRA, a weight-space regularization technique that applies a Laplace approximation to Low-Rank Adaptation. Our approach estimates the model's confidence in each parameter and constrains updates in high-curvature directions, preserving prior knowledge while enabling efficient target-domain learning. By applying the Laplace approximation only to the LoRA weights, the method remains lightweight. We evaluate LaLoRA by fine-tuning a Llama model for mathematical reasoning and demonstrate an improved learning-forgetting trade-off, which can be directly controlled via the method's regularization strength. We further explore different loss landscape curvature approximations for estimating parameter confidence, analyze the effect of the data used for the Laplace approximation, and study robustness across hyperparameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLaLoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6743\u91cd\u4e0a\u5e94\u7528\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u6765\u89e3\u51b3\u6a21\u578b\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4f30\u8ba1\u6bcf\u4e2a\u53c2\u6570\u7684\u4fe1\u5fc3\uff0c\u5e76\u9650\u5236\u9ad8\u66f2\u7387\u65b9\u5411\u4e0a\u7684\u66f4\u65b0\uff0c\u4ece\u800c\u4fdd\u6301\u5148\u524d\u77e5\u8bc6\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u7684\u76ee\u6807\u9886\u57df\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLaLoRA\u80fd\u591f\u6539\u5584\u5b66\u4e60-\u9057\u5fd8\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u6b63\u5219\u5316\u5f3a\u5ea6\u76f4\u63a5\u63a7\u5236\u8fd9\u4e00\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524d\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5982\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\uff0c\u867d\u7136\u53ef\u4ee5\u5feb\u901f\u5730\u5c06\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7279\u5316\u5230\u4e0d\u540c\u7684\u4e0b\u6e38\u5e94\u7528\u4e2d\uff0c\u4f46\u5f80\u5f80\u4f1a\u5f15\u53d1\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5373\u6a21\u578b\u4f1a\u5fd8\u8bb0\u4e4b\u524d\u5b66\u5230\u7684\u91cd\u8981\u9886\u57df\u77e5\u8bc6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LaLoRA\u65b9\u6cd5\u3002", "method": "LaLoRA\u662f\u4e00\u79cd\u6743\u91cd\u7a7a\u95f4\u6b63\u5219\u5316\u6280\u672f\uff0c\u5b83\u5bf9Low-Rank Adaptation (LoRA) \u6743\u91cd\u5e94\u7528\u4e86\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f30\u8ba1\u4e86\u6a21\u578b\u5bf9\u4e8e\u6bcf\u4e2a\u53c2\u6570\u7684\u4fe1\u5fc3\u6c34\u5e73\uff0c\u5e76\u9650\u5236\u4e86\u5728\u9ad8\u66f2\u7387\u65b9\u5411\u4e0a\u7684\u66f4\u65b0\uff0c\u4ee5\u4fdd\u6301\u6a21\u578b\u4e4b\u524d\u7684\u9886\u57df\u77e5\u8bc6\u540c\u65f6\u5141\u8bb8\u6709\u6548\u7684\u76ee\u6807\u57df\u5b66\u4e60\u3002\u901a\u8fc7\u5bf9\u4ec5LoRA\u6743\u91cd\u5e94\u7528\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\uff0c\u4fdd\u8bc1\u4e86\u65b9\u6cd5\u7684\u8f7b\u91cf\u7ea7\u7279\u6027\u3002", "result": "\u7814\u7a76\u8005\u4eec\u901a\u8fc7\u5fae\u8c03\u4e00\u4e2aLlama\u6a21\u578b\u6765\u8fdb\u884c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\uff0c\u5c55\u793a\u4e86LaLoRA\u80fd\u591f\u5728\u5b66\u4e60\u4e0e\u9057\u5fd8\u4e4b\u95f4\u63d0\u4f9b\u66f4\u597d\u7684\u5e73\u8861\uff0c\u5e76\u4e14\u8fd9\u79cd\u5e73\u8861\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u65b9\u6cd5\u4e2d\u7684\u6b63\u5219\u5316\u5f3a\u5ea6\u76f4\u63a5\u63a7\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u4e0d\u540c\u635f\u5931\u666f\u89c2\u66f2\u7387\u903c\u8fd1\u65b9\u5f0f\u5bf9\u53c2\u6570\u4fe1\u5fc3\u4f30\u8ba1\u7684\u5f71\u54cd\u3001\u7528\u4e8e\u62c9\u666e\u62c9\u65af\u903c\u8fd1\u7684\u6570\u636e\u6548\u679c\u4ee5\u53ca\u8d85\u53c2\u6570\u7a33\u5065\u6027\u7684\u7814\u7a76\u3002", "conclusion": "LaLoRA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5728\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65f6\u9047\u5230\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002\u901a\u8fc7\u5408\u7406\u8bbe\u7f6e\u6b63\u5219\u5316\u5f3a\u5ea6\uff0c\u53ef\u4ee5\u5728\u4fdd\u7559\u539f\u6709\u77e5\u8bc6\u7684\u57fa\u7840\u4e0a\u5b9e\u73b0\u65b0\u9886\u57df\u7684\u9ad8\u6548\u5b66\u4e60\u3002"}}
{"id": "2512.17788", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17788", "abs": "https://arxiv.org/abs/2512.17788", "authors": ["Wei Tang", "Yin-Fang Yang", "Weijia Zhang", "Min-Ling Zhang"], "title": "Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning", "comment": null, "summary": "Multi-instance partial-label learning (MIPL) is a weakly supervised framework that extends the principles of multi-instance learning (MIL) and partial-label learning (PLL) to address the challenges of inexact supervision in both instance and label spaces. However, existing MIPL approaches often suffer from poor calibration, undermining classifier reliability. In this work, we propose a plug-and-play calibratable disambiguation loss (CDL) that simultaneously improves classification accuracy and calibration performance. The loss has two instantiations: the first one calibrates predictions based on probabilities from the candidate label set, while the second one integrates probabilities from both candidate and non-candidate label sets. The proposed CDL can be seamlessly incorporated into existing MIPL and PLL frameworks. We provide a theoretical analysis that establishes the lower bound and regularization properties of CDL, demonstrating its superiority over conventional disambiguation losses. Experimental results on benchmark and real-world datasets confirm that our CDL significantly enhances both classification and calibration performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6821\u51c6\u7684\u89e3\u6b67\u635f\u5931\uff08CDL\uff09\uff0c\u53ef\u4ee5\u540c\u65f6\u63d0\u9ad8\u591a\u5b9e\u4f8b\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\uff08MIPL\uff09\u4e2d\u7684\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u5b9e\u4f8b\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u65b9\u6cd5\u7ecf\u5e38\u5b58\u5728\u6821\u51c6\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u635f\u5bb3\u5206\u7c7b\u5668\u7684\u53ef\u9760\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u53ef\u6821\u51c6\u89e3\u6b67\u635f\u5931\uff08CDL\uff09\uff0c\u8be5\u635f\u5931\u6709\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\uff1a\u4e00\u79cd\u57fa\u4e8e\u5019\u9009\u6807\u7b7e\u96c6\u7684\u6982\u7387\u6765\u6821\u51c6\u9884\u6d4b\uff0c\u53e6\u4e00\u79cd\u5219\u7ed3\u5408\u4e86\u5019\u9009\u548c\u975e\u5019\u9009\u6807\u7b7e\u96c6\u7684\u6982\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u89e3\u6b67\u635f\u5931\u76f8\u6bd4\uff0cCDL\u5177\u6709\u66f4\u597d\u7684\u4e0b\u754c\u548c\u6b63\u5219\u5316\u7279\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cCDL\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u548c\u6821\u51c6\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684CDL\u80fd\u6709\u6548\u63d0\u5347MIPL\u6846\u67b6\u4e0b\u7684\u5206\u7c7b\u51c6\u786e\u7387\u548c\u6821\u51c6\u8868\u73b0\uff0c\u5e76\u4e14\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684MIPL\u548cPLL\u6846\u67b6\u4e2d\u3002"}}
{"id": "2512.17820", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17820", "abs": "https://arxiv.org/abs/2512.17820", "authors": ["Liam Collins", "Bhuvesh Kumar", "Clark Mingxuan Ju", "Tong Zhao", "Donald Loveland", "Leonardo Neves", "Neil Shah"], "title": "Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation", "comment": null, "summary": "Modern Sequential Recommendation (SR) models commonly utilize modality features to represent items, motivated in large part by recent advancements in language and vision modeling. To do so, several works completely replace ID embeddings with modality embeddings, claiming that modality embeddings render ID embeddings unnecessary because they can match or even exceed ID embedding performance. On the other hand, many works jointly utilize ID and modality features, but posit that complex fusion strategies, such as multi-stage training and/or intricate alignment architectures, are necessary for this joint utilization. However, underlying both these lines of work is a lack of understanding of the complementarity of ID and modality features. In this work, we address this gap by studying the complementarity of ID- and text-based SR models. We show that these models do learn complementary signals, meaning that either should provide performance gain when used properly alongside the other. Motivated by this, we propose a new SR method that preserves ID-text complementarity through independent model training, then harnesses it through a simple ensembling strategy. Despite this method's simplicity, we show it outperforms several competitive SR baselines, implying that both ID and text features are necessary to achieve state-of-the-art SR performance but complex fusion architectures are not.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86ID\u548c\u57fa\u4e8e\u6587\u672c\u7684\u5e8f\u5217\u63a8\u8350\uff08SR\uff09\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u8865\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684SR\u65b9\u6cd5\uff0c\u901a\u8fc7\u72ec\u7acb\u8bad\u7ec3\u6a21\u578b\u6765\u4fdd\u6301\u8fd9\u79cd\u4e92\u8865\u6027\uff0c\u7136\u540e\u901a\u8fc7\u7b80\u5355\u7684\u96c6\u6210\u7b56\u7565\u52a0\u4ee5\u5229\u7528\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u8fd9\u79cd\u65b9\u6cd5\u7b80\u5355\uff0c\u4f46\u5b83\u8d85\u8d8a\u4e86\u591a\u4e2a\u7ade\u4e89\u6027\u7684SR\u57fa\u7ebf\uff0c\u8868\u660e\u8981\u8fbe\u5230\u6700\u5148\u8fdb\u7684SR\u6027\u80fd\u9700\u8981\u540c\u65f6\u4f7f\u7528ID\u548c\u6587\u672c\u7279\u5f81\uff0c\u4f46\u4e0d\u9700\u8981\u590d\u6742\u7684\u878d\u5408\u67b6\u6784\u3002", "motivation": "\u76ee\u524d\u7684\u5e8f\u5217\u63a8\u8350\uff08SR\uff09\u6a21\u578b\u503e\u5411\u4e8e\u7528\u6a21\u6001\u7279\u5f81\u6765\u8868\u793a\u9879\u76ee\uff0c\u90e8\u5206\u539f\u56e0\u662f\u8bed\u8a00\u548c\u89c6\u89c9\u5efa\u6a21\u7684\u6700\u65b0\u8fdb\u5c55\u3002\u4e00\u4e9b\u5de5\u4f5c\u5b8c\u5168\u7528\u6a21\u6001\u5d4c\u5165\u66ff\u6362ID\u5d4c\u5165\uff0c\u58f0\u79f0\u6a21\u6001\u5d4c\u5165\u4f7f\u5f97ID\u5d4c\u5165\u53d8\u5f97\u4e0d\u5fc5\u8981\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u4ee5\u5339\u914d\u751a\u81f3\u8d85\u8fc7ID\u5d4c\u5165\u7684\u8868\u73b0\u3002\u7136\u800c\uff0c\u5bf9\u4e8eID\u4e0e\u6a21\u6001\u7279\u5f81\u4e4b\u95f4\u4e92\u8865\u6027\u7684\u7406\u89e3\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f5c\u8005\u7814\u7a76\u4e86ID-\u548c\u57fa\u4e8e\u6587\u672c\u7684SR\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u8865\u6027\uff0c\u8bc1\u660e\u8fd9\u4e24\u79cd\u6a21\u578b\u786e\u5b9e\u5b66\u4e60\u5230\u4e86\u4e92\u8865\u4fe1\u53f7\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684SR\u65b9\u6cd5\uff0c\u901a\u8fc7\u72ec\u7acb\u6a21\u578b\u8bad\u7ec3\u4fdd\u7559ID-\u6587\u672c\u4e92\u8865\u6027\uff0c\u518d\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u96c6\u6210\u7b56\u7565\u6765\u5229\u7528\u5b83\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u867d\u7136\u7b80\u5355\uff0c\u4f46\u5728\u51e0\u4e2a\u6709\u7ade\u4e89\u529b\u7684SR\u57fa\u7ebf\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u663e\u793a\u51fa\u5f53\u6070\u5f53\u5730\u7ed3\u5408\u4f7f\u7528\u65f6\uff0cID\u548c\u6587\u672c\u7279\u5f81\u90fd\u80fd\u63d0\u4f9b\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u4e3a\u4e86\u5b9e\u73b0\u6700\u4f73\u7684\u5e8f\u5217\u63a8\u8350\u6027\u80fd\uff0c\u65e2\u9700\u8981ID\u4e5f\u9700\u8981\u6587\u672c\u7279\u5f81\uff0c\u4f46\u5e76\u4e0d\u4e00\u5b9a\u9700\u8981\u590d\u6742\u7684\u878d\u5408\u67b6\u6784\u3002"}}
{"id": "2512.17878", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17878", "abs": "https://arxiv.org/abs/2512.17878", "authors": ["Herlock Rahimi"], "title": "Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow", "comment": "26 pages, 1 figure", "summary": "Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.\n  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8eWasserstein-Fisher-Rao (WFR)\u51e0\u4f55\u7684\u91cd\u52a0\u6743\u673a\u5236\uff0c\u901a\u8fc7\u5f15\u5165\u663e\u5f0f\u7684\u4fee\u6b63\u9879\u548c\u4f7f\u7528Feynman-Kac\u8868\u793a\u6cd5\u5b9e\u73b0\u8fd9\u4e9b\u673a\u5236\uff0c\u4ee5\u6539\u8fdb\u5f97\u5206\u57fa\u6269\u6563\u6a21\u578b\u5728\u975e\u5bf9\u6570\u51f9\u76ee\u6807\u5206\u5e03\u60c5\u51b5\u4e0b\u7684\u91c7\u6837\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5f97\u5206\u7684\u6269\u6563\u6a21\u578b\u5728\u8fde\u7eed\u751f\u6210\u5efa\u6a21\u4e2d\u5904\u4e8e\u9886\u5148\u5730\u4f4d\uff0c\u4f46\u5b83\u4eec\u5bf9\u4e8e\u975e\u51f8\u6216\u591a\u6a21\u5f0f\u666f\u89c2\u7684\u6df7\u5408\u7387\u4f1a\u6025\u5267\u4e0b\u964d\u3002\u9274\u4e8e\u8bb8\u591a\u5b9e\u9645\u751f\u6210\u5efa\u6a21\u4efb\u52a1\u6d89\u53ca\u9ad8\u5ea6\u975e\u5bf9\u6570\u51f9\u7684\u76ee\u6807\u5206\u5e03\uff0c\u6700\u8fd1\u7684\u52aa\u529b\u96c6\u4e2d\u5728\u5f00\u53d1\u80fd\u591f\u8d85\u8d8a\u7ecf\u5178\u6269\u6563\u52a8\u529b\u5b66\u63a2\u7d22\u80fd\u529b\u7684\u91c7\u6837\u65b9\u6848\u4e0a\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4fe1\u606f\u51e0\u4f55\u5de5\u5177\u589e\u5f3a\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u5165\u63a7\u5236\u8d28\u91cf\u91cd\u52a0\u6743\u673a\u5236\uff0c\u5e76\u4e14\u8fd9\u79cd\u89c6\u89d2\u81ea\u7136\u5730\u5bfc\u81f4\u4e86Wasserstein-Fisher-Rao (WFR)\u51e0\u4f55\u7684\u5e94\u7528\u3002\u901a\u8fc7\u5f15\u5165\u660e\u786e\u7684\u6821\u6b63\u9879\u6765\u5236\u5b9a\u8fd9\u79cd\u91cd\u52a0\u6743\u673a\u5236\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u52a0\u6743\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08\u91c7\u7528Feynman-Kac\u8868\u793a\uff09\u6765\u5b9e\u73b0\u8fd9\u4e9b\u673a\u5236\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cWFR\u57fa\u7840\u4e0a\u7684\u91c7\u6837\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u4e00\u79cd\u521d\u6b65\u4f46\u4e25\u683c\u7684\u8c03\u67e5\uff0c\u9610\u660e\u4e86\u5176\u51e0\u4f55\u7ed3\u6784\u548c\u7b97\u5b50\u7406\u8bba\u7ed3\u6784\uff0c\u4e3a\u672a\u6765\u7684\u7406\u8bba\u548c\u7b97\u6cd5\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u4e0e\u5e94\u7528WFR\u51e0\u4f55\u4e8e\u6539\u5584\u590d\u6742\u76ee\u6807\u5206\u5e03\u4e0b\u7684\u91c7\u6837\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u548c\u6280\u672f\u9014\u5f84\uff0c\u6307\u51fa\u4e86\u672a\u6765\u5728\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u8bbe\u8ba1\u4e0a\u7684\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2512.17884", "categories": ["cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.17884", "abs": "https://arxiv.org/abs/2512.17884", "authors": ["Xinyue Yu", "Hayden Schaeffer"], "title": "Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space", "comment": null, "summary": "Operator learning is a data-driven approximation of mappings between infinite-dimensional function spaces, such as the solution operators of partial differential equations. Kernel-based operator learning can offer accurate, theoretically justified approximations that require less training than standard methods. However, they can become computationally prohibitive for large training sets and can be sensitive to noise. We propose a regularized random Fourier feature (RRFF) approach, coupled with a finite element reconstruction map (RRFF-FEM), for learning operators from noisy data. The method uses random features drawn from multivariate Student's $t$ distributions, together with frequency-weighted Tikhonov regularization that suppresses high-frequency noise. We establish high-probability bounds on the extreme singular values of the associated random feature matrix and show that when the number of features $N$ scales like $m \\log m$ with the number of training samples $m$, the system is well-conditioned, which yields estimation and generalization guarantees. Detailed numerical experiments on benchmark PDE problems, including advection, Burgers', Darcy flow, Helmholtz, Navier-Stokes, and structural mechanics, demonstrate that RRFF and RRFF-FEM are robust to noise and achieve improved performance with reduced training time compared to the unregularized random feature model, while maintaining competitive accuracy relative to kernel and neural operator tests.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6b63\u5219\u5316\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RRFF\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u6709\u9650\u5143\u91cd\u6784\u6620\u5c04\uff08RRFF-FEM\uff09\uff0c\u7528\u4e8e\u4ece\u566a\u58f0\u6570\u636e\u4e2d\u5b66\u4e60\u7b97\u5b50\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u4ece\u591a\u53d8\u91cf\u5b66\u751ft\u5206\u5e03\u62bd\u53d6\u7684\u968f\u673a\u7279\u5f81\uff0c\u5e76\u91c7\u7528\u9891\u7387\u52a0\u6743Tikhonov\u6b63\u5219\u5316\u6765\u6291\u5236\u9ad8\u9891\u566a\u58f0\u3002\u901a\u8fc7\u57fa\u51c6\u504f\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\u7684\u8be6\u7ec6\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u672a\u6b63\u5219\u5316\u7684\u968f\u673a\u7279\u5f81\u6a21\u578b\u76f8\u6bd4\uff0cRRFF\u548cRRFF-FEM\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5bf9\u5185\u6838\u548c\u795e\u7ecf\u7b97\u5b50\u6d4b\u8bd5\u7684\u7ade\u4e89\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u6838\u7684\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u63d0\u4f9b\u51c6\u786e\u4e14\u7406\u8bba\u4e0a\u6709\u636e\u53ef\u4f9d\u7684\u903c\u8fd1\uff0c\u4f46\u5f53\u8bad\u7ec3\u96c6\u8f83\u5927\u65f6\u53ef\u80fd\u4f1a\u53d8\u5f97\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u5e76\u4e14\u5bf9\u4e8e\u566a\u58f0\u654f\u611f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u8fd0\u7b97\u6548\u7387\u540c\u65f6\u964d\u4f4e\u5bf9\u566a\u58f0\u7684\u654f\u611f\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u5316\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RRFF\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5176\u4e2d\u968f\u673a\u7279\u5f81\u662f\u4ece\u591a\u53d8\u91cf\u5b66\u751ft\u5206\u5e03\u4e2d\u62bd\u53d6\u7684\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u9891\u7387\u52a0\u6743Tikhonov\u6b63\u5219\u5316\u6280\u672f\u4ee5\u51cf\u8f7b\u9ad8\u9891\u7387\u566a\u58f0\u7684\u5f71\u54cd\u3002\u6b64\u65b9\u6cd5\u8fdb\u4e00\u6b65\u7ed3\u5408\u4e86\u6709\u9650\u5143\u91cd\u6784\u6620\u5c04\uff08FEM\uff09\uff0c\u5f62\u6210RRFF-FEM\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u57fa\u51c6\u504f\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\uff0cRRFF\u548cRRFF-FEM\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u62b5\u6297\u566a\u58f0\u5e72\u6270\uff0c\u800c\u4e14\u76f8\u8f83\u4e8e\u672a\u7ecf\u6b63\u5219\u5316\u7684\u968f\u673a\u7279\u5f81\u6a21\u578b\u800c\u8a00\uff0c\u5728\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u7684\u540c\u65f6\u8fd8\u80fd\u7ef4\u6301\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684RRFF\u53caRRFF-FEM\u65b9\u6cd5\u5c55\u793a\u4e86\u826f\u597d\u7684\u566a\u58f0\u9c81\u68d2\u6027\u548c\u9ad8\u6548\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u6216\u542b\u566a\u6570\u636e\u4e0b\u7684\u7b97\u5b50\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
