<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 10]
- [cs.MM](#cs.MM) [Total: 1]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Investigating the Association Between Text-Based Indications of Foodborne Illness from Yelp Reviews and New York City Health Inspection Outcomes (2023)](https://arxiv.org/abs/2510.16334)
*Eden Shaveet,Crystal Su,Daniel Hsu,Luis Gravano*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Foodborne illnesses are gastrointestinal conditions caused by consuming
contaminated food. Restaurants are critical venues to investigate outbreaks
because they share sourcing, preparation, and distribution of foods. Public
reporting of illness via formal channels is limited, whereas social media
platforms host abundant user-generated content that can provide timely public
health signals. This paper analyzes signals from Yelp reviews produced by a
Hierarchical Sigmoid Attention Network (HSAN) classifier and compares them with
official restaurant inspection outcomes issued by the New York City Department
of Health and Mental Hygiene (NYC DOHMH) in 2023. We evaluate correlations at
the Census tract level, compare distributions of HSAN scores by prevalence of
C-graded restaurants, and map spatial patterns across NYC. We find minimal
correlation between HSAN signals and inspection scores at the tract level and
no significant differences by number of C-graded restaurants. We discuss
implications and outline next steps toward address-level analyses.

</details>


### [2] [Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades](https://arxiv.org/abs/2510.16393)
*Franco Maria Nardini,Raffaele Perego,Nicola Tonellotto,Salvatore Trani*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the exploitation of both lexical and neural relevance signals
for ad-hoc passage retrieval. Our exploration involves a large-scale training
dataset in which dense neural representations of MS-MARCO queries and passages
are complemented and integrated with 253 hand-crafted lexical features
extracted from the same corpus. Blending of the relevance signals from the two
different groups of features is learned by a classical Learning-to-Rank (LTR)
model based on a forest of decision trees. To evaluate our solution, we employ
a pipelined architecture where a dense neural retriever serves as the first
stage and performs a nearest-neighbor search over the neural representations of
the documents. Our LTR model acts instead as the second stage that re-ranks the
set of candidates retrieved by the first stage to enhance effectiveness. The
results of reproducible experiments conducted with state-of-the-art dense
retrievers on publicly available resources show that the proposed solution
significantly enhances the end-to-end ranking performance while relatively
minimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of
up to 11% with an increase in average query latency of only 4.3%. This confirms
the advantage of seamlessly combining two distinct families of signals that
mutually contribute to retrieval effectiveness.

</details>


### [3] [FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation](https://arxiv.org/abs/2510.16597)
*Qiyao Peng,Chen Wang,Yinghui Wang,Hongtao Liu,Xuan Guo,Wenjun Wang*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reviewer recommendation is a critical task for enhancing the efficiency of
academic publishing workflows. However, research in this area has been
persistently hindered by the lack of high-quality benchmark datasets, which are
often limited in scale, disciplinary scope, and comparative analyses of
different methodologies. To address this gap, we introduce FRONTIER-RevRec, a
large-scale dataset constructed from authentic peer review records (2007-2025)
from the Frontiers open-access publishing platform
https://www.frontiersin.org/. The dataset contains 177941 distinct reviewers
and 478379 papers across 209 journals spanning multiple disciplines including
clinical medicine, biology, psychology, engineering, and social sciences. Our
comprehensive evaluation on this dataset reveals that content-based methods
significantly outperform collaborative filtering. This finding is explained by
our structural analysis, which uncovers fundamental differences between
academic recommendation and commercial domains. Notably, approaches leveraging
language models are particularly effective at capturing the semantic alignment
between a paper's content and a reviewer's expertise. Furthermore, our
experiments identify optimal aggregation strategies to enhance the
recommendation pipeline. FRONTIER-RevRec is intended to serve as a
comprehensive benchmark to advance research in reviewer recommendation and
facilitate the development of more effective academic peer review systems. The
FRONTIER-RevRec dataset is available at:
https://anonymous.4open.science/r/FRONTIER-RevRec-5D05.

</details>


### [4] [Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization](https://arxiv.org/abs/2510.16715)
*Zulun Zhu,Haoyu Liu,Mengke He,Siqiang Luo*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Question answering in temporal knowledge graphs requires retrieval that is
both time-consistent and efficient. Existing RAG methods are largely semantic
and typically neglect explicit temporal constraints, which leads to
time-inconsistent answers and inflated token usage. We propose STAR-RAG, a
temporal GraphRAG framework that relies on two key ideas: building a
time-aligned rule graph and conducting propagation on this graph to narrow the
search space and prioritize semantically relevant, time-consistent evidence.
This design enforces temporal proximity during retrieval, reduces the candidate
set of retrieval results, and lowers token consumption without sacrificing
accuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates
the need for heavy model training and fine-tuning, thereby reducing
computational cost and significantly simplifying deployment.Extensive
experiments on real-world temporal KG datasets show that our method achieves
improved answer accuracy while consuming fewer tokens than strong GraphRAG
baselines.

</details>


### [5] [Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices](https://arxiv.org/abs/2510.16736)
*Patrizio Dazzi,William Guglielmo,Franco Maria Nardini,Raffaele Perego,Salvatore Trani*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the usage of FPGA devices for energy-efficient exact
kNN search in high-dimension latent spaces. This work intercepts a relevant
trend that tries to support the increasing popularity of learned
representations based on neural encoder models by making their large-scale
adoption greener and more inclusive. The paper proposes two different
energy-efficient solutions adopting the same FPGA low-level configuration. The
first solution maximizes system throughput by processing the queries of a batch
in parallel over a streamed dataset not fitting into the FPGA memory. The
second minimizes latency by processing each kNN incoming query in parallel over
an in-memory dataset. Reproducible experiments on publicly available image and
text datasets show that our solution outperforms state-of-the-art CPU-based
competitors regarding throughput, latency, and energy consumption.
Specifically, experiments show that the proposed FPGA solutions achieve the
best throughput in terms of queries per second and the best-observed latency
with scale-up factors of up to 16.6X. Similar considerations can be made
regarding energy efficiency, where results show that our solutions can achieve
up to 11.9X energy saving w.r.t. strong CPU-based competitors.

</details>


### [6] [The Layout Is the Model: On Action-Item Coupling in Generative Recommendation](https://arxiv.org/abs/2510.16804)
*Xiaokai Wei,Jiajun Wu,Daiyao Yi,Reza Shirkavand,Michelle Gong*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generative Recommendation (GR) models treat a user's interaction history as a
sequence to be autoregressively predicted. When both items and actions (e.g.,
watch time, purchase, comment) are modeled, the layout-the ordering and
visibility of item/action tokens-critically determines what information the
model can use and how it generalizes. We present a unified study of token
layouts for GR grounded in first principles: (P1) maximize item/action signal
in both input/output space, (P2) preserve the conditioning relationship "action
given item" and (P3) no information leakage.
  While interleaved layout (where item and action occupy separate tokens)
naturally satisfies these principles, it also bloats sequence length with
larger training/inference cost. On the non-interleaved front, we design a novel
and effective approach, Lagged Action Conditioning (LAC), which appears strange
on the surface but aligns well with the design principles to yield strong
accuracy. Comprehensive experiments on public datasets and large-scale
production logs evaluate different layout options and empirically verifies the
design principles. Our proposed non-interleaved method, LAC, achieves
competitive or superior quality at substantially lower FLOPs than interleaving.
Our findings offer actionable guidance for assembling GR systems that are both
accurate and efficient.

</details>


### [7] [Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce](https://arxiv.org/abs/2510.16925)
*Zhiding Liu,Ben Chen,Mingyue Cheng,Enchong Chen,Li Li,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Search-based recommendation is one of the most critical application scenarios
in e-commerce platforms. Users' complex search contexts--such as spatiotemporal
factors, historical interactions, and current query's information--constitute
an essential part of their decision-making, reflecting implicit preferences
that complement explicit query terms. Modeling such rich contextual signals and
their intricate associations with candidate items remains a key challenge.
Although numerous efforts have been devoted to building more effective search
methods, existing approaches still show limitations in integrating contextual
information, which hinders their ability to fully capture user intent.
  To address these challenges, we propose a context-aware reasoning-enhanced
generative search framework for better \textbf{understanding the complicated
context}. Specifically, the framework first unifies heterogeneous user and item
contexts into textual representations or text-based semantic identifiers and
aligns them. To overcome the lack of explicit reasoning trajectories, we
introduce a self-evolving post-training paradigm that iteratively combines
supervised fine-tuning and reinforcement learning to progressively enhance the
model's reasoning capability. In addition, we identify potential biases in
existing RL algorithms when applied to search scenarios and present a debiased
variant of GRPO to improve ranking performance. Extensive experiments on search
log data collected from a real-world e-commerce platform demonstrate that our
approach achieves superior performance compared with strong baselines,
validating its effectiveness for search-based recommendation.

</details>


### [8] [DSEBench: A Test Collection for Explainable Dataset Search with Examples](https://arxiv.org/abs/2510.17228)
*Qing Shi,Jing He,Qiaosheng Chen,Gong Cheng*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dataset search has been an established information retrieval task. Current
paradigms either retrieve datasets that are relevant to a keyword query or find
datasets that are similar to an input target dataset. To allow for their
combined specification of information needs, in this article, we investigate
the more generalized task of Dataset Search with Examples (DSE) and further
extend it to Explainable DSE that requires identifying the metadata and content
fields of a dataset that indicate its relevance to the query and similarity to
the target datasets. To facilitate this research, we construct DSEBench, a test
collection that provides high-quality dataset- and field-level annotations to
enable the evaluation of explainable DSE. We also employ a large language model
to generate numerous annotations to be used for training. We establish
extensive baselines on DSEBench by adapting and evaluating a variety of sparse,
dense, and LLM-based retrieval, reranking, and explanation methods.

</details>


### [9] [On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders](https://arxiv.org/abs/2510.17245)
*Wenyu Mao,Jiancan Wu,Guoqing Hu,Wei Ji,Xiang Wang*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Diffusion models have emerged as a powerful paradigm for generative
sequential recommendation, which typically generate next items to recommend
guided by user interaction histories with a multi-step denoising process.
However, the multi-step process relies on discrete approximations, introducing
discretization error that creates a trade-off between computational efficiency
and recommendation effectiveness. To address this trade-off, we propose TA-Rec,
a two-stage framework that achieves one-step generation by smoothing the
denoising function during pretraining while alleviating trajectory deviation by
aligning with user preferences during fine-tuning. Specifically, to improve the
efficiency without sacrificing the recommendation performance, TA-Rec pretrains
the denoising model with Temporal Consistency Regularization (TCR), enforcing
the consistency between the denoising results across adjacent steps. Thus, we
can smooth the denoising function to map the noise as oracle items in one step
with bounded error. To further enhance effectiveness, TA-Rec introduces
Adaptive Preference Alignment (APA) that aligns the denoising process with user
preference adaptively based on preference pair similarity and timesteps.
Extensive experiments prove that TA-Rec's two-stage objective effectively
mitigates the discretization errors-induced trade-off, enhancing both
efficiency and effectiveness of diffusion-based recommenders.

</details>


### [10] [How role-play shapes relevance judgment in zero-shot LLM rankers](https://arxiv.org/abs/2510.17535)
*Yumeng Wang,Jirui Qi,Catherine Chen,Panagiotis Eustratiadis,Suzan Verberne*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have emerged as promising zero-shot rankers, but
their performance is highly sensitive to prompt formulation. In particular,
role-play prompts, where the model is assigned a functional role or identity,
often give more robust and accurate relevance rankings. However, the mechanisms
and diversity of role-play effects remain underexplored, limiting both
effective use and interpretability. In this work, we systematically examine how
role-play variations influence zero-shot LLM rankers. We employ causal
intervention techniques from mechanistic interpretability to trace how
role-play information shapes relevance judgments in LLMs. Our analysis reveals
that (1) careful formulation of role descriptions have a large effect on the
ranking quality of the LLM; (2) role-play signals are predominantly encoded in
early layers and communicate with task instructions in middle layers, while
receiving limited interaction with query or document representations.
Specifically, we identify a group of attention heads that encode information
critical for role-conditioned relevance. These findings not only shed light on
the inner workings of role-play in LLM ranking but also offer guidance for
designing more effective prompts in IR and beyond, pointing toward broader
opportunities for leveraging role-play in zero-shot applications.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [11] [Taming Modality Entanglement in Continual Audio-Visual Segmentation](https://arxiv.org/abs/2510.17234)
*Yuyang Hong,Qi Yang,Tao Zhang,Zili Wang,Zhaojin Fu,Kun Ding,Bin Fan,Shiming Xiang*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recently, significant progress has been made in multi-modal continual
learning, aiming to learn new tasks sequentially in multi-modal settings while
preserving performance on previously learned ones. However, existing methods
mainly focus on coarse-grained tasks, with limitations in addressing modality
entanglement in fine-grained continual learning settings. To bridge this gap,
we introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to
continuously segment new classes guided by audio. Through comprehensive
analysis, two critical challenges are identified: 1) multi-modal semantic
drift, where a sounding objects is labeled as background in sequential tasks;
2) co-occurrence confusion, where frequent co-occurring classes tend to be
confused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework
is designed to address these challenges. Specifically, for multi-modal semantic
drift, a Multi-modal Sample Selection (MSS) strategy is proposed to select
samples with high modal consistency for rehearsal. Meanwhile, for co-occurence
confusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed,
allowing for the increase of rehearsal sample frequency of those confusable
classes during training process. Moreover, we construct three audio-visual
incremental scenarios to verify effectiveness of our method. Comprehensive
experiments demonstrate that our method significantly outperforms single-modal
continual learning methods.

</details>
