{"id": "2602.17011", "categories": ["cs.MM"], "pdf": "https://arxiv.org/pdf/2602.17011", "abs": "https://arxiv.org/abs/2602.17011", "authors": ["Hongjun Liu", "Leyu Zhou", "Zijianghao Yang", "Rujun Han", "Shitong Duan", "Kuanjian Tang", "Chao Yao"], "title": "CAFE: Channel-Autoregressive Factorized Encoding for Robust Biosignal Spatial Super-Resolution", "comment": null, "summary": "High-density biosignal recordings are critical for neural decoding and clinical monitoring, yet real-world deployments often rely on low-density (LD) montages due to hardware and operational constraints. This motivates spatial super-resolution from LD observations, but heterogeneous dependencies under sparse and noisy measurements often lead to artifact propagation and false non-local correlations. To address this, we propose CAFE, a plug-and-play rollout generation scheme that reconstructs the full montage in geometry-aligned stages. Starting from the LD channels, CAFE first recovers nearby channels and then progressively expands to more distal regions, exploiting reliable local structure before introducing non-local interactions. During training, step-wise supervision is applied over channel groups and teacher forcing with epoch-level scheduled sampling along the group dimension is utilized to reduce exposure bias, enabling parallel computation across steps. At test time, CAFE performs an autoregressive rollout across groups, while remaining plug-and-play by reusing any temporal backbone as the shared predictor. Evaluated on $4$ modalities and $6$ datasets, CAFE demonstrates plug-and-play generality across $3$ backbones (MLP, Conv, Transformer) and achieves consistently better reconstruction than $5$ representative baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAFE\u7684\u5373\u63d2\u5373\u7528\u751f\u6210\u65b9\u6848\uff0c\u80fd\u591f\u4ece\u4f4e\u5bc6\u5ea6\u751f\u7269\u4fe1\u53f7\u8bb0\u5f55\u4e2d\u91cd\u5efa\u5168\u8499\u592a\u5947\uff0c\u901a\u8fc7\u9010\u6b65\u6269\u5c55\u6062\u590d\u66f4\u8fdc\u533a\u57df\uff0c\u51cf\u5c11\u4f2a\u5f71\u4f20\u64ad\u548c\u9519\u8bef\u7684\u975e\u5c40\u90e8\u76f8\u5173\u6027\u3002\u5728\u56db\u79cd\u6a21\u6001\u548c\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u663e\u793a\u51fa\u6bd4\u4e94\u79cd\u4ee3\u8868\u6027\u57fa\u7ebf\u66f4\u597d\u7684\u91cd\u5efa\u6548\u679c\uff0c\u5e76\u80fd\u8de8\u4e09\u79cd\u9aa8\u5e72\uff08MLP\u3001Conv\u3001Transformer\uff09\u901a\u7528\u3002", "motivation": "\u9ad8\u5bc6\u5ea6\u751f\u7269\u4fe1\u53f7\u8bb0\u5f55\u5bf9\u4e8e\u795e\u7ecf\u89e3\u7801\u548c\u4e34\u5e8a\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u901a\u5e38\u53d7\u9650\u4e8e\u786c\u4ef6\u548c\u64cd\u4f5c\u6761\u4ef6\uff0c\u53ea\u80fd\u4f7f\u7528\u4f4e\u5bc6\u5ea6\u5e03\u5c40\u3002\u8fd9\u5bfc\u81f4\u4e86\u4ece\u4f4e\u5bc6\u5ea6\u89c2\u5bdf\u4e2d\u8fdb\u884c\u7a7a\u95f4\u8d85\u5206\u8fa8\u7387\u7684\u9700\u6c42\uff0c\u4f46\u7531\u4e8e\u7a00\u758f\u4e14\u566a\u58f0\u8f83\u5927\u7684\u6d4b\u91cf\u503c\u4e0b\u5f02\u8d28\u4f9d\u8d56\u5173\u7cfb\u7684\u5b58\u5728\uff0c\u5e38\u5e38\u4f1a\u5f15\u8d77\u4f2a\u5f71\u4f20\u64ad\u548c\u9519\u8bef\u7684\u975e\u5c40\u90e8\u76f8\u5173\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86CAFE\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u4ee5\u51e0\u4f55\u5bf9\u9f50\u7684\u65b9\u5f0f\u5206\u9636\u6bb5\u91cd\u5efa\u6574\u4e2a\u8499\u592a\u5947\u3002\u4ece\u4f4e\u5bc6\u5ea6\u901a\u9053\u5f00\u59cb\uff0c\u5148\u6062\u590d\u90bb\u8fd1\u901a\u9053\uff0c\u7136\u540e\u9010\u6b65\u6269\u5c55\u5230\u66f4\u8fdc\u7684\u533a\u57df\uff0c\u4f18\u5148\u5229\u7528\u53ef\u9760\u7684\u5c40\u90e8\u7ed3\u6784\u518d\u5f15\u5165\u975e\u5c40\u90e8\u4ea4\u4e92\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u5bf9\u901a\u9053\u7ec4\u8fdb\u884c\u5206\u6b65\u76d1\u7763\uff0c\u5e76\u6cbf\u7ec4\u7ef4\u5ea6\u91c7\u7528\u6559\u5e08\u5f3a\u8feb\u4e0e\u9884\u5b9a\u91c7\u6837\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u66b4\u9732\u504f\u5dee\uff0c\u5141\u8bb8\u6b65\u9aa4\u95f4\u7684\u5e76\u884c\u8ba1\u7b97\u3002\u6d4b\u8bd5\u65f6\uff0cCAFE\u5728\u5404\u7ec4\u4e4b\u95f4\u6267\u884c\u81ea\u56de\u5f52\u5c55\u5f00\uff0c\u540c\u65f6\u4fdd\u6301\u5373\u63d2\u5373\u7528\u7279\u6027\uff0c\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u4efb\u4f55\u65f6\u95f4\u4e3b\u5e72\u4f5c\u4e3a\u5171\u4eab\u9884\u6d4b\u5668\u3002", "result": "CAFE\u57284\u79cd\u6a21\u6001\u548c6\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u8de8\u8d8a3\u79cd\u9aa8\u5e72\uff08MLP\u3001\u5377\u79ef\u3001\u53d8\u6362\u5668\uff09\u7684\u4e00\u81f4\u66f4\u597d\u91cd\u5efa\u6027\u80fd\uff0c\u4f18\u4e8e5\u79cd\u4ee3\u8868\u6027\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CAFE\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u4ece\u4f4e\u5bc6\u5ea6\u751f\u7269\u4fe1\u53f7\u8bb0\u5f55\u4e2d\u9ad8\u8d28\u91cf\u5730\u91cd\u5efa\u5168\u8499\u592a\u5947\uff0c\u5176\u8bbe\u8ba1\u8003\u8651\u5230\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\u548c\u6311\u6218\u3002"}}
{"id": "2602.16717", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.16717", "abs": "https://arxiv.org/abs/2602.16717", "authors": ["Wensheng Gan", "Gengsen Huang", "Junyu Ren", "Philip S. Yu"], "title": "Guided Exploration of Sequential Rules", "comment": "Preprint", "summary": "In pattern mining, sequential rules provide a formal framework to capture the temporal relationships and inferential dependencies between items. However, the discovery process is computationally intensive. To obtain mining results efficiently and flexibly, many methods have been proposed that rely on specific evaluation metrics (i.e., ensuring results meet minimum threshold requirements). A key issue with these methods, however, is that they generate many sequential rules that are irrelevant to users. Such rules not only incur additional computational overhead but also complicate downstream analysis. In this paper, we investigate how to efficiently discover user-centric sequential rules. The original database is first processed to determine whether a target query rule is present. To prune unpromising items and avoid unnecessary expansions, we design tight and generalizable upper bounds. We introduce a novel method for efficiently generating target sequential rules using the proposed techniques and pruning strategies. In addition, we propose the corresponding mining algorithms for two common evaluation metrics: frequency and utility. We also design two rule similarity metrics to help discover the most relevant sequential rules. Extensive experiments demonstrate that our algorithms outperform state-of-the-art approaches in terms of runtime and memory usage, while discovering a concise set of sequential rules under flexible similarity settings. Targeted sequential rule search can handle sequence data with personalized features and achieve pattern discovery. The proposed solution addresses several challenges and can be applied to two common mining tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u53d1\u73b0\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u5e8f\u5217\u89c4\u5219\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7d27\u5bc6\u4e14\u53ef\u6cdb\u5316\u7684\u4e0a\u9650\u6765\u526a\u679d\u4e0d\u5177\u524d\u666f\u7684\u9879\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u9891\u7387\u548c\u6548\u7528\u4e24\u79cd\u5e38\u89c1\u8bc4\u4f30\u6307\u6807\u7684\u6316\u6398\u7b97\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u540c\u65f6\u80fd\u591f\u6839\u636e\u7075\u6d3b\u7684\u76f8\u4f3c\u6027\u8bbe\u7f6e\u53d1\u73b0\u7b80\u6d01\u7684\u5e8f\u5217\u89c4\u5219\u96c6\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u89c4\u5219\u53d1\u73b0\u8fc7\u7a0b\u8ba1\u7b97\u5bc6\u96c6\uff0c\u800c\u4e14\u751f\u6210\u8bb8\u591a\u5bf9\u7528\u6237\u65e0\u5173\u7684\u89c4\u5219\uff0c\u8fd9\u4e0d\u4ec5\u589e\u52a0\u4e86\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u8fd8\u4f7f\u4e0b\u6e38\u5206\u6790\u590d\u6742\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u8d34\u5408\u7528\u6237\u9700\u6c42\u7684\u5e8f\u5217\u89c4\u5219\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u5904\u7406\u539f\u59cb\u6570\u636e\u5e93\u5224\u65ad\u76ee\u6807\u67e5\u8be2\u89c4\u5219\u662f\u5426\u5b58\u5728\uff1b\u8bbe\u8ba1\u4e86\u7d27\u5bc6\u4e14\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u7684\u4e0a\u9650\u503c\u6765\u526a\u679d\u4e0d\u5177\u6f5c\u529b\u7684\u9879\u76ee\u5e76\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u6269\u5c55\uff1b\u5f15\u5165\u65b0\u7684\u6280\u672f\u4e0e\u526a\u679d\u7b56\u7565\u7528\u4e8e\u9ad8\u6548\u751f\u6210\u76ee\u6807\u5e8f\u5217\u89c4\u5219\uff1b\u4e3a\u9891\u7387\u548c\u6548\u7528\u8fd9\u4e24\u79cd\u5e38\u89c1\u7684\u8bc4\u4ef7\u6307\u6807\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u6316\u6398\u7b97\u6cd5\uff1b\u63d0\u51fa\u4e86\u4e24\u79cd\u89c4\u5219\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u65b9\u6cd5\u5e2e\u52a9\u8bc6\u522b\u6700\u76f8\u5173\u7684\u5e8f\u5217\u89c4\u5219\u3002", "result": "\u6240\u63d0\u7b97\u6cd5\u5728\u8fd0\u884c\u65f6\u95f4\u4e0e\u5185\u5b58\u6d88\u8017\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u4f73\u65b9\u6848\uff0c\u5e76\u80fd\u5728\u7075\u6d3b\u6027\u8f83\u9ad8\u7684\u76f8\u4f3c\u6027\u8bbe\u5b9a\u4e0b\u53d1\u73b0\u4e00\u5957\u7b80\u660e\u627c\u8981\u7684\u5e8f\u5217\u89c4\u5219\u3002\u6b64\u5916\uff0c\u5b9a\u5411\u5e8f\u5217\u89c4\u5219\u641c\u7d22\u53ef\u4ee5\u5904\u7406\u5e26\u6709\u4e2a\u6027\u5316\u7279\u5f81\u7684\u5e8f\u5217\u6570\u636e\u5b9e\u73b0\u6a21\u5f0f\u53d1\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u6210\u529f\u89e3\u51b3\u4e86\u51e0\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5e76\u80fd\u5e94\u7528\u4e8e\u4e24\u79cd\u5e38\u89c1\u7684\u6316\u6398\u4efb\u52a1\u4e2d\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5e8f\u5217\u89c4\u5219\u53d1\u73b0\u7684\u6548\u7387\u4e0e\u76f8\u5173\u6027\u3002"}}
{"id": "2602.16932", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16932", "abs": "https://arxiv.org/abs/2602.16932", "authors": ["Jinming Nian", "Fangchen Li", "Dae Hoon Park", "Yi Fang"], "title": "RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution", "comment": null, "summary": "Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, can automatically discover improved lexical retrieval algorithms. We introduce RankEvolve, a program evolution setup based on AlphaEvolve, in which candidate ranking algorithms are represented as executable code and iteratively mutated, recombined, and selected based on retrieval performance across 12 IR datasets from BEIR and BRIGHT. RankEvolve starts from two seed programs: BM25 and query likelihood with Dirichlet smoothing. The evolved algorithms are novel, effective, and show promising transfer to the full BEIR and BRIGHT benchmarks as well as TREC DL 19 and 20. Our results suggest that evaluator-guided LLM program evolution is a practical path towards automatic discovery of novel ranking algorithms.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aRankEvolve\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8fdb\u5316\u641c\u7d22\u6765\u81ea\u52a8\u53d1\u73b0\u6539\u8fdb\u7684\u8bcd\u6c47\u68c0\u7d22\u7b97\u6cd5\u3002\u4eceBM25\u548c\u5e26\u6709Dirichlet\u5e73\u6ed1\u7684\u67e5\u8be2\u4f3c\u7136\u4e24\u79cd\u79cd\u5b50\u7a0b\u5e8f\u5f00\u59cb\uff0c\u6240\u751f\u6210\u7684\u65b0\u7b97\u6cd5\u5728\u591a\u4e2a\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u663e\u793a\u51fa\u5bf9\u672a\u6765\u57fa\u51c6\u6d4b\u8bd5\u7684\u826f\u597d\u8fc1\u79fb\u6027\u3002", "motivation": "\u5c3d\u7ba1BM25\u548c\u5e26\u6709Dirichlet\u5e73\u6ed1\u7684\u67e5\u8be2\u4f3c\u7136\u7b49\u68c0\u7d22\u7b97\u6cd5\u4f5c\u4e3a\u7b2c\u4e00\u9636\u6bb5\u6392\u5e8f\u5668\u4ecd\u7136\u5f3a\u5927\u4e14\u9ad8\u6548\uff0c\u4f46\u5b83\u4eec\u7684\u6539\u8fdb\u4e3b\u8981\u4f9d\u8d56\u4e8e\u53c2\u6570\u8c03\u4f18\u548c\u4eba\u4e3a\u76f4\u89c9\u3002\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u8bc4\u4f30\u5668\u548c\u8fdb\u5316\u641c\u7d22\u6307\u5bfc\u4e0b\u81ea\u52a8\u53d1\u73b0\u66f4\u4f18\u7684\u8bcd\u6c47\u68c0\u7d22\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86RankEvolve\uff0c\u4e00\u79cd\u57fa\u4e8eAlphaEvolve\u7684\u7a0b\u5e8f\u8fdb\u5316\u8bbe\u7f6e\uff0c\u5728\u8fd9\u4e2a\u8bbe\u7f6e\u4e2d\u5019\u9009\u6392\u540d\u7b97\u6cd5\u88ab\u8868\u793a\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u53d8\u5f02\u3001\u91cd\u7ec4\u4ee5\u53ca\u6839\u636e12\u4e2a\u6765\u81eaBEIR\u548cBRIGHT\u7684\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u7684\u68c0\u7d22\u6027\u80fd\u8fdb\u884c\u9009\u62e9\u3002\u8d77\u59cb\u70b9\u662f\u4e24\u4e2a\u79cd\u5b50\u7a0b\u5e8f\uff1aBM25\u4e0e\u5e26Dirichlet\u5e73\u6ed1\u7684\u67e5\u8be2\u4f3c\u7136\u3002", "result": "\u6f14\u5316\u51fa\u7684\u7b97\u6cd5\u65b0\u9896\u6709\u6548\uff0c\u5e76\u4e14\u5bf9\u5b8c\u6574\u7684BEIR\u3001BRIGHT\u57fa\u51c6\u4ee5\u53caTREC DL 19\u548c20\u8868\u73b0\u51fa\u826f\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u7531\u8bc4\u4f30\u5668\u5f15\u5bfc\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7a0b\u5e8f\u8fdb\u5316\u662f\u4e00\u6761\u901a\u5f80\u81ea\u52a8\u53d1\u73b0\u65b0\u6392\u540d\u7b97\u6cd5\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2602.16748", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.16748", "abs": "https://arxiv.org/abs/2602.16748", "authors": ["Md Asiful Islam", "Shanto Jouerder", "Md Sabit As Sami", "Afia Jahin Prema"], "title": "A Construction-Phase Digital Twin Framework for Quality Assurance and Decision Support in Civil Infrastructure Projects", "comment": null, "summary": "Quality assurance (QA) during construction often relies on inspection records and laboratory test results that become available days or weeks after work is completed. On large highway and bridge projects, this delay limits early intervention and increases the risk of rework, schedule impacts, and fragmented documentation. This study presents a construction-phase digital twin framework designed to support element-level QA and readiness-based decision making during active construction. The framework links inspection records, material production and placement data, early-age sensing, and predictive strength models to individual construction elements. By integrating these data streams, the system represents the evolving quality state of each element and supports structured release or hold decisions before standard-age test results are available. The approach does not replace established inspection and testing procedures. Instead, it supplements existing workflows by improving traceability and enabling earlier, data-informed quality assessments. Practical considerations related to data integration, contractual constraints, and implementation challenges are also discussed. The proposed framework provides a structured pathway for transitioning construction QA from delayed, document-driven review toward proactive, element-level decision support during construction.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65bd\u5de5\u9636\u6bb5\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u65e8\u5728\u652f\u6301\u65bd\u5de5\u8fc7\u7a0b\u4e2d\u5143\u7d20\u7ea7\u522b\u7684\u8d28\u91cf\u4fdd\u8bc1\u548c\u57fa\u4e8e\u51c6\u5907\u60c5\u51b5\u7684\u51b3\u7b56\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u68c0\u67e5\u8bb0\u5f55\u3001\u6750\u6599\u751f\u4ea7\u548c\u653e\u7f6e\u6570\u636e\u3001\u65e9\u671f\u611f\u5e94\u4ee5\u53ca\u9884\u6d4b\u5f3a\u5ea6\u6a21\u578b\u7b49\u6570\u636e\u6d41\u6765\u8868\u793a\u6bcf\u4e2a\u65bd\u5de5\u5143\u7d20\u7684\u8d28\u91cf\u72b6\u6001\u6f14\u53d8\uff0c\u5e76\u5728\u6807\u51c6\u9f84\u671f\u6d4b\u8bd5\u7ed3\u679c\u53ef\u7528\u4e4b\u524d\u652f\u6301\u7ed3\u6784\u5316\u7684\u653e\u884c\u6216\u6682\u505c\u51b3\u7b56\u3002", "motivation": "\u5f53\u524d\u65bd\u5de5\u4e2d\u7684\u8d28\u91cf\u4fdd\u8bc1\u901a\u5e38\u4f9d\u8d56\u4e8e\u5b8c\u5de5\u540e\u6570\u5929\u6216\u6570\u5468\u624d\u80fd\u83b7\u5f97\u7684\u68c0\u9a8c\u8bb0\u5f55\u548c\u5b9e\u9a8c\u5ba4\u6d4b\u8bd5\u7ed3\u679c\uff0c\u8fd9\u9650\u5236\u4e86\u65e9\u671f\u5e72\u9884\u5e76\u589e\u52a0\u4e86\u8fd4\u5de5\u3001\u8fdb\u5ea6\u5f71\u54cd\u53ca\u6587\u4ef6\u788e\u7247\u5316\u7684\u98ce\u9669\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u63d0\u4f9b\u66f4\u65e9\u3001\u6570\u636e\u9a71\u52a8\u7684\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u7684\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u8fde\u63a5\u68c0\u67e5\u8bb0\u5f55\u3001\u6750\u6599\u751f\u4ea7\u548c\u653e\u7f6e\u6570\u636e\u3001\u65e9\u671f\u611f\u5e94\u6280\u672f\u4ee5\u53ca\u9884\u6d4b\u5f3a\u5ea6\u6a21\u578b\u5230\u5355\u72ec\u7684\u65bd\u5de5\u5143\u7d20\u4e0a\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u4ee3\u8868\u6bcf\u4e2a\u5143\u7d20\u8d28\u91cf\u72b6\u6001\u53d8\u5316\u7684\u7cfb\u7edf\u3002", "result": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u53ef\u8ffd\u6eaf\u6027\uff0c\u8fd8\u5141\u8bb8\u5728\u4f20\u7edf\u6d4b\u8bd5\u7ed3\u679c\u51fa\u6765\u4e4b\u524d\u8fdb\u884c\u66f4\u65e9\u7684\u6570\u636e\u4fe1\u606f\u8d28\u91cf\u8bc4\u4f30\uff0c\u4ece\u800c\u8865\u5145\u73b0\u6709\u5de5\u4f5c\u6d41\u7a0b\u800c\u4e0d\u53d6\u4ee3\u5df2\u5efa\u7acb\u7684\u68c0\u9a8c\u548c\u6d4b\u8bd5\u7a0b\u5e8f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u4ece\u5ef6\u8fdf\u7684\u3001\u6587\u6863\u9a71\u52a8\u7684\u5ba1\u67e5\u5411\u4e3b\u52a8\u7684\u3001\u5143\u7d20\u7ea7\u51b3\u7b56\u652f\u6301\u8f6c\u53d8\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u65bd\u5de5\u8fc7\u7a0b\u4e2d\u7684\u8d28\u91cf\u4fdd\u8bc1\u6548\u7387\u3002"}}
{"id": "2602.16730", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16730", "abs": "https://arxiv.org/abs/2602.16730", "authors": ["Lei Han", "Mohamed Abdel-Aty", "Younggun Kim", "Yang-Jun Joo", "Zubayer Islam"], "title": "MMCAformer: Macro-Micro Cross-Attention Transformer for Traffic Speed Prediction with Microscopic Connected Vehicle Driving Behavior", "comment": null, "summary": "Accurate speed prediction is crucial for proactive traffic management to enhance traffic efficiency and safety. Existing studies have primarily relied on aggregated, macroscopic traffic flow data to predict future traffic trends, whereas road traffic dynamics are also influenced by individual, microscopic human driving behaviors. Recent Connected Vehicle (CV) data provide rich driving behavior features, offering new opportunities to incorporate these behavioral insights into speed prediction. To this end, we propose the Macro-Micro Cross-Attention Transformer (MMCAformer) to integrate CV data-based micro driving behavior features with macro traffic features for speed prediction. Specifically, MMCAformer employs self-attention to learn intrinsic dependencies in macro traffic flow and cross-attention to capture spatiotemporal interplays between macro traffic status and micro driving behavior. MMCAformer is optimized with a Student-t negative log-likelihood loss to provide point-wise speed prediction and estimate uncertainty. Experiments on four Florida freeways demonstrate the superior performance of the proposed MMCAformer compared to baselines. Compared with only using macro features, introducing micro driving behavior features not only enhances prediction accuracy (e.g., overall RMSE, MAE, and MAPE reduced by 9.0%, 6.9%, and 10.2%, respectively) but also shrinks model prediction uncertainty (e.g., mean predictive intervals decreased by 10.1-24.0% across the four freeways). Results reveal that hard braking and acceleration frequencies emerge as the most influential features. Such improvements are more pronounced under congested, low-speed traffic conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdMacro-Micro Cross-Attention Transformer (MMCAformer) \u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86\u57fa\u4e8e\u8054\u7f51\u8f66\u8f86\u6570\u636e\u7684\u5fae\u89c2\u9a7e\u9a76\u884c\u4e3a\u7279\u5f81\u4e0e\u5b8f\u89c2\u4ea4\u901a\u6d41\u7279\u6027\u6765\u8fdb\u884c\u901f\u5ea6\u9884\u6d4b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u5b8f\u89c2\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u5f15\u5165\u5fae\u89c2\u9a7e\u9a76\u884c\u4e3a\u7279\u5f81\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff08\u4f8b\u5982RMSE\u3001MAE\u548cMAPE\u5206\u522b\u964d\u4f4e\u4e869.0%\u30016.9%\u548c10.2%\uff09\uff0c\u8fd8\u51cf\u5c11\u4e86\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u51c6\u786e\u7684\u901f\u5ea6\u9884\u6d4b\u5bf9\u4e8e\u4e3b\u52a8\u4ea4\u901a\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u63d0\u9ad8\u4ea4\u901a\u6548\u7387\u548c\u5b89\u5168\u6027\u3002\u867d\u7136\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u4e8e\u805a\u5408\u7684\u5b8f\u89c2\u4ea4\u901a\u6d41\u91cf\u6570\u636e\u6765\u9884\u6d4b\u672a\u6765\u7684\u4ea4\u901a\u8d8b\u52bf\uff0c\u4f46\u9053\u8def\u4ea4\u901a\u52a8\u6001\u4e5f\u53d7\u5230\u4e2a\u4f53\u5fae\u89c2\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u6700\u8fd1\u7684\u8054\u7f51\u8f66\u8f86(CV)\u6570\u636e\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u9a7e\u9a76\u884c\u4e3a\u7279\u5f81\uff0c\u4e3a\u5c06\u8fd9\u4e9b\u884c\u4e3a\u6d1e\u5bdf\u6574\u5408\u5230\u901f\u5ea6\u9884\u6d4b\u4e2d\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u4e86Macro-Micro Cross-Attention Transformer (MMCAformer)\uff0c\u5229\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u5b8f\u89c2\u4ea4\u901a\u6d41\u52a8\u4e2d\u7684\u5185\u5728\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u6355\u6349\u5b8f\u89c2\u4ea4\u901a\u72b6\u6001\u4e0e\u5fae\u89c2\u9a7e\u9a76\u884c\u4e3a\u4e4b\u95f4\u7684\u65f6\u7a7a\u4ea4\u4e92\u4f5c\u7528\u3002\u6b64\u5916\uff0cMMCAformer\u91c7\u7528Student-t\u8d1f\u5bf9\u6570\u4f3c\u7136\u635f\u5931\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u63d0\u4f9b\u70b9\u7ea7\u901f\u5ea6\u9884\u6d4b\u5e76\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u4f5b\u7f57\u91cc\u8fbe\u5dde\u56db\u6761\u9ad8\u901f\u516c\u8def\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684MMCAformer\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002\u4e0e\u53ea\u4f7f\u7528\u5b8f\u89c2\u7279\u5f81\u76f8\u6bd4\uff0c\u5f15\u5165\u5fae\u89c2\u9a7e\u9a76\u884c\u4e3a\u7279\u5f81\u4e0d\u4ec5\u589e\u5f3a\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff08\u4f8b\u5982\u6574\u4f53RMSE\u3001MAE\u548cMAPE\u5206\u522b\u51cf\u5c119.0%\u30016.9%\u548c10.2%\uff09\uff0c\u800c\u4e14\u7f29\u5c0f\u4e86\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\uff08\u4f8b\u5982\u5e73\u5747\u9884\u6d4b\u533a\u95f4\u5728\u56db\u6761\u9ad8\u901f\u516c\u8def\u4e0a\u51cf\u5c11\u4e8610.1-24.0%\uff09\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6025\u5239\u8f66\u548c\u52a0\u901f\u9891\u7387\u6210\u4e3a\u6700\u5177\u5f71\u54cd\u529b\u7684\u56e0\u7d20\uff0c\u5728\u62e5\u5835\u3001\u4f4e\u901f\u4ea4\u901a\u6761\u4ef6\u4e0b\u8fd9\u79cd\u6539\u8fdb\u66f4\u4e3a\u660e\u663e\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5fae\u89c2\u9a7e\u9a76\u884c\u4e3a\u7279\u5f81\u4e0e\u5b8f\u89c2\u4ea4\u901a\u6d41\u4fe1\u606f\uff0cMMCAformer\u80fd\u591f\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u901f\u5ea6\uff0c\u5e76\u4e14\u5728\u4ea4\u901a\u62e5\u5835\u65f6\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002\u8fd9\u8868\u660e\uff0c\u5c06\u9a7e\u9a76\u5458\u884c\u4e3a\u7eb3\u5165\u8003\u8651\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4ea4\u901a\u9884\u6d4b\u7684\u8d28\u91cf\u3002"}}
{"id": "2602.16903", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16903", "abs": "https://arxiv.org/abs/2602.16903", "authors": ["Armando Casta\u00f1eda", "Braulio Ramses Hern\u00e1ndez Mart\u00ednez"], "title": "Read-Modify-Writable Snapshots from Read/Write operations", "comment": null, "summary": "In the context of asynchronous concurrent shared-memory systems, a snapshot algorithm allows failure-prone processes to concurrently and atomically write on the entries of a shared array MEM , and also atomically read the whole array. Recently, Read-Modify-Writable (RMWable) snapshot was proposed, a variant of snapshot that allows processes to perform operations more complex than just read and write, specifically, each entry MEM[k] is an arbitrary readable object. The known RMWable snapshot algorithms heavily rely on powerful low-level operations such as compare&swap or load-link/store-conditional to correctly produce snapshots of MEM. Following the large body of research devoted to understand the limits of what can be solved using the simple read/write low-level operations, which are known to be strictly weaker than compare&swap and load-link/store-conditional, we explore if RMWable snapshots are possible using only read/write operations. We present two read/write RMWable snapshot algorithms, the first one in the standard concurrent shared-memory model where the number of processes n is finite and known in advance, and the second one in a variant of the standard model with unbounded concurrency, where there are infinitely many processes, but at any moment only finitely many processes participate in an execution.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4ec5\u4f7f\u7528\u8bfb/\u5199\u64cd\u4f5c\u5b9e\u73b0RMWable\u5feb\u7167\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u8bfb/\u5199\u64cd\u4f5c\u7684RMWable\u5feb\u7167\u7b97\u6cd5\uff0c\u5206\u522b\u9002\u7528\u4e8e\u8fdb\u7a0b\u6570\u91cf\u5df2\u77e5\u4e14\u6709\u9650\u7684\u6807\u51c6\u5e76\u53d1\u5171\u4eab\u5185\u5b58\u6a21\u578b\u548c\u5177\u6709\u65e0\u9650\u5e76\u53d1\u6027\u7684\u53d8\u4f53\u6a21\u578b\u3002", "motivation": "\u5728\u5f02\u6b65\u5e76\u53d1\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u4e2d\uff0c\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u5141\u8bb8\u8fdb\u7a0b\u6267\u884c\u6bd4\u7b80\u5355\u8bfb\u5199\u66f4\u590d\u6742\u64cd\u4f5c\u7684RMWable\u5feb\u7167\u7b97\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u7b97\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5982\u6bd4\u8f83\u5e76\u4ea4\u6362\u6216\u52a0\u8f7d\u94fe\u63a5/\u5b58\u50a8\u6761\u4ef6\u7b49\u5f3a\u5927\u7684\u5e95\u5c42\u64cd\u4f5c\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u4ec5\u901a\u8fc7\u7b80\u5355\u7684\u8bfb/\u5199\u4f4e\u7ea7\u64cd\u4f5c\u6765\u5b9e\u73b0RMWable\u5feb\u7167\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u51fa\u4e86\u4e24\u79cd\u4ec5\u57fa\u4e8e\u8bfb/\u5199\u64cd\u4f5c\u7684RMWable\u5feb\u7167\u7b97\u6cd5\uff1a\u4e00\u79cd\u9488\u5bf9\u7684\u662f\u6807\u51c6\u7684\u5e76\u53d1\u5171\u4eab\u5185\u5b58\u6a21\u578b\uff0c\u5728\u8be5\u6a21\u578b\u4e2d\u53c2\u4e0e\u8005\u7684\u6570\u91cf\u662f\u6709\u9650\u4e14\u4e8b\u5148\u5df2\u77e5\u7684\uff1b\u53e6\u4e00\u79cd\u5219\u9762\u5411\u4e00\u4e2a\u5177\u6709\u65e0\u754c\u5e76\u53d1\u6027\u7684\u6807\u51c6\u6a21\u578b\u53d8\u79cd\uff0c\u5176\u4e2d\u5c3d\u7ba1\u5b58\u5728\u65e0\u9650\u591a\u7684\u8fdb\u7a0b\uff0c\u4f46\u5728\u4efb\u4f55\u65f6\u523b\u53ea\u6709\u6709\u9650\u6570\u76ee\u7684\u8fdb\u7a0b\u53c2\u4e0e\u5230\u6267\u884c\u8fc7\u7a0b\u4e2d\u3002", "result": "\u6210\u529f\u5730\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684RMWable\u5feb\u7167\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u662f\u5728\u9650\u5236\u5230\u53ea\u4f7f\u7528\u8bfb/\u5199\u8fd9\u7c7b\u76f8\u5bf9\u5f31\u7684\u64cd\u4f5c\u7684\u60c5\u51b5\u4e0b\uff0c\u4f9d\u7136\u80fd\u591f\u652f\u6301RMWable\u5feb\u7167\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5373\u4fbf\u4e0d\u4f9d\u8d56\u4e8e\u66f4\u4e3a\u590d\u6742\u7684\u5e95\u5c42\u539f\u8bed\uff08\u5982\u6bd4\u8f83\u5e76\u4ea4\u6362\uff09\uff0c\u4e5f\u80fd\u591f\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5e76\u53d1\u73af\u5883\u4e0b\u5b9e\u73b0RMWable\u5feb\u7167\u3002"}}
{"id": "2602.16718", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.16718", "abs": "https://arxiv.org/abs/2602.16718", "authors": ["Hong Lin", "Wensheng Gan", "Junyu Ren", "Philip S. Yu"], "title": "UPER: Efficient Utility-driven Partially-ordered Episode Rule Mining", "comment": "Preprint", "summary": "Episode mining is a fundamental problem in analyzing a sequence of numerous events. For discovering strong relationships between events in a complex event sequence, episode rule mining is proposed. However, both the episode and episode rules have strict requirements for the order of events. Hence, partially-ordered episode rule mining (POERM) is designed to loosen the constraints on the ordering, i.e., events in the antecedents and consequents of the rule can be unordered, and POERM has been applied to real-life event prediction. In this paper, we consider the utility of POERM, intending to discover more valuable rules. We define the utility of POERs and propose an algorithm called UPER to discover high-utility partially-ordered episode rules. In addition, we adopt a data structure named NoList to store the necessary information, analyze the expansion of POERs in detail, and propose several pruning strategies (namely WEUP, REUCSP, and REEUP) to reduce the number of candidate rules. Finally, we conduct experiments on several datasets to demonstrate the effectivene", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUPER\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u53d1\u73b0\u9ad8\u5b9e\u7528\u6027\u7684\u90e8\u5206\u6709\u5e8f\u4e8b\u4ef6\u89c4\u5219\uff08POERs\uff09\uff0c\u5e76\u5f15\u5165\u4e86NoList\u6570\u636e\u7ed3\u6784\u548c\u51e0\u79cd\u526a\u679d\u7b56\u7565\u6765\u51cf\u5c11\u5019\u9009\u89c4\u5219\u7684\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u4ef6\u89c4\u5219\u6316\u6398\u5bf9\u4e8e\u4e8b\u4ef6\u987a\u5e8f\u6709\u4e25\u683c\u7684\u8981\u6c42\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u90e8\u5206\u6709\u5e8f\u4e8b\u4ef6\u89c4\u5219\u6316\u6398\uff08POERM\uff09\u6765\u653e\u5bbd\u8fd9\u4e9b\u7ea6\u675f\u3002\u7136\u800c\uff0c\u4e3a\u4e86\u53d1\u73b0\u66f4\u6709\u4ef7\u503c\u7684\u89c4\u5219\uff0c\u8003\u8651\u5c06\u6548\u7528\u6982\u5ff5\u5f15\u5165POERM\u662f\u5fc5\u8981\u7684\u3002", "method": "\u5b9a\u4e49\u4e86POERs\u7684\u6548\u7528\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aUPER\u7684\u65b0\u7b97\u6cd5\u6765\u8bc6\u522b\u9ad8\u5b9e\u7528\u6027\u7684\u90e8\u5206\u6709\u5e8f\u4e8b\u4ef6\u89c4\u5219\u3002\u6b64\u5916\uff0c\u4f7f\u7528NoList\u8fd9\u79cd\u6570\u636e\u7ed3\u6784\u6765\u5b58\u50a8\u5fc5\u8981\u4fe1\u606f\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u5305\u62ecWEUP\u3001REUCSP\u548cREEUP\u5728\u5185\u7684\u51e0\u79cd\u526a\u679d\u7b56\u7565\u4ee5\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u6709\u6548\u5730\u627e\u5230\u5177\u6709\u9ad8\u5b9e\u7528\u6027\u7684\u90e8\u5206\u6709\u5e8f\u4e8b\u4ef6\u89c4\u5219\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u90e8\u5206\u6709\u5e8f\u4e8b\u4ef6\u89c4\u5219\u6316\u6398\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6548\u7528\u5ea6\u91cf\u548c\u6709\u6548\u7684\u526a\u679d\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u89c4\u5219\u6316\u6398\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2602.16735", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.16735", "abs": "https://arxiv.org/abs/2602.16735", "authors": ["Saud Alghumayjan", "Ming Yi", "Bolun Xu"], "title": "A Few-Shot LLM Framework for Extreme Day Classification in Electricity Markets", "comment": null, "summary": "This paper proposes a few-shot classification framework based on Large Language Models (LLMs) to predict whether the next day will have spikes in real-time electricity prices. The approach aggregates system state information, including electricity demand, renewable generation, weather forecasts, and recent electricity prices, into a set of statistical features that are formatted as natural-language prompts and fed to an LLM along with general instructions. The model then determines the likelihood that the next day would be a spike day and reports a confidence score. Using historical data from the Texas electricity market, we demonstrate that this few-shot approach achieves performance comparable to supervised machine learning models, such as Support Vector Machines and XGBoost, and outperforms the latter two when limited historical data are available. These findings highlight the potential of LLMs as a data-efficient tool for classifying electricity price spikes in settings with scarce data.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5c11\u91cf\u6837\u672c\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u6b21\u65e5\u5b9e\u65f6\u7535\u4ef7\u662f\u5426\u4f1a\u98d9\u5347\u3002\u901a\u8fc7\u5c06\u7cfb\u7edf\u72b6\u6001\u4fe1\u606f\u6574\u5408\u4e3a\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5e76\u8f93\u5165\u5230LLMs\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5386\u53f2\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u5982\u652f\u6301\u5411\u91cf\u673a\u548cXGBoost\uff0c\u663e\u793a\u51faLLMs\u4f5c\u4e3a\u6570\u636e\u9ad8\u6548\u5de5\u5177\u5728\u5206\u7c7b\u7535\u4ef7\u98d9\u5347\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u6709\u6548\u5730\u5229\u7528\u6709\u9650\u7684\u6570\u636e\u96c6\u5bf9\u7535\u4ef7\u98d9\u5347\u8fdb\u884c\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u91c7\u7528\u7684\u65b9\u6cd5\u662f\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5c06\u7535\u529b\u9700\u6c42\u3001\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u3001\u5929\u6c14\u9884\u62a5\u53ca\u8fd1\u671f\u7535\u4ef7\u7b49\u7cfb\u7edf\u72b6\u6001\u4fe1\u606f\u8f6c\u6362\u6210\u4e00\u7ec4\u7edf\u8ba1\u7279\u5f81\uff0c\u5e76\u4ee5\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u5f62\u5f0f\u4e0e\u4e00\u822c\u6307\u4ee4\u4e00\u8d77\u63d0\u4f9b\u7ed9LLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5fb7\u514b\u8428\u65af\u5dde\u7535\u529b\u5e02\u573a\u7684\u5386\u53f2\u6570\u636e\u4e0a\uff0c\u8be5\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\u7684\u8868\u73b0\u4e0e\u652f\u6301\u5411\u91cf\u673a\u548cXGBoost\u7b49\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76f8\u5f53\uff1b\u800c\u4e14\u5f53\u53ef\u7528\u7684\u5386\u53f2\u6570\u636e\u8f83\u5c11\u65f6\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u540e\u4e24\u8005\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u5728\u5904\u7406\u6570\u636e\u7a00\u7f3a\u6761\u4ef6\u4e0b\u5bf9\u7535\u4ef7\u98d9\u5347\u8fdb\u884c\u5206\u7c7b\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.16936", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16936", "abs": "https://arxiv.org/abs/2602.16936", "authors": ["Zikai Zhang", "Rui Hu", "Jiahao Xu"], "title": "Heterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation", "comment": "To appear in ICLR 2026", "summary": "Large Language Models (LLMs) have demonstrated remarkable effectiveness in adapting to downstream tasks through fine-tuning. Federated Learning (FL) extends this capability by enabling collaborative fine-tuning across distributed clients using Low-Rank Adaptation (LoRA), while preserving data privacy by avoiding raw data sharing. However, practical deployments face challenges when clients have heterogeneous resources and thus adopt different LoRA ranks, leading to substantial initialization and aggregation noise that undermines performance. To address these challenges, we propose Fed-PLoRA, a novel lightweight heterogeneous federated fine-tuning (FFT) framework. Fed-PLoRA introduces Parallel One-Rank Adaptation (PLoRA), a new LoRA variant that replaces the classic multi-rank LoRA module with multiple parallel one-rank modules, and a novel Select-N-Fold strategy that folds untrained PLoRA modules into the pre-trained weights before local training, thereby accommodating heterogeneous client resources. We provide a unified analysis of initialization and aggregation noise of Fed-PLoRA and demonstrate how it addresses the limitations of state-of-the-art methods. Extensive experiments on diverse LLM fine-tuning tasks demonstrate that Fed-PLoRA consistently outperforms existing methods in both accuracy and efficiency. The code is available at https://github.com/TNI-playground/Fed-PLoRA.", "AI": {"tldr": "\u63d0\u51fa\u4e86Fed-PLoRA\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5f02\u6784\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5e76\u884c\u5355\u79e9\u9002\u5e94(PLoRA)\u548cSelect-N-Fold\u7b56\u7565\u6765\u89e3\u51b3\u5ba2\u6237\u8d44\u6e90\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u521d\u59cb\u5316\u548c\u805a\u5408\u566a\u58f0\u95ee\u9898\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u65b9\u6cd5\u5728\u5904\u7406\u62e5\u6709\u4e0d\u540c\u8d44\u6e90\u7684\u5206\u5e03\u5f0f\u5ba2\u6237\u7aef\u65f6\uff0c\u7531\u4e8e\u91c7\u7528\u4e0d\u540c\u7684LoRA\u7b49\u7ea7\uff0c\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u521d\u59cb\u5316\u548c\u805a\u5408\u566a\u58f0\uff0c\u5f71\u54cd\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u4e14\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u907f\u514d\u539f\u59cb\u6570\u636e\u5171\u4eab\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86Fed-PLoRA\u6846\u67b6\u3002", "method": "Fed-PLoRA\u6846\u67b6\u91c7\u7528\u4e86\u4e24\u79cd\u5173\u952e\u6280\u672f\uff1a\u4e00\u662fParallel One-Rank Adaptation (PLoRA)\uff0c\u5b83\u4f7f\u7528\u591a\u4e2a\u5e76\u884c\u7684\u4e00\u79e9\u6a21\u5757\u66ff\u4ee3\u4f20\u7edf\u7684\u591a\u79e9LoRA\u6a21\u5757\uff1b\u4e8c\u662fSelect-N-Fold\u7b56\u7565\uff0c\u5728\u672c\u5730\u8bad\u7ec3\u524d\u5c06\u672a\u7ecf\u8bad\u7ec3\u7684PLoRA\u6a21\u5757\u6298\u53e0\u5230\u9884\u8bad\u7ec3\u6743\u91cd\u4e2d\uff0c\u4ee5\u6b64\u6765\u9002\u5e94\u5177\u6709\u4e0d\u540c\u8d44\u6e90\u80fd\u529b\u7684\u5ba2\u6237\u7aef\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFed-PLoRA\u5728\u5404\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5fae\u8c03\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u8fd8\u589e\u5f3a\u4e86\u6548\u7387\u3002\u6b64\u5916\uff0c\u5bf9Fed-PLoRA\u8fdb\u884c\u4e86\u7edf\u4e00\u5206\u6790\uff0c\u5c55\u793a\u4e86\u5176\u5982\u4f55\u89e3\u51b3\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u5b58\u5728\u7684\u9650\u5236\u3002", "conclusion": "Fed-PLoRA\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u7531\u4e8e\u5ba2\u6237\u7aef\u8d44\u6e90\u5f02\u8d28\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u901a\u8fc7\u51cf\u5c11\u521d\u59cb\u5316\u4e0e\u805a\u5408\u8fc7\u7a0b\u4e2d\u7684\u566a\u97f3\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.16719", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16719", "abs": "https://arxiv.org/abs/2602.16719", "authors": ["Yaowen Liu", "Xuejia Chen", "Anxin Tian", "Haoyang Li", "Qinbin Li", "Xin Zhang", "Alexander Zhou", "Chen Jason Zhang", "Qing Li", "Lei Chen"], "title": "GPU-Accelerated Algorithms for Graph Vector Search: Taxonomy, Empirical Study, and Research Directions", "comment": null, "summary": "Approximate Nearest Neighbor Search (ANNS) underpins many large-scale data mining and machine learning applications, with efficient retrieval increasingly hinging on GPU acceleration as dataset sizes grow. Although graph-based approaches represent the state of the art in approximate nearest neighbor search, there is a lack of systematic understanding regarding their optimization for modern GPU architectures and their end-to-end effectiveness in practical scenarios. In this work, we present a comprehensive survey and experimental study of GPU-accelerated graph-based vector search algorithms. We establish a detailed taxonomy of GPU optimization strategies and clarify the mapping between algorithmic tasks and hardware execution units within GPUs. Through a thorough evaluation of six leading algorithms on eight large-scale benchmark datasets, we assess both graph index construction and query search performance. Our analysis reveals that distance computation remains the primary computational bottleneck, while data transfer between the host CPU and GPU emerges as the dominant factor influencing real-world latency at large scale. We also highlight key trade-offs in scalability and memory usage across different system designs. Our findings offer clear guidelines for designing scalable and robust GPU-powered approximate nearest neighbor search systems, and provide a comprehensive benchmark for the knowledge discovery and data mining community.", "AI": {"tldr": "\u672c\u6587\u5bf9GPU\u52a0\u901f\u7684\u57fa\u4e8e\u56fe\u7684\u5411\u91cf\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u8c03\u67e5\u548c\u5b9e\u9a8c\u7814\u7a76\uff0c\u65e8\u5728\u4e3a\u5927\u89c4\u6a21\u6570\u636e\u6316\u6398\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e2d\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u63d0\u4f9b\u4f18\u5316\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u6570\u636e\u96c6\u89c4\u6a21\u7684\u589e\u957f\uff0c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u5bf9\u4e8e\u8bb8\u591a\u5927\u89c4\u6a21\u6570\u636e\u6316\u6398\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u800c\u9ad8\u6548\u7684\u68c0\u7d22\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8eGPU\u52a0\u901f\u3002\u5c3d\u7ba1\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u4ee3\u8868\u4e86\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u9886\u57df\u7684\u6700\u65b0\u6280\u672f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5728\u73b0\u4ee3GPU\u67b6\u6784\u4e0a\u8fdb\u884c\u4f18\u5316\u4ee5\u53ca\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7aef\u5230\u7aef\u6709\u6548\u6027\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u8be6\u7ec6\u7684GPU\u4f18\u5316\u7b56\u7565\u5206\u7c7b\u6cd5\uff0c\u5e76\u660e\u786e\u7b97\u6cd5\u4efb\u52a1\u4e0eGPU\u5185\u786c\u4ef6\u6267\u884c\u5355\u5143\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u3002\u5bf9\u516d\u79cd\u9886\u5148\u7684\u7b97\u6cd5\u5728\u516b\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u8003\u5bdf\u4e86\u56fe\u7d22\u5f15\u6784\u5efa\u548c\u67e5\u8be2\u641c\u7d22\u6027\u80fd\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u8ddd\u79bb\u8ba1\u7b97\u4ecd\u7136\u662f\u4e3b\u8981\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u800c\u5728\u5927\u89c4\u6a21\u60c5\u51b5\u4e0b\uff0c\u4e3b\u673aCPU\u4e0eGPU\u4e4b\u95f4\u7684\u6570\u636e\u4f20\u8f93\u6210\u4e3a\u5f71\u54cd\u5b9e\u9645\u5ef6\u8fdf\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u8fd8\u5f3a\u8c03\u4e86\u4e0d\u540c\u7cfb\u7edf\u8bbe\u8ba1\u4e4b\u95f4\u5728\u53ef\u6269\u5c55\u6027\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u7684\u5173\u952e\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u53ef\u6269\u5c55\u4e14\u7a33\u5065\u7684GPU\u9a71\u52a8\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u4e86\u660e\u786e\u6307\u5357\uff0c\u5e76\u4e3a\u77e5\u8bc6\u53d1\u73b0\u548c\u6570\u636e\u6316\u6398\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u3002"}}
{"id": "2602.16974", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16974", "abs": "https://arxiv.org/abs/2602.16974", "authors": ["Yongjie Zhou", "Shuai Wang", "Bevan Koopman", "Guido Zuccon"], "title": "Beyond Chunk-Then-Embed: A Comprehensive Taxonomy and Evaluation of Document Chunking Strategies for Information Retrieval", "comment": "Github link will be pushed later as it's anonymoused at the moment", "summary": "Document chunking is a critical preprocessing step in dense retrieval systems, yet the design space of chunking strategies remains poorly understood. Recent research has proposed several concurrent approaches, including LLM-guided methods (e.g., DenseX and LumberChunker) and contextualized strategies(e.g., Late Chunking), which generate embeddings before segmentation to preserve contextual information. However, these methods emerged independently and were evaluated on benchmarks with minimal overlap, making direct comparisons difficult.\n  This paper reproduces prior studies in document chunking and presents a systematic framework that unifies existing strategies along two key dimensions: (1) segmentation methods, including structure-based methods (fixed-size, sentence-based, and paragraph-based) as well as semantically-informed and LLM-guided methods; and (2) embedding paradigms, which determine the timing of chunking relative to embedding (pre-embedding chunking vs. contextualized chunking). Our reproduction evaluates these approaches in two distinct retrieval settings established in previous work: in-document retrieval (needle-in-a-haystack) and in-corpus retrieval (the standard information retrieval task).\n  Our comprehensive evaluation reveals that optimal chunking strategies are task-dependent: simple structure-based methods outperform LLM-guided alternatives for in-corpus retrieval, while LumberChunker performs best for in-document retrieval. Contextualized chunking improves in-corpus effectiveness but degrades in-document retrieval. We also find that chunk size correlates moderately with in-document but weakly with in-corpus effectiveness, suggesting segmentation method differences are not purely driven by chunk size. Our code and evaluation benchmarks are publicly available at (Anonymoused).", "AI": {"tldr": "\u672c\u6587\u91cd\u73b0\u4e86\u6587\u6863\u5207\u5206\u7684\u5148\u524d\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6cbf\u7740\u4e24\u4e2a\u5173\u952e\u7ef4\u5ea6\u7edf\u4e00\u73b0\u6709\u7b56\u7565\uff1a(1)\u5206\u5272\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u7ed3\u6784\u7684\u65b9\u6cd5\uff08\u56fa\u5b9a\u5927\u5c0f\u3001\u57fa\u4e8e\u53e5\u5b50\u548c\u57fa\u4e8e\u6bb5\u843d\uff09\u4ee5\u53ca\u8bed\u4e49\u77e5\u60c5\u548c\u5927\u6a21\u578b\u5f15\u5bfc\u7684\u65b9\u6cd5\uff1b(2)\u5d4c\u5165\u8303\u5f0f\uff0c\u51b3\u5b9a\u4e86\u76f8\u5bf9\u4e8e\u5d4c\u5165\u7684\u5207\u5206\u65f6\u673a\uff08\u9884\u5d4c\u5165\u5207\u5206\u4e0e\u4e0a\u4e0b\u6587\u5316\u5207\u5206\uff09\u3002\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0c\u6700\u4f73\u5207\u5206\u7b56\u7565\u662f\u4efb\u52a1\u4f9d\u8d56\u6027\u7684\u3002", "motivation": "\u6587\u6863\u5207\u5206\u662f\u5bc6\u96c6\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u4f46\u5173\u4e8e\u5207\u5206\u7b56\u7565\u7684\u8bbe\u8ba1\u7a7a\u95f4\u4e86\u89e3\u4e0d\u8db3\u3002\u6700\u8fd1\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u51e0\u79cd\u5e76\u884c\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5927\u6a21\u578b\u5f15\u5bfc\u7684\u65b9\u6cd5\uff08\u4f8b\u5982DenseX\u548cLumberChunker\uff09\u4ee5\u53ca\u4e0a\u4e0b\u6587\u5316\u7b56\u7565\uff08\u4f8b\u5982Late Chunking\uff09\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5206\u6bb5\u524d\u751f\u6210\u5d4c\u5165\u4ee5\u4fdd\u7559\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u72ec\u7acb\u51fa\u73b0\uff0c\u5e76\u4e14\u662f\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u8bc4\u4f30\u7684\uff0c\u5176\u91cd\u53e0\u90e8\u5206\u5f88\u5c11\uff0c\u8fd9\u4f7f\u5f97\u76f4\u63a5\u6bd4\u8f83\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u672c\u6587\u901a\u8fc7\u91cd\u73b0\u4ee5\u524d\u7684\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u5c06\u73b0\u6709\u7b56\u7565\u6cbf\u4e24\u4e2a\u4e3b\u8981\u7ef4\u5ea6\u7edf\u4e00\u8d77\u6765\u7684\u7cfb\u7edf\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff1a(1)\u5206\u5272\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u7ed3\u6784\u7684\u65b9\u6cd5\uff08\u5982\u56fa\u5b9a\u5927\u5c0f\u3001\u57fa\u4e8e\u53e5\u5b50\u548c\u57fa\u4e8e\u6bb5\u843d\uff09\u4ee5\u53ca\u8bed\u4e49\u77e5\u60c5\u548cLLM\u6307\u5bfc\u7684\u65b9\u6cd5\uff1b(2)\u5d4c\u5165\u6a21\u5f0f\uff0c\u786e\u5b9a\u76f8\u5bf9\u4e8e\u5d4c\u5165\u7684\u5207\u5206\u65f6\u95f4\uff08\u9884\u5d4c\u5165\u5207\u5206\u4e0e\u4e0a\u4e0b\u6587\u5316\u5207\u5206\uff09\u3002", "result": "\u5168\u9762\u8bc4\u4f30\u663e\u793a\uff0c\u6700\u4f18\u7684\u5207\u5206\u7b56\u7565\u53d6\u51b3\u4e8e\u4efb\u52a1\uff1a\u5bf9\u4e8e\u8de8\u6587\u6863\u68c0\u7d22\uff0c\u7b80\u5355\u7684\u57fa\u4e8e\u7ed3\u6784\u7684\u65b9\u6cd5\u4f18\u4e8eLLM\u6307\u5bfc\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u800cLumberChunker\u5219\u5728\u6587\u6863\u5185\u68c0\u7d22\u4e2d\u8868\u73b0\u6700\u4f73\u3002\u4e0a\u4e0b\u6587\u5316\u7684\u5207\u5206\u63d0\u9ad8\u4e86\u8de8\u6587\u6863\u7684\u6709\u6548\u6027\uff0c\u4f46\u964d\u4f4e\u4e86\u6587\u6863\u5185\u68c0\u7d22\u7684\u8868\u73b0\u3002\u8fd8\u53d1\u73b0\u5757\u5927\u5c0f\u4e0e\u6587\u6863\u5185\u6548\u679c\u6709\u4e2d\u7b49\u7a0b\u5ea6\u7684\u76f8\u5173\u6027\uff0c\u800c\u4e0e\u8de8\u6587\u6863\u6709\u6548\u6027\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u8fd9\u8868\u660e\u5206\u5272\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u5f02\u5e76\u975e\u5b8c\u5168\u7531\u5757\u5927\u5c0f\u9a71\u52a8\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u9009\u62e9\u9002\u5f53\u6587\u6863\u5207\u5206\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u68c0\u7d22\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u4e0d\u540c\u5207\u5206\u65b9\u6cd5\u53ca\u5176\u5bf9\u68c0\u7d22\u6027\u80fd\u5f71\u54cd\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2602.16997", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16997", "abs": "https://arxiv.org/abs/2602.16997", "authors": ["Diego Firmenich", "Leandro Antonelli", "Bruno Pazos", "Fabricio Lozada", "Leonardo Morales"], "title": "Exploring LLMs for User Story Extraction from Mockups", "comment": "14 pages, 6 figures. Preprint of the paper published in the 28th Workshop on Requirements Engineering (WER 2025)", "summary": "User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how combining these techniques with large language models (LLMs) enables agile and automated generation of user stories from mockups. To this end, we present a case study that analyzes the ability of LLMs to extract user stories from high-fidelity mockups, both with and without the inclusion of a glossary of the Language Extended Lexicon (LEL) in the prompts. Our results demonstrate that incorporating the LEL significantly enhances the accuracy and suitability of the generated user stories. This approach represents a step forward in the integration of AI into requirements engineering, with the potential to improve communication between users and developers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7ed3\u5408\u9ad8\u4fdd\u771f\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u6a21\u578b\u4e2d\u81ea\u52a8\u751f\u6210\u7528\u6237\u6545\u4e8b\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u8868\u660e\u52a0\u5165\u6269\u5c55\u8bcd\u6c47\u8868\uff08LEL\uff09\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u7684\u7528\u6237\u6545\u4e8b\u7684\u51c6\u786e\u6027\u548c\u9002\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u4fc3\u8fdb\u7ec8\u7aef\u7528\u6237\u7684\u53c2\u4e0e\u5e76\u5b9a\u4e49\u4ed6\u4eec\u7684\u9700\u6c42\uff0c\u672c\u6587\u63a2\u7d22\u4e86\u5c06\u7528\u6237\u6545\u4e8b\u4e0e\u9ad8\u4fdd\u771f\u539f\u578b\u56fe\u76f8\u7ed3\u5408\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u8fd9\u4e9b\u539f\u578b\u56fe\u4e2d\u751f\u6210\u7528\u6237\u6545\u4e8b\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u9ad8\u4fdd\u771f\u539f\u578b\u56fe\u62bd\u53d6\u7528\u6237\u6545\u4e8b\u7684\u80fd\u529b\uff0c\u5e76\u4e14\u6bd4\u8f83\u4e86\u5728\u63d0\u793a\u4e2d\u5305\u542b\u548c\u4e0d\u5305\u542b\u6269\u5c55\u8bcd\u6c47\u8868\uff08LEL\uff09\u7684\u60c5\u51b5\u4e0b\u7684\u6548\u679c\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u63d0\u793a\u4e2d\u52a0\u5165\u6269\u5c55\u8bcd\u6c47\u8868\uff08LEL\uff09\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6240\u751f\u6210\u7528\u6237\u6545\u4e8b\u7684\u51c6\u786e\u5ea6\u4e0e\u5408\u9002\u7a0b\u5ea6\u3002", "conclusion": "\u5c06AI\u6574\u5408\u5230\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u8fd9\u4e00\u65b9\u6cd5\u6807\u5fd7\u7740\u4e00\u4e2a\u8fdb\u6b65\uff0c\u6709\u53ef\u80fd\u6539\u5584\u7528\u6237\u4e0e\u5f00\u53d1\u8005\u4e4b\u95f4\u7684\u6c9f\u901a\u3002"}}
{"id": "2602.16739", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16739", "abs": "https://arxiv.org/abs/2602.16739", "authors": ["Lei Han", "Mohamed Abdel-Aty", "Zubayer Islam", "Chenzhu Wang"], "title": "Real-time Secondary Crash Likelihood Prediction Excluding Post Primary Crash Features", "comment": null, "summary": "Secondary crash likelihood prediction is a critical component of an active traffic management system to mitigate congestion and adverse impacts caused by secondary crashes. However, existing approaches mainly rely on post-crash features (e.g., crash type and severity) that are rarely available in real time, limiting their practical applicability. To address this limitation, we propose a hybrid secondary crash likelihood prediction framework that does not depend on post-crash features. A dynamic spatiotemporal window is designed to extract real-time traffic flow and environmental features from primary crash locations and their upstream segments. The framework includes three models: a primary crash model to estimate the likelihood of secondary crash occurrence, and two secondary crash models to evaluate traffic conditions at crash and upstream segments under different comparative scenarios. An ensemble learning strategy integrating six machine learning algorithms is developed to enhance predictive performance, and a voting-based mechanism combines the outputs of the three models. Experiments on Florida freeways demonstrate that the proposed hybrid framework correctly identifies 91% of secondary crashes with a low false alarm rate of 0.20. The Area Under the ROC Curve improves from 0.654, 0.744, and 0.902 for the individual models to 0.952 for the hybrid model, outperforming previous studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6b21\u7ea7\u78b0\u649e\u53ef\u80fd\u6027\u9884\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4e0d\u4f9d\u8d56\u4e8e\u78b0\u649e\u540e\u7279\u5f81\uff0c\u800c\u662f\u57fa\u4e8e\u5b9e\u65f6\u4ea4\u901a\u6d41\u548c\u73af\u5883\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\u3002\u901a\u8fc7\u96c6\u6210\u516d\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u91c7\u7528\u6295\u7968\u673a\u5236\u7ed3\u5408\u4e09\u4e2a\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u4f5b\u7f57\u91cc\u8fbe\u5dde\u9ad8\u901f\u516c\u8def\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4ee5\u5f80\u7814\u7a76\uff0c\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u8bef\u62a5\u7387\u51c6\u786e\u8bc6\u522b91%\u7684\u6b21\u7ea7\u78b0\u649e\u4e8b\u4ef6\u3002", "motivation": "\u73b0\u6709\u6b21\u7ea7\u78b0\u649e\u53ef\u80fd\u6027\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u78b0\u649e\u7c7b\u578b\u3001\u4e25\u91cd\u7a0b\u5ea6\u7b49\u78b0\u649e\u540e\u7279\u5f81\uff0c\u8fd9\u4e9b\u4fe1\u606f\u5728\u5b9e\u9645\u4e2d\u96be\u4ee5\u5b9e\u65f6\u83b7\u53d6\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u78b0\u649e\u540e\u7279\u6027\u7684\u9884\u6d4b\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u52a8\u6001\u65f6\u7a7a\u7a97\u53e3\u6765\u4ece\u4e3b\u78b0\u649e\u4f4d\u7f6e\u53ca\u5176\u4e0a\u6e38\u8def\u6bb5\u63d0\u53d6\u5b9e\u65f6\u4ea4\u901a\u6d41\u4e0e\u73af\u5883\u7279\u5f81\uff1b\u6784\u5efa\u4e86\u5305\u542b\u4e00\u4e2a\u4e3b\u78b0\u649e\u6a21\u578b\u548c\u4e24\u4e2a\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u6bd4\u8f83\u573a\u666f\u4e0b\u78b0\u649e\u70b9\u53ca\u4e0a\u6e38\u6bb5\u4ea4\u901a\u72b6\u51b5\u7684\u6b21\u7ea7\u78b0\u649e\u6a21\u578b\u5728\u5185\u7684\u6846\u67b6\uff1b\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u7b56\u7565\u6574\u5408\u4e86\u516d\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u6295\u7968\u673a\u5236\u7efc\u5408\u4e09\u4e2a\u6a21\u578b\u7684\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f5b\u7f57\u91cc\u8fbe\u5dde\u9ad8\u901f\u516c\u8def\u7684\u5e94\u7528\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u80fd\u591f\u6b63\u786e\u8bc6\u522b91%\u7684\u6b21\u7ea7\u78b0\u649e\u4e8b\u4ef6\uff0c\u4e14\u8bef\u62a5\u7387\u4ec5\u4e3a0.20\uff1bROC\u66f2\u7ebf\u4e0b\u9762\u79ef\u4ece\u5355\u4e2a\u6a21\u578b\u76840.654\u30010.744\u30010.902\u63d0\u5347\u5230\u4e86\u6df7\u5408\u6a21\u578b\u4e0b\u76840.952\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u7814\u7a76\u6210\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6b21\u7ea7\u78b0\u649e\u53ef\u80fd\u6027\u9884\u6d4b\u6846\u67b6\u80fd\u591f\u5728\u6ca1\u6709\u4f7f\u7528\u78b0\u649e\u540e\u7279\u5f81\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5bf9\u6b21\u7ea7\u78b0\u649e\u7684\u6709\u6548\u9884\u6d4b\uff0c\u5c55\u793a\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u4e0e\u66f4\u4f4e\u7684\u8bef\u62a5\u7387\uff0c\u4e3a\u4ea4\u901a\u7ba1\u7406\u90e8\u95e8\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.16986", "categories": ["cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.16986", "abs": "https://arxiv.org/abs/2602.16986", "authors": ["Qin Ding", "Kevin Course", "Linjian Ma", "Jianhui Sun", "Rouchen Liu", "Zhao Zhu", "Chunxing Yin", "Wei Li", "Dai Li", "Yu Shi", "Xuan Cao", "Ze Yang", "Han Li", "Xing Liu", "Bi Xue", "Hongwei Li", "Rui Jian", "Daisy Shi He", "Jing Qian", "Matt Ma", "Qunshu Zhang", "Rui Li"], "title": "Bending the Scaling Law Curve in Large-Scale Recommendation Systems", "comment": null, "summary": "Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578bULTRA-HSTU\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u6a21\u578b\u548c\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u8f93\u5165\u5e8f\u5217\u3001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u53ca\u6a21\u578b\u62d3\u6251\u7ed3\u6784\u4e0a\u8fdb\u884c\u4e86\u521b\u65b0\u3002\u8be5\u6a21\u578b\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u63a8\u8350\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6269\u5c55\u6548\u7387\u63d0\u5347\uff0c\u5305\u62ec\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u4e865\u500d\u4ee5\u4e0a\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e8621\u500d\uff0c\u5e76\u5df2\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u670d\u52a1\u6570\u5341\u4ebf\u7528\u6237\uff0c\u4fc3\u8fdb\u4e864%\u81f38%\u7684\u6d88\u8d39\u4e0e\u53c2\u4e0e\u5ea6\u589e\u957f\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u4e8e\u4ece\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u4e2d\u5b66\u4e60\u7684\u5e8f\u5217\u6a21\u578b\uff0c\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u7684\u826f\u597d\u6269\u5c55\u6027\u89c4\u5f8b\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u59cb\u63a2\u7d22\u957f\u5e8f\u5217\u5efa\u6a21\u548c\u66f4\u6df1\u5c42\u6b21\u67b6\u6784\u4ee5\u5e94\u5bf9\u63a8\u8350\u4efb\u52a1\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u9760\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5e26\u6765\u7684\u8868\u73b0\u529b\u4f18\u52bf\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u8fdb\u4e00\u6b65\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u63d0\u51fa\u4e86ULTRA-HSTU\u6a21\u578b\u3002", "method": "ULTRA-HSTU\u91c7\u7528\u4e86\u7aef\u5230\u7aef\u7684\u6a21\u578b\u548c\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u65b9\u6848\uff0c\u4e3b\u8981\u521b\u65b0\u70b9\u5728\u4e8e\uff1a1) \u8f93\u5165\u5e8f\u5217\u7684\u8bbe\u8ba1\uff1b2) \u5f15\u5165\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff1b3) \u4f18\u5316\u6a21\u578b\u62d3\u6251\u7ed3\u6784\u3002\u8fd9\u4e9b\u6539\u8fdb\u65e8\u5728\u514b\u670d\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u6311\u6218\u3002", "result": "\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4\uff0cULTRA-HSTU\u4e0d\u4ec5\u5728\u63a8\u8350\u8d28\u91cf\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u5728\u6269\u5c55\u6548\u7387\u65b9\u9762\u4e5f\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\u2014\u2014\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e86\u8d85\u8fc75\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u52a0\u5feb\u4e8621\u500d\u3002\u6b64\u5916\uff0c\u5728\u771f\u5b9e\u751f\u4ea7\u73af\u5883\u4e0b\uff0c\u8be5\u6a21\u578b\u8fd8\u63a8\u52a8\u4e864%\u52308%\u7684\u6d88\u8d39\u91cf\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u589e\u957f\u3002", "conclusion": "ULTRA-HSTU\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578b\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u521b\u65b0\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u5e8f\u5217\u63a8\u8350\u4e2d\u5b58\u5728\u7684\u6548\u7387\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u77db\u76fe\u3002\u5b83\u4e0d\u4ec5\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u5904\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4e5f\u4fdd\u8bc1\u4e86\u63a8\u8350\u7ed3\u679c\u7684\u8d28\u91cf\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.17018", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17018", "abs": "https://arxiv.org/abs/2602.17018", "authors": ["Giovanni Rosa", "David Moreno-Lumbreras", "Raula Gaikovina Kula"], "title": "Not Only for Developers: Exploring Plugin Maintenance for Knowledge-Centric Communities", "comment": "Accepted to SANER2026", "summary": "The adoption of third-party libraries has become integral to modern software development, leading to large ecosystems such as PyPI, NPM, and Maven, where contributors typically share the technical expertise to sustain extensions. In communities that are not exclusively composed of developers, however, maintaining plugin ecosystems can present different challenges. In this early results paper, we study Obsidian, a knowledge--centric platform whose community is focused on writing, organization, and creativity--has built a substantial plugin ecosystem despite not being developer--centric. We investigate what kinds of plugins exist within this hybrid ecosystem and establish a foundation for understanding how they are maintained. Using repository mining and LLM-based topic modeling on a representative sample of 396 plugins, we identify six topics related to knowledge management and tooling, which is (i) dynamic editing and organization, (ii) interface and layouts, (iii) creative writing and productivity, (iv) knowledge sync solutions, (v) linking and script tools, and (vi) workflow enhancements tools. Furthermore, analysis of the Pull Requests from these plugins show that much software evolution has been performed on these ecosystem. These findings suggest that even in mixed communities, plugin ecosystems can develop recognizable engineering structures, motivating future work that highlight three different research directions with six research questions related to the health and sustainability of these non-developer ecosystems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Obsidian\u5e73\u53f0\u4e0a\u7684\u63d2\u4ef6\u751f\u6001\u7cfb\u7edf\uff0c\u5c3d\u7ba1\u5176\u793e\u533a\u4e3b\u8981\u5173\u6ce8\u5199\u4f5c\u3001\u7ec4\u7ec7\u548c\u521b\u9020\u529b\u800c\u975e\u5f00\u53d1\uff0c\u4f46\u4ecd\u5f62\u6210\u4e86\u663e\u8457\u7684\u63d2\u4ef6\u751f\u6001\u3002\u901a\u8fc7\u5bf9396\u4e2a\u4ee3\u8868\u6027\u63d2\u4ef6\u8fdb\u884c\u4ed3\u5e93\u6316\u6398\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u9898\u5efa\u6a21\uff0c\u8bc6\u522b\u51fa\u516d\u4e2a\u4e0e\u77e5\u8bc6\u7ba1\u7406\u548c\u5de5\u5177\u76f8\u5173\u7684\u8bdd\u9898\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u63d2\u4ef6\u7684Pull Requests\uff0c\u63ed\u793a\u5373\u4f7f\u5728\u6df7\u5408\u578b\u793e\u533a\u4e2d\u63d2\u4ef6\u751f\u6001\u7cfb\u7edf\u4e5f\u80fd\u53d1\u5c55\u51fa\u53ef\u8bc6\u522b\u7684\u5de5\u7a0b\u7ed3\u6784\uff0c\u4e3a\u672a\u6765\u5173\u4e8e\u975e\u5f00\u53d1\u8005\u751f\u6001\u7cfb\u7edf\u7684\u5065\u5eb7\u4e0e\u53ef\u6301\u7eed\u6027\u7814\u7a76\u6307\u660e\u4e86\u4e09\u4e2a\u65b9\u5411\u53ca\u516d\u4e2a\u7814\u7a76\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5728\u4e00\u4e2a\u4ee5\u5199\u4f5c\u3001\u7ec4\u7ec7\u548c\u521b\u4f5c\u4e3a\u6838\u5fc3\u4f46\u4e0d\u4ee5\u5f00\u53d1\u4eba\u5458\u4e3a\u4e3b\u7684\u793e\u533a\u91cc\uff0c\u5982\u4f55\u5f62\u6210\u5e76\u7ef4\u62a4\u4e00\u4e2a\u5e9e\u5927\u7684\u63d2\u4ef6\u751f\u6001\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4ed3\u5e93\u6316\u6398\u6280\u672f\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5bf9\u9009\u53d6\u7684396\u4e2a\u63d2\u4ef6\u6837\u672c\u8fdb\u884c\u4e86\u5206\u6790\uff1b\u540c\u65f6\uff0c\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u63d2\u4ef6\u7684Pull Requests\u6765\u4e86\u89e3\u8f6f\u4ef6\u6f14\u8fdb\u7684\u60c5\u51b5\u3002", "result": "\u786e\u5b9a\u4e86\u516d\u4e2a\u4e0e\u77e5\u8bc6\u7ba1\u7406\u548c\u5de5\u5177\u76f8\u5173\u7684\u4e3b\u9898\uff1a\u52a8\u6001\u7f16\u8f91\u4e0e\u7ec4\u7ec7\u3001\u754c\u9762\u4e0e\u5e03\u5c40\u3001\u521b\u610f\u5199\u4f5c\u4e0e\u751f\u4ea7\u529b\u3001\u77e5\u8bc6\u540c\u6b65\u89e3\u51b3\u65b9\u6848\u3001\u94fe\u63a5\u4e0e\u811a\u672c\u5de5\u5177\u4ee5\u53ca\u5de5\u4f5c\u6d41\u589e\u5f3a\u5de5\u5177\u3002\u6b64\u5916\uff0c\u89c2\u5bdf\u5230\u5927\u91cf\u8f6f\u4ef6\u6f14\u5316\u6d3b\u52a8\u53d1\u751f\u5728\u8be5\u751f\u6001\u7cfb\u7edf\u5185\u3002", "conclusion": "\u5373\u4fbf\u662f\u5728\u975e\u5f00\u53d1\u8005\u4e3b\u5bfc\u7684\u6df7\u5408\u578b\u793e\u533a\u4e2d\uff0c\u63d2\u4ef6\u751f\u6001\u7cfb\u7edf\u4e5f\u80fd\u591f\u53d1\u5c55\u51fa\u660e\u663e\u7684\u5de5\u7a0b\u7ed3\u6784\u7279\u5f81\u3002\u8fd9\u4e00\u53d1\u73b0\u6fc0\u53d1\u4e86\u9488\u5bf9\u8fd9\u7c7b\u975e\u4f20\u7edf\u5f00\u53d1\u8005\u751f\u6001\u7cfb\u7edf\u7684\u5065\u5eb7\u5ea6\u4e0e\u53ef\u6301\u7eed\u6027\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u5174\u8da3\u3002"}}
{"id": "2602.16989", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.16989", "abs": "https://arxiv.org/abs/2602.16989", "authors": ["Chentong Hao", "Minmao Wang"], "title": "WSDM Cup 2026 Multilingual Retrieval: A Low-Cost Multi-Stage Retrieval Pipeline", "comment": null, "summary": "We present a low-cost retrieval system for the WSDM Cup 2026 multilingual retrieval task, where English queries are used to retrieve relevant documents from a collection of approximately ten million news articles in Chinese, Persian, and Russian, and to output the top-1000 ranked results for each query. We follow a four-stage pipeline that combines LLM-based GRF-style query expansion with BM25 candidate retrieval, dense ranking using long-text representations from jina-embeddings-v4, and pointwise re-ranking of the top-20 candidates using Qwen3-Reranker-4B while preserving the dense order for the remaining results. On the official evaluation, the system achieves nDCG@20 of 0.403 and Judged@20 of 0.95. We further conduct extensive ablation experiments to quantify the contribution of each stage and to analyze the effectiveness of query expansion, dense ranking, and top-$k$ reranking under limited compute budgets.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4f4e\u6210\u672c\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u7528\u4e8eWSDM Cup 2026\u591a\u8bed\u8a00\u68c0\u7d22\u4efb\u52a1\uff0c\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u67e5\u8be2\u6269\u5c55\u3001BM25\u5019\u9009\u68c0\u7d22\u3001\u4f7f\u7528jina-embeddings-v4\u8fdb\u884c\u5bc6\u96c6\u6392\u5e8f\u4ee5\u53ca\u5229\u7528Qwen3-Reranker-4B\u5bf9\u524d20\u540d\u5019\u9009\u8fdb\u884c\u70b9\u5f0f\u91cd\u6392\u5e8f\u7b49\u56db\u4e2a\u9636\u6bb5\uff0c\u5728\u5b98\u65b9\u8bc4\u4f30\u4e2d\u8fbe\u5230\u4e86nDCG@20\u4e3a0.403\u548cJudged@20\u4e3a0.95\u7684\u6210\u7ee9\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u4f4e\u6210\u672c\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u8de8\u8bed\u8a00\u4fe1\u606f\u68c0\u7d22\u6311\u6218\uff0c\u7279\u522b\u662f\u4ece\u4e2d\u6587\u3001\u6ce2\u65af\u8bed\u548c\u4fc4\u8bed\u6587\u6863\u4e2d\u6839\u636e\u82f1\u6587\u67e5\u8be2\u68c0\u7d22\u76f8\u5173\u6587\u6863\u7684\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u6d41\u7a0b\uff1a\u9996\u5148\u4f7f\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u8fdb\u884cGRF\u98ce\u683c\u7684\u67e5\u8be2\u6269\u5c55\uff1b\u7136\u540e\u5229\u7528BM25\u7b97\u6cd5\u6267\u884c\u5019\u9009\u6587\u6863\u68c0\u7d22\uff1b\u63a5\u7740\u901a\u8fc7jina-embeddings-v4\u751f\u6210\u7684\u957f\u6587\u672c\u8868\u793a\u6765\u8fdb\u884c\u5bc6\u96c6\u578b\u6392\u5e8f\uff1b\u6700\u540e\u4f7f\u7528Qwen3-Reranker-4B\u5bf9\u6392\u540d\u524d20\u4f4d\u7684\u7ed3\u679c\u5b9e\u65bd\u70b9\u5f0f\u91cd\u6392\u5e8f\uff0c\u5e76\u4fdd\u6301\u5176\u4f59\u7ed3\u679c\u7684\u5bc6\u96c6\u987a\u5e8f\u4e0d\u53d8\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u5b98\u65b9\u8bc4\u6d4b\u4e0a\u53d6\u5f97\u4e86nDCG@20\u5f97\u5206\u4e3a0.403\u53caJudged@20\u5f97\u5206\u4e3a0.95\u7684\u826f\u597d\u8868\u73b0\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5e7f\u6cdb\u7684\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e86\u6bcf\u4e2a\u9636\u6bb5\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u4e0d\u540c\u6280\u672f\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5de7\u5999\u5730\u7ed3\u5408\u591a\u79cd\u73b0\u4ee3NLP\u6280\u672f\u548c\u7b56\u7565\u4e5f\u80fd\u6784\u5efa\u51fa\u9ad8\u6548\u800c\u51c6\u786e\u7684\u8de8\u8bed\u8a00\u68c0\u7d22\u7cfb\u7edf\u3002"}}
{"id": "2602.16742", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16742", "abs": "https://arxiv.org/abs/2602.16742", "authors": ["Haoxiang Sun", "Lizhen Xu", "Bing Zhao", "Wotao Yin", "Wei Wang", "Boyu Yang", "Rui Wang", "Hu Wei"], "title": "DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning", "comment": "Under review", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has been shown effective in enhancing the visual reflection and reasoning capabilities of Large Multimodal Models (LMMs). However, existing datasets are predominantly derived from either small-scale manual construction or recombination of prior resources, which limits data diversity and coverage, thereby constraining further gains in model performance. To this end, we introduce \\textbf{DeepVision-103K}, a comprehensive dataset for RLVR training that covers diverse K12 mathematical topics, extensive knowledge points, and rich visual elements. Models trained on DeepVision achieve strong performance on multimodal mathematical benchmarks, and generalize effectively to general multimodal reasoning tasks. Further analysis reveals enhanced visual perception, reflection and reasoning capabilities in trained models, validating DeepVision's effectiveness for advancing multimodal reasoning. Data: \\href{https://huggingface.co/datasets/skylenage/DeepVision-103K}{this url}.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aDeepVision-103K\u7684\u65b0\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u53cd\u601d\u548c\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u8be5\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u5e7f\u6cdb\u7684K12\u6570\u5b66\u4e3b\u9898\u3001\u4e30\u5bcc\u7684\u77e5\u8bc6\u70b9\u4ee5\u53ca\u591a\u6837\u5316\u7684\u89c6\u89c9\u5143\u7d20\uff0c\u5e76\u4e14\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u5728\u591a\u6a21\u6001\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u4e5f\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u4e00\u822c\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e0a\u3002", "motivation": "\u73b0\u6709\u7684\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u6570\u636e\u96c6\u4e3b\u8981\u57fa\u4e8e\u5c0f\u89c4\u6a21\u7684\u624b\u5de5\u6784\u5efa\u6216\u5148\u524d\u8d44\u6e90\u7684\u91cd\u7ec4\uff0c\u8fd9\u9650\u5236\u4e86\u6570\u636e\u7684\u591a\u6837\u6027\u4e0e\u8986\u76d6\u8303\u56f4\uff0c\u8fdb\u800c\u5236\u7ea6\u4e86\u6a21\u578b\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7efc\u5408\u6027\u6570\u636e\u96c6DeepVision-103K\u3002", "method": "\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5305\u542b\u591a\u6837\u5316K12\u6570\u5b66\u8bdd\u9898\u3001\u5e7f\u6cdb\u7684\u77e5\u8bc6\u70b9\u53ca\u4e30\u5bcc\u89c6\u89c9\u5143\u7d20\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6DeepVision-103K\u6765\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "result": "\u4f7f\u7528DeepVision-103K\u8bad\u7ec3\u7684\u6a21\u578b\u4e0d\u4ec5\u5728\u591a\u6a21\u6001\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u4e14\u80fd\u591f\u5f88\u597d\u5730\u63a8\u5e7f\u81f3\u66f4\u5e7f\u6cdb\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u3002\u6b64\u5916\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u5728\u89c6\u89c9\u611f\u77e5\u3001\u53cd\u601d\u4e0e\u63a8\u7406\u80fd\u529b\u4e0a\u6709\u6240\u63d0\u9ad8\u3002", "conclusion": "DeepVision-103K\u4f5c\u4e3a\u4e00\u4e2a\u4e13\u4e3aRLVR\u8bad\u7ec3\u8bbe\u8ba1\u7684\u5168\u9762\u6027\u6570\u636e\u96c6\uff0c\u6709\u6548\u5730\u4fc3\u8fdb\u4e86\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u89c6\u89c9\u53cd\u601d\u4e0e\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u8fdb\u6b65\u3002"}}
{"id": "2602.17318", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17318", "abs": "https://arxiv.org/abs/2602.17318", "authors": ["Patrick Zojer", "Jonas Posner", "Taylan \u00d6zden"], "title": "Evaluating Malleable Job Scheduling in HPC Clusters using Real-World Workloads", "comment": null, "summary": "Optimizing resource utilization in high-performance computing (HPC) clusters is essential for maximizing both system efficiency and user satisfaction. However, traditional rigid job scheduling often results in underutilized resources and increased job waiting times.\n  This work evaluates the benefits of resource elasticity, where the job scheduler dynamically adjusts the resource allocation of malleable jobs at runtime. Using real workload traces from the Cori, Eagle, and Theta supercomputers, we simulate varying proportions (0-100%) of malleable jobs with the ElastiSim software.\n  We evaluate five job scheduling strategies, including a novel one that maintains malleable jobs at their preferred resource allocation when possible. Results show that, compared to fully rigid workloads, malleable jobs yield significant improvements across all key metrics. Considering the best-performing scheduling strategy for each supercomputer, job turnaround times decrease by 37-67%, job makespan by 16-65%, job wait times by 73-99%, and node utilization improves by 5-52%. Although improvements vary, gains remain substantial even at 20% malleable jobs.\n  This work highlights important correlations between workload characteristics (e.g., job runtimes and node requirements), malleability proportions, and scheduling strategies. These findings confirm the potential of malleability to address inefficiencies in current HPC practices and demonstrate that even limited adoption can provide substantial advantages, encouraging its integration into HPC resource management.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\u4e2d\u91c7\u7528\u53ef\u5851\u6027\u4f5c\u4e1a\u8c03\u5ea6\u7b56\u7565\u7684\u76ca\u5904\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8fd0\u884c\u65f6\u8d44\u6e90\u5206\u914d\u6765\u4f18\u5316\u8d44\u6e90\u5229\u7528\u7387\u3002\u57fa\u4e8eCori\u3001Eagle\u548cTheta\u8d85\u7ea7\u8ba1\u7b97\u673a\u7684\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u8ddf\u8e2a\u6a21\u62df\u663e\u793a\uff0c\u5373\u4f7f\u53ea\u670920%\u7684\u53ef\u5851\u6027\u4f5c\u4e1a\u4e5f\u80fd\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u6548\u7387\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u5173\u952e\u6307\u6807\u3002", "motivation": "\u4f20\u7edf\u521a\u6027\u7684\u4f5c\u4e1a\u8c03\u5ea6\u65b9\u6cd5\u5bfc\u81f4\u4e86\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u4e0b\u4ee5\u53ca\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u589e\u52a0\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u65b0\u7684\u8c03\u5ea6\u7b56\u7565\u4ee5\u63d0\u9ad8HPC\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002", "method": "\u4f7f\u7528ElastiSim\u8f6f\u4ef6\u6a21\u62df\u4e0d\u540c\u6bd4\u4f8b\uff08\u4ece0\u5230100%\uff09\u7684\u53ef\u5851\u6027\u4f5c\u4e1a\uff0c\u5e76\u8bc4\u4f30\u4e94\u79cd\u4e0d\u540c\u7684\u4f5c\u4e1a\u8c03\u5ea6\u7b56\u7565\u7684\u6548\u679c\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u79cd\u5c3d\u91cf\u4fdd\u6301\u53ef\u5851\u6027\u4f5c\u4e1a\u5728\u5176\u9996\u9009\u8d44\u6e90\u914d\u7f6e\u7684\u65b0\u7b56\u7565\u3002", "result": "\u76f8\u6bd4\u4e8e\u5b8c\u5168\u521a\u6027\u7684\u4f5c\u4e1a\u8d1f\u8f7d\uff0c\u91c7\u7528\u53ef\u5851\u6027\u4f5c\u4e1a\u80fd\u591f\u663e\u8457\u6539\u5584\u6240\u6709\u5173\u952e\u6307\u6807\uff1a\u4f5c\u4e1a\u5468\u8f6c\u65f6\u95f4\u51cf\u5c11\u4e8637-67%\uff0c\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u51cf\u5c11\u4e8616-65%\uff0c\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u51cf\u5c11\u4e8673-99%\uff0c\u8282\u70b9\u5229\u7528\u7387\u63d0\u9ad8\u4e865-52%\u3002\u5373\u4f7f\u5728\u4ec520%\u7684\u4f5c\u4e1a\u4e3a\u53ef\u5851\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u6539\u8fdb\u4ecd\u7136\u5341\u5206\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f5c\u4e1a\u7279\u6027\uff08\u5982\u8fd0\u884c\u65f6\u95f4\u548c\u8282\u70b9\u9700\u6c42\uff09\u3001\u53ef\u5851\u6027\u6bd4\u4f8b\u4ee5\u53ca\u8c03\u5ea6\u7b56\u7565\u4e4b\u95f4\u5b58\u5728\u91cd\u8981\u5173\u8054\u3002\u8fd9\u8bc1\u5b9e\u4e86\u53ef\u5851\u6027\u5bf9\u4e8e\u89e3\u51b3\u5f53\u524dHPC\u5b9e\u8df5\u4e2d\u5b58\u5728\u7684\u4f4e\u6548\u95ee\u9898\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u5e76\u4e14\u5373\u4f7f\u5c11\u91cf\u5f15\u5165\u4e5f\u53ef\u5e26\u6765\u5b9e\u8d28\u6027\u7684\u4f18\u52bf\uff0c\u9f13\u52b1\u5c06\u5176\u6574\u5408\u8fdbHPC\u8d44\u6e90\u7ba1\u7406\u4e2d\u3002"}}
{"id": "2602.17335", "categories": ["cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17335", "abs": "https://arxiv.org/abs/2602.17335", "authors": ["Jigao Luo", "Qi Chen", "Carsten Binnig"], "title": "Do GPUs Really Need New Tabular File Formats?", "comment": null, "summary": "Parquet is the de facto columnar file format in modern analytical systems, yet its configuration guidelines have largely been shaped by CPU-centric execution models. As GPU-accelerated data processing becomes increasingly prevalent, Parquet files generated with CPU-oriented defaults can severely underutilize GPU parallelism, turning GPU scans into a performance bottleneck.\n  In this work, we systematically study how Parquet configurations affect GPU scan performance. We show that Parquet's poor GPU performance is not inherent to the format itself but rather a consequence of suboptimal configuration choices. By applying GPU-aware configurations, we increase effective read bandwidth up to 125 GB/s without modifying the Parquet specification.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86Parquet\u6587\u4ef6\u683c\u5f0f\u5728GPU\u52a0\u901f\u6570\u636e\u5904\u7406\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u901a\u8fc7\u91c7\u7528\u9488\u5bf9GPU\u4f18\u5316\u7684\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bfb\u53d6\u5e26\u5bbd\uff0c\u6700\u9ad8\u53ef\u8fbe125GB/s\uff0c\u800c\u65e0\u9700\u66f4\u6539Parquet\u89c4\u8303\u672c\u8eab\u3002", "motivation": "\u968f\u7740GPU\u52a0\u901f\u7684\u6570\u636e\u5904\u7406\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u57fa\u4e8eCPU\u8bbe\u8ba1\u9ed8\u8ba4\u8bbe\u7f6e\u751f\u6210\u7684Parquet\u6587\u4ef6\u65e0\u6cd5\u5145\u5206\u5229\u7528GPU\u5e76\u884c\u6027\uff0c\u5bfc\u81f4GPU\u626b\u63cf\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002", "method": "\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u4e0d\u540cParquet\u914d\u7f6e\u5bf9GPU\u626b\u63cf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u8bc1\u660e\u4e86\u901a\u8fc7\u5e94\u7528\u9488\u5bf9GPU\u7684\u914d\u7f6e\u53ef\u4ee5\u5927\u5e45\u5ea6\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528GPU\u611f\u77e5\u914d\u7f6e\u80fd\u591f\u663e\u8457\u589e\u52a0\u6709\u6548\u8bfb\u53d6\u5e26\u5bbd\uff0c\u6700\u9ad8\u901f\u5ea6\u8fbe\u5230\u4e86125GB/s\u3002", "conclusion": "Parquet\u5728GPU\u4e0a\u7684\u4f4e\u6027\u80fd\u5e76\u975e\u7531\u683c\u5f0f\u672c\u8eab\u5f15\u8d77\uff0c\u800c\u662f\u7531\u4e8e\u914d\u7f6e\u9009\u62e9\u4e0d\u5f53\u6240\u81f4\uff1b\u901a\u8fc7\u9002\u5f53\u7684\u914d\u7f6e\u8c03\u6574\uff0c\u53ef\u4ee5\u6781\u5927\u6539\u5584\u5176\u5728GPU\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2602.17036", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17036", "abs": "https://arxiv.org/abs/2602.17036", "authors": ["Rong Fu", "Zijian Zhang", "Haiyun Wei", "Jiekai Wu", "Kun Liu", "Xianda Li", "Haoyu Zhao", "Yang Li", "Yongtai Liu", "Ziming Wang", "Rui Lu", "Simon Fong"], "title": "LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation", "comment": "19 pages, 5 figures", "summary": "The continuous expansion of digital learning environments has catalyzed the demand for intelligent systems capable of providing personalized educational content. While current exercise recommendation frameworks have made significant strides, they frequently encounter obstacles regarding the long-tailed distribution of student engagement and the failure to adapt to idiosyncratic learning trajectories. We present LiveGraph, a novel active-structure neural re-ranking framework designed to overcome these limitations. Our approach utilizes a graph-based representation enhancement strategy to bridge the information gap between active and inactive students while integrating a dynamic re-ranking mechanism to foster content diversity. By prioritizing the structural relationships within learning histories, the proposed model effectively balances recommendation precision with pedagogical variety. Comprehensive experimental evaluations conducted on multiple real-world datasets demonstrate that LiveGraph surpasses contemporary baselines in both predictive accuracy and the breadth of exercise diversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLiveGraph\u7684\u65b0\u9896\u795e\u7ecf\u91cd\u6392\u5e8f\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u7ec3\u4e60\u63a8\u8350\u7cfb\u7edf\u5728\u5b66\u751f\u53c2\u4e0e\u5ea6\u957f\u5c3e\u5206\u5e03\u53ca\u9002\u5e94\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u8868\u793a\u589e\u5f3a\u7b56\u7565\u548c\u52a8\u6001\u91cd\u6392\u5e8f\u673a\u5236\uff0cLiveGraph\u4e0d\u4ec5\u80fd\u591f\u7f29\u5c0f\u6d3b\u8dc3\u4e0e\u975e\u6d3b\u8dc3\u5b66\u751f\u4e4b\u95f4\u7684\u4fe1\u606f\u5dee\u8ddd\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u5185\u5bb9\u591a\u6837\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7ec3\u4e60\u591a\u6837\u6027\u65b9\u9762\uff0cLiveGraph\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5b66\u4e60\u73af\u5883\u7684\u4e0d\u65ad\u6269\u5927\uff0c\u5bf9\u80fd\u591f\u63d0\u4f9b\u4e2a\u6027\u5316\u6559\u80b2\u5185\u5bb9\u7684\u667a\u80fd\u7cfb\u7edf\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u5c3d\u7ba1\u73b0\u6709\u7684\u7ec3\u4e60\u63a8\u8350\u6846\u67b6\u5df2\u7ecf\u53d6\u5f97\u4e86\u4e00\u5b9a\u6210\u5c31\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u5b66\u751f\u53c2\u4e0e\u5ea6\u7684\u957f\u5c3e\u5206\u5e03\u4ee5\u53ca\u9002\u5e94\u72ec\u7279\u5b66\u4e60\u8f68\u8ff9\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86LiveGraph\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u7684\u4e3b\u52a8\u7ed3\u6784\u795e\u7ecf\u91cd\u6392\u5e8f\u6846\u67b6\uff0c\u5b83\u5229\u7528\u57fa\u4e8e\u56fe\u7684\u8868\u793a\u589e\u5f3a\u7b56\u7565\u6765\u5f25\u5408\u6d3b\u8dc3\u4e0e\u4e0d\u6d3b\u8dc3\u5b66\u751f\u95f4\u7684\u4fe1\u606f\u9e3f\u6c9f\uff0c\u5e76\u7ed3\u5408\u4e86\u52a8\u6001\u91cd\u6392\u673a\u5236\u4ee5\u4fc3\u8fdb\u5185\u5bb9\u591a\u6837\u6027\u3002\u8be5\u6a21\u578b\u5f3a\u8c03\u5b66\u4e60\u5386\u53f2\u4e2d\u7684\u7ed3\u6784\u5173\u7cfb\uff0c\u4ece\u800c\u6709\u6548\u5e73\u8861\u63a8\u8350\u7cbe\u5ea6\u4e0e\u6559\u5b66\u591a\u6837\u6027\u3002", "result": "\u901a\u8fc7\u5bf9\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\uff0cLiveGraph\u5728\u9884\u6d4b\u51c6\u786e\u6027\u53ca\u7ec3\u4e60\u591a\u6837\u6027\u5bbd\u5ea6\u4e0a\u5747\u8d85\u8d8a\u4e86\u5f53\u524d\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "LiveGraph\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u7ec3\u4e60\u63a8\u8350\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u9047\u5230\u7684\u5b66\u751f\u53c2\u4e0e\u5ea6\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u4e14\u80fd\u66f4\u597d\u5730\u9002\u5e94\u4e0d\u540c\u7684\u5b66\u4e60\u8def\u5f84\uff0c\u4e3a\u5b9e\u73b0\u66f4\u7cbe\u51c6\u3001\u66f4\u591a\u6837\u5316\u7684\u6559\u80b2\u5185\u5bb9\u63a8\u8350\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2602.16745", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16745", "abs": "https://arxiv.org/abs/2602.16745", "authors": ["Zhangyi Liu", "Huaizhi Qu", "Xiaowei Yin", "He Sun", "Yanjun Han", "Tianlong Chen", "Zhun Deng"], "title": "PETS: A Principled Framework Towards Optimal Trajectory Allocation for Efficient Test-Time Self-Consistency", "comment": null, "summary": "Test-time scaling can improve model performance by aggregating stochastic reasoning trajectories. However, achieving sample-efficient test-time self-consistency under a limited budget remains an open challenge. We introduce PETS (Principled and Efficient Test-TimeSelf-Consistency), which initiates a principled study of trajectory allocation through an optimization framework. Central to our approach is the self-consistency rate, a new measure defined as agreement with the infinite-budget majority vote. This formulation makes sample-efficient test-time allocation theoretically grounded and amenable to rigorous analysis. We study both offline and online settings. In the offline regime, where all questions are known in advance, we connect trajectory allocation to crowdsourcing, a classic and well-developed area, by modeling reasoning traces as workers. This perspective allows us to leverage rich existing theory, yielding theoretical guarantees and an efficient majority-voting-based allocation algorithm. In the online streaming regime, where questions arrive sequentially and allocations must be made on the fly, we propose a novel method inspired by the offline framework. Our approach adapts budgets to question difficulty while preserving strong theoretical guarantees and computational efficiency. Experiments show that PETS consistently outperforms uniform allocation. On GPQA, PETS achieves perfect self-consistency in both settings while reducing the sampling budget by up to 75% (offline) and 55% (online) relative to uniform allocation. Code is available at https://github.com/ZDCSlab/PETS.", "AI": {"tldr": "\u63d0\u51fa\u4e86PETS\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6846\u67b6\u7814\u7a76\u63a8\u7406\u8f68\u8ff9\u5206\u914d\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u9ad8\u6d4b\u8bd5\u65f6\u7684\u6837\u672c\u6548\u7387\u3002\u5728\u7ebf\u4e0b\u548c\u7ebf\u4e0a\u73af\u5883\u4e2d\uff0cPETS\u5747\u80fd\u6709\u6548\u51cf\u5c11\u91c7\u6837\u9884\u7b97\u540c\u65f6\u4fdd\u6301\u9ad8\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u6280\u672f\u867d\u7136\u80fd\u591f\u901a\u8fc7\u805a\u5408\u968f\u673a\u63a8\u7406\u8def\u5f84\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5728\u6709\u9650\u9884\u7b97\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u81ea\u4e00\u81f4\u6027\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86PETS\uff08\u539f\u5219\u6027\u4e14\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u81ea\u4e00\u81f4\u6027\uff09\u65b9\u6cd5\uff0c\u5f15\u5165\u81ea\u6211\u4e00\u81f4\u6027\u6bd4\u7387\u4f5c\u4e3a\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u5c06\u63a8\u7406\u8f68\u8ff9\u5efa\u6a21\u4e3a\u5de5\u4f5c\u8005\u8fde\u63a5\u5230\u4f17\u5305\u9886\u57df\uff0c\u5728\u7ebf\u4e0b\u73af\u5883\u4f7f\u7528\u57fa\u4e8e\u591a\u6570\u6295\u7968\u7684\u5206\u914d\u7b97\u6cd5\uff0c\u5728\u7ebf\u6d41\u5f0f\u73af\u5883\u4e2d\u5219\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u4ee5\u9002\u5e94\u95ee\u9898\u96be\u5ea6\u5e76\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPETS\u5728GPQA\u4e0a\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u7684\u81ea\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u4e0e\u5747\u5300\u5206\u914d\u76f8\u6bd4\uff0c\u5728\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\u51cf\u5c11\u4e86\u9ad8\u8fbe75%\u3001\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u51cf\u5c11\u4e8655%\u7684\u91c7\u6837\u9884\u7b97\u3002", "conclusion": "PETS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u5f3a\u4e14\u8ba1\u7b97\u4e0a\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u6d4b\u8bd5\u65f6\u7684\u6837\u672c\u9ad8\u6548\u81ea\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u65e0\u8bba\u662f\u5728\u9884\u5148\u77e5\u9053\u6240\u6709\u95ee\u9898\u7684\u79bb\u7ebf\u573a\u666f\u8fd8\u662f\u95ee\u9898\u987a\u5e8f\u5230\u8fbe\u7684\u5728\u7ebf\u573a\u666f\u4e2d\u90fd\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.17610", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.17610", "abs": "https://arxiv.org/abs/2602.17610", "authors": ["Nicolau Manubens Gil"], "title": "Exploring Novel Data Storage Approaches for Large-Scale Numerical Weather Prediction", "comment": "PhD. thesis successfully defended at The University of Edinburgh on the 16th October 2025", "summary": "Driven by scientific and industry ambition, HPC and AI applications such as operational Numerical Weather Prediction (NWP) require processing and storing ever-increasing data volumes as fast as possible. Whilst POSIX distributed file systems and NVMe SSDs are currently a common HPC storage configuration providing I/O to applications, new storage solutions have proliferated or gained traction over the last decade with potential to address performance limitations POSIX file systems manifest at scale for certain I/O workloads.\n  This work has primarily aimed to assess the suitability and performance of two object storage systems -namely DAOS and Ceph- for the ECMWF's operational NWP as well as for HPC and AI applications in general. New software-level adapters have been developed which enable the ECMWF's NWP to leverage these systems, and extensive I/O benchmarking has been conducted on a few computer systems, comparing the performance delivered by the evaluated object stores to that of equivalent Lustre file system deployments on the same hardware. Challenges of porting to object storage and its benefits with respect to the traditional POSIX I/O approach have been discussed and, where possible, domain-agnostic performance analysis has been conducted, leading to insight also of relevance to I/O practitioners and the broader HPC community.\n  DAOS and Ceph have both demonstrated excellent performance, but DAOS stood out relative to Ceph and Lustre, providing superior scalability and flexibility for applications to perform I/O at scale as desired. This sets a promising outlook for DAOS and object storage, which might see greater adoption at HPC centres in the years to come, although not necessarily implying a shift away from POSIX-like I/O.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86DAOS\u548cCeph\u4e24\u79cd\u5bf9\u8c61\u5b58\u50a8\u7cfb\u7edf\u5bf9\u4e8eECMWF\u4e1a\u52a1\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\u4ee5\u53caHPC\u548cAI\u5e94\u7528\u7684\u9002\u7528\u6027\u548c\u6027\u80fd\u3002\u901a\u8fc7\u5f00\u53d1\u65b0\u7684\u8f6f\u4ef6\u7ea7\u9002\u914d\u5668\uff0c\u4f7fECMWF\u7684NWP\u80fd\u591f\u5229\u7528\u8fd9\u4e9b\u7cfb\u7edf\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684I/O\u57fa\u51c6\u6d4b\u8bd5\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u4e24\u8005\u90fd\u8868\u73b0\u4f18\u5f02\uff0c\u4f46DAOS\u5728\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\u65b9\u9762\u4f18\u4e8eCeph\u548cLustre\uff0c\u4e3a\u5927\u89c4\u6a21I/O\u64cd\u4f5c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u652f\u6301\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u754c\u4e0e\u5de5\u4e1a\u754c\u7684\u96c4\u5fc3\u4e0d\u65ad\u589e\u957f\uff0c\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u53ca\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5e94\u7528\u5982\u4e1a\u52a1\u6570\u503c\u5929\u6c14\u9884\u62a5\u9700\u8981\u5c3d\u53ef\u80fd\u5feb\u901f\u5730\u5904\u7406\u5e76\u5b58\u50a8\u8d8a\u6765\u8d8a\u591a\u7684\u6570\u636e\u91cf\u3002\u867d\u7136POSIX\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edf\u4e0eNVMe SSD\u662f\u5f53\u524d\u5e38\u89c1\u7684HPC\u5b58\u50a8\u914d\u7f6e\uff0c\u4f46\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u6d8c\u73b0\u6216\u6d41\u884c\u8d77\u6765\u7684\u65b0\u5b58\u50a8\u89e3\u51b3\u65b9\u6848\u53ef\u80fd\u89e3\u51b3\u67d0\u4e9bI/O\u5de5\u4f5c\u8d1f\u8f7d\u4e0bPOSIX\u6587\u4ef6\u7cfb\u7edf\u5728\u89c4\u6a21\u4e0a\u8868\u73b0\u51fa\u7684\u6027\u80fd\u9650\u5236\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4e3b\u8981\u9488\u5bf9\u4e24\u4e2a\u5bf9\u8c61\u5b58\u50a8\u7cfb\u7edf\u2014\u2014\u5373DAOS\u548cCeph\u2014\u2014\u5bf9ECMWF\u8fd0\u8425\u4e2d\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\u4ee5\u53ca\u5176\u4ed6HPC\u548cAI\u5e94\u7528\u7a0b\u5e8f\u7684\u9002\u7528\u6027\u4e0e\u6027\u80fd\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u4e3a\u6b64\u5f00\u53d1\u4e86\u65b0\u7684\u8f6f\u4ef6\u5c42\u9762\u9002\u914d\u5668\u4ee5\u652f\u6301ECMWF NWP\u4f7f\u7528\u8fd9\u4e9b\u7cfb\u7edf\uff0c\u5e76\u4e14\u5728\u51e0\u53f0\u8ba1\u7b97\u673a\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684I/O\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u6240\u8bc4\u4ef7\u7684\u5bf9\u8c61\u5b58\u50a8\u7cfb\u7edf\u7684\u6027\u80fd\u4e0e\u76f8\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\u90e8\u7f72\u7684Lustre\u6587\u4ef6\u7cfb\u7edf\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1DAOS\u548cCeph\u90fd\u5c55\u793a\u4e86\u51fa\u8272\u7684\u6027\u80fd\uff0c\u4f46\u76f8\u6bd4Ceph\u548cLustre\uff0cDAOS\u5c55\u73b0\u51fa\u66f4\u4f18\u7684\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\uff0c\u66f4\u9002\u5408\u4e8e\u5e0c\u671b\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e0b\u6267\u884cI/O\u64cd\u4f5c\u7684\u5e94\u7528\u7a0b\u5e8f\u3002\u8fd9\u8868\u660e\uff0c\u672a\u6765\u51e0\u5e74\u5185HPC\u4e2d\u5fc3\u53ef\u80fd\u4f1a\u66f4\u591a\u91c7\u7528DAOS\u7b49\u5bf9\u8c61\u5b58\u50a8\u6280\u672f\uff0c\u4f46\u8fd9\u5e76\u4e0d\u610f\u5473\u7740\u4f1a\u5b8c\u5168\u8f6c\u5411\u975ePOSIX\u7c7b\u578b\u7684I/O\u65b9\u6cd5\u3002", "conclusion": "DAOS\u548cCeph\u4e24\u79cd\u5bf9\u8c61\u5b58\u50a8\u7cfb\u7edf\u90fd\u8bc1\u660e\u4e86\u5b83\u4eec\u80fd\u591f\u6709\u6548\u652f\u6301HPC\u548cAI\u5e94\u7528\u7684\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u3002\u5176\u4e2d\uff0cDAOS\u56e0\u5176\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u548c\u7075\u6d3b\u6027\u800c\u663e\u5f97\u5c24\u4e3a\u7a81\u51fa\uff0c\u9884\u793a\u7740\u5bf9\u8c61\u5b58\u50a8\u6280\u672f\u5728\u672a\u6765HPC\u8bbe\u65bd\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.17112", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17112", "abs": "https://arxiv.org/abs/2602.17112", "authors": ["Arjun Ashok", "Nafiz Imtiaz Khan", "Swati Singhvi", "Stefan Stanciulescu", "Zhouhao Wang", "Vladimir Filkov"], "title": "Multi-Ecosystem Modeling of OSS Project Sustainability", "comment": "42 pages, 11 figures", "summary": "Many OSS projects join foundations such as Apache, Eclipse, and OSGeo, to aid their immediate plans and improve long-term prospects by getting governance advice, incubation support, and community-building mechanisms. But foundations differ in their policies, funding models, and support strategies. Moreover, since projects joining these foundations are diverse, coming at different lifecycle stages and having different needs, it can be challenging to decide on the appropriate project-foundation match and on the project-specific plan for sustainability.\n  Here, we present an empirical study and quantitative analysis of the sustainability of incubator projects in the Apache, Eclipse, and OSGeo foundations, and, additionally, of OSS projects from GitHub outside of foundations. We develop foundation-specific sustainability models and a project triage, based on projects' sociotechnical trace profiles, and demonstrate their effectiveness across the foundations. Our results show that our models with triage can effectively forecast sustainability outcomes not only within but across foundations. In addition, the generalizability of the framework allows us to apply the approach to GitHub projects outside the foundations. We complement our findings with actionable recovery strategies from previous work and apply them to case studies of failed incubator projects. Our study highlights the value of sociotechnical frameworks in characterizing and addressing software project sustainability issues.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u548c\u5b9a\u91cf\u5206\u6790\uff0c\u63a2\u8ba8\u4e86Apache\u3001Eclipse\u548cOSGeo\u57fa\u91d1\u4f1a\u5b75\u5316\u9879\u76ee\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u5e76\u4e14\u4e5f\u8003\u5bdf\u4e86GitHub\u4e0a\u975e\u57fa\u91d1\u4f1a\u7684\u5f00\u6e90\u9879\u76ee\u3002\u57fa\u4e8e\u9879\u76ee\u793e\u4f1a\u6280\u672f\u8ffd\u8e2a\u6982\u51b5\u5f00\u53d1\u4e86\u7279\u5b9a\u4e8e\u57fa\u91d1\u4f1a\u7684\u53ef\u6301\u7eed\u6027\u6a21\u578b\u53ca\u9879\u76ee\u5206\u7c7b\u65b9\u6cd5\uff0c\u8bc1\u660e\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4ec5\u5728\u57fa\u91d1\u4f1a\u5185\u90e8\u800c\u4e14\u8de8\u57fa\u91d1\u4f1a\u90fd\u80fd\u6709\u6548\u9884\u6d4b\u53ef\u6301\u7eed\u6027\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u88ab\u5e94\u7528\u4e8eGitHub\u4e0a\u975e\u57fa\u91d1\u4f1a\u7684\u9879\u76ee\uff0c\u5e76\u7ed3\u5408\u53ef\u64cd\u4f5c\u7684\u6062\u590d\u7b56\u7565\u5bf9\u5931\u8d25\u6848\u4f8b\u8fdb\u884c\u4e86\u7814\u7a76\u3002", "motivation": "\u8bb8\u591a\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u9879\u76ee\u52a0\u5165\u5230\u5982Apache\u3001Eclipse\u548cOSGeo\u7b49\u57fa\u91d1\u4f1a\u4e2d\u4ee5\u83b7\u5f97\u6cbb\u7406\u5efa\u8bae\u3001\u5b75\u5316\u652f\u6301\u548c\u793e\u533a\u5efa\u8bbe\u673a\u5236\u6765\u5e2e\u52a9\u5b9e\u73b0\u5176\u77ed\u671f\u8ba1\u5212\u5e76\u6539\u5584\u957f\u671f\u524d\u666f\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5404\u57fa\u91d1\u4f1a\u5728\u653f\u7b56\u3001\u8d44\u91d1\u6a21\u5f0f\u548c\u652f\u6301\u7b56\u7565\u4e0a\u7684\u5dee\u5f02\u4ee5\u53ca\u52a0\u5165\u57fa\u91d1\u4f1a\u7684\u9879\u76ee\u5728\u5176\u751f\u547d\u5468\u671f\u9636\u6bb5\u548c\u9700\u6c42\u65b9\u9762\u5b58\u5728\u591a\u6837\u6027\uff0c\u56e0\u6b64\u786e\u5b9a\u5408\u9002\u7684\u9879\u76ee-\u57fa\u91d1\u4f1a\u5339\u914d\u5ea6\u53ca\u5236\u5b9a\u9879\u76ee\u7279\u5f02\u6027\u53ef\u6301\u7eed\u53d1\u5c55\u8ba1\u5212\u53d8\u5f97\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u5b9e\u8bc1\u7814\u7a76\u4e0e\u5b9a\u91cf\u5206\u6790\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u9488\u5bf9Apache\u3001Eclipse\u548cOSGeo\u4e09\u4e2a\u57fa\u91d1\u4f1a\u4e2d\u7684\u5b75\u5316\u9879\u76ee\u4ee5\u53caGitHub\u4e0a\u4e0d\u5c5e\u4e8e\u4efb\u4f55\u57fa\u91d1\u4f1a\u7684OSS\u9879\u76ee\u8fdb\u884c\u4e86\u7814\u7a76\u3002\u6839\u636e\u9879\u76ee\u7684\u793e\u4f1a\u6280\u672f\u8ffd\u8e2a\u60c5\u51b5\u5efa\u7acb\u4e86\u7279\u5b9a\u4e8e\u6bcf\u4e2a\u57fa\u91d1\u4f1a\u7684\u53ef\u6301\u7eed\u6027\u6a21\u578b\u53ca\u4e00\u79cd\u9879\u76ee\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u57fa\u91d1\u4f1a\u95f4\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u5e26\u6709\u9879\u76ee\u5206\u7c7b\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u9884\u6d4b\u5404\u4e2a\u57fa\u91d1\u4f1a\u5185\u5916\u9879\u76ee\u7684\u53ef\u6301\u7eed\u6027\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8fd8\u53ef\u4ee5\u63a8\u5e7f\u5230\u57fa\u91d1\u4f1a\u5916\u7684GitHub\u9879\u76ee\u3002\u901a\u8fc7\u5bf9\u4ee5\u5f80\u5de5\u4f5c\u7684\u53ef\u6267\u884c\u6062\u590d\u7b56\u7565\u7684\u5e94\u7528\uff0c\u4e3a\u5931\u8d25\u7684\u5b75\u5316\u5668\u9879\u76ee\u63d0\u4f9b\u4e86\u6848\u4f8b\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u793e\u4f1a\u6280\u672f\u6846\u67b6\u5728\u63cf\u8ff0\u548c\u89e3\u51b3\u8f6f\u4ef6\u9879\u76ee\u53ef\u6301\u7eed\u6027\u95ee\u9898\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.16746", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16746", "abs": "https://arxiv.org/abs/2602.16746", "authors": ["Yongzhong Xu"], "title": "Low-Dimensional and Transversely Curved Optimization Dynamics in Grokking", "comment": "29 pages, 22 figures", "summary": "Grokking -- the delayed transition from memorization to generalization in small algorithmic tasks -- remains poorly understood. We present a geometric analysis of optimization dynamics in transformers trained on modular arithmetic. PCA of attention weight trajectories reveals that training evolves predominantly within a low-dimensional execution subspace, with a single principal component capturing 68-83% of trajectory variance. To probe loss-landscape geometry, we measure commutator defects -- the non-commutativity of successive gradient steps -- and project them onto this learned subspace. We find that curvature grows sharply in directions orthogonal to the execution subspace while the trajectory remains largely confined to it. Importantly, curvature growth consistently precedes generalization across learning rates and hyperparameter regimes, with the lead time obeying a power law in the grokking timescale. Causal intervention experiments show that motion along the learned subspace is necessary for grokking, while artificially increasing curvature is insufficient. Together, these results support a geometric account in which grokking reflects escape from a metastable regime characterized by low-dimensional confinement and transverse curvature accumulation. All findings replicate across this learning-rate range, a qualitatively different slow regime (lr=5e-5, wd=0.1, 3 layers), and three random seeds, though alignment dynamics differ quantitatively between regimes. Causal intervention experiments establish that orthogonal gradient flow is necessary but not sufficient for grokking: suppressing it prevents generalization with a monotonic dose-response across four operations, while artificially boosting curvature defects has no effect.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u51e0\u4f55\u5206\u6790\u7814\u7a76\u4e86Transformer\u5728\u6a21\u7b97\u672f\u4efb\u52a1\u4e2d\u8bad\u7ec3\u65f6\u4ece\u8bb0\u5fc6\u5230\u6cdb\u5316\u7684\u5ef6\u8fdf\u8f6c\u53d8\uff08\u5373Grokking\u73b0\u8c61\uff09\uff0c\u53d1\u73b0\u4e3b\u8981\u5728\u4f4e\u7ef4\u6267\u884c\u5b50\u7a7a\u95f4\u5185\u8fdb\u884c\uff0c\u5e76\u4e14\u5728\u6b64\u5b50\u7a7a\u95f4\u6b63\u4ea4\u65b9\u5411\u4e0a\u7684\u66f2\u7387\u589e\u957f\u662f\u6cdb\u5316\u53d1\u751f\u524d\u7684\u91cd\u8981\u6807\u5fd7\u3002", "motivation": "\u4e3a\u4e86\u89e3\u91ca\u5c0f\u578b\u7b97\u6cd5\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u4ece\u7b80\u5355\u8bb0\u5fc6\u8f6c\u5411\u771f\u6b63\u7406\u89e3\uff08Grokking\uff09\u8fd9\u4e00\u5ef6\u8fdf\u8f6c\u53d8\u80cc\u540e\u7684\u673a\u5236\u3002", "method": "\u91c7\u7528PCA\u5bf9\u6ce8\u610f\u529b\u6743\u91cd\u8f68\u8ff9\u8fdb\u884c\u4e86\u5206\u6790\uff1b\u6d4b\u91cf\u4e86\u68af\u5ea6\u6b65\u4e4b\u95f4\u975e\u4ea4\u6362\u6027\u7684\u7f3a\u9677\u503c\uff0c\u5e76\u5c06\u5176\u6295\u5f71\u5230\u4e86\u5b66\u4e60\u5f97\u5230\u7684\u5b50\u7a7a\u95f4\u4e0a\uff1b\u8fdb\u884c\u4e86\u56e0\u679c\u5e72\u9884\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u6cbf\u7740\u5b66\u4e60\u5b50\u7a7a\u95f4\u79fb\u52a8\u5bf9\u4e8eGrokking\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u589e\u52a0\u66f2\u7387\u662f\u5426\u8db3\u591f\u4fc3\u4f7fGrokking\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u8fc7\u7a0b\u4e3b\u8981\u5728\u4e00\u4e2a\u4f4e\u7ef4\u6267\u884c\u5b50\u7a7a\u95f4\u5185\u8fdb\u884c\uff0c\u8be5\u5b50\u7a7a\u95f4\u7684\u4e00\u4e2a\u4e3b\u6210\u5206\u53ef\u4ee5\u89e3\u91ca\u8f68\u8ff9\u65b9\u5dee\u768468-83%\uff1b\u6b63\u4ea4\u4e8e\u6267\u884c\u5b50\u7a7a\u95f4\u7684\u65b9\u5411\u4e0a\u89c2\u5bdf\u5230\u66f2\u7387\u663e\u8457\u589e\u957f\uff0c\u800c\u8fd9\u79cd\u589e\u957f\u901a\u5e38\u53d1\u751f\u5728\u6cdb\u5316\u4e4b\u524d\uff1b\u4ec5\u6cbf\u7740\u5b66\u4e60\u5b50\u7a7a\u95f4\u79fb\u52a8\u662fGrokking\u6240\u5fc5\u9700\u7684\uff0c\u4f46\u5355\u72ec\u589e\u52a0\u66f2\u7387\u5e76\u4e0d\u8db3\u4ee5\u5f15\u53d1Grokking\u3002", "conclusion": "Grokking\u53cd\u6620\u4e86\u4ece\u4e00\u4e2a\u7279\u5f81\u4e3a\u4f4e\u7ef4\u9650\u5236\u548c\u6a2a\u5411\u66f2\u7387\u7d2f\u79ef\u7684\u4e9a\u7a33\u6001\u533a\u57df\u9003\u9038\u7684\u8fc7\u7a0b\u3002"}}
{"id": "2602.17552", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17552", "abs": "https://arxiv.org/abs/2602.17552", "authors": ["Tripti Agarwal", "Sheng Di", "Xin Liang", "Zhaoyuan Su", "Yuxiao Li", "Ganesh Gopalakrishnan", "Hanqi Guo", "Franck Cappello"], "title": "TopoSZp: Lightweight Topology-Aware Error-controlled Compression for Scientific Data", "comment": "11 pages, 9 figures, 2 tables", "summary": "Error-bounded lossy compression is essential for managing the massive data volumes produced by large-scale HPC simulations. While state-of-the-art compressors such as SZ and ZFP provide strong numerical error guarantees, they often fail to preserve topological structures (example, minima, maxima, and saddle points) that are critical for scientific analysis. Existing topology-aware compressors address this limitation but incur substantial computational overhead. We present TopoSZp, a lightweight, topology-aware, error-controlled lossy compressor that preserves critical points and their relationships while maintaining high compression and decompression performance. Built on the high-throughput SZp compressor, TopoSZp integrates efficient critical point detection, local ordering preservation, and targeted saddle point refinement, all within a relaxed but strictly enforced error bound. Experimental results on real-world scientific datasets show that TopoSZp achieves 3 to 100 times fewer non-preserved critical points, introduces no false positives or incorrect critical point types, and delivers 100 to 10000 times faster compression and 10 to 500 times faster decompression compared to existing topology-aware compressors, while maintaining competitive compression ratios.", "AI": {"tldr": "TopoSZp\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u62d3\u6251\u611f\u77e5\u7684\u3001\u8bef\u5dee\u63a7\u5236\u7684\u6709\u635f\u538b\u7f29\u5668\uff0c\u5b83\u80fd\u6709\u6548\u4fdd\u5b58\u5173\u952e\u70b9\u53ca\u5176\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u538b\u7f29\u548c\u89e3\u538b\u7f29\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u6548\u538b\u7f29\u5668\u5982SZ\u548cZFP\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u6570\u503c\u8bef\u5dee\u4fdd\u8bc1\uff0c\u4f46\u5f80\u5f80\u65e0\u6cd5\u4fdd\u7559\u5bf9\u79d1\u5b66\u5206\u6790\u81f3\u5173\u91cd\u8981\u7684\u62d3\u6251\u7ed3\u6784\uff08\u4f8b\u5982\u6700\u5c0f\u503c\u3001\u6700\u5927\u503c\u548c\u978d\u70b9\uff09\u3002\u800c\u73b0\u5b58\u7684\u62d3\u6251\u611f\u77e5\u538b\u7f29\u5668\u867d\u7136\u89e3\u51b3\u4e86\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u5374\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u4fdd\u7559\u5173\u952e\u62d3\u6251\u7279\u5f81\u53c8\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u662f\u975e\u5e38\u5fc5\u8981\u7684\u3002", "method": "\u57fa\u4e8e\u9ad8\u541e\u5410\u91cf\u7684SZp\u538b\u7f29\u5668\uff0cTopoSZp\u96c6\u6210\u4e86\u6709\u6548\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u3001\u5c40\u90e8\u6392\u5e8f\u4fdd\u62a4\u4ee5\u53ca\u6709\u9488\u5bf9\u6027\u7684\u978d\u70b9\u7ec6\u5316\u6280\u672f\uff0c\u5728\u4e00\u4e2a\u5bbd\u677e\u4f46\u4e25\u683c\u5b9e\u65bd\u7684\u8bef\u5dee\u8303\u56f4\u5185\u8fd0\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u62d3\u6251\u611f\u77e5\u538b\u7f29\u5668\u76f8\u6bd4\uff0cTopoSZp\u5728\u771f\u5b9e\u4e16\u754c\u79d1\u5b66\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e863\u5230100\u500d\u66f4\u5c11\u7684\u975e\u4fdd\u7559\u5173\u952e\u70b9\uff0c\u6ca1\u6709\u5f15\u5165\u5047\u9633\u6027\u6216\u4e0d\u6b63\u786e\u7684\u5173\u952e\u70b9\u7c7b\u578b\uff0c\u5e76\u4e14\u538b\u7f29\u901f\u5ea6\u5feb\u4e86100\u523010000\u500d\uff0c\u89e3\u538b\u7f29\u901f\u5ea6\u5feb\u4e8610\u5230500\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u7684\u538b\u7f29\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51faTopoSZp\uff0c\u7814\u7a76\u8005\u4eec\u6210\u529f\u5730\u4e3a\u5927\u89c4\u6a21HPC\u6a21\u62df\u4ea7\u751f\u7684\u6d77\u91cf\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e2\u80fd\u591f\u6709\u6548\u4fdd\u5b58\u91cd\u8981\u62d3\u6251\u7279\u5f81\u53c8\u62e5\u6709\u51fa\u8272\u6027\u80fd\u8868\u73b0\u7684\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.17131", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17131", "abs": "https://arxiv.org/abs/2602.17131", "authors": ["Yuki Takei", "Toshiaki Aoki", "Chaiyong Ragkhitwetsagul"], "title": "Quantifying Competitive Relationships Among Open-Source Software Projects", "comment": "12 pages, 3 figures, 7 tables. Accepted at MSR 2026", "summary": "Throughout the history of software, evolution has occurred in cycles of rise and fall driven by competition, and open-source software (OSS) is no exception. This cycle is accelerating, particularly in rapidly evolving domains such as web development and deep learning. However, the impact of competitive relationships among OSS projects on their survival remains unclear, and there are risks of losing a competitive edge to rivals. To address this, this study proposes a new automated method called ``Mutual Impact Analysis of OSS (MIAO)'' to quantify these competitive relationships. The proposed method employs a structural vector autoregressive model and impulse response functions, normally used in macroeconomic analysis, to analyze the interactions among OSS projects. In an empirical analysis involving mining and analyzing 187 OSS project groups, MIAO identified projects that were forced to cease development owing to competitive influences with up to 81\\% accuracy, and the resulting features supported predictive experiments that anticipate cessation one year ahead with up to 77\\% accuracy. This suggests that MIAO could be a valuable tool for OSS project maintainers to understand the dynamics of OSS ecosystems and predict the rise and fall of OSS projects.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMIAO\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u95f4\u7684\u7ade\u4e89\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u5c55\u793a\u4e86\u5176\u5728\u9884\u6d4b\u9879\u76ee\u7ec8\u6b62\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u9886\u57df\u5185\u7684\u7ade\u4e89\u5bf9\u5176\u751f\u5b58\u7684\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\uff0c\u5b58\u5728\u5931\u53bb\u7ade\u4e89\u4f18\u52bf\u7ed9\u7ade\u4e89\u5bf9\u624b\u7684\u98ce\u9669\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u79cd\u60c5\u51b5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u91cf\u5316\u8fd9\u4e9b\u7ade\u4e89\u5173\u7cfb\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a'Mutual Impact Analysis of OSS (MIAO)'\u7684\u65b0\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u7ed3\u6784\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u548c\u8109\u51b2\u54cd\u5e94\u51fd\u6570\uff08\u901a\u5e38\u7528\u4e8e\u5b8f\u89c2\u7ecf\u6d4e\u5206\u6790\u4e2d\uff09\u6765\u5206\u6790OSS\u9879\u76ee\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u901a\u8fc7\u5bf9187\u4e2aOSS\u9879\u76ee\u7ec4\u8fdb\u884c\u6316\u6398\u548c\u5206\u6790\uff0cMIAO\u80fd\u591f\u4ee5\u9ad8\u8fbe81%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u51fa\u56e0\u7ade\u4e89\u5f71\u54cd\u800c\u88ab\u8feb\u505c\u6b62\u5f00\u53d1\u7684\u9879\u76ee\uff0c\u5e76\u4e14\u751f\u6210\u7684\u7279\u5f81\u652f\u6301\u4e86\u63d0\u524d\u4e00\u5e74\u9884\u6d4b\u505c\u6b62\u60c5\u51b5\u7684\u5b9e\u9a8c\uff0c\u51c6\u786e\u7387\u8fbe\u523077%\u3002", "conclusion": "MIAO\u53ef\u4ee5\u6210\u4e3aOSS\u9879\u76ee\u7ef4\u62a4\u8005\u4e86\u89e3OSS\u751f\u6001\u7cfb\u7edf\u52a8\u6001\u53ca\u9884\u6d4b\u9879\u76ee\u5174\u8870\u8d8b\u52bf\u7684\u5b9d\u8d35\u5de5\u5177\u3002"}}
{"id": "2602.16747", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16747", "abs": "https://arxiv.org/abs/2602.16747", "authors": ["Xidong Wang", "Shuqi Guo", "Yue Shen", "Junying Chen", "Jian Wang", "Jinjie Gu", "Ping Zhang", "Lei Liu", "Benyou Wang"], "title": "LiveClin: A Live Clinical Benchmark without Leakage", "comment": null, "summary": "The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for approximating real-world clinical practice. Built from contemporary, peer-reviewed case reports and updated biannually, LiveClin ensures clinical currency and resists data contamination. Using a verified AI-human workflow involving 239 physicians, we transform authentic patient cases into complex, multimodal evaluation scenarios that span the entire clinical pathway. The benchmark currently comprises 1,407 case reports and 6,605 questions. Our evaluation of 26 models on LiveClin reveals the profound difficulty of these real-world scenarios, with the top-performing model achieving a Case Accuracy of just 35.7%. In benchmarking against human experts, Chief Physicians achieved the highest accuracy, followed closely by Attending Physicians, with both surpassing most models. LiveClin thus provides a continuously evolving, clinically grounded framework to guide the development of medical LLMs towards closing this gap and achieving greater reliability and real-world utility. Our data and code are publicly available at https://github.com/AQ-MedAI/LiveClin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLiveClin\u7684\u5b9e\u65f6\u57fa\u51c6\uff0c\u65e8\u5728\u89e3\u51b3\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u548c\u77e5\u8bc6\u8fc7\u65f6\u95ee\u9898\u3002\u901a\u8fc7\u4f7f\u7528\u5f53\u4ee3\u540c\u884c\u8bc4\u5ba1\u7684\u75c5\u4f8b\u62a5\u544a\u6784\u5efa\uff0c\u5e76\u6bcf\u534a\u5e74\u66f4\u65b0\u4e00\u6b21\uff0c\u786e\u4fdd\u4e86\u4e34\u5e8a\u76f8\u5173\u6027\u548c\u9632\u6b62\u6570\u636e\u6c61\u67d3\u3002\u7ecf26\u4e2a\u6a21\u578b\u6d4b\u8bd5\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u4ec5\u4e3a35.7%\uff0c\u8868\u660e\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e0b\u7684\u6311\u6218\u6027\u3002", "motivation": "\u7531\u4e8e\u6570\u636e\u6c61\u67d3\u548c\u77e5\u8bc6\u8fc7\u65f6\u95ee\u9898\uff0c\u73b0\u6709\u7684\u9759\u6001\u57fa\u51c6\u5728\u8bc4\u4f30\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65f6\u5b58\u5728\u53ef\u9760\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u66f4\u8d34\u8fd1\u5b9e\u9645\u4e34\u5e8a\u5b9e\u8df5\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u53cd\u6620\u6700\u65b0\u533b\u5b66\u8fdb\u5c55\u4e14\u907f\u514d\u6570\u636e\u6c61\u67d3\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aLiveClin\u7684\u5b9e\u65f6\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u57fa\u4e8e\u6700\u65b0\u7684\u540c\u884c\u8bc4\u5ba1\u6848\u4f8b\u62a5\u544a\u6784\u5efa\uff0c\u5e76\u5b9a\u671f\u66f4\u65b0\u4ee5\u4fdd\u6301\u4fe1\u606f\u7684\u65f6\u6548\u6027\uff1b\u5229\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4eba\u5de5\u667a\u80fd-\u4eba\u7c7b\u5de5\u4f5c\u6d41\u7a0b\u5c06\u771f\u5b9e\u7684\u60a3\u8005\u6848\u4f8b\u8f6c\u5316\u4e3a\u590d\u6742\u7684\u591a\u6a21\u6001\u8bc4\u4f30\u60c5\u666f\uff0c\u6db5\u76d6\u6574\u4e2a\u4e34\u5e8a\u8def\u5f84\uff1b\u5bf926\u4e2a\u4e0d\u540c\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "LiveClin\u76ee\u524d\u5305\u542b1,407\u4efd\u6848\u4f8b\u62a5\u544a\u548c6,605\u4e2a\u95ee\u9898\uff1b\u6700\u4f73\u8868\u73b0\u6a21\u578b\u7684\u6848\u4f8b\u51c6\u786e\u7387\u4e3a35.7%\uff1b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u6bd4\uff0c\u4e3b\u4efb\u533b\u5e08\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u968f\u540e\u662f\u4e3b\u6cbb\u533b\u5e08\uff0c\u4e24\u8005\u90fd\u8d85\u8fc7\u4e86\u5927\u591a\u6570\u6a21\u578b\u7684\u8868\u73b0\u3002", "conclusion": "LiveClin\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6301\u7eed\u53d1\u5c55\u3001\u57fa\u4e8e\u4e34\u5e8a\u7684\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u66f4\u52a0\u53ef\u9760\u5e76\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.17264", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17264", "abs": "https://arxiv.org/abs/2602.17264", "authors": ["Michael M\u00fcller", "Amir Reza Mohammadi", "Andreas Peintner", "Beatriz Barroso Gstrein", "G\u00fcnther Specht", "Eva Zangerle"], "title": "On the Reliability of User-Centric Evaluation of Conversational Recommender Systems", "comment": "5 pages, 2 figures. Submitted to UMAP 2026. Code available at https://github.com/michael-mue/reliable-crs-eval", "summary": "User-centric evaluation has become a key paradigm for assessing Conversational Recommender Systems (CRS), aiming to capture subjective qualities such as satisfaction, trust, and rapport. To enable scalable evaluation, recent work increasingly relies on third-party annotations of static dialogue logs by crowd workers or large language models. However, the reliability of this practice remains largely unexamined. In this paper, we present a large-scale empirical study investigating the reliability and structure of user-centric CRS evaluation on static dialogue transcripts. We collected 1,053 annotations from 124 crowd workers on 200 ReDial dialogues using the 18-dimensional CRS-Que framework. Using random-effects reliability models and correlation analysis, we quantify the stability of individual dimensions and their interdependencies. Our results show that utilitarian and outcome-oriented dimensions such as accuracy, usefulness, and satisfaction achieve moderate reliability under aggregation, whereas socially grounded constructs such as humanness and rapport are substantially less reliable. Furthermore, many dimensions collapse into a single global quality signal, revealing a strong halo effect in third-party judgments. These findings challenge the validity of single-annotator and LLM-based evaluation protocols and motivate the need for multi-rater aggregation and dimension reduction in offline CRS evaluation.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u9759\u6001\u5bf9\u8bdd\u8bb0\u5f55\u7684\u7528\u6237\u4e2d\u5fc3\u578b\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u548c\u7ed3\u6784\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u5b9e\u7528\u6027\u53ca\u7ed3\u679c\u5bfc\u5411\u7ef4\u5ea6\u5982\u51c6\u786e\u6027\u3001\u6709\u7528\u6027\u548c\u6ee1\u610f\u5ea6\u5728\u805a\u5408\u540e\u8fbe\u5230\u4e86\u4e2d\u7b49\u53ef\u9760\u6027\uff0c\u800c\u793e\u4f1a\u6027\u57fa\u7840\u6784\u5efa\u5982\u4eba\u6027\u548c\u9ed8\u5951\u5ea6\u5219\u660e\u663e\u4e0d\u592a\u53ef\u9760\u3002\u6b64\u5916\uff0c\u8bb8\u591a\u7ef4\u5ea6\u88ab\u7b80\u5316\u4e3a\u5355\u4e00\u7684\u6574\u4f53\u8d28\u91cf\u4fe1\u53f7\uff0c\u63ed\u793a\u4e86\u7b2c\u4e09\u65b9\u8bc4\u5224\u4e2d\u7684\u5f3a\u70c8\u5149\u73af\u6548\u5e94\u3002", "motivation": "\u7531\u4e8e\u7528\u6237\u4e2d\u5fc3\u578b\u8bc4\u4f30\u5df2\u6210\u4e3a\u8861\u91cf\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u5173\u952e\u8303\u5f0f\uff0c\u65e8\u5728\u6355\u6349\u8bf8\u5982\u6ee1\u610f\u5ea6\u3001\u4fe1\u4efb\u548c\u9ed8\u5951\u7b49\u4e3b\u89c2\u54c1\u8d28\uff0c\u4f46\u8fd9\u79cd\u505a\u6cd5\u7684\u53ef\u9760\u6027\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u68c0\u9a8c\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8c03\u67e5\u57fa\u4e8e\u9759\u6001\u5bf9\u8bdd\u8bb0\u5f55\u7684\u7528\u6237\u4e2d\u5fc3\u578b\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u548c\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u6536\u96c6124\u540d\u4f17\u5305\u5de5\u4f5c\u8005\u5bf9200\u4e2aReDial\u5bf9\u8bdd\u6309\u716718\u7ef4CRS-Que\u6846\u67b6\u8fdb\u884c\u76841,053\u6b21\u6ce8\u91ca\uff0c\u5e76\u8fd0\u7528\u968f\u673a\u6548\u5e94\u53ef\u9760\u6027\u6a21\u578b\u548c\u76f8\u5173\u6027\u5206\u6790\u6765\u91cf\u5316\u5404\u4e2a\u7ef4\u5ea6\u7684\u7a33\u5b9a\u6027\u548c\u5b83\u4eec\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u50cf\u51c6\u786e\u6027\u3001\u6709\u7528\u6027\u548c\u6ee1\u610f\u5ea6\u8fd9\u6837\u7684\u5b9e\u7528\u6027\u548c\u7ed3\u679c\u5bfc\u5411\u7ef4\u5ea6\u5728\u805a\u5408\u540e\u5177\u6709\u4e2d\u7b49\u53ef\u9760\u6027\uff1b\u800c\u4eba\u6027\u5316\u548c\u9ed8\u5951\u5ea6\u8fd9\u7c7b\u4ee5\u793e\u4f1a\u4e3a\u57fa\u7840\u7684\u6784\u5ff5\u53ef\u9760\u6027\u663e\u8457\u8f83\u4f4e\u3002\u800c\u4e14\u5f88\u591a\u7ef4\u5ea6\u6700\u7ec8\u90fd\u5f52\u7ed3\u4e3a\u4e00\u4e2a\u5168\u5c40\u7684\u8d28\u91cf\u4fe1\u53f7\uff0c\u663e\u793a\u51fa\u7b2c\u4e09\u65b9\u8bc4\u4ef7\u4e2d\u5b58\u5728\u7684\u5f3a\u70c8\u5149\u73af\u6548\u5e94\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8d28\u7591\u4e86\u5355\u6807\u6ce8\u8005\u548c\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\u8bc4\u4f30\u534f\u8bae\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u79bb\u7ebf\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u8bc4\u4f30\u4e2d\u591a\u8bc4\u5206\u8005\u805a\u5408\u548c\u7ef4\u5ea6\u7f29\u51cf\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2602.17183", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17183", "abs": "https://arxiv.org/abs/2602.17183", "authors": ["Kishan Maharaj", "Nandakishore Menon", "Ashita Saxena", "Srikanth Tamilselvam"], "title": "Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering", "comment": "11 pages, 4 Figures, 5 Tables, Work in Progress", "summary": "Large language models (LLMs) increasingly assist software engineering tasks that require reasoning over long code contexts, yet their robustness under varying input conditions remains unclear. We conduct a systematic study of long-context code question answering using controlled ablations that test sensitivity to answer format, distractors, and context scale. Extending LongCodeBench Python dataset with new COBOL and Java question-answer sets, we evaluate state-of-the-art models under three settings: (i) shuffled multiple-choice options, (ii) open-ended questions and (iii) needle-in-a-haystack contexts containing relevant and adversarially irrelevant information. Results show substantial performance drops in both shuffled multiple-choice options and open-ended questions, and brittle behavior in the presence of irrelevant cues. Our findings highlight limitations of current long-context evaluations and provide a broader benchmark for assessing code reasoning in both legacy and modern systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u63a7\u5236\u6d88\u878d\u5b9e\u9a8c\u6765\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4ee3\u7801\u4e0a\u4e0b\u6587\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5305\u62ec\u7b54\u6848\u683c\u5f0f\u3001\u5e72\u6270\u9879\u548c\u4e0a\u4e0b\u6587\u89c4\u6a21\u7684\u654f\u611f\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u9009\u62e9\u9879\u6253\u4e71\u548c\u5f00\u653e\u5f0f\u95ee\u9898\u8bbe\u7f6e\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u4e14\u5728\u5b58\u5728\u4e0d\u76f8\u5173\u7ebf\u7d22\u65f6\u8868\u73b0\u8106\u5f31\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u6765\u8f85\u52a9\u9700\u8981\u5bf9\u957f\u4ee3\u7801\u8fdb\u884c\u63a8\u7406\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u4f46\u5b83\u4eec\u5728\u4e0d\u540c\u8f93\u5165\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u4ecd\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u8fd9\u9879\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e00\u7cfb\u5217\u53d7\u63a7\u5b9e\u9a8c\u6765\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u957f\u4ee3\u7801\u6587\u672c\u65f6\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u8005\u6269\u5c55\u4e86LongCodeBench Python\u6570\u636e\u96c6\uff0c\u65b0\u589e\u4e86COBOL\u548cJava\u7684\u95ee\u9898-\u7b54\u6848\u96c6\u5408\uff0c\u5e76\u5728\u4e09\u79cd\u8bbe\u5b9a\u4e0b\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff1a(i) \u6253\u4e71\u7684\u9009\u62e9\u9898\u9009\u9879 (ii) \u5f00\u653e\u5f0f\u95ee\u9898 (iii) \u5305\u542b\u76f8\u5173\u4e0e\u6076\u610f\u65e0\u5173\u4fe1\u606f\u7684'\u5927\u6d77\u635e\u9488'\u5f0f\u4e0a\u4e0b\u6587\u73af\u5883\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u9762\u5bf9\u6253\u4e71\u987a\u5e8f\u7684\u9009\u62e9\u9898\u9009\u9879\u4ee5\u53ca\u5f00\u653e\u5f0f\u95ee\u9898\u65f6\uff0c\u6a21\u578b\u7684\u8868\u73b0\u6709\u660e\u663e\u4e0b\u6ed1\uff1b\u540c\u65f6\uff0c\u5728\u9047\u5230\u4e0d\u76f8\u5173\u7684\u63d0\u793a\u4fe1\u606f\u65f6\uff0c\u6a21\u578b\u7684\u884c\u4e3a\u663e\u5f97\u5f88\u8106\u5f31\u3002", "conclusion": "\u5f53\u524d\u9488\u5bf9\u957f\u4ee3\u7801\u80cc\u666f\u4e0b\u7684\u8bc4\u4ef7\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u672c\u7814\u7a76\u63d0\u4f9b\u7684\u66f4\u5e7f\u6cdb\u7684\u57fa\u51c6\u53ef\u4ee5\u5e2e\u52a9\u66f4\u597d\u5730\u8bc4\u4f30\u73b0\u4ee3\u53ca\u9057\u7559\u7cfb\u7edf\u4e2d\u4ee3\u7801\u63a8\u7406\u7684\u80fd\u529b\u3002"}}
{"id": "2602.16762", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.16762", "abs": "https://arxiv.org/abs/2602.16762", "authors": ["Ayush Roy", "Tahsin Fuad Hassan", "Roshan Ayyalasomayajula", "Vishnu Suresh Lokhande"], "title": "Attending to Routers Aids Indoor Wireless Localization", "comment": "AAAI 2026 Workshop on Machine Learning for Wireless Communication and Networks (ML4Wireless)", "summary": "Modern machine learning-based wireless localization using Wi-Fi signals continues to face significant challenges in achieving groundbreaking performance across diverse environments. A major limitation is that most existing algorithms do not appropriately weight the information from different routers during aggregation, resulting in suboptimal convergence and reduced accuracy. Motivated by traditional weighted triangulation methods, this paper introduces the concept of attention to routers, ensuring that each router's contribution is weighted differently when aggregating information from multiple routers for triangulation. We demonstrate, by incorporating attention layers into a standard machine learning localization architecture, that emphasizing the relevance of each router can substantially improve overall performance. We have also shown through evaluation over the open-sourced datasets and demonstrate that Attention to Routers outperforms the benchmark architecture by over 30% in accuracy.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\u5230\u8def\u7531\u5668\u4e0a\uff0c\u6539\u8fdb\u4e86\u57fa\u4e8eWi-Fi\u4fe1\u53f7\u7684\u65e0\u7ebf\u5b9a\u4f4d\u7b97\u6cd5\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u8def\u7531\u5668\u7684\u4fe1\u606f\u5728\u805a\u5408\u65f6\u6839\u636e\u5176\u91cd\u8981\u6027\u88ab\u8d4b\u4e88\u4e0d\u540c\u7684\u6743\u91cd\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u5927\u591a\u6570\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u4f7f\u7528Wi-Fi\u4fe1\u53f7\u8fdb\u884c\u65e0\u7ebf\u5b9a\u4f4d\u7684\u65b9\u6cd5\u6ca1\u6709\u9002\u5f53\u8003\u8651\u4e0d\u540c\u8def\u7531\u5668\u4fe1\u606f\u7684\u91cd\u8981\u6027\uff0c\u5bfc\u81f4\u6536\u655b\u6548\u679c\u4e0d\u4f73\u4e14\u51c6\u786e\u6027\u964d\u4f4e\u3002\u53d7\u4f20\u7edf\u52a0\u6743\u4e09\u89d2\u6d4b\u91cf\u65b9\u6cd5\u542f\u53d1\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4e3a\u5404\u4e2a\u8def\u7531\u5668\u5206\u914d\u4e0d\u540c\u7684\u6743\u91cd\u6765\u4f18\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014\u5bf9\u8def\u7531\u5668\u65bd\u52a0\u6ce8\u610f\u529b\uff0c\u5373\u5728\u6807\u51c6\u673a\u5668\u5b66\u4e60\u5b9a\u4f4d\u67b6\u6784\u4e2d\u52a0\u5165\u6ce8\u610f\u529b\u5c42\uff0c\u4ee5\u5f3a\u8c03\u6bcf\u4e2a\u8def\u7531\u5668\u5bf9\u4e8e\u6700\u7ec8\u5b9a\u4f4d\u7ed3\u679c\u7684\u76f8\u5173\u6027\u548c\u8d21\u732e\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5f00\u6e90\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u57fa\u51c6\u67b6\u6784\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u9ad8\u8d85\u8fc730%\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u8def\u7531\u5668\u5f15\u5165\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u57fa\u4e8eWi-Fi\u4fe1\u53f7\u7684\u65e0\u7ebf\u5b9a\u4f4d\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.17327", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17327", "abs": "https://arxiv.org/abs/2602.17327", "authors": ["Michael Dinzinger", "Laura Caspari", "Ali Salman", "Irvin Topi", "Jelena Mitrovi\u0107", "Michael Granitzer"], "title": "WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval", "comment": null, "summary": "We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.", "AI": {"tldr": "WebFAQ 2.0, a significantly expanded and more diverse FAQ dataset covering 108 languages, introduces a novel data collection method and includes a hard negatives dataset for training dense retrievers. It supports two main fine-tuning strategies and is part of an ongoing effort with regular updates.", "motivation": "The motivation behind WebFAQ 2.0 is to provide a more comprehensive, multilingual, and contextually rich FAQ-based resource for natural question-answer pairs, addressing the limitations of its predecessor by expanding language coverage, increasing the number of bilingual aligned QA pairs, and offering a hard negatives dataset for better training of dense retrievers in response to community feedback.", "method": "WebFAQ 2.0 employs a new data collection strategy that directly crawls and extracts web content, leading to a more diverse and multilingual dataset. Additionally, it provides a hard negatives dataset mined using a two-stage retrieval pipeline, which is designed to improve the training of dense retrievers. The resource enables two primary fine-tuning strategies: Contrastive Learning with MultipleNegativesRanking loss and Knowledge Distillation with MarginMSE loss.", "result": "The result is a significantly larger and more diverse FAQ-based resource, with over 198 million QA pairs across 108 languages, including over 14.3 million bilingual aligned QA pairs. The introduction of a hard negatives dataset, containing 1.25 million queries across 20 languages, enhances the utility of WebFAQ 2.0 for training and improving dense retrievers. This version also initiates a long-term effort for continuous expansion and refinement via the Open Web Index.", "conclusion": "WebFAQ 2.0 represents a major advancement in FAQ-based datasets, offering extensive multilingual coverage, richer contextual information, and valuable resources for training and fine-tuning dense retrievers. Its ongoing development through the Open Web Index ensures it remains a dynamic and growing resource for the research community."}}
{"id": "2602.17614", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17614", "abs": "https://arxiv.org/abs/2602.17614", "authors": ["Obaidullah Zaland", "Sajib Mistry", "Monowar Bhuyan"], "title": "Guarding the Middle: Protecting Intermediate Representations in Federated Split Learning", "comment": "Accepted for Publication in IEEE International Conference on Big Data (IEEE BigData) 2025", "summary": "Big data scenarios, where massive, heterogeneous datasets are distributed across clients, demand scalable, privacy-preserving learning methods. Federated learning (FL) enables decentralized training of machine learning (ML) models across clients without data centralization. Decentralized training, however, introduces a computational burden on client devices. U-shaped federated split learning (UFSL) offloads a fraction of the client computation to the server while keeping both data and labels on the clients' side. However, the intermediate representations (i.e., smashed data) shared by clients with the server are prone to exposing clients' private data. To reduce exposure of client data through intermediate data representations, this work proposes k-anonymous differentially private UFSL (KD-UFSL), which leverages privacy-enhancing techniques such as microaggregation and differential privacy to minimize data leakage from the smashed data transferred to the server. We first demonstrate that an adversary can access private client data from intermediate representations via a data-reconstruction attack, and then present a privacy-enhancing solution, KD-UFSL, to mitigate this risk. Our experiments indicate that, alongside increasing the mean squared error between the actual and reconstructed images by up to 50% in some cases, KD-UFSL also decreases the structural similarity between them by up to 40% on four benchmarking datasets. More importantly, KD-UFSL improves privacy while preserving the utility of the global model. This highlights its suitability for large-scale big data applications where privacy and utility must be balanced.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdk-\u533f\u540d\u5dee\u5206\u9690\u79c1U\u5f62\u8054\u90a6\u5206\u88c2\u5b66\u4e60(KD-UFSL)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5fae\u805a\u5408\u548c\u5dee\u5206\u9690\u79c1\u7b49\u9690\u79c1\u589e\u5f3a\u6280\u672f\u6765\u6700\u5c0f\u5316\u4ece\u5ba2\u6237\u7aef\u4f20\u8f93\u5230\u670d\u52a1\u5668\u7684\u4e2d\u95f4\u6570\u636e(\u5373\u7c89\u788e\u6570\u636e)\u7684\u6570\u636e\u6cc4\u6f0f\u3002\u5b9e\u9a8c\u8868\u660e\uff0cKD-UFSL\u5728\u589e\u52a0\u5b9e\u9645\u4e0e\u91cd\u5efa\u56fe\u50cf\u4e4b\u95f4\u7684\u5747\u65b9\u8bef\u5dee\u7684\u540c\u65f6\uff0c\u4e5f\u964d\u4f4e\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u9690\u79c1\u6027\u540c\u65f6\u4fdd\u6301\u4e86\u5168\u5c40\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u5728\u5927\u6570\u636e\u573a\u666f\u4e2d\uff0c\u5206\u6563\u5f0f\u8bad\u7ec3\u867d\u7136\u53ef\u4ee5\u5b9e\u73b0\u8de8\u5ba2\u6237\u7aef\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u800c\u65e0\u9700\u96c6\u4e2d\u6570\u636e\uff0c\u4f46\u7ed9\u5ba2\u6237\u7aef\u8bbe\u5907\u5e26\u6765\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002U\u5f62\u8054\u90a6\u5206\u88c2\u5b66\u4e60\uff08UFSL\uff09\u80fd\u591f\u5c06\u90e8\u5206\u5ba2\u6237\u7aef\u8ba1\u7b97\u5378\u8f7d\u5230\u670d\u52a1\u5668\u4e0a\uff0c\u4f46\u5ba2\u6237\u5411\u670d\u52a1\u5668\u5171\u4eab\u7684\u4e2d\u95f4\u8868\u793a\u5bb9\u6613\u66b4\u9732\u5ba2\u6237\u7684\u79c1\u6709\u6570\u636e\u3002\u4e3a\u4e86\u51cf\u5c11\u901a\u8fc7\u4e2d\u95f4\u6570\u636e\u8868\u793a\u66b4\u9732\u5ba2\u6237\u6570\u636e\u7684\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u7ef4\u6301\u6a21\u578b\u6548\u7528\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86k-\u533f\u540d\u5dee\u5206\u9690\u79c1U\u5f62\u8054\u90a6\u5206\u88c2\u5b66\u4e60(KD-UFSL)\uff0c\u7ed3\u5408\u4f7f\u7528\u5fae\u805a\u5408\u548c\u5dee\u5206\u9690\u79c1\u6280\u672f\u4ee5\u51cf\u5c11\u7531\u7c89\u788e\u6570\u636e\u8f6c\u79fb\u81f3\u670d\u52a1\u5668\u65f6\u53ef\u80fd\u5f15\u53d1\u7684\u6570\u636e\u6cc4\u9732\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cKD-UFSL\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u5b9e\u9645\u4e0e\u91cd\u5efa\u56fe\u7247\u95f4\u7684\u5e73\u5747\u5e73\u65b9\u8bef\u5dee\u9ad8\u8fbe50%\uff0c\u5e76\u964d\u4f4e\u4e24\u8005\u4e4b\u95f4\u7ed3\u6784\u76f8\u4f3c\u5ea6\u8fbe40%\u3002\u6b64\u5916\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8fd8\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6539\u5584\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5168\u7403\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "KD-UFSL\u4e3a\u5927\u89c4\u6a21\u5927\u6570\u636e\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u8861\u9690\u79c1\u4e0e\u5b9e\u7528\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u4e8e\u9700\u8981\u540c\u65f6\u8003\u8651\u9690\u79c1\u4fdd\u62a4\u548c\u6a21\u578b\u6027\u80fd\u7684\u5927\u89c4\u6a21\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.17354", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17354", "abs": "https://arxiv.org/abs/2602.17354", "authors": ["Daniele Malitesta", "Emanuele Rossi", "Claudio Pomo", "Tommaso Di Noia", "Fragkiskos D. Malliaros"], "title": "Training-free Graph-based Imputation of Missing Modalities in Multimodal Recommendation", "comment": "Accepted in IEEE Transactions on Knowledge and Data Engineering (IEEE TKDE)", "summary": "Multimodal recommender systems (RSs) represent items in the catalog through multimodal data (e.g., product images and descriptions) that, in some cases, might be noisy or (even worse) missing. In those scenarios, the common practice is to drop items with missing modalities and train the multimodal RSs on a subsample of the original dataset. To date, the problem of missing modalities in multimodal recommendation has still received limited attention in the literature, lacking a precise formalisation as done with missing information in traditional machine learning. In this work, we first provide a problem formalisation for missing modalities in multimodal recommendation. Second, by leveraging the user-item graph structure, we re-cast the problem of missing multimodal information as a problem of graph features interpolation on the item-item co-purchase graph. On this basis, we propose four training-free approaches that propagate the available multimodal features throughout the item-item graph to impute the missing features. Extensive experiments on popular multimodal recommendation datasets demonstrate that our solutions can be seamlessly plugged into any existing multimodal RS and benchmarking framework while still preserving (or even widen) the performance gap between multimodal and traditional RSs. Moreover, we show that our graph-based techniques can perform better than traditional imputations in machine learning under different missing modalities settings. Finally, we analyse (for the first time in multimodal RSs) how feature homophily calculated on the item-item graph can influence our graph-based imputations.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u7531\u4e8e\u6570\u636e\u7f3a\u5931\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u586b\u8865\u7f3a\u5931\u7684\u591a\u6a21\u6001\u4fe1\u606f\u3002\u901a\u8fc7\u5c06\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u9879\u76ee-\u9879\u76ee\u5171\u8d2d\u56fe\u4e0a\u7684\u7279\u5f81\u63d2\u503c\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u56db\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u6765\u4f20\u64ad\u53ef\u7528\u7684\u591a\u6a21\u6001\u7279\u5f81\u4ee5\u586b\u8865\u7f3a\u5931\u7684\u90e8\u5206\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u4e0d\u4ec5\u80fd\u591f\u65e0\u7f1d\u5730\u96c6\u6210\u5230\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u800c\u4e14\u5728\u4e0d\u540c\u7f3a\u5931\u6a21\u6001\u8bbe\u7f6e\u4e0b\u6bd4\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u586b\u5145\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u5728\u56e0\u4e3a\u566a\u97f3\u6216\u4e22\u5931\u5bfc\u81f4\u7684\u6570\u636e\u4e0d\u5b8c\u6574\u95ee\u9898\uff0c\u901a\u5e38\u505a\u6cd5\u662f\u5220\u9664\u6709\u7f3a\u5931\u6a21\u6001\u7684\u6761\u76ee\u7136\u540e\u4ec5\u5728\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b50\u6837\u672c\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7f3a\u5931\u6a21\u6001\u7684\u95ee\u9898\uff0c\u5728\u6587\u732e\u4e2d\u8fd8\u6ca1\u6709\u5f97\u5230\u5145\u5206\u7684\u5173\u6ce8\u548c\u7cbe\u786e\u7684\u5f62\u5f0f\u5316\u63cf\u8ff0\u3002", "method": "\u6587\u7ae0\u9996\u5148\u5bf9\u591a\u6a21\u6001\u63a8\u8350\u4e2d\u7684\u7f3a\u5931\u6a21\u6001\u95ee\u9898\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u63cf\u8ff0\u3002\u63a5\u7740\u5229\u7528\u7528\u6237-\u9879\u76ee\u56fe\u7ed3\u6784\uff0c\u5c06\u7f3a\u5931\u591a\u6a21\u6001\u4fe1\u606f\u7684\u95ee\u9898\u8f6c\u5316\u4e3a\u9879\u76ee-\u9879\u76ee\u5171\u8d2d\u56fe\u4e0a\u7684\u7279\u5f81\u63d2\u503c\u95ee\u9898\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u56db\u79cd\u4e0d\u9700\u8981\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6574\u4e2a\u9879\u76ee-\u9879\u76ee\u56fe\u4e0a\u4f20\u64ad\u53ef\u7528\u7684\u591a\u6a21\u6001\u7279\u5f81\u6765\u4f30\u8ba1\u7f3a\u5931\u7279\u5f81\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6848\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u4e0e\u4efb\u4f55\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u548c\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u6574\u5408\uff0c\u540c\u65f6\u4fdd\u6301\uff08\u751a\u81f3\u6269\u5927\uff09\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e0e\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u9996\u6b21\u5206\u6790\u4e86\u9879\u76ee-\u9879\u76ee\u56fe\u4e0a\u8ba1\u7b97\u7684\u7279\u5f81\u540c\u8d28\u6027\u5982\u4f55\u5f71\u54cd\u57fa\u4e8e\u56fe\u7684\u586b\u8865\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5904\u7406\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u7f3a\u5931\u6a21\u6001\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u65b9\u6cd5\u5728\u591a\u79cd\u7f3a\u5931\u6a21\u6001\u8bbe\u5b9a\u4e0b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.17237", "categories": ["cs.SE", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.17237", "abs": "https://arxiv.org/abs/2602.17237", "authors": ["Tannaz Zameni", "Petra van den Bos", "Arend Rensink"], "title": "Disjunction Composition of BDD Transition Systems for Model-Based Testing", "comment": "Technical report with proofs", "summary": "We introduce a compositional approach to model-based test generation in Behavior-Driven Development (BDD). BDD is an agile methodology in which system behavior is specified through textual scenarios that, in our approach, are translated into transition systems used for model-based testing. This paper formally defines disjunction composition, to combine BDD transition systems that represent alternative system behaviors. Disjunction composition allows for modeling and testing the integrated behavior while ensuring that the testing power of the original set of scenarios is preserved. This is proved using a symbolic semantics for BDD transition systems, with the property that the symbolic equivalence of two BDD transition systems guarantees that they fail the same test cases. Also, we demonstrate the potential of disjunction composition by applying the composition in an industrial case study.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\uff08BDD\uff09\u7684\u6a21\u578b\u6d4b\u8bd5\u751f\u6210\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49\u6790\u53d6\u7ec4\u5408\u6765\u5408\u5e76\u8868\u793a\u7cfb\u7edf\u53ef\u9009\u884c\u4e3a\u7684BDD\u8f6c\u6362\u7cfb\u7edf\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u4fdd\u6301\u539f\u59cb\u573a\u666f\u96c6\u7684\u6d4b\u8bd5\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5de5\u4e1a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6790\u53d6\u7ec4\u5408\u7684\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u5728\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u4e2d\u63d0\u9ad8\u6a21\u578b\u6d4b\u8bd5\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5f53\u9700\u8981\u5904\u7406\u63cf\u8ff0\u7cfb\u7edf\u4e0d\u540c\u4f46\u53ef\u80fd\u7684\u884c\u4e3a\u9009\u9879\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ec4\u5408\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u96c6\u6210\u8fd9\u4e9b\u884c\u4e3a\u6a21\u578b\u5e76\u786e\u4fdd\u6574\u4f53\u6d4b\u8bd5\u80fd\u529b\u4e0d\u53d7\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u2018\u6790\u53d6\u7ec4\u5408\u2019\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u7ed3\u5408\u4ee3\u8868\u7cfb\u7edf\u66ff\u4ee3\u884c\u4e3a\u7684BDD\u8f6c\u6362\u7cfb\u7edf\u3002\u901a\u8fc7\u4f7f\u7528BDD\u8f6c\u6362\u7cfb\u7edf\u7684\u7b26\u53f7\u8bed\u4e49\u6765\u8bc1\u660e\u8fd9\u79cd\u7ec4\u5408\u65b9\u5f0f\u53ef\u4ee5\u4fdd\u6301\u539f\u6709\u573a\u666f\u96c6\u5408\u7684\u6d4b\u8bd5\u6548\u80fd\u3002", "result": "\u6210\u529f\u5730\u5b9a\u4e49\u4e86\u5982\u4f55\u901a\u8fc7\u2018\u6790\u53d6\u7ec4\u5408\u2019\u6765\u6574\u5408\u591a\u4e2aBDD\u8f6c\u6362\u7cfb\u7edf\u800c\u4e0d\u635f\u5931\u539f\u6709\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\uff1b\u5e76\u4e14\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u5de5\u4e1a\u5e94\u7528\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u5f15\u5165\u7684\u6790\u53d6\u7ec4\u5408\u4e3aBDD\u4e2d\u7684\u6a21\u578b\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u6709\u529b\u7684\u65b0\u624b\u6bb5\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u5355\u72ec\u884c\u4e3a\u6a21\u578b\u6d4b\u8bd5\u80fd\u529b\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u5bf9\u591a\u79cd\u884c\u4e3a\u6a21\u5f0f\u7684\u4e00\u4f53\u5316\u5efa\u6a21\u4e0e\u6d4b\u8bd5\u3002"}}
{"id": "2602.16784", "categories": ["cs.LG", "cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.16784", "abs": "https://arxiv.org/abs/2602.16784", "authors": ["Victoria Lin", "Louis-Philippe Morency", "Eli Ben-Michael"], "title": "Omitted Variable Bias in Language Models Under Distribution Shift", "comment": null, "summary": "Despite their impressive performance on a wide variety of tasks, modern language models remain susceptible to distribution shifts, exhibiting brittle behavior when evaluated on data that differs in distribution from their training data. In this paper, we describe how distribution shifts in language models can be separated into observable and unobservable components, and we discuss how established approaches for dealing with distribution shift address only the former. Importantly, we identify that the resulting omitted variable bias from unobserved variables can compromise both evaluation and optimization in language models. To address this challenge, we introduce a framework that maps the strength of the omitted variables to bounds on the worst-case generalization performance of language models under distribution shift. In empirical experiments, we show that using these bounds directly in language model evaluation and optimization provides more principled measures of out-of-distribution performance, improves true out-of-distribution performance relative to standard distribution shift adjustment methods, and further enables inference about the strength of the omitted variables when target distribution labels are available.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u9047\u5230\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e4b\u5916\u7684\u6570\u636e\u65f6\u7684\u8106\u5f31\u6027\uff0c\u533a\u5206\u4e86\u53ef\u89c2\u5bdf\u548c\u4e0d\u53ef\u89c2\u5bdf\u7684\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\u6765\u5904\u7406\u7531\u4e8e\u672a\u89c2\u6d4b\u53d8\u91cf\u5bfc\u81f4\u7684\u9057\u6f0f\u53d8\u91cf\u504f\u5dee\u95ee\u9898\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u5408\u7406\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u672a\u77e5\u5206\u5e03\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5141\u8bb8\u5bf9\u672a\u89c2\u6d4b\u53d8\u91cf\u5f3a\u5ea6\u8fdb\u884c\u63a8\u65ad\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9762\u5bf9\u4e0e\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0d\u540c\u7684\u6570\u636e\u65f6\u4ecd\u7136\u663e\u5f97\u975e\u5e38\u8106\u5f31\u3002\u73b0\u6709\u5e94\u5bf9\u5206\u5e03\u53d8\u5316\u7684\u65b9\u6cd5\u53ea\u89e3\u51b3\u4e86\u53ef\u4ee5\u89c2\u5bdf\u5230\u7684\u90e8\u5206\uff0c\u800c\u672a\u80fd\u89e3\u51b3\u90a3\u4e9b\u4e0d\u53ef\u89c1\u7684\u56e0\u7d20\u6240\u5e26\u6765\u7684\u5f71\u54cd\u3002\u8fd9\u4e9b\u672a\u88ab\u6ce8\u610f\u5230\u7684\u53d8\u5316\u53ef\u80fd\u5bfc\u81f4\u8bc4\u4f30\u548c\u4f18\u5316\u8fc7\u7a0b\u4e2d\u7684\u504f\u5dee\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u672a\u89c2\u5bdf\u5230\u53d8\u91cf\u7684\u5f71\u54cd\u5f3a\u5ea6\u6620\u5c04\u5230\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5e03\u53d8\u5316\u4e0b\u6700\u5dee\u60c5\u51b5\u6cdb\u5316\u6027\u80fd\u7684\u754c\u9650\u4e0a\u3002\u6b64\u5916\uff0c\u5728\u6709\u76ee\u6807\u5206\u5e03\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u53ef\u4ee5\u5229\u7528\u6b64\u6846\u67b6\u6765\u63a8\u65ad\u672a\u89c2\u5bdf\u5230\u53d8\u91cf\u7684\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76f4\u63a5\u4f7f\u7528\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u7684\u8fb9\u754c\u6765\u8fdb\u884c\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e0e\u4f18\u5316\uff0c\u4e0d\u4ec5\u80fd\u7ed9\u51fa\u66f4\u52a0\u51c6\u786e\u7684\u8d85\u51fa\u5206\u5e03\u6027\u80fd\u5ea6\u91cf\uff0c\u800c\u4e14\u76f8\u6bd4\u4f20\u7edf\u8c03\u6574\u65b9\u6cd5\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u771f\u5b9e\u73af\u5883\u4e0b\u7684\u8d85\u51fa\u5206\u5e03\u6027\u80fd\u3002", "conclusion": "\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u4e2d\u7531\u672a\u89c2\u6d4b\u53d8\u91cf\u5f15\u8d77\u7684\u9057\u6f0f\u53d8\u91cf\u504f\u5dee\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u6539\u5584\u6a21\u578b\u5728\u4e0d\u540c\u5206\u5e03\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.17625", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17625", "abs": "https://arxiv.org/abs/2602.17625", "authors": ["Obaidullah Zaland", "Zulfiqar Ahmad Khan", "Monowar Bhuyan"], "title": "Catastrophic Forgetting Resilient One-Shot Incremental Federated Learning", "comment": "Accepted for publication in the IEEE International Conference on Big Data (IEEE BigData) 2025", "summary": "Modern big-data systems generate massive, heterogeneous, and geographically dispersed streams that are large-scale and privacy-sensitive, making centralization challenging. While federated learning (FL) provides a privacy-enhancing training mechanism, it assumes a static data flow and learns a collaborative model over multiple rounds, making learning with \\textit{incremental} data challenging in limited-communication scenarios. This paper presents One-Shot Incremental Federated Learning (OSI-FL), the first FL framework that addresses the dual challenges of communication overhead and catastrophic forgetting. OSI-FL communicates category-specific embeddings, devised by a frozen vision-language model (VLM) from each client in a single communication round, which a pre-trained diffusion model at the server uses to synthesize new data similar to the client's data distribution. The synthesized samples are used on the server for training. However, two challenges still persist: i) tasks arriving incrementally need to retrain the global model, and ii) as future tasks arrive, retraining the model introduces catastrophic forgetting. To this end, we augment training with Selective Sample Retention (SSR), which identifies and retains the top-p most informative samples per category and task pair based on sample loss. SSR bounds forgetting by ensuring that representative retained samples are incorporated into training in further iterations. The experimental results indicate that OSI-FL outperforms baselines, including traditional and one-shot FL approaches, in both class-incremental and domain-incremental scenarios across three benchmark datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOne-Shot Incremental Federated Learning (OSI-FL)\u7684\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5355\u8f6e\u901a\u4fe1\u4e2d\u4f20\u9012\u7c7b\u522b\u7279\u5b9a\u5d4c\u5165\u6765\u5e94\u5bf9\u901a\u4fe1\u5f00\u9500\u548c\u707e\u96be\u6027\u9057\u5fd8\u7684\u53cc\u91cd\u6311\u6218\uff0c\u5e76\u91c7\u7528Selective Sample Retention (SSR)\u65b9\u6cd5\u4fdd\u7559\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6837\u672c\u4ee5\u51cf\u5c11\u9057\u5fd8\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOSI-FL\u5728\u7c7b\u589e\u91cf\u548c\u57df\u589e\u91cf\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5047\u8bbe\u6570\u636e\u6d41\u662f\u9759\u6001\u7684\uff0c\u5e76\u4e14\u5728\u591a\u8f6e\u6b21\u4e2d\u5b66\u4e60\u534f\u4f5c\u6a21\u578b\uff0c\u8fd9\u4f7f\u5f97\u5728\u6709\u9650\u901a\u4fe1\u573a\u666f\u4e0b\u5904\u7406\u589e\u91cf\u6570\u636e\u53d8\u5f97\u56f0\u96be\u3002\u6b64\u5916\uff0c\u968f\u7740\u65b0\u4efb\u52a1\u7684\u5230\u6765\uff0c\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86One-Shot Incremental Federated Learning (OSI-FL)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5141\u8bb8\u5ba2\u6237\u7aef\u901a\u8fc7\u5355\u8f6e\u901a\u4fe1\u5411\u670d\u52a1\u5668\u53d1\u9001\u7531\u51bb\u7ed3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7c7b\u522b\u7279\u5b9a\u5d4c\u5165\u3002\u670d\u52a1\u5668\u4f7f\u7528\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u5408\u6210\u4e0e\u5ba2\u6237\u7aef\u6570\u636e\u5206\u5e03\u76f8\u4f3c\u7684\u65b0\u6570\u636e\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u5408\u6210\u6837\u672c\u6765\u8bad\u7ec3\u6a21\u578b\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5f15\u5165\u4e86Selective Sample Retention (SSR)\u673a\u5236\uff0c\u8be5\u673a\u5236\u6839\u636e\u6837\u672c\u635f\u5931\u8bc6\u522b\u5e76\u4fdd\u7559\u6bcf\u4e2a\u7c7b\u522b\u548c\u4efb\u52a1\u5bf9\u4e2d\u6700\u5177\u6709\u4fe1\u606f\u4ef7\u503c\u7684\u9876\u90e8p\u4e2a\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u65e0\u8bba\u662f\u5bf9\u4e8e\u7c7b\u589e\u91cf\u8fd8\u662f\u57df\u589e\u91cf\u7684\u60c5\u51b5\uff0cOSI-FL\u7684\u8868\u73b0\u90fd\u4f18\u4e8e\u5305\u62ec\u4f20\u7edfFL\u65b9\u6cd5\u5728\u5185\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OSI-FL\u6210\u529f\u5730\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u4fe1\u6210\u672c\u9ad8\u4ee5\u53ca\u9762\u5bf9\u589e\u91cf\u6570\u636e\u65f6\u5bb9\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.17410", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17410", "abs": "https://arxiv.org/abs/2602.17410", "authors": ["Bingqian Li", "Bowen Zheng", "Xiaolei Wang", "Long Zhang", "Jinpeng Wang", "Sheng Chen", "Wayne Xin Zhao", "Ji-rong Wen"], "title": "Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers", "comment": null, "summary": "Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\u7684\u65b0\u504f\u597d\u5fae\u8c03\u6846\u67b6ILRec\uff0c\u901a\u8fc7\u4ece\u4e2d\u95f4\u5c42\u63d0\u53d6\u81ea\u96be\u8d1f\u6837\u672c\u4fe1\u53f7\u6765\u6539\u8fdb\u504f\u597d\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5e8f\u5217\u7ea7\u3001\u79bb\u7ebf\u751f\u6210\u7684\u8d1f\u6837\u672c\uff0c\u5728\u9002\u5e94\u5177\u6709\u5927\u91cf\u8d1f\u9879\u76ee\u7a7a\u95f4\u7684\u63a8\u8350\u4efb\u52a1\u65f6\u4e0d\u591f\u533a\u5206\u6027\u548c\u4fe1\u606f\u6027\u3002", "method": "\u63d0\u51fa\u4e86ILRec\uff0c\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5fae\u8c03\u6846\u67b6\uff0c\u5229\u7528\u6765\u81ea\u4e2d\u95f4\u5c42\u7684\u81ea\u96be\u8d1f\u4fe1\u53f7\u6539\u5584\u504f\u597d\u5b66\u4e60\u3002\u5305\u62ec\u8de8\u5c42\u504f\u597d\u4f18\u5316\u548c\u8de8\u5c42\u504f\u597d\u84b8\u998f\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u5f15\u5165\u8f7b\u91cf\u7ea7\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u4e3a\u8d1f\u4fe1\u53f7\u5206\u914d\u4ee4\u724c\u7ea7\u522b\u5956\u52b1\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cILRec\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u5730\u4ece\u4e2d\u95f4\u5c42\u9009\u53d6\u66f4\u7ec6\u7c92\u5ea6\u7684\u8d1f\u76d1\u7763\u5e76\u5c06\u5176\u6574\u5408\u5230\u8bad\u7ec3\u4e2d\uff0cILRec\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u6548\u679c\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.17320", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17320", "abs": "https://arxiv.org/abs/2602.17320", "authors": ["Stefano Lambiase", "Manuel De Stefano", "Fabio Palomba", "Filomena Ferrucci", "Andrea De Lucia"], "title": "Socio-Technical Well-Being of Quantum Software Communities: An Overview on Community Smells", "comment": null, "summary": "Quantum computing has gained significant attention due to its potential to solve computational problems beyond the capabilities of classical computers. With major corporations and academic institutions investing in quantum hardware and software, there has been a rise in the development of quantum-enabled systems, particularly within open-source communities. However, despite the promising nature of quantum technologies, these communities face critical socio-technical challenges, including the emergence of socio-technical anti-patterns known as community smells. These anti-patterns, prevalent in open-source environments, have the potential to negatively impact both product quality and community health by introducing technical debt and amplifying architectural and code smells. Despite the importance of these socio-technical factors, there remains a scarcity of research investigating their influence within quantum open-source communities. This work aims to address this gap by providing a first step in analyzing the socio-technical well-being of quantum communities through a cross-sectional study. By understanding the socio-technical dynamics at play, it is expected that foundational knowledge can be established to mitigate the risks associated with community smells and ensure the long-term sustainability of open-source quantum initiatives.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f00\u6e90\u91cf\u5b50\u8ba1\u7b97\u793e\u533a\u4e2d\u7684\u793e\u4f1a\u6280\u672f\u53cd\u6a21\u5f0f\uff08\u79f0\u4e3a\u793e\u533a\u6c14\u5473\uff09\uff0c\u8fd9\u4e9b\u53cd\u6a21\u5f0f\u53ef\u80fd\u5bf9\u4ea7\u54c1\u54c1\u8d28\u548c\u793e\u533a\u5065\u5eb7\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u901a\u8fc7\u4e00\u9879\u6a2a\u65ad\u9762\u7814\u7a76\uff0c\u6587\u7ae0\u65e8\u5728\u5206\u6790\u91cf\u5b50\u793e\u533a\u7684\u793e\u4f1a\u6280\u672f\u72b6\u51b5\uff0c\u5e76\u4e3a\u51cf\u8f7b\u4e0e\u793e\u533a\u6c14\u5473\u76f8\u5173\u7684\u98ce\u9669\u63d0\u4f9b\u57fa\u7840\u6027\u77e5\u8bc6\uff0c\u4ee5\u786e\u4fdd\u5f00\u6e90\u91cf\u5b50\u9879\u76ee\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u5c3d\u7ba1\u91cf\u5b50\u6280\u672f\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5f00\u6e90\u793e\u533a\u5728\u5f00\u53d1\u91cf\u5b50\u652f\u6301\u7cfb\u7edf\u65f6\u9762\u4e34\u91cd\u8981\u7684\u793e\u4f1a\u6280\u672f\u6311\u6218\uff0c\u5305\u62ec\u53ef\u80fd\u5bfc\u81f4\u6280\u672f\u548c\u4ee3\u7801\u8d28\u91cf\u4e0b\u964d\u7684\u793e\u4f1a\u6280\u672f\u53cd\u6a21\u5f0f\u3002\u76ee\u524d\u5bf9\u4e8e\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u91cf\u5b50\u5f00\u6e90\u793e\u533a\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u91c7\u7528\u6a2a\u65ad\u9762\u7814\u7a76\u65b9\u6cd5\u6765\u5206\u6790\u91cf\u5b50\u5f00\u6e90\u793e\u533a\u7684\u793e\u4f1a\u6280\u672f\u798f\u7949\u3002", "result": "\u901a\u8fc7\u4e86\u89e3\u793e\u4f1a\u6280\u672f\u52a8\u6001\uff0c\u53ef\u4ee5\u5efa\u7acb\u57fa\u7840\u6027\u77e5\u8bc6\uff0c\u4ee5\u7f13\u89e3\u4e0e\u793e\u533a\u6c14\u5473\u6709\u5173\u7684\u98ce\u9669\uff0c\u4fdd\u8bc1\u5f00\u6e90\u91cf\u5b50\u8ba1\u5212\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "conclusion": "\u7406\u89e3\u91cf\u5b50\u5f00\u6e90\u793e\u533a\u4e2d\u793e\u4f1a\u6280\u672f\u4e92\u52a8\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u8bc6\u522b\u548c\u5904\u7406\u793e\u533a\u6c14\u5473\uff0c\u5bf9\u4e8e\u786e\u4fdd\u9879\u76ee\u8d28\u91cf\u548c\u793e\u533a\u5065\u5eb7\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.16787", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16787", "abs": "https://arxiv.org/abs/2602.16787", "authors": ["Victoria Lin", "Xinnuo Xu", "Rachel Lawrence", "Risa Ueno", "Amit Sharma", "Javier Gonzalez", "Niranjani Prasad"], "title": "Better Think Thrice: Learning to Reason Causally with Double Counterfactual Consistency", "comment": null, "summary": "Despite their strong performance on reasoning benchmarks, large language models (LLMs) have proven brittle when presented with counterfactual questions, suggesting weaknesses in their causal reasoning ability. While recent work has demonstrated that labeled counterfactual tasks can be useful benchmarks of LLMs' causal reasoning, producing such data at the scale required to cover the vast potential space of counterfactuals is limited. In this work, we introduce double counterfactual consistency (DCC), a lightweight inference-time method for measuring and guiding the ability of LLMs to reason causally. Without requiring labeled counterfactual data, DCC verifies a model's ability to execute two important elements of causal reasoning: causal intervention and counterfactual prediction. Using DCC, we evaluate the causal reasoning abilities of various leading LLMs across a range of reasoning tasks and interventions. Moreover, we demonstrate the effectiveness of DCC as a training-free test-time rejection sampling criterion and show that it can directly improve performance on reasoning tasks across multiple model families.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u63a8\u7406\u65f6\u95f4\u65b9\u6cd5\uff0c\u5373\u53cc\u91cd\u53cd\u4e8b\u5b9e\u4e00\u81f4\u6027\uff08DCC\uff09\uff0c\u7528\u4e8e\u8861\u91cf\u548c\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002DCC \u4e0d\u9700\u8981\u6807\u8bb0\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\uff0c\u80fd\u591f\u9a8c\u8bc1\u6a21\u578b\u6267\u884c\u56e0\u679c\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u9884\u6d4b\u7684\u80fd\u529b\u3002\u7814\u7a76\u5c55\u793a\u4e86 DCC \u5728\u591a\u79cd\u9886\u5148 LLMs \u4e2d\u63d0\u9ad8\u63a8\u7406\u4efb\u52a1\u6027\u80fd\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f53\u9762\u5bf9\u53cd\u4e8b\u5b9e\u95ee\u9898\u65f6\u663e\u5f97\u8106\u5f31\uff0c\u8fd9\u8868\u660e\u5b83\u4eec\u5728\u56e0\u679c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5f31\u70b9\u3002\u867d\u7136\u6709\u7814\u7a76\u8868\u660e\u5e26\u6709\u6807\u7b7e\u7684\u53cd\u4e8b\u5b9e\u4efb\u52a1\u53ef\u4ee5\u4f5c\u4e3a\u8bc4\u4f30 LLMs \u56e0\u679c\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u57fa\u51c6\uff0c\u4f46\u751f\u6210\u8db3\u4ee5\u8986\u76d6\u5e7f\u6cdb\u6f5c\u5728\u53cd\u4e8b\u5b9e\u7a7a\u95f4\u7684\u6570\u636e\u89c4\u6a21\u6709\u9650\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0d\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u65b9\u6cd5\u6765\u8861\u91cf\u548c\u6539\u8fdb LLMs \u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86\u53cc\u91cd\u53cd\u4e8b\u5b9e\u4e00\u81f4\u6027\uff08DCC\uff09\u8fd9\u4e00\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u3001\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u6807\u8bb0\u7684\u53cd\u4e8b\u5b9e\u6570\u636e\u5373\u53ef\u6d4b\u91cf\u5e76\u6307\u5bfcLLMs\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u7684\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u80fd\u591f\u6709\u6548\u5730\u5b9e\u65bd\u56e0\u679c\u5e72\u9884\u4ee5\u53ca\u51c6\u786e\u5730\u505a\u51fa\u53cd\u4e8b\u5b9e\u9884\u6d4b\u3002", "result": "\u901a\u8fc7\u5bf9\u4e00\u7cfb\u5217\u9886\u5148\u7684LLMs\u8fdb\u884c\u4e0d\u540c\u7c7b\u578b\u7684\u63a8\u7406\u4efb\u52a1\u53ca\u5e72\u9884\u63aa\u65bd\u4e0b\u7684\u6d4b\u8bd5\uff0c\u8bc1\u5b9e\u4e86DCC\u80fd\u6709\u6548\u8bc4\u4ef7\u8fd9\u4e9b\u6a21\u578b\u7684\u56e0\u679c\u63a8\u7406\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u8fd8\u8bc1\u660e\u4e86DCC\u53ef\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6d4b\u8bd5\u65f6\u95f4\u62d2\u7edd\u91c7\u6837\u6807\u51c6\uff0c\u5e76\u4e14\u76f4\u63a5\u4fc3\u8fdb\u4e86\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u63d0\u5347\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u7528DCC\u65b9\u6cd5\u53ef\u4ee5\u5728\u6ca1\u6709\u989d\u5916\u8bad\u7ec3\u6216\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u56e0\u679c\u5173\u7cfb\u76f8\u5173\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2602.16793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16793", "abs": "https://arxiv.org/abs/2602.16793", "authors": ["Xingyu Dang", "Rohit Agarwal", "Rodrigo Porto", "Anirudh Goyal", "Liam H Fowl", "Sanjeev Arora"], "title": "Escaping the Cognitive Well: Efficient Competition Math with Off-the-Shelf Models", "comment": null, "summary": "In the past year, custom and unreleased math reasoning models reached gold medal performance on the International Mathematical Olympiad (IMO). Similar performance was then reported using large-scale inference on publicly available models but at prohibitive costs (e.g., 3000 USD per problem). In this work, we present an inference pipeline that attains best-in-class performance on IMO-style math problems at an average inference cost orders of magnitude below competing methods while using only general-purpose off-the-shelf models. Our method relies on insights about grader failure in solver-grader pipelines, which we call the Cognitive Well (iterative refinement converging to a wrong solution that the solver as well as the pipeline's internal grader consider to be basically correct). Our pipeline addresses these failure modes through conjecture extraction, wherein candidate lemmas are isolated from generated solutions and independently verified alongside their negations in a fresh environment (context detachment). On IMO-ProofBench Advanced (PB-Adv), our pipeline achieves 67.1 percent performance using Gemini 3.0 Pro with an average cost per question of approximately 31 USD. At the time of evaluation, this represented the state-of-the-art on PB-Adv among both public and unreleased models, and more than doubles the success rate of the next best publicly accessible pipeline, all at a fraction of the cost.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u5728\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\uff08IMO\uff09\u6837\u5f0f\u7684\u6570\u5b66\u95ee\u9898\u4e0a\u8fbe\u5230\u4e86\u540c\u7c7b\u6700\u4f73\u7684\u8868\u73b0\uff0c\u540c\u65f6\u5927\u5e45\u5ea6\u964d\u4f4e\u4e86\u63a8\u7406\u6210\u672c\u3002\u901a\u8fc7\u89e3\u51b3\u8bc4\u4f30\u8005\u5728\u89e3\u9898-\u8bc4\u5206\u7ba1\u9053\u4e2d\u7684\u8ba4\u77e5\u9677\u9631\u95ee\u9898\uff0c\u5373\u8fed\u4ee3\u6539\u8fdb\u6536\u655b\u5230\u4e00\u4e2a\u89e3\u9898\u5668\u548c\u5185\u90e8\u8bc4\u5206\u7cfb\u7edf\u90fd\u8ba4\u4e3a\u57fa\u672c\u6b63\u786e\u7684\u9519\u8bef\u89e3\u51b3\u65b9\u6848\uff0c\u6b64\u65b9\u6cd5\u4f7f\u7528\u4e86\u731c\u60f3\u63d0\u53d6\u6280\u672f\uff0c\u4ece\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e2d\u5206\u79bb\u51fa\u5019\u9009\u5f15\u7406\uff0c\u5e76\u5728\u65b0\u7684\u73af\u5883\u4e2d\u72ec\u7acb\u9a8c\u8bc1\u5b83\u4eec\u53ca\u5176\u5426\u5b9a\u3002\u5728IMO-ProofBench Advanced\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u4f7f\u7528Gemini 3.0 Pro\u6a21\u578b\u5b9e\u73b0\u4e8667.1%\u7684\u6210\u7ee9\uff0c\u6bcf\u9898\u5e73\u5747\u6210\u672c\u7ea6\u4e3a31\u7f8e\u5143\uff0c\u8fd9\u662f\u516c\u5f00\u6a21\u578b\u4e2d\u6700\u597d\u7684\u8868\u73b0\u4e4b\u4e00\uff0c\u4e14\u6bd4\u4e0b\u4e00\u4e2a\u6700\u4f73\u516c\u5f00\u53ef\u8bbf\u95ee\u7ba1\u9053\u7684\u6210\u529f\u7387\u9ad8\u51fa\u4e00\u500d\u591a\u3002", "motivation": "\u8fc7\u53bb\u4e00\u5e74\u91cc\uff0c\u5b9a\u5236\u548c\u672a\u53d1\u5e03\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u5df2\u7ecf\u5728\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\uff08IMO\uff09\u4e0a\u8fbe\u5230\u4e86\u91d1\u724c\u6c34\u5e73\u7684\u8868\u73b0\u3002\u5c3d\u7ba1\u540e\u6765\u62a5\u544a\u79f0\u5229\u7528\u5927\u89c4\u6a21\u63a8\u7406\u5728\u516c\u5f00\u53ef\u7528\u6a21\u578b\u4e0a\u4e5f\u80fd\u8fbe\u5230\u7c7b\u4f3c\u8868\u73b0\uff0c\u4f46\u5176\u6210\u672c\u6781\u5176\u9ad8\u6602\uff08\u4f8b\u5982\uff0c\u6bcf\u9898\u9700\u82b1\u8d393000\u7f8e\u5143\uff09\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u7ecf\u6d4e\u7684\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3IMO\u98ce\u683c\u7684\u6570\u5b66\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u7684\u65b9\u6cd5\u57fa\u4e8e\u5bf9\u89e3\u9898-\u8bc4\u5206\u7ba1\u9053\u4e2d\u8bc4\u4f30\u5931\u8d25\u60c5\u51b5\u7684\u8ba4\u77e5\u4e95\u6548\u5e94\u7684\u7406\u89e3\uff0c\u5373\u8fed\u4ee3\u6539\u8fdb\u8fc7\u7a0b\u53ef\u80fd\u6700\u7ec8\u6536\u655b\u81f3\u4e00\u4e2a\u88ab\u89e3\u9898\u5668\u53ca\u7ba1\u9053\u5185\u90e8\u8bc4\u5206\u673a\u5236\u8bef\u8ba4\u4e3a\u6b63\u786e\u4f46\u5b9e\u9645\u4e0a\u9519\u8bef\u7684\u7b54\u6848\u3002\u4e3a\u514b\u670d\u8fd9\u4e00\u6311\u6218\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u731c\u60f3\u63d0\u53d6\u7b56\u7565\uff1a\u4ece\u5df2\u4ea7\u751f\u7684\u89e3\u7b54\u4e2d\u62bd\u53d6\u5019\u9009\u5f15\u7406\uff0c\u5e76\u5c06\u5176\u4e0e\u5bf9\u5e94\u7684\u5426\u5b9a\u4e00\u8d77\uff0c\u5728\u4e00\u4e2a\u5168\u65b0\u7684\u4e0a\u4e0b\u6587\u4e2d\u72ec\u7acb\u8fdb\u884c\u9a8c\u8bc1\uff08\u5373\u4e0a\u4e0b\u6587\u8131\u79bb\uff09\u3002\u6574\u4e2a\u6d41\u7a0b\u91c7\u7528\u901a\u7528\u73b0\u6210\u6a21\u578b\u5b8c\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728IMO-ProofBench Advanced\u6570\u636e\u96c6\u4e0a\u5e94\u7528Gemini 3.0 Pro\u6a21\u578b\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u7ba1\u9053\u80fd\u591f\u8fbe\u523067.1%\u7684\u6027\u80fd\u6307\u6807\uff0c\u5e73\u5747\u6bcf\u9898\u5904\u7406\u8d39\u7528\u5927\u7ea6\u4e3a31\u7f8e\u5143\u3002\u8fd9\u4e0d\u4ec5\u4ee3\u8868\u4e86\u5f53\u65f6PB-Adv\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u516c\u5f00\u4e0e\u975e\u516c\u5f00\u6a21\u578b\u7684\u6700\u4f73\u8868\u73b0\uff0c\u800c\u4e14\u76f8\u5bf9\u4e8e\u6b21\u4f18\u516c\u5f00\u8bbf\u95ee\u7ba1\u9053\u6765\u8bf4\uff0c\u6210\u529f\u6bd4\u7387\u7ffb\u4e86\u4e00\u756a\u8fd8\u591a\uff0c\u540c\u65f6\u6210\u672c\u4ec5\u4e3a\u540e\u8005\u7684\u4e00\u5c0f\u90e8\u5206\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u65b0\u9896\u9ad8\u6548\u7684\u63a8\u7406\u6d41\u7a0b\uff0c\u80fd\u591f\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u9ad8\u89e3\u51b3IMO\u7ea7\u522b\u6570\u5b66\u96be\u9898\u7684\u80fd\u529b\u3002\u8fd9\u6807\u5fd7\u7740\u5411\u66f4\u5e7f\u6cdb\u5730\u5229\u7528\u5148\u8fdbAI\u6280\u672f\u4fc3\u8fdb\u6570\u5b66\u6559\u80b2\u548c\u4e2a\u4eba\u5b66\u4e60\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2602.17426", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17426", "abs": "https://arxiv.org/abs/2602.17426", "authors": ["Marco Autili", "Gianluca Filippone", "Mashal Afzal Memon", "Patrizio Pelliccione"], "title": "The Runtime Dimension of Ethics in Self-Adaptive Systems", "comment": null, "summary": "Self-adaptive systems increasingly operate in close interaction with humans, often sharing the same physical or virtual environments and making decisions with ethical implications at runtime. Current approaches typically encode ethics as fixed, rule-based constraints or as a single chosen ethical theory embedded at design time. This overlooks a fundamental property of human-system interaction settings: ethical preferences vary across individuals and groups, evolve with context, and may conflict, while still needing to remain within a legally and regulatorily defined hard-ethics envelope (e.g., safety and compliance constraints). This paper advocates a shift from static ethical rules to runtime ethical reasoning for self-adaptive systems, where ethical preferences are treated as runtime requirements that must be elicited, represented, and continuously revised as stakeholders and situations change. We argue that satisfying such requirements demands explicit ethics-based negotiation to manage ethical trade-offs among multiple humans who interact with, are represented by, or are affected by a system. We identify key challenges, ethical uncertainty, conflicts among ethical values (including human, societal, and environmental drivers), and multi-dimensional/multi-party/multi-driver negotiation, and outline research directions and questions toward ethically self-adaptive systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u5021\u4ece\u9759\u6001\u7684\u4f26\u7406\u89c4\u5219\u8f6c\u5411\u8fd0\u884c\u65f6\u4f26\u7406\u63a8\u7406\uff0c\u4ee5\u9002\u5e94\u81ea\u9002\u5e94\u7cfb\u7edf\u4e2d\u4e2a\u4f53\u548c\u7fa4\u4f53\u95f4\u4e0d\u540c\u7684\u3001\u53ef\u53d8\u7684\u4e14\u53ef\u80fd\u51b2\u7a81\u7684\u4f26\u7406\u504f\u597d\u3002\u63d0\u51fa\u9700\u8981\u5728\u5229\u76ca\u76f8\u5173\u8005\u4e4b\u95f4\u8fdb\u884c\u660e\u786e\u7684\u57fa\u4e8e\u4f26\u7406\u7684\u534f\u5546\u6765\u7ba1\u7406\u591a\u4e2a\u4f26\u7406\u6743\u8861\uff0c\u5e76\u786e\u5b9a\u4e86\u5173\u952e\u6311\u6218\u53ca\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u901a\u5e38\u5c06\u4f26\u7406\u7f16\u7801\u4e3a\u56fa\u5b9a\u7684\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u7ea6\u675f\u6216\u8bbe\u8ba1\u65f6\u5d4c\u5165\u7684\u5355\u4e00\u9009\u5b9a\u4f26\u7406\u7406\u8bba\uff0c\u8fd9\u5ffd\u7565\u4e86\u4eba\u7c7b-\u7cfb\u7edf\u4ea4\u4e92\u8bbe\u7f6e\u7684\u4e00\u4e2a\u57fa\u672c\u5c5e\u6027\uff1a\u4f26\u7406\u504f\u597d\u56e0\u4eba\u800c\u5f02\u3001\u968f\u60c5\u5883\u53d8\u5316\uff0c\u5e76\u53ef\u80fd\u5b58\u5728\u51b2\u7a81\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u504f\u597d\u4ecd\u7136\u9700\u8981\u4fdd\u6301\u5728\u6cd5\u5f8b\u548c\u76d1\u7ba1\u5b9a\u4e49\u7684\u786c\u6027\u4f26\u7406\u8303\u56f4\u5185\uff08\u4f8b\u5982\uff0c\u5b89\u5168\u4e0e\u5408\u89c4\u7ea6\u675f\uff09\u3002", "method": "\u6587\u7ae0\u6ca1\u6709\u5177\u4f53\u63cf\u8ff0\u4e00\u79cd\u65b9\u6cd5\u8bba\uff0c\u800c\u662f\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u4e3b\u5f20\u91c7\u7528\u8fd0\u884c\u65f6\u4f26\u7406\u63a8\u7406\u7684\u65b9\u5f0f\uff0c\u5c06\u4f26\u7406\u504f\u597d\u89c6\u4e3a\u5fc5\u987b\u6839\u636e\u5229\u76ca\u76f8\u5173\u8005\u548c\u60c5\u5883\u7684\u53d8\u5316\u6301\u7eed\u66f4\u65b0\u7684\u8fd0\u884c\u65f6\u9700\u6c42\u3002", "result": "\u6307\u51fa\u4e86\u5b9e\u73b0\u4f26\u7406\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u4f26\u7406\u4e0d\u786e\u5b9a\u6027\u3001\u4f26\u7406\u4ef7\u503c\u89c2\u4e4b\u95f4\u7684\u51b2\u7a81\uff08\u5305\u62ec\u4eba\u7c7b\u3001\u793e\u4f1a\u548c\u73af\u5883\u9a71\u52a8\u56e0\u7d20\uff09\u4ee5\u53ca\u591a\u7ef4\u5ea6/\u591a\u65b9/\u591a\u9a71\u52a8\u56e0\u7d20\u534f\u5546\u7b49\u95ee\u9898\uff0c\u5e76\u6982\u8ff0\u4e86\u671d\u5411\u4f26\u7406\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u7814\u7a76\u65b9\u5411\u548c\u95ee\u9898\u3002", "conclusion": "\u4e3a\u4e86\u6784\u5efa\u80fd\u591f\u5904\u7406\u591a\u6837\u5316\u3001\u52a8\u6001\u5316\u5e76\u4e14\u6f5c\u5728\u51b2\u7a81\u7684\u4f26\u7406\u504f\u597d\u7684\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u6211\u4eec\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u8fd0\u884c\u65f6\u4f26\u7406\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u663e\u5f0f\u7684\u4f26\u7406\u57fa\u7840\u534f\u5546\u6765\u89e3\u51b3\u591a\u65b9\u9762\u4e4b\u95f4\u7684\u4f26\u7406\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2602.16796", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.16796", "abs": "https://arxiv.org/abs/2602.16796", "authors": ["Zifan Wang", "Riccardo De Santi", "Xiaoyu Mo", "Michael M. Zavlanos", "Andreas Krause", "Karl H. Johansson"], "title": "Efficient Tail-Aware Generative Optimization via Flow Model Fine-Tuning", "comment": "33 pages", "summary": "Fine-tuning pre-trained diffusion and flow models to optimize downstream utilities is central to real-world deployment. Existing entropy-regularized methods primarily maximize expected reward, providing no mechanism to shape tail behavior. However, tail control is often essential: the lower tail determines reliability by limiting low-reward failures, while the upper tail enables discovery by prioritizing rare, high-reward outcomes. In this work, we present Tail-aware Flow Fine-Tuning (TFFT), a principled and efficient distributional fine-tuning algorithm based on the Conditional Value-at-Risk (CVaR). We address two distinct tail-shaping goals: right-CVaR for seeking novel samples in the high-reward tail and left-CVaR for controlling worst-case samples in the low-reward tail. Unlike prior approaches that rely on non-linear optimization, we leverage the variational dual formulation of CVaR to decompose it into a decoupled two-stage procedure: a lightweight one-dimensional threshold optimization step, and a single entropy-regularized fine-tuning process via a specific pseudo-reward. This decomposition achieves CVaR fine-tuning efficiently with computational cost comparable to standard expected fine-tuning methods. We demonstrate the effectiveness of TFFT across illustrative experiments, high-dimensional text-to-image generation, and molecular design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u98ce\u9669\u4ef7\u503c(CVaR)\u7684\u5c3e\u90e8\u611f\u77e5\u6d41\u5fae\u8c03\u7b97\u6cd5(TFFT)\uff0c\u65e8\u5728\u4f18\u5316\u9884\u8bad\u7ec3\u6269\u6563\u548c\u6d41\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u901a\u8fc7\u5173\u6ce8\u9ad8\u5956\u52b1\u5c3e\u90e8\u7684\u65b0\u9896\u6837\u672c\u63a2\u7d22\u4e0e\u4f4e\u5956\u52b1\u5c3e\u90e8\u7684\u6700\u574f\u60c5\u51b5\u63a7\u5236\uff0cTFFT\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5177\u6210\u672c\u6548\u76ca\u7684\u65b9\u6cd5\u6765\u8c03\u6574\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u71b5\u6b63\u5219\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8e\u6700\u5927\u5316\u9884\u671f\u56de\u62a5\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5c3e\u90e8\u884c\u4e3a\u8fdb\u884c\u8c03\u63a7\u7684\u673a\u5236\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u65e0\u8bba\u662f\u4e3a\u4e86\u63d0\u9ad8\u53ef\u9760\u6027\u8fd8\u662f\u4fc3\u8fdb\u65b0\u53d1\u73b0\uff0c\u63a7\u5236\u5c3e\u90e8\u5206\u5e03\u90fd\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u8c03\u6574\u5c3e\u90e8\u5206\u5e03\u7684\u5fae\u8c03\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Tail-aware Flow Fine-Tuning (TFFT)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u6761\u4ef6\u98ce\u9669\u4ef7\u503c(CVaR)\u7406\u8bba\uff0c\u901a\u8fc7\u5c06CVaR\u5206\u89e3\u4e3a\u4e24\u9636\u6bb5\u8fc7\u7a0b\u2014\u2014\u4e00\u7ef4\u9608\u503c\u4f18\u5316\u6b65\u9aa4\u53ca\u5355\u4e2a\u901a\u8fc7\u7279\u5b9a\u4f2a\u5956\u52b1\u6267\u884c\u7684\u71b5\u6b63\u5219\u5316\u5fae\u8c03\u8fc7\u7a0b\u2014\u2014\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u5c3e\u90e8\u63a7\u5236\u3002\u8fd9\u79cd\u65b9\u6cd5\u907f\u514d\u4e86\u975e\u7ebf\u6027\u4f18\u5316\u7684\u9700\u6c42\uff0c\u5e76\u4fdd\u6301\u4e86\u4e0e\u4f20\u7edf\u671f\u671b\u5fae\u8c03\u65b9\u6cd5\u76f8\u5f53\u7684\u8ba1\u7b97\u6210\u672c\u3002", "result": "TFFT\u5728\u8bf4\u660e\u6027\u5b9e\u9a8c\u3001\u9ad8\u7ef4\u5ea6\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4ee5\u53ca\u5206\u5b50\u8bbe\u8ba1\u7b49\u591a\u4e2a\u9886\u57df\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002\u8868\u660e\u4e86\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u5730\u5bfb\u627e\u9ad8\u56de\u62a5\u5c3e\u90e8\u7684\u65b0\u9896\u6837\u672c\uff0c\u540c\u65f6\u4e5f\u80fd\u591f\u5f88\u597d\u5730\u63a7\u5236\u4f4e\u56de\u62a5\u5c3e\u90e8\u7684\u60c5\u51b5\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6574\u4f53\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "Tail-aware Flow Fine-Tuning (TFFT)\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u5206\u5e03\u5fae\u8c03\u7b97\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165CVaR\u7684\u6982\u5ff5\u5b9e\u73b0\u4e86\u5bf9\u6a21\u578b\u5c3e\u90e8\u5206\u5e03\u7684\u6709\u6548\u63a7\u5236\uff0c\u4e3a\u6539\u5584\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.17654", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17654", "abs": "https://arxiv.org/abs/2602.17654", "authors": ["Jiaqi Xi", "Raghav Saboo", "Luming Chen", "Martin Wang", "Sudeep Das"], "title": "Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval", "comment": null, "summary": "We propose a two-stage \"Mine and Refine\" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\"Mine and Refine\"\u5bf9\u6bd4\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u591a\u7c7b\u522b\u7535\u5b50\u5546\u52a1\u641c\u7d22\u68c0\u7d22\u4e2d\u7684\u8bed\u4e49\u6587\u672c\u5d4c\u5165\u3002\u901a\u8fc7\u8f7b\u91cf\u7ea7LLM\u5fae\u8c03\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u653f\u7b56\u7684\u4e00\u81f4\u6027\u76d1\u7763\uff0c\u5e76\u4f7f\u7528\u6807\u7b7e\u611f\u77e5\u7684\u76d1\u7763\u5bf9\u6bd4\u76ee\u6807\u8bad\u7ec3\u591a\u8bed\u8a00Siamese\u53cc\u5854\u68c0\u7d22\u5668\uff0c\u518d\u901a\u8fc7ANN\u6316\u6398\u96be\u6837\u672c\u5e76\u91cd\u65b0\u6807\u6ce8\uff0c\u5f15\u5165circle loss\u7684\u591a\u7c7b\u6269\u5c55\u4ee5\u660e\u786e\u533a\u5206\u4e0d\u540c\u76f8\u5173\u7ea7\u522b\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\u754c\u9650\uff0c\u8fdb\u4e00\u6b65\u5b8c\u5584\u548c\u4e30\u5bcc\u4e86\u5d4c\u5165\u7a7a\u95f4\u3002", "motivation": "\u5927\u89c4\u6a21\u7535\u5b50\u5546\u52a1\u641c\u7d22\u9700\u8981\u80fd\u591f\u9002\u5e94\u957f\u5c3e\u3001\u566a\u58f0\u67e5\u8be2\u7684\u5d4c\u5165\u6280\u672f\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4ea7\u54c1\u548c\u653f\u7b56\u7ea6\u675f\u76f8\u517c\u5bb9\u7684\u53ef\u6269\u5c55\u76d1\u7763\u3002\u5b9e\u9645\u6311\u6218\u5728\u4e8e\u76f8\u5173\u6027\u901a\u5e38\u662f\u5206\u7ea7\u7684\uff1a\u7528\u6237\u63a5\u53d7\u66ff\u4ee3\u54c1\u6216\u8865\u5145\u54c1\u800c\u4e0d\u4ec5\u4ec5\u662f\u7cbe\u786e\u5339\u914d\uff0c\u751f\u4ea7\u7cfb\u7edf\u4ece\u8fd9\u4e9b\u76f8\u5173\u5c42\u9762\u4e0a\u6e05\u6670\u5206\u79bb\u76f8\u4f3c\u5ea6\u5f97\u5206\u4e2d\u53d7\u76ca\uff0c\u4ee5\u4fbf\u4e8e\u7a33\u5b9a\u6df7\u5408\u548c\u9608\u503c\u8bbe\u5b9a\u3002", "method": "1. \u5fae\u8c03\u8f7b\u91cf\u7ea7LLM\u5904\u7406\u4eba\u7c7b\u6ce8\u91ca\u4e0b\u7684\u4e09\u7ea7\u76f8\u5173\u6307\u5357\uff0c\u5e76\u901a\u8fc7\u53c2\u4e0e\u9a71\u52a8\u5ba1\u6838\u51cf\u5c11\u6b8b\u4f59\u566a\u97f3\u3002\n2. \u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u6807\u7b7e\u610f\u8bc6\u7684\u76d1\u7763\u5bf9\u6bd4\u76ee\u6807\u8bad\u7ec3\u4e00\u4e2a\u591a\u8bed\u8a00Siamese\u53cc\u5854\u68c0\u7d22\u5668\u3002\n3. \u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u6316\u6398\u96be\u6837\u672c\uff0c\u5e76\u7528\u7b56\u7565\u4e00\u81f4\u7684LLM\u91cd\u65b0\u6807\u6ce8\uff0c\u5f15\u5165\u4e00\u79cdcircle loss\u7684\u591a\u7c7b\u6269\u5c55\u65b9\u6cd5\u6765\u660e\u786e\u533a\u5206\u4e0d\u540c\u76f8\u5173\u7ea7\u522b\u95f4\u7684\u76f8\u4f3c\u8fb9\u754c\u3002\n4. \u901a\u8fc7\u9644\u52a0\u62fc\u5199\u589e\u5f3a\u548c\u5408\u6210\u67e5\u8be2\u751f\u6210\u8fdb\u4e00\u6b65\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u79bb\u7ebf\u8bc4\u4f30\u548c\u751f\u4ea7A/B\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u68c0\u7d22\u76f8\u5173\u6027\uff0c\u5e76\u5728\u53c2\u4e0e\u5ea6\u548c\u5546\u4e1a\u5f71\u54cd\u65b9\u9762\u53d6\u5f97\u4e86\u7edf\u8ba1\u5b66\u4e0a\u663e\u8457\u7684\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u201cMine and Refine\u201d\u4e24\u9636\u6bb5\u5bf9\u6bd4\u8bad\u7ec3\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u591a\u7c7b\u522b\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\u7684\u68c0\u7d22\u8d28\u91cf\u53ca\u7528\u6237\u4f53\u9a8c\uff0c\u540c\u65f6\u6ee1\u8db3\u4e86\u53ef\u6269\u5c55\u6027\u548c\u653f\u7b56\u4e00\u81f4\u6027\u8981\u6c42\u3002"}}
{"id": "2602.17498", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17498", "abs": "https://arxiv.org/abs/2602.17498", "authors": ["Julian Frattini", "Quim Motger"], "title": "Towards a Software Reference Architecture for Natural Language Processing Tools in Requirements Engineering", "comment": null, "summary": "Natural Language Processing (NLP) tools support requirements engineering (RE) tasks like requirements elicitation, classification, and validation. However, they are often developed from scratch despite functional overlaps, and abandoned after publication. This lack of interoperability and maintenance incurs unnecessary development effort, impedes tool comparison and benchmarking, complicates documentation, and diminishes the long-term sustainability of NLP4RE tools. To address these issues, we postulate a vision to transition from monolithic NLP4RE tools to an ecosystem of reusable, interoperable modules. We outline a research roadmap towards a software reference architecture (SRA) to realize this vision, elaborated following a standard methodological framework for SRA development. As an initial step, we conducted a stakeholder-driven focus group session to elicit generic system requirements for NLP4RE tools. This activity resulted in 36 key system requirements, further motivating the need for a dedicated SRA. Overall, the proposed vision, roadmap, and initial contribution pave the way towards improved development, reuse, and long-term maintenance of NLP4RE tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u5355\u4e00\u7684NLP4RE\u5de5\u5177\u8f6c\u5411\u53ef\u91cd\u7528\u3001\u53ef\u4e92\u64cd\u4f5c\u6a21\u5757\u751f\u6001\u7cfb\u7edf\u7684\u613f\u666f\uff0c\u5e76\u4e3a\u6b64\u5236\u5b9a\u4e86\u4e00\u4e2a\u8f6f\u4ef6\u53c2\u8003\u67b6\u6784\uff08SRA\uff09\u7684\u7814\u53d1\u8def\u7ebf\u56fe\uff0c\u4ee5\u4fc3\u8fdb\u6b64\u7c7b\u5de5\u5177\u7684\u5f00\u53d1\u3001\u590d\u7528\u53ca\u957f\u671f\u7ef4\u62a4\u3002", "motivation": "\u5f53\u524dNLP\u5de5\u5177\u5728\u652f\u6301\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\u65f6\u5b58\u5728\u529f\u80fd\u91cd\u590d\u5efa\u8bbe\u3001\u7f3a\u4e4f\u4e92\u64cd\u4f5c\u6027\u4ee5\u53ca\u7ef4\u62a4\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u5f00\u53d1\u5de5\u4f5c\u91cf\u589e\u52a0\uff0c\u963b\u788d\u4e86\u5de5\u5177\u6bd4\u8f83\u4e0e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u540c\u65f6\u589e\u52a0\u4e86\u6587\u6863\u7f16\u5236\u96be\u5ea6\uff0c\u964d\u4f4e\u4e86NLP4RE\u5de5\u5177\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "method": "\u4f5c\u8005\u4eec\u9996\u5148\u63d0\u51fa\u4e86\u5411\u53ef\u91cd\u7528\u3001\u53ef\u4e92\u64cd\u4f5c\u6a21\u5757\u751f\u6001\u7cfb\u7edf\u8fc7\u6e21\u7684\u613f\u666f\uff1b\u63a5\u7740\uff0c\u6309\u7167\u6807\u51c6\u65b9\u6cd5\u8bba\u6846\u67b6\u8be6\u7ec6\u89c4\u5212\u4e86\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u6240\u9700\u7684\u8f6f\u4ef6\u53c2\u8003\u67b6\u6784\uff08SRA\uff09\u7814\u53d1\u8def\u7ebf\u56fe\uff1b\u6700\u540e\uff0c\u901a\u8fc7\u5f00\u5c55\u5229\u76ca\u76f8\u5173\u8005\u9a71\u52a8\u7684\u91cd\u70b9\u5c0f\u7ec4\u4f1a\u8bae\u6765\u6536\u96c6NLP4RE\u5de5\u5177\u7684\u4e00\u822c\u7cfb\u7edf\u9700\u6c42\u3002", "result": "\u7814\u7a76\u6d3b\u52a8\u6210\u529f\u5730\u8bc6\u522b\u51fa36\u4e2a\u5173\u952e\u7cfb\u7edf\u9700\u6c42\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u4e13\u95e8\u8bbe\u8ba1SRA\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u613f\u666f\u3001\u8def\u7ebf\u56fe\u548c\u521d\u6b65\u8d21\u732e\u4e3a\u6539\u8fdbNLP4RE\u5de5\u5177\u7684\u5f00\u53d1\u3001\u590d\u7528\u53ca\u5176\u957f\u671f\u7ef4\u62a4\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16821", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16821", "abs": "https://arxiv.org/abs/2602.16821", "authors": ["Ammar Kheder", "Helmi Toropainen", "Wenqing Peng", "Samuel Ant\u00e3o", "Jia Chen", "Zhi-Song Liu", "Michael Boy"], "title": "TopoFlow: Physics-guided Neural Networks for high-resolution air quality prediction", "comment": null, "summary": "We propose TopoFlow (Topography-aware pollutant Flow learning), a physics-guided neural network for efficient, high-resolution air quality prediction. To explicitly embed physical processes into the learning framework, we identify two critical factors governing pollutant dynamics: topography and wind direction. Complex terrain can channel, block, and trap pollutants, while wind acts as a primary driver of their transport and dispersion. Building on these insights, TopoFlow leverages a vision transformer architecture with two novel mechanisms: topography-aware attention, which explicitly models terrain-induced flow patterns, and wind-guided patch reordering, which aligns spatial representations with prevailing wind directions. Trained on six years of high-resolution reanalysis data assimilating observations from over 1,400 surface monitoring stations across China, TopoFlow achieves a PM2.5 RMSE of 9.71 ug/m3, representing a 71-80% improvement over operational forecasting systems and a 13% improvement over state-of-the-art AI baselines. Forecast errors remain well below China's 24-hour air quality threshold of 75 ug/m3 (GB 3095-2012), enabling reliable discrimination between clean and polluted conditions. These performance gains are consistent across all four major pollutants and forecast lead times from 12 to 96 hours, demonstrating that principled integration of physical knowledge into neural networks can fundamentally advance air quality prediction.", "AI": {"tldr": "TopoFlow, a physics-guided neural network, incorporates topography and wind direction to predict air quality with high resolution. It uses topography-aware attention and wind-guided patch reordering, achieving a 71-80% improvement over current forecasting systems for PM2.5 prediction.", "motivation": "The motivation is to improve the accuracy of air quality predictions by integrating physical processes, specifically the effects of topography and wind direction, into the learning model. This addresses the limitations of existing models in handling complex terrain and wind dynamics, which are crucial for pollutant transport and dispersion.", "method": "TopoFlow employs a vision transformer architecture enhanced with two mechanisms: topography-aware attention that considers terrain-induced flow patterns, and wind-guided patch reordering that aligns spatial representations with the prevailing wind directions. The model was trained on six years of high-resolution reanalysis data from over 1,400 surface monitoring stations in China.", "result": "TopoFlow achieved a PM2.5 RMSE of 9.71 ug/m3, marking a 71-80% improvement over operational forecasting systems and a 13% enhancement over state-of-the-art AI baselines. The model also reliably discriminates between clean and polluted conditions, maintaining forecast errors below China's 24-hour air quality threshold of 75 ug/m3 (GB 3095-2012).", "conclusion": "The integration of physical knowledge regarding topography and wind direction into neural networks significantly advances air quality prediction, as demonstrated by TopoFlow's consistent performance improvements across major pollutants and various forecast lead times."}}
{"id": "2602.16826", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16826", "abs": "https://arxiv.org/abs/2602.16826", "authors": ["Nigel Doering", "Rahath Malladi", "Arshia Sangwan", "David Danks", "Tauhidur Rahman"], "title": "HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind", "comment": "Accepted at the Workshop on Theory of Mind for AI (ToM4AI) at the 40th AAAI Conference on Artificial Intelligence (AAAI-26), Singapore, 2026", "summary": "Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Inspired by the belief-desire-intention structure of human cognition, our three-level VAE hierarchy achieves substantial performance improvements on a 3,185-node campus navigation task. However, we identify a critical limitation: while our hierarchical structure improves prediction, learned latent representations lack explicit grounding to actual mental states. We propose self-supervised alignment strategies and present this work to solicit community feedback on grounding approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHiVAE\u7684\u5206\u5c42\u53d8\u5206\u67b6\u6784\uff0c\u65e8\u5728\u5c06\u5fc3\u667a\u7406\u8bba(ToM)\u63a8\u7406\u6269\u5c55\u5230\u66f4\u771f\u5b9e\u7684\u65f6\u7a7a\u9886\u57df\u3002\u901a\u8fc7\u5728\u5177\u67093,185\u4e2a\u8282\u70b9\u7684\u6821\u56ed\u5bfc\u822a\u4efb\u52a1\u4e0a\u6d4b\u8bd5\uff0c\u8be5\u67b6\u6784\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002\u4e0d\u8fc7\uff0c\u4e5f\u6307\u51fa\u4e86\u4e00\u4e2a\u5173\u952e\u9650\u5236\uff1a\u867d\u7136\u8fd9\u79cd\u5206\u5c42\u7ed3\u6784\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u6240\u5b66\u5230\u7684\u6f5c\u5728\u8868\u793a\u7f3a\u4e4f\u4e0e\u5b9e\u9645\u5fc3\u7406\u72b6\u6001\u7684\u5177\u4f53\u8054\u7cfb\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u81ea\u6211\u76d1\u7763\u5bf9\u9f50\u7b56\u7565\uff0c\u5e76\u5bfb\u6c42\u793e\u533a\u5bf9\u4e8e\u5982\u4f55\u66f4\u597d\u5730\u5b9e\u73b0\u8fd9\u4e9b\u6f5c\u5728\u8868\u793a\u4e0e\u771f\u5b9e\u5fc3\u7406\u72b6\u6001\u4e4b\u95f4\u7684\u5173\u8054\u7684\u610f\u89c1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u6613\u4e8e\u4eba\u7c7b\u7406\u89e3\u7684\u5c0f\u89c4\u6a21\u7f51\u683c\u4e16\u754c\u7a7a\u95f4\u4e2d\u5e94\u7528\u5fc3\u667a\u7406\u8bba(ToM)\uff0c\u800c\u8fd9\u9879\u5de5\u4f5c\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5c06ToM\u63a8\u7406\u80fd\u529b\u6269\u5c55\u81f3\u66f4\u52a0\u590d\u6742\u4e14\u8d34\u8fd1\u73b0\u5b9e\u4e16\u754c\u7684\u65f6\u7a7a\u73af\u5883\u4e0b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86HiVAE\uff08\u5206\u5c42\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\uff09\uff0c\u5b83\u53d7\u5230\u4eba\u7c7b\u8ba4\u77e5\u4e2d\u7684\u4fe1\u5ff5-\u6b32\u671b-\u610f\u56fe\u7ed3\u6784\u542f\u53d1\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u4e09\u5c42VAE\u5c42\u6b21\u7ed3\u6784\u6765\u6539\u5584ToM\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e00\u9879\u6d89\u53ca3,185\u4e2a\u8282\u70b9\u7684\u6821\u56ed\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0cHiVAE\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1b\u7136\u800c\uff0c\u540c\u65f6\u4e5f\u53d1\u73b0\u6240\u5b66\u4e60\u5230\u7684\u6f5c\u5728\u8868\u5f81\u672a\u80fd\u660e\u786e\u5730\u4e0e\u5b9e\u9645\u7684\u5fc3\u7406\u72b6\u6001\u76f8\u8054\u7cfb\u3002", "conclusion": "\u5c3d\u7ba1HiVAE\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8ToM\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u65f6\uff0c\u4f46\u5176\u6f5c\u5728\u8868\u793a\u7f3a\u4e4f\u4e0e\u5b9e\u9645\u5fc3\u7406\u72b6\u6001\u7684\u76f4\u63a5\u5bf9\u5e94\u5173\u7cfb\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e9b\u81ea\u6211\u76d1\u7763\u7684\u5bf9\u9f50\u7b56\u7565\uff0c\u5e76\u5e0c\u671b\u5f97\u5230\u66f4\u591a\u5173\u4e8e\u5982\u4f55\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u53cd\u9988\u3002"}}
{"id": "2602.16833", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16833", "abs": "https://arxiv.org/abs/2602.16833", "authors": ["Zhicheng Zhang", "Ziyan Wang", "Yali Du", "Fei Fang"], "title": "VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study", "comment": null, "summary": "Exploration remains a key bottleneck for reinforcement learning (RL) post-training of large language models (LLMs), where sparse feedback and large action spaces can lead to premature collapse into repetitive behaviors. We propose Verbalized Action Masking (VAM), which verbalizes an action mask in the prompt and enforces that the model outputs an action from the masked set. Building on this interface, we introduce iterative action-space pruning: if the target action is not sampled, we remove valid sampled actions from the mask and resample under the reduced candidate set, repeating until the target is sampled or a fixed budget is exhausted. We study VAM in chess and evaluate it under two training regimes: an engine-play regime that generates states via play against an engine opponent and a fixed-dataset regime that trains from a fixed dataset of positions with verifier scores. Across held-out chess puzzles and full-game play measured by average centipawn loss (ACPL), VAM improves learning efficiency and final performance over strong baselines, highlighting verbalized masking as a practical mechanism for controllable exploration in LLM RL post-training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVerbalized Action Masking (VAM)\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u3002\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u53e3\u5934\u5316\u884c\u52a8\u63a9\u7801\uff0c\u5e76\u57fa\u4e8e\u6b64\u6267\u884c\u8fed\u4ee3\u52a8\u4f5c\u7a7a\u95f4\u526a\u679d\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u5728\u56fd\u9645\u8c61\u68cb\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e86\u6bd4\u5f3a\u57fa\u7ebf\u66f4\u597d\u7684\u5b66\u4e60\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5f3a\u5316\u5b66\u4e60(RL)\u540e\u8bad\u7ec3\u9636\u6bb5\u9047\u5230\u7684\u63a2\u7d22\u74f6\u9888\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u7a00\u758f\u53cd\u9988\u548c\u5927\u52a8\u4f5c\u7a7a\u95f4\u65f6\u5bb9\u6613\u9677\u5165\u91cd\u590d\u884c\u4e3a\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Verbalized Action Masking (VAM)\u6280\u672f\uff0c\u5b83\u5c06\u52a8\u4f5c\u63a9\u7801\u53e3\u5934\u5316\u5e76\u5728\u63d0\u793a\u4e2d\u5b9e\u65bd\uff0c\u786e\u4fdd\u6a21\u578b\u4ec5\u4ece\u88ab\u63a9\u7801\u7684\u52a8\u4f5c\u96c6\u4e2d\u8f93\u51fa\u52a8\u4f5c\uff1b\u5e76\u4e14\u57fa\u4e8e\u8fd9\u79cd\u65b9\u6cd5\u5f15\u5165\u4e86\u8fed\u4ee3\u5f0f\u52a8\u4f5c\u7a7a\u95f4\u524a\u51cf\uff1a\u5982\u679c\u76ee\u6807\u52a8\u4f5c\u6ca1\u6709\u88ab\u91c7\u6837\uff0c\u5219\u4ece\u63a9\u7801\u4e2d\u79fb\u9664\u6709\u6548\u7684\u5df2\u91c7\u6837\u52a8\u4f5c\uff0c\u5e76\u5728\u51cf\u5c11\u540e\u7684\u5019\u9009\u96c6\u5408\u4e0b\u91cd\u65b0\u91c7\u6837\uff0c\u76f4\u81f3\u62bd\u5230\u76ee\u6807\u6216\u8fbe\u5230\u9884\u5b9a\u6b21\u6570\u4e3a\u6b62\u3002", "result": "\u5728\u56fd\u9645\u8c61\u68cb\u7684\u7814\u7a76\u6848\u4f8b\u4e2d\uff0c\u65e0\u8bba\u662f\u5728\u4e0e\u5f15\u64ce\u5bf9\u624b\u5bf9\u5f08\u751f\u6210\u72b6\u6001\u7684\u5f15\u64ce\u73a9\u6cd5\u6a21\u5f0f\u8fd8\u662f\u4f7f\u7528\u5e26\u6709\u9a8c\u8bc1\u8005\u8bc4\u5206\u7684\u56fa\u5b9a\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u7684\u6a21\u5f0f\u4e0b\uff0cVAM\u76f8\u6bd4\u5f3a\u5927\u7684\u57fa\u7ebf\u90fd\u5c55\u73b0\u51fa\u4e86\u66f4\u9ad8\u7684\u5b66\u4e60\u6548\u7387\u53ca\u6700\u7ec8\u8868\u73b0\u3002", "conclusion": "VAM\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u5b9e\u7528\u7684\u53ef\u63a7\u63a2\u7d22\u673a\u5236\uff0c\u5728\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u8868\u73b0\u65b9\u9762\u663e\u793a\u51fa\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2602.16837", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16837", "abs": "https://arxiv.org/abs/2602.16837", "authors": ["Hanna Herasimchyk", "Robin Labryga", "Tomislav Prusina", "S\u00f6ren Laue"], "title": "A Residual-Aware Theory of Position Bias in Transformers", "comment": null, "summary": "Transformer models systematically favor certain token positions, yet the architectural origins of this position bias remain poorly understood. Under causal masking at infinite depth, prior theoretical analyses of attention rollout predict an inevitable collapse of attention onto the first token. Such collapse, however, does not occur in practice. We resolve this discrepancy with a residual-aware theory of cumulative attention rollout. By incorporating residual connections, we show that this architectural component prevents collapse under realistic conditions. At finite depth, we prove that causal Transformers induce a U-shaped position bias, with attention concentrating on early and late tokens. This result provides a principled architectural explanation for the Lost-in-the-Middle phenomenon.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u8003\u8651\u6b8b\u5dee\u8fde\u63a5\u7684\u7d2f\u79ef\u6ce8\u610f\u529b\u4f20\u64ad\u7406\u8bba\uff0c\u89e3\u51b3\u4e86\u4e4b\u524d\u7406\u8bba\u9884\u6d4b\u4e0e\u5b9e\u9645\u89c2\u5bdf\u5230\u7684Transformer\u6a21\u578b\u4f4d\u7f6e\u504f\u7f6e\u73b0\u8c61\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u8bc1\u660e\u4e86\u56e0\u679cTransformer\u5728\u6709\u9650\u6df1\u5ea6\u4e0b\u4f1a\u4ea7\u751fU\u5f62\u7684\u4f4d\u7f6e\u504f\u7f6e\uff0c\u5373\u6ce8\u610f\u529b\u96c6\u4e2d\u5728\u5e8f\u5217\u7684\u5f00\u5934\u548c\u7ed3\u5c3e\u5904\uff0c\u4e3a'Lost-in-the-Middle'\u73b0\u8c61\u63d0\u4f9b\u4e86\u67b6\u6784\u5c42\u9762\u7684\u89e3\u91ca\u3002", "motivation": "\u5148\u524d\u5bf9\u4e8e\u6ce8\u610f\u529b\u4f20\u64ad\u7684\u7406\u8bba\u5206\u6790\u9884\u6d4b\uff0c\u5728\u65e0\u9650\u6df1\u5ea6\u4e14\u91c7\u7528\u56e0\u679c\u63a9\u7801\u7684\u60c5\u51b5\u4e0b\uff0c\u6ce8\u610f\u529b\u4f1a\u4e0d\u53ef\u907f\u514d\u5730\u96c6\u4e2d\u4e8e\u7b2c\u4e00\u4e2atoken\u4e0a\u3002\u7136\u800c\uff0c\u5b9e\u9645\u60c5\u51b5\u5e76\u975e\u5982\u6b64\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u7406\u8bba\u9884\u6d4b\u4e0e\u5b9e\u8df5\u7ecf\u9a8c\u4e0d\u7b26\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22Transformer\u6a21\u578b\u4e2d\u4f4d\u7f6e\u504f\u7f6e\u7684\u786e\u5207\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8003\u8651\u5230\u6b8b\u5dee\u8fde\u63a5\u7684\u7d2f\u79ef\u6ce8\u610f\u529b\u4f20\u64ad\u65b0\u7406\u8bba\uff1b\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u5206\u6790\u4e86\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\uff08\u5373\u6709\u9650\u5c42\u6570\uff09\u6b8b\u5dee\u8fde\u63a5\u5982\u4f55\u9632\u6b62\u6ce8\u610f\u529b\u5b8c\u5168\u574d\u7f29\u5230\u9996\u4e2atoken\u4e0a\uff1b\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u56e0\u679c\u5173\u7cfb\u4e0b\u7684Transformer\u6a21\u578b\u4f1a\u5728\u6709\u9650\u6df1\u5ea6\u5185\u5f62\u6210\u4e00\u79cdU\u578b\u7684\u4f4d\u7f6e\u504f\u597d\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u6b8b\u5dee\u8fde\u63a5\u662f\u963b\u6b62\u6ce8\u610f\u529b\u5b8c\u5168\u574d\u7f29\u7684\u5173\u952e\u56e0\u7d20\uff1b\u63ed\u793a\u4e86\u56e0\u679cTransformer\u786e\u5b9e\u503e\u5411\u4e8e\u5728\u5e8f\u5217\u7684\u8d77\u59cb\u7aef\u548c\u672b\u7aef\u5206\u914d\u66f4\u591a\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u4ece\u800c\u5f62\u6210U\u5f62\u5206\u5e03\u7279\u5f81\uff1b\u4e3a\u2018\u8ff7\u5931\u4e2d\u95f4\u2019\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7ed3\u6784\u7684\u5408\u7406\u89e3\u91ca\u3002", "conclusion": "\u672c\u7814\u7a76\u4e0d\u4ec5\u9610\u660e\u4e86Transformer\u67b6\u6784\u4e2d\u4f4d\u7f6e\u504f\u7f6e\u73b0\u8c61\u80cc\u540e\u7684\u673a\u5236\uff0c\u8fd8\u5f3a\u8c03\u4e86\u6b8b\u5dee\u8fde\u63a5\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002\u8fd9\u4e9b\u53d1\u73b0\u52a0\u6df1\u4e86\u6211\u4eec\u5bf9Transformer\u5de5\u4f5c\u539f\u7406\u7684\u7406\u89e3\uff0c\u5e76\u53ef\u80fd\u6307\u5bfc\u672a\u6765\u66f4\u9ad8\u6548\u67b6\u6784\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2602.16839", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16839", "abs": "https://arxiv.org/abs/2602.16839", "authors": ["Zeliang Zhang", "Xiaodong Liu", "Hao Cheng", "Hao Sun", "Chenliang Xu", "Jianfeng Gao"], "title": "Training Large Reasoning Models Efficiently via Progressive Thought Encoding", "comment": "ICLR 2026, 15 pages", "summary": "Large reasoning models (LRMs) excel on complex problems but face a critical barrier to efficiency: reinforcement learning (RL) training requires long rollouts for outcome-based rewards, where autoregressive decoding dominates time and memory usage. While sliding-window cache strategies can bound memory, they disrupt long-context reasoning and degrade performance. We introduce Progressive Thought Encoding, a parameter-efficient fine-tuning method that enables LRMs to reason effectively under fixed-size caches. By progressively encoding intermediate reasoning into fixed-size vector representations, our approach eliminates the need to backpropagate through full-cache rollouts, thereby reducing memory usage, while maintaining constant memory during inference. Experiments on three models, including Qwen2.5-3B-Instruct, Qwen2.5-7B-Instruct, and DeepSeek-R1-Distill-Llama-8B, on six widely used challenging mathematical benchmarks show consistent gains: our method achieves +19.3% improvement over LoRA-based fine-tuning and +29.9% over LRMs without fine-tuning on average, with up to +23.4 accuracy improvement on AIME2024/2025 under the same tight cache budgets. These results demonstrate that Progressive Thought Encoding not only improves reasoning accuracy but also makes RL training of LRMs substantially more efficient and scalable under real-world memory constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\u2014\u2014\u6e10\u8fdb\u601d\u60f3\u7f16\u7801\uff0c\u8be5\u65b9\u6cd5\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u591f\u5728\u56fa\u5b9a\u5927\u5c0f\u7684\u7f13\u5b58\u4e0b\u6709\u6548\u8fdb\u884c\u63a8\u7406\u3002\u901a\u8fc7\u5c06\u4e2d\u95f4\u63a8\u7406\u9010\u6b65\u7f16\u7801\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u8868\u793a\uff0c\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5185\u5b58\u5360\u7528\u4e0d\u53d8\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eLoRA\u5fae\u8c03\u548c\u5176\u4ed6\u672a\u5fae\u8c03\u7684\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u76f8\u6bd4\uff0c\u672c\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u63d0\u9ad8\u4e86RL\u8bad\u7ec3\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6548\u7387\u65b9\u9762\u9762\u4e34\u4e00\u4e2a\u5173\u952e\u969c\u788d\uff1a\u57fa\u4e8e\u7ed3\u679c\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u9700\u8981\u957f\u65f6\u95f4\u5c55\u5f00\uff0c\u5176\u4e2d\u81ea\u56de\u5f52\u89e3\u7801\u5360\u636e\u4e86\u5927\u91cf\u65f6\u95f4\u548c\u5185\u5b58\u3002\u867d\u7136\u6ed1\u52a8\u7a97\u53e3\u7f13\u5b58\u7b56\u7565\u53ef\u4ee5\u9650\u5236\u5185\u5b58\u4f7f\u7528\uff0c\u4f46\u4f1a\u7834\u574f\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u5e76\u964d\u4f4e\u6027\u80fd\u3002", "method": "\u5f15\u5165\u4e86\u6e10\u8fdb\u601d\u60f3\u7f16\u7801\uff0c\u8fd9\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5141\u8bb8LRMs\u5728\u56fa\u5b9a\u5927\u5c0f\u7684\u7f13\u5b58\u6761\u4ef6\u4e0b\u6709\u6548\u63a8\u7406\u3002\u901a\u8fc7\u5c06\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u9010\u6b65\u7f16\u7801\u4e3a\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\u8868\u793a\uff0c\u907f\u514d\u4e86\u5728\u6574\u4e2a\u7f13\u5b58\u5c55\u5f00\u8fc7\u7a0b\u4e2d\u53cd\u5411\u4f20\u64ad\u7684\u9700\u6c42\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u671f\u95f4\u4fdd\u6301\u6052\u5b9a\u7684\u5185\u5b58\u6d88\u8017\u3002", "result": "\u5728\u4e09\u4e2a\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ecQwen2.5-3B-Instruct\u3001Qwen2.5-7B-Instruct\u548cDeepSeek-R1-Distill-Llama-8B\uff0c\u5728\u516d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u4e86\u4e00\u81f4\u7684\u8fdb\u6b65\uff1a\u4e0e\u57fa\u4e8eLoRA\u7684\u5fae\u8c03\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad8\u4e8619.3%\uff0c\u4e0e\u6ca1\u6709\u5fae\u8c03\u7684LRMs\u76f8\u6bd4\u63d0\u9ad8\u4e8629.9%\uff1b\u5728\u76f8\u540c\u7684\u4e25\u683c\u7f13\u5b58\u9884\u7b97\u4e0b\uff0cAIME2024/2025\u4e0a\u7684\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u5347\u4e8623.4%\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86\u6e10\u8fdb\u601d\u60f3\u7f16\u7801\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\uff0c\u8fd8\u4f7f\u5f97LRMs\u5728\u5b9e\u9645\u5185\u5b58\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684RL\u8bad\u7ec3\u66f4\u52a0\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u3002"}}
{"id": "2602.16842", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16842", "abs": "https://arxiv.org/abs/2602.16842", "authors": ["Rachitesh Kumar", "Omar Mouchtaki"], "title": "What is the Value of Censored Data? An Exact Analysis for the Data-driven Newsvendor", "comment": null, "summary": "We study the offline data-driven newsvendor problem with censored demand data. In contrast to prior works where demand is fully observed, we consider the setting where demand is censored at the inventory level and only sales are observed; sales match demand when there is sufficient inventory, and equal the available inventory otherwise. We provide a general procedure to compute the exact worst-case regret of classical data-driven inventory policies, evaluated over all demand distributions. Our main technical result shows that this infinite-dimensional, non-convex optimization problem can be reduced to a finite-dimensional one, enabling an exact characterization of the performance of policies for any sample size and censoring levels. We leverage this reduction to derive sharp insights on the achievable performance of standard inventory policies under demand censoring. In particular, our analysis of the Kaplan-Meier policy shows that while demand censoring fundamentally limits what can be learned from passive sales data, just a small amount of targeted exploration at high inventory levels can substantially improve worst-case guarantees, enabling near-optimal performance even under heavy censoring. In contrast, when the point-of-sale system does not record stockout events and only reports realized sales, a natural and commonly used approach is to treat sales as demand. Our results show that policies based on this sales-as-demand heuristic can suffer severe performance degradation as censored data accumulates, highlighting how the quality of point-of-sale information critically shapes what can, and cannot, be learned offline.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u9700\u6c42\u6570\u636e\u88ab\u5e93\u5b58\u6c34\u5e73\u622a\u65ad\u7684\u60c5\u51b5\u4e0b\uff0c\u79bb\u7ebf\u6570\u636e\u9a71\u52a8\u7684\u62a5\u7ae5\u95ee\u9898\u3002\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u8ba1\u7b97\u7ecf\u5178\u6570\u636e\u9a71\u52a8\u5e93\u5b58\u7b56\u7565\u7684\u786e\u5207\u6700\u574f\u60c5\u51b5\u9057\u61be\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u8be5\u95ee\u9898\u53ef\u4ee5\u7b80\u5316\u4e3a\u6709\u9650\u7ef4\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u800c\u5bf9\u5404\u79cd\u6837\u672c\u91cf\u548c\u622a\u65ad\u6c34\u5e73\u4e0b\u7684\u653f\u7b56\u8868\u73b0\u8fdb\u884c\u7cbe\u786e\u523b\u753b\u3002\u7279\u522b\u662f\u5206\u6790\u4e86Kaplan-Meier\u7b56\u7565\uff0c\u8868\u660e\u5373\u4f7f\u5728\u4e25\u91cd\u622a\u65ad\u60c5\u51b5\u4e0b\uff0c\u5c11\u91cf\u6709\u9488\u5bf9\u6027\u7684\u9ad8\u5e93\u5b58\u63a2\u7d22\u4e5f\u80fd\u663e\u8457\u6539\u5584\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\uff0c\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u8868\u73b0\u3002\u800c\u57fa\u4e8e\u9500\u552e\u5373\u9700\u6c42\u542f\u53d1\u5f0f\u7684\u7b56\u7565\u5219\u53ef\u80fd\u968f\u7740\u622a\u65ad\u6570\u636e\u79ef\u7d2f\u906d\u53d7\u4e25\u91cd\u7684\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5f53\u9700\u6c42\u6570\u636e\u88ab\u5e93\u5b58\u6c34\u5e73\u622a\u65ad\u65f6\u7684\u6570\u636e\u9a71\u52a8\u62a5\u7ae5\u95ee\u9898\uff0c\u4e0e\u4e4b\u524d\u5de5\u4f5c\u4e2d\u7684\u5b8c\u5168\u89c2\u5bdf\u9700\u6c42\u4e0d\u540c\uff0c\u5728\u6b64\u8bbe\u7f6e\u4e0b\u4ec5\u80fd\u89c2\u5bdf\u5230\u9500\u552e\u989d\u5ea6\uff1b\u5f53\u5e93\u5b58\u5145\u8db3\u65f6\u9500\u552e\u989d\u7b49\u4e8e\u9700\u6c42\uff0c\u5426\u5219\u7b49\u4e8e\u53ef\u5f97\u5e93\u5b58\u3002\u8fd9\u4e00\u95ee\u9898\u7684\u6838\u5fc3\u5728\u4e8e\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u4e0d\u5b8c\u5168\u4fe1\u606f\u6765\u4f18\u5316\u5e93\u5b58\u7ba1\u7406\u51b3\u7b56\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u8fc7\u7a0b\u6765\u8ba1\u7b97\u6240\u6709\u9700\u6c42\u5206\u5e03\u4e0a\u8bc4\u4f30\u7684\u7ecf\u5178\u6570\u636e\u9a71\u52a8\u5e93\u5b58\u7b56\u7565\u7684\u786e\u5207\u6700\u574f\u60c5\u51b5\u9057\u61be\u3002\u4e3b\u8981\u6280\u672f\u6210\u679c\u8868\u660e\uff0c\u8fd9\u4e2a\u65e0\u9650\u7ef4\u975e\u51f8\u4f18\u5316\u95ee\u9898\u53ef\u4ee5\u51cf\u5c11\u5230\u4e00\u4e2a\u6709\u9650\u7ef4\u7684\u95ee\u9898\uff0c\u8fd9\u4f7f\u5f97\u80fd\u591f\u5bf9\u4efb\u4f55\u6837\u672c\u5927\u5c0f\u548c\u622a\u65ad\u6c34\u5e73\u4e0b\u7684\u7b56\u7565\u6027\u80fd\u8fdb\u884c\u7cbe\u786e\u63cf\u8ff0\u3002\u6b64\u5916\uff0c\u8fd8\u7279\u522b\u5206\u6790\u4e86Kaplan-Meier\u7b56\u7565\u53ca\u57fa\u4e8e\u9500\u552e\u5373\u9700\u6c42\u5047\u8bbe\u7684\u7b56\u7565\u8868\u73b0\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u9700\u6c42\u622a\u65ad\u4ece\u6839\u672c\u4e0a\u9650\u5236\u4e86\u4ece\u88ab\u52a8\u9500\u552e\u6570\u636e\u4e2d\u6240\u80fd\u5b66\u5230\u7684\u4fe1\u606f\u91cf\uff0c\u4f46\u53ea\u8981\u5728\u8f83\u9ad8\u5e93\u5b58\u6c34\u5e73\u4e0a\u8fdb\u884c\u5c11\u91cf\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\u5c31\u53ef\u4ee5\u5927\u5e45\u63d0\u9ad8\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u4fdd\u8bc1\uff0c\u5373\u4f7f\u5728\u4e25\u91cd\u622a\u65ad\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u8868\u73b0\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5982\u679cPOS\u7cfb\u7edf\u672a\u8bb0\u5f55\u7f3a\u8d27\u4e8b\u4ef6\u4e14\u4ec5\u62a5\u544a\u5b9e\u9645\u9500\u552e\uff0c\u5219\u57fa\u4e8e\u9500\u552e\u5373\u9700\u6c42\u5047\u8bbe\u7684\u7b56\u7565\u53ef\u80fd\u4f1a\u968f\u7740\u622a\u65ad\u6570\u636e\u7684\u7d2f\u79ef\u800c\u7ecf\u5386\u4e25\u91cd\u7684\u6027\u80fd\u9000\u5316\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u9500\u552e\u70b9\u4fe1\u606f\u7cfb\u7edf\u8d28\u91cf\u5bf9\u4e8e\u79bb\u7ebf\u5b66\u4e60\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002\u5373\u4f7f\u662f\u5728\u9700\u6c42\u6570\u636e\u88ab\u622a\u65ad\u7684\u60c5\u5f62\u4e0b\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u8bbe\u8ba1\uff08\u5982\uff1a\u9488\u5bf9\u9ad8\u5e93\u5b58\u6c34\u5e73\u7684\u63a2\u7d22\uff09\uff0c\u4ecd\u6709\u53ef\u80fd\u83b7\u5f97\u63a5\u8fd1\u6700\u4f18\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u5982\u679c\u7b80\u5355\u5730\u5c06\u9500\u552e\u7b49\u540c\u4e8e\u9700\u6c42\uff0c\u5219\u53ef\u80fd\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u635f\u5931\u3002"}}
{"id": "2602.16864", "categories": ["cs.LG", "cs.AI", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.16864", "abs": "https://arxiv.org/abs/2602.16864", "authors": ["Daniel Durstewitz", "Christoph J\u00fcrgen Hemmer", "Florian Hess", "Charlotte Ricarda Doll", "Lukas Eisenmann"], "title": "Position: Why a Dynamical Systems Perspective is Needed to Advance Time Series Modeling", "comment": null, "summary": "Time series (TS) modeling has come a long way from early statistical, mainly linear, approaches to the current trend in TS foundation models. With a lot of hype and industrial demand in this field, it is not always clear how much progress there really is. To advance TS forecasting and analysis to the next level, here we argue that the field needs a dynamical systems (DS) perspective. TS of observations from natural or engineered systems almost always originate from some underlying DS, and arguably access to its governing equations would yield theoretically optimal forecasts. This is the promise of DS reconstruction (DSR), a class of ML/AI approaches that aim to infer surrogate models of the underlying DS from data. But models based on DS principles offer other profound advantages: Beyond short-term forecasts, they enable to predict the long-term statistics of an observed system, which in many practical scenarios may be the more relevant quantities. DS theory furthermore provides domain-independent theoretical insight into mechanisms underlying TS generation, and thereby will inform us, e.g., about upper bounds on performance of any TS model, generalization into unseen regimes as in tipping points, or potential control strategies. After reviewing some of the central concepts, methods, measures, and models in DS theory and DSR, we will discuss how insights from this field can advance TS modeling in crucial ways, enabling better forecasting with much lower computational and memory footprints. We conclude with a number of specific suggestions for translating insights from DSR into TS modeling.", "AI": {"tldr": "The paper argues for the integration of a dynamical systems (DS) perspective into time series (TS) forecasting and analysis, suggesting that DS reconstruction (DSR) methods can provide more accurate long-term forecasts and deeper theoretical insights into TS generation. It reviews key concepts in DS theory and DSR, illustrating how these can improve TS modeling with reduced computational and memory requirements, and concludes with specific recommendations for applying DSR to TS.", "motivation": "\u9274\u4e8e\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u9886\u57df\u4ece\u65e9\u671f\u7684\u7edf\u8ba1\u65b9\u6cd5\u53d1\u5c55\u5230\u5f53\u524d\u7684\u57fa\u7840\u6a21\u578b\u8d8b\u52bf\uff0c\u6587\u7ae0\u63d0\u51fa\u9700\u8981\u91c7\u7528\u52a8\u529b\u7cfb\u7edf\uff08DS\uff09\u7684\u89c6\u89d2\u6765\u63a8\u52a8\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u5206\u6790\u8fbe\u5230\u65b0\u7684\u6c34\u5e73\u3002\u57fa\u4e8eDS\u7684\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u63d0\u4f9b\u7406\u8bba\u4e0a\u6700\u4f18\u7684\u77ed\u671f\u9884\u6d4b\uff0c\u8fd8\u80fd\u5e2e\u52a9\u9884\u6d4b\u7cfb\u7edf\u7684\u957f\u671f\u7edf\u8ba1\u6570\u636e\uff0c\u8fd9\u5bf9\u4e8e\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u6765\u8bf4\u53ef\u80fd\u662f\u66f4\u91cd\u8981\u7684\u91cf\u5ea6\u3002\u6b64\u5916\uff0cDS\u7406\u8bba\u63d0\u4f9b\u4e86\u5173\u4e8e\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u673a\u5236\u80cc\u540e\u7684\u72ec\u7acb\u4e8e\u9886\u57df\u7684\u7406\u8bba\u89c1\u89e3\uff0c\u8fd9\u6709\u52a9\u4e8e\u7406\u89e3\u4efb\u4f55\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u9650\u3001\u5728\u672a\u89c1\u60c5\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u53ef\u80fd\u7684\u63a7\u5236\u7b56\u7565\u3002", "method": "\u6587\u7ae0\u9996\u5148\u56de\u987e\u4e86\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u4e0e\u52a8\u529b\u7cfb\u7edf\u91cd\u6784\uff08DSR\uff09\u4e2d\u7684\u6838\u5fc3\u6982\u5ff5\u3001\u65b9\u6cd5\u3001\u6d4b\u91cf\u53ca\u6a21\u578b\u3002\u968f\u540e\u8ba8\u8bba\u4e86\u5982\u4f55\u901a\u8fc7\u6765\u81eaDS\u9886\u57df\u7684\u89c1\u89e3\u4ee5\u5173\u952e\u65b9\u5f0f\u63a8\u8fdb\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\uff0c\u4f7f\u9884\u6d4b\u66f4\u52a0\u51c6\u786e\u7684\u540c\u65f6\u5927\u5927\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5c06DSR\u65b9\u6cd5\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86\u5229\u7528DSR\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u5f3a\u8c03\u4e86\u7ed3\u5408\u52a8\u529b\u7cfb\u7edf\u89c2\u70b9\u5bf9\u4e8e\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u53ca\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.16876", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.16876", "abs": "https://arxiv.org/abs/2602.16876", "authors": ["Yaroslav Solovko"], "title": "ML-driven detection and reduction of ballast information in multi-modal datasets", "comment": "20 pages, 27 figures, 10 tables", "summary": "Modern datasets often contain ballast as redundant or low-utility information that increases dimensionality, storage requirements, and computational cost without contributing meaningful analytical value. This study introduces a generalized, multimodal framework for ballast detection and reduction across structured, semi-structured, unstructured, and sparse data types. Using diverse datasets, entropy, mutual information, Lasso, SHAP, PCA, topic modelling, and embedding analysis are applied to identify and eliminate ballast features. A novel Ballast Score is proposed to integrate these signals into a unified, cross-modal pruning strategy. Experimental results demonstrate that significant portions of the feature space as often exceeding 70% in sparse or semi-structured data, can be pruned with minimal or even improved classification performance, along with substantial reductions in training time and memory footprint. The framework reveals distinct ballast typologies (e.g. statistical, semantic, infrastructural), and offers practical guidance for leaner, more efficient machine learning pipelines.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u51cf\u5c11\u7ed3\u6784\u5316\u3001\u534a\u7ed3\u6784\u5316\u3001\u975e\u7ed3\u6784\u5316\u548c\u7a00\u758f\u6570\u636e\u7c7b\u578b\u4e2d\u7684\u5197\u4f59\u6216\u4f4e\u6548\u4fe1\u606f\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u538b\u8231\u7269\u5206\u6570\u6765\u6574\u5408\u591a\u79cd\u6280\u672f\u4fe1\u53f7\uff0c\u5f62\u6210\u4e86\u8de8\u6a21\u5f0f\u4fee\u526a\u7b56\u7565\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u4ee5\u526a\u9664\u7279\u5f81\u7a7a\u95f4\u4e2d\u9ad8\u8fbe70%\u4ee5\u4e0a\u7684\u90e8\u5206\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u751a\u81f3\u6539\u5584\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u5927\u5e45\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u5360\u7528\u3002", "motivation": "\u73b0\u4ee3\u6570\u636e\u96c6\u7ecf\u5e38\u5305\u542b\u589e\u52a0\u7ef4\u5ea6\u3001\u5b58\u50a8\u9700\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u800c\u4e0d\u63d0\u4f9b\u6709\u610f\u4e49\u5206\u6790\u4ef7\u503c\u7684\u5197\u4f59\u6216\u4f4e\u6548\u4fe1\u606f\uff08\u79f0\u4e3a\u538b\u8231\u7269\uff09\u3002\u4e3a\u4e86\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u6765\u8bc6\u522b\u5e76\u6d88\u9664\u8fd9\u4e9b\u4e0d\u5fc5\u8981\u7684\u7279\u5f81\u3002", "method": "\u8be5\u7814\u7a76\u5e94\u7528\u4e86\u71b5\u3001\u4e92\u4fe1\u606f\u3001Lasso\u3001SHAP\u3001PCA\u3001\u4e3b\u9898\u5efa\u6a21\u4ee5\u53ca\u5d4c\u5165\u5f0f\u5206\u6790\u7b49\u6280\u672f\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u4ee5\u8bc6\u522b\u548c\u53bb\u9664\u538b\u8231\u7269\u7279\u5f81\u3002\u5e76\u4e14\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u538b\u8231\u7269\u8bc4\u5206\uff0c\u5c06\u4e0a\u8ff0\u5404\u79cd\u6280\u672f\u7684\u7ed3\u679c\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u8de8\u6a21\u5f0f\u4fee\u526a\u7b56\u7565\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u7a00\u758f\u6216\u534a\u7ed3\u6784\u5316\u6570\u636e\u4e2d\uff0c\u901a\u5e38\u8d85\u8fc770%\u7684\u7279\u5f81\u7a7a\u95f4\u53ef\u4ee5\u88ab\u524a\u51cf\uff0c\u540c\u65f6\u5bf9\u5206\u7c7b\u8868\u73b0\u7684\u5f71\u54cd\u6781\u5c0f\u751a\u81f3\u6709\u6240\u63d0\u5347\uff0c\u6b64\u5916\u8fd8\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u4e0e\u5185\u5b58\u4f7f\u7528\u91cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u538b\u8231\u7269\uff08\u4f8b\u5982\u7edf\u8ba1\u578b\u3001\u8bed\u4e49\u578b\u3001\u57fa\u7840\u8bbe\u65bd\u578b\uff09\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u7cbe\u7b80\u9ad8\u6548\u7684\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2602.16887", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.16887", "abs": "https://arxiv.org/abs/2602.16887", "authors": ["F. S. Menezes", "M. C. F. G. Barretto", "E. Q. C. Garcia", "T. A. E. Ferreira", "J. G. Alvez"], "title": "Construction of a classification model for dementia among Brazilian adults aged 50 and over", "comment": "38 pages; 3 figures", "summary": "To build a dementia classification model for middle-aged and elderly Brazilians, implemented in Python, combining variable selection and multivariable analysis, using low-cost variables with modification potential. Observational study with a predictive modeling approach using a cross-sectional design, aimed at estimating the chances of developing dementia, using data from the Brazilian Longitudinal Study of Aging (ELSI-Brazil), involving 9,412 participants. Dementia was determined based on neuropsychological assessment and informant-based cognitive function. Analyses were performed using Random Forest (RF) and multivariable logistic regression to estimate the risk of dementia in the middle-aged and elderly populations of Brazil. The prevalence of dementia was 9.6%. The highest odds of dementia were observed in illiterate individuals (Odds Ratio (OR) = 7.42), individuals aged 90 years or older (OR = 11.00), low weight (OR = 2.11), low handgrip strength (OR = 2.50), self-reported black skin color (OR = 1.47), physical inactivity (OR = 1.61), self-reported hearing loss (OR = 1.65), and presence of depressive symptoms (OR = 1.72). Higher education (OR=0.44), greater life satisfaction (OR=0.72), and being employed (OR=0.78) were protective factors. The RF model outperformed logistic regression, achieving an area under the ROC curve of 0.776, with a sensitivity of 0.708, a specificity of 0.702, an F1-score of 0.311, a G-means of 0.705, and an accuracy of 0.703. Conclusion: The findings reinforce the multidimensional nature of dementia and the importance of accessible factors for identifying vulnerable individuals. Strengthening public policies focused on promoting brain health can contribute significantly to the efficient allocation of resources in primary care and dementia prevention in Brazil", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u53d8\u91cf\u9009\u62e9\u548c\u591a\u53d8\u91cf\u5206\u6790\uff0c\u5229\u7528\u4f4e\u6210\u672c\u4e14\u53ef\u8c03\u6574\u7684\u53d8\u91cf\uff0c\u5728Python\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u9488\u5bf9\u5df4\u897f\u4e2d\u8001\u5e74\u4eba\u7684\u75f4\u5446\u75c7\u5206\u7c7b\u6a21\u578b\u3002\u4f7f\u7528\u6765\u81eaELSI-Brazil\u7684\u6570\u636e\uff0c\u5bf99,412\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u4e86\u6a2a\u65ad\u9762\u8bbe\u8ba1\u7684\u7814\u7a76\u3002\u968f\u673a\u68ee\u6797\uff08RF\uff09\u6a21\u578b\u7684\u8868\u73b0\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u786e\u5b9a\u4e86\u591a\u79cd\u75f4\u5446\u98ce\u9669\u56e0\u7d20\u53ca\u4fdd\u62a4\u6027\u56e0\u7d20\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u7528\u4f4e\u6210\u672c\u4e14\u5177\u6709\u6f5c\u5728\u53ef\u8c03\u8282\u6027\u7684\u53d8\u91cf\u6765\u5efa\u7acb\u4e00\u4e2a\u9488\u5bf9\u5df4\u897f\u4e2d\u8001\u5e74\u4eba\u7fa4\u4f53\u7684\u75f4\u5446\u75c7\u5206\u7c7b\u6a21\u578b\uff0c\u4ee5\u4fc3\u8fdb\u8d44\u6e90\u7684\u6709\u6548\u5206\u914d\u548c\u75f4\u5446\u75c7\u9884\u9632\u3002", "method": "\u91c7\u7528\u89c2\u5bdf\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a2a\u65ad\u9762\u8bbe\u8ba1\uff0c\u65e8\u5728\u4f30\u8ba1\u53d1\u5c55\u6210\u75f4\u5446\u75c7\u7684\u53ef\u80fd\u6027\u3002\u8be5\u7814\u7a76\u4f7f\u7528\u4e86\u5df4\u897f\u8001\u9f84\u5316\u7eb5\u5411\u7814\u7a76(ELSI-Brazil)\u7684\u6570\u636e\uff0c\u6d89\u53ca9,412\u540d\u53c2\u4e0e\u8005\u3002\u8fd0\u7528\u968f\u673a\u68ee\u6797(RF)\u4e0e\u591a\u53d8\u91cf\u903b\u8f91\u56de\u5f52\u5206\u6790\u6765\u4f30\u8ba1\u75f4\u5446\u75c7\u7684\u98ce\u9669\u3002", "result": "\u75f4\u5446\u75c7\u7684\u60a3\u75c5\u7387\u4e3a9.6%\u3002\u6587\u76f2\u3001\u5e74\u9f84\u226590\u5c81\u3001\u4f4e\u4f53\u91cd\u3001\u63e1\u529b\u5f31\u3001\u81ea\u62a5\u9ed1\u76ae\u80a4\u3001\u7f3a\u4e4f\u4f53\u80b2\u6d3b\u52a8\u3001\u542c\u529b\u635f\u5931\u4ee5\u53ca\u6291\u90c1\u75c7\u72b6\u7b49\u56e0\u7d20\u4e0e\u8f83\u9ad8\u7684\u75f4\u5446\u98ce\u9669\u76f8\u5173\uff1b\u800c\u8f83\u9ad8\u6559\u80b2\u6c34\u5e73\u3001\u751f\u6d3b\u6ee1\u610f\u5ea6\u9ad8\u53ca\u5c31\u4e1a\u72b6\u6001\u5219\u4e3a\u4fdd\u62a4\u6027\u56e0\u7d20\u3002\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u5176ROC\u66f2\u7ebf\u4e0b\u9762\u79ef\u8fbe\u52300.776\uff0c\u654f\u611f\u5ea6\u4e3a0.708\uff0c\u7279\u5f02\u5ea6\u4e3a0.702\uff0cF1\u5206\u6570\u4e3a0.311\uff0cG\u5747\u503c\u4e3a0.705\uff0c\u51c6\u786e\u7387\u4e3a0.703\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u75f4\u5446\u75c7\u7684\u591a\u7ef4\u6027\u8d28\u53ca\u5176\u8bc6\u522b\u8106\u5f31\u4e2a\u4f53\u65f6\u53ef\u8bbf\u95ee\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002\u52a0\u5f3a\u5173\u6ce8\u8111\u5065\u5eb7\u4fc3\u8fdb\u7684\u516c\u5171\u653f\u7b56\u5bf9\u4e8e\u5df4\u897f\u521d\u7ea7\u4fdd\u5065\u670d\u52a1\u4e2d\u8d44\u6e90\u7684\u6709\u6548\u914d\u7f6e\u53ca\u75f4\u5446\u75c7\u9884\u9632\u6709\u7740\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2602.16966", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16966", "abs": "https://arxiv.org/abs/2602.16966", "authors": ["Sourav Chakraborty", "Amit Kiran Rege", "Claire Monteleoni", "Lijun Chen"], "title": "A Unified Framework for Locality in Scalable MARL", "comment": null, "summary": "Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservative, as they are based on worst-case, environment-only bounds (e.g., supremums over actions) and fail to capture the regularizing effect of the policy itself. In this work, we establish that locality can also be a \\emph{policy-dependent} phenomenon. Our central contribution is a novel decomposition of the policy-induced interdependence matrix, $H^\u03c0$, which decouples the environment's sensitivity to state ($E^{\\mathrm{s}}$) and action ($E^{\\mathrm{a}}$) from the policy's sensitivity to state ($\u03a0(\u03c0)$). This decomposition reveals that locality can be induced by a smooth policy (small $\u03a0(\u03c0)$) even when the environment is strongly action-coupled, exposing a fundamental locality-optimality tradeoff. We use this framework to derive a general spectral condition $\u03c1(E^{\\mathrm{s}}+E^{\\mathrm{a}}\u03a0(\u03c0)) < 1$ for exponential decay, which is strictly tighter than prior norm-based conditions. Finally, we leverage this theory to analyze a provably-sound localized block-coordinate policy improvement framework with guarantees tied directly to this spectral radius.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u8bf1\u5bfc\u7684\u76f8\u4e92\u4f9d\u8d56\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5373\u4f7f\u5728\u73af\u5883\u5f3a\u70c8\u8026\u5408\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u6ed1\u7b56\u7565\u4e5f\u80fd\u8bf1\u5bfc\u5c40\u90e8\u6027\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u4e2a\u66f4\u4e25\u683c\u7684\u8c31\u6761\u4ef6\u6765\u4fdd\u8bc1\u6307\u6570\u8870\u51cf\u6027\u8d28\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u9762\u4e34\u7ef4\u5ea6\u707e\u96be\u6311\u6218\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u57fa\u4e8e\u73af\u5883\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u672a\u80fd\u6355\u6349\u7b56\u7565\u672c\u8eab\u7684\u6b63\u5219\u5316\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5206\u89e3\u7b56\u7565\u8bf1\u5bfc\u7684\u76f8\u4e92\u4f9d\u8d56\u77e9\u9635$H^\u03c0$\uff0c\u5c06\u73af\u5883\u5bf9\u72b6\u6001\u548c\u52a8\u4f5c\u7684\u654f\u611f\u5ea6\u4e0e\u7b56\u7565\u5bf9\u72b6\u6001\u7684\u654f\u611f\u5ea6\u89e3\u8026\uff0c\u8fdb\u800c\u5206\u6790\u5c40\u90e8\u6027\u548c\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e00\u822c\u8c31\u6761\u4ef6$\u03c1(E^s+E^a\u03a0(\u03c0)) < 1$\u4ee5\u786e\u4fdd\u4ef7\u503c\u51fd\u6570\u7684\u6307\u6570\u8870\u51cf\u6027\u8d28\u3002", "result": "\u53d1\u73b0\u4e86\u5e73\u6ed1\u7b56\u7565\u53ef\u4ee5\u5728\u73af\u5883\u5f3a\u52a8\u4f5c\u8026\u5408\u7684\u60c5\u51b5\u4e0b\u8bf1\u5bfc\u5c40\u90e8\u6027\uff1b\u63d0\u51fa\u4e86\u6bd4\u4e4b\u524d\u57fa\u4e8e\u8303\u6570\u6761\u4ef6\u66f4\u4e3a\u4e25\u683c\u7684\u8c31\u6761\u4ef6\uff1b\u5229\u7528\u8be5\u7406\u8bba\u5206\u6790\u4e86\u4e00\u4e2a\u5177\u6709\u76f4\u63a5\u4e0e\u8c31\u534a\u5f84\u76f8\u5173\u4fdd\u8bc1\u7684\u5c40\u90e8\u5757\u5750\u6807\u7b56\u7565\u6539\u8fdb\u6846\u67b6\u3002", "conclusion": "\u672c\u7814\u7a76\u5de5\u4f5c\u4e3a\u7406\u89e3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5c40\u90e8\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u4e14\u4e3a\u8bbe\u8ba1\u6709\u6548\u7b97\u6cd5\u6307\u51fa\u4e86\u6f5c\u5728\u65b9\u5411\u3002"}}
{"id": "2602.16967", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16967", "abs": "https://arxiv.org/abs/2602.16967", "authors": ["Yongzhong Xu"], "title": "Early-Warning Signals of Grokking via Loss-Landscape Geometry", "comment": "26 pages, 13 figures", "summary": "Grokking -- the abrupt transition from memorization to generalization after prolonged training -- has been linked to confinement on low-dimensional execution manifolds in modular arithmetic. Whether this mechanism extends beyond arithmetic remains open. We study two sequence-learning benchmarks: SCAN compositional generalization and Dyck-1 depth prediction. Across both tasks and a wide range of learning rates, the commutator defect -- a curvature measure derived from non-commuting gradient updates -- rises well before generalization, with lead times following a superlinear power law (alpha approximately 1.18 for SCAN, approximately 1.13 for Dyck), consistent with prior results on modular arithmetic. Weight-space PCA reveals that spectral concentration is not a universal precursor; the commutator defect is. Causal interventions demonstrate a mechanistic role: amplifying non-commutativity accelerates grokking (roughly 32% on SCAN, roughly 50% on Dyck), while suppressing orthogonal gradient flow delays or prevents it. The three task families form a spectrum of causal sensitivity -- modular arithmetic is rigid, Dyck is responsive, SCAN is intermediate -- yet suppression delays or prevents grokking in all cases, establishing necessity as a universal finding. These results identify the commutator defect as a robust, architecture-agnostic, causally implicated early-warning signal for delayed generalization in transformers.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u5e8f\u5217\u5b66\u4e60\u57fa\u51c6\u4efb\u52a1\uff08SCAN\u548cDyck-1\uff09\uff0c\u975e\u4ea4\u6362\u68af\u5ea6\u66f4\u65b0\u7684\u66f2\u7387\u6d4b\u5ea6\u2014\u2014\u6362\u4f4d\u7f3a\u9677\uff0c\u5728\u6cdb\u5316\u4e4b\u524d\u663e\u8457\u589e\u52a0\uff0c\u5e76\u4e14\u901a\u8fc7\u5e72\u9884\u5b9e\u9a8c\u8868\u660e\u589e\u5f3a\u975e\u4ea4\u6362\u6027\u53ef\u4ee5\u52a0\u901f\u7406\u89e3\u8fc7\u7a0b\uff0c\u800c\u6291\u5236\u6b63\u4ea4\u68af\u5ea6\u6d41\u5219\u4f1a\u5ef6\u8fdf\u6216\u963b\u6b62\u5b83\u3002\u8fd9\u8868\u660e\u6362\u4f4d\u7f3a\u9677\u662f\u8f6c\u6362\u5668\u4e2d\u5ef6\u8fdf\u6cdb\u5316\u7684\u53ef\u9760\u65e9\u671f\u9884\u8b66\u4fe1\u53f7\u3002", "motivation": "\u63a2\u8ba8\u5728\u6a21\u5757\u5316\u7b97\u672f\u4ee5\u5916\u7684\u4efb\u52a1\u4e2d\uff0c\u957f\u65f6\u95f4\u8bad\u7ec3\u540e\u4ece\u8bb0\u5fc6\u5230\u6cdb\u5316\u7684\u7a81\u7136\u8f6c\u53d8\uff08\u5373\u7406\u89e3\uff09\u662f\u5426\u4e5f\u9075\u5faa\u76f8\u4f3c\u673a\u5236\u3002", "method": "\u9009\u53d6\u4e86\u4e24\u4e2a\u5e8f\u5217\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\uff1aSCAN\u7ec4\u5408\u6cdb\u5316\u4e0eDyck-1\u6df1\u5ea6\u9884\u6d4b\uff0c\u4f7f\u7528\u4e0d\u540c\u5b66\u4e60\u7387\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u91c7\u7528\u6743\u91cd\u7a7a\u95f4PCA\u5206\u6790\u3001\u56e0\u679c\u5e72\u9884\u7b49\u65b9\u6cd5\u6765\u7814\u7a76\u6362\u4f4d\u7f3a\u9677\u7684\u4f5c\u7528\u3002", "result": "\u6362\u4f4d\u7f3a\u9677\u5728\u6cdb\u5316\u524d\u660e\u663e\u4e0a\u5347\uff0c\u4e14\u5176\u4e0a\u5347\u65f6\u95f4\u9075\u5faa\u8d85\u7ebf\u6027\u5e42\u5f8b\uff1b\u653e\u5927\u975e\u4ea4\u6362\u6027\u80fd\u591f\u52a0\u901f\u7406\u89e3\u8fc7\u7a0b\uff0c\u800c\u6291\u5236\u6b63\u4ea4\u68af\u5ea6\u6d41\u5219\u4f1a\u5ef6\u8fdf\u6216\u963b\u6b62\u8be5\u8fc7\u7a0b\uff1b\u6362\u4f4d\u7f3a\u9677\u4f5c\u4e3a\u65e9\u671f\u9884\u8b66\u4fe1\u53f7\u6bd4\u5149\u8c31\u96c6\u4e2d\u66f4\u666e\u904d\u9002\u7528\u3002", "conclusion": "\u6362\u4f4d\u7f3a\u9677\u88ab\u8ba4\u5b9a\u4e3a\u4e00\u79cd\u53ef\u9760\u7684\u3001\u67b6\u6784\u65e0\u5173\u7684\u3001\u4e0e\u539f\u56e0\u76f8\u5173\u7684\u65e9\u671f\u9884\u8b66\u4fe1\u53f7\uff0c\u9002\u7528\u4e8e\u53d8\u6362\u5668\u4e2d\u7684\u5ef6\u8fdf\u6cdb\u5316\u73b0\u8c61\u3002"}}
{"id": "2602.16977", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16977", "abs": "https://arxiv.org/abs/2602.16977", "authors": ["Zachary Coalson", "Beth Sohler", "Aiden Gabriel", "Sanghyun Hong"], "title": "Fail-Closed Alignment for Large Language Models", "comment": "Pre-print", "summary": "We identify a structural weakness in current large language model (LLM) alignment: modern refusal mechanisms are fail-open. While existing approaches encode refusal behaviors across multiple latent features, suppressing a single dominant feature$-$via prompt-based jailbreaks$-$can cause alignment to collapse, leading to unsafe generation. Motivated by this, we propose fail-closed alignment as a design principle for robust LLM safety: refusal mechanisms should remain effective even under partial failures via redundant, independent causal pathways. We present a concrete instantiation of this principle: a progressive alignment framework that iteratively identifies and ablates previously learned refusal directions, forcing the model to reconstruct safety along new, independent subspaces. Across four jailbreak attacks, we achieve the strongest overall robustness while mitigating over-refusal and preserving generation quality, with small computational overhead. Our mechanistic analyses confirm that models trained with our method encode multiple, causally independent refusal directions that prompt-based jailbreaks cannot suppress simultaneously, providing empirical support for fail-closed alignment as a principled foundation for robust LLM safety.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u9f50\u539f\u5219\u2014\u2014fail-closed alignment\uff0c\u7528\u4e8e\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002\u901a\u8fc7\u8fed\u4ee3\u5730\u8bc6\u522b\u5e76\u6d88\u9664\u4e4b\u524d\u5b66\u5230\u7684\u62d2\u7edd\u65b9\u5411\uff0c\u4fc3\u4f7f\u6a21\u578b\u6cbf\u7740\u65b0\u7684\u72ec\u7acb\u5b50\u7a7a\u95f4\u91cd\u5efa\u5b89\u5168\u6027\uff0c\u4ece\u800c\u5728\u9762\u5bf9\u90e8\u5206\u5931\u6548\u65f6\u4ecd\u80fd\u4fdd\u6301\u6709\u6548\u7684\u62d2\u7edd\u673a\u5236\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u7f16\u7801\u591a\u4e2a\u56e0\u679c\u4e0a\u72ec\u7acb\u7684\u62d2\u7edd\u65b9\u5411\uff0c\u8fd9\u4e9b\u65b9\u5411\u65e0\u6cd5\u88ab\u540c\u65f6\u6291\u5236\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6574\u4f53\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u62d2\u7edd\u673a\u5236\u5b58\u5728\u7ed3\u6784\u6027\u5f31\u70b9\uff0c\u5728\u5355\u4e00\u4e3b\u8981\u7279\u5f81\u88ab\u6291\u5236\u65f6\u53ef\u80fd\u5bfc\u81f4\u6574\u4e2a\u5bf9\u9f50\u673a\u5236\u5d29\u6e83\uff0c\u4ea7\u751f\u4e0d\u5b89\u5168\u7684\u5185\u5bb9\u751f\u6210\u3002\u57fa\u4e8e\u6b64\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bbe\u8ba1\u539f\u5219\u2014\u2014fail-closed alignment\uff0c\u65e8\u5728\u5373\u4f7f\u5728\u90e8\u5206\u529f\u80fd\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u8bc1\u62d2\u7edd\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6e10\u8fdb\u5f0f\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u590d\u8bc6\u522b\u548c\u79fb\u9664\u5df2\u5b66\u4e60\u5230\u7684\u62d2\u7edd\u8def\u5f84\uff0c\u5f3a\u5236\u6a21\u578b\u6cbf\u7740\u65b0\u7684\u3001\u76f8\u4e92\u72ec\u7acb\u7684\u5b50\u7a7a\u95f4\u91cd\u65b0\u6784\u5efa\u5176\u5b89\u5168\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u610f\u5728\u521b\u5efa\u5197\u4f59\u4e14\u72ec\u7acb\u7684\u56e0\u679c\u8def\u5f84\u6765\u7ef4\u6301\u6a21\u578b\u7684\u5b89\u5168\u6027\u80fd\u3002", "result": "\u5728\u56db\u4e2a\u8d8a\u72f1\u653b\u51fb\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5c55\u73b0\u4e86\u6700\u5f3a\u7684\u6574\u4f53\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8fc7\u5ea6\u62d2\u7edd\u7684\u60c5\u51b5\uff0c\u5e76\u4fdd\u6301\u4e86\u826f\u597d\u7684\u751f\u6210\u8d28\u91cf\uff0c\u4e14\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u8f83\u5c0f\u3002\u8fdb\u4e00\u6b65\u7684\u673a\u5236\u5206\u6790\u8bc1\u5b9e\u4e86\u901a\u8fc7\u672c\u65b9\u6cd5\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u786e\u5b9e\u5305\u542b\u4e86\u591a\u4e2a\u56e0\u679c\u4e0a\u72ec\u7acb\u7684\u62d2\u7edd\u65b9\u5411\uff0c\u8fd9\u4f7f\u5f97\u57fa\u4e8e\u63d0\u793a\u7684\u8d8a\u72f1\u653b\u51fb\u96be\u4ee5\u540c\u65f6\u538b\u5236\u6240\u6709\u8fd9\u4e9b\u65b9\u5411\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u91c7\u7528fail-closed alignment\u4f5c\u4e3a\u8bbe\u8ba1\u539f\u5219\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u5f00\u53d1\u66f4\u52a0\u53ef\u9760\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.16980", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16980", "abs": "https://arxiv.org/abs/2602.16980", "authors": ["Leo Marchyok", "Zachary Coalson", "Sungho Keum", "Sooel Son", "Sanghyun Hong"], "title": "Discovering Universal Activation Directions for PII Leakage in Language Models", "comment": "Pre-print", "summary": "Modern language models exhibit rich internal structure, yet little is known about how privacy-sensitive behaviors, such as personally identifiable information (PII) leakage, are represented and modulated within their hidden states. We present UniLeak, a mechanistic-interpretability framework that identifies universal activation directions: latent directions in a model's residual stream whose linear addition at inference time consistently increases the likelihood of generating PII across prompts. These model-specific directions generalize across contexts and amplify PII generation probability, with minimal impact on generation quality. UniLeak recovers such directions without access to training data or groundtruth PII, relying only on self-generated text. Across multiple models and datasets, steering along these universal directions substantially increases PII leakage compared to existing prompt-based extraction methods. Our results offer a new perspective on PII leakage: the superposition of a latent signal in the model's representations, enabling both risk amplification and mitigation.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6UniLeak\uff0c\u5b83\u80fd\u591f\u8bc6\u522b\u51fa\u6a21\u578b\u9690\u85cf\u72b6\u6001\u4e2d\u666e\u904d\u5b58\u5728\u7684\u6fc0\u6d3b\u65b9\u5411\uff0c\u8fd9\u4e9b\u65b9\u5411\u80fd\u591f\u5728\u63a8\u7406\u65f6\u7ebf\u6027\u5730\u589e\u52a0\u751f\u6210\u4e2a\u4eba\u53ef\u8bc6\u522b\u4fe1\u606f(PII)\u7684\u53ef\u80fd\u6027\u3002\u8fd9\u79cd\u673a\u5236\u65e0\u9700\u8bbf\u95ee\u8bad\u7ec3\u6570\u636e\u6216\u771f\u5b9ePII\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u6a21\u578b\u81ea\u52a8\u751f\u6210\u7684\u6587\u672c\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0c\u6cbf\u7740\u8fd9\u4e9b\u901a\u7528\u65b9\u5411\u64cd\u4f5c\u663e\u8457\u589e\u52a0\u4e86PII\u6cc4\u9732\u7684\u98ce\u9669\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9690\u79c1\u654f\u611f\u884c\u4e3a\uff08\u5982\u4e2a\u4eba\u53ef\u8bc6\u522b\u4fe1\u606fPII\u6cc4\u9732\uff09\u5982\u4f55\u5728\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u4e2d\u88ab\u8868\u793a\u53ca\u8c03\u8282\u3002\u9274\u4e8e\u6b64\u9886\u57df\u4e86\u89e3\u5c1a\u6d45\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7406\u89e3\u5e76\u63a7\u5236\u8fd9\u7c7b\u98ce\u9669\u3002", "method": "\u5f00\u53d1\u4e86\u540d\u4e3aUniLeak\u7684\u673a\u5236\u89e3\u91ca\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u6a21\u578b\u6b8b\u5dee\u6d41\u4e2d\u7684\u901a\u7528\u6fc0\u6d3b\u65b9\u5411\u3002\u901a\u8fc7\u4ec5\u5229\u7528\u6a21\u578b\u81ea\u4ea7\u6587\u672c\uff0c\u800c\u4e0d\u9700\u8981\u8bad\u7ec3\u6570\u636e\u6216\u771f\u5b9e\u7684PII\u4fe1\u606f\uff0c\u5c31\u80fd\u627e\u5230\u90a3\u4e9b\u80fd\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u7ebf\u6027\u6dfb\u52a0\u6301\u7eed\u63d0\u9ad8\u8de8\u63d0\u793a\u751f\u6210PII\u53ef\u80fd\u6027\u7684\u65b9\u5411\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u4e0e\u6570\u636e\u96c6\u4e4b\u95f4\uff0c\u6cbf\u5df2\u8bc6\u522b\u51fa\u7684\u901a\u7528\u65b9\u5411\u8fdb\u884c\u8c03\u6574\u53ef\u4ee5\u5927\u5927\u589e\u52a0PII\u6cc4\u9732\u7684\u673a\u4f1a\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u63d0\u53d6\u65b9\u6cd5\u6548\u679c\u66f4\u4f73\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u4e00\u4e2a\u5173\u4e8ePII\u6cc4\u9732\u7684\u65b0\u89c6\u89d2\uff1a\u5373\u6a21\u578b\u8868\u793a\u4e2d\u5b58\u5728\u7684\u6f5c\u5728\u4fe1\u53f7\u53e0\u52a0\u73b0\u8c61\uff0c\u8fd9\u65e2\u53ef\u80fd\u653e\u5927\u98ce\u9669\u4e5f\u53ef\u80fd\u6709\u52a9\u4e8e\u51cf\u8f7b\u98ce\u9669\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u8bc6\u522b\u5e76\u64cd\u63a7\u7279\u5b9a\u6a21\u578b\u5185\u7684\u901a\u7528\u6fc0\u6d3b\u65b9\u5411\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u8c03\u63a7PII\u6cc4\u9732\u98ce\u9669\u3002\u8fd9\u4e00\u53d1\u73b0\u4e0d\u4ec5\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5904\u7406\u9690\u79c1\u654f\u611f\u4fe1\u606f\u7684\u4e00\u79cd\u65b0\u65b9\u5f0f\uff0c\u540c\u65f6\u4e5f\u4e3a\u51cf\u5c11\u6b64\u7c7b\u98ce\u9669\u63d0\u4f9b\u4e86\u6f5c\u5728\u9014\u5f84\u3002"}}
{"id": "2602.16994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16994", "abs": "https://arxiv.org/abs/2602.16994", "authors": ["Rahul Thomas", "Teo Kitanovski", "Micah Goldblum", "Arka Pal"], "title": "Dynamic Delayed Tree Expansion For Improved Multi-Path Speculative Decoding", "comment": null, "summary": "Multi-path speculative decoding accelerates lossless sampling from a target model by using a cheaper draft model to generate a draft tree of tokens, and then applies a verification algorithm that accepts a subset of these. While prior work has proposed various verification algorithms for i.i.d rollouts, their relative performance under matched settings remains unclear. In this work, we firstly present a systematic evaluation of verification strategies across model families, tasks, and sampling regimes, and find that Traversal Verification dominates consistently, with OT-based methods lagging far behind. Our analysis uncovers that this occurs because OT-based methods achieve high multi-token acceptance near the root of the draft tree, while multi-token gains are most impactful deeper in the draft tree, where draft and target distributions diverge. Based on this insight, we propose delayed tree expansion, which drafts a partial single path, delaying the i.i.d. branching point. We show that delayed tree expansion preserves the target distribution and improves on root-node i.i.d rollouts. Further, we develop a dynamic neural selector that estimates the expected block efficiency of optimal-transport-based verification methods from draft and target features, enabling context-dependent expansion decisions. Our neural selector allows OT-based methods like SpecInfer to outperform Traversal Verification for the first time, achieving 5% higher average throughput across a wide range of models, datasets, and sampling settings.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u4e0d\u540c\u9a8c\u8bc1\u7b56\u7565\u5728\u591a\u8def\u5f84\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u904d\u5386\u9a8c\u8bc1\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u7684\u65b9\u6cd5\u3002\u4e3a\u6539\u8fdbOT\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5ef6\u8fdf\u6811\u6269\u5c55\u6280\u672f\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u52a8\u6001\u795e\u7ecf\u9009\u62e9\u5668\u6765\u4f30\u8ba1\u57fa\u4e8eOT\u7684\u9a8c\u8bc1\u65b9\u6cd5\u7684\u9884\u671f\u5757\u6548\u7387\uff0c\u4ece\u800c\u4f7f\u5f97OT\u65b9\u6cd5\u5982SpecInfer\u9996\u6b21\u8d85\u8d8a\u4e86\u904d\u5386\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u91c7\u6837\u8bbe\u7f6e\u4e0b\u5e73\u5747\u541e\u5410\u91cf\u63d0\u9ad8\u4e865%\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u63d0\u51fa\u4e86\u5404\u79cd\u72ec\u7acb\u540c\u5206\u5e03\u5c55\u5f00\u60c5\u51b5\u4e0b\u7684\u9a8c\u8bc1\u7b97\u6cd5\uff0c\u4f46\u5b83\u4eec\u5728\u5339\u914d\u8bbe\u7f6e\u4e0b\u7684\u76f8\u5bf9\u6027\u80fd\u5c1a\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u7684\u9a8c\u8bc1\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u591a\u8def\u5f84\u63a8\u6d4b\u89e3\u7801\u7684\u6548\u679c\uff0c\u5e76\u5bfb\u6c42\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u89e3\u7801\u6548\u7387\u3002", "method": "\u9996\u5148\u5bf9\u8de8\u6a21\u578b\u5bb6\u65cf\u3001\u4efb\u52a1\u548c\u91c7\u6837\u673a\u5236\u7684\u9a8c\u8bc1\u7b56\u7565\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u5ef6\u8fdf\u6811\u6269\u5c55\u6280\u672f\u548c\u4e00\u4e2a\u80fd\u591f\u6839\u636e\u8349\u7a3f\u4e0e\u76ee\u6807\u7279\u5f81\u4f30\u8ba1\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\u9884\u671f\u5757\u6548\u7387\u7684\u52a8\u6001\u795e\u7ecf\u9009\u62e9\u5668\u3002", "result": "\u904d\u5386\u9a8c\u8bc1\u65b9\u6cd5\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u800c\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u65b9\u6cd5\u5219\u5728\u8349\u7a3f\u6811\u6839\u90e8\u9644\u8fd1\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u591a\u4ee4\u724c\u63a5\u53d7\u7387\u3002\u901a\u8fc7\u5f15\u5165\u5ef6\u8fdf\u6811\u6269\u5c55\u53ca\u52a8\u6001\u795e\u7ecf\u9009\u62e9\u5668\uff0c\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u65b9\u6cd5\u5982SpecInfer\u5b9e\u73b0\u4e86\u76f8\u5bf9\u4e8e\u904d\u5386\u9a8c\u8bc1\u65b9\u6cd5\u9ad8\u8fbe5%\u7684\u5e73\u5747\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5ef6\u8fdf\u6811\u6269\u5c55\u4ee5\u53ca\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u70b9\u7684\u795e\u7ecf\u9009\u62e9\u5668\uff0c\u53ef\u4ee5\u663e\u8457\u6539\u5584\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u9a8c\u8bc1\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u4f7f\u5176\u5728\u591a\u79cd\u6761\u4ef6\u4e0b\u8d85\u8d8a\u4f20\u7edf\u904d\u5386\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2602.17009", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17009", "abs": "https://arxiv.org/abs/2602.17009", "authors": ["Nikunj Gupta", "James Zachary Hare", "Jesse Milzman", "Rajgopal Kannan", "Viktor Prasanna"], "title": "Action-Graph Policies: Learning Action Co-dependencies in Multi-Agent Reinforcement Learning", "comment": null, "summary": "Coordinating actions is the most fundamental form of cooperation in multi-agent reinforcement learning (MARL). Successful decentralized decision-making often depends not only on good individual actions, but on selecting compatible actions across agents to synchronize behavior, avoid conflicts, and satisfy global constraints. In this paper, we propose Action Graph Policies (AGP), that model dependencies among agents' available action choices. It constructs, what we call, \\textit{coordination contexts}, that enable agents to condition their decisions on global action dependencies. Theoretically, we show that AGPs induce a strictly more expressive joint policy compared to fully independent policies and can realize coordinated joint actions that are provably more optimal than greedy execution even from centralized value-decomposition methods. Empirically, we show that AGP achieves 80-95\\% success on canonical coordination tasks with partial observability and anti-coordination penalties, where other MARL methods reach only 10-25\\%. We further demonstrate that AGP consistently outperforms these baselines in diverse multi-agent environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u884c\u52a8\u56fe\u7b56\u7565\uff08AGP\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5efa\u6a21\u667a\u80fd\u4f53\u4e4b\u95f4\u53ef\u9009\u52a8\u4f5c\u7684\u4f9d\u8d56\u5173\u7cfb\u3002\u901a\u8fc7\u6784\u5efa\u534f\u8c03\u4e0a\u4e0b\u6587\uff0c\u4f7f\u5f97\u667a\u80fd\u4f53\u80fd\u591f\u57fa\u4e8e\u5168\u5c40\u52a8\u4f5c\u4f9d\u8d56\u6027\u505a\u51fa\u51b3\u7b56\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAGP\u5728\u5177\u6709\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u53cd\u534f\u8c03\u60e9\u7f5a\u7684\u7ecf\u5178\u534f\u8c03\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e8680-95%\u7684\u6210\u529f\u7387\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u7684\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6301\u7eed\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u534f\u8c03\u884c\u52a8\u662f\u5408\u4f5c\u6700\u57fa\u672c\u7684\u5f62\u5f0f\u3002\u6210\u529f\u7684\u5206\u6563\u51b3\u7b56\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u4e2a\u4f53\u7684\u597d\u52a8\u4f5c\uff0c\u8fd8\u5728\u4e8e\u9009\u62e9\u8de8\u667a\u80fd\u4f53\u95f4\u517c\u5bb9\u7684\u52a8\u4f5c\u4ee5\u540c\u6b65\u884c\u4e3a\u3001\u907f\u514d\u51b2\u7a81\u5e76\u6ee1\u8db3\u5168\u5c40\u7ea6\u675f\u6761\u4ef6\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6709\u6548\u5efa\u6a21\u667a\u80fd\u4f53\u4e4b\u95f4\u53ef\u9009\u52a8\u4f5c\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u4f18\u7684\u8054\u5408\u884c\u52a8\u3002", "method": "\u63d0\u51fa\u4e86\u884c\u52a8\u56fe\u7b56\u7565\uff08Action Graph Policies, AGP\uff09\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5efa\u6a21\u667a\u80fd\u4f53\u53ef\u7528\u884c\u52a8\u9009\u9879\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u6784\u9020\u6240\u8c13\u7684\u201c\u534f\u8c03\u4e0a\u4e0b\u6587\u201d\uff0c\u8ba9\u667a\u80fd\u4f53\u53ef\u4ee5\u6839\u636e\u5168\u7403\u884c\u52a8\u4f9d\u8d56\u6027\u6765\u8c03\u6574\u81ea\u5df1\u7684\u51b3\u5b9a\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4e0e\u5b8c\u5168\u72ec\u7acb\u7684\u7b56\u7565\u76f8\u6bd4\uff0cAGP\u8bf1\u5bfc\u51fa\u4e00\u4e2a\u66f4\u5177\u8868\u73b0\u529b\u7684\u8054\u5408\u7b56\u7565\uff0c\u5e76\u4e14\u80fd\u591f\u5b9e\u73b0\u6bd4\u96c6\u4e2d\u5f0f\u4ef7\u503c\u5206\u89e3\u65b9\u6cd5\u4e2d\u7684\u8d2a\u5a6a\u6267\u884c\u66f4\u4e3a\u4f18\u5316\u7684\u534f\u8c03\u8054\u5408\u884c\u52a8\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5177\u6709\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u53cd\u534f\u8c03\u60e9\u7f5a\u7684\u7ecf\u5178\u534f\u8c03\u4efb\u52a1\u4e0a\uff0cAGP\u8fbe\u5230\u4e8680-95%\u7684\u6210\u529f\u7387\uff1b\u800c\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\uff0c\u5176\u4ed6MARL\u65b9\u6cd5\u4ec5\u80fd\u8fbe\u523010-25%\u7684\u6210\u529f\u7387\u3002\u6b64\u5916\uff0cAGP\u8fd8\u5728\u591a\u79cd\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u6301\u7eed\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "AGP\u4e3a\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u534f\u8c03\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9014\u5f84\uff0c\u901a\u8fc7\u5f15\u5165\u5bf9\u667a\u80fd\u4f53\u95f4\u52a8\u4f5c\u4f9d\u8d56\u6027\u7684\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u534f\u8c03\u6027\u80fd\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002"}}
{"id": "2602.17013", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17013", "abs": "https://arxiv.org/abs/2602.17013", "authors": ["Kevin D. Oden"], "title": "Malliavin Calculus as Stochastic Backpropogation", "comment": null, "summary": "We establish a rigorous connection between pathwise (reparameterization) and score-function (Malliavin) gradient estimators by showing that both arise from the Malliavin integration-by-parts identity. Building on this equivalence, we introduce a unified and variance-aware hybrid estimator that adaptively combines pathwise and Malliavin gradients using their empirical covariance structure. The resulting formulation provides a principled understanding of stochastic backpropagation and achieves minimum variance among all unbiased linear combinations, with closed-form finite-sample convergence bounds. We demonstrate 9% variance reduction on VAEs (CIFAR-10) and up to 35% on strongly-coupled synthetic problems. Exploratory policy gradient experiments reveal that non-stationary optimization landscapes present challenges for the hybrid approach, highlighting important directions for future work. Overall, this work positions Malliavin calculus as a conceptually unifying and practically interpretable framework for stochastic gradient estimation, clarifying when hybrid approaches provide tangible benefits and when they face inherent limitations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u8def\u5f84\u91cd\u53c2\u6570\u5316\u548c\u5f97\u5206\u51fd\u6570\uff08Malliavin\uff09\u68af\u5ea6\u4f30\u8ba1\u5668\u4e4b\u95f4\u7684\u4e25\u683c\u8054\u7cfb\uff0c\u5e76\u57fa\u4e8e\u6b64\u7b49\u4ef7\u6027\u5f15\u5165\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u5177\u6709\u65b9\u5dee\u611f\u77e5\u80fd\u529b\u7684\u6df7\u5408\u4f30\u8ba1\u5668\uff0c\u8be5\u4f30\u8ba1\u5668\u5229\u7528\u4e86\u4e24\u79cd\u68af\u5ea6\u7684\u5b9e\u8bc1\u534f\u65b9\u5dee\u7ed3\u6784\u81ea\u9002\u5e94\u5730\u7ed3\u5408\u4e24\u8005\u3002\u7814\u7a76\u7ed3\u679c\u5728VAE\u4e0a\u5b9e\u73b0\u4e869%\u7684\u65b9\u5dee\u51cf\u5c11\uff0c\u5728\u5f3a\u8026\u5408\u5408\u6210\u95ee\u9898\u4e0a\u6700\u591a\u51cf\u5c11\u4e8635%\u7684\u65b9\u5dee\u3002\u6b64\u5916\uff0c\u63a2\u7d22\u6027\u7b56\u7565\u68af\u5ea6\u5b9e\u9a8c\u8868\u660e\uff0c\u975e\u5e73\u7a33\u4f18\u5316\u573a\u666f\u7ed9\u6df7\u5408\u65b9\u6cd5\u5e26\u6765\u4e86\u6311\u6218\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u5efa\u7acb\u8def\u5f84\u91cd\u53c2\u6570\u5316\u4e0eMalliavin\u68af\u5ea6\u4f30\u8ba1\u5668\u95f4\u7684\u8054\u7cfb\u6765\u63d0\u4f9b\u4e00\u4e2a\u66f4\u52a0\u7edf\u4e00\u548c\u53ef\u89e3\u91ca\u7684\u968f\u673a\u68af\u5ea6\u4f30\u8ba1\u6846\u67b6\uff0c\u4ece\u800c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u65b9\u5dee\u95ee\u9898\u5e76\u63d0\u5347\u4f30\u8ba1\u6548\u7387\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86\u8def\u5f84\u91cd\u53c2\u6570\u5316\u548cMalliavin\u68af\u5ea6\u4f30\u8ba1\u5668\u90fd\u6e90\u4e8eMalliavin\u79ef\u5206\u90e8\u5206\u6052\u7b49\u5f0f\uff1b\u7136\u540e\u57fa\u4e8e\u8fd9\u79cd\u7b49\u4ef7\u5173\u7cfb\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u6df7\u5408\u4f30\u8ba1\u5668\uff0c\u5b83\u80fd\u591f\u6839\u636e\u7ecf\u9a8c\u534f\u65b9\u5dee\u81ea\u9002\u5e94\u5730\u7ec4\u5408\u8fd9\u4e24\u79cd\u68af\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u6df7\u5408\u4f30\u8ba1\u5668\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u65b9\u5dee\uff0c\u7279\u522b\u662f\u5728VAEs(CIFAR-10)\u4e0a\u7684\u65b9\u5dee\u51cf\u5c11\u4e869%\uff0c\u4ee5\u53ca\u5728\u67d0\u4e9b\u5408\u6210\u95ee\u9898\u4e0a\u6700\u9ad8\u53ef\u8fbe35%\u3002\u4f46\u540c\u65f6\u4e5f\u53d1\u73b0\uff0c\u5728\u975e\u5e73\u7a33\u4f18\u5316\u73af\u5883\u4e2d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u9762\u4e34\u7740\u4e00\u5b9a\u6311\u6218\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5c06Malliavin\u5fae\u79ef\u5206\u5b9a\u4f4d\u4e3a\u6982\u5ff5\u4e0a\u7edf\u4e00\u3001\u5b9e\u8df5\u4e0a\u6613\u4e8e\u7406\u89e3\u7684\u968f\u673a\u68af\u5ea6\u4f30\u8ba1\u6846\u67b6\uff0c\u660e\u786e\u4e86\u6df7\u5408\u65b9\u6cd5\u4f55\u65f6\u80fd\u5e26\u6765\u5b9e\u9645\u597d\u5904\u53ca\u5176\u5185\u5728\u5c40\u9650\u6027\u6240\u5728\u3002"}}
{"id": "2602.17025", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17025", "abs": "https://arxiv.org/abs/2602.17025", "authors": ["Gagan Mundada", "Zihan Huang", "Rohan Surana", "Sheldon Yu", "Jennifer Yuntong Zhang", "Xintong Li", "Tong Yu", "Lina Yao", "Jingbo Shang", "Julian McAuley", "Junda Wu"], "title": "WS-GRPO: Weakly-Supervised Group-Relative Policy Optimization for Rollout-Efficient Reasoning", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) is effective for training language models on complex reasoning. However, since the objective is defined relative to a group of sampled trajectories, extended deliberation can create more chances to realize relative gains, leading to inefficient reasoning and overthinking, and complicating the trade-off between correctness and rollout efficiency. Controlling this behavior is difficult in practice, considering (i) Length penalties are hard to calibrate because longer rollouts may reflect harder problems that require longer reasoning, penalizing tokens risks truncating useful reasoning along with redundant continuation; and (ii) supervision that directly indicates when to continue or stop is typically unavailable beyond final answer correctness. We propose Weakly Supervised GRPO (WS-GRPO), which improves rollout efficiency by converting terminal rewards into correctness-aware guidance over partial trajectories. Unlike global length penalties that are hard to calibrate, WS-GRPO trains a preference model from outcome-only correctness to produce prefix-level signals that indicate when additional continuation is beneficial. Thus, WS-GRPO supplies outcome-derived continue/stop guidance, reducing redundant deliberation while maintaining accuracy. We provide theoretical results and empirically show on reasoning benchmarks that WS-GRPO substantially reduces rollout length while remaining competitive with GRPO baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5f31\u76d1\u7763\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(WS-GRPO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ec8\u7aef\u5956\u52b1\u8f6c\u6362\u4e3a\u5bf9\u90e8\u5206\u8f68\u8ff9\u7684\u6b63\u786e\u6027\u611f\u77e5\u6307\u5bfc\u6765\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u8bad\u7ec3\u4e86\u4e00\u4e2a\u504f\u597d\u6a21\u578b\uff0c\u4ece\u7ed3\u679c\u7684\u6b63\u786e\u6027\u4e2d\u5b66\u4e60\u4f55\u65f6\u7ee7\u7eed\u6216\u505c\u6b62\u63a8\u7406\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u5197\u4f59\u601d\u8003\u540c\u65f6\u4fdd\u6301\u4e86\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cWS-GRPO\u80fd\u591f\u5728\u663e\u8457\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\u7684\u540c\u65f6\u4e0eGRPO\u57fa\u7ebf\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u65b9\u6cd5\u5728\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u590d\u6742\u63a8\u7406\u65f6\u6709\u6548\uff0c\u4f46\u5176\u76ee\u6807\u5b9a\u4e49\u76f8\u5bf9\u4e8e\u4e00\u7ec4\u91c7\u6837\u8f68\u8ff9\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4f4e\u6548\u63a8\u7406\u548c\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u63a7\u5236\u8fd9\u79cd\u884c\u4e3a\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u96be\u4ee5\u51c6\u786e\u6821\u51c6\u957f\u5ea6\u60e9\u7f5a\uff0c\u5e76\u4e14\u76f4\u63a5\u6307\u793a\u4f55\u65f6\u7ee7\u7eed\u6216\u505c\u6b62\u7684\u76d1\u7763\u901a\u5e38\u53ea\u5b58\u5728\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5f31\u76d1\u7763\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08WS-GRPO\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5c06\u7ec8\u7aef\u5956\u52b1\u8f6c\u53d8\u4e3a\u57fa\u4e8e\u6b63\u786e\u6027\u7684\u3001\u8986\u76d6\u90e8\u5206\u8f68\u8ff9\u7684\u6307\u5bfc\u4fe1\u53f7\u6765\u6539\u5584\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6eda\u52a8\u6548\u7387\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4ec5\u57fa\u4e8e\u7ed3\u679c\u6b63\u786e\u6027\u7684\u6570\u636e\u6765\u8bad\u7ec3\u4e00\u4e2a\u504f\u597d\u6a21\u578b\uff0c\u8fdb\u800c\u4ea7\u751f\u524d\u7f00\u7ea7\u522b\u7684\u4fe1\u53f7\uff0c\u6307\u51fa\u4f55\u65f6\u989d\u5916\u7684\u5ef6\u7eed\u662f\u6709\u76ca\u7684\u3002", "result": "\u7406\u8bba\u5206\u6790\u52a0\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWS-GRPO\u80fd\u591f\u5927\u5e45\u51cf\u5c11\u6eda\u52a8\u8f93\u51fa\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u4f7f\u7528GRPO\u7684\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165WS-GRPO\uff0c\u7814\u7a76\u8005\u4eec\u627e\u5230\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u5730\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ee5\u6267\u884c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u65b9\u5f0f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4e5f\u7ef4\u6301\u4e86\u6a21\u578b\u7684\u8868\u73b0\u529b\u3002"}}
{"id": "2602.17027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17027", "abs": "https://arxiv.org/abs/2602.17027", "authors": ["Paimon Goulart", "Jordan Steinhauser", "Dawon Ahn", "Kylene Shuler", "Edward Korzus", "Jia Chen", "Evangelos E. Papalexakis"], "title": "Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods", "comment": null, "summary": "Scientific discovery pipelines typically involve complex, rigid, and time-consuming processes, from data preparation to analyzing and interpreting findings. Recent advances in AI have the potential to transform such pipelines in a way that domain experts can focus on interpreting and understanding findings, rather than debugging rigid pipelines or manually annotating data. As part of an active collaboration between data science/AI researchers and behavioral neuroscientists, we showcase an example AI-enhanced pipeline, specifically designed to transform and accelerate the way that the domain experts in the team are able to gain insights out of experimental data. The application at hand is in the domain of behavioral neuroscience, studying fear generalization in mice, an important problem whose progress can advance our understanding of clinically significant and often debilitating conditions such as PTSD (Post-Traumatic Stress Disorder). We identify the emerging paradigm of \"In-Context Learning\" (ICL) as a suitable interface for domain experts to automate parts of their pipeline without the need for or familiarity with AI model training and fine-tuning, and showcase its remarkable efficacy in data preparation and pattern interpretation. Also, we introduce novel AI-enhancements to tensor decomposition model, which allows for more seamless pattern discovery from the heterogeneous data in our application. We thoroughly evaluate our proposed pipeline experimentally, showcasing its superior performance compared to what is standard practice in the domain, as well as against reasonable ML baselines that do not fall under the ICL paradigm, to ensure that we are not compromising performance in our quest for a seamless and easy-to-use interface for domain experts. Finally, we demonstrate effective discovery, with results validated by the domain experts in the team.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cdAI\u589e\u5f3a\u7684\u79d1\u7814\u53d1\u73b0\u6d41\u7a0b\uff0c\u7279\u522b\u9488\u5bf9\u884c\u4e3a\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u4e2d\u6050\u60e7\u6cdb\u5316\u7684\u7814\u7a76\u3002\u901a\u8fc7\u5229\u7528'\u60c5\u5883\u5b66\u4e60'(ICL)\u8fd9\u4e00\u65b0\u5174\u8303\u5f0f\u4ee5\u53ca\u5bf9\u5f20\u91cf\u5206\u89e3\u6a21\u578b\u7684\u521b\u65b0\u6027\u6539\u8fdb\uff0c\u8be5\u6d41\u7a0b\u80fd\u591f\u81ea\u52a8\u5316\u90e8\u5206\u5b9e\u9a8c\u6570\u636e\u5904\u7406\u548c\u6a21\u5f0f\u8bc6\u522b\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u5de5\u4f5c\u6548\u7387\u5e76\u4fdd\u8bc1\u4e86\u7814\u7a76\u6210\u679c\u7684\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u79d1\u5b66\u7814\u7a76\u6d41\u7a0b\u590d\u6742\u3001\u50f5\u5316\u4e14\u8017\u65f6\u957f\uff0c\u4ece\u6570\u636e\u51c6\u5907\u5230\u5206\u6790\u89e3\u8bfb\u90fd\u9700\u5927\u91cf\u4eba\u529b\u6295\u5165\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7AI\u6280\u672f\u7b80\u5316\u8fd9\u4e00\u6d41\u7a0b\uff0c\u4f7f\u9886\u57df\u4e13\u5bb6\u80fd\u66f4\u4e13\u6ce8\u4e8e\u7406\u89e3\u7814\u7a76\u7ed3\u679c\u800c\u975e\u7e41\u7410\u7684\u6570\u636e\u5904\u7406\u5de5\u4f5c\u3002", "method": "\u91c7\u7528\u201c\u60c5\u5883\u5b66\u4e60\u201d(ICL)\u4f5c\u4e3a\u63a5\u53e3\uff0c\u8ba9\u9886\u57df\u4e13\u5bb6\u65e0\u9700\u6df1\u5165\u4e86\u89e3AI\u6a21\u578b\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u90e8\u5206\u6d41\u7a0b\u81ea\u52a8\u5316\uff1b\u540c\u65f6\u5bf9\u5f20\u91cf\u5206\u89e3\u6a21\u578b\u8fdb\u884c\u4e86\u521b\u65b0\u6027\u6539\u8fdb\u4ee5\u66f4\u597d\u5730\u5904\u7406\u5f02\u6784\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u7ba1\u9053\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5f53\u524d\u9886\u57df\u5185\u7684\u6807\u51c6\u505a\u6cd5\u53ca\u5176\u4ed6\u975eICL\u8303\u5f0f\u7684\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5f97\u5230\u4e86\u56e2\u961f\u5185\u9886\u57df\u4e13\u5bb6\u7684\u8ba4\u53ef\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165AI\u6280\u672f\u7279\u522b\u662fICL\u4e0e\u6539\u826f\u540e\u7684\u5f20\u91cf\u5206\u89e3\u6a21\u578b\uff0c\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u884c\u4e3a\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u6570\u636e\u5206\u6790\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u7814\u7a76\u8d28\u91cf\u3002"}}
{"id": "2602.17050", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17050", "abs": "https://arxiv.org/abs/2602.17050", "authors": ["Ziliang Zhao", "Bi Xue", "Emma Lin", "Mengjiao Zhou", "Kaustubh Vartak", "Shakhzod Ali-Zade", "Carson Lu", "Tao Li", "Bin Kuang", "Rui Jian", "Bin Wen", "Dennis van der Staay", "Yixin Bao", "Eddy Li", "Chao Deng", "Songbin Liu", "Qifan Wang", "Kai Ren"], "title": "Multi-Probe Zero Collision Hash (MPZCH): Mitigating Embedding Collisions and Enhancing Model Freshness in Large-Scale Recommenders", "comment": "10 pages, 6 figures", "summary": "Embedding tables are critical components of large-scale recommendation systems, facilitating the efficient mapping of high-cardinality categorical features into dense vector representations. However, as the volume of unique IDs expands, traditional hash-based indexing methods suffer from collisions that degrade model performance and personalization quality. We present Multi-Probe Zero Collision Hash (MPZCH), a novel indexing mechanism based on linear probing that effectively mitigates embedding collisions. With reasonable table sizing, it often eliminates these collisions entirely while maintaining production-scale efficiency. MPZCH utilizes auxiliary tensors and high-performance CUDA kernels to implement configurable probing and active eviction policies. By retiring obsolete IDs and resetting reassigned slots, MPZCH prevents the stale embedding inheritance typical of hash-based methods, ensuring new features learn effectively from scratch. Despite its collision-mitigation overhead, the system maintains training QPS and inference latency comparable to existing methods. Rigorous online experiments demonstrate that MPZCH achieves zero collisions for user embeddings and significantly improves item embedding freshness and quality. The solution has been released within the open-source TorchRec library for the broader community.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u7d22\u5f15\u673a\u5236MPZCH\uff0c\u5b83\u57fa\u4e8e\u7ebf\u6027\u63a2\u6d4b\u6765\u6709\u6548\u51cf\u5c11\u5d4c\u5165\u78b0\u649e\uff0c\u5e76\u4e14\u5728\u4fdd\u8bc1\u751f\u4ea7\u89c4\u6a21\u6548\u7387\u7684\u540c\u65f6\u901a\u5e38\u80fd\u591f\u5b8c\u5168\u6d88\u9664\u8fd9\u4e9b\u78b0\u649e\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f85\u52a9\u5f20\u91cf\u548c\u9ad8\u6027\u80fdCUDA\u5185\u6838\u5b9e\u73b0\u4e86\u53ef\u914d\u7f6e\u7684\u63a2\u6d4b\u548c\u4e3b\u52a8\u9a71\u9010\u7b56\u7565\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u552f\u4e00ID\u6570\u91cf\u7684\u589e\u957f\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u54c8\u5e0c\u7684\u7d22\u5f15\u65b9\u6cd5\u4f1a\u9047\u5230\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u548c\u4e2a\u4eba\u5316\u8d28\u91cf\u4e0b\u964d\u7684\u51b2\u7a81\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Multi-Probe Zero Collision Hash (MPZCH)\uff0c\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u63a2\u6d4b\u7684\u65b0\u7d22\u5f15\u673a\u5236\uff0c\u5b83\u5229\u7528\u8f85\u52a9\u5f20\u91cf\u548c\u9ad8\u6027\u80fdCUDA\u5185\u6838\u6765\u6267\u884c\u53ef\u914d\u7f6e\u7684\u63a2\u6d4b\u53ca\u79ef\u6781\u7684\u6dd8\u6c70\u7b56\u7565\uff0c\u4ece\u800c\u907f\u514d\u4e86\u65e7\u5d4c\u5165\u7ee7\u627f\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u65b0\u7279\u5f81\u53ef\u4ee5\u4ece\u96f6\u5f00\u59cb\u6709\u6548\u5730\u5b66\u4e60\u3002", "result": "\u5728\u7ebf\u5b9e\u9a8c\u4e25\u683c\u8bc1\u660e\uff0cMPZCH\u5bf9\u4e8e\u7528\u6237\u5d4c\u5165\u5b9e\u73b0\u4e86\u96f6\u78b0\u649e\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u9879\u76ee\u5d4c\u5165\u7684\u65b0\u9c9c\u5ea6\u548c\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "MPZCH\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u89e3\u51b3\u5927\u578b\u63a8\u8350\u7cfb\u7edf\u4e2d\u7531\u4e8e\u9ad8\u57fa\u6570\u5206\u7c7b\u7279\u5f81\u5f15\u8d77\u7684\u5d4c\u5165\u8868\u78b0\u649e\u95ee\u9898\uff0c\u6539\u5584\u4e86\u4e2a\u6027\u5316\u63a8\u8350\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6848\u5df2\u7ecf\u4f5c\u4e3a\u5f00\u6e90\u5e93TorchRec\u7684\u4e00\u90e8\u5206\u53d1\u5e03\u7ed9\u66f4\u5e7f\u6cdb\u7684\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2602.17071", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17071", "abs": "https://arxiv.org/abs/2602.17071", "authors": ["Rong Fu", "Muge Qi", "Chunlei Meng", "Shuo Yin", "Kun Liu", "Zhaolu Kang", "Simon Fong"], "title": "AdvSynGNN: Structure-Adaptive Graph Neural Nets via Adversarial Synthesis and Self-Corrective Propagation", "comment": "32 pages, 8 figures", "summary": "Graph neural networks frequently encounter significant performance degradation when confronted with structural noise or non-homophilous topologies. To address these systemic vulnerabilities, we present AdvSynGNN, a comprehensive architecture designed for resilient node-level representation learning. The proposed framework orchestrates multi-resolution structural synthesis alongside contrastive objectives to establish geometry-sensitive initializations. We develop a transformer backbone that adaptively accommodates heterophily by modulating attention mechanisms through learned topological signals. Central to our contribution is an integrated adversarial propagation engine, where a generative component identifies potential connectivity alterations while a discriminator enforces global coherence. Furthermore, label refinement is achieved through a residual correction scheme guided by per-node confidence metrics, which facilitates precise control over iterative stability. Empirical evaluations demonstrate that this synergistic approach effectively optimizes predictive accuracy across diverse graph distributions while maintaining computational efficiency. The study concludes with practical implementation protocols to ensure the robust deployment of the AdvSynGNN system in large-scale environments.", "AI": {"tldr": "AdvSynGNN is a robust architecture for node-level representation learning in graph neural networks, which uses multi-resolution structural synthesis, contrastive objectives, and an adversarial propagation engine to handle structural noise and non-homophilous topologies, leading to improved predictive accuracy and computational efficiency.", "motivation": "The motivation behind the paper is to address the performance degradation of graph neural networks (GNNs) when dealing with structural noise or non-homophilous (heterophilic) topologies. The authors aim to create a more resilient GNN model that can maintain high performance across various graph structures, including those where nodes are not necessarily connected to similar nodes.", "method": "The method introduced is AdvSynGNN, which includes a transformer backbone that adapts to heterophily by adjusting attention mechanisms based on learned topological signals. It also features an adversarial propagation engine with a generative component that suggests connectivity changes and a discriminator that enforces global coherence. Additionally, it employs a residual correction scheme for label refinement, guided by per-node confidence metrics.", "result": "Empirical evaluations show that AdvSynGNN optimizes predictive accuracy across different graph distributions while keeping computational efficiency. The framework is designed to be robust against structural noise and capable of handling non-homophilous topologies, thereby improving the overall performance of GNNs in diverse scenarios.", "conclusion": "The study concludes that the AdvSynGNN system effectively addresses the challenges faced by GNNs in the presence of structural noise and non-homophilous topologies. It provides practical implementation protocols for deploying the system in large-scale environments, ensuring robustness and efficiency."}}
{"id": "2602.17080", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.17080", "abs": "https://arxiv.org/abs/2602.17080", "authors": ["Minxin Zhang", "Yuxuan Liu", "Hayden Scheaffer"], "title": "Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum", "comment": "39 pages, 6 figures", "summary": "Efficient stochastic optimization typically integrates an update direction that performs well in the deterministic regime with a mechanism adapting to stochastic perturbations. While Adam uses adaptive moment estimates to promote stability, Muon utilizes the weight layers' matrix structure via orthogonalized momentum, showing superior performance in large language model training. We propose a new optimizer and a diagonal extension, NAMO and NAMO-D, providing the first principled integration of orthogonalized momentum with norm-based Adam-type noise adaptation. NAMO scales orthogonalized momentum using a single adaptive stepsize, preserving orthogonality while improving upon Muon at negligible additional cost. NAMO-D instead right-multiplies orthogonalized momentum by a diagonal matrix with clamped entries. This design enables neuron-wise noise adaptation and aligns with the common near block-diagonal Hessian structure. Under standard assumptions, we establish optimal convergence rates for both algorithms in the deterministic setting and show that, in the stochastic setting, their convergence guarantees adapt to the noise level of stochastic gradients. Experiments on pretraining GPT-2 models demonstrate improved performance of both NAMO and NAMO-D compared to the AdamW and Muon baselines, with NAMO-D achieving further gains over NAMO via an additional clamping hyperparameter that balances the competing goals of maintaining a well-conditioned update direction and leveraging fine-grained noise adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668NAMO\u53ca\u5176\u5bf9\u89d2\u6269\u5c55NAMO-D\uff0c\u9996\u6b21\u5c06\u6b63\u4ea4\u5316\u52a8\u91cf\u4e0e\u57fa\u4e8e\u8303\u6570\u7684Adam\u578b\u566a\u58f0\u9002\u5e94\u539f\u5219\u6027\u5730\u7ed3\u5408\u8d77\u6765\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3GPT-2\u6a21\u578b\u65f6\uff0c\u4e24\u8005\u76f8\u6bd4AdamW\u548cMuon\u57fa\u7ebf\u5747\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002", "motivation": "\u4e3a\u4e86\u5728\u968f\u673a\u4f18\u5316\u4e2d\u7ed3\u5408\u4e00\u4e2a\u5728\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\u7684\u66f4\u65b0\u65b9\u5411\u4ee5\u53ca\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u968f\u673a\u6270\u52a8\u7684\u673a\u5236\uff0c\u540c\u65f6\u6539\u8fdb\u73b0\u6709\u7684\u4f18\u5316\u65b9\u6cd5\u5982Adam\u548cMuon\uff0c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u65b0\u7684\u4f18\u5316\u5668NAMO\u53ca\u5b83\u7684\u5bf9\u89d2\u6269\u5c55\u7248\u672cNAMO-D\uff0c\u5176\u4e2dNAMO\u4f7f\u7528\u5355\u4e2a\u81ea\u9002\u5e94\u6b65\u957f\u6765\u8c03\u6574\u6b63\u4ea4\u5316\u52a8\u91cf\u4fdd\u6301\u5176\u6b63\u4ea4\u6027\uff0c\u800cNAMO-D\u5219\u901a\u8fc7\u5bf9\u6b63\u4ea4\u5316\u52a8\u91cf\u53f3\u4e58\u4ee5\u4e00\u4e2a\u5177\u6709\u94b3\u5236\u6761\u76ee\u7684\u5bf9\u89d2\u77e9\u9635\u5b9e\u73b0\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u566a\u58f0\u9002\u5e94\u3002", "result": "NAMO\u548cNAMO-D\u5728\u786e\u5b9a\u6027\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u6700\u4f18\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u4e14\u5728\u968f\u673a\u73af\u5883\u4e2d\u5b83\u4eec\u7684\u6536\u655b\u4fdd\u8bc1\u80fd\u9002\u5e94\u968f\u673a\u68af\u5ea6\u7684\u566a\u58f0\u6c34\u5e73\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u4e8c\u8005\u5728\u9884\u8bad\u7ec3GPT-2\u6a21\u578b\u4e0a\u4f18\u4e8eAdamW\u548cMuon\u57fa\u7ebf\uff0c\u7279\u522b\u662fNAMO-D\u901a\u8fc7\u989d\u5916\u7684\u94b3\u5236\u8d85\u53c2\u6570\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "NAMO\u548cNAMO-D\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u96c6\u6210\u6b63\u4ea4\u5316\u52a8\u91cf\u4e0e\u57fa\u4e8e\u8303\u6570\u7684\u566a\u58f0\u9002\u5e94\uff0c\u4ece\u800c\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u8868\u73b0\u51fa\u8272\u3002NAMO-D\u7279\u522b\u9002\u5408\u4e8e\u9700\u8981\u7cbe\u7ec6\u566a\u58f0\u9002\u5e94\u7684\u4efb\u52a1\u3002"}}
{"id": "2602.17088", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17088", "abs": "https://arxiv.org/abs/2602.17088", "authors": ["Haoyu Wang", "Zhuo Huang", "Xiaolong Wang", "Bo Han", "Zhiwei Lin", "Tongliang Liu"], "title": "MeGU: Machine-Guided Unlearning with Target Feature Disentanglement", "comment": null, "summary": "The growing concern over training data privacy has elevated the \"Right to be Forgotten\" into a critical requirement, thereby raising the demand for effective Machine Unlearning. However, existing unlearning approaches commonly suffer from a fundamental trade-off: aggressively erasing the influence of target data often degrades model utility on retained data, while conservative strategies leave residual target information intact. In this work, the intrinsic representation properties learned during model pretraining are analyzed. It is demonstrated that semantic class concepts are entangled at the feature-pattern level, sharing associated features while preserving concept-specific discriminative components. This entanglement fundamentally limits the effectiveness of existing unlearning paradigms. Motivated by this insight, we propose Machine-Guided Unlearning (MeGU), a novel framework that guides unlearning through concept-aware re-alignment. Specifically, Multi-modal Large Language Models (MLLMs) are leveraged to explicitly determine re-alignment directions for target samples by assigning semantically meaningful perturbing labels. To improve efficiency, inter-class conceptual similarities estimated by the MLLM are encoded into a lightweight transition matrix. Furthermore, MeGU introduces a positive-negative feature noise pair to explicitly disentangle target concept influence. During finetuning, the negative noise suppresses target-specific feature patterns, while the positive noise reinforces remaining associated features and aligns them with perturbing concepts. This coordinated design enables selective disruption of target-specific representations while preserving shared semantic structures. As a result, MeGU enables controlled and selective forgetting, effectively mitigating both under-unlearning and over-unlearning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5f15\u5bfc\u7684\u9057\u5fd8\u6846\u67b6\uff08MeGU\uff09\uff0c\u901a\u8fc7\u6982\u5ff5\u611f\u77e5\u7684\u91cd\u65b0\u5bf9\u9f50\u6765\u6307\u5bfc\u9057\u5fd8\u8fc7\u7a0b\u3002\u5229\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u76ee\u6807\u6837\u672c\u5206\u914d\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u6270\u52a8\u6807\u7b7e\uff0c\u540c\u65f6\u5f15\u5165\u6b63\u8d1f\u7279\u5f81\u566a\u58f0\u5bf9\u4ee5\u663e\u5f0f\u89e3\u7f20\u76ee\u6807\u6982\u5ff5\u5f71\u54cd\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u5171\u4eab\u8bed\u4e49\u7ed3\u6784\u7684\u540c\u65f6\u9009\u62e9\u6027\u5730\u7834\u574f\u7279\u5b9a\u4e8e\u76ee\u6807\u7684\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u9762\u4e34\u4e00\u4e2a\u57fa\u672c\u6743\u8861\uff1a\u79ef\u6781\u62b9\u9664\u76ee\u6807\u6570\u636e\u7684\u5f71\u54cd\u5f80\u5f80\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u4fdd\u7559\u6570\u636e\u4e0a\u7684\u5b9e\u7528\u6027\u4e0b\u964d\uff0c\u800c\u4fdd\u5b88\u7b56\u7565\u5219\u4f1a\u7559\u4e0b\u76ee\u6807\u4fe1\u606f\u6b8b\u4f59\u3002\u6b64\u5916\uff0c\u9884\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u5230\u7684\u5185\u5728\u8868\u5f81\u5c5e\u6027\u4e2d\uff0c\u8bed\u4e49\u7c7b\u6982\u5ff5\u5728\u7279\u5f81\u6a21\u5f0f\u5c42\u9762\u662f\u7ea0\u7f20\u5728\u4e00\u8d77\u7684\uff0c\u8fd9\u4ece\u6839\u672c\u4e0a\u9650\u5236\u4e86\u73b0\u6709\u9057\u5fd8\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u673a\u5668\u5f15\u5bfc\u7684\u9057\u5fd8\uff08MeGU\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6982\u5ff5\u611f\u77e5\u7684\u91cd\u65b0\u5bf9\u9f50\u6765\u6307\u5bfc\u9057\u5fd8\u8fc7\u7a0b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e3a\u9700\u8981\u88ab\u9057\u5fd8\u7684\u76ee\u6807\u6837\u672c\u5206\u914d\u5177\u6709\u8bed\u4e49\u610f\u4e49\u7684\u6270\u52a8\u6807\u7b7e\uff0c\u5e76\u4e14\u57fa\u4e8eMLLM\u4f30\u8ba1\u7684\u7c7b\u95f4\u6982\u5ff5\u76f8\u4f3c\u5ea6\u6784\u5efa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8f6c\u6362\u77e9\u9635\u3002\u6b64\u5916\uff0cMeGU\u8fd8\u5f15\u5165\u4e86\u6b63\u8d1f\u7279\u5f81\u566a\u58f0\u5bf9\uff0c\u7528\u4e8e\u660e\u786e\u5206\u79bb\u76ee\u6807\u6982\u5ff5\u7684\u5f71\u54cd\u3002\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff0c\u8d1f\u566a\u58f0\u6291\u5236\u4e86\u4e0e\u76ee\u6807\u76f8\u5173\u7684\u7279\u5f81\u6a21\u5f0f\uff0c\u800c\u6b63\u566a\u58f0\u5219\u5f3a\u5316\u4e86\u5269\u4f59\u7684\u76f8\u5173\u7279\u5f81\uff0c\u5e76\u5c06\u5b83\u4eec\u4e0e\u6270\u52a8\u6982\u5ff5\u5bf9\u9f50\u3002", "result": "MeGU\u80fd\u591f\u5b9e\u73b0\u53d7\u63a7\u548c\u9009\u62e9\u6027\u7684\u9057\u5fd8\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u9057\u5fd8\u4e0d\u8db3\u548c\u8fc7\u5ea6\u9057\u5fd8\u7684\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528MeGU\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u5904\u7406\u2018\u88ab\u9057\u5fd8\u7684\u6743\u5229\u2019\u95ee\u9898\uff0c\u5728\u79fb\u9664\u7279\u5b9a\u6570\u636e\u75d5\u8ff9\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5bf9\u4e8e\u5176\u4ed6\u6570\u636e\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.17089", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.17089", "abs": "https://arxiv.org/abs/2602.17089", "authors": ["Xinghao Dong", "Huchen Yang", "Jin-long Wu"], "title": "Synergizing Transport-Based Generative Models and Latent Geometry for Stochastic Closure Modeling", "comment": null, "summary": "Diffusion models recently developed for generative AI tasks can produce high-quality samples while still maintaining diversity among samples to promote mode coverage, providing a promising path for learning stochastic closure models. Compared to other types of generative AI models, such as GANs and VAEs, the sampling speed is known as a key disadvantage of diffusion models. By systematically comparing transport-based generative models on a numerical example of 2D Kolmogorov flows, we show that flow matching in a lower-dimensional latent space is suited for fast sampling of stochastic closure models, enabling single-step sampling that is up to two orders of magnitude faster than iterative diffusion-based approaches. To control the latent space distortion and thus ensure the physical fidelity of the sampled closure term, we compare the implicit regularization offered by a joint training scheme against two explicit regularizers: metric-preserving (MP) and geometry-aware (GA) constraints. Besides offering a faster sampling speed, both explicitly and implicitly regularized latent spaces inherit the key topological information from the lower-dimensional manifold of the original complex dynamical system, which enables the learning of stochastic closure models without demanding a huge amount of training data.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6d41\u5339\u914d\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u9002\u7528\u4e8e\u5feb\u901f\u91c7\u6837\u968f\u673a\u95ed\u5408\u6a21\u578b\uff0c\u6bd4\u8fed\u4ee3\u6269\u6563\u65b9\u6cd5\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u6bd4\u8f83\u9690\u5f0f\u6b63\u5219\u5316\u548c\u4e24\u79cd\u663e\u5f0f\u6b63\u5219\u5316\uff08\u4fdd\u6301\u5ea6\u91cf\u548c\u51e0\u4f55\u611f\u77e5\u7ea6\u675f\uff09\u7684\u6548\u679c\uff0c\u8868\u660e\u65e0\u8bba\u662f\u663e\u5f0f\u8fd8\u662f\u9690\u5f0f\u6b63\u5219\u5316\u7684\u6f5c\u5728\u7a7a\u95f4\u90fd\u80fd\u591f\u7ee7\u627f\u539f\u59cb\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4f4e\u7ef4\u6d41\u5f62\u7684\u5173\u952e\u62d3\u6251\u4fe1\u606f\uff0c\u4ece\u800c\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u968f\u673a\u95ed\u5408\u6a21\u578b\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u80fd\u591f\u4e3a\u751f\u6210AI\u4efb\u52a1\u63d0\u4f9b\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u5e76\u7ef4\u6301\u6837\u672c\u591a\u6837\u6027\u4ee5\u4fc3\u8fdb\u6a21\u5f0f\u8986\u76d6\uff0c\u4f46\u5176\u91c7\u6837\u901f\u5ea6\u8f83\u6162\u88ab\u89c6\u4e3a\u4e3b\u8981\u52a3\u52bf\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u6d41\u5339\u914d\u6280\u672f\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u52a0\u901f\u91c7\u6837\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u8bc1\u7269\u7406\u4fdd\u771f\u5ea6\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4f20\u8f93\u7684\u751f\u6210\u6a21\u578b\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5177\u4f53\u662f\u57282D Kolmogorov\u6d41\u7684\u6570\u503c\u793a\u4f8b\u4e0a\u8fdb\u884c\u3002\u6b64\u5916\uff0c\u8fd8\u8bc4\u4f30\u4e86\u8054\u5408\u8bad\u7ec3\u65b9\u6848\u63d0\u4f9b\u7684\u9690\u5f0f\u6b63\u5219\u5316\u4e0e\u4e24\u79cd\u663e\u5f0f\u6b63\u5219\u5316\u2014\u2014\u4fdd\u6301\u5ea6\u91cf(MP)\u548c\u51e0\u4f55\u611f\u77e5(GA)\u7ea6\u675f\u2014\u2014\u4e4b\u95f4\u7684\u6548\u679c\u5dee\u5f02\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4f7f\u7528\u6d41\u5339\u914d\u53ef\u4ee5\u5b9e\u73b0\u5355\u6b65\u91c7\u6837\uff0c\u6bd4\u8fed\u4ee3\u6269\u6563\u65b9\u6cd5\u5feb\u81f3\u591a\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002\u800c\u4e14\uff0c\u65e0\u8bba\u662f\u901a\u8fc7\u9690\u5f0f\u8fd8\u662f\u663e\u5f0f\u6b63\u5219\u5316\u7684\u6f5c\u5728\u7a7a\u95f4\u90fd\u4fdd\u7559\u4e86\u539f\u59cb\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4f4e\u7ef4\u6d41\u5f62\u7684\u5173\u952e\u62d3\u6251\u4fe1\u606f\uff0c\u8fd9\u4f7f\u5f97\u5373\u4f7f\u6ca1\u6709\u5927\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u4e5f\u80fd\u5b66\u4e60\u5230\u6709\u6548\u7684\u968f\u673a\u95ed\u5408\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u9700\u8981\u5feb\u901f\u91c7\u6837\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u5b66\u4e60\u968f\u673a\u95ed\u5408\u6a21\u578b\u65f6\uff0c\u5229\u7528\u6d41\u5339\u914d\u6280\u672f\u5728\u9002\u5f53\u6b63\u5219\u5316\u7684\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u64cd\u4f5c\u662f\u4e00\u4e2a\u6709\u6548\u7b56\u7565\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\uff0c\u8fd8\u4fdd\u8bc1\u4e86\u6240\u5b66\u6a21\u578b\u7684\u7269\u7406\u51c6\u786e\u6027\u3002"}}
{"id": "2602.17095", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17095", "abs": "https://arxiv.org/abs/2602.17095", "authors": ["Chuiyang Meng", "Ming Tang", "Vincent W. S. Wong"], "title": "FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignment", "comment": null, "summary": "Parameter-efficient fine-tuning techniques such as low-rank adaptation (LoRA) enable large language models (LLMs) to adapt to downstream tasks efficiently. Federated learning (FL) further facilitates this process by enabling collaborative fine-tuning across distributed clients without sharing private data. However, the use of two separate low-rank matrices in LoRA for federated fine-tuning introduces two types of challenges. The first challenge arises from the error induced by separately aggregating those two low-rank matrices. The second challenge occurs even when the product of two low-rank matrices is aggregated. The server needs to recover factors via matrix decomposition, which is non-unique and can introduce decomposition drift. To tackle the aforementioned challenges, we propose FLoRG, a federated fine-tuning framework which employs a single low-rank matrix for fine-tuning and aggregates its Gram matrix (i.e., the matrix of inner products of its column vectors), eliminating the aggregation error while also reducing the communication overhead. FLoRG minimizes the decomposition drift by introducing a Procrustes alignment approach which aligns the decomposed matrix between consecutive fine-tuning rounds for consistent updates. We theoretically analyze the convergence of FLoRG and prove that adopting the Procrustes alignment results in a tighter convergence bound. Experimental results across multiple LLM fine-tuning benchmarks demonstrate that FLoRG outperforms five state-of-the-art baseline schemes in the downstream task accuracy and can reduce the communication overhead by up to 2041$\\times$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFLoRG\u7684\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u5355\u4e2a\u4f4e\u79e9\u77e9\u9635\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u805a\u96c6\u5176Gram\u77e9\u9635\uff0c\u4ee5\u89e3\u51b3\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5e26\u6765\u7684\u805a\u5408\u8bef\u5dee\u548c\u5206\u89e3\u6f02\u79fb\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFLoRG\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u8fd8\u5927\u5e45\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5982\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u8fdb\u884c\u5fae\u8c03\u65f6\u9047\u5230\u7684\u95ee\u9898\u2014\u2014\u5373\u7531\u4e8e\u5206\u522b\u805a\u5408\u4e24\u4e2a\u4f4e\u79e9\u77e9\u9635\u6240\u5f15\u8d77\u7684\u9519\u8bef\u4ee5\u53ca\u5373\u4f7f\u805a\u5408\u4e86\u4e24\u4e2a\u4f4e\u79e9\u77e9\u9635\u4e58\u79ef\u540e\u4ecd\u9700\u901a\u8fc7\u975e\u552f\u4e00\u6027\u77e9\u9635\u5206\u89e3\u6765\u6062\u590d\u56e0\u5b50\u5bfc\u81f4\u7684\u5206\u89e3\u6f02\u79fb\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFLoRG\u6846\u67b6\uff0c\u5b83\u91c7\u7528\u5355\u4e00\u4f4e\u79e9\u77e9\u9635\u4ee3\u66ff\u4f20\u7edf\u7684\u53cc\u4f4e\u79e9\u77e9\u9635\u8bbe\u8ba1\u6765\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u805a\u96c6\u6b64\u4f4e\u79e9\u77e9\u9635\u7684Gram\u77e9\u9635\u800c\u975e\u76f4\u63a5\u805a\u96c6\u4f4e\u79e9\u77e9\u9635\u672c\u8eab\u6765\u6d88\u9664\u56e0\u5206\u6563\u5f0f\u805a\u5408\u800c\u4ea7\u751f\u7684\u8bef\u5dee\u3002\u540c\u65f6\uff0c\u5f15\u5165Procrustes\u5bf9\u9f50\u65b9\u6cd5\u6700\u5c0f\u5316\u8fde\u7eed\u5fae\u8c03\u8f6e\u6b21\u95f4\u56e0\u77e9\u9635\u5206\u89e3\u975e\u552f\u4e00\u6027\u800c\u5bfc\u81f4\u7684\u6f02\u79fb\u95ee\u9898\uff0c\u786e\u4fdd\u66f4\u65b0\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff0c\u91c7\u7528Procrustes\u5bf9\u9f50\u6cd5\u53ef\u4ee5\u5f97\u5230\u66f4\u7d27\u7684\u6536\u655b\u754c\u9650\uff1b\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cFLoRG\u76f8\u6bd4\u4e94\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6848\uff0c\u5728\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u8fd8\u80fd\u5c06\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u81f3\u591a2041\u500d\u3002", "conclusion": "FLoRG\u4e3a\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.17102", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17102", "abs": "https://arxiv.org/abs/2602.17102", "authors": ["Sai Vineeth Kandappareddigari", "Santhoshkumar Jagadish", "Gauri Verma", "Ilhuicamina Contreras", "Christopher Dignam", "Anmol Srivastava", "Benjamin Demers"], "title": "Operationalization of Machine Learning with Serverless Architecture: An Industrial Operationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction", "comment": "13 pages. ICAD '26", "summary": "This paper presents a serverless MLOps framework orchestrating the complete ML lifecycle from data ingestion, training, deployment, monitoring, and retraining to using event-driven pipelines and managed services. The architecture is model-agnostic, supporting diverse inference patterns through standardized interfaces, enabling rapid adaptation without infrastructure overhead. We demonstrate practical applicability through an industrial implementation for Harmonized System (HS) code prediction, a compliance-critical task where short, unstructured product descriptions are mapped to standardized codes used by customs authorities in global trade. Frequent updates and ambiguous descriptions make classification challenging, with errors causing shipment delays and financial losses. Our solution uses a custom text embedding encoder and multiple deep learning architectures, with Text-CNN achieving 98 percent accuracy on ground truth data. Beyond accuracy, the pipeline ensures reproducibility, auditability, and SLA adherence under variable loads via auto-scaling. A key feature is automated A/B testing, enabling dynamic model selection and safe promotion in production. Cost-efficiency drives model choice; while transformers may achieve similar accuracy, their long-term operational costs are significantly higher. Deterministic classification with predictable latency and explainability is prioritized, though the architecture remains extensible to transformer variants and LLM-based inference. The paper first introduces the deep learning architectures with simulations and model comparisons, then discusses industrialization through serverless architecture, demonstrating automated retraining, prediction, and validation of HS codes. This work provides a replicable blueprint for operationalizing ML using serverless architecture, enabling enterprises to scale while optimizing performance and economics.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65e0\u670d\u52a1\u5668\u7684MLOps\u6846\u67b6\uff0c\u7528\u4e8e\u7ba1\u7406\u4ece\u6570\u636e\u6444\u5165\u5230\u91cd\u65b0\u8bad\u7ec3\u7684\u5b8c\u6574\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u3002\u901a\u8fc7\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u2014\u2014HS\u7f16\u7801\u9884\u6d4b\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5176\u4e2dText-CNN\u6a21\u578b\u8fbe\u5230\u4e8698%\u7684\u51c6\u786e\u7387\u3002\u6b64\u5916\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u8fd8\u786e\u4fdd\u4e86\u53ef\u91cd\u590d\u6027\u3001\u53ef\u5ba1\u8ba1\u6027\u548c\u670d\u52a1\u7ea7\u522b\u534f\u8bae\u9075\u5b88\uff0c\u5e76\u4e14\u4f18\u5148\u8003\u8651\u6210\u672c\u6548\u76ca\u548c\u786e\u5b9a\u6027\u7684\u5206\u7c7b\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65e0\u670d\u52a1\u5668MLOps\u6846\u67b6\uff0c\u4ee5\u7b80\u5316\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u9879\u76ee\u4ece\u5f00\u53d1\u5230\u90e8\u7f72\u7684\u6574\u4e2a\u8fc7\u7a0b\u3002\u7279\u522b\u5730\uff0c\u901a\u8fc7\u4e00\u4e2a\u5de5\u4e1a\u5b9e\u65bd\u4f8b\u5b50\u2014\u2014HS\u4ee3\u7801\u9884\u6d4b\uff0c\u8bf4\u660e\u4e86\u8be5\u6846\u67b6\u5728\u5904\u7406\u5173\u952e\u5408\u89c4\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u4e86\u4e8b\u4ef6\u9a71\u52a8\u7684\u7ba1\u9053\u548c\u670d\u52a1\u6765\u6784\u5efa\u4e00\u4e2a\u65e0\u670d\u52a1\u5668\u67b6\u6784\uff0c\u652f\u6301\u591a\u79cd\u63a8\u7406\u6a21\u5f0f\u3002\u5bf9\u4e8eHS\u4ee3\u7801\u9884\u6d4b\u95ee\u9898\uff0c\u4f7f\u7528\u4e86\u81ea\u5b9a\u4e49\u6587\u672c\u5d4c\u5165\u7f16\u7801\u5668\u52a0\u4e0a\u51e0\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u6700\u7ec8\u9009\u62e9Text-CNN\u4f5c\u4e3a\u6700\u4f73\u6a21\u578b\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6848\u4e0d\u4ec5\u5728HS\u4ee3\u7801\u9884\u6d4b\u4e0a\u53d6\u5f97\u4e8698%\u7684\u9ad8\u51c6\u786e\u5ea6\uff0c\u800c\u4e14\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4fdd\u8bc1\u4e86\u826f\u597d\u7684\u53ef\u518d\u73b0\u6027\u3001\u5ba1\u8ba1\u80fd\u529b\u548cSLA\u9075\u5faa\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7684A/B\u6d4b\u8bd5\u673a\u5236\u5b9e\u73b0\u4e86\u52a8\u6001\u6a21\u578b\u9009\u62e9\u4e0e\u5b89\u5168\u63a8\u5e7f\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u670d\u52a1\u5668\u67b6\u6784\u5b9e\u73b0\u673a\u5668\u5b66\u4e60\u64cd\u4f5c\u7684\u53ef\u590d\u5236\u84dd\u56fe\uff0c\u5e2e\u52a9\u4f01\u4e1a\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\u4e5f\u5173\u6ce8\u7ecf\u6d4e\u6210\u672c\u3002\u867d\u7136\u6587\u4e2d\u63d0\u5230\u7684\u67b6\u6784\u4e3b\u8981\u9488\u5bf9\u975eTransformer\u7c7b\u6a21\u578b\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4f46\u5176\u8bbe\u8ba1\u5177\u6709\u8db3\u591f\u7684\u7075\u6d3b\u6027\u4ee5\u9002\u5e94\u672a\u6765\u53ef\u80fd\u5f15\u5165\u7684\u65b0\u6280\u672f\u3002"}}
{"id": "2602.17117", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17117", "abs": "https://arxiv.org/abs/2602.17117", "authors": ["Yicheng Cao", "Zhuo Huang", "Yu Yao", "Yiming Ying", "Daoyi Dong", "Tongliang Liu"], "title": "i-PhysGaussian: Implicit Physical Simulation for 3D Gaussian Splatting", "comment": null, "summary": "Physical simulation predicts future states of objects based on material properties and external loads, enabling blueprints for both Industry and Engineering to conduct risk management. Current 3D reconstruction-based simulators typically rely on explicit, step-wise updates, which are sensitive to step time and suffer from rapid accuracy degradation under complicated scenarios, such as high-stiffness materials or quasi-static movement. To address this, we introduce i-PhysGaussian, a framework that couples 3D Gaussian Splatting (3DGS) with an implicit Material Point Method (MPM) integrator. Unlike explicit methods, our solution obtains an end-of-step state by minimizing a momentum-balance residual through implicit Newton-type optimization with a GMRES solver. This formulation significantly reduces time-step sensitivity and ensures physical consistency. Our results demonstrate that i-PhysGaussian maintains stability at up to 20x larger time steps than explicit baselines, preserving structural coherence and smooth motion even in complex dynamic transitions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u54083D\u9ad8\u65af\u70b9\u7ed8\u548c\u9690\u5f0f\u7269\u8d28\u70b9\u65b9\u6cd5\u7684\u65b0\u578b\u7269\u7406\u6a21\u62df\u6846\u67b6i-PhysGaussian\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u52a8\u91cf\u5e73\u8861\u6b8b\u5dee\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u6a21\u62df\u6548\u679c\uff0c\u5c24\u5176\u5728\u5904\u7406\u9ad8\u521a\u5ea6\u6750\u6599\u6216\u51c6\u9759\u6001\u8fd0\u52a8\u7b49\u590d\u6742\u573a\u666f\u65f6\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e3D\u91cd\u5efa\u7684\u6a21\u62df\u5668\u901a\u5e38\u4f9d\u8d56\u4e8e\u663e\u5f0f\u7684\u3001\u9010\u6b65\u66f4\u65b0\u7684\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u65f6\u95f4\u6b65\u957f\u654f\u611f\uff0c\u5728\u9762\u5bf9\u5982\u9ad8\u521a\u5ea6\u6750\u6599\u6216\u51c6\u9759\u6001\u79fb\u52a8\u8fd9\u6837\u7684\u590d\u6742\u60c5\u51b5\u65f6\uff0c\u51c6\u786e\u6027\u4f1a\u5feb\u901f\u4e0b\u964d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u6a21\u62df\u7cbe\u5ea6\u4e0e\u7a33\u5b9a\u6027\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86i-PhysGaussian\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c063D\u9ad8\u65af\u70b9\u7ed8(3DGS)\u4e0e\u9690\u5f0f\u7269\u8d28\u70b9\u6cd5(MPM)\u79ef\u5206\u5668\u76f8\u7ed3\u5408\u3002\u4e0e\u4f20\u7edf\u7684\u663e\u5f0f\u65b9\u6cd5\u4e0d\u540c\uff0ci-PhysGaussian\u901a\u8fc7\u4f7f\u7528GMRES\u6c42\u89e3\u5668\u8fdb\u884c\u9690\u5f0f\u7684Newton\u7c7b\u578b\u4f18\u5316\u6765\u6700\u5c0f\u5316\u52a8\u91cf\u5e73\u8861\u6b8b\u5dee\uff0c\u4ece\u800c\u5f97\u5230\u6700\u7ec8\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e8e\u663e\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0ci-PhysGaussian\u80fd\u591f\u5728\u9ad8\u8fbe20\u500d\u5927\u7684\u65f6\u95f4\u6b65\u957f\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u5373\u4f7f\u662f\u5728\u590d\u6742\u7684\u52a8\u6001\u8f6c\u6362\u4e2d\u4e5f\u80fd\u4fdd\u6301\u7ed3\u6784\u7684\u4e00\u81f4\u6027\u548c\u5e73\u6ed1\u7684\u52a8\u4f5c\u3002", "conclusion": "i-PhysGaussian\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u7269\u7406\u6a21\u62df\u5668\u5c40\u9650\u6027\u7684\u65b0\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9700\u8981\u66f4\u9ad8\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\u7684\u590d\u6742\u573a\u666f\u65f6\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2602.17122", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17122", "abs": "https://arxiv.org/abs/2602.17122", "authors": ["Xihao Piao", "Zheng Chen", "Lingwei Zhu", "Yushun Dong", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series", "comment": null, "summary": "Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data. Existing methods attempt to alleviate the dependence by, e.g., removing low-order moments from each individual sample. These solutions fail to capture the underlying time-evolving structure across samples and do not model the complex time structure. In this paper, we aim to address the distribution shift in the frequency space by considering all possible time structures. To this end, we propose a Time-Invariant Frequency Operator (TIFO), which learns stationarity-aware weights over the frequency spectrum across the entire dataset. The weight representation highlights stationary frequency components while suppressing non-stationary ones, thereby mitigating the distribution shift issue in time series. To justify our method, we show that the Fourier transform of time series data implicitly induces eigen-decomposition in the frequency space. TIFO is a plug-and-play approach that can be seamlessly integrated into various forecasting models. Experiments demonstrate our method achieves 18 top-1 and 6 top-2 results out of 28 forecasting settings. Notably, it yields 33.3% and 55.3% improvements in average MSE on the ETTm2 dataset. In addition, TIFO reduces computational costs by 60% -70% compared to baseline methods, demonstrating strong scalability across diverse forecasting models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u95f4\u4e0d\u53d8\u9891\u7387\u7b97\u5b50(TIFO)\uff0c\u901a\u8fc7\u5728\u6574\u4e2a\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u9891\u8c31\u4e0a\u7684\u5e73\u7a33\u6027\u611f\u77e5\u6743\u91cd\u6765\u89e3\u51b3\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002TIFO\u80fd\u591f\u5728\u591a\u79cd\u9884\u6d4b\u6a21\u578b\u4e2d\u65e0\u7f1d\u96c6\u6210\uff0c\u5e76\u4e14\u5b9e\u9a8c\u663e\u793a\u5b83\u572828\u4e2a\u9884\u6d4b\u8bbe\u7f6e\u4e2d\u670918\u6b21\u6392\u540d\u7b2c\u4e00\u30016\u6b21\u6392\u540d\u7b2c\u4e8c\uff0c\u540c\u65f6\u5728ETTm2\u6570\u636e\u96c6\u4e0a\u5e73\u5747MSE\u63d0\u9ad8\u4e8633.3%\u81f355.3%\uff0c\u5e76\u4e14\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u964d\u4f4e\u4e8660%-70%\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9762\u4e34\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u7531\u4e0d\u540c\u5206\u5e03\u4ea7\u751f\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u4f8b\u5982\u4ece\u6bcf\u4e2a\u6837\u672c\u4e2d\u53bb\u9664\u4f4e\u9636\u77e9\u6765\u51cf\u8f7b\u8fd9\u79cd\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u672a\u80fd\u6355\u6349\u5230\u6837\u672c\u95f4\u7684\u57fa\u672c\u65f6\u53d8\u7ed3\u6784\uff0c\u4e5f\u672a\u5bf9\u590d\u6742\u7684\u65f6\u95f4\u7ed3\u6784\u8fdb\u884c\u5efa\u6a21\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u65f6\u95f4\u4e0d\u53d8\u9891\u7387\u7b97\u5b50\uff08TIFO\uff09\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8003\u8651\u6240\u6709\u53ef\u80fd\u7684\u65f6\u95f4\u7ed3\u6784\uff0c\u5728\u9891\u57df\u5185\u89e3\u51b3\u4e86\u5206\u5e03\u504f\u79fb\u7684\u95ee\u9898\u3002TIFO\u80fd\u591f\u5b66\u4e60\u6574\u4e2a\u6570\u636e\u96c6\u9891\u8c31\u4e0a\u7684\u5e73\u7a33\u6027\u654f\u611f\u6743\u91cd\uff0c\u4ece\u800c\u7a81\u51fa\u5e73\u7a33\u9891\u7387\u6210\u5206\u5e76\u6291\u5236\u975e\u5e73\u7a33\u6210\u5206\uff0c\u8fdb\u800c\u7f13\u89e3\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u572828\u4e2a\u9884\u6d4b\u573a\u666f\u4e2d\u53d6\u5f97\u4e8618\u6b21\u7b2c\u4e00\u548c6\u6b21\u7b2c\u4e8c\u7684\u6210\u7ee9\u3002\u7279\u522b\u5730\uff0c\u5728ETTm2\u6570\u636e\u96c6\u4e0a\uff0c\u5e73\u5747MSE\u5206\u522b\u63d0\u5347\u4e8633.3%\u548c55.3%\u3002\u6b64\u5916\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cTIFO\u8fd8\u51cf\u5c11\u4e8660%-70%\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "TIFO\u4f5c\u4e3a\u89e3\u51b3\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5206\u5e03\u504f\u79fb\u95ee\u9898\u7684\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u80fd\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5c55\u73b0\u51fa\u4e86\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.17133", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17133", "abs": "https://arxiv.org/abs/2602.17133", "authors": ["Linwei Zhai", "Han Ding", "Mingzhi Lin", "Cui Zhao", "Fei Wang", "Ge Wang", "Wang Zhi", "Wei Xi"], "title": "VP-VAE: Rethinking Vector Quantization via Adaptive Vector Perturbation", "comment": null, "summary": "Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental to modern generative modeling, yet they often suffer from training instability and \"codebook collapse\" due to the inherent coupling of representation learning and discrete codebook optimization. In this paper, we propose VP-VAE (Vector Perturbation VAE), a novel paradigm that decouples representation learning from discretization by eliminating the need for an explicit codebook during training. Our key insight is that, from the neural network's viewpoint, performing quantization primarily manifests as injecting a structured perturbation in latent space. Accordingly, VP-VAE replaces the non-differentiable quantizer with distribution-consistent and scale-adaptive latent perturbations generated via Metropolis--Hastings sampling. This design enables stable training without a codebook while making the model robust to inference-time quantization error. Moreover, under the assumption of approximately uniform latent variables, we derive FSP (Finite Scalar Perturbation), a lightweight variant of VP-VAE that provides a unified theoretical explanation and a practical improvement for FSQ-style fixed quantizers. Extensive experiments on image and audio benchmarks demonstrate that VP-VAE and FSP improve reconstruction fidelity and achieve substantially more balanced token usage, while avoiding the instability inherent to coupled codebook training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578bVP-VAE\uff0c\u5b83\u901a\u8fc7\u6d88\u9664\u8bad\u7ec3\u671f\u95f4\u5bf9\u663e\u5f0f\u7801\u672c\u7684\u9700\u6c42\u6765\u89e3\u8026\u8868\u793a\u5b66\u4e60\u548c\u79bb\u6563\u5316\u8fc7\u7a0b\u3002VP-VAE\u4f7f\u7528Metropolis-Hastings\u91c7\u6837\u751f\u6210\u7684\u6f5c\u53d8\u91cf\u6270\u52a8\u4ee3\u66ff\u975e\u53ef\u5fae\u5206\u91cf\u5316\u5668\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u65e0\u7801\u672c\u7684\u7a33\u5b9a\u8bad\u7ec3\uff0c\u5e76\u4e14\u5bf9\u4e8e\u63a8\u7406\u65f6\u7684\u91cf\u5316\u8bef\u5dee\u66f4\u52a0\u9c81\u68d2\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u8fd1\u4f3c\u5747\u5300\u6f5c\u5728\u53d8\u91cf\u7684\u5047\u8bbe\uff0c\u8fd8\u5bfc\u51fa\u4e86FSP\uff08\u6709\u9650\u6807\u91cf\u6270\u52a8\uff09\uff0c\u4f5c\u4e3aVP-VAE\u7684\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u53d8\u4f53\uff0c\u4e3aFSQ\u98ce\u683c\u7684\u56fa\u5b9a\u91cf\u5316\u5668\u63d0\u4f9b\u7edf\u4e00\u7406\u8bba\u89e3\u91ca\u53ca\u5b9e\u9645\u6539\u8fdb\u3002\u5b9e\u9a8c\u8868\u660e\uff0cVP-VAE\u4e0eFSP\u5728\u56fe\u50cf\u548c\u97f3\u9891\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u8fbe\u5230\u66f4\u5e73\u8861\u7684\u4ee4\u724c\u4f7f\u7528\u7387\uff0c\u540c\u65f6\u907f\u514d\u4e86\u7531\u4e8e\u8054\u5408\u7801\u672c\u8bad\u7ec3\u5f15\u8d77\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u7684VQ-VAE\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u9047\u5230\u4e0d\u7a33\u5b9a\u6027\u548c\u201c\u7801\u672c\u5d29\u6e83\u201d\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u56e0\u4e3a\u8868\u793a\u5b66\u4e60\u4e0e\u79bb\u6563\u7801\u672c\u4f18\u5316\u4e4b\u95f4\u5b58\u5728\u5185\u5728\u8054\u7cfb\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5c06\u8868\u793a\u5b66\u4e60\u4e0e\u79bb\u6563\u5316\u8fc7\u7a0b\u5206\u79bb\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u6548\u679c\u3002", "method": "VP-VAE\u901a\u8fc7\u5f15\u5165\u5206\u5e03\u4e00\u81f4\u4e14\u5c3a\u5ea6\u81ea\u9002\u5e94\u7684\u6f5c\u53d8\u91cf\u6270\u52a8\u6765\u66ff\u4ee3\u975e\u53ef\u5fae\u5206\u91cf\u5316\u5668\uff0c\u8fd9\u4e9b\u6270\u52a8\u662f\u901a\u8fc7Metropolis--Hastings\u91c7\u6837\u4ea7\u751f\u7684\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5728\u6ca1\u6709\u663e\u5f0f\u7801\u672c\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u7a33\u5b9a\u8bad\u7ec3\uff0c\u5e76\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u63a8\u7406\u9636\u6bb5\u91cf\u5316\u9519\u8bef\u7684\u9c81\u68d2\u6027\u3002\u53e6\u5916\uff0c\u6587\u7ae0\u8fd8\u63d0\u51fa\u4e86FSP\uff08\u6709\u9650\u6807\u91cf\u6270\u52a8\uff09\u4f5c\u4e3aVP-VAE\u7684\u4e00\u79cd\u7b80\u5316\u7248\u672c\uff0c\u9002\u7528\u4e8e\u8fd1\u4f3c\u5747\u5300\u5206\u5e03\u7684\u6f5c\u53d8\u91cf\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u56fe\u50cf\u548c\u97f3\u9891\u6570\u636e\u96c6\u4e0a\uff0cVP-VAE\u548cFSP\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\uff0c\u5e76\u4e14\u5728\u4ee4\u724c\u4f7f\u7528\u65b9\u9762\u8868\u73b0\u5f97\u66f4\u4e3a\u5747\u8861\u3002\u6b64\u5916\uff0c\u65b0\u65b9\u6cd5\u6709\u6548\u907f\u514d\u4e86\u7531\u8054\u5408\u7801\u672c\u8bad\u7ec3\u5bfc\u81f4\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "conclusion": "VP-VAE\u53ca\u5176\u53d8\u4f53FSP\u4e3a\u89e3\u51b3VQ-VAE\u4e2d\u5b58\u5728\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u548c\u7801\u672c\u5d29\u6e83\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5c06\u8868\u793a\u5b66\u4e60\u4ece\u79bb\u6563\u5316\u8fc7\u7a0b\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u5176\u6027\u80fd\u3002"}}
{"id": "2602.17149", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17149", "abs": "https://arxiv.org/abs/2602.17149", "authors": ["Tong Guan", "Sheng Pan", "Johan Barthelemy", "Zhao Li", "Yujun Cai", "Cesare Alippi", "Ming Jin", "Shirui Pan"], "title": "TimeOmni-VL: Unified Models for Time Series Understanding and Generation", "comment": null, "summary": "Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multimodal models (UMMs) have bridged this gap in vision, their potential for time series remains untapped. We propose TimeOmni-VL, the first vision-centric framework that unifies time series understanding and generation through two key innovations: (1) Fidelity-preserving bidirectional mapping between time series and images (Bi-TSI), which advances Time Series-to-Image (TS2I) and Image-to-Time Series (I2TS) conversions to ensure near-lossless transformations. (2) Understanding-guided generation. We introduce TSUMM-Suite, a novel dataset consists of six understanding tasks rooted in time series analytics that are coupled with two generation tasks. With a calibrated Chain-of-Thought, TimeOmni-VL is the first to leverage time series understanding as an explicit control signal for high-fidelity generation. Experiments confirm that this unified approach significantly improves both semantic understanding and numerical precision, establishing a new frontier for multimodal time series modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TimeOmni-VL\uff0c\u8fd9\u662f\u4e00\u4e2a\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u771f\u5ea6\u7684\u53cc\u5411\u6620\u5c04\u548c\u7406\u89e3\u5bfc\u5411\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u7edf\u4e00\u4e86\u65f6\u95f4\u5e8f\u5217\u7684\u7406\u89e3\u4e0e\u751f\u6210\u3002\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u65b9\u6cd5\u5728\u63d0\u9ad8\u8bed\u4e49\u7406\u89e3\u548c\u6570\u503c\u7cbe\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\uff0c\u4e3a\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u7684\u524d\u6cbf\u3002", "motivation": "\u6700\u8fd1\u7684\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u5728\u6570\u503c\u751f\u6210\u548c\u8bed\u4e49\u7406\u89e3\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u5206\u6b67\u3002\u751f\u6210\u6a21\u578b\u5f80\u5f80\u4f9d\u8d56\u4e8e\u8868\u9762\u6a21\u5f0f\u5339\u914d\uff0c\u800c\u9762\u5411\u7406\u89e3\u7684\u6a21\u578b\u5219\u96be\u4ee5\u63d0\u4f9b\u9ad8\u4fdd\u771f\u7684\u6570\u503c\u8f93\u51fa\u3002\u5c3d\u7ba1\u7edf\u4e00\u7684\u591a\u6a21\u6001\u6a21\u578b(UMMs)\u5df2\u7ecf\u5728\u89c6\u89c9\u9886\u57df\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u5728\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u53d1\u6398\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTimeOmni-VL\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u521b\u65b0\u6765\u7edf\u5408\u65f6\u95f4\u5e8f\u5217\u7684\u7406\u89e3\u4e0e\u751f\u6210\uff1a\uff081\uff09\u5f00\u53d1\u4e86\u65f6\u95f4\u5e8f\u5217\u4e0e\u56fe\u50cf\u4e4b\u95f4\u7684\u4fdd\u771f\u5ea6\u4fdd\u7559\u53cc\u5411\u6620\u5c04\uff08Bi-TSI\uff09\uff0c\u6539\u8fdb\u4e86TS2I\u548cI2TS\u8f6c\u6362\u8fc7\u7a0b\uff0c\u786e\u4fdd\u8fd1\u4e4e\u65e0\u635f\u7684\u8f6c\u6362\u3002\uff082\uff09\u5b9e\u65bd\u4e86\u57fa\u4e8e\u7406\u89e3\u7684\u751f\u6210\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6TSUMM-Suite\uff0c\u5b83\u5305\u542b\u4e86\u516d\u4e2a\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u7406\u89e3\u4efb\u52a1\u4ee5\u53ca\u4e24\u9879\u751f\u6210\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u4e0d\u4ec5\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u589e\u5f3a\u4e86\u6570\u503c\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "TimeOmni-VL\u4f5c\u4e3a\u9996\u4e2a\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u7406\u89e3\u4f5c\u4e3a\u663e\u5f0f\u63a7\u5236\u4fe1\u53f7\u4ee5\u5b9e\u73b0\u9ad8\u4fdd\u771f\u751f\u6210\u7684\u7cfb\u7edf\uff0c\u4e3a\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u8bbe\u7acb\u4e86\u65b0\u7684\u6807\u51c6\u3002"}}
{"id": "2602.17155", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17155", "abs": "https://arxiv.org/abs/2602.17155", "authors": ["Yicheng Lang", "Changsheng Wang", "Yihua Zhang", "Mingyi Hong", "Zheng Zhang", "Wotao Yin", "Sijia Liu"], "title": "Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization", "comment": null, "summary": "Zeroth-order (ZO) optimization provides a gradient-free alternative to first-order (FO) methods by estimating gradients via finite differences of function evaluations, and has recently emerged as a memory-efficient paradigm for fine-tuning large-scale models by avoiding backpropagation. However, ZO optimization has a fundamental tension between accuracy and query efficiency. In this work, we show that ZO optimization can be substantially improved by unifying two complementary principles: (i) a projection-based subspace view that reduces gradient estimation variance by exploiting the intrinsic low-rank structure of model updates, and (ii) Muon-style spectral optimization that applies gradient orthogonalization to extract informative spectral structure from noisy ZO gradients. These findings form a unified framework of subspace gradient orthogonalization, which we instantiate in a new method, ZO-Muon, admitting a natural interpretation as a low-rank Muon optimizer in the ZO setting. Extensive experiments on large language models (LLMs) and vision transformers (ViTs) demonstrate that ZO-Muon significantly accelerates convergence and achieves a win-win improvement in accuracy and query/runtime efficiency. Notably, compared to the popular MeZO baseline, ZO-Muon requires only 24.7% of the queries to reach the same SST-2 performance for LLM fine-tuning, and improves accuracy by 25.1% on ViT-B fine-tuning on CIFAR-100.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5ZO-Muon\uff0c\u901a\u8fc7\u7ed3\u5408\u6295\u5f71\u5b50\u7a7a\u95f4\u89c6\u56fe\u548cMuon\u98ce\u683c\u7684\u8c31\u4f18\u5316\u6765\u63d0\u9ad8\u96f6\u9636\u4f18\u5316\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8f6c\u6362\u5668\u4e0a\u7684\u6536\u655b\u901f\u5ea6\u660e\u663e\u52a0\u5feb\uff0c\u5e76\u4e14\u5728\u67e5\u8be2/\u8fd0\u884c\u65f6\u6548\u7387\u65b9\u9762\u4e5f\u6709\u6240\u6539\u5584\u3002", "motivation": "\u96f6\u9636\uff08ZO\uff09\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u68af\u5ea6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u51fd\u6570\u8bc4\u4f30\u7684\u6709\u9650\u5dee\u5206\u4f30\u8ba1\u68af\u5ea6\uff0c\u5728\u907f\u514d\u53cd\u5411\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4ece\u800c\u6210\u4e3a\u4e00\u79cd\u5185\u5b58\u9ad8\u6548\u7684\u8303\u5f0f\u3002\u7136\u800c\uff0cZO\u4f18\u5316\u5728\u51c6\u786e\u6027\u548c\u67e5\u8be2\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u7684\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5373\u5b50\u7a7a\u95f4\u68af\u5ea6\u6b63\u4ea4\u5316\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u4e24\u4e2a\u4e92\u8865\u539f\u5219\uff1a(i) \u5229\u7528\u6a21\u578b\u66f4\u65b0\u5185\u5728\u4f4e\u79e9\u7ed3\u6784\u51cf\u5c11\u68af\u5ea6\u4f30\u8ba1\u65b9\u5dee\u7684\u57fa\u4e8e\u6295\u5f71\u7684\u5b50\u7a7a\u95f4\u89c6\u56fe\uff1b(ii) \u5e94\u7528\u68af\u5ea6\u6b63\u4ea4\u5316\u7684Muon\u98ce\u683c\u8c31\u4f18\u5316\u4ece\u5608\u6742\u7684ZO\u68af\u5ea6\u4e2d\u63d0\u53d6\u4fe1\u606f\u4e30\u5bcc\u7684\u8c31\u7ed3\u6784\u3002\u8fd9\u4e9b\u53d1\u73b0\u5f62\u6210\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5ZO-Muon\uff0c\u5b83\u53ef\u88ab\u89e3\u91ca\u4e3aZO\u8bbe\u7f6e\u4e0b\u7684\u4f4e\u79e9Muon\u4f18\u5316\u5668\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u663e\u793a\uff0cZO-Muon\u663e\u8457\u52a0\u901f\u4e86\u6536\u655b\u8fc7\u7a0b\uff0c\u5e76\u5728\u7cbe\u5ea6\u4e0e\u67e5\u8be2/\u8fd0\u884c\u65f6\u95f4\u6548\u7387\u4e0a\u5b9e\u73b0\u4e86\u53cc\u8d62\u6539\u8fdb\u3002\u7279\u522b\u662f\uff0c\u4e0e\u6d41\u884c\u7684MeZO\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5bf9\u4e8eLLM\u5fae\u8c03\u8fbe\u5230\u76f8\u540c\u7684SST-2\u6027\u80fd\uff0cZO-Muon\u4ec5\u9700\u898124.7%\u7684\u67e5\u8be2\u91cf\uff0c\u5e76\u5728CIFAR-100\u4e0a\u7684ViT-B\u5fae\u8c03\u63d0\u9ad8\u4e8625.1%\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u878d\u5408\u4e24\u79cd\u4e92\u8865\u539f\u7406\u2014\u2014\u6295\u5f71\u5f0f\u5b50\u7a7a\u95f4\u89c6\u89d2\u53caMuon\u6837\u5f0f\u7684\u8c31\u4f18\u5316\u2014\u2014\u53ef\u4ee5\u5927\u5e45\u5ea6\u63d0\u5347ZO\u4f18\u5316\u7684\u8868\u73b0\u3002\u6240\u63d0\u51fa\u7684ZO-Muon\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u52a0\u901f\u6536\u655b\uff0c\u8fd8\u5728\u51c6\u786e\u7387\u4e0e\u67e5\u8be2/\u8fd0\u884c\u6548\u7387\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\u3002"}}
{"id": "2602.17171", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17171", "abs": "https://arxiv.org/abs/2602.17171", "authors": ["Ayush Goel", "Arjun Kohli", "Sarvagya Somvanshi"], "title": "In-Context Learning in Linear vs. Quadratic Attention Models: An Empirical Study on Regression Tasks", "comment": null, "summary": "Recent work has demonstrated that transformers and linear attention models can perform in-context learning (ICL) on simple function classes, such as linear regression. In this paper, we empirically study how these two attention mechanisms differ in their ICL behavior on the canonical linear-regression task of Garg et al. We evaluate learning quality (MSE), convergence, and generalization behavior of each architecture. We also analyze how increasing model depth affects ICL performance. Our results illustrate both the similarities and limitations of linear attention relative to quadratic attention in this setting.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86transformers\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u9488\u5bf9\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u65f6\u7684\u5b66\u4e60\u8d28\u91cf\u3001\u6536\u655b\u6027\u548c\u6cdb\u5316\u884c\u4e3a\uff0c\u5e76\u63a2\u8ba8\u4e86\u6a21\u578b\u6df1\u5ea6\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u5e76\u5bf9\u6bd4transformers\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5728\u5904\u7406\u7b80\u5355\u51fd\u6570\u7c7b\uff08\u5982\u7ebf\u6027\u56de\u5f52\uff09\u65f6\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u5dee\u5f02\u53ca\u5176\u7279\u6027\u3002", "method": "\u91c7\u7528Garg\u7b49\u4eba\u63d0\u51fa\u7684\u7ecf\u5178\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4f5c\u4e3a\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e24\u79cd\u6ce8\u610f\u673a\u5236\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u5b66\u4e60\u8d28\u91cf(MSE)\u3001\u6536\u655b\u6027\u53ca\u6cdb\u5316\u884c\u4e3a\uff0c\u5e76\u5206\u6790\u6a21\u578b\u6df1\u5ea6\u589e\u52a0\u5bf9\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u7ed9\u5b9a\u8bbe\u7f6e\u4e0b\uff0c\u867d\u7136\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u76f8\u5bf9\u4e8e\u4e8c\u6b21\u65b9\u6ce8\u610f\u529b\u6709\u5176\u76f8\u4f3c\u4e4b\u5904\uff0c\u4f46\u4e5f\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5728\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u4e00\u5b9a\u7684\u6709\u6548\u6027\uff0c\u4f46\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u4e8c\u6b21\u65b9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b83\u4ecd\u7136\u9762\u4e34\u7740\u4e00\u4e9b\u6311\u6218\u3002"}}
{"id": "2602.17206", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17206", "abs": "https://arxiv.org/abs/2602.17206", "authors": ["Ron Shapira Weber", "Oren Freifeld"], "title": "SoftDTW-CUDA-Torch: Memory-Efficient GPU-Accelerated Soft Dynamic Time Warping for PyTorch", "comment": "Technical Report", "summary": "We present softdtw-cuda-torch, an open-source PyTorch library for computing Soft Dynamic Time Warping (SoftDTW) on GPUs. Our implementation addresses three key limitations of existing GPU implementations of SoftDTW: a hard sequence-length cap of 1024, numerical instability in the backward pass for small smoothing parameters, and excessive GPU memory consumption from materializing pairwise distance tensors. We introduce (1) tiled anti-diagonal kernel execution that removes the sequence-length constraint, (2) a log-space back-ward pass that prevents floating-point overflow, and (3) a fused distance-computation mode that eliminates the O(BN M ) intermediate distance tensor, achieving up to 98% memory reduction compared to prior work. The library supports arbitrary sequence lengths, full PyTorch autograd integration, and Soft-DTW Barycenter computation. Code is available at https://github.com/BGU-CS-VIL/sdtw-cuda-torch.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3asoftdtw-cuda-torch\u7684\u5f00\u6e90PyTorch\u5e93\uff0c\u8be5\u5e93\u80fd\u591f\u5728GPU\u4e0a\u8ba1\u7b97Soft Dynamic Time Warping (SoftDTW)\uff0c\u5e76\u89e3\u51b3\u4e86\u73b0\u6709GPU\u5b9e\u73b0\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a\u5e8f\u5217\u957f\u5ea6\u4e0a\u9650\u4e3a1024\u3001\u5c0f\u5e73\u6ed1\u53c2\u6570\u4e0b\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u4ee5\u53ca\u6210\u5bf9\u8ddd\u79bb\u5f20\u91cf\u5bfc\u81f4\u7684\u8fc7\u9ad8\u7684GPU\u5185\u5b58\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7684GPU\u4e0a\u7684SoftDTW\u5b9e\u73b0\u5b58\u5728\u51e0\u4e2a\u95ee\u9898\uff1a\u53ea\u80fd\u5904\u7406\u957f\u5ea6\u4e0d\u8d85\u8fc71024\u7684\u5e8f\u5217\u3001\u5f53\u5e73\u6ed1\u53c2\u6570\u8f83\u5c0f\u65f6\u540e\u5411\u4f20\u9012\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u6570\u503c\u4e0d\u7a33\u5b9a\u3001\u4ee5\u53ca\u7531\u4e8e\u5b58\u50a8\u6210\u5bf9\u8ddd\u79bb\u77e9\u9635\u800c\u5bfc\u81f4\u7684GPU\u5185\u5b58\u4f7f\u7528\u8fc7\u9ad8\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f15\u5165(1)\u5206\u5757\u5bf9\u89d2\u7ebf\u6838\u6267\u884c\u6765\u6d88\u9664\u5e8f\u5217\u957f\u5ea6\u9650\u5236\uff0c(2)\u91c7\u7528\u5bf9\u6570\u7a7a\u95f4\u53cd\u5411\u4f20\u9012\u9632\u6b62\u6d6e\u70b9\u6ea2\u51fa\uff0c(3)\u878d\u5408\u7684\u8ddd\u79bb\u8ba1\u7b97\u6a21\u5f0f\u4ee5\u6d88\u9664O(BNM)\u4e2d\u95f4\u8ddd\u79bb\u5f20\u91cf\uff0c\u4ece\u800c\u8fbe\u5230\u9ad8\u8fbe98%\u7684\u5185\u5b58\u51cf\u5c11\u3002", "result": "\u5f00\u53d1\u4e86softdtw-cuda-torch\u5e93\uff0c\u5b83\u652f\u6301\u4efb\u610f\u957f\u5ea6\u7684\u5e8f\u5217\u3001\u5b8c\u5168\u96c6\u6210\u4e8ePyTorch autograd\uff0c\u5e76\u80fd\u8fdb\u884cSoft-DTW Barycenter\u8ba1\u7b97\u3002\u4e0e\u4e4b\u524d\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0c\u8be5\u5e93\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5185\u5b58\u8282\u7701\u3002", "conclusion": "softdtw-cuda-torch\u662f\u4e00\u4e2a\u6539\u8fdb\u7684PyTorch\u5e93\uff0c\u7528\u4e8e\u5728GPU\u4e0a\u9ad8\u6548\u5730\u6267\u884cSoftDTW\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u5b9e\u73b0\u4e2d\u9047\u5230\u7684\u4e3b\u8981\u6311\u6218\u3002"}}
{"id": "2602.17251", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17251", "abs": "https://arxiv.org/abs/2602.17251", "authors": ["Jingying Ma", "Feng Wu", "Yucheng Xing", "Qika Lin", "Tianyu Liu", "Chenyu Liu", "Ziyu Jia", "Mengling Feng"], "title": "Structured Prototype-Guided Adaptation for EEG Foundation Models", "comment": null, "summary": "Electroencephalography (EEG) foundation models (EFMs) have achieved strong performance under full fine-tuning but exhibit poor generalization when subject-level supervision is limited, a common constraint in real-world clinical settings. We show that this failure stems not merely from limited supervision, but from a structural mismatch between noisy, limited supervision and the highly plastic parameter space of EFMs. To address this challenge, we propose SCOPE, a Structured COnfidence-aware Prototype-guided adaptation framework for EFM fine-tuning. SCOPE follows a two-stage pipeline. In the first stage, we construct reliable external supervision by learning geometry-regularized task priors, constructing balanced class-level prototypes over the resulting embeddings, and producing confidence-aware pseudo-labels from their agreement to filter unreliable signals on unlabeled data. In the second stage, we introduce ProAdapter, which adapts frozen EEG foundation models via a lightweight adapter conditioned on the structured prototypes. Experiments across three EEG tasks and five foundation model backbones demonstrate that SCOPE consistently achieves strong performance and efficiency under label-limited cross-subject settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSCOPE\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6709\u9650\u6807\u7b7e\u7684\u8de8\u4e3b\u4f53\u8bbe\u7f6e\u4e0b\u5bf9EEG\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u901a\u8fc7\u6784\u5efa\u53ef\u9760\u7684\u5916\u90e8\u76d1\u7763\u548c\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6765\u89e3\u51b3\u7531\u4e8e\u6709\u9650\u76d1\u7763\u548c\u6a21\u578b\u53c2\u6570\u7a7a\u95f4\u4e4b\u95f4\u7684\u7ed3\u6784\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684EEG\u57fa\u7840\u6a21\u578b\uff08EFMs\uff09\u5728\u5168\u5fae\u8c03\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u9645\u4e34\u5e8a\u73af\u5883\u4e2d\u5e38\u89c1\u7684\u53d7\u8bd5\u8005\u7ea7\u522b\u76d1\u7763\u53d7\u9650\u65f6\uff0c\u5176\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e00\u95ee\u9898\u4e0d\u4ec5\u6e90\u4e8e\u76d1\u7763\u7684\u9650\u5236\uff0c\u8fd8\u56e0\u4e3aEFM\u7684\u9ad8\u5ea6\u53ef\u5851\u6027\u53c2\u6570\u7a7a\u95f4\u4e0e\u566a\u58f0\u5927\u3001\u6709\u9650\u7684\u76d1\u7763\u4e4b\u95f4\u5b58\u5728\u7ed3\u6784\u4e0a\u7684\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u4e86SCOPE\uff0c\u4e00\u79cd\u7ed3\u6784\u5316\u4fe1\u5fc3\u611f\u77e5\u539f\u578b\u5f15\u5bfc\u9002\u5e94\u6846\u67b6\uff0c\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u5b66\u4e60\u51e0\u4f55\u6b63\u5219\u5316\u7684\u4efb\u52a1\u5148\u9a8c\uff0c\u5728\u7ed3\u679c\u5d4c\u5165\u4e0a\u6784\u5efa\u5e73\u8861\u7684\u7c7b\u7ea7\u539f\u578b\uff0c\u5e76\u4ece\u5b83\u4eec\u7684\u4e00\u81f4\u6027\u4e2d\u751f\u6210\u4fe1\u5fc3\u611f\u77e5\u4f2a\u6807\u7b7e\u4ee5\u8fc7\u6ee4\u672a\u6807\u8bb0\u6570\u636e\u4e0a\u7684\u4e0d\u53ef\u9760\u4fe1\u53f7\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165ProAdapter\uff0c\u5b83\u901a\u8fc7\u57fa\u4e8e\u7ed3\u6784\u5316\u539f\u578b\u7684\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6765\u8c03\u6574\u51bb\u7ed3\u7684EEG\u57fa\u7840\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2aEEG\u4efb\u52a1\u548c\u4e94\u4e2a\u57fa\u7840\u6a21\u578b\u9aa8\u5e72\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCOPE\u5728\u6807\u7b7e\u6709\u9650\u7684\u8de8\u4e3b\u4f53\u73af\u5883\u4e0b\u59cb\u7ec8\u8868\u73b0\u51fa\u8272\u4e14\u9ad8\u6548\u3002", "conclusion": "SCOPE\u4e3aEEG\u57fa\u7840\u6a21\u578b\u5728\u6709\u9650\u76d1\u7763\u6761\u4ef6\u4e0b\u7684\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u4e2a\u4f53\u95f4\u7684\u8868\u73b0\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.17263", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17263", "abs": "https://arxiv.org/abs/2602.17263", "authors": ["Alexander Klemps", "Denis Ilia", "Pradeep Kr. Banerjee", "Ye Chen", "Henrik T\u00fcnnermann", "Nihat Ay"], "title": "Learning a Latent Pulse Shape Interface for Photoinjector Laser Systems", "comment": null, "summary": "Controlling the longitudinal laser pulse shape in photoinjectors of Free-Electron Lasers is a powerful lever for optimizing electron beam quality, but systematic exploration of the vast design space is limited by the cost of brute-force pulse propagation simulations. We present a generative modeling framework based on Wasserstein Autoencoders to learn a differentiable latent interface between pulse shaping and downstream beam dynamics. Our empirical findings show that the learned latent space is continuous and interpretable while maintaining high-fidelity reconstructions. Pulse families such as higher-order Gaussians trace coherent trajectories, while standardizing the temporal pulse lengths shows a latent organization correlated with pulse energy. Analysis via principal components and Gaussian Mixture Models reveals a well behaved latent geometry, enabling smooth transitions between distinct pulse types via linear interpolation. The model generalizes from simulated data to real experimental pulse measurements, accurately reconstructing pulses and embedding them consistently into the learned manifold. Overall, the approach reduces reliance on expensive pulse-propagation simulations and facilitates downstream beam dynamics simulation and analysis.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWasserstein\u81ea\u7f16\u7801\u5668\u7684\u751f\u6210\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u8109\u51b2\u6574\u5f62\u548c\u4e0b\u6e38\u675f\u6d41\u52a8\u529b\u5b66\u4e4b\u95f4\u7684\u53ef\u5fae\u6f5c\u7a7a\u95f4\u63a5\u53e3\u3002\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5bf9\u6602\u8d35\u7684\u8109\u51b2\u4f20\u64ad\u6a21\u62df\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u4fc3\u8fdb\u4e86\u675f\u6d41\u52a8\u529b\u5b66\u7684\u6a21\u62df\u548c\u5206\u6790\u3002", "motivation": "\u5728\u81ea\u7531\u7535\u5b50\u6fc0\u5149\u5668\u7684\u5149\u7535\u6ce8\u5165\u5668\u4e2d\u63a7\u5236\u7eb5\u5411\u6fc0\u5149\u8109\u51b2\u5f62\u72b6\u662f\u4f18\u5316\u7535\u5b50\u675f\u8d28\u91cf\u7684\u6709\u6548\u624b\u6bb5\uff0c\u4f46\u7531\u4e8e\u66b4\u529b\u8109\u51b2\u4f20\u64ad\u6a21\u62df\u7684\u6210\u672c\u9ad8\u6602\uff0c\u7cfb\u7edf\u5730\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u53d7\u5230\u4e86\u9650\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5bf9\u8fd9\u4e9b\u6210\u672c\u9ad8\u6602\u6a21\u62df\u7684\u4f9d\u8d56\u3002", "method": "\u91c7\u7528\u57fa\u4e8eWasserstein\u81ea\u7f16\u7801\u5668\u7684\u751f\u6210\u6a21\u578b\u6846\u67b6\uff0c\u5efa\u7acb\u8109\u51b2\u6574\u5f62\u4e0e\u4e0b\u6e38\u675f\u6d41\u52a8\u529b\u5b66\u4e4b\u95f4\u7684\u4e00\u4e2a\u53ef\u5fae\u5206\u6f5c\u53d8\u91cf\u63a5\u53e3\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u80fd\u591f\u5b66\u4e60\u5230\u4e00\u4e2a\u8fde\u7eed\u4e14\u53ef\u89e3\u91ca\u7684\u6f5c\u7a7a\u95f4\uff0c\u5e76\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u7684\u91cd\u5efa\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u5b66\u5230\u7684\u6f5c\u7a7a\u95f4\u662f\u8fde\u7eed\u4e14\u53ef\u89e3\u91ca\u7684\uff0c\u540c\u65f6\u80fd\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u91cd\u5efa\u3002\u4e0d\u540c\u7c7b\u578b\u7684\u8109\u51b2\u53ef\u4ee5\u901a\u8fc7\u7ebf\u6027\u63d2\u503c\u5e73\u6ed1\u8fc7\u6e21\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u4ece\u6a21\u62df\u6570\u636e\u63a8\u5e7f\u5230\u771f\u5b9e\u5b9e\u9a8c\u8109\u51b2\u6d4b\u91cf\uff0c\u51c6\u786e\u91cd\u6784\u8109\u51b2\u5e76\u5c06\u5b83\u4eec\u4e00\u81f4\u5730\u5d4c\u5165\u5230\u5df2\u5b66\u4e60\u7684\u6d41\u5f62\u4e2d\u3002", "conclusion": "\u672c\u7814\u7a76\u6240\u63d0\u51fa\u7684\u57fa\u4e8eWasserstein\u81ea\u7f16\u7801\u5668\u7684\u751f\u6210\u5efa\u6a21\u6846\u67b6\u4e3a\u8109\u51b2\u6574\u5f62\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u5b66\u4e60\u5de5\u5177\uff0c\u51cf\u5c11\u4e86\u5bf9\u6602\u8d35\u8109\u51b2\u4f20\u64ad\u6a21\u62df\u7684\u9700\u6c42\uff0c\u5e76\u6709\u52a9\u4e8e\u8fdb\u884c\u540e\u7eed\u7684\u675f\u6d41\u52a8\u529b\u5b66\u6a21\u62df\u548c\u5206\u6790\u5de5\u4f5c\u3002"}}
{"id": "2602.17270", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17270", "abs": "https://arxiv.org/abs/2602.17270", "authors": ["Jonathan Heek", "Emiel Hoogeboom", "Thomas Mensink", "Tim Salimans"], "title": "Unified Latents (UL): How to train your latents", "comment": null, "summary": "We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUnified Latents (UL)\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u5148\u9a8c\u8054\u5408\u6b63\u5219\u5316\u5b66\u4e60\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u7531\u6269\u6563\u6a21\u578b\u89e3\u7801\u3002\u8be5\u65b9\u6cd5\u5728ImageNet-512\u4e0a\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u7684FID\u5206\u65701.4\u548c\u9ad8\u8d28\u91cf\u7684\u91cd\u5efa\u8d28\u91cf\uff08PSNR\uff09\uff0c\u540c\u65f6\u6bd4\u57fa\u4e8eStable Diffusion\u6f5c\u53d8\u91cf\u8bad\u7ec3\u7684\u6a21\u578b\u9700\u8981\u66f4\u5c11\u7684\u8bad\u7ec3FLOPs\u3002\u6b64\u5916\uff0c\u5728Kinetics-600\u6570\u636e\u96c6\u4e0a\u8bbe\u7f6e\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7684FVD\u5f97\u52061.3\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6f5c\u5728\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u8868\u793a\u4e0d\u4ec5\u5177\u6709\u826f\u597d\u7684\u751f\u6210\u80fd\u529b\uff0c\u800c\u4e14\u8fd8\u80fd\u4fdd\u6301\u9ad8\u91cd\u5efa\u8d28\u91cf\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86Unified Latents (UL)\u6846\u67b6\uff0c\u5176\u4e2d\u6f5c\u5728\u8868\u793a\u53d7\u5230\u6269\u6563\u5148\u9a8c\u7684\u5171\u540c\u6b63\u5219\u5316\uff0c\u5e76\u901a\u8fc7\u6269\u6563\u6a21\u578b\u8fdb\u884c\u89e3\u7801\u3002\u7279\u522b\u5730\uff0c\u901a\u8fc7\u5c06\u7f16\u7801\u5668\u8f93\u51fa\u566a\u58f0\u4e0e\u5148\u9a8c\u7684\u6700\u5c0f\u566a\u58f0\u6c34\u5e73\u5173\u8054\u8d77\u6765\uff0c\u5f62\u6210\u4e00\u4e2a\u7b80\u6d01\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u4ece\u800c\u4e3a\u6f5c\u5728\u6bd4\u7279\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u81f4\u7684\u4e0a\u9650\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728ImageNet-512\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u7684FID\u5206\u65701.4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u91cd\u5efa\u8d28\u91cf(PSNR)\uff0c\u5e76\u4e14\u76f8\u6bd4\u4e8e\u57fa\u4e8eStable Diffusion\u6f5c\u53d8\u91cf\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6240\u9700\u8bad\u7ec3FLOPs\u66f4\u5c11\u3002\u53e6\u5916\uff0c\u5728Kinetics-600\u89c6\u9891\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f73\u7684FVD\u5206\u65701.3\u3002", "conclusion": "Unified Latents (UL)\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u5b66\u4e60\u6f5c\u5728\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u56fe\u50cf\u53ca\u89c6\u9891\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2602.17276", "categories": ["cs.LG", "math.CO"], "pdf": "https://arxiv.org/pdf/2602.17276", "abs": "https://arxiv.org/abs/2602.17276", "authors": ["Ivan Damnjanovi\u0107", "Uro\u0161 Milivojevi\u0107", "Irena \u0110or\u0111evi\u0107", "Dragan Stevanovi\u0107"], "title": "RLGT: A reinforcement learning framework for extremal graph theory", "comment": null, "summary": "Reinforcement learning (RL) is a subfield of machine learning that focuses on developing models that can autonomously learn optimal decision-making strategies over time. In a recent pioneering paper, Wagner demonstrated how the Deep Cross-Entropy RL method can be applied to tackle various problems from extremal graph theory by reformulating them as combinatorial optimization problems. Subsequently, many researchers became interested in refining and extending the framework introduced by Wagner, thereby creating various RL environments specialized for graph theory. Moreover, a number of problems from extremal graph theory were solved through the use of RL. In particular, several inequalities concerning the Laplacian spectral radius of graphs were refuted, new lower bounds were obtained for certain Ramsey numbers, and contributions were made to the Tur\u00e1n-type extremal problem in which the forbidden structures are cycles of length three and four. Here, we present Reinforcement Learning for Graph Theory (RLGT), a novel RL framework that systematizes the previous work and provides support for both undirected and directed graphs, with or without loops, and with an arbitrary number of edge colors. The framework efficiently represents graphs and aims to facilitate future RL-based research in extremal graph theory through optimized computational performance and a clean and modular design.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u56fe\u8bba\u7684\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6RLGT\uff0c\u8be5\u6846\u67b6\u7cfb\u7edf\u5316\u4e86\u5148\u524d\u7684\u5de5\u4f5c\uff0c\u5e76\u652f\u6301\u65e0\u5411\u548c\u6709\u5411\u56fe\uff0c\u65e0\u8bba\u662f\u5426\u6709\u73af\u4ee5\u53ca\u5177\u6709\u4efb\u610f\u6570\u91cf\u7684\u8fb9\u989c\u8272\u3002", "motivation": "\u53d7\u5230Wagner\u63d0\u51fa\u7684\u6df1\u5ea6\u4ea4\u53c9\u71b5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5e94\u7528\u4e8e\u6781\u503c\u56fe\u8bba\u95ee\u9898\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u6539\u8fdb\u548c\u6269\u5c55\u8fd9\u4e00\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u66f4\u591a\u56fe\u8bba\u4e2d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRLGT\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5bf9\u4ee5\u524d\u7684\u5de5\u4f5c\u8fdb\u884c\u4e86\u7cfb\u7edf\u5316\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u65e0\u5411\u56fe\u548c\u6709\u5411\u56fe\u3001\u5e26\u6216\u4e0d\u5e26\u73af\u7684\u60c5\u51b5\uff0c\u540c\u65f6\u652f\u6301\u591a\u8272\u8fb9\u3002", "result": "RLGT\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u56fe\u8868\u793a\u65b9\u5f0f\uff0c\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u7684\u8ba1\u7b97\u6027\u80fd\u548c\u6e05\u6670\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\u4fc3\u8fdb\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6781\u503c\u56fe\u8bba\u672a\u6765\u7684\u7814\u7a76\u3002", "conclusion": "RLGT\u6846\u67b6\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u5de5\u5177\uff0c\u5b83\u4e3a\u56fe\u8bba\u7279\u522b\u662f\u6781\u503c\u56fe\u8bba\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u652f\u6301\uff0c\u6709\u671b\u5728\u672a\u6765\u7684\u7814\u7a76\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2602.17284", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17284", "abs": "https://arxiv.org/abs/2602.17284", "authors": ["Vitaly Feldman", "Moshe Shenfeld"], "title": "Efficient privacy loss accounting for subsampling and random allocation", "comment": null, "summary": "We consider the privacy amplification properties of a sampling scheme in which a user's data is used in $k$ steps chosen randomly and uniformly from a sequence (or set) of $t$ steps. This sampling scheme has been recently applied in the context of differentially private optimization (Chua et al., 2024a; Choquette-Choo et al., 2025) and communication-efficient high-dimensional private aggregation (Asi et al., 2025), where it was shown to have utility advantages over the standard Poisson sampling. Theoretical analyses of this sampling scheme (Feldman & Shenfeld, 2025; Dong et al., 2025) lead to bounds that are close to those of Poisson sampling, yet still have two significant shortcomings. First, in many practical settings, the resulting privacy parameters are not tight due to the approximation steps in the analysis. Second, the computed parameters are either the hockey stick or Renyi divergence, both of which introduce overheads when used in privacy loss accounting.\n  In this work, we demonstrate that the privacy loss distribution (PLD) of random allocation applied to any differentially private algorithm can be computed efficiently. When applied to the Gaussian mechanism, our results demonstrate that the privacy-utility trade-off for random allocation is at least as good as that of Poisson subsampling. In particular, random allocation is better suited for training via DP-SGD. To support these computations, our work develops new tools for general privacy loss accounting based on a notion of PLD realization. This notion allows us to extend accurate privacy loss accounting to subsampling which previously required manual noise-mechanism-specific analysis.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u968f\u673a\u5206\u914d\u91c7\u6837\u65b9\u6848\u7684\u9690\u79c1\u653e\u5927\u7279\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u4e2d\u7684\u9690\u79c1\u635f\u5931\u5206\u5e03\u53ef\u4ee5\u88ab\u6709\u6548\u8ba1\u7b97\u3002\u7279\u522b\u5730\uff0c\u5f53\u5e94\u7528\u4e8e\u9ad8\u65af\u673a\u5236\u65f6\uff0c\u968f\u673a\u5206\u914d\u81f3\u5c11\u4e0e\u6cca\u677e\u5b50\u91c7\u6837\u4e00\u6837\u597d\uff0c\u5e76\u4e14\u66f4\u9002\u5408\u4e8e\u901a\u8fc7DP-SGD\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u65b0\u7684\u5de5\u5177\u6765\u652f\u6301\u57fa\u4e8e\u9690\u79c1\u635f\u5931\u5206\u5e03\u5b9e\u73b0\u6982\u5ff5\u7684\u4e00\u822c\u9690\u79c1\u635f\u5931\u6838\u7b97\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5e94\u7528\u7684\u4e00\u79cd\u7279\u5b9a\u91c7\u6837\u65b9\u6848\u2014\u2014\u4ece\u4e00\u7cfb\u5217\u6b65\u9aa4\u4e2d\u5747\u5300\u968f\u673a\u9009\u62e9k\u6b65\u4f7f\u7528\u7528\u6237\u7684\u8d44\u6599\u6570\u636e\uff0c\u76f8\u6bd4\u6807\u51c6\u6cca\u677e\u91c7\u6837\u5177\u6709\u5b9e\u7528\u6027\u4f18\u52bf\u3002\u7136\u800c\uff0c\u5bf9\u8be5\u65b9\u6848\u7684\u7406\u8bba\u5206\u6790\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a\u9996\u5148\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u5206\u6790\u8fc7\u7a0b\u4e2d\u7684\u8fd1\u4f3c\u5904\u7406\u5bfc\u81f4\u9690\u79c1\u53c2\u6570\u4e0d\u591f\u7cbe\u786e\uff1b\u5176\u6b21\uff0c\u5f53\u524d\u8ba1\u7b97\u51fa\u7684\u9690\u79c1\u53c2\u6570\uff08\u5982\u66f2\u68cd\u7403\u68d2\u6216R\u00e9nyi\u6563\u5ea6\uff09\u5728\u7528\u4e8e\u9690\u79c1\u635f\u5931\u6838\u7b97\u65f6\u5f15\u5165\u4e86\u989d\u5916\u5f00\u9500\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u51c6\u786e\u3001\u9ad8\u6548\u7684\u9690\u79c1\u635f\u5931\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u8ba1\u7b97\u968f\u673a\u5206\u914d\u7ed9\u4efb\u610f\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u5e26\u6765\u7684\u9690\u79c1\u635f\u5931\u5206\u5e03\u7684\u65b9\u6cd5\u3002\u7279\u522b\u662f\u9488\u5bf9\u9ad8\u65af\u673a\u5236\uff0c\u5c55\u793a\u4e86\u968f\u673a\u5206\u914d\u5728\u9690\u79c1-\u6548\u7528\u6743\u8861\u65b9\u9762\u81f3\u5c11\u7b49\u540c\u4e8e\u751a\u81f3\u4f18\u4e8e\u6cca\u677e\u5b50\u91c7\u6837\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4f7f\u7528DP-SGD\u8fdb\u884c\u8bad\u7ec3\u66f4\u52a0\u5408\u9002\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u5f00\u53d1\u4e86\u57fa\u4e8e\u9690\u79c1\u635f\u5931\u5206\u5e03\u5b9e\u73b0\u7684\u65b0\u5de5\u5177\uff0c\u4ee5\u6539\u8fdb\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u9690\u79c1\u635f\u5931\u6838\u7b97\u6d41\u7a0b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u968f\u673a\u5206\u914d\u7684\u9690\u79c1\u635f\u5931\u5206\u5e03\u80fd\u591f\u88ab\u6709\u6548\u5730\u8ba1\u7b97\u51fa\u6765\uff1b\u5f53\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u9ad8\u65af\u673a\u5236\u65f6\uff0c\u5b83\u5c55\u73b0\u51fa\u4e0e\u6cca\u677e\u5b50\u91c7\u6837\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u9690\u79c1-\u6548\u7528\u5e73\u8861\uff1b\u65b0\u63d0\u51fa\u7684PLD\u5b9e\u73b0\u6982\u5ff5\u5141\u8bb8\u5c06\u7cbe\u786e\u7684\u9690\u79c1\u635f\u5931\u6838\u7b97\u6269\u5c55\u5230\u4ee5\u524d\u9700\u8981\u624b\u52a8\u8fdb\u884c\u566a\u58f0\u673a\u5236\u7279\u5f02\u6027\u5206\u6790\u7684\u5b50\u91c7\u6837\u60c5\u5f62\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u6709\u6548\u8ba1\u7b97\u968f\u673a\u5206\u914d\u9690\u79c1\u635f\u5931\u5206\u5e03\u7684\u65b9\u6cd5\u53ca\u5176\u5728\u9ad8\u65af\u673a\u5236\u4e2d\u7684\u5e94\u7528\uff0c\u4e3a\u5dee\u5206\u9690\u79c1\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002\u7ed3\u679c\u8868\u660e\uff0c\u968f\u673a\u5206\u914d\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u63a5\u8fd1\u751a\u81f3\u4f18\u4e8e\u73b0\u6709\u7684\u6cca\u677e\u91c7\u6837\u65b9\u6cd5\uff0c\u800c\u4e14\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u9690\u79c1\u635f\u5931\u6838\u7b97\u5de5\u5177\uff0c\u4f7f\u5f97\u6574\u4e2a\u8fc7\u7a0b\u53d8\u5f97\u66f4\u52a0\u9ad8\u6548\u548c\u901a\u7528\u3002"}}
{"id": "2602.17330", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17330", "abs": "https://arxiv.org/abs/2602.17330", "authors": ["Rong Fu", "Zijian Zhang", "Wenxin Zhang", "Kun Liu", "Jiekai Wu", "Xianda Li", "Simon Fong"], "title": "SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework", "comment": "27 pages, 9 figures", "summary": "Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that addresses these challenges by combining antigen-aware, near-subquadratic retrieval with GPU-accelerated affinity kernels, learned multimodal fusion, and fairness-constrained clustering. The system employs compact MinHash prefiltering to sharply reduce candidate comparisons, a differentiable gating module that adaptively weights complementary alignment and embedding channels on a per-pair basis, and an automated calibration routine that enforces proportional representation of rare antigen-specific subgroups. On large viral and tumor repertoires SubQuad achieves measured gains in throughput and peak memory usage while preserving or improving recall@k, cluster purity, and subgroup equity. By co-designing indexing, similarity fusion, and equity-aware objectives, SubQuad offers a scalable, bias-aware platform for repertoire mining and downstream translational tasks such as vaccine target prioritization and biomarker discovery.", "AI": {"tldr": "SubQuad\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u7ba1\u9053\uff0c\u5b83\u7ed3\u5408\u4e86\u6297\u539f\u611f\u77e5\u3001\u8fd1\u4e9a\u4e8c\u6b21\u68c0\u7d22\u4e0eGPU\u52a0\u901f\u4eb2\u548c\u529b\u5185\u6838\u3001\u5b66\u4e60\u591a\u6a21\u6001\u878d\u5408\u4ee5\u53ca\u516c\u5e73\u7ea6\u675f\u805a\u7c7b\uff0c\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6bd4\u8f83\u5206\u6790\u9002\u5e94\u6027\u514d\u75ab\u5e93\u65f6\u9047\u5230\u7684\u6210\u672c\u95ee\u9898\u548c\u6570\u636e\u96c6\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u5728\u4eba\u7fa4\u89c4\u6a21\u4e0a\u8fdb\u884c\u9002\u5e94\u6027\u514d\u75ab\u5e93\u7684\u6bd4\u8f83\u5206\u6790\u53d7\u5230\u4e24\u4e2a\u5b9e\u9645\u74f6\u9888\u7684\u963b\u788d\uff1a\u51e0\u4e4e\u4e8c\u6b21\u65b9\u7684\u6210\u5bf9\u4eb2\u548c\u529b\u8bc4\u4f30\u6210\u672c\u4ee5\u53ca\u6570\u636e\u96c6\u5931\u8861\uff0c\u8fd9\u63a9\u76d6\u4e86\u4e34\u5e8a\u4e0a\u91cd\u8981\u7684\u5c11\u6570\u514b\u9686\u578b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86SubQuad\u7cfb\u7edf\u3002", "method": "SubQuad\u901a\u8fc7\u7ed3\u5408\u6297\u539f\u611f\u77e5\u7684\u8fd1\u4e9a\u4e8c\u6b21\u68c0\u7d22\u3001GPU\u52a0\u901f\u7684\u4eb2\u548c\u529b\u5185\u6838\u3001\u5b66\u4e60\u591a\u6a21\u6001\u878d\u5408\u4ee5\u53ca\u516c\u5e73\u7ea6\u675f\u805a\u7c7b\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u8be5\u7cfb\u7edf\u4f7f\u7528\u7d27\u51d1\u7684MinHash\u9884\u8fc7\u6ee4\u4ee5\u663e\u8457\u51cf\u5c11\u5019\u9009\u6bd4\u8f83\u6b21\u6570\uff0c\u4e00\u4e2a\u53ef\u5fae\u5206\u95e8\u63a7\u6a21\u5757\u6839\u636e\u6bcf\u5bf9\u57fa\u7840\u81ea\u9002\u5e94\u5730\u52a0\u6743\u4e92\u8865\u5bf9\u9f50\u548c\u5d4c\u5165\u901a\u9053\uff0c\u5e76\u4e14\u6709\u4e00\u4e2a\u81ea\u52a8\u5316\u6821\u51c6\u4f8b\u7a0b\u6765\u786e\u4fdd\u7a00\u6709\u6297\u539f\u7279\u5f02\u6027\u5b50\u7fa4\u7684\u6bd4\u4f8b\u4ee3\u8868\u3002", "result": "\u5bf9\u4e8e\u5927\u578b\u75c5\u6bd2\u548c\u80bf\u7624\u5e93\uff0cSubQuad\u5728\u541e\u5410\u91cf\u548c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u5b9e\u73b0\u4e86\u6d4b\u91cf\u589e\u76ca\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u53ec\u56de\u7387@k\u3001\u7c07\u7eaf\u5ea6\u548c\u5b50\u7fa4\u516c\u5e73\u6027\u3002", "conclusion": "\u901a\u8fc7\u5171\u540c\u8bbe\u8ba1\u7d22\u5f15\u3001\u76f8\u4f3c\u6027\u878d\u5408\u548c\u516c\u5e73\u610f\u8bc6\u76ee\u6807\uff0cSubQuad\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u504f\u89c1\u611f\u77e5\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u5e93\u6316\u6398\u53ca\u4e0b\u6e38\u8f6c\u5316\u4efb\u52a1\uff0c\u4f8b\u5982\u75ab\u82d7\u9776\u70b9\u4f18\u5148\u7ea7\u6392\u5e8f\u548c\u751f\u7269\u6807\u5fd7\u7269\u53d1\u73b0\u3002"}}
{"id": "2602.17363", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17363", "abs": "https://arxiv.org/abs/2602.17363", "authors": ["Gabriel Mongaras", "Eric C. Larson"], "title": "2Mamba2Furious: Linear in Complexity, Competitive in Accuracy", "comment": null, "summary": "Linear attention transformers have become a strong alternative to softmax attention due to their efficiency. However, linear attention tends to be less expressive and results in reduced accuracy compared to softmax attention. To bridge the accuracy gap between softmax attention and linear attention, we manipulate Mamba-2, a very strong linear attention variant. We first simplify Mamba-2 down to its most fundamental and important components, evaluating which specific choices make it most accurate. From this simplified Mamba variant (Mamba-2S), we improve the A-mask and increase the order of the hidden state, resulting in a method, which we call 2Mamba, that is nearly as accurate as softmax attention, yet much more memory efficient for long context lengths. We also investigate elements to Mamba-2 that help surpass softmax attention accuracy. Code is provided for all our experiments", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7b80\u5316\u5e76\u6539\u8fdbMamba-2\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u51fa\u4e862Mamba\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u63a5\u8fd1Softmax\u6ce8\u610f\u529b\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u7684\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u7ebf\u6027\u6ce8\u610f\u529b\u8f6c\u6362\u5668\u56e0\u5176\u9ad8\u6548\u6027\u6210\u4e3aSoftmax\u6ce8\u610f\u529b\u7684\u4e00\u4e2a\u5f3a\u6709\u529b\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u8868\u8fbe\u529b\u8f83\u5f31\u4e14\u51c6\u786e\u6027\u8f83\u4f4e\u3002\u4e3a\u7f29\u5c0fSoftmax\u6ce8\u610f\u529b\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b\u4e4b\u95f4\u7684\u51c6\u786e\u6027\u5dee\u8ddd\uff0c\u7814\u7a76\u4eba\u5458\u5bf9\u4e00\u79cd\u975e\u5e38\u5f3a\u5927\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u53d8\u4f53Mamba-2\u8fdb\u884c\u4e86\u8c03\u6574\u3002", "method": "\u9996\u5148\u5c06Mamba-2\u7b80\u5316\u4e3a\u5176\u6700\u57fa\u672c\u548c\u6700\u91cd\u8981\u7684\u7ec4\u4ef6\uff0c\u5e76\u8bc4\u4f30\u54ea\u4e9b\u5177\u4f53\u9009\u62e9\u4f7f\u5176\u6700\u4e3a\u51c6\u786e\uff1b\u57fa\u4e8e\u7b80\u5316\u7684Mamba-2S\uff0c\u8fdb\u4e00\u6b65\u6539\u8fdbA-mask\u5e76\u589e\u52a0\u9690\u85cf\u72b6\u6001\u7684\u9636\u6570\uff0c\u5f00\u53d1\u51fa\u79f0\u4e3a2Mamba\u7684\u65b9\u6cd5\u3002", "result": "\u5f00\u53d1\u51fa\u76842Mamba\u65b9\u6cd5\u51e0\u4e4e\u4e0eSoftmax\u6ce8\u610f\u529b\u4e00\u6837\u51c6\u786e\uff0c\u4f46\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u5185\u5b58\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u4f7fMamba-2\u8d85\u8d8aSoftmax\u6ce8\u610f\u529b\u51c6\u786e\u6027\u7684\u56e0\u7d20\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5316Mamba-2\u5e76\u5bf9\u5176\u5173\u952e\u7ec4\u4ef6\u8fdb\u884c\u6539\u8fdb\uff0c\u6210\u529f\u5730\u5f00\u53d1\u51fa\u4e86\u65e2\u9ad8\u6548\u53c8\u9ad8\u51c6\u786e\u5ea6\u7684\u65b0\u65b9\u6cd52Mamba\uff0c\u5b83\u5728\u957f\u5e8f\u5217\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.17364", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17364", "abs": "https://arxiv.org/abs/2602.17364", "authors": ["Justyna Andrys-Olek", "Paulina Tworek", "Luca Gherardini", "Mark W. Ruddock", "Mary Jo Kurt", "Peter Fitzgerald", "Jose Sousa"], "title": "A feature-stable and explainable machine learning framework for trustworthy decision-making under incomplete clinical data", "comment": null, "summary": "Machine learning models are increasingly applied to biomedical data, yet their adoption in high stakes domains remains limited by poor robustness, limited interpretability, and instability of learned features under realistic data perturbations, such as missingness. In particular, models that achieve high predictive performance may still fail to inspire trust if their key features fluctuate when data completeness changes, undermining reproducibility and downstream decision-making. Here, we present CACTUS (Comprehensive Abstraction and Classification Tool for Uncovering Structures), an explainable machine learning framework explicitly designed to address these challenges in small, heterogeneous, and incomplete clinical datasets. CACTUS integrates feature abstraction, interpretable classification, and systematic feature stability analysis to quantify how consistently informative features are preserved as data quality degrades. Using a real-world haematuria cohort comprising 568 patients evaluated for bladder cancer, we benchmark CACTUS against widely used machine learning approaches, including random forests and gradient boosting methods, under controlled levels of randomly introduced missing data. We demonstrate that CACTUS achieves competitive or superior predictive performance while maintaining markedly higher stability of top-ranked features as missingness increases, including in sex-stratified analyses. Our results show that feature stability provides information complementary to conventional performance metrics and is essential for assessing the trustworthiness of machine learning models applied to biomedical data. By explicitly quantifying robustness to missing data and prioritising interpretable, stable features, CACTUS offers a generalizable framework for trustworthy data-driven decision support.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCACTUS\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5c0f\u89c4\u6a21\u3001\u5f02\u8d28\u6027\u53ca\u4e0d\u5b8c\u6574\u4e34\u5e8a\u6570\u636e\u96c6\u4e2d\u7684\u9c81\u68d2\u6027\u5dee\u3001\u89e3\u91ca\u6027\u6709\u9650\u548c\u7279\u5f81\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002\u901a\u8fc7\u4e0e\u968f\u673a\u68ee\u6797\u7b49\u65b9\u6cd5\u6bd4\u8f83\uff0c\u5728\u5b9e\u9645\u8840\u5c3f\u961f\u5217\u4e2d\uff0cCACTUS\u5c55\u793a\u4e86\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u6c34\u5e73\u7684\u7279\u5f81\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5728\u751f\u7269\u533b\u5b66\u6570\u636e\u4e0a\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7531\u4e8e\u9c81\u68d2\u6027\u5dee\u3001\u89e3\u91ca\u6027\u6709\u9650\u4ee5\u53ca\u5728\u771f\u5b9e\u6570\u636e\u6270\u52a8\u4e0b\uff08\u5982\u7f3a\u5931\u503c\uff09\u7279\u5f81\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5176\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e94\u7528\u4ecd\u53d7\u5230\u9650\u5236\u3002\u7279\u522b\u662f\u5f53\u5173\u952e\u7279\u5f81\u968f\u6570\u636e\u5b8c\u6574\u6027\u53d8\u5316\u800c\u6ce2\u52a8\u65f6\uff0c\u5373\u4f7f\u6a21\u578b\u5177\u6709\u9ad8\u9884\u6d4b\u6027\u80fd\u4e5f\u53ef\u80fd\u65e0\u6cd5\u8d62\u5f97\u4fe1\u4efb\uff0c\u4ece\u800c\u5f71\u54cd\u53ef\u91cd\u590d\u6027\u548c\u4e0b\u6e38\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCACTUS (Comprehensive Abstraction and Classification Tool for Uncovering Structures) \u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u7279\u5f81\u62bd\u8c61\u3001\u53ef\u89e3\u91ca\u5206\u7c7b\u548c\u7cfb\u7edf\u5316\u7684\u7279\u5f81\u7a33\u5b9a\u6027\u5206\u6790\uff0c\u7528\u4e8e\u91cf\u5316\u968f\u7740\u6570\u636e\u8d28\u91cf\u4e0b\u964d\u65f6\u6301\u7eed\u4fe1\u606f\u7279\u5f81\u7684\u4e00\u81f4\u6027\u4fdd\u5b58\u60c5\u51b5\u3002", "result": "\u5728\u5305\u542b568\u540d\u63a5\u53d7\u8180\u80f1\u764c\u8bc4\u4f30\u60a3\u8005\u7684\u73b0\u5b9e\u4e16\u754c\u8840\u5c3f\u961f\u5217\u4e2d\uff0c\u5c06CACTUS\u4e0e\u5305\u62ec\u968f\u673a\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\u65b9\u6cd5\u5728\u5185\u7684\u5e7f\u6cdb\u4f7f\u7528\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5728\u63a7\u5236\u5f15\u5165\u7684\u968f\u673a\u7f3a\u5931\u6570\u636e\u6c34\u5e73\u4e0b\u8fdb\u884c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u968f\u7740\u7f3a\u5931\u7a0b\u5ea6\u589e\u52a0\uff0cCACTUS\u4e0d\u4ec5\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u7684\u6216\u66f4\u4f18\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u9876\u7ea7\u7279\u5f81\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7279\u5f81\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u4f20\u7edf\u6027\u80fd\u6307\u6807\u4e4b\u5916\u7684\u4fe1\u606f\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8bc4\u4f30\u5e94\u7528\u4e8e\u751f\u7269\u533b\u5b66\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u4fe1\u4efb\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u660e\u786e\u91cf\u5316\u5bf9\u7f3a\u5931\u6570\u636e\u7684\u9c81\u68d2\u6027\u5e76\u4f18\u5148\u8003\u8651\u53ef\u89e3\u91ca\u3001\u7a33\u5b9a\u7684\u7279\u5f81\uff0cCACTUS\u4e3a\u53ef\u4fe1\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2602.17477", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17477", "abs": "https://arxiv.org/abs/2602.17477", "authors": ["Gurjeet Sangra Singh", "Frantzeska Lavda", "Giangiacomo Mercatali", "Alexandros Kalousis"], "title": "Variational Grey-Box Dynamics Matching", "comment": "AISTATS 2026. Code is available at https://github.com/DMML-Geneva/VGB-DM", "summary": "Deep generative models such as flow matching and diffusion models have shown great potential in learning complex distributions and dynamical systems, but often act as black-boxes, neglecting underlying physics. In contrast, physics-based simulation models described by ODEs/PDEs remain interpretable, but may have missing or unknown terms, unable to fully describe real-world observations. We bridge this gap with a novel grey-box method that integrates incomplete physics models directly into generative models. Our approach learns dynamics from observational trajectories alone, without ground-truth physics parameters, in a simulation-free manner that avoids scalability and stability issues of Neural ODEs. The core of our method lies in modelling a structured variational distribution within the flow matching framework, by using two latent encodings: one to model the missing stochasticity and multi-modal velocity, and a second to encode physics parameters as a latent variable with a physics-informed prior. Furthermore, we present an adaptation of the framework to handle second-order dynamics. Our experiments on representative ODE/PDE problems show that our method performs on par with or superior to fully data-driven approaches and previous grey-box baselines, while preserving the interpretability of the physics model. Our code is available at https://github.com/DMML-Geneva/VGB-DM.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7070\u76d2\u65b9\u6cd5\uff0c\u5c06\u4e0d\u5b8c\u5168\u7684\u7269\u7406\u6a21\u578b\u76f4\u63a5\u6574\u5408\u5230\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u4ec5\u4ece\u89c2\u6d4b\u8f68\u8ff9\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u5e76\u907f\u514d\u4e86\u795e\u7ecfODE\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u7269\u7406\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u8868\u73b0\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u548c\u5148\u524d\u7684\u7070\u76d2\u57fa\u7ebf\u3002", "motivation": "\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5982\u6d41\u5339\u914d\u548c\u6269\u6563\u6a21\u578b\u5728\u5b66\u4e60\u590d\u6742\u5206\u5e03\u548c\u52a8\u6001\u7cfb\u7edf\u65b9\u9762\u8868\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u901a\u5e38\u4f5c\u4e3a\u9ed1\u76d2\u64cd\u4f5c\uff0c\u5ffd\u89c6\u4e86\u6f5c\u5728\u7684\u7269\u7406\u7279\u6027\u3002\u76f8\u53cd\u5730\uff0c\u57fa\u4e8eODE/PDE\u63cf\u8ff0\u7684\u7269\u7406\u6a21\u62df\u6a21\u578b\u867d\u7136\u53ef\u89e3\u91ca\uff0c\u4f46\u7531\u4e8e\u7f3a\u5c11\u6216\u672a\u77e5\u7684\u9879\u800c\u65e0\u6cd5\u5b8c\u5168\u63cf\u8ff0\u73b0\u5b9e\u4e16\u754c\u7684\u73b0\u8c61\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u4e0d\u5b8c\u5168\u7269\u7406\u6a21\u578b\u4e0e\u751f\u6210\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u4ece\u800c\u540c\u65f6\u4fdd\u7559\u7269\u7406\u4e0a\u7684\u53ef\u89e3\u91ca\u6027\u5e76\u589e\u5f3a\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7070\u76d2\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u5728\u65e0\u9700\u771f\u5b9e\u7269\u7406\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u4ece\u89c2\u6d4b\u8f68\u8ff9\u4e2d\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u4e14\u6574\u4e2a\u8fc7\u7a0b\u65e0\u9700\u8fdb\u884c\u6a21\u62df\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\u5229\u7528\u6d41\u5339\u914d\u6846\u67b6\u5185\u7684\u4e00\u79cd\u7ed3\u6784\u5316\u53d8\u5206\u5206\u5e03\u5efa\u6a21\u65b9\u5f0f\uff0c\u901a\u8fc7\u4e24\u4e2a\u6f5c\u7f16\u7801\u6765\u5b9e\u73b0\uff1a\u4e00\u4e2a\u7528\u4e8e\u5efa\u6a21\u7f3a\u5931\u7684\u968f\u673a\u6027\u548c\u591a\u6a21\u6001\u901f\u5ea6\uff0c\u53e6\u4e00\u4e2a\u5219\u4ee5\u7269\u7406\u4fe1\u606f\u5148\u9a8c\u7684\u65b9\u5f0f\u7f16\u7801\u7269\u7406\u53c2\u6570\u4e3a\u6f5c\u53d8\u91cf\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u9002\u5e94\u5904\u7406\u4e8c\u9636\u52a8\u529b\u5b66\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4ee3\u8868\u6027\u7684ODE/PDE\u95ee\u9898\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u7684\u8868\u73b0\u4e0e\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u53ca\u4e4b\u524d\u7684\u7070\u76d2\u57fa\u51c6\u76f8\u6bd4\uff0c\u8981\u4e48\u76f8\u5f53\u8981\u4e48\u66f4\u4f18\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7269\u7406\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u7070\u76d2\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u5c06\u4e0d\u5b8c\u6574\u7684\u7269\u7406\u77e5\u8bc6\u878d\u5165\u5230\u4e86\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u4e4b\u4e2d\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u4e8e\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u7406\u89e3\u80fd\u529b\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u8fd9\u4e3a\u672a\u6765\u7ed3\u5408\u7269\u7406\u539f\u7406\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.17486", "categories": ["cs.LG", "cs.GT", "cs.MA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.17486", "abs": "https://arxiv.org/abs/2602.17486", "authors": ["Yuma Fujimoto", "Kenshi Abe", "Kaito Ariu"], "title": "Linear Convergence in Games with Delayed Feedback via Extra Prediction", "comment": "9 pages, 3 figures (main); 5 pages, 1 figure (appendix)", "summary": "Feedback delays are inevitable in real-world multi-agent learning. They are known to severely degrade performance, and the convergence rate under delayed feedback is still unclear, even for bilinear games. This paper derives the rate of linear convergence of Weighted Optimistic Gradient Descent-Ascent (WOGDA), which predicts future rewards with extra optimism, in unconstrained bilinear games. To analyze the algorithm, we interpret it as an approximation of the Extra Proximal Point (EPP), which is updated based on farther future rewards than the classical Proximal Point (PP). Our theorems show that standard optimism (predicting the next-step reward) achieves linear convergence to the equilibrium at a rate $\\exp(-\u0398(t/m^{5}))$ after $t$ iterations for delay $m$. Moreover, employing extra optimism (predicting farther future reward) tolerates a larger step size and significantly accelerates the rate to $\\exp(-\u0398(t/(m^{2}\\log m)))$. Our experiments also show accelerated convergence driven by the extra optimism and are qualitatively consistent with our theorems. In summary, this paper validates that extra optimism is a promising countermeasure against performance degradation caused by feedback delays.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5728\u65e0\u7ea6\u675f\u53cc\u7ebf\u6027\u535a\u5f08\u4e2d\u5f15\u5165\u52a0\u6743\u4e50\u89c2\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347\uff08WOGDA\uff09\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7ebf\u6027\u53cd\u9988\u5ef6\u8fdf\u4e0b\u7684\u6536\u655b\u901f\u5ea6\u3002\u7279\u522b\u5730\uff0c\u7814\u7a76\u53d1\u73b0\u989d\u5916\u4e50\u89c2\uff08\u9884\u6d4b\u66f4\u8fdc\u672a\u6765\u7684\u5956\u52b1\uff09\u53ef\u4ee5\u5bb9\u5fcd\u66f4\u5927\u7684\u6b65\u957f\uff0c\u5e76\u663e\u8457\u52a0\u901f\u6536\u655b\u901f\u7387\u81f3$\\exp(-\\u0398(t/(m^2\\\\log m)))$\u3002\u5b9e\u9a8c\u7ed3\u679c\u4e0e\u7406\u8bba\u4e00\u81f4\uff0c\u8868\u660e\u989d\u5916\u4e50\u89c2\u662f\u5e94\u5bf9\u7531\u53cd\u9988\u5ef6\u8fdf\u5f15\u8d77\u6027\u80fd\u4e0b\u964d\u7684\u6709\u6548\u5bf9\u7b56\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u4e0d\u53ef\u907f\u514d\u5730\u5b58\u5728\u53cd\u9988\u5ef6\u8fdf\u95ee\u9898\uff0c\u8fd9\u5df2\u77e5\u4f1a\u4e25\u91cd\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u5e26\u6709\u5ef6\u8fdf\u53cd\u9988\u7684\u6536\u655b\u7387\u5373\u4f7f\u5bf9\u4e8e\u53cc\u7ebf\u6027\u535a\u5f08\u4e5f\u4ecd\u7136\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u80fd\u591f\u5bf9\u6297\u7531\u4e8e\u53cd\u9988\u5ef6\u8fdf\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u52a0\u6743\u4e50\u89c2\u68af\u5ea6\u4e0b\u964d-\u4e0a\u5347(WOGDA)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u989d\u5916\u4e50\u89c2\u6765\u9884\u6d4b\u672a\u6765\u5956\u52b1\u3002\u6b64\u5916\uff0c\u8fd8\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86WOGDA\u7b97\u6cd5\u4f5c\u4e3a\u66f4\u8fdc\u672a\u6765\u5956\u52b1\u57fa\u7840\u4e0a\u66f4\u65b0\u7684Extra Proximal Point (EPP)\u7684\u4e00\u79cd\u8fd1\u4f3c\u5f62\u5f0f\u7684\u884c\u4e3a\u8868\u73b0\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6807\u51c6\u4e50\u89c2\uff08\u5373\u9884\u6d4b\u4e0b\u4e00\u6b65\u5956\u52b1\uff09\u5728$t$\u6b21\u8fed\u4ee3\u540e\u4ee5$\\exp(-\\u0398(t/m^5))$\u7684\u901f\u5ea6\u5411\u5747\u8861\u70b9\u7ebf\u6027\u6536\u655b\uff1b\u800c\u91c7\u7528\u989d\u5916\u4e50\u89c2\u5219\u53ef\u63a5\u53d7\u66f4\u5927\u7684\u6b65\u957f\u5e76\u663e\u8457\u52a0\u5feb\u6536\u655b\u901f\u5ea6\u8fbe\u5230$\\exp(-\\u0398(t/(m^2\\\\log m)))$\u3002\u5b9e\u9a8c\u89c2\u5bdf\u5230\u7684\u7ed3\u679c\u4e0e\u7406\u8bba\u5206\u6790\u76f8\u7b26\u3002", "conclusion": "\u989d\u5916\u4e50\u89c2\u662f\u4e00\u79cd\u6709\u524d\u9014\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u7f13\u89e3\u56e0\u53cd\u9988\u5ef6\u8fdf\u9020\u6210\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002"}}
{"id": "2602.17510", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17510", "abs": "https://arxiv.org/abs/2602.17510", "authors": ["Kasun Dewage", "Marianna Pensky", "Suranadi De Silva", "Shankadeep Mondal"], "title": "LORA-CRAFT: Cross-layer Rank Adaptation via Frozen Tucker Decomposition of Pre-trained Attention Weights", "comment": null, "summary": "We introduce CRAFT (Cross-layer Rank Adaptation via Frozen Tucker), a parameter-efficient fine-tuning (PEFT) method that applies Tucker tensor decomposition to pre-trained attention weight matrices stacked across transformer layers and trains only small square adaptation matrices on the resulting frozen Tucker factors. Existing tensor-based PEFT methods decompose gradient updates: LoTR applies Tucker decomposition with shared factor matrices, while SuperLoRA groups and reshapes $\u0394W$ across layers before applying Tucker decomposition. Separately, methods like PiSSA apply SVD to pre-trained weights but operate independently per layer. CRAFT bridges these two lines of work: it performs full Tucker decomposition via Higher-Order SVD (HOSVD) directly on pre-trained weights organized as cross-layer 3D tensors, freezes all resulting factors, and adapts the model through lightweight trainable transformations applied to each factor matrix. Experiments on the GLUE benchmark using RoBERTa-base and RoBERTa-large demonstrate that CRAFT achieves competitive performance with existing methods while requiring only 41K Tucker adaptation parameters--a count independent of model dimension and depth at fixed Tucker ranks.", "AI": {"tldr": "CRAFT\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9884\u8bad\u7ec3\u7684\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u8fdb\u884cTucker\u5f20\u91cf\u5206\u89e3\uff0c\u5e76\u4ec5\u5728\u5f97\u5230\u7684\u51bb\u7ed3Tucker\u56e0\u5b50\u4e0a\u8bad\u7ec3\u5c0f\u578b\u5e73\u65b9\u9002\u5e94\u77e9\u9635\uff0c\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u6240\u9700\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u53c2\u6570\u6548\u7387\uff0c\u51cf\u5c11\u9700\u8981\u8bad\u7ec3\u7684\u65b0\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5c06\u8de8\u5c42\u5806\u53e0\u7684\u9884\u8bad\u7ec3\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u7ec4\u7ec7\u62103D\u5f20\u91cf\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u5168Tucker\u5206\u89e3\uff08\u4f7f\u7528HOSVD\uff09\uff0c\u7136\u540e\u51bb\u7ed3\u6240\u6709\u751f\u6210\u7684\u56e0\u7d20\u77e9\u9635\uff0c\u518d\u5bf9\u6bcf\u4e2a\u56e0\u7d20\u77e9\u9635\u5e94\u7528\u8f7b\u91cf\u7ea7\u53ef\u8bad\u7ec3\u53d8\u6362\u6765\u8c03\u6574\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728GLUE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f\u7528RoBERTa-base\u548cRoBERTa-large\u65f6\uff0cCRAFT\u80fd\u591f\u4ee5\u56fa\u5b9aTucker\u79e9\u7684\u60c5\u51b5\u4e0b\uff0c\u72ec\u7acb\u4e8e\u6a21\u578b\u7ef4\u5ea6\u548c\u6df1\u5ea6\uff0c\u4ec5\u970041K\u4e2aTucker\u9002\u5e94\u53c2\u6570\u5c31\u8fbe\u5230\u4e0e\u5176\u4ed6\u65b9\u6cd5\u76f8\u7ade\u4e89\u7684\u8868\u73b0\u3002", "conclusion": "CRAFT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6240\u9700\u7684\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\uff0c\u8fd9\u4e3a\u66f4\u9ad8\u6548\u5730\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2602.17525", "categories": ["cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17525", "abs": "https://arxiv.org/abs/2602.17525", "authors": ["Luca Ghafourpour", "Sinho Chewi", "Alessio Figalli", "Aram-Alexandre Pooladian"], "title": "Variational inference via radial transport", "comment": null, "summary": "In variational inference (VI), the practitioner approximates a high-dimensional distribution $\u03c0$ with a simple surrogate one, often a (product) Gaussian distribution. However, in many cases of practical interest, Gaussian distributions might not capture the correct radial profile of $\u03c0$, resulting in poor coverage. In this work, we approach the VI problem from the perspective of optimizing over these radial profiles. Our algorithm radVI is a cheap, effective add-on to many existing VI schemes, such as Gaussian (mean-field) VI and Laplace approximation. We provide theoretical convergence guarantees for our algorithm, owing to recent developments in optimization over the Wasserstein space--the space of probability distributions endowed with the Wasserstein distance--and new regularity properties of radial transport maps in the style of Caffarelli (2000).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53d8\u5206\u63a8\u7406(radVI)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u4f18\u5316\u5f84\u5411\u5256\u9762\u6765\u6539\u5584\u9ad8\u65af\u5206\u5e03\u8fd1\u4f3c\u590d\u6742\u5206\u5e03\u65f6\u7684\u8986\u76d6\u6548\u679c\u3002\u6b64\u65b9\u6cd5\u53ef\u4ee5\u4f5c\u4e3a\u73b0\u6709\u591a\u79cd\u53d8\u5206\u63a8\u7406\u65b9\u6848\u5982\u9ad8\u65af\u5747\u573a\u53d8\u5206\u63a8\u7406\u548c\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u7684\u6709\u6548\u8865\u5145\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u5728\u53d8\u5206\u63a8\u7406\u4e2d\uff0c\u4f7f\u7528\u9ad8\u65af\u5206\u5e03\u53bb\u8fd1\u4f3c\u4e00\u4e2a\u9ad8\u7ef4\u5206\u5e03\u03c0\u5f80\u5f80\u4e0d\u80fd\u51c6\u786e\u6355\u6349\u5230\u03c0\u7684\u5f84\u5411\u8f6e\u5ed3\uff0c\u4ece\u800c\u5bfc\u81f4\u8f83\u5dee\u7684\u8986\u76d6\u6548\u679c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u4ece\u4f18\u5316\u5f84\u5411\u8f6e\u5ed3\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aradVI\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u65e8\u5728\u901a\u8fc7\u4f18\u5316\u76ee\u6807\u5206\u5e03\u7684\u5f84\u5411\u8f6e\u5ed3\u6765\u6539\u8fdb\u73b0\u6709\u7684\u53d8\u5206\u63a8\u7406\u6280\u672f\u3002\u5b83\u57fa\u4e8eWasserstein\u7a7a\u95f4\u4e0a\u7684\u4f18\u5316\u8fdb\u5c55\u4ee5\u53ca\u7c7b\u4f3cCaffarelli (2000)\u98ce\u683c\u7684\u5f84\u5411\u4f20\u8f93\u6620\u5c04\u7684\u65b0\u89c4\u5f8b\u6027\u5c5e\u6027\u63d0\u4f9b\u652f\u6301\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cradVI\u7b97\u6cd5\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u6210\u672c\u6709\u6548\u5730\u589e\u5f3a\u8bb8\u591a\u73b0\u5b58\u53d8\u5206\u63a8\u7406\u65b9\u6848\u7684\u8868\u73b0\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u9ad8\u65af\uff08\u5747\u573a\uff09\u53d8\u5206\u63a8\u7406\u4e0e\u62c9\u666e\u62c9\u65af\u903c\u8fd1\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u4e3a\u6240\u63d0\u7b97\u6cd5\u7ed9\u51fa\u4e86\u7406\u8bba\u4e0a\u7684\u6536\u655b\u6027\u4fdd\u969c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165radVI\u7b97\u6cd5\uff0c\u5728\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u4e86\u53d8\u5206\u63a8\u7406\u5bf9\u590d\u6742\u5206\u5e03\u7684\u8fd1\u4f3c\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u5177\u6709\u975e\u5178\u578b\u5f84\u5411\u7279\u6027\u7684\u5206\u5e03\u6765\u8bf4\u5c24\u4e3a\u6709\u6548\u3002"}}
{"id": "2602.17526", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17526", "abs": "https://arxiv.org/abs/2602.17526", "authors": ["Peter Balogh"], "title": "The Anxiety of Influence: Bloom Filters in Transformer Attention Heads", "comment": "13 pages, 8 figures, code at https://github.com/pbalogh/anxiety-of-influence v2: L3H0 reclassified as prefix-attention head following confound control. Capacity analysis updated. Duplicate-token head overlap experiment added v3: All experiments were independently validated on CPU to rule out hardware-specific computation artifacts. Results are consistent across backends", "summary": "Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question \"has this token appeared before in the context?\" We identify these heads across four language models (GPT-2 small, medium, and large; Pythia-160M) and show that they form a spectrum of membership-testing strategies. Two heads (L0H1 and L0H5 in GPT-2 small) function as high-precision membership filters with false positive rates of 0-4\\% even at 180 unique context tokens -- well above the $d_\\text{head} = 64$ bit capacity of a classical Bloom filter. A third head (L1H11) shows the classic Bloom filter capacity curve: its false positive rate follows the theoretical formula $p \\approx (1 - e^{-kn/m})^k$ with $R^2 = 1.0$ and fitted capacity $m \\approx 5$ bits, saturating by $n \\approx 20$ unique tokens. A fourth head initially identified as a Bloom filter (L3H0) was reclassified as a general prefix-attention head after confound controls revealed its apparent capacity curve was a sequence-length artifact. Together, the three genuine membership-testing heads form a multi-resolution system concentrated in early layers (0-1), taxonomically distinct from induction and previous-token heads, with false positive rates that decay monotonically with embedding distance -- consistent with distance-sensitive Bloom filters. These heads generalize broadly: they respond to any repeated token type, not just repeated names, with 43\\% higher generalization than duplicate-token-only heads. Ablation reveals these heads contribute to both repeated and novel token processing, indicating that membership testing coexists with broader computational roles. The reclassification of L3H0 through confound controls strengthens rather than weakens the case: the surviving heads withstand the scrutiny that eliminated a false positive in our own analysis.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u67d0\u4e9bTransformer\u6ce8\u610f\u529b\u5934\u5728\u56db\u4e2a\u8bed\u8a00\u6a21\u578b\u4e2d\u4f5c\u4e3a\u6210\u5458\u6d4b\u8bd5\u5668\u5de5\u4f5c\uff0c\u80fd\u591f\u4ee5\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u4e0a\u4e0b\u6587\u4e2d\u662f\u5426\u51fa\u73b0\u8fc7\u67d0\u4e2a\u6807\u8bb0\u3002\u8fd9\u4e9b\u6210\u5458\u6d4b\u8bd5\u5934\u5f62\u6210\u4e86\u4e00\u79cd\u591a\u5206\u8fa8\u7387\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u5bf9\u91cd\u590d\u7684\u540d\u5b57\u6709\u53cd\u5e94\uff0c\u8fd8\u5bf9\u4efb\u4f55\u7c7b\u578b\u7684\u91cd\u590d\u6807\u8bb0\u6709\u54cd\u5e94\uff0c\u5e76\u4e14\u5b83\u4eec\u5bf9\u4e8e\u5904\u7406\u91cd\u590d\u548c\u65b0\u5947\u7684\u6807\u8bb0\u90fd\u6709\u8d21\u732e\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22Transformer\u67b6\u6784\u4e2d\u7684\u7279\u5b9a\u6ce8\u610f\u529b\u5934\u5982\u4f55\u4e13\u95e8\u7528\u4e8e\u68c0\u6d4b\u5f53\u524d\u5904\u7406\u7684\u6807\u8bb0\u662f\u5426\u4e4b\u524d\u5df2\u5728\u4e0a\u4e0b\u6587\u4e2d\u51fa\u73b0\u8fc7\u3002\u901a\u8fc7\u5206\u6790GPT-2\u7cfb\u5217\u53caPythia-160M\u6a21\u578b\u5185\u7684\u6ce8\u610f\u529b\u5934\u884c\u4e3a\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u63ed\u793a\u8fd9\u4e9b\u201c\u6210\u5458\u6d4b\u8bd5\u201d\u5934\u7684\u5de5\u4f5c\u673a\u5236\u53ca\u5176\u5728\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u5bf9GPT-2\u5c0f\u578b\u3001\u4e2d\u578b\u3001\u5927\u578b\u4ee5\u53caPythia-160M\u56db\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\uff0c\u7814\u7a76\u4eba\u5458\u786e\u5b9a\u4e86\u51e0\u4e2a\u4e13\u6ce8\u4e8e\u6210\u5458\u6d4b\u8bd5\u529f\u80fd\u7684\u6ce8\u610f\u529b\u5934\u3002\u4ed6\u4eec\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u8fd9\u4e9b\u5934\u7684\u5177\u4f53\u8868\u73b0\u5f62\u5f0f\uff0c\u5305\u62ec\u8bef\u62a5\u7387\u4e0e\u4e0a\u4e0b\u6587\u6807\u8bb0\u6570\u91cf\u95f4\u7684\u5173\u7cfb\u7b49\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u5934\u7684\u529f\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728GPT-2\u5c0f\u578b\u6a21\u578b\u4e2d\u53d1\u73b0\u4e86\u4e09\u4e2a\u771f\u6b63\u7684\u6210\u5458\u6d4b\u8bd5\u6ce8\u610f\u529b\u5934\uff0c\u5176\u4e2d\u4e24\u4e2a\u8868\u73b0\u51fa\u6781\u4f4e\u7684\u8bef\u62a5\u7387\uff1b\u53e6\u4e00\u4e2a\u5219\u9075\u5faa\u7ecf\u5178\u5e03\u9686\u8fc7\u6ee4\u5668\u7684\u5bb9\u91cf\u66f2\u7ebf\u3002\u6b64\u5916\uff0c\u539f\u672c\u88ab\u5f52\u7c7b\u4e3a\u5e03\u9686\u8fc7\u6ee4\u5668\u7684\u4e00\u4e2a\u6ce8\u610f\u529b\u5934\uff08L3H0\uff09\u7ecf\u8fc7\u63a7\u5236\u6df7\u6dc6\u56e0\u7d20\u540e\u88ab\u91cd\u65b0\u5206\u7c7b\u4e3a\u4e00\u822c\u7684\u524d\u7f00\u6ce8\u610f\u529b\u5934\u3002\u8fd9\u4e9b\u6210\u5458\u6d4b\u8bd5\u5934\u663e\u793a\u51fa\u6bd4\u4ec5\u5173\u6ce8\u91cd\u590d\u6807\u8bb0\u7684\u5934\u66f4\u9ad8\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u5904\u7406\u91cd\u590d\u548c\u65b0\u9896\u6807\u8bb0\u65f6\u90fd\u53d1\u6325\u4e86\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u4e00\u4e9bTransformer\u6ce8\u610f\u529b\u5934\u786e\u5b9e\u6267\u884c\u7740\u7c7b\u4f3c\u6210\u5458\u6d4b\u8bd5\u7684\u4efb\u52a1\uff0c\u5b83\u4eec\u4e0d\u4ec5\u80fd\u591f\u51c6\u786e\u5730\u8bc6\u522b\u51fa\u4e0a\u4e0b\u6587\u4e2d\u5df2\u5b58\u5728\u7684\u6807\u8bb0\uff0c\u800c\u4e14\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u91cd\u590d\u6807\u8bb0\u4e5f\u5177\u6709\u826f\u597d\u7684\u54cd\u5e94\u6027\u3002\u8fd9\u8868\u660e\uff0c\u8fd9\u7c7b\u6ce8\u610f\u529b\u5934\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u626e\u6f14\u7740\u91cd\u8981\u7684\u89d2\u8272\uff0c\u65e2\u6709\u52a9\u4e8e\u91cd\u590d\u4fe1\u606f\u7684\u5904\u7406\u4e5f\u6709\u52a9\u4e8e\u65b0\u4fe1\u606f\u7684\u5b66\u4e60\u3002"}}
{"id": "2602.17531", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17531", "abs": "https://arxiv.org/abs/2602.17531", "authors": ["Zachary Berger", "Daniel Prakah-Asante", "John Guttag", "Collin M. Stultz"], "title": "Position: Evaluation of ECG Representations Must Be Fixed", "comment": "Project website at https://ecgfix.csail.mit.edu/", "summary": "This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominated by arrhythmia and waveform-morphology labels, even though the ECG is known to encode substantially broader clinical information. We argue that downstream evaluation should expand to include an assessment of structural heart disease and patient-level forecasting, in addition to other evolving ECG-related endpoints, as relevant clinical targets. Next, we outline evaluation best practices for multi-label, imbalanced settings, and show that when they are applied, the literature's current conclusion about which representations perform best is altered. Furthermore, we demonstrate the surprising result that a randomly initialized encoder with linear evaluation matches state-of-the-art pre-training on many tasks. This motivates the use of a random encoder as a reasonable baseline model. We substantiate our observations with an empirical evaluation of three representative ECG pre-training approaches across six evaluation settings: the three standard benchmarks, a structural disease dataset, hemodynamic inference, and patient forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f53\u524d12\u5bfc\u8054\u5fc3\u7535\u56fe\u8868\u793a\u5b66\u4e60\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u9700\u8981\u6539\u8fdb\uff0c\u4ee5\u786e\u4fdd\u8fdb\u5c55\u53ef\u9760\u4e14\u7b26\u5408\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u76ee\u6807\u3002\u5efa\u8bae\u6269\u5c55\u4e0b\u6e38\u8bc4\u4f30\u4ee5\u5305\u62ec\u7ed3\u6784\u6027\u5fc3\u810f\u75c5\u548c\u60a3\u8005\u6c34\u5e73\u9884\u6d4b\u7b49\uff0c\u5e76\u6307\u51fa\u5728\u591a\u6807\u7b7e\u3001\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e2d\u5e94\u7528\u6700\u4f73\u8bc4\u4f30\u5b9e\u8df5\u65f6\uff0c\u6587\u732e\u4e2d\u5173\u4e8e\u54ea\u79cd\u8868\u793a\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\u7684\u7ed3\u8bba\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u6b64\u5916\uff0c\u968f\u673a\u521d\u59cb\u5316\u7f16\u7801\u5668\u5728\u7ebf\u6027\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\u4e0e\u6700\u5148\u8fdb\u7684\u9884\u8bad\u7ec3\u76f8\u5f53\uff0c\u8fd9\u652f\u6301\u4e86\u4f7f\u7528\u968f\u673a\u7f16\u7801\u5668\u4f5c\u4e3a\u5408\u7406\u57fa\u7ebf\u6a21\u578b\u7684\u89c2\u70b9\u3002", "motivation": "\u73b0\u6709\u768412\u5bfc\u8054\u5fc3\u7535\u56fe\u8868\u793a\u5b66\u4e60\u9886\u57df\u4e3b\u8981\u96c6\u4e2d\u5728\u51e0\u4e2a\u516c\u5f00\u7684\u591a\u6807\u7b7e\u57fa\u51c6\u4e0a\uff0c\u8fd9\u4e9b\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5fc3\u5f8b\u5931\u5e38\u548c\u6ce2\u5f62\u5f62\u6001\u6807\u8bb0\uff0c\u800c\u5ffd\u7565\u4e86\u5fc3\u7535\u56fe\u6240\u5305\u542b\u7684\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u9700\u8981\u8c03\u6574\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u53cd\u6620\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\uff0c\u5e76\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u5065\u5eb7\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u6269\u5927\u5bf9\u7ed3\u6784\u6027\u5fc3\u810f\u75c5\u53ca\u60a3\u8005\u5c42\u9762\u9884\u6d4b\u7b49\u989d\u5916\u4e34\u5e8a\u76ee\u6807\u7684\u8bc4\u4f30\u8303\u56f4\uff0c\u5e76\u9488\u5bf9\u591a\u6807\u7b7e\u3001\u6570\u636e\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u63d0\u51fa\u6700\u4f73\u8bc4\u4f30\u5b9e\u8df5\u5efa\u8bae\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5bf9\u4e09\u79cd\u4ee3\u8868\u6027\u7684\u5fc3\u7535\u56fe\u9884\u8bad\u7ec3\u65b9\u6cd5\u5728\u516d\u4e2a\u4e0d\u540c\u8bc4\u4f30\u573a\u666f\u4e0b\u7684\u5b9e\u8bc1\u7814\u7a76\u6765\u9a8c\u8bc1\u5176\u89c2\u70b9\u3002", "result": "\u5f53\u91c7\u7528\u63a8\u8350\u7684\u6700\u4f73\u8bc4\u4f30\u5b9e\u8df5\u65f6\uff0c\u5bf9\u4e8e\u54ea\u4e9b\u8868\u5f81\u65b9\u6cd5\u6700\u6709\u6548\u7684\u73b0\u6709\u7ed3\u8bba\u53d1\u751f\u4e86\u6539\u53d8\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\uff0c\u4e00\u4e2a\u5e26\u6709\u7ebf\u6027\u8bc4\u4f30\u7684\u968f\u673a\u521d\u59cb\u5316\u7f16\u7801\u5668\u80fd\u591f\u4e0e\u6700\u5148\u8fdb\u7684\u9884\u8bad\u7ec3\u6280\u672f\u76f8\u5ab2\u7f8e\u3002\u8fd9\u610f\u5473\u7740\u53ef\u4ee5\u8003\u8651\u5c06\u968f\u673a\u7f16\u7801\u5668\u4f5c\u4e3a\u5408\u7406\u7684\u57fa\u51c6\u6a21\u578b\u3002", "conclusion": "\u4e3a\u4e86\u4f7f12\u5bfc\u8054\u5fc3\u7535\u56fe\u8868\u793a\u5b66\u4e60\u7684\u7814\u7a76\u8fdb\u6b65\u66f4\u52a0\u53ef\u9760\u5e76\u7d27\u5bc6\u8054\u7cfb\u4e34\u5e8a\u610f\u4e49\uff0c\u6709\u5fc5\u8981\u62d3\u5bbd\u8bc4\u4f30\u8303\u56f4\u81f3\u66f4\u591a\u6837\u7684\u4e34\u5e8a\u7ec8\u70b9\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\u5373\u4f7f\u662f\u7b80\u5355\u7684\u968f\u673a\u521d\u59cb\u5316\u7f16\u7801\u5668\u4e5f\u80fd\u63d0\u4f9b\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.17550", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17550", "abs": "https://arxiv.org/abs/2602.17550", "authors": ["Xiaoliang Fu", "Jiaye Lin", "Yangyi Fang", "Binbin Zheng", "Chaowen Hu", "Zekai Shao", "Cong Qin", "Lu Pan", "Ke Zeng", "Xunliang Cai"], "title": "MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning", "comment": null, "summary": "Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical challenges in these methods: (1) inefficient gradient utilization caused by the binary cutoff of hard clipping, (2) insensitive probability mass arising from uniform ratio constraints that ignore the token distribution, and (3) asymmetric signal reliability stemming from the disparate credit assignment ambiguity between positive and negative samples. To bridge these gaps, we propose Mass-Adaptive Soft Policy Optimization (MASPO), a unified framework designed to harmonize these three dimensions. MASPO integrates a differentiable soft Gaussian gating to maximize gradient utility, a mass-adaptive limiter to balance exploration across the probability spectrum, and an asymmetric risk controller to align update magnitudes with signal confidence. Extensive evaluations demonstrate that MASPO serves as a robust, all-in-one RLVR solution, significantly outperforming strong baselines. Our code is available at: https://anonymous.4open.science/r/ma1/README.md.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6MASPO\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709RLVR\u7b97\u6cd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMASPO\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60(RLVR)\u7b97\u6cd5\uff0c\u5982GRPO\uff0c\u5728\u5904\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u6982\u7387\u8d28\u91cf\u4e0d\u654f\u611f\u4ee5\u53ca\u4fe1\u53f7\u53ef\u9760\u6027\u4e0d\u5bf9\u79f0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Mass-Adaptive Soft Policy Optimization (MASPO)\uff0c\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5fae\u8f6f\u9ad8\u65af\u95e8\u63a7\u673a\u5236\u6765\u6700\u5927\u5316\u68af\u5ea6\u5229\u7528\u6548\u7387\uff1b\u4f7f\u7528\u8d28\u91cf\u81ea\u9002\u5e94\u9650\u5236\u5668\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff1b\u5e76\u901a\u8fc7\u975e\u5bf9\u79f0\u98ce\u9669\u63a7\u5236\u5668\u8c03\u6574\u66f4\u65b0\u5e45\u5ea6\u4ee5\u5339\u914d\u4fe1\u53f7\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5e7f\u6cdb\u7684\u8bc4\u4f30\u663e\u793a\uff0cMASPO\u4f5c\u4e3a\u4e00\u79cd\u9c81\u68d2\u4e14\u5168\u9762\u7684RLVR\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u6027\u80fd\u660e\u663e\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "MASPO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u9047\u5230\u7684\u7279\u5b9a\u6311\u6218\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.17554", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17554", "abs": "https://arxiv.org/abs/2602.17554", "authors": ["Corinna Cortes", "Mehryar Mohri", "Yutao Zhong"], "title": "A Theoretical Framework for Modular Learning of Robust Generative Models", "comment": null, "summary": "Training large-scale generative models is resource-intensive and relies heavily on heuristic dataset weighting. We address two fundamental questions: Can we train Large Language Models (LLMs) modularly-combining small, domain-specific experts to match monolithic performance-and can we do so robustly for any data mixture, eliminating heuristic tuning? We present a theoretical framework for modular generative modeling where a set of pre-trained experts are combined via a gating mechanism. We define the space of normalized gating functions, $G_{1}$, and formulate the problem as a minimax game to find a single robust gate that minimizes divergence to the worst-case data mixture. We prove the existence of such a robust gate using Kakutani's fixed-point theorem and show that modularity acts as a strong regularizer, with generalization bounds scaling with the lightweight gate's complexity. Furthermore, we prove that this modular approach can theoretically outperform models retrained on aggregate data, with the gap characterized by the Jensen-Shannon Divergence. Finally, we introduce a scalable Stochastic Primal-Dual algorithm and a Structural Distillation method for efficient inference. Empirical results on synthetic and real-world datasets confirm that our modular architecture effectively mitigates gradient conflict and can robustly outperform monolithic baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u751f\u6210\u6a21\u578b\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u4e13\u5bb6\u548c\u95e8\u63a7\u673a\u5236\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\u4ee5\u53ca\u6570\u636e\u96c6\u6743\u91cd\u8c03\u6574\u8fc7\u4e8e\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u95ee\u9898\u3002\u7814\u7a76\u8005\u8bc1\u660e\u4e86\u5b58\u5728\u4e00\u79cd\u9c81\u68d2\u6027\u7684\u95e8\u63a7\u51fd\u6570\u53ef\u4ee5\u6700\u5c0f\u5316\u4e0e\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6570\u636e\u6df7\u5408\u7684\u5dee\u5f02\uff0c\u5e76\u4e14\u8fd9\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u53ef\u4ee5\u4f18\u4e8e\u57fa\u4e8e\u805a\u5408\u6570\u636e\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u968f\u673a\u539f\u59cb\u5bf9\u5076\u7b97\u6cd5\u548c\u7ed3\u6784\u84b8\u998f\u65b9\u6cd5\u6765\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6a21\u5757\u5316\u67b6\u6784\u80fd\u591f\u6709\u6548\u7f13\u89e3\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u5355\u4e00\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u9488\u5bf9\u5927\u89c4\u6a21\u751f\u6210\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\u53ca\u6570\u636e\u96c6\u6743\u91cd\u8c03\u6574\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u7ecf\u9a8c\u89c4\u5219\u7684\u95ee\u9898\uff0c\u63a2\u8ba8\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7ec4\u5408\u5c0f\u578b\u3001\u9886\u57df\u7279\u5b9a\u7684\u4e13\u5bb6\u6a21\u578b\u6765\u8fbe\u5230\u4e0e\u5355\u4e00\u5927\u578b\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u8fd9\u4e00\u8fc7\u7a0b\u5bf9\u4e8e\u4efb\u4f55\u6570\u636e\u6df7\u5408\u90fd\u8db3\u591f\u7a33\u5065\uff0c\u4ece\u800c\u6d88\u9664\u6389\u7ecf\u9a8c\u6027\u7684\u8c03\u4f18\u9700\u6c42\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u7528\u4e8e\u6a21\u5757\u5316\u7684\u751f\u6210\u5efa\u6a21\uff0c\u5176\u4e2d\u4e00\u7ec4\u9884\u8bad\u7ec3\u597d\u7684\u4e13\u5bb6\u6a21\u578b\u901a\u8fc7\u67d0\u79cd\u95e8\u63a7\u673a\u5236\u88ab\u7ed3\u5408\u5728\u4e00\u8d77\u3002\u5b9a\u4e49\u4e86\u6807\u51c6\u5316\u95e8\u63a7\u51fd\u6570\u7a7a\u95f4G1\uff0c\u5e76\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u6781\u5c0f\u6781\u5927\u535a\u5f08\uff0c\u4ee5\u627e\u5230\u4e00\u4e2a\u80fd\u6700\u5c0f\u5316\u4e0e\u6700\u7cdf\u7cd5\u7684\u6570\u636e\u6df7\u5408\u4e4b\u95f4\u5dee\u5f02\u7684\u9c81\u68d2\u95e8\u63a7\u3002\u5229\u7528Kakutani\u4e0d\u52a8\u70b9\u5b9a\u7406\u8bc1\u660e\u4e86\u8fd9\u79cd\u9c81\u68d2\u95e8\u63a7\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u5757\u5316\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u6709\u529b\u7684\u6b63\u5219\u5316\u624b\u6bb5\u7684\u4f5c\u7528\u3002\u53e6\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u968f\u673a\u539f\u5bf9\u5076\u7b97\u6cd5\u548c\u7ed3\u6784\u84b8\u998f\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u6a21\u5757\u5316\u67b6\u6784\u80fd\u591f\u6709\u6548\u5730\u51cf\u8f7b\u68af\u5ea6\u51b2\u7a81\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u5355\u4e00\u4f53\u7cfb\u57fa\u7ebf\u800c\u8a00\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\u5747\u8868\u73b0\u51fa\u4e86\u66f4\u4f73\u7684\u9c81\u68d2\u6027\u548c\u8d85\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u6784\u5efa\u548c\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u66f4\u52a0\u9ad8\u6548\u548c\u7075\u6d3b\uff0c\u800c\u4e14\u8fd8\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u5f15\u5165\u6a21\u5757\u5316\u601d\u60f3\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u8d44\u6e90\uff0c\u540c\u65f6\u8fd8\u80fd\u63d0\u9ad8\u6a21\u578b\u9762\u5bf9\u4e0d\u540c\u6570\u636e\u5206\u5e03\u65f6\u7684\u8868\u73b0\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.17559", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17559", "abs": "https://arxiv.org/abs/2602.17559", "authors": ["Yaoyue Zheng", "Yin Zhang", "Joost van de Weijer", "Gido M van de Ven", "Shaoyi Du", "Xuetao Zhang", "Zhiqiang Tian"], "title": "Revisiting Weight Regularization for Low-Rank Continual Learning", "comment": "Accepted by ICLR 2026", "summary": "Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regularization techniques within PECL. Extensive experiments on various benchmarks demonstrate the effectiveness of EWC-LoRA, achieving a stability-plasticity trade-off superior to existing low-rank CL approaches. These results indicate that, even under low-rank parameterizations, weight regularization remains an effective mechanism for mitigating task interference. Code is available at: https://github.com/yaoyz96/low-rank-cl.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEWC-LoRA\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u4f4e\u79e9\u6301\u7eed\u5b66\u4e60\u4e2d\u5e94\u7528\u6743\u91cd\u6b63\u5219\u5316\uff08\u5982EWC\uff09\u6765\u7f13\u89e3\u4efb\u52a1\u5e72\u6270\uff0c\u4ece\u800c\u4e3a\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u9ad8\u6548\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8ba1\u7b97\u548c\u5185\u5b58\u6548\u7387\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u867d\u7136\u53c2\u6570\u9ad8\u6548\u6301\u7eed\u5b66\u4e60(PECL)\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u4f46\u6743\u91cd\u6b63\u5219\u5316\u6280\u672f\u5728\u8fd9\u4e00\u65b0\u8303\u5f0f\u4e2d\u7684\u5e94\u7528\u4ecd\u8f83\u5c11\u88ab\u63a2\u7d22\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u51cf\u8f7b\u4efb\u52a1\u95f4\u7684\u5e72\u6270\uff0c\u4f5c\u8005\u4eec\u5e0c\u671b\u91cd\u65b0\u5ba1\u89c6\u5982\u4f55\u5728\u4f4e\u79e9\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e2d\u6709\u6548\u5730\u8fd0\u7528\u6743\u91cd\u6b63\u5219\u5316\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86EWC-LoRA\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7EWC\u5bf9\u5171\u4eab\u4f4e\u79e9\u66f4\u65b0\u8fdb\u884c\u6b63\u5219\u5316\u5904\u7406\uff0c\u4ee5\u6b64\u6765\u63a7\u5236\u4efb\u52a1\u95f4\u5e72\u6270\u95ee\u9898\u3002\u6b64\u6cd5\u5229\u7528\u4e86\u4f4e\u79e9\u8868\u793a\u6765\u4f30\u8ba1\u6574\u4e2a\u7ef4\u5ea6\u7a7a\u95f4\u4e0a\u7684\u53c2\u6570\u91cd\u8981\u6027\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u5b58\u50a8\u9700\u6c42\u548c\u63a8\u7406\u6210\u672c\u4e0d\u968f\u4efb\u52a1\u6570\u91cf\u589e\u52a0\u800c\u53d8\u5316\u7684\u7279\u70b9\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u4f4e\u79e9\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0cEWC-LoRA\u80fd\u591f\u5728\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u4f18\u6027\u80fd\u3002\u8fd9\u8bc1\u660e\u4e86\u5373\u4f7f\u662f\u5728\u4f4e\u79e9\u53c2\u6570\u5316\u6761\u4ef6\u4e0b\uff0c\u6743\u91cd\u6b63\u5219\u5316\u4f9d\u7136\u662f\u7f13\u89e3\u4efb\u52a1\u5e72\u6270\u7684\u6709\u6548\u673a\u5236\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5373\u4f7f\u91c7\u7528\u4f4e\u79e9\u53c2\u6570\u5316\u65b9\u6848\u65f6\uff0c\u6743\u91cd\u6b63\u5219\u5316\u4f9d\u65e7\u80fd\u591f\u6709\u6548\u51cf\u5c11\u4efb\u52a1\u5e72\u6270\uff0c\u540c\u65f6EWC-LoRA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5728\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u6301\u7eed\u5b66\u4e60\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2602.17568", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17568", "abs": "https://arxiv.org/abs/2602.17568", "authors": ["Sofiane Ennadir", "Tianze Wang", "Oleg Smirnov", "Sahar Asadi", "Lele Cao"], "title": "Be Wary of Your Time Series Preprocessing", "comment": "Accepted at the AI4TS workshop at AAAI-26", "summary": "Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-based and global scaling, impact the expressivity of Transformer-based architectures for time series representation learning. We propose a novel expressivity framework tailored to time series, which quantifies a model's ability to distinguish between similar and dissimilar inputs in the representation space. Using this framework, we derive theoretical bounds for two widely used normalization methods: Standard and Min-Max scaling. Our analysis reveals that the choice of normalization strategy can significantly influence the model's representational capacity, depending on the task and data characteristics. We complement our theory with empirical validation on classification and forecasting benchmarks using multiple Transformer-based models. Our results show that no single normalization method consistently outperforms others, and in some cases, omitting normalization entirely leads to superior performance. These findings highlight the critical role of preprocessing in time series learning and motivate the need for more principled normalization strategies tailored to specific tasks and datasets.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u4e0d\u540c\u7684\u5f52\u4e00\u5316\u7b56\u7565\uff08\u5b9e\u4f8b\u57fa\u7840\u548c\u5168\u5c40\u7f29\u653e\uff09\u5bf9\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u5b66\u4e60\u8868\u8fbe\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u8868\u8fbe\u80fd\u529b\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u6807\u51c6\u5316\u548c\u6700\u5c0f-\u6700\u5927\u7f29\u653e\u4e24\u79cd\u5e38\u7528\u65b9\u6cd5\u7684\u7406\u8bba\u8fb9\u754c\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6ca1\u6709\u4e00\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5\u80fd\u591f\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u7701\u7565\u5f52\u4e00\u5316\u6b65\u9aa4\u53cd\u800c\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5f52\u4e00\u5316\u548c\u7f29\u653e\u662f\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u57fa\u672c\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u4f46\u5b83\u4eec\u5728\u57fa\u4e8eTransformer\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\u5c1a\u672a\u4ece\u7406\u8bba\u89d2\u5ea6\u5145\u5206\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u6df1\u5165\u7814\u7a76\u4e0d\u540c\u5f52\u4e00\u5316\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u8fd9\u7c7b\u6a21\u578b\u7684\u8868\u73b0\u529b\uff0c\u4ee5\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u5b66\u4e60\u4efb\u52a1\u7684\u6548\u679c\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u8bbe\u8ba1\u7684\u65b0\u8868\u8fbe\u529b\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u533a\u5206\u76f8\u4f3c\u4e0e\u4e0d\u76f8\u4f3c\u8f93\u5165\u7684\u80fd\u529b\u3002\n2. \u4e3a\u4e24\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f52\u4e00\u5316\u65b9\u6cd5\u2014\u2014\u6807\u51c6\u7f29\u653e\u548c\u6700\u5c0f-\u6700\u5927\u7f29\u653e\u2014\u2014\u63a8\u5bfc\u51fa\u7406\u8bba\u754c\u9650\u3002\n3. \u5728\u5206\u7c7b\u548c\u9884\u6d4b\u57fa\u51c6\u4e0a\u4f7f\u7528\u591a\u4e2a\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f52\u4e00\u5316\u7b56\u7565\u7684\u9009\u62e9\u53ef\u4ee5\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u8868\u5f81\u80fd\u529b\uff0c\u8fd9\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u4efb\u52a1\u548c\u6570\u636e\u7279\u5f81\u3002\u6ca1\u6709\u4efb\u4f55\u4e00\u79cd\u5f52\u4e00\u5316\u65b9\u6cd5\u80fd\u591f\u5728\u6240\u6709\u573a\u666f\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\uff1b\u6709\u65f6\u5019\uff0c\u5b8c\u5168\u4e0d\u5e94\u7528\u5f52\u4e00\u5316\u53cd\u800c\u4f1a\u5f97\u5230\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u9884\u5904\u7406\u6b65\u9aa4\u5bf9\u4e8e\u65f6\u95f4\u5e8f\u5217\u5b66\u4e60\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u9700\u8981\u5f00\u53d1\u66f4\u52a0\u539f\u5219\u6027\u7684\u3001\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u5b9a\u5236\u7684\u5f52\u4e00\u5316\u7b56\u7565\u3002"}}
{"id": "2602.17608", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17608", "abs": "https://arxiv.org/abs/2602.17608", "authors": ["Baihe Huang", "Eric Xu", "Kannan Ramchandran", "Jiantao Jiao", "Michael I. Jordan"], "title": "Towards Anytime-Valid Statistical Watermarking", "comment": null, "summary": "The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach for selecting sampling distributions and the reliance on fixed-horizon hypothesis testing, which precludes valid early stopping. In this paper, we bridge this gap by developing the first e-value-based watermarking framework, Anchored E-Watermarking, that unifies optimal sampling with anytime-valid inference. Unlike traditional approaches where optional stopping invalidates Type-I error guarantees, our framework enables valid, anytime-inference by constructing a test supermartingale for the detection process. By leveraging an anchor distribution to approximate the target model, we characterize the optimal e-value with respect to the worst-case log-growth rate and derive the optimal expected stopping time. Our theoretical claims are substantiated by simulations and evaluations on established benchmarks, showing that our framework can significantly enhance sample efficiency, reducing the average token budget required for detection by 13-15% relative to state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Anchored E-Watermarking\u6846\u67b6\uff0c\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8ee\u503c\u7684\u6c34\u5370\u6280\u672f\uff0c\u5b83\u7edf\u4e00\u4e86\u6700\u4f18\u91c7\u6837\u4e0e\u4efb\u610f\u65f6\u95f4\u6709\u6548\u7684\u63a8\u65ad\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u9009\u62e9\u91c7\u6837\u5206\u5e03\u4e0a\u7684\u968f\u610f\u6027\u4ee5\u53ca\u56fa\u5b9a\u8303\u56f4\u5047\u8bbe\u68c0\u9a8c\u7684\u95ee\u9898\u3002\u901a\u8fc7\u6a21\u62df\u548c\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u5c06\u68c0\u6d4b\u6240\u9700\u7684\u5e73\u5747\u4ee4\u724c\u9884\u7b97\u76f8\u5bf9\u51cf\u5c11\u4e8613-15%\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u666e\u53ca\uff0c\u533a\u5206\u673a\u5668\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u6587\u672c\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u5c3d\u7ba1\u7edf\u8ba1\u6c34\u5370\u6280\u672f\u5c55\u73b0\u51fa\u4e86\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u5173\u952e\u9650\u5236\uff1a\u7f3a\u4e4f\u9009\u62e9\u91c7\u6837\u5206\u5e03\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4f9d\u8d56\u4e8e\u4e0d\u5141\u8bb8\u63d0\u524d\u6709\u6548\u505c\u6b62\u7684\u56fa\u5b9a\u671f\u9650\u5047\u8bbe\u68c0\u9a8c\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aAnchored E-Watermarking\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u662f\u9996\u6b21\u57fa\u4e8ee\u503c\u8bbe\u8ba1\u7684\u6c34\u5370\u65b9\u6848\uff0c\u65e8\u5728\u7ed3\u5408\u6700\u4f73\u91c7\u6837\u7b56\u7565\u4e0e\u4efb\u610f\u65f6\u523b\u90fd\u6709\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u951a\u5b9a\u5206\u5e03\u6765\u8fd1\u4f3c\u76ee\u6807\u6a21\u578b\uff0c\u4ece\u800c\u786e\u5b9a\u5173\u4e8e\u6700\u574f\u60c5\u51b5\u5bf9\u6570\u589e\u957f\u7387\u7684\u6700\u4f73e\u503c\uff0c\u5e76\u63a8\u5bfc\u51fa\u6700\u4f18\u9884\u671f\u505c\u6b62\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5206\u6790\u53ca\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5927\u5e45\u63d0\u5347\u6837\u672c\u5229\u7528\u6548\u7387\uff0c\u5728\u4fdd\u6301\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u76ee\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u800c\u8a00\uff0c\u6240\u9700\u7528\u4e8e\u68c0\u6d4b\u7684\u5e73\u5747\u4ee4\u724c\u6570\u964d\u4f4e\u4e8613\u81f315\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "Anchored E-Watermarking\u6846\u67b6\u4e3a\u8bc6\u522b\u673a\u5668\u751f\u6210\u6587\u672c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u4e0d\u4ec5\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8fd8\u901a\u8fc7\u4f18\u5316\u91c7\u6837\u7b56\u7565\u5b9e\u73b0\u4e86\u8d44\u6e90\u7684\u6709\u6548\u8282\u7ea6\u3002"}}
{"id": "2602.17616", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17616", "abs": "https://arxiv.org/abs/2602.17616", "authors": ["Luke Huang", "Zhuoyang Zhang", "Qinghao Hu", "Shang Yang", "Song Han"], "title": "Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs", "comment": null, "summary": "Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the policy-gradient estimator markedly $\\textbf{higher variance}$: training on stale rollouts creates heavy-tailed importance ratios, causing a small fraction of samples to dominate updates. This amplification makes gradients noisy and learning unstable relative to matched on-policy training. Across math and general reasoning benchmarks, we find collapse is reliably predicted by effective sample size (ESS) and unstable gradient norms. Motivated by this diagnosis, we propose $\\textbf{V}$ariance $\\textbf{C}$ontrolled $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{VCPO}$), a general stabilization method for REINFORCE/GRPO-style algorithms that (i) scales learning rate based on effective sample size to dampen unreliable updates, and (ii) applies a closed-form minimum-variance baseline for the off-policy setting, avoiding an auxiliary value model and adding minimal overhead. Empirically, VCPO substantially improves robustness for asynchronous training across math, general reasoning, and tool-use tasks, outperforming a broad suite of baselines spanning masking/clipping stabilizers and algorithmic variants. This reduces long-context, multi-turn training time by 2.5$\\times$ while matching synchronous performance, demonstrating that explicit control of policy-gradient variance is key for reliable asynchronous RL at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVCPO\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u63a7\u5236\u7b56\u7565\u68af\u5ea6\u7684\u65b9\u5dee\u6765\u63d0\u9ad8\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2dREINFORCE/GRPO\u7c7b\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8bc1\u660eVCPO\u5728\u6570\u5b66\u3001\u4e00\u822c\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u4efb\u52a1\u4e2d\u7684\u5f02\u6b65\u8bad\u7ec3\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u4e0e\u540c\u6b65\u6027\u80fd\u76f8\u5339\u914d\u7684\u540c\u65f6\u5c06\u957f\u4e0a\u4e0b\u6587\u591a\u8f6e\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e862.5\u500d\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u6ce8\u610f\u5230\uff0c\u5728\u5e7f\u6cdb\u91c7\u7528\u7684\u65e0\u6279\u8bc4\u5bb6\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff08\u5982REINFORCE\u548cGRPO\uff09\u4e2d\uff0c\u9ad8\u5f02\u6b65\u6027\u4f1a\u5bfc\u81f4\u7b56\u7565\u68af\u5ea6\u4f30\u8ba1\u5668\u51fa\u73b0\u66f4\u9ad8\u7684\u65b9\u5dee\uff1a\u57fa\u4e8e\u8fc7\u65f6\u7684\u5e8f\u5217\u8fdb\u884c\u8bad\u7ec3\u4f1a\u4ea7\u751f\u91cd\u5c3e\u7684\u91cd\u8981\u6027\u6bd4\u7387\uff0c\u4f7f\u5f97\u4e00\u5c0f\u90e8\u5206\u6837\u672c\u4e3b\u5bfc\u66f4\u65b0\u8fc7\u7a0b\u3002\u8fd9\u5bfc\u81f4\u4e86\u68af\u5ea6\u566a\u58f0\u589e\u5927\u4ee5\u53ca\u76f8\u5bf9\u4e8e\u5339\u914d\u7684\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\u6765\u8bf4\u5b66\u4e60\u53d8\u5f97\u4e0d\u7a33\u5b9a\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u53d1\u73b0\u6709\u6548\u6837\u672c\u5927\u5c0f(ESS)\u548c\u4e0d\u7a33\u5b9a\u7684\u68af\u5ea6\u8303\u6570\u80fd\u591f\u53ef\u9760\u5730\u9884\u6d4b\u5d29\u6e83\u73b0\u8c61\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aVariance Controlled Policy Optimization (VCPO)\u7684\u65b9\u6cd5\u3002VCPO\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff1a(i) \u6839\u636e\u6709\u6548\u6837\u672c\u5927\u5c0f\u8c03\u6574\u5b66\u4e60\u7387\u4ee5\u51cf\u5f31\u4e0d\u53ef\u9760\u66f4\u65b0\u7684\u5f71\u54cd\uff1b(ii) \u5e94\u7528\u4e00\u79cd\u9488\u5bf9\u79bb\u7ebf\u7b56\u7565\u73af\u5883\u4e0b\u7684\u5c01\u95ed\u5f62\u5f0f\u6700\u5c0f\u65b9\u5dee\u57fa\u7ebf\uff0c\u907f\u514d\u4f7f\u7528\u8f85\u52a9\u4ef7\u503c\u6a21\u578b\u5e76\u4fdd\u6301\u8f83\u4f4e\u7684\u989d\u5916\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cVCPO\u5728\u5305\u62ec\u6570\u5b66\u3001\u4e00\u822c\u63a8\u7406\u53ca\u5de5\u5177\u4f7f\u7528\u5728\u5185\u7684\u591a\u4e2a\u4efb\u52a1\u4e0a\u5bf9\u4e8e\u5f02\u6b65\u8bad\u7ec3\u8868\u73b0\u51fa\u663e\u8457\u589e\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u8d85\u8d8a\u4e86\u4e00\u7cfb\u5217\u6db5\u76d6\u63a9\u7801/\u526a\u8f91\u7a33\u5b9a\u5668\u548c\u7b97\u6cd5\u53d8\u4f53\u7684\u57fa\u51c6\u65b9\u6cd5\u3002\u7279\u522b\u662f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u8fbe\u5230\u4e0e\u540c\u6b65\u8bad\u7ec3\u76f8\u540c\u6548\u679c\u7684\u540c\u65f6\uff0c\u5c06\u957f\u65f6\u95f4\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u4e0b\u7684\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u81f3\u539f\u6765\u768440%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u663e\u5f0f\u63a7\u5236\u7b56\u7565\u68af\u5ea6\u65b9\u5dee\u662f\u5b9e\u73b0\u5927\u89c4\u6a21\u53ef\u9760\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u3002VCPO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u6765\u7a33\u5b9aREINFORCE/GRPO\u98ce\u683c\u7b97\u6cd5\uff0c\u4ece\u800c\u4f7f\u5f97\u5b83\u4eec\u66f4\u9002\u5408\u5e94\u7528\u4e8e\u9700\u8981\u9ad8\u6548\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u7684\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2602.17633", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17633", "abs": "https://arxiv.org/abs/2602.17633", "authors": ["Shayan Kiyani", "Sima Noorani", "George Pappas", "Hamed Hassani"], "title": "When to Trust the Cheap Check: Weak and Strong Verification for Reasoning", "comment": null, "summary": "Reasoning with LLMs increasingly unfolds inside a broader verification loop. Internally, systems use cheap checks, such as self-consistency or proxy rewards, which we call weak verification. Externally, users inspect outputs and steer the model through feedback until results are trustworthy, which we call strong verification. These signals differ sharply in cost and reliability: strong verification can establish trust but is resource-intensive, while weak verification is fast and scalable but noisy and imperfect. We formalize this tension through weak--strong verification policies, which decide when to accept or reject based on weak verification and when to defer to strong verification. We introduce metrics capturing incorrect acceptance, incorrect rejection, and strong-verification frequency. Over population, we show that optimal policies admit a two-threshold structure and that calibration and sharpness govern the value of weak verifiers. Building on this, we develop an online algorithm that provably controls acceptance and rejection errors without assumptions on the query stream, the language model, or the weak verifier.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5f31\u9a8c\u8bc1\u4e0e\u5f3a\u9a8c\u8bc1\u7684\u4f7f\u7528\u7b56\u7565\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u5bf9\u67e5\u8be2\u6d41\u3001\u8bed\u8a00\u6a21\u578b\u6216\u5f31\u9a8c\u8bc1\u5668\u505a\u51fa\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u63a7\u5236\u63a5\u53d7\u548c\u62d2\u7edd\u9519\u8bef\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8d8a\u6765\u8d8a\u591a\u5730\u5d4c\u5165\u5230\u4e00\u4e2a\u66f4\u5e7f\u6cdb\u7684\u9a8c\u8bc1\u5faa\u73af\u4e2d\uff0c\u5982\u4f55\u5e73\u8861\u5185\u90e8\u5feb\u901f\u4f46\u4e0d\u5b8c\u5168\u53ef\u9760\u7684\u5f31\u9a8c\u8bc1\u4e0e\u5916\u90e8\u53ef\u9760\u4f46\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u5f3a\u9a8c\u8bc1\u6210\u4e3a\u4e86\u4e00\u4e2a\u4e9f\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u5f31-\u5f3a\u9a8c\u8bc1\u7b56\u7565\u6765\u51b3\u5b9a\u4f55\u65f6\u57fa\u4e8e\u5f31\u9a8c\u8bc1\u63a5\u53d7\u6216\u62d2\u7edd\u7ed3\u679c\uff0c\u4ee5\u53ca\u4f55\u65f6\u9700\u8981\u4f9d\u8d56\u4e8e\u5f3a\u9a8c\u8bc1\u3002\u5f15\u5165\u4e86\u8861\u91cf\u9519\u8bef\u63a5\u53d7\u3001\u9519\u8bef\u62d2\u7edd\u53ca\u5f3a\u9a8c\u8bc1\u9891\u7387\u7684\u6307\u6807\uff0c\u5e76\u5c55\u793a\u4e86\u6700\u4f18\u7b56\u7565\u5177\u6709\u53cc\u9608\u503c\u7ed3\u6784\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u7ebf\u7b97\u6cd5\u4ee5\u63a7\u5236\u63a5\u53d7\u548c\u62d2\u7edd\u9519\u8bef\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6821\u51c6\u5ea6\u548c\u6e05\u6670\u5ea6\u51b3\u5b9a\u4e86\u5f31\u9a8c\u8bc1\u5668\u7684\u4ef7\u503c\uff1b\u6240\u63d0\u51fa\u7684\u5728\u7ebf\u7b97\u6cd5\u80fd\u591f\u5728\u6ca1\u6709\u4efb\u4f55\u9884\u8bbe\u6761\u4ef6\u4e0b\u6709\u6548\u7ba1\u7406\u63a5\u53d7\u548c\u62d2\u7edd\u9519\u8bef\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u548c\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9a8c\u8bc1\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u7279\u522b\u662f\u5173\u4e8e\u5982\u4f55\u9ad8\u6548\u7ed3\u5408\u5f31\u9a8c\u8bc1\u4e0e\u5f3a\u9a8c\u8bc1\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2602.17634", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17634", "abs": "https://arxiv.org/abs/2602.17634", "authors": ["Xinghong Fu", "Yanhong Li", "Georgios Papaioannou", "Yoon Kim"], "title": "Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting", "comment": null, "summary": "Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent work on time series foundation modeling has focused on scaling. This has resulted in time series foundation models with hundreds of millions of parameters that are, while performant, inefficient and expensive to use in practice. This paper describes a simple recipe for learning efficient foundation models for zero-shot time series forecasting that are orders of magnitude smaller. We show that large-scale transformers are not necessary: small hybrid models that interleave long convolution and linear RNN layers (in particular DeltaNet layers) can match the performance of larger transformer-based models while being more than a hundred times smaller. We also describe several data augmentation and inference strategies that further improve performance. This recipe results in Reverso, a family of efficient time series foundation models for zero-shot forecasting that significantly push the performance-efficiency Pareto frontier.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b66\u4e60\u9ad8\u6548\u57fa\u7840\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002\u8fd9\u4e9b\u6a21\u578b\u6bd4\u5927\u578bTransformer\u6a21\u578b\u5c0f\u5f88\u591a\u500d\uff0c\u4f46\u901a\u8fc7\u7ed3\u5408\u957f\u5377\u79ef\u548c\u7ebf\u6027RNN\u5c42\uff08\u7279\u522b\u662fDeltaNet\u5c42\uff09\u80fd\u8fbe\u5230\u7c7b\u4f3c\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u66f4\u52a0\u7ecf\u6d4e\u5b9e\u7528\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u51e0\u79cd\u6570\u636e\u589e\u5f3a\u548c\u63a8\u7406\u7b56\u7565\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u89c4\u6a21Transformer\u5728\u5176\u4ed6\u6a21\u6001\u5982\u8bed\u8a00\u548c\u89c6\u89c9\u4e0a\u5c55\u793a\u4e86\u901a\u8fc7\u6269\u5c55\u63d0\u9ad8\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9886\u57df\uff0c\u6784\u5efa\u5177\u6709\u6570\u4ebf\u53c2\u6570\u7684\u57fa\u7840\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u5374\u975e\u5e38\u4f4e\u6548\u4e14\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u89c4\u6a21\u66f4\u5c0f\u4f46\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6df7\u5408\u6a21\u578b\u4ea4\u66ff\u4f7f\u7528\u957f\u5377\u79ef\u4e0e\u7ebf\u6027RNN\u5c42\uff08\u7279\u522b\u662fDeltaNet\u5c42\uff09\uff0c\u4ee5\u5b9e\u73b0\u4e0e\u8f83\u5927\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6a21\u578b\u5927\u5c0f\u4ec5\u4e3a\u540e\u8005\u7684\u767e\u5206\u4e4b\u4e00\u3002\u53e6\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u51e0\u79cd\u6570\u636e\u589e\u5f3a\u53ca\u63a8\u7406\u7b56\u7565\uff0c\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5c0f\u578b\u6df7\u5408\u6a21\u578b\u80fd\u591f\u5728\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u7684\u540c\u65f6\u5339\u914d\u5927\u578bTransformer\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e14\u6548\u7387\u66f4\u9ad8\u3002\u63d0\u51fa\u7684Reverso\u6a21\u578b\u5bb6\u65cf\u5728\u63a8\u8fdb\u6027\u80fd-\u6548\u7387\u5e15\u7d2f\u6258\u524d\u6cbf\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u96f6\u6837\u672c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u800c\u8a00\uff0c\u4e0d\u9700\u8981\u4f9d\u8d56\u4e8e\u5927\u89c4\u6a21\u7684Transformer\u67b6\u6784\uff1b\u901a\u8fc7\u91c7\u7528\u7279\u5b9a\u8bbe\u8ba1\u7684\u5c0f\u578b\u6df7\u5408\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u8fbe\u5230\u76f8\u4f3c\u751a\u81f3\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u6781\u5927\u5730\u964d\u4f4e\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6210\u672c\u4e0e\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2602.17642", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17642", "abs": "https://arxiv.org/abs/2602.17642", "authors": ["Dhruv Talwar", "Harsh Desai", "Wendong Yin", "Goutam Mohanty", "Rafael Reveles"], "title": "A.R.I.S.: Automated Recycling Identification System for E-Waste Classification Using Deep Learning", "comment": null, "summary": "Traditional electronic recycling processes suffer from significant resource loss due to inadequate material separation and identification capabilities, limiting material recovery. We present A.R.I.S. (Automated Recycling Identification System), a low-cost, portable sorter for shredded e-waste that addresses this efficiency gap. The system employs a YOLOx model to classify metals, plastics, and circuit boards in real time, achieving low inference latency with high detection accuracy. Experimental evaluation yielded 90% overall precision, 82.2% mean average precision (mAP), and 84% sortation purity. By integrating deep learning with established sorting methods, A.R.I.S. enhances material recovery efficiency and lowers barriers to advanced recycling adoption. This work complements broader initiatives in extending product life cycles, supporting trade-in and recycling programs, and reducing environmental impact across the supply chain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aA.R.I.S.\u7684\u4f4e\u6210\u672c\u4fbf\u643a\u5f0f\u7535\u5b50\u5e9f\u7269\u5206\u62e3\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408YOLOx\u6a21\u578b\u5b9e\u73b0\u5b9e\u65f6\u5206\u7c7b\u91d1\u5c5e\u3001\u5851\u6599\u548c\u7535\u8def\u677f\u6750\u6599\uff0c\u63d0\u9ad8\u4e86\u56de\u6536\u6548\u7387\u548c\u5206\u7c7b\u7eaf\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7535\u5b50\u56de\u6536\u8fc7\u7a0b\u56e0\u6750\u6599\u5206\u79bb\u548c\u8bc6\u522b\u80fd\u529b\u4e0d\u8db3\u800c\u5bfc\u81f4\u8d44\u6e90\u635f\u5931\u4e25\u91cd\uff0c\u9650\u5236\u4e86\u6750\u6599\u56de\u6536\u7387\u3002", "method": "\u5f00\u53d1\u4e86A.R.I.S.\uff08\u81ea\u52a8\u5316\u56de\u6536\u8bc6\u522b\u7cfb\u7edf\uff09\uff0c\u4e00\u79cd\u4f4e\u6210\u672c\u4e14\u4fbf\u643a\u5f0f\u7684\u788e\u7535\u5b50\u5e9f\u6599\u5206\u9009\u5668\uff0c\u5229\u7528YOLOx\u6a21\u578b\u5b9e\u65f6\u5206\u7c7b\u91d1\u5c5e\u3001\u5851\u6599\u548c\u7535\u8def\u677f\uff0c\u5e76\u8fbe\u5230\u4f4e\u63a8\u7406\u5ef6\u8fdf\u4e0e\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u6574\u4f53\u7cbe\u5ea6\u4e3a90%\uff0c\u5e73\u5747\u7cbe\u5ea6\u5747\u503c(mAP)\u4e3a82.2%\uff0c\u4ee5\u53ca84%\u7684\u5206\u9009\u7eaf\u51c0\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u73b0\u6709\u5206\u62e3\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0cA.R.I.S.\u63d0\u9ad8\u4e86\u6750\u6599\u56de\u6536\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u91c7\u7528\u5148\u8fdb\u56de\u6536\u6280\u672f\u7684\u95e8\u69db\uff0c\u652f\u6301\u4ea7\u54c1\u751f\u547d\u5468\u671f\u5ef6\u957f\u3001\u6362\u8d2d\u53ca\u56de\u6536\u8ba1\u5212\u7b49\u66f4\u5e7f\u6cdb\u7684\u4e3e\u63aa\u4ee5\u51cf\u5c11\u4f9b\u5e94\u94fe\u4e2d\u7684\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2602.17645", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17645", "abs": "https://arxiv.org/abs/2602.17645", "authors": ["Xiaohan Zhao", "Zhaoyi Li", "Yaxin Luo", "Jiacheng Cui", "Zhiqiang Shen"], "title": "Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting", "comment": "Code at: https://github.com/vila-lab/M-Attack-V2", "summary": "Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5M-Attack-V2\uff0c\u901a\u8fc7\u5f15\u5165\u591a\u88c1\u526a\u5bf9\u9f50\uff08MCA\uff09\u548c\u8f85\u52a9\u76ee\u6807\u5bf9\u9f50\uff08ATA\uff09\u7b49\u6280\u672f\u6765\u51cf\u5c11\u68af\u5ea6\u65b9\u5dee\u3001\u5e73\u6ed1\u76ee\u6807\u6d41\u5f62\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u9488\u5bf9\u524d\u6cbf\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u6210\u529f\u653b\u51fb\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8f6c\u79fb\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u65f6\u5b58\u5728\u9ad8\u65b9\u5dee\u3001\u51e0\u4e4e\u6b63\u4ea4\u7684\u68af\u5ea6\u95ee\u9898\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5c40\u90e8\u5bf9\u9f50\u4e0d\u7a33\u5b9a\u548c\u4f18\u5316\u56f0\u96be\u3002\u8fd9\u4e9b\u95ee\u9898\u4e3b\u8981\u5f52\u56e0\u4e8eViT\u5bf9\u4e8e\u7ffb\u8bd1\u654f\u611f\u4ee5\u53ca\u6e90\u4e0e\u76ee\u6807\u88c1\u526a\u4e4b\u95f4\u7684\u7ed3\u6784\u4e0d\u5bf9\u79f0\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86M-Attack-V2\uff0c\u4e00\u4e2a\u57fa\u4e8eM-Attack\u5347\u7ea7\u7248\u7684\u65b9\u6cd5\u3002\u5b83\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u591a\u88c1\u526a\u5bf9\u9f50(Multi-Crop Alignment, MCA)\uff0c\u901a\u8fc7\u5e73\u5747\u6765\u81ea\u591a\u4e2a\u72ec\u7acb\u91c7\u6837\u5c40\u90e8\u89c6\u56fe\u7684\u68af\u5ea6\u4ee5\u51cf\u5c11\u65b9\u5dee\uff1b2) \u8f85\u52a9\u76ee\u6807\u5bf9\u9f50(Auxiliary Target Alignment, ATA)\uff0c\u7528\u8bed\u4e49\u76f8\u5173\u5206\u5e03\u7684\u5c0f\u578b\u8f85\u52a9\u96c6\u66ff\u6362\u6fc0\u8fdb\u7684\u76ee\u6807\u589e\u5f3a\uff0c\u4ece\u800c\u751f\u6210\u66f4\u5e73\u6ed1\u3001\u66f4\u4f4e\u65b9\u5dee\u7684\u76ee\u6807\u6d41\u5f62\u3002\u6b64\u5916\uff0c\u8fd8\u91cd\u65b0\u89e3\u91ca\u4e86\u52a8\u91cf\u4f5c\u4e3aPatch Momentum\uff0c\u56de\u653e\u5386\u53f2\u88c1\u526a\u68af\u5ea6\uff1b\u7ed3\u5408\u7cbe\u70bc\u7684\u8865\u4e01\u5927\u5c0f\u96c6\u6210(PE+)\uff0c\u8fdb\u4e00\u6b65\u52a0\u5f3a\u53ef\u4f20\u9012\u65b9\u5411\u3002", "result": "M-Attack-V2\u5728\u591a\u79cd\u5148\u8fdb\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u6210\u529f\u653b\u51fb\u7387\uff0c\u6bd4\u5982\u5c06Claude-4.0\u4e0a\u7684\u6210\u529f\u7387\u4ece8%\u63d0\u5347\u5230\u4e8630%\uff0cGemini-2.5-Pro\u4ece83%\u523097%\uff0cGPT-5\u5219\u4ece98%\u8fbe\u5230\u4e86100%\uff0c\u8d85\u8fc7\u4e86\u4e4b\u524d\u6240\u6709\u9488\u5bf9LVLMs\u7684\u9ed1\u76d2\u653b\u51fb\u8868\u73b0\u3002", "conclusion": "M-Attack-V2\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u4e14\u6a21\u5757\u5316\u7684\u6539\u8fdb\u65b9\u6848\uff0c\u5728\u51cf\u5c11\u68af\u5ea6\u566a\u58f0\u3001\u63d0\u9ad8\u5c40\u90e8\u5339\u914d\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u6700\u65b0\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2602.17646", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17646", "abs": "https://arxiv.org/abs/2602.17646", "authors": ["Sima Noorani", "Shayan Kiyani", "Hamed Hassani", "George Pappas"], "title": "Multi-Round Human-AI Collaboration with User-Specified Requirements", "comment": null, "summary": "As humans increasingly rely on multiround conversational AI for high stakes decisions, principled frameworks are needed to ensure such interactions reliably improve decision quality. We adopt a human centric view governed by two principles: counterfactual harm, ensuring the AI does not undermine human strengths, and complementarity, ensuring it adds value where the human is prone to err. We formalize these concepts via user defined rules, allowing users to specify exactly what harm and complementarity mean for their specific task. We then introduce an online, distribution free algorithm with finite sample guarantees that enforces the user-specified constraints over the collaboration dynamics. We evaluate our framework across two interactive settings: LLM simulated collaboration on a medical diagnostic task and a human crowdsourcing study on a pictorial reasoning task. We show that our online procedure maintains prescribed counterfactual harm and complementarity violation rates even under nonstationary interaction dynamics. Moreover, tightening or loosening these constraints produces predictable shifts in downstream human accuracy, confirming that the two principles serve as practical levers for steering multi-round collaboration toward better decision quality without the need to model or constrain human behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u4e2d\u5fc3\u89c6\u89d2\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u786e\u4fddAI\u4e0d\u524a\u5f31\u4eba\u7c7b\u4f18\u52bf\uff08\u53cd\u4e8b\u5b9e\u4f24\u5bb3\u539f\u5219\uff09\u548c\u5728\u4eba\u7c7b\u6613\u51fa\u9519\u7684\u5730\u65b9\u589e\u52a0\u4ef7\u503c\uff08\u4e92\u8865\u6027\u539f\u5219\uff09\u6765\u63d0\u9ad8\u591a\u8f6e\u5bf9\u8bddAI\u51b3\u7b56\u7684\u8d28\u91cf\u3002\u8be5\u6846\u67b6\u5141\u8bb8\u7528\u6237\u5b9a\u4e49\u89c4\u5219\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5728\u7ebf\u3001\u65e0\u5206\u5e03\u7b97\u6cd5\u4ee5\u4fdd\u8bc1\u7528\u6237\u6307\u5b9a\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u5408\u4f5c\u52a8\u6001\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u975e\u5e73\u7a33\u4ea4\u4e92\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4e5f\u80fd\u4fdd\u6301\u89c4\u5b9a\u7684\u53cd\u4e8b\u5b9e\u4f24\u5bb3\u548c\u4e92\u8865\u6027\u8fdd\u89c4\u7387\uff0c\u5e76\u4e14\u8c03\u6574\u8fd9\u4e9b\u7ea6\u675f\u53ef\u4ee5\u9884\u6d4b\u6027\u5730\u6539\u53d8\u6700\u7ec8\u7684\u4eba\u7c7b\u51c6\u786e\u6027\uff0c\u4ece\u800c\u5728\u4e0d\u9700\u8981\u5efa\u6a21\u6216\u9650\u5236\u4eba\u7c7b\u884c\u4e3a\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u51b3\u7b56\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u4eba\u4eec\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u591a\u8f6e\u5bf9\u8bddAI\u8fdb\u884c\u91cd\u8981\u51b3\u7b56\uff0c\u9700\u8981\u6709\u539f\u5219\u6027\u7684\u6846\u67b6\u6765\u786e\u4fdd\u8fd9\u79cd\u4e92\u52a8\u53ef\u9760\u5730\u6539\u5584\u51b3\u7b56\u8d28\u91cf\u3002\u672c\u6587\u4ece\u4ee5\u4eba\u4e3a\u672c\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u63d0\u51fa\u4e86\u4e24\u4e2a\u539f\u5219\uff1a\u53cd\u4e8b\u5b9e\u4f24\u5bb3\uff08\u786e\u4fddAI\u4e0d\u4f1a\u524a\u5f31\u4eba\u7c7b\u7684\u4f18\u52bf\uff09\u548c\u4e92\u8865\u6027\uff08\u786e\u4fddAI\u80fd\u5728\u4eba\u7c7b\u5bb9\u6613\u51fa\u9519\u7684\u5730\u65b9\u589e\u52a0\u4ef7\u503c\uff09\u3002", "method": "\u672c\u6587\u9996\u5148\u5c06\u8fd9\u4e24\u4e2a\u6982\u5ff5\u901a\u8fc7\u7528\u6237\u81ea\u5b9a\u4e49\u89c4\u5219\u7684\u5f62\u5f0f\u5316\u8868\u8fbe\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u660e\u786e\u5b9a\u4e49\u4ec0\u4e48\u662f\u4f24\u5bb3\u4e0e\u4e92\u8865\u6027\u3002\u63a5\u7740\uff0c\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5728\u7ebf\u4e14\u65e0\u9700\u4e8b\u5148\u77e5\u9053\u6570\u636e\u5206\u5e03\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u5408\u4f5c\u8fc7\u7a0b\u4e2d\u5f3a\u5236\u6267\u884c\u7528\u6237\u8bbe\u5b9a\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u5e76\u4e14\u5bf9\u6837\u672c\u6570\u91cf\u6709\u9650\u7684\u60c5\u51b5\u7ed9\u51fa\u4e86\u6027\u80fd\u4fdd\u8bc1\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u79cd\u4e92\u52a8\u573a\u666f\u2014\u2014\u533b\u5b66\u8bca\u65ad\u4efb\u52a1\u4e0a\u7684LLM\u6a21\u62df\u534f\u4f5c\u4ee5\u53ca\u4e00\u9879\u56fe\u5f62\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4eba\u7fa4\u5916\u5305\u7814\u7a76\u2014\u2014\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5373\u4f7f\u5728\u4ea4\u4e92\u52a8\u6001\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u5728\u7ebf\u8fc7\u7a0b\u4e5f\u80fd\u591f\u7ef4\u6301\u9884\u5b9a\u7684\u53cd\u4e8b\u5b9e\u4f24\u5bb3\u53ca\u4e92\u8865\u6027\u8fdd\u89c4\u6bd4\u7387\u3002\u6b64\u5916\uff0c\u8c03\u6574\u8fd9\u4e9b\u7ea6\u675f\u6761\u4ef6\u4f1a\u5bfc\u81f4\u4e0b\u6e38\u4eba\u7c7b\u51c6\u786e\u6027\u7684\u53ef\u9884\u89c1\u53d8\u52a8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u63a7\u5236\u53cd\u4e8b\u5b9e\u4f24\u5bb3\u548c\u4e92\u8865\u6027\u539f\u5219\uff0c\u53ef\u4ee5\u5728\u4e0d\u76f4\u63a5\u5efa\u6a21\u6216\u9650\u5236\u4eba\u7c7b\u884c\u4e3a\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u5730\u5f15\u5bfc\u591a\u8f6e\u6b21\u534f\u4f5c\u671d\u7740\u66f4\u597d\u7684\u51b3\u7b56\u8d28\u91cf\u53d1\u5c55\u3002"}}
{"id": "2602.17658", "categories": ["cs.LG", "cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.17658", "abs": "https://arxiv.org/abs/2602.17658", "authors": ["Payel Bhattacharjee", "Osvaldo Simeone", "Ravi Tandon"], "title": "MARS: Margin-Aware Reward-Modeling with Self-Refinement", "comment": null, "summary": "Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMARS\u7684\u81ea\u9002\u5e94\u3001\u8fb9\u754c\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u548c\u91c7\u6837\u7b56\u7565\uff0c\u4e13\u95e8\u9488\u5bf9\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u6a21\u7cca\u548c\u5931\u8d25\u6a21\u5f0f\u3002\u901a\u8fc7\u5728\u4f4e\u8fb9\u754c\uff08\u5373\u6a21\u578b\u6700\u4e0d\u786e\u5b9a\u7684\uff09\u504f\u597d\u5bf9\u4e0a\u96c6\u4e2d\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u5e76\u901a\u8fc7\u56f0\u96be\u6837\u672c\u589e\u5f3a\u6765\u8fed\u4ee3\u4f18\u5316\u8bad\u7ec3\u5206\u5e03\uff0c\u4ece\u800c\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u901a\u5e38\u5728\u8868\u793a\u6216\u8bed\u4e49\u5c42\u9762\u64cd\u4f5c\uff0c\u5ffd\u7565\u4e86\u5956\u52b1\u6a21\u578b\u4f30\u8ba1\u96be\u5ea6\u7684\u95ee\u9898\u3002\u7531\u4e8e\u8bad\u7ec3\u53ef\u9760\u7684\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u4e8e\u6602\u8d35\u4e14\u6709\u9650\u7684\u4eba\u7c7b\u6807\u6ce8\u504f\u597d\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86MARS\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u7684\u3001\u8fb9\u754c\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u4e0e\u91c7\u6837\u7b56\u7565\uff0c\u7279\u522b\u5173\u6ce8\u5956\u52b1\u6a21\u578b\u4e2d\u4e0d\u786e\u5b9a\u6027\u6700\u9ad8\u7684\u4f4e\u8fb9\u754c\u504f\u597d\u5bf9\uff0c\u5e76\u901a\u8fc7\u56f0\u96be\u6837\u672c\u589e\u5f3a\u6280\u672f\u8fed\u4ee3\u5730\u6539\u8fdb\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u589e\u52a0\u635f\u5931\u51fd\u6570\u7684\u5e73\u5747\u66f2\u7387\uff0c\u8fdb\u800c\u63d0\u9ad8\u4fe1\u606f\u91cf\u5e76\u6539\u5584\u6761\u4ef6\uff1b\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u663e\u793a\uff0c\u4e0e\u5747\u5300\u589e\u5f3a\u76f8\u6bd4\uff0cMARS\u5728\u9c81\u68d2\u5956\u52b1\u5efa\u6a21\u65b9\u9762\u5177\u6709\u6301\u7eed\u7684\u4f18\u52bf\u3002", "conclusion": "MARS\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u6a21\u7cca\u6027\u548c\u5931\u8d25\u60c5\u51b5\uff0c\u4e3a\u5b9e\u73b0\u66f4\u53ef\u9760\u548c\u9c81\u68d2\u7684\u5956\u52b1\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
