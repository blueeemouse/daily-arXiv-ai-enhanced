{"id": "2512.08526", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.08526", "abs": "https://arxiv.org/abs/2512.08526", "authors": ["Shunit Agmon", "Jonathan Gal", "Amir Gilad", "Ester Livshits", "Or Mutay", "Brit Youngmann", "Benny Kimelfeld"], "title": "Analyzing Deviations from Monotonic Trends through Database Repair", "comment": null, "summary": "Datasets often exhibit violations of expected monotonic trends - for example, higher education level correlating with higher average salary, newer homes being more expensive, or diabetes prevalence increasing with age. We address the problem of quantifying how far a dataset deviates from such trends. To this end, we introduce Aggregate Order Dependencies (AODs), an aggregation-centric extension of the previously studied order dependencies. An AOD specifies that the aggregated value of a target attribute (e.g., mean salary) should monotonically increase or decrease with the grouping attribute (e.g., education level).\n  We formulate the AOD repair problem as finding the smallest set of tuples to delete from a table so that the given AOD is satisfied. We analyze the computational complexity of this problem and propose a general algorithmic template for solving it. We instantiate the template for common aggregation functions, introduce optimization techniques that substantially improve the runtime of the template instances, and develop efficient heuristic alternatives. Our experimental study, carried out on both real-world and synthetic datasets, demonstrates the practical efficiency of the algorithms and provides insight into the performance of the heuristics. We also present case studies that uncover and explain unexpected AOD violations using our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u805a\u5408\u987a\u5e8f\u4f9d\u8d56\uff08AODs\uff09\u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u91cf\u5316\u6570\u636e\u96c6\u504f\u79bb\u9884\u671f\u5355\u8c03\u8d8b\u52bf\u7684\u7a0b\u5ea6\uff0c\u5e76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5220\u9664\u6700\u5c11\u6570\u91cf\u7684\u5143\u7ec4\u6765\u4fee\u590dAOD\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "motivation": "\u6570\u636e\u96c6\u4e2d\u7ecf\u5e38\u51fa\u73b0\u8fdd\u53cd\u9884\u671f\u5355\u8c03\u8d8b\u52bf\u7684\u60c5\u51b5\uff0c\u6bd4\u5982\u66f4\u9ad8\u7684\u6559\u80b2\u6c34\u5e73\u4e0e\u5e73\u5747\u5de5\u8d44\u6210\u6b63\u6bd4\u7b49\u3002\u672c\u6587\u65e8\u5728\u91cf\u5316\u6570\u636e\u96c6\u504f\u79bb\u8fd9\u79cd\u8d8b\u52bf\u7684\u7a0b\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5b9a\u4e49\u4e86\u805a\u5408\u987a\u5e8f\u4f9d\u8d56(AODs)\uff0c\u4f5c\u4e3a\u4e4b\u524d\u7814\u7a76\u7684\u987a\u5e8f\u4f9d\u8d56\u6027\u7684\u4ee5\u805a\u5408\u4e3a\u4e2d\u5fc3\u7684\u6269\u5c55\u3002\u5c06AOD\u4fee\u590d\u95ee\u9898\u5b9a\u4e49\u4e3a\u4ece\u8868\u4e2d\u627e\u5230\u8981\u5220\u9664\u7684\u6700\u5c0f\u5143\u7ec4\u96c6\u5408\uff0c\u4ee5\u4fbf\u6ee1\u8db3\u7ed9\u5b9a\u7684AOD\u3002\u5206\u6790\u4e86\u8be5\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7b97\u6cd5\u6a21\u677f\u6765\u89e3\u51b3\u5b83\u3002", "result": "\u5b9e\u9a8c\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u662f\u9ad8\u6548\u7684\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u5173\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u6027\u80fd\u7684\u89c1\u89e3\u3002\u6848\u4f8b\u7814\u7a76\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u8be5\u6846\u67b6\u53d1\u73b0\u548c\u89e3\u91ca\u610f\u5916\u7684AOD\u8fdd\u89c4\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165AODs\u6982\u5ff5\u4ee5\u53ca\u5f00\u53d1\u76f8\u5173\u7b97\u6cd5\u548c\u4f18\u5316\u6280\u672f\uff0c\u672c\u6587\u4e3a\u7406\u89e3\u548c\u4fee\u6b63\u6570\u636e\u96c6\u4e2d\u8fdd\u53cd\u5355\u8c03\u8d8b\u52bf\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2512.08679", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.08679", "abs": "https://arxiv.org/abs/2512.08679", "authors": ["Tal Blau", "Brit Youngmann", "Anna Fariha", "Yuval Moskovitch"], "title": "Causal Explanations for Disparate Trends: Where and Why?", "comment": null, "summary": "During data analysis, we are often perplexed by certain disparities observed between two groups of interest within a dataset. To better understand an observed disparity, we need explanations that can pinpoint the data regions where the disparity is most pronounced, along with its causes, i.e., factors that alleviate or exacerbate the disparity. This task is complex and tedious, particularly for large and high-dimensional datasets, demanding an automatic system for discovering explanations (data regions and causes) of an observed disparity. It is critical that explanations for disparities are not only interpretable but also actionable-enabling users to make informed, data-driven decisions. This requires explanations to go beyond surface-level correlations and instead capture causal relationships. We introduce ExDis, a framework for discovering causal Explanations for Disparities between two groups of interest. ExDis identifies data regions (subpopulations) where disparities are most pronounced (or reversed), and associates specific factors that causally contribute to the disparity within each identified data region. We formally define the ExDis framework and the associated optimization problem, analyze its complexity, and develop an efficient algorithm to solve the problem. Through extensive experiments over three real-world datasets, we demonstrate that ExDis generates meaningful causal explanations, outperforms prior methods, and scales effectively to handle large, high-dimensional datasets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aExDis\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u4e24\u7ec4\u5174\u8da3\u4e4b\u95f4\u5dee\u5f02\u7684\u56e0\u679c\u89e3\u91ca\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u8bc6\u522b\u5dee\u5f02\u6700\u663e\u8457\u7684\u6570\u636e\u533a\u57df\uff08\u5b50\u7fa4\u4f53\uff09\uff0c\u8fd8\u80fd\u5173\u8054\u5728\u6bcf\u4e2a\u5df2\u8bc6\u522b\u6570\u636e\u533a\u57df\u5185\u5bf9\u5dee\u5f02\u6709\u56e0\u679c\u8d21\u732e\u7684\u5177\u4f53\u56e0\u7d20\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0cExDis\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u7684\u56e0\u679c\u89e3\u91ca\uff0c\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u5730\u6269\u5c55\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u3001\u9ad8\u7ef4\u5ea6\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u5728\u6570\u636e\u5206\u6790\u8fc7\u7a0b\u4e2d\uff0c\u89c2\u5bdf\u5230\u7684\u6570\u636e\u96c6\u4e2d\u4e24\u7ec4\u5174\u8da3\u4e4b\u95f4\u7684\u67d0\u4e9b\u5dee\u5f02\u5e38\u5e38\u4ee4\u4eba\u56f0\u60d1\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u89c2\u5bdf\u5230\u7684\u5dee\u5f02\uff0c\u9700\u8981\u80fd\u591f\u6307\u51fa\u5dee\u5f02\u6700\u4e3a\u663e\u8457\u7684\u6570\u636e\u533a\u57df\u53ca\u5176\u539f\u56e0\u7684\u89e3\u91ca\uff0c\u5373\u7f13\u89e3\u6216\u52a0\u5267\u5dee\u5f02\u7684\u56e0\u7d20\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u578b\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u6765\u8bf4\uff0c\u8fd9\u662f\u4e00\u9879\u590d\u6742\u800c\u7e41\u7410\u7684\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u81ea\u52a8\u7cfb\u7edf\u6765\u53d1\u73b0\u89c2\u5bdf\u5230\u7684\u5dee\u5f02\u7684\u539f\u56e0\uff08\u6570\u636e\u533a\u57df\u548c\u56e0\u7d20\uff09\u3002\u91cd\u8981\u7684\u662f\uff0c\u5bf9\u4e8e\u5dee\u5f02\u7684\u89e3\u91ca\u4e0d\u4ec5\u8981\u53ef\u89e3\u8bfb\uff0c\u800c\u4e14\u8fd8\u8981\u53ef\u64cd\u4f5c\u6027\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u505a\u51fa\u660e\u667a\u7684\u3001\u57fa\u4e8e\u6570\u636e\u7684\u51b3\u7b56\u3002\u8fd9\u5c31\u8981\u6c42\u89e3\u91ca\u8d85\u8d8a\u8868\u9762\u7684\u76f8\u5173\u6027\uff0c\u800c\u662f\u6355\u6349\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86ExDis\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u4e24\u7ec4\u5174\u8da3\u95f4\u5dee\u5f02\u7684\u56e0\u679c\u89e3\u91ca\u3002\u8be5\u6846\u67b6\u8bbe\u8ba1\u4e86\u76f8\u5173\u4f18\u5316\u95ee\u9898\u5e76\u5206\u6790\u5176\u590d\u6742\u6027\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002ExDis\u53ef\u4ee5\u8bc6\u522b\u5dee\u5f02\u6700\u663e\u8457\uff08\u6216\u9006\u8f6c\uff09\u7684\u6570\u636e\u533a\u57df\uff08\u5b50\u7fa4\u4f53\uff09\uff0c\u5e76\u786e\u5b9a\u5728\u6bcf\u4e2a\u5df2\u8bc6\u522b\u6570\u636e\u533a\u57df\u5185\u5bf9\u5dee\u5f02\u4ea7\u751f\u56e0\u679c\u5f71\u54cd\u7684\u5177\u4f53\u56e0\u7d20\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cExDis\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u7684\u56e0\u679c\u89e3\u91ca\uff0c\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u6269\u5c55\u4ee5\u5e94\u5bf9\u5927\u578b\u3001\u9ad8\u7ef4\u5ea6\u6570\u636e\u96c6\u3002", "conclusion": "ExDis\u6846\u67b6\u4e3a\u7406\u89e3\u6570\u636e\u4e2d\u4e24\u7ec4\u95f4\u7684\u5dee\u5f02\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u51c6\u786e\u5730\u5b9a\u4f4d\u5dee\u5f02\u6700\u5927\u7684\u6570\u636e\u533a\u57df\uff0c\u8fd8\u80fd\u591f\u63ed\u793a\u9020\u6210\u8fd9\u79cd\u5dee\u5f02\u80cc\u540e\u7684\u56e0\u679c\u56e0\u7d20\uff0c\u4ece\u800c\u5e2e\u52a9\u7528\u6237\u6839\u636e\u6570\u636e\u9a71\u52a8\u505a\u51fa\u66f4\u660e\u667a\u7684\u51b3\u7b56\u3002"}}
{"id": "2510.00002", "categories": ["cs.SE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.00002", "abs": "https://arxiv.org/abs/2510.00002", "authors": ["Dong Liu"], "title": "Formally and Empirically Verified Methodologies for Scalable Hierarchical Full-Stack Systems", "comment": "Significant revision: refined paper structure, updated FDR 4.2.7 machine-checked CSP models, strengthened LTL-based correctness verification, and incorporated a detailed description of the enterprise-grade experimental environment", "summary": "This paper introduces Primary Breadth-First Development (PBFD) and Primary Depth-First Development (PDFD)-formally and empirically verified methodologies for scalable, industrial-grade full-stack software engineering. Both approaches enforce structural and behavioral correctness through graph-theoretic modeling, bridging formal methods and real-world practice. PBFD and PDFD model software development as layered directed graphs with unified state machines, verified using Communicating Sequential Processes (CSP) and Linear Temporal Logic (LTL). This guarantees bounded-refinement termination, deadlock freedom, and structural completeness. To manage hierarchical data at scale, we present the Three-Level Encapsulation (TLE)-a novel bitmask-based encoding scheme. TLE operations are verified via CSP failures-divergences refinement, ensuring constant-time updates and compact storage that underpin PBFD's robust performance. PBFD demonstrates exceptional industrial viability through eight years of enterprise deployment with zero critical failures, achieving approximately 20x faster develop-ment than Salesforce OmniScript, 7-8x faster query performance, and 11.7x storage reduction compared to conventional relational models. These results are established through longitudinal observational studies, quasi-experimental runtime comparisons, and controlled schema-level experiments. Open-source Minimum Viable Product implementations validate key behavioral properties, including bounded refinement and constant-time bitmask operations, un-der reproducible conditions. All implementations, formal specifications, and non-proprietary datasets are publicly available.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e24\u79cd\u5f62\u5f0f\u4e0a\u548c\u7ecf\u9a8c\u4e0a\u90fd\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\uff1a\u521d\u7ea7\u5e7f\u5ea6\u4f18\u5148\u5f00\u53d1\uff08PBFD\uff09\u548c\u521d\u7ea7\u6df1\u5ea6\u4f18\u5148\u5f00\u53d1\uff08PDFD\uff09\uff0c\u5b83\u4eec\u901a\u8fc7\u56fe\u8bba\u5efa\u6a21\u6765\u4fdd\u8bc1\u8f6f\u4ef6\u7ed3\u6784\u548c\u884c\u4e3a\u7684\u6b63\u786e\u6027\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e09\u7ea7\u5c01\u88c5\uff08TLE\uff09\u4f4d\u63a9\u7801\u7f16\u7801\u65b9\u6848\u4ee5\u9ad8\u6548\u7ba1\u7406\u5927\u89c4\u6a21\u5c42\u6b21\u6570\u636e\u3002PBFD\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\u5177\u6709\u66f4\u5feb\u7684\u5f00\u53d1\u901f\u5ea6\u3001\u67e5\u8be2\u6027\u80fd\u548c\u66f4\u5c11\u7684\u5b58\u50a8\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5168\u6808\u8f6f\u4ef6\u5de5\u7a0b\u7684\u53ef\u6269\u5c55\u6027\u548c\u5de5\u4e1a\u7ea7\u5e94\u7528\uff0c\u540c\u65f6\u786e\u4fdd\u8f6f\u4ef6\u67b6\u6784\u548c\u884c\u4e3a\u4e0a\u7684\u6b63\u786e\u6027\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0e\u5b9e\u9645\u5e94\u7528\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u521d\u7ea7\u5e7f\u5ea6\u4f18\u5148\u5f00\u53d1(PBFD) \u548c\u521d\u7ea7\u6df1\u5ea6\u4f18\u5148\u5f00\u53d1(PDFD) \u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u56fe\u8bba\u5efa\u6a21\u6280\u672f\u5c06\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u8868\u793a\u4e3a\u5206\u5c42\u6709\u5411\u56fe\u53ca\u7edf\u4e00\u72b6\u6001\u673a\u3002\u5f15\u5165\u4e86\u57fa\u4e8e\u4f4d\u63a9\u7801\u7684\u4e09\u7ea7\u5c01\u88c5(TLE) \u7f16\u7801\u65b9\u6848\u7528\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u5c42\u7ea7\u6570\u636e\u3002", "result": "PBFD\u65b9\u6cd5\u5728\u516b\u5e74\u4f01\u4e1a\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u672a\u53d1\u751f\u4efb\u4f55\u91cd\u5927\u6545\u969c\uff0c\u5176\u5f00\u53d1\u901f\u5ea6\u6bd4Salesforce OmniScript\u5feb\u7ea620\u500d\uff0c\u67e5\u8be2\u6027\u80fd\u63d0\u9ad87-8\u500d\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u5173\u7cfb\u578b\u6a21\u578b\u5b58\u50a8\u9700\u6c42\u51cf\u5c11\u4e8611.7\u500d\u3002\u8fd9\u4e9b\u6210\u679c\u901a\u8fc7\u957f\u671f\u89c2\u5bdf\u7814\u7a76\u3001\u51c6\u5b9e\u9a8c\u8fd0\u884c\u65f6\u6bd4\u8f83\u4ee5\u53ca\u63a7\u5236\u7ec4\u6a21\u5f0f\u7ea7\u522b\u5b9e\u9a8c\u5f97\u5230\u8bc1\u5b9e\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u7528PBFD\u6216PDFD\u7b49\u521b\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u5728\u5f00\u53d1\u6548\u7387\u3001\u6267\u884c\u6027\u80fd\u4ee5\u53ca\u8d44\u6e90\u5229\u7528\u65b9\u9762\u7684\u8868\u73b0\u3002\u5f00\u653e\u6e90\u4ee3\u7801MVP\u5b9e\u73b0\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.07846", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07846", "abs": "https://arxiv.org/abs/2512.07846", "authors": ["Guoyao Li", "Ran He", "Shusen Jing", "Kayhan Behdin", "Yubo Wang", "Sundara Raman Ramachandran", "Chanh Nguyen", "Jian Sheng", "Xiaojing Ma", "Chuanrui Zhu", "Sriram Vasudevan", "Muchen Wu", "Sayan Ghosh", "Lin Su", "Qingquan Song", "Xiaoqing Wang", "Zhipeng Wang", "Qing Lan", "Yanning Chen", "Jingwei Wu", "Luke Simon", "Wenjing Zhang", "Qi Guo", "Fedor Borisyuk"], "title": "MixLM: High-Throughput and Effective LLM Ranking via Text-Embedding Mix-Interaction", "comment": null, "summary": "Large language models (LLMs) excel at capturing semantic nuances and therefore show impressive relevance ranking performance in modern recommendation and search systems. However, they suffer from high computational overhead under industrial latency and throughput requirements. In particular, cross-encoder ranking systems often create long context prefill-heavy workloads, as the model has to be presented with the user, query and item information. To this end, we propose MixLM, a novel LLM-based ranking framework, which significantly improves the system throughput via reducing the input context length, while preserving the semantic strength of cross-encoder rankers. In contrast to a standard ranking system where the context is presented to the model as pure text, we propose to use mix-interaction, a mixture of text and embedding tokens to represent the input. Specifically, MixLM encodes all items in the catalog into a few embedding tokens and stores in a nearline cache. The encoded item descriptions are used during online inference, effectively reducing the item length from a few thousand text tokens to a few embedding tokens. We share insights from deploying our MixLM framework to a real-world search application at LinkedIn, including a detailed discussion of our training pipelines, as well as a thorough analysis of our online serving infrastructure optimization. Comparing with strong baselines, MixLM increased throughput by 10.0x under the same latency budget, while maintaining relevance metrics. The efficiency gains delivered by MixLM enabled full-traffic deployment of LLM-powered search, which resulted in a significant 0.47% increase in Daily Active Users (DAU) in online A/B tests.", "AI": {"tldr": "MixLM\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8de8\u7f16\u7801\u5668\u6392\u540d\u5668\u7684\u8bed\u4e49\u5f3a\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u548c\u641c\u7d22\u7cfb\u7edf\u7684\u541e\u5410\u91cf\u3002\u5b83\u4f7f\u7528\u6587\u672c\u548c\u5d4c\u5165\u4ee4\u724c\u7684\u6df7\u5408\u6765\u8868\u793a\u8f93\u5165\uff0c\u5c06\u9879\u76ee\u63cf\u8ff0\u7f16\u7801\u4e3a\u51e0\u4e2a\u5d4c\u5165\u4ee4\u724c\uff0c\u5e76\u5b58\u50a8\u5728\u8fd1\u7ebf\u7f13\u5b58\u4e2d\u3002\u90e8\u7f72\u5230LinkedIn\u7684\u5b9e\u9645\u641c\u7d22\u5e94\u7528\u540e\uff0c\u5728\u76f8\u540c\u7684\u5ef6\u8fdf\u9884\u7b97\u4e0b\uff0cMixLM\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u541e\u5410\u91cf\u63d0\u9ad8\u4e8610\u500d\uff0c\u4e14\u76f8\u5173\u6027\u6307\u6807\u4fdd\u6301\u4e0d\u53d8\u3002\u6b64\u5916\uff0c\u8fd8\u5e26\u6765\u4e86\u6bcf\u65e5\u6d3b\u8dc3\u7528\u6237(DAU)0.47%\u7684\u589e\u957f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u73b0\u4ee3\u63a8\u8350\u548c\u641c\u7d22\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9762\u4e34\u5de5\u4e1a\u7ea7\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u8981\u6c42\u4e0b\u7684\u9ad8\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002\u7279\u522b\u662f\u8de8\u7f16\u7801\u5668\u6392\u5e8f\u7cfb\u7edf\u901a\u5e38\u56e0\u4e3a\u9700\u8981\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u9884\u586b\u5145\u5de5\u4f5c\u8d1f\u8f7d\u800c\u589e\u52a0\u8ba1\u7b97\u8d1f\u62c5\u3002\u4e3a\u4e86\u63d0\u9ad8\u7cfb\u7edf\u541e\u5410\u91cf\u5e76\u7ef4\u6301\u8bed\u4e49\u8868\u8fbe\u529b\uff0c\u63d0\u51fa\u4e86MixLM\u6846\u67b6\u3002", "method": "MixLM\u901a\u8fc7\u91c7\u7528\u6587\u672c\u4e0e\u5d4c\u5165\u4ee4\u724c\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u6765\u5448\u73b0\u8f93\u5165\u5185\u5bb9\uff0c\u51cf\u5c11\u4e86\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8be5\u65b9\u6cd5\u5c06\u76ee\u5f55\u4e2d\u7684\u6240\u6709\u6761\u76ee\u7f16\u7801\u6210\u5c11\u91cf\u5d4c\u5165\u4ee4\u724c\uff0c\u5e76\u5b58\u50a8\u4e8e\u8fd1\u7ebf\u7f13\u5b58\u4e2d\uff0c\u4ece\u800c\u5728\u7ebf\u63a8\u7406\u65f6\u6709\u6548\u7f29\u77ed\u4e86\u4ece\u6570\u5343\u4e2a\u6587\u672c\u4ee4\u724c\u81f3\u5c11\u6570\u4e2a\u5d4c\u5165\u4ee4\u724c\u7684\u9879\u76ee\u957f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u76f8\u540c\u7684\u5ef6\u8fdf\u9884\u7b97\u4e0b\uff0cMixLM\u76f8\u6bd4\u5f3a\u5927\u57fa\u7ebf\u63d0\u5347\u4e8610\u500d\u7684\u541e\u5410\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5173\u6027\u5ea6\u91cf\u3002MixLM\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4f7f\u5f97LLM\u9a71\u52a8\u7684\u641c\u7d22\u80fd\u591f\u5168\u9762\u90e8\u7f72\uff0c\u5bfc\u81f4\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u65e5\u6d3b\u8dc3\u7528\u6237\u6570(DAU)\u663e\u8457\u589e\u52a0\u4e860.47%\u3002", "conclusion": "MixLM\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8eLLM\u7684\u6392\u540d\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u8f93\u5165\u8868\u793a\u5f62\u5f0f\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u8de8\u7f16\u7801\u5668\u7cfb\u7edf\u9762\u4e34\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u4e0d\u4ec5\u6781\u5927\u63d0\u9ad8\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\uff0c\u800c\u4e14\u5bf9\u5b9e\u9645\u4e1a\u52a1\u4ea7\u751f\u4e86\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2512.08551", "categories": ["cs.SE", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.08551", "abs": "https://arxiv.org/abs/2512.08551", "authors": ["Kai Marquardt", "Mona Schulz", "Anne Koziolek", "Lucia Happe"], "title": "Gamification with Purpose: What Learners Prefer to Motivate Their Learning", "comment": "31 pages, 10 figures, Springer EAIT in review", "summary": "This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative feedback was also collected to uncover motivational drivers. Learners consistently preferred GDEs that support learning processes directly-most notably progress bars, concept maps, immediate feedback, and achievements. Qualitative analysis revealed six recurring motivational themes, including visible progress, content relevance, and constructive feedback. The findings suggest that learners value gamification elements that are meaningfully integrated with educational content and support intrinsic motivation. Purpose-aligned gamification should prioritize tools that visualize learning progress and provide actionable feedback, rather than relying solely on extrinsic incentives.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u56de\u987e\u786e\u5b9a\u4e86\u5341\u79cd\u5e7f\u6cdb\u8ba8\u8bba\u7684\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\uff0c\u5e76\u4f7f\u7528\u6700\u4f73-\u6700\u5dee\u7f29\u653e\uff08BWS\uff09\u8c03\u67e5\u6cd5\u6765\u6536\u96c6125\u540d\u53c2\u4e0e\u8005\u5bf9\u8fd9\u4e9b\u5143\u7d20\u7684\u504f\u597d\u6392\u540d\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5b66\u4e60\u8005\u66f4\u503e\u5411\u4e8e\u90a3\u4e9b\u76f4\u63a5\u652f\u6301\u5b66\u4e60\u8fc7\u7a0b\u7684\u6e38\u620f\u5316\u5143\u7d20\uff0c\u5982\u8fdb\u5ea6\u6761\u3001\u6982\u5ff5\u56fe\u3001\u5373\u65f6\u53cd\u9988\u548c\u6210\u5c31\u3002\u5efa\u8bae\u6e38\u620f\u5316\u7b56\u7565\u5e94\u4f18\u5148\u8003\u8651\u80fd\u591f\u53ef\u89c6\u5316\u5b66\u4e60\u8fdb\u5ea6\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6027\u53cd\u9988\u7684\u5de5\u5177\uff0c\u800c\u4e0d\u662f\u5355\u7eaf\u4f9d\u8d56\u5916\u90e8\u6fc0\u52b1\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5b66\u4e60\u8005\u5bf9\u4e8e\u6559\u80b2\u60c5\u5883\u4e2d\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\u7684\u504f\u597d\uff0c\u4ee5\u6307\u5bfc\u76ee\u7684\u5bfc\u5411\u7684\u6e38\u620f\u5316\u7b56\u7565\u7684\u53d1\u5c55\u3002\u5b83\u5f3a\u8c03\u4e86\u4e00\u79cd\u4ee5\u5b66\u4e60\u8005\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\uff0c\u5c06\u6e38\u620f\u5316\u8bbe\u8ba1\u4e0e\u6559\u5b66\u76ee\u6807\u76f8\u4e00\u81f4\uff0c\u540c\u65f6\u964d\u4f4e\u98ce\u9669\uff0c\u6bd4\u5982\u5185\u5728\u52a8\u673a\u7684\u4fb5\u8680\u3002", "method": "\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u6587\u732e\u7efc\u8ff0\u4ee5\u8bc6\u522b\u51fa\u5341\u4e2a\u88ab\u5e7f\u6cdb\u8ba8\u8bba\u7684\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\u3002\u4e3a\u6bcf\u4e2a\u5143\u7d20\u5f00\u53d1\u4e86\u89c6\u89c9\u539f\u578b\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u5305\u542b125\u540d\u53c2\u4e0e\u8005\u7684\u6700\u4f73-\u6700\u5dee\u7f29\u653e\uff08BWS\uff09\u8c03\u67e5\u6765\u83b7\u53d6\u504f\u597d\u6392\u540d\u3002\u6b64\u5916\u8fd8\u6536\u96c6\u4e86\u5b9a\u6027\u7684\u53cd\u9988\u4ee5\u63ed\u793a\u52a8\u673a\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u5b66\u4e60\u8005\u59cb\u7ec8\u504f\u597d\u90a3\u4e9b\u80fd\u591f\u76f4\u63a5\u652f\u6301\u5b66\u4e60\u8fc7\u7a0b\u7684\u6e38\u620f\u8bbe\u8ba1\u5143\u7d20\u2014\u2014\u7279\u522b\u662f\u8fdb\u5ea6\u6761\u3001\u6982\u5ff5\u5730\u56fe\u3001\u5373\u65f6\u53cd\u9988\u4ee5\u53ca\u6210\u5c31\u3002\u5b9a\u6027\u5206\u6790\u63ed\u9732\u4e86\u516d\u4e2a\u91cd\u590d\u51fa\u73b0\u7684\u52a8\u673a\u4e3b\u9898\uff0c\u5305\u62ec\u53ef\u89c1\u7684\u8fdb\u6b65\u3001\u5185\u5bb9\u76f8\u5173\u6027\u548c\u5efa\u8bbe\u6027\u7684\u53cd\u9988\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u6e38\u620f\u5316\u5143\u7d20\u4e0e\u6559\u80b2\u5185\u5bb9\u6709\u610f\u4e49\u5730\u7ed3\u5408\u5728\u4e00\u8d77\u5e76\u4e14\u652f\u6301\u5185\u5728\u52a8\u673a\u65f6\uff0c\u5b66\u4e60\u8005\u4f1a\u66f4\u52a0\u91cd\u89c6\u8fd9\u4e9b\u6e38\u620f\u5316\u5143\u7d20\u3002\u4e3a\u4e86\u5b9e\u73b0\u76ee\u6807\u4e00\u81f4\u7684\u6e38\u620f\u5316\uff0c\u5e94\u8be5\u4f18\u5148\u8003\u8651\u53ef\u4ee5\u53ef\u89c6\u5316\u5b66\u4e60\u8fdb\u5c55\u5e76\u63d0\u4f9b\u5b9e\u7528\u53cd\u9988\u7684\u5de5\u5177\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f9d\u9760\u5916\u5728\u5956\u52b1\u3002"}}
{"id": "2512.08005", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08005", "abs": "https://arxiv.org/abs/2512.08005", "authors": ["Stepan Vanecek", "Matthew Turner", "Manisha Gajbe", "Matthew Wolf", "Martin Schulz"], "title": "Modeling the Potential of Message-Free Communication via CXL.mem", "comment": "14 pages, including References, 10 figures, to be published in SCA/HPCAsia 2026: Supercomputing Asia and International Conference on High Performance Computing in Asia Pacific Region (SCA/HPCAsia 2026)", "summary": "Heterogeneous memory technologies are increasingly important instruments in addressing the memory wall in HPC systems. While most are deployed in single node setups, CXL.mem is a technology that implements memories that can be attached to multiple nodes simultaneously, enabling shared memory pooling. This opens new possibilities, particularly for efficient inter-node communication.\n  In this paper, we present a novel performance evaluation toolchain combined with an extended performance model for message-based communication, which can be used to predict potential performance benefits from using CXL.mem for data exchange. Our approach analyzes data access patterns of MPI applications: it analyzes on-node accesses to/from MPI buffers, as well as cross-node MPI traffic to gather a full understanding of the impact of memory performance. We combine this data in an extended performance model to predict which data transfers could benefit from direct CXL.mem implementations as compared to traditional MPI messages. Our model works on a per-MPI call granularity, allowing the identification and later optimizations of those MPI invocations in the code with the highest potential for speedup by using CXL.mem.\n  For our toolchain, we extend the memory trace sampling tool Mitos and use it to extract data access behavior. In the post-processing step, the raw data is automatically analyzed to provide performance models for each individual MPI call. We validate the models on two sample applications -- a 2D heat transfer miniapp and the HPCG benchmark -- and use them to demonstrate their support for targeted optimizations by integrating CXL.mem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\u94fe\uff0c\u7ed3\u5408\u4e86\u6269\u5c55\u7684\u6027\u80fd\u6a21\u578b\uff0c\u7528\u4e8e\u57fa\u4e8e\u6d88\u606f\u7684\u901a\u4fe1\u3002\u8be5\u65b9\u6cd5\u5206\u6790\u4e86MPI\u5e94\u7528\u7a0b\u5e8f\u7684\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4ee5\u9884\u6d4b\u4f7f\u7528CXL.mem\u6280\u672f\u8fdb\u884c\u6570\u636e\u4ea4\u6362\u53ef\u80fd\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f02\u6784\u5185\u5b58\u6280\u672f\u5728\u89e3\u51b3HPC\u7cfb\u7edf\u4e2d\u7684\u5185\u5b58\u5899\u95ee\u9898\u4e0a\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u867d\u7136\u5927\u591a\u6570\u6280\u672f\u90e8\u7f72\u5728\u5355\u8282\u70b9\u8bbe\u7f6e\u4e2d\uff0c\u4f46CXL.mem\u80fd\u591f\u540c\u65f6\u8fde\u63a5\u5230\u591a\u4e2a\u8282\u70b9\uff0c\u4ece\u800c\u5b9e\u73b0\u5171\u4eab\u5185\u5b58\u6c60\u3002\u8fd9\u79cd\u6280\u672f\u4e3a\u9ad8\u6548\u7684\u8282\u70b9\u95f4\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\u94fe\u548c\u4e00\u4e2a\u6269\u5c55\u7684\u6027\u80fd\u6a21\u578b\u6765\u9884\u6d4b\u5982\u679c\u4f7f\u7528CXL.mem\u800c\u975e\u4f20\u7edfMPI\u6d88\u606f\u8fdb\u884c\u6570\u636e\u4f20\u8f93\u53ef\u80fd\u5e26\u6765\u7684\u6027\u80fd\u6539\u8fdb\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u5206\u6790MPI\u5e94\u7528\u7684\u8282\u70b9\u5185\u8bbf\u95ee\u4ee5\u53ca\u8de8\u8282\u70b9MPI\u6d41\u91cf\u6765\u7406\u89e3\u5185\u5b58\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u7ed3\u5408\u8fd9\u4e9b\u6570\u636e\u5728\u4e00\u4e2a\u6269\u5c55\u7684\u6027\u80fd\u6a21\u578b\u4e2d\uff0c\u4ee5\u6bcf\u6761MPI\u8c03\u7528\u7c92\u5ea6\u5de5\u4f5c\uff0c\u5e2e\u52a9\u8bc6\u522b\u5e76\u4f18\u5316\u4ee3\u7801\u4e2d\u53ef\u4ee5\u5229\u7528CXL.mem\u52a0\u901f\u7684\u90e8\u5206\u3002\u4e3a\u4e86\u6784\u5efa\u8fd9\u4e2a\u5de5\u5177\u94fe\uff0c\u4ed6\u4eec\u8fd8\u6269\u5c55\u4e86\u5185\u5b58\u8ddf\u8e2a\u91c7\u6837\u5de5\u5177Mitos\u6765\u63d0\u53d6\u6570\u636e\u8bbf\u95ee\u884c\u4e3a\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u4e24\u4e2a\u793a\u4f8b\u5e94\u7528\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u2014\u2014\u4e00\u4e2a2D\u70ed\u4f20\u5bfc\u8ff7\u4f60\u5e94\u7528\u7a0b\u5e8f\u548cHPCG\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u4eec\u5982\u4f55\u652f\u6301\u901a\u8fc7\u96c6\u6210CXL.mem\u6765\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u3002", "conclusion": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30CXL.mem\u5bf9\u4e8e\u6539\u5584\u7279\u5b9aMPI\u8c03\u7528\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u4e3a\u5c06\u6765\u5229\u7528CXL.mem\u6280\u672f\u8fdb\u884c\u9ad8\u6548\u6570\u636e\u4ea4\u6362\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.07843", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07843", "abs": "https://arxiv.org/abs/2512.07843", "authors": ["Long Lian", "Sida Wang", "Felix Juefei-Xu", "Tsu-Jui Fu", "Xiuyu Li", "Adam Yala", "Trevor Darrell", "Alane Suhr", "Yuandong Tian", "Xi Victoria Lin"], "title": "ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models", "comment": null, "summary": "Scaling inference-time computation has enabled Large Language Models (LLMs) to achieve strong reasoning performance, but inherently sequential decoding leads to substantial latency, especially on complex tasks. Recent work on adaptive parallel reasoning aims to improve inference efficiency by decomposing the problem-solving process into concurrent reasoning threads when beneficial. However, existing methods on realistic tasks are either limited to supervised behavior cloning or exhibit significant accuracy drops compared to widely-used sequential long chain-of-thought (CoT) baselines. Moreover, many require customized inference engines, complicating deployment. We introduce ThreadWeaver, a framework for adaptive parallel reasoning that achieves accuracy on par with popular sequential reasoning models of comparable size while significantly reducing inference latency. ThreadWeaver's performance stems from three key innovations: 1) a two-stage parallel trajectory generator that produces large-scale, high-quality CoT data with parallel annotations for supervised fine-tuning; 2) a trie-based training-inference co-design that enables parallel reasoning on any off-the-shelf autoregressive inference engine without modifying position embeddings or KV caches; and 3) a parallelization-aware reinforcement learning framework that teaches the model to balance accuracy with effective parallelization. Across six challenging mathematical reasoning benchmarks, ThreadWeaver trained atop Qwen3-8B achieves accuracy comparable to cutting-edge sequential reasoning models (71.9% on average and 79.9% on AIME24) while delivering up to 1.53x average speedup in token latency, establishing a new Pareto frontier between accuracy and efficiency.", "AI": {"tldr": "ThreadWeaver, a new framework for adaptive parallel reasoning in large language models, matches the accuracy of leading sequential reasoning models while reducing inference latency, through innovations like a two-stage parallel trajectory generator, trie-based training-inference co-design, and a reinforcement learning framework that balances accuracy with parallelization. It demonstrates up to 1.53x speedup in token latency across six mathematical reasoning benchmarks.", "motivation": "The motivation is to improve the efficiency of inference in Large Language Models (LLMs) by addressing the high latency caused by sequential decoding, especially on complex tasks, without sacrificing accuracy or requiring customized inference engines.", "method": "ThreadWeaver introduces a three-pronged approach: a two-stage parallel trajectory generator for creating high-quality CoT data, a trie-based method compatible with off-the-shelf autoregressive inference engines, and a reinforcement learning framework that teaches the model to balance accuracy with parallelization.", "result": "Across six challenging mathematical reasoning benchmarks, ThreadWeaver, when trained on top of Qwen3-8B, achieves an average accuracy of 71.9% and up to 79.9% on AIME24, while providing an average speedup of 1.53x in token latency compared to sequential reasoning models.", "conclusion": "ThreadWeaver successfully establishes a new Pareto frontier between accuracy and efficiency for LLMs, offering a solution that is both accurate and efficient, without the need for custom inference engines, making it a practical choice for deployment."}}
{"id": "2512.08067", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.08067", "abs": "https://arxiv.org/abs/2512.08067", "authors": ["Qingyang Hu", "Yucheng Huang", "Manshi Yang"], "title": "CapsuleFS A Multi-credential DataCapsule Filesystem", "comment": null, "summary": "CapsuleFS (CFS) is the first filesystem to integrate multi-credential functionality within a POSIX-compliant framework, utilizing DataCapsule as the storage provider. This innovative system is established based on the Global Data Plane in the area of edge computing. Our comprehensive design and implementation of CFS successfully fulfill the objective of providing a multi-credential Common Access API. The architecture of CFS is methodically segmented into three integral components: Firstly, the DataCapsule server, tasked with the storage, dissemination, and replication of DataCapsules on the edge. Secondly, the middleware, a crucial element running in a Trusted Execution Environment responsible for the enforcement and management of write permissions and requests. Finally, the client component, which manifests as a POSIX-compliant filesystem, is adaptable and operational across many architectures. Experimental evaluations of CFS reveal that, while its read and write performances are comparatively modest, it upholds a high degree of functional correctness. This attribute distinctly positions CFS as a viable candidate for application in real-world software development scenarios. The paper also delineates potential future enhancements, aimed at augmenting the practicality of CFS in the landscape of software development.", "AI": {"tldr": "CapsuleFS (CFS)\u662f\u9996\u4e2a\u5728POSIX\u517c\u5bb9\u6846\u67b6\u5185\u6574\u5408\u591a\u51ed\u8bc1\u529f\u80fd\u7684\u6587\u4ef6\u7cfb\u7edf\uff0c\u5229\u7528DataCapsule\u4f5c\u4e3a\u5b58\u50a8\u63d0\u4f9b\u8005\uff0c\u5e76\u57fa\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u9886\u57df\u7684\u5168\u5c40\u6570\u636e\u5e73\u9762\u6784\u5efa\u3002\u5c3d\u7ba1\u5176\u8bfb\u5199\u6027\u80fd\u8f83\u4e3a\u666e\u901a\uff0c\u4f46\u5176\u9ad8\u5ea6\u7684\u529f\u80fd\u6b63\u786e\u6027\u4f7f\u5176\u6210\u4e3a\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u53ef\u884c\u9009\u62e9\u3002", "motivation": "\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u63d0\u4f9b\u591a\u51ed\u8bc1\u8bbf\u95eeAPI\u5e76\u5728POSIX\u517c\u5bb9\u6846\u67b6\u5185\u8fd0\u884c\u7684\u6587\u4ef6\u7cfb\u7edf\uff0c\u4ee5\u6ee1\u8db3\u8fb9\u7f18\u8ba1\u7b97\u9886\u57df\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7531DataCapsule\u670d\u52a1\u5668\u3001\u8fd0\u884c\u4e8e\u53ef\u4fe1\u6267\u884c\u73af\u5883\u4e2d\u7684\u4e2d\u95f4\u4ef6\u4ee5\u53ca\u5ba2\u6237\u7aef\u7ec4\u4ef6\u6784\u6210\u7684\u4e09\u90e8\u5206\u67b6\u6784\u6765\u8fbe\u6210\u76ee\u6807\u3002", "result": "CFS\u867d\u7136\u5728\u8bfb\u5199\u6027\u80fd\u4e0a\u8868\u73b0\u4e00\u822c\uff0c\u4f46\u5b83\u5177\u6709\u5f88\u9ad8\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8fd9\u4f7f\u5f97\u5b83\u9002\u5408\u7528\u4e8e\u5b9e\u9645\u7684\u8f6f\u4ef6\u5f00\u53d1\u60c5\u5883\u4e2d\u3002", "conclusion": "CFS\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u7528\u6237\u63d0\u4f9b\u4e00\u4e2a\u591a\u51ed\u8bc1\u8bbf\u95ee\u63a5\u53e3\u7684\u76ee\u6807\uff0c\u4e14\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u4fa7\u91cd\u4e8e\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.08078", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08078", "abs": "https://arxiv.org/abs/2512.08078", "authors": ["Qiang Mao", "Han Qin", "Robert Neary", "Charles Wang", "Fusheng Wei", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "A Comparative Study of Retrieval Methods in Azure AI Search", "comment": null, "summary": "Increasingly, attorneys are interested in moving beyond keyword and semantic search to improve the efficiency of how they find key information during a document review task. Large language models (LLMs) are now seen as tools that attorneys can use to ask natural language questions of their data during document review to receive accurate and concise answers. This study evaluates retrieval strategies within Microsoft Azure's Retrieval-Augmented Generation (RAG) framework to identify effective approaches for Early Case Assessment (ECA) in eDiscovery. During ECA, legal teams analyze data at the outset of a matter to gain a general understanding of the data and attempt to determine key facts and risks before beginning full-scale review. In this paper, we compare the performance of Azure AI Search's keyword, semantic, vector, hybrid, and hybrid-semantic retrieval methods. We then present the accuracy, relevance, and consistency of each method's AI-generated responses. Legal practitioners can use the results of this study to enhance how they select RAG configurations in the future.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5fae\u8f6fAzure\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6846\u67b6\u5185\u7684\u68c0\u7d22\u7b56\u7565\uff0c\u4ee5\u8bc6\u522b\u7535\u5b50\u53d1\u73b0\u4e2d\u65e9\u671f\u6848\u4ef6\u8bc4\u4f30(ECA)\u7684\u6709\u6548\u65b9\u6cd5\u3002\u6bd4\u8f83\u4e86Azure AI\u641c\u7d22\u7684\u5173\u952e\u8bcd\u3001\u8bed\u4e49\u3001\u5411\u91cf\u3001\u6df7\u5408\u548c\u6df7\u5408-\u8bed\u4e49\u68c0\u7d22\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u6bcf\u79cd\u65b9\u6cd5AI\u751f\u6210\u54cd\u5e94\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5f8b\u5e08\u4eec\u8d8a\u6765\u8d8a\u6709\u5174\u8da3\u8d85\u8d8a\u5173\u952e\u8bcd\u548c\u8bed\u4e49\u641c\u7d22\uff0c\u4ee5\u63d0\u9ad8\u5728\u6587\u6863\u5ba1\u9605\u4efb\u52a1\u4e2d\u67e5\u627e\u5173\u952e\u4fe1\u606f\u7684\u6548\u7387\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u73b0\u5728\u88ab\u89c6\u4e3a\u5f8b\u5e08\u53ef\u4ee5\u7528\u6765\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5de5\u5177\uff0c\u4ee5\u4fbf\u5728\u6587\u6863\u5ba1\u9605\u671f\u95f4\u4ece\u6570\u636e\u4e2d\u83b7\u5f97\u51c6\u786e\u7b80\u6d01\u7684\u7b54\u6848\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83Azure AI Search\u63d0\u4f9b\u7684\u5173\u952e\u8bcd\u3001\u8bed\u4e49\u3001\u5411\u91cf\u3001\u6df7\u5408\u4ee5\u53ca\u6df7\u5408-\u8bed\u4e49\u68c0\u7d22\u65b9\u6cd5\u7684\u8868\u73b0\u6765\u8bc4\u4f30\u68c0\u7d22\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u4e0d\u540c\u68c0\u7d22\u65b9\u6cd5\u4e0bAI\u751f\u6210\u56de\u7b54\u7684\u51c6\u786e\u6027\u3001\u76f8\u5173\u6027\u53ca\u4e00\u81f4\u6027\u8868\u73b0\u3002", "conclusion": "\u6cd5\u5f8b\u4ece\u4e1a\u8005\u53ef\u4ee5\u5229\u7528\u8fd9\u9879\u7814\u7a76\u7684\u7ed3\u679c\u6765\u6539\u8fdb\u672a\u6765RAG\u914d\u7f6e\u7684\u9009\u62e9\u3002"}}
{"id": "2512.08242", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.08242", "abs": "https://arxiv.org/abs/2512.08242", "authors": ["Marco Kurzynski", "Shaizeen Aga", "Di Wu"], "title": "Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency", "comment": null, "summary": "Training large language models (LLMs) efficiently requires a deep understanding of how modern GPU systems behave under real-world distributed training workloads. While prior work has focused primarily on kernel-level performance or single-GPU microbenchmarks, the complex interaction between communication, computation, memory behavior, and power management in multi-GPU LLM training remains poorly characterized. In this work, we introduce Chopper, a profiling and analysis framework that collects, aligns, and visualizes GPU kernel traces and hardware performance counters across multiple granularities (i.e., from individual kernels to operations, layers, phases, iterations, and GPUs). Using Chopper, we perform a comprehensive end-to-end characterization of Llama 3 8B training under fully sharded data parallelism (FSDP) on an eight-GPU AMD InstinctTM MI300X node. Our analysis reveals several previously underexplored bottlenecks and behaviors, such as memory determinism enabling higher, more stable GPU and memory frequencies. We identify several sources of inefficiencies, with frequency overhead (DVFS effects) being the single largest contributor to the gap between theoretical and observed performance, exceeding the impact of MFMA utilization loss, communication/computation overlap, and kernel launch overheads. Overall, Chopper provides the first holistic, multi-granularity characterization of LLM training on AMD InstinctTM MI300X GPUs, yielding actionable insights for optimizing training frameworks, improving power-management strategies, and guiding future GPU architecture and system design.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aChopper\u7684\u5206\u6790\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u6536\u96c6\u3001\u5bf9\u9f50\u5e76\u53ef\u89c6\u5316\u591a\u7c92\u5ea6\u7684GPU\u5185\u6838\u8ddf\u8e2a\u548c\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u3002\u901a\u8fc7\u4f7f\u7528Chopper\u5bf9Llama 3 8B\u6a21\u578b\u5728AMD InstinctTM MI300X GPU\u4e0a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4e4b\u524d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u74f6\u9888\u4e0e\u884c\u4e3a\uff0c\u5e76\u8bc6\u522b\u51fa\u9891\u7387\u5f00\u9500\u662f\u7406\u8bba\u4e0e\u5b9e\u9645\u6027\u80fd\u5dee\u8ddd\u7684\u6700\u5927\u8d21\u732e\u8005\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e2aGPU\u5fae\u57fa\u51c6\u6d4b\u8bd5\u6216\u5185\u6838\u7ea7\u6027\u80fd\u4e0a\uff0c\u800c\u9488\u5bf9\u591aGPU\u73af\u5883\u4e0b\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u901a\u4fe1\u3001\u8ba1\u7b97\u3001\u5185\u5b58\u884c\u4e3a\u4ee5\u53ca\u529f\u8017\u7ba1\u7406\u4e4b\u95f4\u590d\u6742\u4ea4\u4e92\u7684\u7814\u7a76\u76f8\u5bf9\u4e0d\u8db3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86Chopper\u8fd9\u4e00\u5206\u6790\u5de5\u5177\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u591a\u7ef4\u5ea6\u89c6\u89d2\u6765\u7406\u89e3\u8fd9\u4e9b\u4ea4\u4e92\u5982\u4f55\u5f71\u54cd\u6574\u4f53\u6548\u7387\u3002", "method": "Chopper\u662f\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u6536\u96c6\u3001\u5bf9\u9f50\u548c\u5c55\u793a\u4e0d\u540c\u7ea7\u522b\uff08\u4ece\u5355\u72ec\u7684\u5185\u6838\u5230\u64cd\u4f5c\u3001\u5c42\u3001\u9636\u6bb5\u3001\u8fed\u4ee3\u4e43\u81f3\u6574\u4e2aGPU\uff09\u4e0bGPU\u5185\u6838\u8ffd\u8e2a\u4fe1\u606f\u53ca\u786c\u4ef6\u6027\u80fd\u6307\u6807\u7684\u6846\u67b6\u3002\u5229\u7528\u8be5\u5de5\u5177\uff0c\u7814\u7a76\u56e2\u961f\u5bf9\u91c7\u7528\u5b8c\u5168\u5206\u7247\u6570\u636e\u5e76\u884c(FSDP)\u6280\u672f\uff0c\u5728\u7531\u516b\u4e2aAMD InstinctTM MI300X\u7ec4\u6210\u7684\u8282\u70b9\u4e0a\u8fdb\u884c\u8bad\u7ec3\u7684Llama 3 8B\u6a21\u578b\u8fdb\u884c\u4e86\u8be6\u5c3d\u7684\u7aef\u5230\u7aef\u7279\u5f81\u63cf\u7ed8\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5e94\u7528Chopper\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u4e4b\u524d\u8f83\u5c11\u5173\u6ce8\u7684\u95ee\u9898\u70b9\uff0c\u6bd4\u5982\u786e\u5b9a\u6027\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u80fd\u591f\u652f\u6301\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684GPU\u4e0e\u5185\u5b58\u8fd0\u884c\u9891\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u6307\u51fa\u52a8\u6001\u7535\u538b\u9891\u7387\u8c03\u6574(DVFS)\u5e26\u6765\u7684\u9891\u7387\u5f00\u9500\u662f\u5bfc\u81f4\u7406\u8bba\u4e0e\u5b9e\u9645\u6027\u80fd\u5dee\u5f02\u7684\u4e3b\u8981\u56e0\u7d20\u4e4b\u4e00\uff0c\u5176\u5f71\u54cd\u751a\u81f3\u8d85\u8fc7\u4e86\u77e9\u9635\u4e58\u6cd5\u7d2f\u79ef(MFMA)\u5229\u7528\u7387\u635f\u5931\u3001\u901a\u8baf/\u8ba1\u7b97\u91cd\u53e0\u4ee5\u53ca\u5185\u6838\u542f\u52a8\u5ef6\u8fdf\u7b49\u56e0\u7d20\u3002", "conclusion": "Chopper\u4e3aAMD InstinctTM MI300X GPU\u4e0a\u6267\u884c\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u4e14\u591a\u5c42\u6b21\u7684\u7279\u6027\u63cf\u8ff0\u3002\u5b83\u4e0d\u4ec5\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u5f53\u524d\u7cfb\u7edf\u4e2d\u7684\u4f4e\u6548\u4e4b\u5904\uff0c\u4e5f\u4e3a\u4f18\u5316\u8bad\u7ec3\u6846\u67b6\u3001\u6539\u8fdb\u529f\u8017\u7ba1\u7406\u7b56\u7565\u4ee5\u53ca\u6307\u5bfc\u672a\u6765GPU\u67b6\u6784\u548c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.07983", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07983", "abs": "https://arxiv.org/abs/2512.07983", "authors": ["Nan Jia", "Anita Raja", "Raffi Khatchadourian"], "title": "An Empirical Framework for Evaluating Semantic Preservation Using Hugging Face", "comment": "Accepted to Hawaii International Conference on System Sciences (HICSS) 2026", "summary": "As machine learning (ML) becomes an integral part of high-autonomy systems, it is critical to ensure the trustworthiness of learning-enabled software systems (LESS). Yet, the nondeterministic and run-time-defined semantics of ML complicate traditional software refactoring. We define semantic preservation in LESS as the property that optimizations of intelligent components do not alter the system's overall functional behavior. This paper introduces an empirical framework to evaluate semantic preservation in LESS by mining model evolution data from HuggingFace. We extract commit histories, $\\textit{Model Cards}$, and performance metrics from a large number of models. To establish baselines, we conducted case studies in three domains, tracing performance changes across versions. Our analysis demonstrates how $\\textit{semantic drift}$ can be detected via evaluation metrics across commits and reveals common refactoring patterns based on commit message analysis. Although API constraints limited the possibility of estimating a full-scale threshold, our pipeline offers a foundation for defining community-accepted boundaries for semantic preservation. Our contributions include: (1) a large-scale dataset of ML model evolution, curated from 1.7 million Hugging Face entries via a reproducible pipeline using the native HF hub API, (2) a practical pipeline for the evaluation of semantic preservation for a subset of 536 models and 4000+ metrics and (3) empirical case studies illustrating semantic drift in practice. Together, these contributions advance the foundations for more maintainable and trustworthy ML systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ecf\u9a8c\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u6316\u6398HuggingFace\u4e0a\u7684\u6a21\u578b\u6f14\u5316\u6570\u636e\u6765\u8bc4\u4f30\u5b66\u4e60\u578b\u8f6f\u4ef6\u7cfb\u7edf(LESS)\u4e2d\u7684\u8bed\u4e49\u4fdd\u6301\u3002\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u91cf\u6a21\u578b\u7684\u63d0\u4ea4\u5386\u53f2\u3001\u6a21\u578b\u5361\u7247\u548c\u6027\u80fd\u6307\u6807\uff0c\u63ed\u793a\u4e86\u57fa\u4e8e\u63d0\u4ea4\u4fe1\u606f\u5206\u6790\u7684\u5e38\u89c1\u91cd\u6784\u6a21\u5f0f\uff0c\u5e76\u68c0\u6d4b\u4e86\u8de8\u63d0\u4ea4\u7684\u8bc4\u4f30\u6307\u6807\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6f14\u5316\u6570\u636e\u96c6\u3001\u4e00\u4e2a\u5b9e\u7528\u7684\u8bed\u4e49\u4fdd\u6301\u8bc4\u4f30\u7ba1\u9053\u4ee5\u53ca\u5c55\u793a\u5b9e\u9645\u8bed\u4e49\u6f02\u79fb\u7684\u7ecf\u9a8c\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6210\u4e3a\u9ad8\u81ea\u6cbb\u7cfb\u7edf\u7684\u4e00\u4e2a\u7ec4\u6210\u90e8\u5206\uff0c\u786e\u4fdd\u5b66\u4e60\u578b\u8f6f\u4ef6\u7cfb\u7edf\uff08LESS\uff09\u7684\u53ef\u4fe1\u5ea6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cML\u7684\u975e\u786e\u5b9a\u6027\u548c\u8fd0\u884c\u65f6\u5b9a\u4e49\u7684\u8bed\u4e49\u590d\u6742\u5316\u4e86\u4f20\u7edf\u7684\u8f6f\u4ef6\u91cd\u6784\u3002\u6587\u7ae0\u65e8\u5728\u5b9a\u4e49\u5e76\u8bc4\u4f30LESS\u4e2d\u7684\u8bed\u4e49\u4fdd\u6301\uff0c\u5373\u667a\u80fd\u7ec4\u4ef6\u7684\u4f18\u5316\u4e0d\u6539\u53d8\u7cfb\u7edf\u7684\u6574\u4f53\u529f\u80fd\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u4eceHuggingFace\u83b7\u53d6\u6a21\u578b\u6f14\u53d8\u6570\u636e\uff0c\u5305\u62ec\u63d0\u4ea4\u5386\u53f2\u3001\u300a\u6a21\u578b\u5361\u7247\u300b\u548c\u6027\u80fd\u6307\u6807\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7ecf\u9a8c\u6846\u67b6\u6765\u8bc4\u4f30\u8bed\u4e49\u4fdd\u6301\u3002\u5728\u4e09\u4e2a\u9886\u57df\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\u4ee5\u5efa\u7acb\u57fa\u51c6\u7ebf\uff0c\u8ffd\u8e2a\u4e0d\u540c\u7248\u672c\u4e4b\u95f4\u7684\u6027\u80fd\u53d8\u5316\u3002\u901a\u8fc7\u5bf9\u63d0\u4ea4\u4fe1\u606f\u7684\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u5e38\u89c1\u7684\u91cd\u6784\u6a21\u5f0f\u548c\u8bed\u4e49\u6f02\u79fb\u73b0\u8c61\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u53ef\u4ee5\u901a\u8fc7\u8de8\u63d0\u4ea4\u7684\u8bc4\u4f30\u6307\u6807\u68c0\u6d4b\u5230\u8bed\u4e49\u6f02\u79fb\uff0c\u5e76\u4e14\u57fa\u4e8e\u63d0\u4ea4\u6d88\u606f\u5206\u6790\u63ed\u793a\u4e86\u4e00\u4e9b\u5e38\u89c1\u7684\u91cd\u6784\u6a21\u5f0f\u3002\u867d\u7136API\u9650\u5236\u4f7f\u5f97\u65e0\u6cd5\u4f30\u8ba1\u5168\u89c4\u6a21\u9608\u503c\uff0c\u4f46\u8be5\u7ba1\u9053\u4e3a\u5b9a\u4e49\u793e\u533a\u63a5\u53d7\u7684\u8bed\u4e49\u4fdd\u6301\u8fb9\u754c\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u66f4\u53ef\u7ef4\u62a4\u548c\u53ef\u4fe1\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u57fa\u7840\u5efa\u8bbe\uff0c\u5305\u62ec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u3001\u4e00\u4e2a\u5b9e\u7528\u7684\u8bed\u4e49\u4fdd\u6301\u8bc4\u4f30\u7ba1\u9053\u53ca\u5176\u5b9e\u8bc1\u6848\u4f8b\u7814\u7a76\u3002"}}
{"id": "2512.08079", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08079", "abs": "https://arxiv.org/abs/2512.08079", "authors": ["Qiang Mao", "Fusheng Wei", "Robert Neary", "Charles Wang", "Han Qin", "Jianping Zhang", "Nathaniel Huber-Fliflet"], "title": "Leveraging Machine Learning and Large Language Models for Automated Image Clustering and Description in Legal Discovery", "comment": null, "summary": "The rapid increase in digital image creation and retention presents substantial challenges during legal discovery, digital archive, and content management. Corporations and legal teams must organize, analyze, and extract meaningful insights from large image collections under strict time pressures, making manual review impractical and costly. These demands have intensified interest in automated methods that can efficiently organize and describe large-scale image datasets. This paper presents a systematic investigation of automated cluster description generation through the integration of image clustering, image captioning, and large language models (LLMs). We apply K-means clustering to group images into 20 visually coherent clusters and generate base captions using the Azure AI Vision API. We then evaluate three critical dimensions of the cluster description process: (1) image sampling strategies, comparing random, centroid-based, stratified, hybrid, and density-based sampling against using all cluster images; (2) prompting techniques, contrasting standard prompting with chain-of-thought prompting; and (3) description generation methods, comparing LLM-based generation with traditional TF-IDF and template-based approaches. We assess description quality using semantic similarity and coverage metrics. Results show that strategic sampling with 20 images per cluster performs comparably to exhaustive inclusion while significantly reducing computational cost, with only stratified sampling showing modest degradation. LLM-based methods consistently outperform TF-IDF baselines, and standard prompts outperform chain-of-thought prompts for this task. These findings provide practical guidance for deploying scalable, accurate cluster description systems that support high-volume workflows in legal discovery and other domains requiring automated organization of large image collections.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u6574\u5408\u56fe\u50cf\u805a\u7c7b\u3001\u56fe\u50cf\u5b57\u5e55\u751f\u6210\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u81ea\u52a8\u751f\u6210\u96c6\u7fa4\u63cf\u8ff0\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u6bcf\u96c6\u7fa420\u5f20\u56fe\u7247\u7684\u6218\u7565\u6027\u91c7\u6837\u65b9\u6cd5\u5728\u4fdd\u8bc1\u63cf\u8ff0\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff1b\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u8868\u73b0\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684TF-IDF\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u6807\u51c6\u63d0\u793a\u65b9\u5f0f\u6bd4\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u66f4\u9002\u5408\u6b64\u4efb\u52a1\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u56fe\u50cf\u521b\u5efa\u4e0e\u4fdd\u5b58\u7684\u5feb\u901f\u589e\u957f\uff0c\u5728\u6cd5\u5f8b\u53d1\u73b0\u3001\u6570\u5b57\u5b58\u6863\u53ca\u5185\u5bb9\u7ba1\u7406\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7740\u5de8\u5927\u6311\u6218\u3002\u4f01\u4e1a\u548c\u6cd5\u5f8b\u56e2\u961f\u9700\u8981\u5728\u4e25\u683c\u7684\u65f6\u95f4\u538b\u529b\u4e0b\u4ece\u5927\u91cf\u7684\u56fe\u50cf\u96c6\u5408\u4e2d\u7ec4\u7ec7\u3001\u5206\u6790\u5e76\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u4f7f\u5f97\u624b\u52a8\u5ba1\u67e5\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u4e14\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e\u80fd\u591f\u9ad8\u6548\u5730\u7ec4\u7ec7\u548c\u63cf\u8ff0\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\u3002", "method": "\u91c7\u7528K-means\u7b97\u6cd5\u5c06\u56fe\u50cf\u5206\u621020\u4e2a\u89c6\u89c9\u4e0a\u4e00\u81f4\u7684\u96c6\u7fa4\uff0c\u5e76\u5229\u7528Azure AI Vision API\u751f\u6210\u57fa\u7840\u5b57\u5e55\u3002\u63a5\u7740\u8bc4\u4f30\u4e86\u96c6\u7fa4\u63cf\u8ff0\u8fc7\u7a0b\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u65b9\u9762\uff1a1\uff09\u56fe\u50cf\u91c7\u6837\u7b56\u7565\uff0c\u6bd4\u8f83\u968f\u673a\u3001\u57fa\u4e8e\u4e2d\u5fc3\u70b9\u3001\u5206\u5c42\u3001\u6df7\u5408\u4ee5\u53ca\u57fa\u4e8e\u5bc6\u5ea6\u7684\u91c7\u6837\u65b9\u6cd5\u4e0e\u4f7f\u7528\u6240\u6709\u96c6\u7fa4\u56fe\u50cf\u4e4b\u95f4\u7684\u5dee\u5f02\uff1b2\uff09\u63d0\u793a\u6280\u672f\uff0c\u5bf9\u6bd4\u6807\u51c6\u63d0\u793a\u4e0e\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u7684\u6548\u679c\uff1b3\uff09\u63cf\u8ff0\u751f\u6210\u65b9\u6cd5\uff0c\u6bd4\u8f83\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u4e0e\u4f20\u7edfTF-IDF\u53ca\u6a21\u677f\u5316\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6bcf\u96c6\u7fa4\u9009\u53d620\u5f20\u56fe\u7247\u7684\u6218\u7565\u6027\u91c7\u6837\u65b9\u6848\u5728\u4fdd\u6301\u826f\u597d\u63cf\u8ff0\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u5ea6\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u800c\u53ea\u6709\u5206\u5c42\u91c7\u6837\u7684\u6548\u679c\u7565\u6709\u4e0b\u964d\u3002\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u59cb\u7ec8\u4f18\u4e8eTF-IDF\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u4e14\u9488\u5bf9\u8fd9\u9879\u4efb\u52a1\u800c\u8a00\uff0c\u6807\u51c6\u63d0\u793a\u65b9\u5f0f\u4f18\u4e8e\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u90e8\u7f72\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u96c6\u7fa4\u63cf\u8ff0\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u652f\u6301\u6cd5\u5f8b\u53d1\u73b0\u53ca\u5176\u4ed6\u9700\u8981\u81ea\u52a8\u7ec4\u7ec7\u5927\u91cf\u56fe\u50cf\u96c6\u5408\u9886\u57df\u7684\u9ad8\u5bb9\u91cf\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2512.08288", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08288", "abs": "https://arxiv.org/abs/2512.08288", "authors": ["Chinmaya Kumar Dehury", "Lauri Lov\u00e9n", "Praveen Kumar Donta", "Ilir Murturi", "Schahram Dustdar"], "title": "Synergizing Monetization, Orchestration, and Semantics in Computing Continuum", "comment": "Currently submitted to IEEE Computers", "summary": "Industry demands are growing for hyper-distributed applications that span from the cloud to the edge in domains such as smart manufacturing, transportation, and agriculture. Yet today's solutions struggle to meet these demands due to inherent limitations in scalability, interoperability, and trust. In this article, we introduce HERMES (Heterogeneous Computing Continuum with Resource Monetization, Orchestration, and Semantic) - a novel framework designed to transform connectivity and data utilization across the computing continuum. HERMES establishes an open, seamless, and secure environment where resources, from cloud servers to tiny edge devices, can be orchestrated intelligently, data and services can be monetized in a distributed marketplace, and knowledge is shared through semantic interoperability. By bridging these key facets, HERMES lays a foundation for a new generation of distributed applications that are more efficient, trustworthy, and autonomous.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aHERMES\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u65e8\u5728\u901a\u8fc7\u667a\u80fd\u7f16\u6392\u8d44\u6e90\u3001\u5206\u5e03\u5f0f\u5e02\u573a\u4e2d\u7684\u6570\u636e\u548c\u670d\u52a1\u53d8\u73b0\u4ee5\u53ca\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u6765\u6539\u53d8\u8ba1\u7b97\u8fde\u7eed\u4f53\u4e2d\u7684\u8fde\u63a5\u6027\u548c\u6570\u636e\u5229\u7528\u3002", "motivation": "\u5f53\u524d\u89e3\u51b3\u65b9\u6848\u7531\u4e8e\u5728\u53ef\u6269\u5c55\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u548c\u4fe1\u4efb\u65b9\u9762\u7684\u56fa\u6709\u9650\u5236\uff0c\u96be\u4ee5\u6ee1\u8db3\u4ece\u4e91\u5230\u8fb9\u7f18\u7684\u8d85\u5206\u5e03\u5f0f\u5e94\u7528\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86HERMES\u6846\u67b6\uff0c\u5b83\u521b\u9020\u4e86\u4e00\u4e2a\u5f00\u653e\u3001\u65e0\u7f1d\u548c\u5b89\u5168\u7684\u73af\u5883\uff0c\u80fd\u591f\u667a\u80fd\u5730\u7f16\u6392\u4ece\u4e91\u670d\u52a1\u5668\u5230\u5fae\u5c0f\u8fb9\u7f18\u8bbe\u5907\u7684\u5404\u79cd\u8d44\u6e90\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u5e02\u573a\u5b9e\u73b0\u6570\u636e\u548c\u670d\u52a1\u7684\u8d27\u5e01\u5316\uff0c\u540c\u65f6\u501f\u52a9\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u5206\u4eab\u77e5\u8bc6\u3002", "result": "HERMES\u4e3a\u65b0\u4e00\u4ee3\u66f4\u52a0\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u81ea\u4e3b\u7684\u5206\u5e03\u5f0f\u5e94\u7528\u7a0b\u5e8f\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "HERMES\u901a\u8fc7\u7ed3\u5408\u5173\u952e\u65b9\u9762\u5982\u667a\u80fd\u8d44\u6e90\u7ba1\u7406\u3001\u5206\u5e03\u5f0f\u5e02\u573a\u7684\u6570\u636e\u4e0e\u670d\u52a1\u8d27\u5e01\u5316\u53ca\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u5728\u652f\u6301\u8de8\u4e91\u8ba1\u7b97\u81f3\u8fb9\u7f18\u7aef\u7684\u8d85\u5206\u5e03\u5f0f\u5e94\u7528\u65f6\u9047\u5230\u7684\u95ee\u9898\u3002"}}
{"id": "2512.07990", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07990", "abs": "https://arxiv.org/abs/2512.07990", "authors": ["Thanh Nguyen", "Chaima Boufaied", "Ronnie de Souza Santos"], "title": "A Gray Literature Study on Fairness Requirements in AI-enabled Software Engineering", "comment": null, "summary": "Today, with the growing obsession with applying Artificial Intelligence (AI), particularly Machine Learning (ML), to software across various contexts, much of the focus has been on the effectiveness of AI models, often measured through common metrics such as F1- score, while fairness receives relatively little attention. This paper presents a review of existing gray literature, examining fairness requirements in AI context, with a focus on how they are defined across various application domains, managed throughout the Software Development Life Cycle (SDLC), and the causes, as well as the corresponding consequences of their violation by AI models. Our gray literature investigation shows various definitions of fairness requirements in AI systems, commonly emphasizing non-discrimination and equal treatment across different demographic and social attributes. Fairness requirement management practices vary across the SDLC, particularly in model training and bias mitigation, fairness monitoring and evaluation, and data handling practices. Fairness requirement violations are frequently linked, but not limited, to data representation bias, algorithmic and model design bias, human judgment, and evaluation and transparency gaps. The corresponding consequences include harm in a broad sense, encompassing specific professional and societal impacts as key examples, stereotype reinforcement, data and privacy risks, and loss of trust and legitimacy in AI-supported decisions. These findings emphasize the need for consistent frameworks and practices to integrate fairness into AI software, paying as much attention to fairness as to effectiveness.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u7070\u8272\u6587\u732e\uff0c\u63a2\u8ba8\u4e86AI\u73af\u5883\u4e0b\u7684\u516c\u5e73\u6027\u8981\u6c42\uff0c\u5305\u62ec\u5b83\u4eec\u5728\u4e0d\u540c\u5e94\u7528\u9886\u57df\u7684\u5b9a\u4e49\u3001\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u7ba1\u7406\u65b9\u5f0f\u4ee5\u53ca\u8fdd\u53cd\u8fd9\u4e9b\u8981\u6c42\u7684\u539f\u56e0\u548c\u540e\u679c\u3002\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u4e00\u81f4\u7684\u6846\u67b6\u548c\u5b9e\u8df5\u6765\u5c06\u516c\u5e73\u6027\u878d\u5165AI\u8f6f\u4ef6\u4e2d\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\uff08\u7279\u522b\u662f\u673a\u5668\u5b66\u4e60\uff09\u5728\u5404\u79cd\u8f6f\u4ef6\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5f53\u524d\u7684\u5173\u6ce8\u70b9\u4e3b\u8981\u96c6\u4e2d\u5728AI\u6a21\u578b\u7684\u6709\u6548\u6027\u4e0a\uff0c\u800c\u5bf9\u516c\u5e73\u6027\u7684\u5173\u6ce8\u76f8\u5bf9\u8f83\u5c11\u3002\u6587\u7ae0\u65e8\u5728\u901a\u8fc7\u5ba1\u67e5\u73b0\u6709\u7070\u8272\u6587\u732e\uff0c\u63a2\u8ba8AI\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u8981\u6c42\u7684\u5b9a\u4e49\u3001\u7ba1\u7406\u53ca\u5176\u8fdd\u80cc\u6240\u5e26\u6765\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7070\u8272\u6587\u732e\u8c03\u67e5\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86AI\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u8981\u6c42\u7684\u4e0d\u540c\u5b9a\u4e49\u3001\u5728\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u7ba1\u7406\u5b9e\u8df5\uff0c\u4ee5\u53ca\u8fdd\u53cd\u8fd9\u4e9b\u8981\u6c42\u7684\u539f\u56e0\u4e0e\u540e\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cAI\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u8981\u6c42\u901a\u5e38\u5f3a\u8c03\u8de8\u4e0d\u540c\u4eba\u53e3\u548c\u793e\u4f1a\u5c5e\u6027\u7684\u975e\u6b67\u89c6\u548c\u5e73\u7b49\u5bf9\u5f85\uff1b\u516c\u5e73\u6027\u8981\u6c42\u7ba1\u7406\u5b9e\u8df5\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u6709\u6240\u4e0d\u540c\uff1b\u8fdd\u53cd\u516c\u5e73\u6027\u8981\u6c42\u7684\u539f\u56e0\u591a\u6837\uff0c\u5305\u62ec\u6570\u636e\u8868\u793a\u504f\u89c1\u3001\u7b97\u6cd5\u8bbe\u8ba1\u504f\u89c1\u7b49\uff0c\u5e76\u4e14\u53ef\u80fd\u5bfc\u81f4\u5e7f\u6cdb\u7684\u793e\u4f1a\u548c\u4e2a\u4eba\u5c42\u9762\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u4e86\u786e\u4fddAI\u652f\u6301\u51b3\u7b56\u7684\u4fe1\u4efb\u5ea6\u548c\u5408\u6cd5\u6027\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u81f4\u7684\u6846\u67b6\u548c\u5b9e\u8df5\u4ee5\u540c\u7b49\u91cd\u89c6AI\u8f6f\u4ef6\u4e2d\u7684\u516c\u5e73\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2512.07848", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07848", "abs": "https://arxiv.org/abs/2512.07848", "authors": ["Di Zhu", "Chen Xie", "Ziwei Wang", "Haoyun Zhang"], "title": "RaX-Crash: A Resource Efficient and Explainable Small Model Pipeline with an Application to City Scale Injury Severity Prediction", "comment": null, "summary": "New York City reports over one hundred thousand motor vehicle collisions each year, creating substantial injury and public health burden. We present RaX-Crash, a resource efficient and explainable small model pipeline for structured injury severity prediction on the official NYC Motor Vehicle Collisions dataset. RaX-Crash integrates three linked tables with tens of millions of records, builds a unified feature schema in partitioned storage, and trains compact tree based ensembles (Random Forest and XGBoost) on engineered tabular features, which are compared against locally deployed small language models (SLMs) prompted with textual summaries. On a temporally held out test set, XGBoost and Random Forest achieve accuracies of 0.7828 and 0.7794, clearly outperforming SLMs (0.594 and 0.496); class imbalance analysis shows that simple class weighting improves fatal recall with modest accuracy trade offs, and SHAP attribution highlights human vulnerability factors, timing, and location as dominant drivers of predicted severity. Overall, RaX-Crash indicates that interpretable small model ensembles remain strong baselines for city scale injury analytics, while hybrid pipelines that pair tabular predictors with SLM generated narratives improve communication without sacrificing scalability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RaX-Crash\u6a21\u578b\uff0c\u7528\u4e8e\u7ebd\u7ea6\u5e02\u4ea4\u901a\u4e8b\u6545\u4f24\u5bb3\u4e25\u91cd\u7a0b\u5ea6\u7684\u9884\u6d4b\u3002\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u6570\u636e\u8868\u3001\u6784\u5efa\u7edf\u4e00\u7279\u5f81\u6a21\u5f0f\uff0c\u5e76\u8bad\u7ec3\u7d27\u51d1\u578b\u6811\u96c6\u5408\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\u548cXGBoost\uff09\uff0c\u4e0e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002\u7814\u7a76\u8868\u660e\uff0c\u53ef\u89e3\u91ca\u7684\u5c0f\u578b\u6a21\u578b\u96c6\u5408\u5bf9\u4e8e\u57ce\u5e02\u89c4\u6a21\u7684\u4f24\u5bb3\u5206\u6790\u6765\u8bf4\u662f\u5f3a\u6709\u529b\u7684\u57fa\u7840\uff0c\u800c\u7ed3\u5408\u8868\u683c\u9884\u6d4b\u5668\u4e0e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u53d9\u8ff0\u53ef\u4ee5\u6539\u5584\u6c9f\u901a\u800c\u4e0d\u727a\u7272\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u9762\u5bf9\u7ebd\u7ea6\u5e02\u6bcf\u5e74\u62a5\u544a\u7684\u5927\u91cf\u673a\u52a8\u8f66\u78b0\u649e\u4e8b\u6545\u53ca\u5176\u5e26\u6765\u7684\u5065\u5eb7\u8d1f\u62c5\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u4e8b\u6545\u4f24\u5bb3\u4e25\u91cd\u7a0b\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86RaX-Crash\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u6574\u5408\u4e86\u4e09\u4e2a\u5305\u542b\u6570\u5343\u4e07\u6761\u8bb0\u5f55\u7684\u6570\u636e\u8868\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u5206\u533a\u5b58\u50a8\u4e2d\u7684\u7edf\u4e00\u7279\u5f81\u67b6\u6784\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u4e86\u7d27\u51d1\u578b\u7684\u6811\u72b6\u96c6\u6210\u6a21\u578b\uff08\u968f\u673a\u68ee\u6797\u548cXGBoost\uff09\u3002\u6b64\u5916\uff0c\u8fd8\u4e0e\u672c\u5730\u90e8\u7f72\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5728\u65f6\u95f4\u4e0a\u4fdd\u7559\u7684\u6d4b\u8bd5\u96c6\u4e0a\uff0cXGBoost\u548c\u968f\u673a\u68ee\u6797\u5206\u522b\u8fbe\u5230\u4e860.7828\u548c0.7794\u7684\u51c6\u786e\u7387\uff0c\u660e\u663e\u4f18\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff08\u5206\u522b\u4e3a0.594\u548c0.496\uff09\u3002\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u6790\u8868\u660e\uff0c\u7b80\u5355\u7684\u7c7b\u522b\u52a0\u6743\u53ef\u4ee5\u5728\u9002\u5ea6\u964d\u4f4e\u6574\u4f53\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u81f4\u547d\u4e8b\u4ef6\u53ec\u56de\u7387\uff1bSHAP\u5f52\u56e0\u5219\u5f3a\u8c03\u4e86\u4eba\u7c7b\u8106\u5f31\u56e0\u7d20\u3001\u65f6\u673a\u53ca\u5730\u70b9\u4f5c\u4e3a\u9884\u6d4b\u4e25\u91cd\u7a0b\u5ea6\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u89e3\u91ca\u7684\u5c0f\u578b\u6a21\u578b\u96c6\u5408\u5728\u57ce\u5e02\u89c4\u6a21\u7684\u4f24\u5bb3\u5206\u6790\u4e2d\u4ecd\u7136\u4fdd\u6301\u4e3a\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff1b\u540c\u65f6\uff0c\u7ed3\u5408\u8868\u683c\u9884\u6d4b\u5668\u4e0e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u7684\u53d9\u8ff0\u80fd\u591f\u589e\u5f3a\u4ea4\u6d41\u6548\u679c\u800c\u4e0d\u635f\u5bb3\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.08083", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08083", "abs": "https://arxiv.org/abs/2512.08083", "authors": ["Keith Huffman", "Jianping Zhang", "Nathaniel Huber-Fliflet", "Fusheng Wei", "Peter Gronvall"], "title": "Exploiting the Randomness of Large Language Models (LLM) in Text Classification Tasks: Locating Privileged Documents in Legal Matters", "comment": null, "summary": "In legal matters, text classification models are most often used to filter through large datasets in search of documents that meet certain pre-selected criteria like relevance to a certain subject matter, such as legally privileged communications and attorney-directed documents. In this context, large language models have demonstrated strong performance. This paper presents an empirical study investigating the role of randomness in LLM-based classification for attorney-client privileged document detection, focusing on four key dimensions: (1) the effectiveness of LLMs in identifying legally privileged documents, (2) the influence of randomness control parameters on classification outputs, (3) their impact on overall classification performance, and (4) a methodology for leveraging randomness to enhance accuracy. Experimental results showed that LLMs can identify privileged documents effectively, randomness control parameters have minimal impact on classification performance, and importantly, our developed methodology for leveraging randomness can have a significant impact on improving accuracy. Notably, this methodology that leverages randomness could also enhance a corporation's confidence in an LLM's output when incorporated into its sanctions-compliance processes. As organizations increasingly rely on LLMs to augment compliance workflows, reducing output variability helps build internal and regulatory confidence in LLM-derived sanctions-screening decisions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f8b\u5e08-\u5ba2\u6237\u7279\u6743\u6587\u6863\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u968f\u673a\u6027\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\uff0c\u5e76\u6709\u52a9\u4e8e\u589e\u5f3a\u4f01\u4e1a\u5bf9LLM\u8f93\u51fa\u7684\u4fe1\u5fc3\u3002", "motivation": "\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u6765\u8f85\u52a9\u5408\u89c4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u51cf\u5c11\u8f93\u51fa\u53d8\u5f02\u6027\u5bf9\u4e8e\u5efa\u7acb\u5185\u90e8\u548c\u76d1\u7ba1\u673a\u6784\u5bf9\u57fa\u4e8eLLM\u7684\u5236\u88c1\u7b5b\u9009\u51b3\u7b56\u7684\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u4ee5\u53ca\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u4f18\u5316LLM\u5728\u8bc6\u522b\u6cd5\u5f8b\u7279\u6743\u6587\u4ef6\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5bf9\u4f7f\u7528\u4e0d\u540c\u968f\u673a\u6027\u8bbe\u7f6e\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u8bc6\u522b\u5f8b\u5e08-\u5ba2\u6237\u7279\u6743\u6587\u6863\u65f6\u7684\u6709\u6548\u6027\uff1b\u5206\u6790\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u7ed3\u679c\u7684\u5177\u4f53\u5f71\u54cd\uff1b\u5e76\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u968f\u673a\u6027\u4ee5\u589e\u5f3a\u51c6\u786e\u6027\u7684\u65b0\u65b9\u6cd5\u8bba\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u8bc6\u522b\u7279\u6743\u6587\u6863\uff1b\u968f\u673a\u6027\u63a7\u5236\u53c2\u6570\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u8f83\u5c0f\uff1b\u6240\u63d0\u51fa\u7684\u5229\u7528\u968f\u673a\u6027\u6539\u8fdb\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u65b9\u6cd5\u5229\u7528\u968f\u673a\u6027\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f8b\u5e08-\u5ba2\u6237\u7279\u6743\u6587\u6863\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e5f\u6709\u52a9\u4e8e\u63d0\u5347\u4f01\u4e1a\u5bf9\u8be5\u6280\u672f\u5e94\u7528\u4e8e\u5236\u88c1\u5408\u89c4\u8fc7\u7a0b\u7684\u4fe1\u5fc3\u3002"}}
{"id": "2512.08321", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08321", "abs": "https://arxiv.org/abs/2512.08321", "authors": ["Yuki Uchino", "Qianxiang Ma", "Toshiyuki Imamura", "Katsuhisa Ozaki", "Patrick Lars Gutsche"], "title": "Emulation of Complex Matrix Multiplication based on the Chinese Remainder Theorem", "comment": "11 pages, 13 figures", "summary": "Modern computing architectures feature low-precision matrix multiplication units that achieve substantially higher throughput than their high-precision counterparts. Motivated by this architectural trend, the emulation of high-precision matrix multiplication using low-precision hardware has attracted significant interest in the high-performance computing community. Ozaki, Uchino, and Imamura introduced the Ozaki-II scheme as a general framework for emulating matrix multiplication. Building on this framework, Uchino, Ozaki, and Imamura developed high-performance and power-efficient techniques for emulating single- and double-precision real matrix multiplication on INT8 matrix engines. Extending this line of research, the present study proposes high-performance emulation methods for single- and double-precision complex matrix multiplication on INT8 matrix engines, based on the Ozaki-II scheme. On an NVIDIA B200 GPU, the proposed methods achieve 4.0x--5.6x and 4.4x--6.5x speedups over the native single- and double-precision complex matrix multiplication routines from cuBLAS, respectively, for sufficiently large problem sizes. When lower accuracy than that of the standard routine is acceptable, the proposed methods can operate at even higher speed. Conversely, with only a modest increase in computation time, they can also deliver higher accuracy than the standard routines. These properties suggest that the proposed approach has the potential to serve as a default algorithm across a wide range of applications.", "AI": {"tldr": "This paper introduces high-performance methods for emulating single- and double-precision complex matrix multiplication on INT8 hardware, achieving significant speedups over native cuBLAS routines while also offering flexibility in accuracy-speed trade-offs.", "motivation": "The motivation behind this research is the trend towards low-precision computing architectures, which offer higher throughput compared to high-precision units. The goal is to develop efficient techniques for emulating high-precision matrix multiplication using these low-precision hardware, specifically for complex numbers, following the successful application of similar techniques for real numbers.", "method": "The researchers build upon the Ozaki-II scheme, a general framework for emulating matrix multiplication, to develop their methods for single- and double-precision complex matrix multiplication on INT8 matrix engines. These methods are designed to be both high-performance and power-efficient.", "result": "The proposed methods achieve 4.0x--5.6x and 4.4x--6.5x speedups over the native single- and double-precision complex matrix multiplication routines from cuBLAS, respectively, when tested on an NVIDIA B200 GPU. Additionally, they provide options for trading off between speed and accuracy, allowing for either faster execution with lower precision or slightly slower but more accurate results than standard routines.", "conclusion": "The study concludes that the developed methods for emulating complex matrix multiplications on INT8 hardware not only significantly outperform traditional high-precision implementations in terms of speed but also offer a flexible balance between computational efficiency and result accuracy, making them suitable as a default algorithm across various applications."}}
{"id": "2512.08032", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.08032", "abs": "https://arxiv.org/abs/2512.08032", "authors": ["Arghavan Sanei", "Chaima Amiri", "Atefeh Shokrizadeh", "Jinghui Cheng"], "title": "What Pulls the Strings? Understanding the Characteristics and Role of Argumentation in Open-Source Software Usability Discussions", "comment": "22 pages, 6 figures", "summary": "The usability of open-source software (OSS) is important but frequently overlooked in favor of technical and functional complexity. Argumentation can be a pivotal device for diverse stakeholders in OSS usability discussions to express opinions and persuade others. However, the characteristics of argument discourse in those discussions remain unknown, resulting in difficulties in providing effective support for discussion participants. We address this through a comprehensive analysis of argument discourse and quality in five OSS projects. Our results indicated that usability discussions are predominantly argument-driven, although their qualities vary. Issue comments exhibit lower-quality arguments than the issue posts, suggesting a shortage of collective intelligence about usability in OSS communities. Moreover, argument discourse and quality have various impacts on the subsequent behavior of participants. Overall, this research offers insights to help OSS stakeholders build more effective arguments and eventually improve OSS usability. These insights can also inform studies about other distributed collaborative communities.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u4e94\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u8bba\u70b9\u8bdd\u8bed\u548c\u8d28\u91cf\uff0c\u63ed\u793a\u4e86\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u53ef\u7528\u6027\u8ba8\u8bba\u4e3b\u8981\u7531\u8bba\u70b9\u9a71\u52a8\uff0c\u4f46\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u3002\u95ee\u9898\u8bc4\u8bba\u6bd4\u539f\u59cb\u5e16\u5b50\u663e\u793a\u51fa\u66f4\u4f4e\u7684\u8bba\u70b9\u8d28\u91cf\uff0c\u8868\u660e\u5728OSS\u793e\u533a\u4e2d\u5173\u4e8e\u53ef\u7528\u6027\u7684\u96c6\u4f53\u667a\u6167\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u8bba\u70b9\u7684\u8bdd\u8bed\u548c\u8d28\u91cf\u5bf9\u53c2\u4e0e\u8005\u540e\u7eed\u884c\u4e3a\u6709\u7740\u4e0d\u540c\u7684\u5f71\u54cd\u3002\u8be5\u7814\u7a76\u4e3a\u63d0\u9ad8OSS\u7684\u53ef\u7528\u6027\u548c\u652f\u6301\u5206\u5e03\u5f0f\u534f\u4f5c\u793e\u533a\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "motivation": "\u5c3d\u7ba1\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u7684\u53ef\u7528\u6027\u5f88\u91cd\u8981\uff0c\u4f46\u5728\u5f80\u5f80\u88ab\u6280\u672f\u4e0e\u529f\u80fd\u590d\u6742\u6027\u6240\u63a9\u76d6\u3002\u4e89\u8bba\u5728OSS\u53ef\u7528\u6027\u8ba8\u8bba\u4e2d\u5bf9\u4e8e\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u8868\u8fbe\u610f\u89c1\u548c\u8bf4\u670d\u4ed6\u4eba\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u8ba8\u8bba\u4e2d\u8bba\u70b9\u8bdd\u8bed\u7684\u7279\u70b9\u5c1a\u4e0d\u6e05\u695a\uff0c\u5bfc\u81f4\u96be\u4ee5\u5411\u8ba8\u8bba\u53c2\u4e0e\u8005\u63d0\u4f9b\u6709\u6548\u7684\u652f\u6301\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9\u4e94\u4e2aOSS\u9879\u76ee\u7684\u8bba\u70b9\u8bdd\u8bed\u548c\u8d28\u91cf\u8fdb\u884c\u5168\u9762\u5206\u6790\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u7528\u6027\u8ba8\u8bba\u4e3b\u8981\u662f\u7531\u8bba\u70b9\u9a71\u52a8\u7684\uff0c\u4e0d\u8fc7\u5b83\u4eec\u7684\u8d28\u91cf\u5b58\u5728\u5dee\u5f02\uff1b\u95ee\u9898\u8bc4\u8bba\u4e2d\u7684\u8bba\u70b9\u8d28\u91cf\u4f4e\u4e8e\u539f\u5e16\u53d1\u5e03\u7684\u8bba\u70b9\u8d28\u91cf\uff0c\u8fd9\u6697\u793a\u4e86OSS\u793e\u7fa4\u4e2d\u6709\u5173\u53ef\u7528\u6027\u7684\u96c6\u4f53\u667a\u6167\u6709\u6240\u6b20\u7f3a\u3002\u53e6\u5916\uff0c\u8bba\u70b9\u8bdd\u8bed\u53ca\u5176\u8d28\u91cf\u5bf9\u53c2\u4e0e\u8005\u7684\u540e\u7eed\u884c\u4e3a\u4ea7\u751f\u591a\u79cd\u5f71\u54cd\u3002", "conclusion": "\u603b\u7684\u6765\u8bf4\uff0c\u8fd9\u9879\u7814\u7a76\u4e3a\u5e2e\u52a9OSS\u5229\u76ca\u76f8\u5173\u8005\u6784\u5efa\u66f4\u6709\u6548\u7684\u8bba\u636e\uff0c\u5e76\u6700\u7ec8\u6539\u5584OSS\u7684\u53ef\u7528\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002\u8fd9\u4e9b\u89c1\u89e3\u4e5f\u53ef\u4ee5\u4e3a\u5176\u4ed6\u5206\u5e03\u5f0f\u534f\u4f5c\u793e\u533a\u7684\u7814\u7a76\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2512.08398", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08398", "abs": "https://arxiv.org/abs/2512.08398", "authors": ["Jiin Park", "Hyuna Jeon", "Yoonseo Lee", "Jisu Hong", "Misuk Kim"], "title": "Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring", "comment": null, "summary": "Ontology-based knowledge graph (KG) construction is a core technology that enables multidimensional understanding and advanced reasoning over domain knowledge. Industrial standards, in particular, contain extensive technical information and complex rules presented in highly structured formats that combine tables, scopes of application, constraints, exceptions, and numerical calculations, making KG construction especially challenging. In this study, we propose a method that organizes such documents into a hierarchical semantic structure, decomposes sentences and tables into atomic propositions derived from conditional and numerical rules, and integrates them into an ontology-knowledge graph through LLM-based triple extraction. Our approach captures both the hierarchical and logical structures of documents, effectively representing domain-specific semantics that conventional methods fail to reflect. To verify its effectiveness, we constructed rule, table, and multi-hop QA datasets, as well as a toxic clause detection dataset, from industrial standards, and implemented an ontology-aware KG-RAG framework for comparative evaluation. Experimental results show that our method achieves significant performance improvements across all QA types compared to existing KG-RAG approaches. This study demonstrates that reliable and scalable knowledge representation is feasible even for industrial documents with intertwined conditions, constraints, and scopes, contributing to future domain-specific RAG development and intelligent document management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ec4\u7ec7\u6587\u6863\u7684\u5c42\u6b21\u8bed\u4e49\u7ed3\u6784\u3001\u5206\u89e3\u53e5\u5b50\u548c\u8868\u683c\u4e3a\u539f\u5b50\u547d\u9898\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u5143\u7ec4\u63d0\u53d6\u5c06\u5176\u6574\u5408\u5230\u672c\u4f53-\u77e5\u8bc6\u56fe\u8c31\u4e2d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u7c7b\u578b\u7684\u95ee\u7b54\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5de5\u4e1a\u6807\u51c6\u5305\u542b\u4e86\u5927\u91cf\u6280\u672f\u4fe1\u606f\u548c\u590d\u6742\u89c4\u5219\uff0c\u8fd9\u4e9b\u5185\u5bb9\u4ee5\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u683c\u5f0f\u5448\u73b0\uff0c\u5305\u62ec\u8868\u683c\u3001\u9002\u7528\u8303\u56f4\u3001\u7ea6\u675f\u6761\u4ef6\u3001\u4f8b\u5916\u60c5\u51b5\u4ee5\u53ca\u6570\u503c\u8ba1\u7b97\u7b49\uff0c\u8fd9\u4f7f\u5f97\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u7684\u6784\u5efa\u53d8\u5f97\u7279\u522b\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u7684\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5730\u53cd\u6620\u9886\u57df\u7279\u5b9a\u7684\u8bed\u4e49\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5b83\u9996\u5148\u5c06\u6587\u6863\u7ec4\u7ec7\u6210\u4e00\u4e2a\u5c42\u6b21\u5316\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u7136\u540e\u5c06\u53e5\u5b50\u548c\u8868\u683c\u5206\u89e3\u4e3a\u6e90\u81ea\u6761\u4ef6\u548c\u6570\u503c\u89c4\u5219\u7684\u539f\u5b50\u547d\u9898\uff0c\u6700\u540e\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e09\u5143\u7ec4\u63d0\u53d6\u6280\u672f\u5c06\u8fd9\u4e9b\u539f\u5b50\u547d\u9898\u96c6\u6210\u5230\u672c\u4f53-\u77e5\u8bc6\u56fe\u8c31\u4e2d\u3002", "result": "\u4e3a\u4e86\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4ece\u5de5\u4e1a\u6807\u51c6\u4e2d\u6784\u5efa\u4e86\u89c4\u5219\u3001\u8868\u683c\u53ca\u591a\u8df3QA\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u6709\u6bd2\u6761\u6b3e\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u672c\u4f53\u611f\u77e5\u7684KG-RAG\u6846\u67b6\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6240\u6709\u7c7b\u578b\u7684\u95ee\u7b54\u4e0a\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684KG-RAG\u65b9\u6cd5\uff0c\u6240\u63d0\u65b9\u6cd5\u5747\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5bf9\u4e8e\u90a3\u4e9b\u5305\u542b\u4ea4\u7ec7\u6761\u4ef6\u3001\u7ea6\u675f\u548c\u8303\u56f4\u7684\u5de5\u4e1a\u6587\u6863\u6765\u8bf4\uff0c\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u8868\u793a\u4e5f\u662f\u53ef\u884c\u7684\uff0c\u8fd9\u6709\u52a9\u4e8e\u672a\u6765\u9886\u57df\u7279\u5b9aRAG\u7684\u53d1\u5c55\u548c\u667a\u80fd\u6587\u6863\u7ba1\u7406\u3002"}}
{"id": "2512.08365", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08365", "abs": "https://arxiv.org/abs/2512.08365", "authors": ["Yi Pan", "Wenbo Qian", "Dedong Xie", "Ruiyan Hu", "Yigong Hu", "Baris Kasikci"], "title": "Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging", "comment": "12 pages, 10 fi", "summary": "The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving performance. These inefficiencies arise in widely used ML frameworks and applications, yet developers often lack the visibility and tools to detect and diagnose them.\n  We propose differential energy debugging, a novel approach that leverages the observation that competing ML systems often implement similar functionality with vastly different energy consumption. Building on this insight, we design and implement Magneton, an energy profiler that compares energy consumption between similar ML systems at the operator level and automatically pinpoints code regions and configuration choices responsible for excessive energy use. Applied to 9 popular ML systems spanning LLM inference, general ML frameworks, and image generation, Magneton detects and diagnoses 16 known cases of software energy inefficiency and further discovers 8 previously unknown cases, 7 of which have been confirmed by developers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014\u5dee\u5f02\u80fd\u91cf\u8c03\u8bd5\uff0c\u901a\u8fc7\u8be5\u65b9\u6cd5\u5f00\u53d1\u4e86Magneton\u8fd9\u4e00\u80fd\u91cf\u5206\u6790\u5de5\u5177\uff0c\u80fd\u591f\u6bd4\u8f83\u7c7b\u4f3c\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e4b\u95f4\u7684\u80fd\u8017\uff0c\u5e76\u81ea\u52a8\u8bc6\u522b\u5bfc\u81f4\u8fc7\u5ea6\u80fd\u8017\u7684\u4ee3\u7801\u533a\u57df\u548c\u914d\u7f6e\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u7684\u4f18\u5316\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u786c\u4ef6\u80fd\u6548\u4e0a\uff0c\u800c\u8f6f\u4ef6\u8bbe\u8ba1\u4e0d\u4f73\u5bfc\u81f4\u7684\u80fd\u6e90\u6d6a\u8d39\u5f80\u5f80\u88ab\u5ffd\u89c6\u3002\u8fd9\u79cd\u4f4e\u6548\u7387\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u548c\u5e94\u7528\u4e2d\u51fa\u73b0\uff0c\u4f46\u5f00\u53d1\u8005\u901a\u5e38\u7f3a\u4e4f\u68c0\u6d4b\u548c\u8bca\u65ad\u8fd9\u4e9b\u95ee\u9898\u7684\u53ef\u89c1\u6027\u548c\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u5dee\u5f02\u80fd\u91cf\u8c03\u8bd5\u65b9\u6cd5\uff0c\u57fa\u4e8e\u4e0d\u540cML\u7cfb\u7edf\u5373\u4f7f\u5b9e\u73b0\u76f8\u4f3c\u529f\u80fd\u65f6\u4e5f\u53ef\u80fd\u5b58\u5728\u5de8\u5927\u80fd\u8017\u5dee\u5f02\u8fd9\u4e00\u89c2\u5bdf\u7ed3\u679c\u3002\u57fa\u4e8e\u6b64\u6d1e\u5bdf\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86Magneton\uff0c\u4e00\u4e2a\u80fd\u591f\u5728\u64cd\u4f5c\u5458\u7ea7\u522b\u6bd4\u8f83\u76f8\u4f3cML\u7cfb\u7edf\u4e4b\u95f4\u80fd\u8017\u7684\u80fd\u91cf\u5206\u6790\u5668\uff0c\u81ea\u52a8\u5b9a\u4f4d\u9020\u6210\u8fc7\u5ea6\u80fd\u8017\u7684\u4ee3\u7801\u533a\u57df\u548c\u914d\u7f6e\u9009\u9879\u3002", "result": "\u5c06Magneton\u5e94\u7528\u4e8e9\u4e2a\u6d41\u884c\u7684ML\u7cfb\u7edf\uff08\u5305\u62ecLLM\u63a8\u7406\u3001\u901a\u7528ML\u6846\u67b6\u548c\u56fe\u50cf\u751f\u6210\uff09\uff0c\u6210\u529f\u68c0\u6d4b\u5e76\u8bca\u65ad\u51fa16\u4e2a\u5df2\u77e5\u7684\u8f6f\u4ef6\u80fd\u8017\u6548\u7387\u4f4e\u4e0b\u6848\u4f8b\uff0c\u5e76\u8fdb\u4e00\u6b65\u53d1\u73b0\u4e868\u4e2a\u5148\u524d\u672a\u77e5\u7684\u60c5\u51b5\uff0c\u5176\u4e2d7\u4e2a\u5df2\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5dee\u5f02\u80fd\u91cf\u8c03\u8bd5\u53ca\u5176\u5b9e\u73b0\u5de5\u5177Magneton\uff0c\u7814\u7a76\u4eba\u5458\u4e3a\u89e3\u51b3\u8f6f\u4ef6\u5c42\u9762\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u8017\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6574\u4f53\u7cfb\u7edf\u7684\u80fd\u6548\u3002"}}
{"id": "2512.08213", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08213", "abs": "https://arxiv.org/abs/2512.08213", "authors": ["Md Nazmul Haque", "Elizabeth Lin", "Lawrence Arkoh", "Biruk Tadesse", "Bowen Xu"], "title": "Secure or Suspect? Investigating Package Hallucinations of Shell Command in Original and Quantized LLMs", "comment": null, "summary": "Large Language Models for code (LLMs4Code) are increasingly used to generate software artifacts, including library and package recommendations in languages such as Go. However, recent evidence shows that LLMs frequently hallucinate package names or generate dependencies containing known security vulnerabilities, posing significant risks to developers and downstream software supply chains. At the same time, quantization has become a widely adopted technique to reduce inference cost and enable deployment of LLMs on resource-constrained environments. Despite its popularity, little is known about how quantization affects the correctness and security of LLM-generated software dependencies while generating shell commands for package installation.\n  In this work, we conduct the first systematic empirical study of the impact of quantization on package hallucination and vulnerability risks in LLM-generated Go packages. We evaluate five Qwen model sizes under full-precision, 8-bit, and 4-bit quantization across three datasets (SO, MBPP, and paraphrase). Our results show that quantization substantially increases the package hallucination rate (PHR), with 4-bit models exhibiting the most severe degradation. We further find that even among the correctly generated packages, the vulnerability presence rate (VPR) rises as precision decreases, indicating elevated security risk in lower-precision models. Finally, our analysis of hallucinated outputs reveals that most fabricated packages resemble realistic URL-based Go module paths, such as most commonly malformed or non-existent GitHub and golang.org repositories, highlighting a systematic pattern in how LLMs hallucinate dependencies. Overall, our findings provide actionable insights into the reliability and security implications of deploying quantized LLMs for code generation and dependency recommendation.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5730\u63a2\u8ba8\u4e86\u91cf\u5316\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684Go\u8bed\u8a00\u5305\u4e2d\u7684\u5305\u5e7b\u89c9\u7387\u548c\u6f0f\u6d1e\u98ce\u9669\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u91cf\u5316\u663e\u8457\u589e\u52a0\u4e86\u5305\u5e7b\u89c9\u7387\uff0c\u5c24\u5176\u662f4\u4f4d\u91cf\u5316\u6a21\u578b\u8868\u73b0\u6700\u4e3a\u4e25\u91cd\u3002\u540c\u65f6\uff0c\u5373\u4f7f\u5728\u6b63\u786e\u751f\u6210\u7684\u5305\u4e2d\uff0c\u968f\u7740\u7cbe\u5ea6\u964d\u4f4e\u5b89\u5168\u6f0f\u6d1e\u51fa\u73b0\u7387\u4e5f\u4f1a\u4e0a\u5347\uff0c\u63ed\u793a\u4e86\u90e8\u7f72\u91cf\u5316\u540e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u548c\u4f9d\u8d56\u63a8\u8350\u65f6\u53ef\u80fd\u5e26\u6765\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4e8e\u751f\u6210\u8f6f\u4ef6\u5de5\u4ef6\uff0c\u5305\u62ec\u5e93\u548c\u5305\u7684\u63a8\u8350\uff0c\u4f46\u6700\u8fd1\u7684\u8bc1\u636e\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u5e38\u5e38\u4f1a\u5e7b\u60f3\u51fa\u4e0d\u5b58\u5728\u7684\u5305\u540d\u6216\u751f\u6210\u542b\u6709\u5df2\u77e5\u5b89\u5168\u6f0f\u6d1e\u7684\u4f9d\u8d56\u9879\uff0c\u7ed9\u5f00\u53d1\u8005\u53ca\u4e0b\u6e38\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5e26\u6765\u4e86\u91cd\u5927\u98ce\u9669\u3002\u540c\u65f6\uff0c\u5c3d\u7ba1\u91cf\u5316\u6280\u672f\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\u4ee5\u51cf\u5c11\u63a8\u7406\u6210\u672c\u5e76\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u4f46\u5bf9\u4e8e\u91cf\u5316\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u8f6f\u4ef6\u4f9d\u8d56\u9879\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u5374\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u7814\u7a76\u4eba\u5458\u9009\u62e9\u4e86\u4e94\u79cd\u4e0d\u540c\u89c4\u6a21\u7684Qwen\u6a21\u578b\uff0c\u5728\u5168\u7cbe\u5ea6\u30018\u4f4d\u4ee5\u53ca4\u4f4d\u91cf\u5316\u6761\u4ef6\u4e0b\uff0c\u9488\u5bf9SO\u3001MBPP\u548cparaphrase\u4e09\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u91cf\u5316\u663e\u8457\u63d0\u9ad8\u4e86\u5305\u5e7b\u89c9\u7387\uff08PHR\uff09\uff0c\u5176\u4e2d4\u4f4d\u6a21\u578b\u9000\u5316\u6700\u4e3a\u4e25\u91cd\uff1b\u800c\u4e14\u5373\u4fbf\u662f\u5728\u90a3\u4e9b\u6b63\u786e\u751f\u6210\u7684\u5305\u91cc\uff0c\u968f\u7740\u7cbe\u5ea6\u4e0b\u964d\u5176\u5305\u542b\u7684\u5b89\u5168\u6f0f\u6d1e\u5b58\u5728\u7387\uff08VPR\uff09\u4e5f\u6709\u6240\u4e0a\u5347\uff1b\u6b64\u5916\uff0c\u5206\u6790\u8fd8\u53d1\u73b0\u5927\u591a\u6570\u865a\u6784\u51fa\u6765\u7684\u5305\u770b\u8d77\u6765\u50cf\u771f\u5b9e\u7684\u57fa\u4e8eURL\u7684Go\u6a21\u5757\u8def\u5f84\uff0c\u6bd4\u5982\u6700\u5e38\u89c1\u7684\u9519\u8bef\u683c\u5f0f\u6216\u4e0d\u5b58\u5728\u4e8eGitHub\u548cgolang.org\u4e0a\u7684\u4ed3\u5e93\u5730\u5740\u3002", "conclusion": "\u603b\u4f53\u800c\u8a00\uff0c\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u90e8\u7f72\u91cf\u5316\u540e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u751f\u6210\u548c\u4f9d\u8d56\u63a8\u8350\u65f6\u6240\u9762\u4e34\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\u6311\u6218\u7684\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2512.08702", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.08702", "abs": "https://arxiv.org/abs/2512.08702", "authors": ["Jinfeng Xu", "Zheyu Chen", "Shuo Yang", "Jinze Li", "Zitong Wan", "Hewei Wang", "Weijie Liu", "Yijie Li", "Edith C. H. Ngai"], "title": "VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation", "comment": "Accepted by KDD 2026", "summary": "Although existing multimodal recommendation models have shown promising performance, their effectiveness continues to be limited by the pervasive data sparsity problem. This problem arises because users typically interact with only a small subset of available items, leading existing models to arbitrarily treat unobserved items as negative samples. To this end, we propose VI-MMRec, a model-agnostic and training cost-free framework that enriches sparse user-item interactions via similarity-aware virtual user-item interactions. These virtual interactions are constructed based on modality-specific feature similarities of user-interacted items. Specifically, VI-MMRec introduces two different strategies: (1) Overlay, which independently aggregates modality-specific similarities to preserve modality-specific user preferences, and (2) Synergistic, which holistically fuses cross-modal similarities to capture complementary user preferences. To ensure high-quality augmentation, we design a statistically informed weight allocation mechanism that adaptively assigns weights to virtual user-item interactions based on dataset-specific modality relevance. As a plug-and-play framework, VI-MMRec seamlessly integrates with existing models to enhance their performance without modifying their core architecture. Its flexibility allows it to be easily incorporated into various existing models, maximizing performance with minimal implementation effort. Moreover, VI-MMRec introduces no additional overhead during training, making it significantly advantageous for practical deployment. Comprehensive experiments conducted on six real-world datasets using seven state-of-the-art multimodal recommendation models validate the effectiveness of our VI-MMRec.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVI-MMRec\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u57fa\u4e8e\u7528\u6237\u4ea4\u4e92\u9879\u7684\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u76f8\u4f3c\u6027\u6784\u5efa\u865a\u62df\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u6765\u4e30\u5bcc\u7a00\u758f\u7684\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u3002VI-MMRec\u5f15\u5165\u4e86\u4e24\u79cd\u4e0d\u540c\u7684\u7b56\u7565\uff08Overlay\u548cSynergistic\uff09\u6765\u5904\u7406\u6a21\u6001\u7279\u5b9a\u504f\u597d\u53ca\u4e92\u8865\u504f\u597d\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7edf\u8ba1\u4fe1\u606f\u9a71\u52a8\u7684\u6743\u91cd\u5206\u914d\u673a\u5236\u4ee5\u81ea\u9002\u5e94\u5730\u4e3a\u865a\u62df\u4ea4\u4e92\u5206\u914d\u6743\u91cd\u3002\u4f5c\u4e3a\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u6846\u67b6\uff0cVI-MMRec\u80fd\u591f\u4e0e\u73b0\u6709\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\uff0c\u63d0\u9ad8\u6027\u80fd\u800c\u65e0\u9700\u4fee\u6539\u5176\u6838\u5fc3\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u5c3d\u7ba1\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4ecd\u7136\u53d7\u5230\u6570\u636e\u7a00\u758f\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a\u7528\u6237\u901a\u5e38\u53ea\u4e0e\u4e00\u5c0f\u90e8\u5206\u53ef\u7528\u9879\u76ee\u8fdb\u884c\u4e92\u52a8\uff0c\u5bfc\u81f4\u73b0\u6709\u6a21\u578b\u5c06\u672a\u89c2\u5bdf\u5230\u7684\u9879\u76ee\u968f\u610f\u89c6\u4e3a\u8d1f\u9762\u6837\u672c\u3002", "method": "\u63d0\u51fa\u4e86VI-MMRec\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u7528\u6237\u5df2\u4ea4\u4e92\u9879\u76ee\u7684\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u76f8\u4f3c\u6027\u751f\u6210\u865a\u62df\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\uff0c\u4ee5\u6b64\u6765\u6269\u5145\u7a00\u758f\u7684\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u6570\u636e\u3002VI-MMRec\u5305\u62ec\u4e24\u79cd\u7b56\u7565\uff1a(1) Overlay\uff0c\u72ec\u7acb\u805a\u5408\u6a21\u6001\u7279\u5b9a\u76f8\u4f3c\u6027\u4ee5\u4fdd\u7559\u6a21\u6001\u7279\u5b9a\u7528\u6237\u504f\u597d\uff1b(2) Synergistic\uff0c\u7efc\u5408\u878d\u5408\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\u4ee5\u6355\u6349\u4e92\u8865\u7528\u6237\u504f\u597d\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6839\u636e\u6570\u636e\u96c6\u7279\u5b9a\u6a21\u6001\u76f8\u5173\u6027\u81ea\u9002\u5e94\u5206\u914d\u6743\u91cd\u7ed9\u865a\u62df\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u7684\u673a\u5236\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u4e03\u79cd\u6700\u5148\u8fdb\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86VI-MMRec\u7684\u6709\u6548\u6027\u3002", "conclusion": "VI-MMRec\u4f5c\u4e3a\u4e00\u6b3e\u6a21\u578b\u65e0\u5173\u4e14\u65e0\u8bad\u7ec3\u6210\u672c\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u7a00\u758f\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u539f\u6709\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b83\u5177\u6709\u7075\u6d3b\u6027\u9ad8\u3001\u6613\u4e8e\u5b9e\u73b0\u7b49\u4f18\u70b9\uff0c\u975e\u5e38\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.08563", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08563", "abs": "https://arxiv.org/abs/2512.08563", "authors": ["Taras Skazhenik", "Nikolai Korobenikov", "Andrei Churbanov", "Anton Malakhov", "Vitaly Aksenov"], "title": "Basic Lock Algorithms in Lightweight Thread Environments", "comment": null, "summary": "Traditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed.\n  In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations.\n  In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\uff08\u4e5f\u79f0\u4e3a\u5f02\u6b65\u8c03\u7528\u6216\u534f\u7a0b\uff09\u8bbf\u95ee\u7684\u4e92\u65a5\u9501\u5b9e\u73b0\uff0c\u6307\u51fa\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u7ebf\u7a0b\u8bbe\u8ba1\u7684\u4e92\u65a5\u9501\u5728\u65b0\u73af\u5883\u4e2d\u53ef\u80fd\u5f15\u53d1\u6b7b\u9501\u95ee\u9898\uff0c\u5e76\u4e14\u4e0d\u540c\u7684\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u5e93\u9700\u8981\u7279\u5b9a\u7684\u9501\u5b9e\u73b0\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u5bf9TTAS\u548cMCS\u9501\u7684\u4fee\u6539\u7248\u672c\u4ee5\u9002\u5e94\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\uff0c\u5e76\u5efa\u8bae\u4f7f\u7528\u961f\u5217\u9501\u6765\u5e73\u8861\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u8bbf\u95ee\u7684\u6570\u636e\u7ed3\u6784\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u4e92\u65a5\u9501\u7684\u8bbe\u8ba1\u9700\u8981\u8003\u8651\u624b\u52a8\u4e0a\u4e0b\u6587\u5207\u6362\u7684\u7279\u70b9\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7684\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u5e93\u6709\u7740\u4e0d\u540c\u7684\u5b9e\u73b0\u548c\u63a5\u53e3\uff0c\u8fd9\u8981\u6c42\u5f00\u53d1\u4e0e\u4e4b\u76f8\u9002\u5e94\u7684\u4e0d\u540c\u9501\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5bf9\u73b0\u6709\u7684TTAS\u548cMCS\u9501\u8fdb\u884c\u4fee\u6539\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u73af\u5883\u3002\u7814\u7a76\u4e2d\u6bd4\u8f83\u4e86\u4e24\u79cd\u4e0a\u4e0b\u6587\u5207\u6362\u673a\u5236\uff1ayielding\uff08\u8ba9\u51fa\uff09\u548csleeping\uff08\u4f11\u7720\uff09\uff0c\u5e76\u5206\u6790\u5b83\u4eec\u5bf9\u4e8e\u9501\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4fee\u6539\u540e\u7684TTAS\u548cMCS\u9501\u80fd\u591f\u5728\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u73af\u5883\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u4f46\u5176\u6027\u80fd\u4f1a\u6839\u636e\u5177\u4f53\u8bbe\u7f6e\u800c\u6709\u5f88\u5927\u5dee\u5f02\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63a8\u8350\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u591a\u4e2aMCS\u961f\u5217\u4e0e\u4e00\u4e2a\u5171\u4eabTTAS\u7684\u961f\u5217\u9501\u65b9\u6848\u3002", "conclusion": "\u4e3a\u4e86\u786e\u4fdd\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u80fd\u591f\u9ad8\u6548\u5730\u4f7f\u7528\u4e92\u65a5\u9501\uff0c\u9700\u8981\u7279\u522b\u8bbe\u8ba1\u9002\u5408\u8fd9\u79cd\u73af\u5883\u7684\u9501\u673a\u5236\u3002\u6587\u4e2d\u63d0\u51fa\u7684\u961f\u5217\u9501\u65b9\u6848\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u901a\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u79cd\u8f7b\u91cf\u7ea7\u7ebf\u7a0b\u5e93\u4e2d\u63d0\u4f9b\u8f83\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2512.08245", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08245", "abs": "https://arxiv.org/abs/2512.08245", "authors": ["Julien Cardinal", "Imen Benzarti", "Ghizlane El boussaidi", "Christophe Pere"], "title": "Migrating QAOA from Qiskit 1.x to 2.x: An experience report", "comment": null, "summary": "Migrating quantum algorithms across evolving frameworks introduces subtle behavioral changes that affect accuracy and reproducibility. This paper reports our experience converting the Quantum Approximate Optimization Algorithm (QAOA) from Qiskit Algorithms with Qiskit 1.x (v1 primitives) to a custom implementation using Qiskit 2.x (v2 primitives). Despite identical circuits, optimizers, and Hamiltonians, the new version produced drastically different results. A systematic analysis revealed the root cause: the sampling budget -- the number of circuit executions (shots) per iteration. The library's implicit use of unlimited shots yielded dense probability distributions, whereas the v2 default of 10 000 shots captured only 23% of the state space. Increasing shots to 250 000 restored library-level accuracy. This study highlights how hidden parameters at the quantum--classical interaction level can dominate hybrid algorithm performance and provides actionable recommendations for developers and framework designers to ensure reproducible results in quantum software migration.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5c06\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u4eceQiskit 1.x\u8fc1\u79fb\u5230Qiskit 2.x\uff0c\u63ed\u793a\u4e86\u91c7\u6837\u9884\u7b97\uff08\u5373\u6bcf\u8fed\u4ee3\u7535\u8def\u6267\u884c\u6b21\u6570\uff09\u5bf9\u7ed3\u679c\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002\u5c3d\u7ba1\u7535\u8def\u3001\u4f18\u5316\u5668\u548c\u54c8\u5bc6\u987f\u91cf\u76f8\u540c\uff0c\u65b0\u7248\u672c\u7684\u7ed3\u679c\u5374\u5927\u76f8\u5f84\u5ead\uff0c\u539f\u56e0\u662fQiskit 2.x\u9ed8\u8ba4\u768410,000\u6b21\u91c7\u6837\u4ec5\u8986\u76d6\u4e86\u72b6\u6001\u7a7a\u95f4\u768423%\u3002\u589e\u52a0\u91c7\u6837\u5230250,000\u6b21\u6062\u590d\u4e86\u51c6\u786e\u5ea6\u3002", "motivation": "\u8fc1\u79fb\u91cf\u5b50\u7b97\u6cd5\u81f3\u65b0\u6846\u67b6\u65f6\u53ef\u80fd\u4f1a\u5f15\u5165\u7ec6\u5fae\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u8fd9\u4e9b\u53d8\u5316\u4f1a\u5f71\u54cd\u7b97\u6cd5\u7684\u51c6\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8fd9\u79cd\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u95ee\u9898\uff0c\u5e76\u627e\u51fa\u5bfc\u81f4\u7ed3\u679c\u5dee\u5f02\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5c06QAOA\u4ece\u4f7f\u7528Qiskit 1.x\u7684Qiskit Algorithms\u8f6c\u6362\u4e3a\u57fa\u4e8eQiskit 2.x\u81ea\u5b9a\u4e49\u5b9e\u73b0\u3002\u4ed6\u4eec\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u7535\u8def\u8bbe\u8ba1\u3001\u4f18\u5316\u5668\u53ca\u54c8\u5bc6\u987f\u91cf\u8bbe\u5b9a\uff0c\u4f46\u6ce8\u610f\u5230\u5728\u65b0\u7684\u5b9e\u73b0\u4e2d\u5f97\u5230\u4e86\u622a\u7136\u4e0d\u540c\u7684\u7ed3\u679c\u3002\u968f\u540e\uff0c\u901a\u8fc7\u5bf9\u95ee\u9898\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u7684\u7535\u8def\u6267\u884c\u6b21\u6570\uff08\u91c7\u6837\u9884\u7b97\uff09\u8fdb\u884c\u4e86\u6df1\u5165\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cQiskit 1.x\u5e93\u9690\u5f0f\u5730\u91c7\u7528\u4e86\u65e0\u9650\u6b21\u7684\u91c7\u6837\u9884\u7b97\uff0c\u8fd9\u4f7f\u5f97\u80fd\u591f\u83b7\u5f97\u5bc6\u96c6\u7684\u6982\u7387\u5206\u5e03\uff1b\u800cQiskit 2.x\u7684\u9ed8\u8ba4\u8bbe\u7f6e\u4ec5\u4e3a10,000\u6b21\u91c7\u6837\uff0c\u53ea\u80fd\u6355\u6349\u5230\u5927\u7ea623%\u7684\u72b6\u6001\u7a7a\u95f4\u3002\u901a\u8fc7\u5c06\u91c7\u6837\u6b21\u6570\u63d0\u9ad8\u5230250,000\u6b21\uff0c\u7814\u7a76\u8005\u4eec\u6210\u529f\u6062\u590d\u5230\u4e86\u4e0e\u539f\u59cb\u5e93\u76f8\u5f53\u7684\u7ed3\u679c\u7cbe\u5ea6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5728\u91cf\u5b50-\u7ecf\u5178\u4ea4\u4e92\u5c42\u9762\u4e0a\u9690\u85cf\u53c2\u6570\u5982\u91c7\u6837\u9884\u7b97\u53ef\u4ee5\u663e\u8457\u5f71\u54cd\u6df7\u5408\u578b\u91cf\u5b50\u7b97\u6cd5\u7684\u8868\u73b0\u3002\u4e3a\u4e86\u786e\u4fdd\u91cf\u5b50\u8f6f\u4ef6\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u7684\u7ed3\u679c\u53ef\u518d\u73b0\u6027\uff0c\u5f00\u53d1\u8005\u548c\u6846\u67b6\u8bbe\u8ba1\u8005\u5e94\u91cd\u89c6\u5e76\u9002\u5f53\u8c03\u6574\u8fd9\u4e9b\u53c2\u6570\u3002"}}
{"id": "2512.08698", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08698", "abs": "https://arxiv.org/abs/2512.08698", "authors": ["Ilya Kokorin", "Evgeny Chernatskiy", "Vitaly Aksenov"], "title": "Model-based Testing of Practical Distributed Systems in Actor Model", "comment": "16 pages", "summary": "Designing and implementing distributed systems correctly can be quite challenging. Although these systems are often accompanied by formal specifications that are verified using model-checking techniques, a gap still exists between the implementation and its formal specification: there is no guarantee that the implementation is free of bugs.\n  To bridge this gap, we can use model-based testing. Specifically, if the model of the system can be interpreted as a finite-state automaton, we can generate an exhaustive test suite for the implementation that covers all possible states and transitions.\n  In this paper, we discuss how to efficiently generate such a test suite for distributed systems written in the actor model. Importantly, our approach does not require any modifications to the code or interfering with the distributed system execution environment. As an example, we verified an implementation of a replication algorithm based on Viewstamped Replication, which is used in a real-world system.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e3a\u91c7\u7528actor\u6a21\u578b\u7f16\u5199\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u751f\u6210\u8be6\u5c3d\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u4ece\u800c\u786e\u4fdd\u5b9e\u73b0\u4e0e\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u8bbe\u8ba1\u548c\u5b9e\u73b0\u6b63\u786e\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u9762\u4e34\u6311\u6218\uff0c\u5c3d\u7ba1\u8fd9\u4e9b\u7cfb\u7edf\u901a\u5e38\u4f1a\u9644\u5e26\u7ecf\u8fc7\u6a21\u578b\u68c0\u67e5\u6280\u672f\u9a8c\u8bc1\u7684\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u4f46\u5b9e\u73b0\u4e0e\u5176\u5f62\u5f0f\u5316\u89c4\u8303\u4e4b\u95f4\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u5c06\u7cfb\u7edf\u6a21\u578b\u89e3\u91ca\u4e3a\u6709\u9650\u72b6\u6001\u673a\u7684\u65b9\u6cd5\uff0c\u5e76\u9488\u5bf9\u4f7f\u7528actor\u6a21\u578b\u7f16\u5199\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u9ad8\u6548\u5730\u751f\u6210\u8986\u76d6\u6240\u6709\u53ef\u80fd\u72b6\u6001\u548c\u8f6c\u6362\u7684\u8be6\u5c3d\u6d4b\u8bd5\u5957\u4ef6\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u5bf9\u4ee3\u7801\u8fdb\u884c\u4efb\u4f55\u4fee\u6539\u6216\u5e72\u6270\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6267\u884c\u73af\u5883\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8eViewstamped Replication\u590d\u5236\u7b97\u6cd5\u7684\u771f\u5b9e\u4e16\u754c\u7cfb\u7edf\u5b9e\u73b0\u4f5c\u4e3a\u4f8b\u5b50\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u5e94\u7528\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u7f29\u5c0f\u5206\u5e03\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u4e0e\u5176\u5f62\u5f0f\u5316\u89c4\u8303\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u800c\u65e0\u9700\u5bf9\u73b0\u6709\u7cfb\u7edf\u8fdb\u884c\u6539\u52a8\u3002"}}
{"id": "2512.08266", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08266", "abs": "https://arxiv.org/abs/2512.08266", "authors": ["Zhensu Sun", "Chengran Yang", "Xiaoning Du", "Zhou Yang", "Li Li", "David Lo"], "title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand", "comment": "Accepted by ASE'25", "summary": "Large language models (LLMs) have shown exceptional performance in code generation and understanding tasks, yet their high computational costs hinder broader adoption. One important factor is the inherent verbosity of programming languages, such as unnecessary formatting elements and lengthy boilerplate code. This leads to inflated token counts in both input and generated outputs, which increases inference costs and slows down the generation process. Prior work improves this through simplifying programming language grammar, reducing token usage across both code understanding and generation tasks. However, it is confined to syntactic transformations, leaving significant opportunities for token reduction unrealized at the semantic level.\n  In this work, we propose Token Sugar, a concept that replaces frequent and verbose code patterns with reversible, token-efficient shorthand in the source code. To realize this concept in practice, we designed a systematic solution that mines high-frequency, token-heavy patterns from a code corpus, maps each to a unique shorthand, and integrates them into LLM pretraining via code transformation. With this solution, we obtain 799 (code pattern, shorthand) pairs, which can reduce up to 15.1% token count in the source code and is complementary to existing syntax-focused methods. We further trained three widely used LLMs on Token Sugar-augmented data. Experimental results show that these models not only achieve significant token savings (up to 11.2% reduction) during generation but also maintain near-identical Pass@1 scores compared to baselines trained on unprocessed code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aToken Sugar\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u7528\u53ef\u9006\u7684\u7b80\u5199\u66ff\u6362\u9891\u7e41\u4e14\u5197\u957f\u7684\u4ee3\u7801\u6a21\u5f0f\u6765\u51cf\u5c11\u6e90\u4ee3\u7801\u4e2d\u7684token\u6570\u91cf\u3002\u8be5\u65b9\u6cd5\u4ece\u4ee3\u7801\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u9ad8\u9891\u3001token\u5bc6\u96c6\u7684\u6a21\u5f0f\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u6a21\u5f0f\u5206\u914d\u4e00\u4e2a\u72ec\u7279\u7684\u7b80\u5199\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7b80\u5199\u6574\u5408\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\uff08\u6700\u591a\u53ef\u8fbe11.2%\uff09\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u8fd1\u7684Pass@1\u5f97\u5206\u3002", "motivation": "\u7531\u4e8e\u7f16\u7a0b\u8bed\u8a00\u56fa\u6709\u7684\u5197\u4f59\u6027\uff08\u5982\u4e0d\u5fc5\u8981\u7684\u683c\u5f0f\u5143\u7d20\u548c\u5197\u957f\u7684\u6837\u677f\u4ee3\u7801\uff09\uff0c\u5bfc\u81f4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4ee3\u7801\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u65f6\u9762\u4e34\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u6709\u5de5\u4f5c\u5c1d\u8bd5\u901a\u8fc7\u7b80\u5316\u7f16\u7a0b\u8bed\u8a00\u8bed\u6cd5\u6765\u51cf\u5c11token\u4f7f\u7528\uff0c\u4f46\u5b83\u4eec\u4e3b\u8981\u96c6\u4e2d\u5728\u8bed\u6cd5\u5c42\u9762\u7684\u8f6c\u6362\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u8bed\u4e49\u5c42\u9762\u7684\u673a\u4f1a\u8fdb\u4e00\u6b65\u51cf\u5c11token\u3002", "method": "\u63d0\u51fa\u4e86Token Sugar\u6982\u5ff5\uff0c\u65e8\u5728\u901a\u8fc7\u53ef\u9006\u7684\u7b80\u5199\u5f62\u5f0f\u66ff\u4ee3\u5e38\u89c1\u4e14\u5197\u957f\u7684\u4ee3\u7801\u6a21\u5f0f\uff0c\u4ece\u800c\u964d\u4f4e\u6e90\u4ee3\u7801\u4e2d\u7684token\u6570\u91cf\u3002\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u4ece\u4ee3\u7801\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u9ad8\u9891\u6b21\u3001token\u5bc6\u96c6\u578b\u6a21\u5f0f\uff0c\u7ed9\u6bcf\u4e2a\u6a21\u5f0f\u5206\u914d\u552f\u4e00\u7684\u7b80\u5199\uff0c\u5e76\u901a\u8fc7\u4ee3\u7801\u8f6c\u6362\u5c06\u5176\u878d\u5165\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u4e2d\u3002", "result": "\u901a\u8fc7\u5e94\u7528Token Sugar\uff0c\u7814\u7a76\u4eba\u5458\u83b7\u5f97\u4e86799\u5bf9\uff08\u4ee3\u7801\u6a21\u5f0f\uff0c\u7b80\u5199\uff09\uff0c\u80fd\u591f\u51cf\u5c11\u9ad8\u8fbe15.1%\u7684\u6e90\u4ee3\u7801token\u6570\u91cf\uff0c\u5e76\u4e14\u4e0e\u73b0\u6709\u7684\u4fa7\u91cd\u4e8e\u8bed\u6cd5\u7684\u65b9\u6cd5\u4e92\u8865\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ecf\u8fc7Token Sugar\u589e\u5f3a\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684token\u8282\u7701\uff08\u6700\u9ad8\u8fbe\u523011.2%\u7684\u51cf\u5c11\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u672a\u7ecf\u5904\u7406\u4ee3\u7801\u8bad\u7ec3\u7684\u57fa\u7ebf\u6a21\u578b\u51e0\u4e4e\u76f8\u540c\u7684Pass@1\u5f97\u5206\u3002", "conclusion": "Token Sugar\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u9014\u5f84\u4ee5\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u65f6\u6240\u9700\u7684token\u6570\u91cf\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5c55\u793a\u4e86\u4e0e\u73b0\u6709\u4e13\u6ce8\u4e8e\u8bed\u6cd5\u4f18\u5316\u7684\u65b9\u6cd5\u76f8\u7ed3\u5408\u7684\u826f\u597d\u6f5c\u529b\u3002"}}
{"id": "2512.07855", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07855", "abs": "https://arxiv.org/abs/2512.07855", "authors": ["Huizheng Wang", "Hongbin Wang", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "LAPA: Log-Domain Prediction-Driven Dynamic Sparsity Accelerator for Transformer Model", "comment": null, "summary": "Attention-based Transformers have revolutionized natural language processing (NLP) and shown strong performance in computer vision (CV) tasks. However, as the input sequence varies, the computational bottlenecks in Transformer models exhibit dynamic behavior across stages, which calls for a cross-stage sparse acceleration strategy. Unfortunately, most existing sparse Transformer approaches are single-stage based, and their sparsity prediction mechanisms lead to significant power overhead when applied across multiple stages. To this end, this paper proposes a log-domain attention prediction algorithm-architecture co-design, named LAPA. First, an asymmetric leading one computing (ALOC) scheme is designed to eliminate expensive multiplications. Next, a mixed-precision multi-round shifting accumulation (MRSA) mechanism is further proposed to mitigate the accumulation overhead. A data-feature dependent filter (DDF) strategy is designed to work in concert with the MRSA process. Finally, an elaborate accelerator is designed to translate the theoretical enhancement into practical hardware improvement. Experimental results show that LAPA achieves 3.52x, 3.24x and 2.79x higher energy efficiency than the state-of-the-art (SOTA) works Spatten, Sanger and FACT, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u57df\u6ce8\u610f\u529b\u9884\u6d4b\u7684\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\uff08LAPA\uff09\uff0c\u901a\u8fc7\u521b\u65b0\u6027\u8ba1\u7b97\u65b9\u6848\u548c\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86Transformer\u6a21\u578b\u5728\u4e0d\u540c\u9636\u6bb5\u7684\u7a00\u758f\u52a0\u901f\u6548\u7387\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u9ad8\u7684\u80fd\u6548\u3002", "motivation": "\u73b0\u6709\u7684\u7a00\u758fTransformer\u65b9\u6cd5\u5927\u591a\u57fa\u4e8e\u5355\u9636\u6bb5\u8bbe\u8ba1\uff0c\u5f53\u5e94\u7528\u4e8e\u591a\u4e2a\u9636\u6bb5\u65f6\uff0c\u5176\u7a00\u758f\u6027\u9884\u6d4b\u673a\u5236\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u529f\u8017\u5f00\u9500\u3002\u968f\u7740\u8f93\u5165\u5e8f\u5217\u7684\u53d8\u5316\uff0cTransformer\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u8868\u73b0\u51fa\u8de8\u9636\u6bb5\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u8fd9\u8981\u6c42\u6709\u4e00\u79cd\u8de8\u9636\u6bb5\u7684\u7a00\u758f\u52a0\u901f\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLAPA\uff08Log-domain Attention Prediction Algorithm-architecture co-design\uff09\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1. \u4e0d\u5bf9\u79f0\u9886\u5148\u4e00\u8ba1\u7b97\uff08ALOC\uff09\u65b9\u6848\u6765\u6d88\u9664\u6602\u8d35\u7684\u4e58\u6cd5\u64cd\u4f5c\uff1b2. \u6df7\u5408\u7cbe\u5ea6\u591a\u8f6e\u79fb\u4f4d\u7d2f\u52a0\uff08MRSA\uff09\u673a\u5236\u51cf\u5c11\u7d2f\u79ef\u5f00\u9500\uff1b3. \u6570\u636e\u7279\u5f81\u4f9d\u8d56\u8fc7\u6ee4\uff08DDF\uff09\u7b56\u7565\u4e0eMRSA\u8fc7\u7a0b\u534f\u540c\u5de5\u4f5c\uff1b4. \u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u52a0\u901f\u5668\u5c06\u7406\u8bba\u589e\u5f3a\u8f6c\u5316\u4e3a\u5b9e\u9645\u786c\u4ef6\u6539\u8fdb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLAPA\u76f8\u6bd4\u6700\u5148\u8fdb\u4f5c\u54c1Spatten\u3001Sanger\u548cFACT\u5206\u522b\u5b9e\u73b0\u4e863.52\u500d\u30013.24\u500d\u53ca2.79\u500d\u7684\u80fd\u91cf\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165LAPA\u8fd9\u4e00\u521b\u65b0\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u9488\u5bf9Transformer\u6a21\u578b\u5b58\u5728\u7684\u8de8\u9636\u6bb5\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u6548\u8def\u5f84\uff0c\u6781\u5927\u5730\u63d0\u5347\u4e86\u5904\u7406\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u65f6\u7684\u80fd\u6548\u8868\u73b0\u3002"}}
{"id": "2512.08725", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08725", "abs": "https://arxiv.org/abs/2512.08725", "authors": ["Giulio Attenni", "Youssef Moawad", "Novella Bartolini", "Lauritz Thamsen"], "title": "Spatio-Temporal Shifting to Reduce Carbon, Water, and Land-Use Footprints of Cloud Workloads", "comment": "This is a pre-print of our paper currently under review", "summary": "In this paper, we investigate the potential of spatial and temporal cloud workload shifting to reduce carbon, water, and land-use footprints. Specifically, we perform a simulation study using real-world data from multiple cloud providers (AWS and Azure) and workload traces for different applications (big data analytics and FaaS). Our simulation results indicate that spatial shifting can substantially lower carbon, water, and land use footprints, with observed reductions ranging from 20% to 85%, depending on the scenario and optimization criteria. Temporal shifting also decreases the footprint, though to a lesser extent. When applied together, the two strategies yield the greatest overall reduction, driven mainly by spatial shifting with temporal adjustments providing an additional, incremental benefit. Sensitivity analysis demonstrates that such shifting is robust to prediction errors in grid mix data and to variations across different seasons.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6a21\u62df\u5206\u6790\u4e86\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u7684\u8f6c\u79fb\u5bf9\u51cf\u5c11\u78b3\u3001\u6c34\u548c\u571f\u5730\u4f7f\u7528\u8db3\u8ff9\u7684\u6f5c\u529b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u7a7a\u95f4\u8f6c\u79fb\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8fd9\u4e9b\u8db3\u8ff9\uff0c\u800c\u65f6\u95f4\u8f6c\u79fb\u4e5f\u6709\u52a9\u4e8e\u51cf\u5c11\u4f46\u6548\u679c\u8f83\u5c0f\u3002\u7ed3\u5408\u4e24\u79cd\u7b56\u7565\u80fd\u5b9e\u73b0\u6700\u5927\u7684\u603b\u4f53\u51cf\u6392\u6548\u679c\uff0c\u5e76\u4e14\u8fd9\u79cd\u8f6c\u79fb\u5bf9\u4e8e\u9884\u6d4b\u8bef\u5dee\u548c\u5b63\u8282\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u8ba8\u901a\u8fc7\u8c03\u6574\u4e91\u670d\u52a1\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5206\u5e03\uff08\u5305\u62ec\u5730\u7406\u4f4d\u7f6e\u548c\u65f6\u95f4\u5b89\u6392\uff09\u6765\u964d\u4f4e\u5176\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u51cf\u5c11\u78b3\u6392\u653e\u3001\u6c34\u8d44\u6e90\u6d88\u8017\u4ee5\u53ca\u571f\u5730\u5229\u7528\u3002", "method": "\u91c7\u7528\u6765\u81ea\u591a\u4e2a\u4e91\u670d\u52a1\u5546\u7684\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u4eff\u771f\u7814\u7a76\uff0c\u6db5\u76d6\u4e86\u4e0d\u540c\u5e94\u7528\u573a\u666f\u5982\u5927\u6570\u636e\u5206\u6790\u4e0e\u51fd\u6570\u5373\u670d\u52a1(FaaS)\u7b49\u3002", "result": "\u7a7a\u95f4\u8f6c\u79fb\u663e\u793a\u51fa\u6781\u5927\u7684\u6f5c\u529b\uff0c\u53ef\u4f7f\u78b3\u3001\u6c34\u53ca\u571f\u5730\u4f7f\u7528\u7684\u8db3\u8ff9\u51cf\u5c1120%\u81f385%\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u573a\u666f\u8bbe\u7f6e\u548c\u4f18\u5316\u76ee\u6807\uff1b\u65f6\u95f4\u8f6c\u79fb\u540c\u6837\u6709\u52a9\u4e8e\u51cf\u5c11\u8db3\u8ff9\uff0c\u4f46\u7a0b\u5ea6\u8f83\u4f4e\uff1b\u5f53\u540c\u65f6\u5e94\u7528\u8fd9\u4e24\u79cd\u7b56\u7565\u65f6\uff0c\u53ef\u4ee5\u83b7\u5f97\u6700\u4f73\u7684\u6574\u4f53\u51cf\u6392\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u5408\u7406\u89c4\u5212\u4e91\u8ba1\u7b97\u8d44\u6e90\u7684\u7a7a\u95f4\u5e03\u5c40\u548c\u4f7f\u7528\u65f6\u673a\uff0c\u80fd\u591f\u6709\u6548\u51cf\u8f7b\u5176\u5bf9\u81ea\u7136\u73af\u5883\u9020\u6210\u7684\u8d1f\u62c5\uff0c\u4e3a\u6784\u5efa\u66f4\u52a0\u7eff\u8272\u53ef\u6301\u7eed\u7684\u4fe1\u606f\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.08277", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08277", "abs": "https://arxiv.org/abs/2512.08277", "authors": ["Yihan Liao", "Jacky Keung", "Zhenyu Mao", "Jingyu Zhang", "Jialong Li"], "title": "FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection", "comment": "Accepted Artifact at ACSOS 2025", "summary": "Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.", "AI": {"tldr": "FedLAD\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u65e8\u5728\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7ea6\u675f\u4e0b\u8bad\u7ec3\u548c\u8bc4\u4f30\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\uff08LAD\uff09\u6a21\u578b\u3002\u5b83\u652f\u6301\u591a\u79cdLAD\u6a21\u578b\u3001\u57fa\u51c6\u6570\u636e\u96c6\u548c\u805a\u5408\u7b56\u7565\u7684\u5373\u63d2\u5373\u7528\u96c6\u6210\uff0c\u5e76\u63d0\u4f9b\u8fd0\u884c\u65f6\u652f\u6301\u4ee5\u5b9e\u73b0\u9a8c\u8bc1\u65e5\u5fd7\u8bb0\u5f55\u3001\u53c2\u6570\u8c03\u4f18\u548c\u81ea\u9002\u5e94\u7b56\u7565\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u96c6\u4e2d\u5f0f\u8bad\u7ec3\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7531\u4e8e\u9690\u79c1\u9650\u5236\u548c\u7cfb\u7edf\u65e5\u5fd7\u7684\u5206\u6563\u7279\u6027\u800c\u96be\u4ee5\u5b9e\u73b0\u3002\u867d\u7136\u8054\u90a6\u5b66\u4e60\u4e3a\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u8054\u90a6\u8bbe\u7f6e\u4e0b\u7684LAD\u9700\u6c42\u8bbe\u8ba1\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u63d0\u51fa\u4e86FedLAD\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u80fd\u591f\u652f\u6301\u4e0d\u540cLAD\u6a21\u578b\u3001\u57fa\u51c6\u6570\u636e\u96c6\u4ee5\u53ca\u805a\u5408\u7b56\u7565\u4e4b\u95f4\u7684\u7075\u6d3b\u96c6\u6210\uff0c\u5e76\u4e14\u5177\u5907\u81ea\u6211\u76d1\u63a7\u3001\u81ea\u6211\u914d\u7f6e\u4e0e\u81ea\u6211\u9002\u5e94\u529f\u80fd\uff0c\u4ee5\u4fbf\u4e8e\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u5b9e\u9a8c\u7814\u7a76\u3002", "result": "FedLAD\u6210\u529f\u5730\u586b\u8865\u4e86\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e0eLAD\u9700\u6c42\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u4e13\u4e3a\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u5b9a\u5236\u7684\u8054\u90a6\u5b66\u4e60\u6d4b\u8bd5\u5e73\u53f0\uff0cFedLAD\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u5185\u66f4\u52a0\u9ad8\u6548\u548c\u9690\u79c1\u53cb\u597d\u7684\u7814\u7a76\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2512.07856", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07856", "abs": "https://arxiv.org/abs/2512.07856", "authors": ["Haokun Zhao", "Yingzhe Bai", "Qingyang Xu", "Lixin Zhou", "Jianxin Chen", "Jicong Fan"], "title": "Medical Test-free Disease Detection Based on Big Data", "comment": null, "summary": "Accurate disease detection is of paramount importance for effective medical treatment and patient care. However, the process of disease detection is often associated with extensive medical testing and considerable costs, making it impractical to perform all possible medical tests on a patient to diagnose or predict hundreds or thousands of diseases. In this work, we propose Collaborative Learning for Disease Detection (CLDD), a novel graph-based deep learning model that formulates disease detection as a collaborative learning task by exploiting associations among diseases and similarities among patients adaptively. CLDD integrates patient-disease interactions and demographic features from electronic health records to detect hundreds or thousands of diseases for every patient, with little to no reliance on the corresponding medical tests. Extensive experiments on a processed version of the MIMIC-IV dataset comprising 61,191 patients and 2,000 diseases demonstrate that CLDD consistently outperforms representative baselines across multiple metrics, achieving a 6.33\\% improvement in recall and 7.63\\% improvement in precision. Furthermore, case studies on individual patients illustrate that CLDD can successfully recover masked diseases within its top-ranked predictions, demonstrating both interpretability and reliability in disease prediction. By reducing diagnostic costs and improving accessibility, CLDD holds promise for large-scale disease screening and social health security.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bCLDD\uff0c\u7528\u4e8e\u75be\u75c5\u68c0\u6d4b\u3002\u901a\u8fc7\u5229\u7528\u75be\u75c5\u95f4\u7684\u5173\u8054\u548c\u60a3\u8005\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u51cf\u5c11\u5bf9\u5177\u4f53\u533b\u7597\u6d4b\u8bd5\u7684\u4f9d\u8d56\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u75be\u75c5\u7b5b\u67e5\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCLDD\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u5728\u53ec\u56de\u7387\u548c\u7cbe\u786e\u5ea6\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u51c6\u786e\u7684\u75be\u75c5\u68c0\u6d4b\u5bf9\u4e8e\u6709\u6548\u7684\u533b\u7597\u6cbb\u7597\u548c\u60a3\u8005\u62a4\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u901a\u5e38\u4f34\u968f\u7740\u5927\u91cf\u7684\u533b\u5b66\u68c0\u67e5\u548c\u9ad8\u6602\u7684\u6210\u672c\u3002\u8fd9\u4f7f\u5f97\u4e3a\u6bcf\u4f4d\u60a3\u8005\u8fdb\u884c\u5168\u9762\u7684\u533b\u5b66\u6d4b\u8bd5\u4ee5\u8bca\u65ad\u6216\u9884\u6d4b\u6570\u767e\u4e43\u81f3\u6570\u5343\u79cd\u75be\u75c5\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u75be\u75c5\u68c0\u6d4b\u6548\u7387\u540c\u65f6\u964d\u4f4e\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u534f\u4f5c\u5b66\u4e60\u75be\u75c5\u68c0\u6d4b\uff08Collaborative Learning for Disease Detection, CLDD\uff09\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u56fe\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u5c06\u75be\u75c5\u68c0\u6d4b\u89c6\u4e3a\u4e00\u4e2a\u534f\u4f5c\u5b66\u4e60\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5229\u7528\u75be\u75c5\u4e4b\u95f4\u7684\u8054\u7cfb\u4ee5\u53ca\u60a3\u8005\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u6765\u8fdb\u884c\u3002CLDD\u6574\u5408\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u60a3\u8005-\u75be\u75c5\u4ea4\u4e92\u4f5c\u7528\u548c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\uff0c\u80fd\u591f\u5728\u51e0\u4e4e\u4e0d\u4f9d\u8d56\u76f8\u5e94\u7684\u533b\u5b66\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\u4e3a\u6bcf\u4f4d\u60a3\u8005\u68c0\u6d4b\u51fa\u6570\u767e\u751a\u81f3\u6570\u5343\u79cd\u75be\u75c5\u3002", "result": "\u5728\u5904\u7406\u8fc7\u7684MIMIC-IV\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cCLDD\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u4ee3\u8868\u6027\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e866.33%\u7684\u53ec\u56de\u7387\u6539\u5584\u548c7.63%\u7684\u7cbe\u786e\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0c\u9488\u5bf9\u4e2a\u522b\u60a3\u8005\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cCLDD\u80fd\u591f\u5728\u9876\u7ea7\u9884\u6d4b\u4e2d\u6210\u529f\u6062\u590d\u88ab\u63a9\u76d6\u7684\u75be\u75c5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u75be\u75c5\u9884\u6d4b\u65b9\u9762\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "CLDD\u901a\u8fc7\u51cf\u5c11\u8bca\u65ad\u6210\u672c\u5e76\u63d0\u9ad8\u533b\u7597\u670d\u52a1\u7684\u53ef\u53ca\u6027\uff0c\u5728\u5927\u89c4\u6a21\u75be\u75c5\u7b5b\u67e5\u548c\u793e\u4f1a\u5065\u5eb7\u5b89\u5168\u4fdd\u969c\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.07857", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07857", "abs": "https://arxiv.org/abs/2512.07857", "authors": ["Junhua Shi", "Qingyun Sun", "Haonan Yuan", "Xingcheng Fu"], "title": "SA^2GFM: Enhancing Robust Graph Foundation Models with Structure-Aware Semantic Augmentation", "comment": null, "summary": "We present Graph Foundation Models (GFMs) which have made significant progress in various tasks, but their robustness against domain noise, structural perturbations, and adversarial attacks remains underexplored. A key limitation is the insufficient modeling of hierarchical structural semantics, which are crucial for generalization. In this paper, we propose SA^2GFM, a robust GFM framework that improves domain-adaptive representations through Structure-Aware Semantic Augmentation. First, we encode hierarchical structural priors by transforming entropy-based encoding trees into structure-aware textual prompts for feature augmentation. The enhanced inputs are processed by a self-supervised Information Bottleneck mechanism that distills robust, transferable representations via structure-guided compression. To address negative transfer in cross-domain adaptation, we introduce an expert adaptive routing mechanism, combining a mixture-of-experts architecture with a null expert design. For efficient downstream adaptation, we propose a fine-tuning module that optimizes hierarchical structures through joint intra- and inter-community structure learning. Extensive experiments demonstrate that SA^2GFM outperforms 9 state-of-the-art baselines in terms of effectiveness and robustness against random noise and adversarial perturbations for node and graph classification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SA^2GFM\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u8bed\u4e49\u589e\u5f3a\u63d0\u9ad8\u56fe\u57fa\u7840\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u9886\u57df\u9002\u5e94\u6027\u3002\u8be5\u6846\u67b6\u5229\u7528\u57fa\u4e8e\u71b5\u7684\u7f16\u7801\u6811\u8f6c\u5316\u4e3a\u7ed3\u6784\u611f\u77e5\u6587\u672c\u63d0\u793a\u4ee5\u589e\u5f3a\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u673a\u5236\u63d0\u70bc\u51fa\u9c81\u68d2\u53ef\u8fc1\u79fb\u8868\u793a\u3002\u4e3a\u89e3\u51b3\u8de8\u57df\u9002\u5e94\u4e2d\u7684\u8d1f\u9762\u8fc1\u79fb\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e13\u5bb6\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSA^2GFM\u5728\u8282\u70b9\u548c\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e9\u79cd\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u62b5\u6297\u968f\u673a\u566a\u58f0\u548c\u5bf9\u6297\u6270\u52a8\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7684\u56fe\u57fa\u7840\u6a21\u578b\uff08GFMs\uff09\u867d\u7136\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5e94\u5bf9\u9886\u57df\u566a\u58f0\u3001\u7ed3\u6784\u6270\u52a8\u4ee5\u53ca\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u7684\u9c81\u68d2\u6027\u4ecd\u5f85\u63a2\u7d22\u3002\u6b64\u5916\uff0c\u5bf9\u5c42\u6b21\u7ed3\u6784\u8bed\u4e49\u5efa\u6a21\u4e0d\u8db3\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faSA^2GFM\u6846\u67b6\uff0c\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u51e0\u70b9\uff1a1. \u901a\u8fc7\u5c06\u57fa\u4e8e\u71b5\u7684\u7f16\u7801\u6811\u8f6c\u6362\u6210\u7ed3\u6784\u611f\u77e5\u6587\u672c\u63d0\u793a\u6765\u589e\u5f3a\u8f93\u5165\u7279\u5f81\uff1b2. \u5229\u7528\u81ea\u6211\u76d1\u7763\u7684\u4fe1\u606f\u74f6\u9888\u673a\u5236\u5904\u7406\u589e\u5f3a\u540e\u7684\u8f93\u5165\uff0c\u901a\u8fc7\u7ed3\u6784\u5f15\u5bfc\u538b\u7f29\u63d0\u53d6\u9c81\u68d2\u4e14\u53ef\u8f6c\u79fb\u7684\u8868\u793a\uff1b3. \u91c7\u7528\u4e13\u5bb6\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u5904\u7406\u8de8\u57df\u9002\u5e94\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u8d1f\u8fc1\u79fb\u73b0\u8c61\uff1b4. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5fae\u8c03\u6a21\u5757\uff0c\u901a\u8fc7\u8054\u5408\u5185\u90e8\u548c\u793e\u533a\u95f4\u7ed3\u6784\u5b66\u4e60\u4f18\u5316\u5c42\u6b21\u7ed3\u6784\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5bf9\u4e8e\u8282\u70b9\u548c\u56fe\u5206\u7c7b\u4efb\u52a1\uff0cSA^2GFM\u4e0d\u4ec5\u5728\u6548\u679c\u4e0a\u8d85\u8d8a\u4e869\u4e2a\u6700\u65b0\u7684\u57fa\u51c6\u65b9\u6cd5\uff0c\u800c\u4e14\u5728\u9762\u5bf9\u968f\u673a\u566a\u97f3\u53ca\u5bf9\u6297\u6027\u5e72\u6270\u65f6\u4e5f\u5c55\u73b0\u51fa\u4e86\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u56fe\u57fa\u7840\u6a21\u578b\u6846\u67b6\u2014\u2014SA^2GFM\uff0c\u5b83\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u8bed\u4e49\u589e\u5f3a\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.08461", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08461", "abs": "https://arxiv.org/abs/2512.08461", "authors": ["Nicolas Matton", "Anthony Simonofski", "Marie-Ange Remiche", "Beno\u00eet Vanderose"], "title": "Measuring Agile Agreement: Development and Validation of the Manifesto and Principle Scales", "comment": "12 pages, 1 figure, 2 appendix, preprint", "summary": "While the importance of human factors in agile software development is widely acknowledged, the measurement of an individual's \"agile agreement\" remains an ill-defined and challenging area. A key limitation in existing research is the failure to distinguish between agreement with the abstract, high-level values of the Agile Manifesto and agreement with the concrete, day-to-day practices derived from the 12 Principles. This paper addresses this methodological gap by presenting the design and validation of two distinct instruments: the novel Manifesto Agreement Scale (MAS), and the Principle Agreement Scale (PAS), which is a systematic adaptation and refinement of a prior instrument.\n  We detail the systematic process of item creation and selection, survey design, and validation. The results demonstrate that both scales possess important internal consistency and construct validity. A convergence and divergence analysis, including Proportional Odds Logistic Regression, a Bland-Altman plot, and an Intraclass Correlation Coefficient (ICC), reveals that while the two scales are moderately correlated, they are not interchangeable and capture distinct dimensions of agile agreement. The primary contribution of this work is a pair of publicly available instruments, validated within a specific demographic of Belgian IT professionals. These scales represent a critical initial step toward facilitating a more nuanced measurement of agile agreement, distinguishing agile agreement across various levels of perception and aiding in a more refined interpretation of person-agile fit.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u4e24\u79cd\u65b0\u7684\u91cf\u8868\u2014\u2014\u654f\u6377\u5ba3\u8a00\u540c\u610f\u5ea6\u91cf\u8868\uff08MAS\uff09\u548c\u539f\u5219\u540c\u610f\u5ea6\u91cf\u8868\uff08PAS\uff09\uff0c\u4ee5\u533a\u5206\u4e2a\u4eba\u5bf9\u654f\u6377\u5ba3\u8a00\u7684\u4ef7\u503c\u89c2\u548c\u5177\u4f53\u5b9e\u8df5\u7684\u8ba4\u540c\u7a0b\u5ea6\u3002\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u9879\u76ee\u521b\u5efa\u3001\u9009\u62e9\u3001\u8c03\u67e5\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u7814\u7a76\u8bc1\u660e\u4e86\u4e24\u4e2a\u91cf\u8868\u90fd\u5177\u6709\u826f\u597d\u7684\u5185\u90e8\u4e00\u81f4\u6027\u548c\u7ed3\u6784\u6548\u5ea6\uff0c\u5e76\u4e14\u867d\u7136\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u4e2d\u7b49\u76f8\u5173\u6027\uff0c\u4f46\u5b83\u4eec\u6355\u6349\u7684\u662f\u654f\u6377\u8ba4\u540c\u7684\u4e0d\u540c\u7ef4\u5ea6\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u80fd\u6709\u6548\u5730\u533a\u5206\u4e2a\u4f53\u5bf9\u4e8e\u654f\u6377\u5ba3\u8a00\u4e2d\u7684\u62bd\u8c61\u4ef7\u503c\u89c2\u4e0e\u6e90\u81ea12\u539f\u5219\u7684\u5177\u4f53\u65e5\u5e38\u5b9e\u8df5\u4e4b\u95f4\u7684\u8ba4\u540c\u5dee\u5f02\uff0c\u5bfc\u81f4'\u654f\u6377\u8ba4\u540c'\u6d4b\u91cf\u9886\u57df\u5b9a\u4e49\u6a21\u7cca\u4e14\u5145\u6ee1\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e24\u79cd\u4e0d\u540c\u7684\u5de5\u5177\uff1a\u5168\u65b0\u7684\u654f\u6377\u5ba3\u8a00\u540c\u610f\u5ea6\u91cf\u8868\uff08MAS\uff09\u4ee5\u53ca\u7ecf\u8fc7\u7cfb\u7edf\u8c03\u6574\u548c\u6539\u8fdb\u7684\u539f\u5219\u540c\u610f\u5ea6\u91cf\u8868\uff08PAS\uff09\uff0c\u6765\u586b\u8865\u8fd9\u4e00\u65b9\u6cd5\u8bba\u7a7a\u767d\u3002\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u9879\u76ee\u7684\u521b\u5efa\u4e0e\u9009\u62e9\u3001\u95ee\u5377\u8bbe\u8ba1\u53ca\u9a8c\u8bc1\u8fc7\u7a0b\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4e24\u4e2a\u91cf\u8868\u5747\u663e\u793a\u51fa\u91cd\u8981\u7684\u5185\u90e8\u4e00\u81f4\u6027\u548c\u6784\u5efa\u6709\u6548\u6027\u3002\u901a\u8fc7\u6bd4\u4f8b\u51e0\u7387\u903b\u8f91\u56de\u5f52\u3001Bland-Altman\u56fe\u548c\u7ec4\u5185\u76f8\u5173\u7cfb\u6570(ICC)\u8fdb\u884c\u7684\u6536\u655b\u6027\u548c\u53d1\u6563\u6027\u5206\u6790\u8868\u660e\uff0c\u5c3d\u7ba1\u4e24\u4e2a\u91cf\u8868\u4e4b\u95f4\u6709\u4e2d\u7b49\u7a0b\u5ea6\u7684\u76f8\u5173\u6027\uff0c\u4f46\u5b83\u4eec\u5e76\u975e\u53ef\u4e92\u6362\u7684\uff0c\u800c\u662f\u6355\u6349\u5230\u4e86\u654f\u6377\u8ba4\u540c\u7684\u4e0d\u540c\u65b9\u9762\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7684\u4e3b\u8981\u8d21\u732e\u5728\u4e8e\u63d0\u4f9b\u4e86\u4e00\u5bf9\u516c\u5f00\u53ef\u7528\u7684\u5de5\u5177\uff0c\u8fd9\u4e9b\u5de5\u5177\u5728\u6bd4\u5229\u65f6IT\u4e13\u4e1a\u4eba\u58eb\u8fd9\u4e00\u7279\u5b9a\u7fa4\u4f53\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u8fd9\u4e9b\u91cf\u8868\u4ee3\u8868\u4e86\u4fc3\u8fdb\u66f4\u7ec6\u81f4\u5730\u8861\u91cf\u654f\u6377\u8ba4\u540c\u7684\u91cd\u8981\u7b2c\u4e00\u6b65\uff0c\u6709\u52a9\u4e8e\u533a\u5206\u4e0d\u540c\u5c42\u6b21\u7684\u8ba4\u77e5\u4e0b\u7684\u654f\u6377\u8ba4\u540c\uff0c\u5e76\u652f\u6301\u66f4\u52a0\u7cbe\u7ec6\u7684\u4eba-\u654f\u6377\u5339\u914d\u89e3\u91ca\u3002"}}
{"id": "2512.07858", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07858", "abs": "https://arxiv.org/abs/2512.07858", "authors": ["Da Zhang", "Bingyu Li", "Zhiyuan Zhao", "Yanhan Zhang", "Junyu Gao", "Feiping Nie", "Xuelong Li"], "title": "FAIM: Frequency-Aware Interactive Mamba for Time Series Classification", "comment": null, "summary": "Time series classification (TSC) is crucial in numerous real-world applications, such as environmental monitoring, medical diagnosis, and posture recognition. TSC tasks require models to effectively capture discriminative information for accurate class identification. Although deep learning architectures excel at capturing temporal dependencies, they often suffer from high computational cost, sensitivity to noise perturbations, and susceptibility to overfitting on small-scale datasets. To address these challenges, we propose FAIM, a lightweight Frequency-Aware Interactive Mamba model. Specifically, we introduce an Adaptive Filtering Block (AFB) that leverages Fourier Transform to extract frequency-domain features from time series data. The AFB incorporates learnable adaptive thresholds to dynamically suppress noise and employs element-wise coupling of global and local semantic adaptive filtering, enabling in-depth modeling of the synergy among different frequency components. Furthermore, we design an Interactive Mamba Block (IMB) to facilitate efficient multi-granularity information interaction, balancing the extraction of fine-grained discriminative features and comprehensive global contextual information, thereby endowing FAIM with powerful and expressive representations for TSC tasks. Additionally, we incorporate a self-supervised pre-training mechanism to enhance FAIM's understanding of complex temporal patterns and improve its robustness across various domains and high-noise scenarios. Extensive experiments on multiple benchmarks demonstrate that FAIM consistently outperforms existing state-of-the-art (SOTA) methods, achieving a superior trade-off between accuracy and efficiency and exhibits outstanding performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u9891\u7387\u611f\u77e5\u4ea4\u4e92\u578b\u66fc\u5df4\u6a21\u578b(FAIM)\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b(TSC)\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6ee4\u6ce2\u5757\u548c\u4ea4\u4e92\u578b\u66fc\u5df4\u5757\u89e3\u51b3\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728TSC\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5982\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u5bf9\u566a\u58f0\u654f\u611f\u53ca\u8fc7\u62df\u5408\u7b49\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660eFAIM\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u867d\u7136\u80fd\u591f\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e0a\u5b58\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u5bf9\u566a\u58f0\u6270\u52a8\u654f\u611f\u4ee5\u53ca\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5bb9\u6613\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u6a21\u578b\u5728\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u7406\u89e3\u548c\u9ad8\u566a\u58f0\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86FAIM\u6a21\u578b\u3002", "method": "FAIM\u7531\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\u6784\u6210\uff1a\u81ea\u9002\u5e94\u6ee4\u6ce2\u5757\uff08AFB\uff09\u4e0e\u4ea4\u4e92\u578b\u66fc\u5df4\u5757\uff08IMB\uff09\u3002AFB\u5229\u7528\u5085\u91cc\u53f6\u53d8\u6362\u4ece\u65f6\u5e8f\u6570\u636e\u4e2d\u63d0\u53d6\u9891\u57df\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u53ef\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u9608\u503c\u52a8\u6001\u6291\u5236\u566a\u58f0\uff1b\u540c\u65f6\uff0c\u901a\u8fc7\u5168\u5c40\u548c\u5c40\u90e8\u8bed\u4e49\u81ea\u9002\u5e94\u8fc7\u6ee4\u4e4b\u95f4\u7684\u5143\u7d20\u7ea7\u8026\u5408\uff0c\u6df1\u5165\u5efa\u6a21\u4e0d\u540c\u9891\u7387\u6210\u5206\u95f4\u7684\u534f\u540c\u4f5c\u7528\u3002IMB\u5219\u65e8\u5728\u4fc3\u8fdb\u591a\u7c92\u5ea6\u4fe1\u606f\u7684\u6709\u6548\u4e92\u52a8\uff0c\u5728\u63d0\u53d6\u7cbe\u7ec6\u5224\u522b\u7279\u5f81\u7684\u540c\u65f6\u4fdd\u6301\u5168\u9762\u7684\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\u83b7\u53d6\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u81ea\u6211\u76d1\u7763\u9884\u8bad\u7ec3\u673a\u5236\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u7684\u7406\u89e3\u80fd\u529b\u53ca\u5176\u8de8\u9886\u57df\u7684\u9c81\u62e8\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0cFAIM\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u6548\u7387\u3002\u5b83\u5728\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u65f6\u5747\u80fd\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u8868\u73b0\u529b\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "FAIM\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u514b\u670d\u4e86\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u9ad8\u8fd0\u7b97\u8d1f\u62c5\u3001\u6613\u53d7\u566a\u97f3\u5f71\u54cd\u53ca\u8fc7\u62df\u5408\u98ce\u9669\u7b49\u3002\u901a\u8fc7\u5f15\u5165\u72ec\u7279\u7684\u81ea\u9002\u5e94\u6ee4\u6ce2\u6280\u672f\u548c\u4ea4\u4e92\u5f0f\u4fe1\u606f\u5904\u7406\u673a\u5236\uff0cFAIM\u80fd\u591f\u5728\u4fdd\u8bc1\u9ad8\u6548\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u51c6\u786e\u53ef\u9760\u7684\u5206\u7c7b\u7ed3\u679c\u3002"}}
{"id": "2512.08472", "categories": ["cs.SE", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.08472", "abs": "https://arxiv.org/abs/2512.08472", "authors": ["Kai Marquardt", "Robert Hanak", "Anne Koziolek", "Lucia Happe"], "title": "Measuring Computer Science Enthusiasm: A Questionnaire-Based Analysis of Age and Gender Effects on Students' Interest", "comment": "20 pages, 10 figures, Springer Nature Scientific Reports in review", "summary": "This study offers new insights into students' interest in computer science (CS) education by disentangling the distinct effects of age and gender across a diverse adolescent sample. Grounded in the person-object theory of interest (POI), we conceptualize enthusiasm as a short-term, activating expression of interest that combines positive affect, perceived relevance, and intention to re-engage. Experiencing such enthusiasm can temporarily shift CS attitudes and strengthen future engagement intentions, making it a valuable lens for evaluating brief outreach activities. To capture these dynamics, we developed a theoretically grounded questionnaire for pre-post assessment of the enthusiasm potential of CS interventions. Using data from more than 400 students participating in online CS courses, we examined age- and gender-related patterns in enthusiasm. The findings challenge the prevailing belief that early exposure is the primary pathway to sustained interest in CS. Instead, we identify a marked decline in enthusiasm during early adolescence, particularly among girls, alongside substantial variability in interest trajectories across age groups. Crucially, our analyses reveal that age is a more decisive factor than gender in shaping interest development and uncover key developmental breakpoints. Despite starting with lower baseline attitudes, older students showed the largest positive changes following the intervention, suggesting that well-designed short activities can effectively re-activate interest even at later ages. Overall, the study highlights the need for a dynamic, age-sensitive framework for CS education in which instructional strategies are aligned with developmental trajectories.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u533a\u5206\u5e74\u9f84\u548c\u6027\u522b\u5bf9\u591a\u6837\u5316\u7684\u9752\u5c11\u5e74\u6837\u672c\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8e\u5b66\u751f\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u5174\u8da3\u7684\u65b0\u89c1\u89e3\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5e74\u9f84\u6bd4\u6027\u522b\u5728\u5851\u9020\u5174\u8da3\u53d1\u5c55\u65b9\u9762\u66f4\u4e3a\u5173\u952e\uff0c\u5e76\u63ed\u793a\u4e86\u91cd\u8981\u7684\u53d1\u5c55\u8f6c\u6298\u70b9\u3002\u5c3d\u7ba1\u8f83\u5e74\u957f\u7684\u5b66\u751f\u6700\u521d\u7684\u6001\u5ea6\u8f83\u4f4e\uff0c\u4f46\u4ed6\u4eec\u5728\u5e72\u9884\u540e\u8868\u73b0\u51fa\u6700\u5927\u7684\u79ef\u6781\u53d8\u5316\uff0c\u8868\u660e\u5373\u4f7f\u5728\u8f83\u5927\u5e74\u9f84\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u77ed\u671f\u6d3b\u52a8\u4e5f\u80fd\u6709\u6548\u91cd\u65b0\u6fc0\u6d3b\u5174\u8da3\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u89e3\u5f00\u5e74\u9f84\u548c\u6027\u522b\u5bf9\u5b66\u751f\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\uff08CS\uff09\u6559\u80b2\u4e2d\u7684\u5174\u8da3\u7684\u4e0d\u540c\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3\u8fd9\u79cd\u5174\u8da3\u63d0\u4f9b\u65b0\u7684\u89c6\u89d2\u3002\u57fa\u4e8e\u4eba-\u7269\u5174\u8da3\u7406\u8bba\uff08POI\uff09\uff0c\u7814\u7a76\u8005\u5c06\u70ed\u60c5\u89c6\u4e3a\u4e00\u79cd\u77ed\u671f\u3001\u6fc0\u6d3b\u7684\u5174\u8da3\u8868\u8fbe\u5f62\u5f0f\uff0c\u7ed3\u5408\u6b63\u9762\u60c5\u611f\u3001\u76f8\u5173\u6027\u611f\u77e5\u53ca\u518d\u53c2\u4e0e\u610f\u613f\u3002\u7ecf\u5386\u8fd9\u6837\u7684\u70ed\u60c5\u53ef\u4ee5\u6682\u65f6\u6539\u53d8\u5bf9CS\u7684\u6001\u5ea6\u5e76\u52a0\u5f3a\u672a\u6765\u53c2\u4e0e\u610f\u5411\uff0c\u4f7f\u5176\u6210\u4e3a\u8bc4\u4f30\u7b80\u77ed\u63a8\u5e7f\u6d3b\u52a8\u4ef7\u503c\u7684\u91cd\u8981\u89c6\u89d2\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u7684\u95ee\u5377\uff0c\u7528\u4e8e\u524d\u540e\u8bc4\u4f30CS\u5e72\u9884\u63aa\u65bd\u7684\u70ed\u60c5\u6f5c\u529b\u3002\u5229\u7528\u8d85\u8fc7400\u540d\u53c2\u52a0\u5728\u7ebfCS\u8bfe\u7a0b\u7684\u5b66\u751f\u7684\u6570\u636e\uff0c\u7814\u7a76\u4eba\u5458\u8003\u5bdf\u4e86\u4e0d\u540c\u5e74\u9f84\u6bb5\u548c\u6027\u522b\u95f4\u70ed\u60c5\u8868\u73b0\u7684\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u65e9\u671f\u63a5\u89e6\u662f\u901a\u5f80\u6301\u7eed\u5bf9CS\u611f\u5174\u8da3\u7684\u4e3b\u8981\u9014\u5f84\u8fd9\u4e00\u666e\u904d\u89c2\u70b9\u3002\u76f8\u53cd\u5730\uff0c\u7814\u7a76\u53d1\u73b0\u9752\u6625\u671f\u65e9\u671f\u5c24\u5176\u662f\u5973\u5b69\u4e2d\u5b58\u5728\u663e\u8457\u7684\u70ed\u60c5\u4e0b\u964d\u8d8b\u52bf\uff0c\u540c\u65f6\u5404\u5e74\u9f84\u6bb5\u95f4\u5174\u8da3\u8f68\u8ff9\u5b58\u5728\u5f88\u5927\u5dee\u5f02\u3002\u91cd\u8981\u7684\u662f\uff0c\u5206\u6790\u663e\u793a\uff0c\u5728\u5851\u9020\u5174\u8da3\u53d1\u5c55\u4e2d\u5e74\u9f84\u662f\u4e00\u4e2a\u6bd4\u6027\u522b\u66f4\u52a0\u51b3\u5b9a\u6027\u7684\u56e0\u7d20\uff0c\u5e76\u63ed\u793a\u4e86\u4e00\u4e9b\u5173\u952e\u7684\u53d1\u5c55\u8f6c\u6298\u70b9\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5c3d\u7ba1\u5f00\u59cb\u65f6\u6001\u5ea6\u57fa\u7ebf\u8f83\u4f4e\uff0c\u4f46\u8f83\u5e74\u957f\u7684\u5b66\u751f\u5728\u5e72\u9884\u540e\u8868\u73b0\u51fa\u6700\u5927\u5e45\u5ea6\u7684\u79ef\u6781\u6027\u53d8\u5316\u3002", "conclusion": "\u603b\u4f53\u800c\u8a00\uff0c\u8fd9\u9879\u7814\u7a76\u8868\u660e\u9700\u8981\u4e00\u4e2a\u52a8\u6001\u4e14\u8003\u8651\u5e74\u9f84\u654f\u611f\u6027\u7684CS\u6559\u80b2\u6846\u67b6\uff0c\u5176\u4e2d\u6559\u5b66\u7b56\u7565\u5e94\u4e0e\u53d1\u80b2\u8f68\u8ff9\u76f8\u4e00\u81f4\u3002"}}
{"id": "2512.07863", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07863", "abs": "https://arxiv.org/abs/2512.07863", "authors": ["Jianling Gao", "Chongyang Tao", "Xuelian Lin", "Junfeng Liu", "Shuai Ma"], "title": "SetAD: Semi-Supervised Anomaly Learning in Contextual Sets", "comment": "9 pages", "summary": "Semi-supervised anomaly detection (AD) has shown great promise by effectively leveraging limited labeled data. However, existing methods are typically structured around scoring individual points or simple pairs. Such {point- or pair-centric} view not only overlooks the contextual nature of anomalies, which are defined by their deviation from a collective group, but also fails to exploit the rich supervisory signals that can be generated from the combinatorial composition of sets. Consequently, such models struggle to exploit the high-order interactions within the data, which are critical for learning discriminative representations. To address these limitations, we propose SetAD, a novel framework that reframes semi-supervised AD as a Set-level Anomaly Detection task. SetAD employs an attention-based set encoder trained via a graded learning objective, where the model learns to quantify the degree of anomalousness within an entire set. This approach directly models the complex group-level interactions that define anomalies. Furthermore, to enhance robustness and score calibration, we propose a context-calibrated anomaly scoring mechanism, which assesses a point's anomaly score by aggregating its normalized deviations from peer behavior across multiple, diverse contextual sets. Extensive experiments on 10 real-world datasets demonstrate that SetAD significantly outperforms state-of-the-art models. Notably, we show that our model's performance consistently improves with increasing set size, providing strong empirical support for the set-based formulation of anomaly detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6SetAD\uff0c\u8be5\u6846\u67b6\u5c06\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u89c6\u4e3a\u96c6\u5408\u7ea7\u522b\u7684\u4efb\u52a1\uff0c\u901a\u8fc7\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u96c6\u5408\u7f16\u7801\u5668\u548c\u4e0a\u4e0b\u6587\u6821\u51c6\u7684\u5f02\u5e38\u8bc4\u5206\u673a\u5236\u6765\u5b66\u4e60\u590d\u6742\u7684\u6570\u636e\u7ec4\u5185\u4ea4\u4e92\uff0c\u4ece\u800c\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u968f\u7740\u96c6\u5408\u5927\u5c0f\u7684\u589e\u52a0\uff0cSetAD\u7684\u8868\u73b0\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u534a\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u5355\u4e2a\u70b9\u6216\u7b80\u5355\u5bf9\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u5f02\u5e38\u503c\u662f\u7531\u5176\u504f\u79bb\u96c6\u4f53\u7fa4\u4f53\u5b9a\u4e49\u7684\u8fd9\u4e00\u4e8b\u5b9e\uff0c\u4e5f\u672a\u80fd\u5145\u5206\u5229\u7528\u53ef\u4ee5\u4ece\u96c6\u5408\u7ec4\u5408\u4e2d\u4ea7\u751f\u7684\u4e30\u5bcc\u76d1\u7763\u4fe1\u53f7\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u6a21\u578b\u96be\u4ee5\u5229\u7528\u5bf9\u4e8e\u5b66\u4e60\u533a\u5206\u6027\u8868\u793a\u81f3\u5173\u91cd\u8981\u7684\u9ad8\u9636\u6570\u636e\u4ea4\u4e92\u3002", "method": "SetAD\u91c7\u7528\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u96c6\u5408\u7f16\u7801\u5668\uff0c\u5e76\u901a\u8fc7\u5206\u7ea7\u5b66\u4e60\u76ee\u6807\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u91cf\u5316\u6574\u4e2a\u96c6\u5408\u5185\u7684\u5f02\u5e38\u7a0b\u5ea6\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u589e\u5f3a\u9c81\u68d2\u6027\u548c\u8bc4\u5206\u6821\u51c6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0a\u4e0b\u6587\u6821\u51c6\u7684\u5f02\u5e38\u8bc4\u5206\u673a\u5236\uff0c\u8be5\u673a\u5236\u901a\u8fc7\u6c47\u603b\u4e00\u4e2a\u70b9\u5728\u591a\u4e2a\u591a\u6837\u5316\u4e0a\u4e0b\u6587\u96c6\u5408\u4e2d\u7684\u6807\u51c6\u5316\u504f\u5dee\u6765\u8bc4\u4f30\u5176\u5f02\u5e38\u5f97\u5206\u3002", "result": "\u572810\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSetAD\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u4e14\u968f\u7740\u96c6\u5408\u89c4\u6a21\u7684\u589e\u52a0\uff0c\u6a21\u578b\u6027\u80fd\u6301\u7eed\u6539\u5584\uff0c\u4e3a\u57fa\u4e8e\u96c6\u5408\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u5b9e\u8bc1\u652f\u6301\u3002", "conclusion": "SetAD\u901a\u8fc7\u5f15\u5165\u96c6\u5408\u7ea7\u522b\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4ee5\u53ca\u4e0a\u4e0b\u6587\u6821\u51c6\u7684\u5f02\u5e38\u8bc4\u5206\u673a\u5236\uff0c\u5728\u534a\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2512.07864", "categories": ["cs.LG", "econ.EM", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.07864", "abs": "https://arxiv.org/abs/2512.07864", "authors": ["Muhammad Sukri Bin Ramli"], "title": "Pattern Recognition of Ozone-Depleting Substance Exports in Global Trade Data", "comment": null, "summary": "New methods are needed to monitor environmental treaties, like the Montreal Protocol, by reviewing large, complex customs datasets. This paper introduces a framework using unsupervised machine learning to systematically detect suspicious trade patterns and highlight activities for review. Our methodology, applied to 100,000 trade records, combines several ML techniques. Unsupervised Clustering (K-Means) discovers natural trade archetypes based on shipment value and weight. Anomaly Detection (Isolation Forest and IQR) identifies rare \"mega-trades\" and shipments with commercially unusual price-per-kilogram values. This is supplemented by Heuristic Flagging to find tactics like vague shipment descriptions. These layers are combined into a priority score, which successfully identified 1,351 price outliers and 1,288 high-priority shipments for customs review. A key finding is that high-priority commodities show a different and more valuable value-to-weight ratio than general goods. This was validated using Explainable AI (SHAP), which confirmed vague descriptions and high value as the most significant risk predictors. The model's sensitivity was validated by its detection of a massive spike in \"mega-trades\" in early 2021, correlating directly with the real-world regulatory impact of the US AIM Act. This work presents a repeatable unsupervised learning pipeline to turn raw trade data into prioritized, usable intelligence for regulatory groups.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6846\u67b6\u6765\u76d1\u6d4b\u73af\u5883\u6761\u7ea6\u9075\u5b88\u60c5\u51b5\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5927\u91cf\u590d\u6742\u7684\u6d77\u5173\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4e86K-Means\u805a\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u542f\u53d1\u5f0f\u6807\u8bb0\u7b49\u6280\u672f\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u51fa1,351\u4e2a\u4ef7\u683c\u5f02\u5e38\u503c\u548c1,288\u4e2a\u9ad8\u4f18\u5148\u7ea7\u7684\u8d27\u7269\u7528\u4e8e\u6d77\u5173\u5ba1\u67e5\u3002", "motivation": "\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u76d1\u63a7\u50cf\u300a\u8499\u7279\u5229\u5c14\u8bae\u5b9a\u4e66\u300b\u8fd9\u6837\u7684\u73af\u5883\u6761\u7ea6\uff0c\u901a\u8fc7\u5bf9\u5927\u91cf\u7684\u590d\u6742\u6d77\u5173\u6570\u636e\u8fdb\u884c\u5ba1\u67e5\u3002", "method": "\u8bba\u6587\u4e2d\u5f15\u5165\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5730\u68c0\u6d4b\u53ef\u7591\u8d38\u6613\u6a21\u5f0f\uff0c\u5e76\u7a81\u51fa\u663e\u793a\u9700\u8981\u5ba1\u67e5\u7684\u6d3b\u52a8\u3002\u7814\u7a76\u65b9\u6cd5\u5e94\u7528\u4e8e10\u4e07\u6761\u8d38\u6613\u8bb0\u5f55\uff0c\u7ed3\u5408\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\uff1a\u65e0\u76d1\u7763\u805a\u7c7b\uff08K-Means\uff09\u57fa\u4e8e\u8d27\u7269\u4ef7\u503c\u548c\u91cd\u91cf\u53d1\u73b0\u81ea\u7136\u8d38\u6613\u539f\u578b\uff1b\u5f02\u5e38\u68c0\u6d4b\uff08\u5b64\u7acb\u68ee\u6797\u6cd5\u548c\u56db\u5206\u4f4d\u6570\u8303\u56f4\uff09\u8bc6\u522b\u7f55\u89c1\u7684\u201c\u5de8\u91cf\u4ea4\u6613\u201d\u4ee5\u53ca\u5546\u4e1a\u4e0a\u4e0d\u5e38\u89c1\u7684\u6bcf\u516c\u65a4\u4ef7\u683c\u503c\u7684\u8d27\u7269\uff1b\u5e76\u8f85\u4ee5\u542f\u53d1\u5f0f\u6807\u8bb0\u6765\u67e5\u627e\u8bf8\u5982\u6a21\u7cca\u7684\u8d27\u7269\u63cf\u8ff0\u4e4b\u7c7b\u7684\u7b56\u7565\u3002\u8fd9\u4e9b\u5c42\u6b21\u88ab\u7efc\u5408\u6210\u4e00\u4e2a\u4f18\u5148\u7ea7\u5206\u6570\u3002", "result": "\u6a21\u578b\u6210\u529f\u8bc6\u522b\u4e861,351\u4e2a\u4ef7\u683c\u5f02\u5e38\u503c\u548c1,288\u4e2a\u9ad8\u4f18\u5148\u7ea7\u7684\u8d27\u7269\u4f9b\u6d77\u5173\u5ba1\u67e5\u3002\u91cd\u8981\u53d1\u73b0\u662f\u9ad8\u4f18\u5148\u7ea7\u5546\u54c1\u663e\u793a\u51fa\u4e0e\u4e00\u822c\u5546\u54c1\u4e0d\u540c\u7684\u4e14\u66f4\u6709\u4ef7\u503c\u7684\u4ef7\u503c-\u91cd\u91cf\u6bd4\u3002\u8fd9\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\uff08SHAP\uff09\u5f97\u5230\u9a8c\u8bc1\uff0c\u786e\u8ba4\u4e86\u6a21\u7cca\u63cf\u8ff0\u548c\u9ad8\u4ef7\u503c\u662f\u6700\u663e\u8457\u7684\u98ce\u9669\u9884\u6d4b\u56e0\u7d20\u3002\u6a21\u578b\u7684\u654f\u611f\u6027\u4e5f\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u56e0\u4e3a\u5b83\u68c0\u6d4b\u5230\u4e862021\u5e74\u521d\u201c\u5de8\u91cf\u4ea4\u6613\u201d\u7684\u5de8\u5927\u5cf0\u503c\uff0c\u8fd9\u76f4\u63a5\u4e0e\u7f8e\u56fdAIM\u6cd5\u6848\u7684\u5b9e\u9645\u76d1\u7ba1\u5f71\u54cd\u76f8\u5173\u8054\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u6d41\u7a0b\uff0c\u80fd\u591f\u5c06\u539f\u59cb\u8d38\u6613\u6570\u636e\u8f6c\u5316\u4e3a\u4f18\u5148\u6392\u5e8f\u7684\u3001\u53ef\u7528\u7684\u60c5\u62a5\uff0c\u4e3a\u76d1\u7ba1\u56e2\u4f53\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2512.08657", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08657", "abs": "https://arxiv.org/abs/2512.08657", "authors": ["Renato Cordeiro Ferreira", "Aditya Dhinavahi", "Rowanne Trapmann", "Willem-Jan van den Heuvel"], "title": "Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain", "comment": "7 pages, 3 figures (3 diagrams), submitted to ICSA 2026", "summary": "ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.", "AI": {"tldr": "\u672c\u7ecf\u9a8c\u62a5\u544a\u4ecb\u7ecd\u4e86\u5728\u6784\u5efa\u6d77\u6d0b\u5b88\u62a4\u8005\uff08\u4e00\u4e2a\u7528\u4e8e\u6d77\u4e8b\u9886\u57df\u5f02\u5e38\u68c0\u6d4b\u7684ML-\u542f\u7528\u7cfb\u7edf\uff09\u8fc7\u7a0b\u4e2d\u5e94\u7528\u7684\u8f6f\u4ef6\u67b6\u6784\u91cd\u7528\u6280\u672f\uff0c\u7279\u522b\u662f\u5982\u4f55\u5229\u7528\u7aef\u53e3\u548c\u9002\u914d\u5668\u6a21\u5f0f\u4ece\u5355\u4e00\u4ee3\u7801\u5e93\u652f\u6301\u591a\u4e2a\u5fae\u670d\u52a1\u7684\u6784\u5efa\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u5206\u4eabOcean Guard\u9879\u76ee\u4e2d\u9047\u5230\u7684\u6311\u6218\u548c\u5438\u53d6\u7684\u7ecf\u9a8c\u6559\u8bad\uff0c\u9f13\u52b1\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u3001\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u4ee5\u53ca\u6570\u636e\u79d1\u5b66\u5bb6\u4eec\u91c7\u7528\u516d\u8fb9\u5f62\u67b6\u6784\u6a21\u5f0f\u6765\u5f00\u53d1\u4ed6\u4eec\u7684ML-\u542f\u7528\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e86\u7aef\u53e3\u548c\u9002\u914d\u5668\u8bbe\u8ba1\u6a21\u5f0f\u4ee5\u4fc3\u8fdb\u4ee3\u7801\u590d\u7528\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u540c\u4e00\u4ee3\u7801\u5e93\u5f00\u53d1\u591a\u4e2a\u5fae\u670d\u52a1\u3002", "result": "\u6210\u529f\u5730\u8fd0\u7528\u4e86\u516d\u8fb9\u5f62\u67b6\u6784\u4e0b\u7684\u7aef\u53e3\u4e0e\u9002\u914d\u5668\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4e86\u9488\u5bf9\u6d77\u4e8b\u9886\u57df\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u7684\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u670d\u52a1\u6784\u5efa\u65b9\u5f0f\u3002", "conclusion": "\u8be5\u62a5\u544a\u5c55\u793a\u4e86\u5982\u4f55\u6709\u6548\u5730\u5c06\u516d\u8fb9\u5f62\u67b6\u6784\u5e94\u7528\u4e8eML-\u542f\u7528\u7cfb\u7edf\u7684\u8bbe\u8ba1\u5f53\u4e2d\uff0c\u5f3a\u8c03\u4e86\u6b64\u65b9\u6cd5\u5bf9\u4e8e\u63d0\u9ad8\u8f6f\u4ef6\u7ec4\u4ef6\u53ef\u91cd\u7528\u6027\u548c\u7075\u6d3b\u6027\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.07865", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07865", "abs": "https://arxiv.org/abs/2512.07865", "authors": ["Philipp Stark", "Alexandros Sopasakis", "Ola Hall", "Markus Grillitsch"], "title": "Using Text-Based Life Trajectories from Swedish Register Data to Predict Residential Mobility with Pretrained Transformers", "comment": null, "summary": "We transform large-scale Swedish register data into textual life trajectories to address two long-standing challenges in data analysis: high cardinality of categorical variables and inconsistencies in coding schemes over time. Leveraging this uniquely comprehensive population register, we convert register data from 6.9 million individuals (2001-2013) into semantically rich texts and predict individuals' residential mobility in later years (2013-2017). These life trajectories combine demographic information with annual changes in residence, work, education, income, and family circumstances, allowing us to assess how effectively such sequences support longitudinal prediction. We compare multiple NLP architectures (including LSTM, DistilBERT, BERT, and Qwen) and find that sequential and transformer-based models capture temporal and semantic structure more effectively than baseline models. The results show that textualized register data preserves meaningful information about individual pathways and supports complex, scalable modeling. Because few countries maintain longitudinal microdata with comparable coverage and precision, this dataset enables analyses and methodological tests that would be difficult or impossible elsewhere, offering a rigorous testbed for developing and evaluating new sequence-modeling approaches. Overall, our findings demonstrate that combining semantically rich register data with modern language models can substantially advance longitudinal analysis in social sciences.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u5927\u89c4\u6a21\u745e\u5178\u767b\u8bb0\u6570\u636e\u8f6c\u5316\u4e3a\u6587\u672c\u751f\u547d\u8f68\u8ff9\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u5206\u6790\u4e2d\u7684\u4e24\u4e2a\u957f\u671f\u96be\u9898\uff1a\u5206\u7c7b\u53d8\u91cf\u7684\u9ad8\u57fa\u6570\u548c\u968f\u65f6\u95f4\u53d8\u5316\u7684\u7f16\u7801\u65b9\u6848\u4e0d\u4e00\u81f4\u3002\u901a\u8fc7\u5c06690\u4e07\u4e2a\u4f53\uff082001-2013\u5e74\uff09\u7684\u6570\u636e\u8f6c\u6362\u4e3a\u8bed\u4e49\u4e30\u5bcc\u7684\u6587\u672c\uff0c\u5e76\u9884\u6d4b\u4e2a\u4eba\u5728\u540e\u7eed\u51e0\u5e74\uff082013-2017\u5e74\uff09\u7684\u5c45\u4f4f\u6d41\u52a8\u6027\u3002\u6bd4\u8f83\u4e86\u591a\u79cdNLP\u67b6\u6784\uff08\u5305\u62ecLSTM\u3001DistilBERT\u3001BERT\u548cQwen\uff09\uff0c\u53d1\u73b0\u5e8f\u5217\u6a21\u578b\u548c\u57fa\u4e8etransformer\u7684\u6a21\u578b\u6bd4\u57fa\u7ebf\u6a21\u578b\u66f4\u6709\u6548\u5730\u6355\u6349\u5230\u4e86\u65f6\u95f4\u4e0e\u8bed\u4e49\u7ed3\u6784\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6587\u672c\u5316\u767b\u8bb0\u6570\u636e\u4fdd\u7559\u4e86\u5173\u4e8e\u4e2a\u4eba\u8def\u5f84\u7684\u6709\u610f\u4e49\u4fe1\u606f\uff0c\u5e76\u652f\u6301\u590d\u6742\u7684\u53ef\u6269\u5c55\u5efa\u6a21\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u6570\u636e\u5206\u6790\u4e2d\u9762\u4e34\u7684\u4e24\u5927\u6311\u6218\uff1a\u5206\u7c7b\u53d8\u91cf\u7684\u9ad8\u57fa\u6570\u95ee\u9898\u4ee5\u53ca\u968f\u65f6\u95f4\u63a8\u79fb\u51fa\u73b0\u7684\u7f16\u7801\u65b9\u6848\u4e0d\u4e00\u81f4\u6027\u3002\u540c\u65f6\uff0c\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u4e30\u5bcc\u7684\u767b\u8bb0\u8d44\u6599\u4e0e\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u6765\u63a8\u52a8\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u5185\u7eb5\u5411\u5206\u6790\u7684\u8fdb\u6b65\u3002", "method": "\u5229\u7528\u5168\u9762\u7684\u4eba\u53e3\u767b\u8bb0\u518c\uff0c\u5c062001\u81f32013\u5e74\u95f4690\u4e07\u4eba\u7684\u6ce8\u518c\u6570\u636e\u8f6c\u53d8\u4e3a\u5305\u542b\u4eba\u53e3\u7edf\u8ba1\u5b66\u4fe1\u606f\u53ca\u6bcf\u5e74\u5c45\u4f4f\u5730\u3001\u5de5\u4f5c\u3001\u6559\u80b2\u3001\u6536\u5165\u548c\u5bb6\u5ead\u72b6\u51b5\u53d8\u52a8\u60c5\u51b5\u7684\u8bed\u4e49\u4e30\u5bcc\u6587\u672c\u3002\u7136\u540e\u8fd0\u7528\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u67b6\u6784\uff08\u5982LSTM\u3001DistilBERT\u3001BERT\u548cQwen\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u5e8f\u5217\u5bf9\u652f\u6301\u957f\u671f\u9884\u6d4b\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5e8f\u5217\u578b\u548c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u80fd\u591f\u66f4\u52a0\u6709\u6548\u5730\u6355\u6349\u5230\u65f6\u95f4\u4e0a\u548c\u8bed\u4e49\u4e0a\u7684\u7ed3\u6784\u7279\u5f81\u3002\u6587\u672c\u5316\u7684\u6ce8\u518c\u6570\u636e\u4e0d\u4ec5\u4fdd\u7559\u4e86\u5173\u4e8e\u4e2a\u4eba\u53d1\u5c55\u8def\u5f84\u7684\u91cd\u8981\u4fe1\u606f\uff0c\u8fd8\u652f\u6301\u4e86\u590d\u6742\u4e14\u53ef\u6269\u5c55\u7684\u5efa\u6a21\u9700\u6c42\u3002", "conclusion": "\u7ed3\u5408\u5bcc\u542b\u8bed\u4e49\u7684\u6ce8\u518c\u6570\u636e\u4e0e\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u663e\u8457\u4fc3\u8fdb\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u7684\u7eb5\u5411\u5206\u6790\u65b9\u6cd5\u7684\u53d1\u5c55\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u5f88\u5c11\u6709\u56fd\u5bb6\u80fd\u7ef4\u6301\u5982\u6b64\u8986\u76d6\u5e7f\u6cdb\u4e14\u7cbe\u786e\u5ea6\u9ad8\u7684\u7eb5\u5411\u5fae\u89c2\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u8be5\u6570\u636e\u96c6\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u65b0\u7684\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2512.08706", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08706", "abs": "https://arxiv.org/abs/2512.08706", "authors": ["Leon Kogler", "Maximilian Ehrhart", "Benedikt Dornauer", "Eduard Paul Enoiu"], "title": "RESTifAI: LLM-Based Workflow for Reusable REST API Testing", "comment": "Accepted for ICSE 2026 Demonstration track", "summary": "With this paper, we introduce RESTifAI, an LLM-driven approach for generating reusable, CI/CD ready REST API tests, following the happy-path approach. Unlike existing tools that often focus primarily on internal server errors, RESTifAI systematically constructs valid test scenarios (happy paths) and derives negative cases to verify both intended functionality (2xx responses) and robustness against invalid inputs or business-rule violations (4xx responses). The results indicate that RESTifAI performs on par with the latest LLM tools, i.e., AutoRestTest and LogiAgent, while addressing limitations related to reusability, oracle complexity, and integration. To support this, we provide common comparative results and demonstrate the tool's applicability in industrial services. For tool demonstration, please refer to https://www.youtube.com/watch?v=2vtQo0T0Lo4. RESTifAI is publicly available at https://github.com/casablancahotelsoftware/RESTifAI.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5RESTifAI\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u590d\u7528\u4e14\u9002\u7528\u4e8eCI/CD\u7684REST API\u6d4b\u8bd5\u7528\u4f8b\uff0c\u540c\u65f6\u5904\u7406\u4e86\u6b63\u5411\u548c\u8d1f\u5411\u573a\u666f\u4ee5\u9a8c\u8bc1\u529f\u80fd\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002\u8be5\u5de5\u5177\u5728\u591a\u4e2a\u65b9\u9762\u4e0e\u6700\u65b0LLM\u5de5\u5177\u8868\u73b0\u76f8\u5f53\uff0c\u5e76\u89e3\u51b3\u4e86\u590d\u7528\u6027\u3001oracle\u590d\u6742\u5ea6\u53ca\u96c6\u6210\u76f8\u5173\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684API\u6d4b\u8bd5\u5de5\u5177\u4e3b\u8981\u5173\u6ce8\u4e8e\u5185\u90e8\u670d\u52a1\u5668\u9519\u8bef\u68c0\u6d4b\uff0c\u800c\u5ffd\u89c6\u4e86\u7cfb\u7edf\u5730\u6784\u5efa\u6709\u6548\u7684\u6d4b\u8bd5\u573a\u666f\uff08\u5373\u6b63\u5e38\u8def\u5f84\uff09\u4ee5\u53ca\u6d3e\u751f\u51fa\u8d1f\u9762\u6848\u4f8b\u6765\u9a8c\u8bc1\u9884\u671f\u529f\u80fd\uff082xx\u54cd\u5e94\uff09\u548c\u5bf9\u65e0\u6548\u8f93\u5165\u6216\u4e1a\u52a1\u89c4\u5219\u8fdd\u53cd\u7684\u9c81\u68d2\u6027\uff084xx\u54cd\u5e94\uff09\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u6d4b\u8bd5\u7528\u4f8b\u7684\u590d\u7528\u6027\u548c\u964d\u4f4eoracle\u590d\u6742\u5ea6\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86RESTifAI\u3002", "method": "RESTifAI\u662f\u4e00\u79cd\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u7cfb\u7edf\u5316\u5730\u521b\u5efa\u7b26\u5408\u2018\u5feb\u4e50\u8def\u5f84\u2019\u7b56\u7565\u7684REST API\u6d4b\u8bd5\uff0c\u5e76\u4e14\u4e5f\u80fd\u591f\u751f\u6210\u4e00\u4e9b\u8d1f\u9762\u6848\u4f8b\u6765\u786e\u4fddAPI\u4e0d\u4ec5\u5728\u6b63\u5e38\u60c5\u51b5\u4e0b\u5de5\u4f5c\u826f\u597d\uff0c\u800c\u4e14\u80fd\u591f\u59a5\u5584\u5904\u7406\u5f02\u5e38\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRESTifAI\u7684\u8868\u73b0\u4e0e\u6700\u65b0\u7684LLM\u5de5\u5177AutoRestTest\u548cLogiAgent\u76f8\u5f53\uff0c\u540c\u65f6\u5b83\u8fd8\u514b\u670d\u4e86\u5173\u4e8e\u6d4b\u8bd5\u7528\u4f8b\u590d\u7528\u6027\u3001oracle\u95ee\u9898\u7b80\u5316\u4ee5\u53ca\u66f4\u987a\u7545\u96c6\u6210\u7b49\u65b9\u9762\u7684\u9650\u5236\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165RESTifAI\uff0c\u4f5c\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u5f0f\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684REST API\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8fd9\u4e9b\u6d4b\u8bd5\u7528\u4f8b\u65e2\u8003\u8651\u5230\u4e86\u529f\u80fd\u6027\u7684\u9a8c\u8bc1\u4e5f\u8003\u8651\u5230\u4e86\u5bf9\u6297\u975e\u6cd5\u8f93\u5165\u6216\u8fdd\u53cd\u4e1a\u52a1\u89c4\u5219\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u9a8c\u8bc1\u3002\u6b64\u5916\uff0cRESTifAI\u8fd8\u5f3a\u8c03\u4e86\u6d4b\u8bd5\u7528\u4f8b\u7684\u590d\u7528\u4ef7\u503c\u53ca\u5176\u6613\u4e8e\u96c6\u6210\u5230\u6301\u7eed\u96c6\u6210/\u6301\u7eed\u90e8\u7f72\u6d41\u7a0b\u4e2d\u7684\u7279\u70b9\u3002"}}
{"id": "2512.08810", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08810", "abs": "https://arxiv.org/abs/2512.08810", "authors": ["Viola Campos", "Robin Kuschnereit", "Adrian Ulges"], "title": "Multicalibration for LLM-based Code Generation", "comment": "Accepted at AI-SQE 2026 (The 1st International Workshop on AI for Software Quality Evaluation: Judgment, Metrics, Benchmarks, and Beyond)", "summary": "As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u591a\u6821\u51c6\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5176\u5bf9\u4ee3\u7801\u6b63\u786e\u6027\u9884\u6d4b\u7684\u4fe1\u5fc3\u5206\u6570\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5728\u4e09\u4e2a\u51fd\u6570\u5408\u6210\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u56db\u79cd\u591a\u6821\u51c6\u65b9\u6cd5\uff0c\u53d1\u73b0\u76f8\u8f83\u4e8e\u672a\u7ecf\u6821\u51c6\u7684\u6a21\u578b\u548c\u57fa\u7840\u6821\u51c6\u65b9\u6cd5\uff0c\u591a\u6821\u51c6\u80fd\u591f\u663e\u8457\u63d0\u5347\u6280\u80fd\u8bc4\u5206\uff0c\u5e76\u4e14\u516c\u5f00\u4e86\u7528\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eAI\u7684\u4ee3\u7801\u751f\u6210\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u7814\u7a76\u8005\u4eec\u6b63\u5728\u63a2\u7d22\u5982\u4f55\u6821\u51c6\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u786e\u4fdd\u5b83\u4eec\u7684\u4fe1\u5fc3\u5206\u6570\u80fd\u51c6\u786e\u53cd\u6620\u4ee3\u7801\u6b63\u786e\u7684\u5b9e\u9645\u53ef\u80fd\u6027\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u591a\u6821\u51c6\u7684\u6982\u5ff5\u6765\u6355\u6349\u7f16\u7801\u95ee\u9898\u4e2d\u7684\u989d\u5916\u56e0\u7d20\uff0c\u5982\u590d\u6742\u5ea6\u3001\u4ee3\u7801\u957f\u5ea6\u6216\u6240\u7528\u7f16\u7a0b\u8bed\u8a00\u7b49\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u6700\u65b0\u7684\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\uff08Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill\uff09\uff0c\u5e76\u5728\u5728\u8fd9\u4e09\u4e2a\u51fd\u6570\u5408\u6210\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u591a\u6821\u51c6\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u672a\u7ecf\u8fc7\u6821\u51c6\u7684\u4ee4\u724c\u4f3c\u7136\u503c\u76f8\u6bd4\uff0c\u4f7f\u7528\u591a\u6821\u51c6\u6280\u672f\u53ef\u4ee5\u5c06\u6280\u80fd\u8bc4\u5206\u63d0\u9ad81.03\uff1b\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u6821\u51c6\u65b9\u6cd5\uff0c\u5219\u63d0\u9ad8\u4e860.37\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u4e0a\u8ff0\u56e0\u7d20\u5728\u6821\u51c6\u8fc7\u7a0b\u4e2d\u5f71\u54cd\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u591a\u6821\u51c6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6539\u5584\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u4ee3\u7801\u6b63\u786e\u6027\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4e3a\u672a\u6765\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u540c\u65f6\uff0c\u516c\u5f00\u53d1\u5e03\u7684\u6570\u636e\u96c6\u4e5f\u6709\u52a9\u4e8e\u4fc3\u8fdb\u540e\u7eed\u76f8\u5173\u5de5\u4f5c\u7684\u5f00\u5c55\u3002"}}
{"id": "2512.08867", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08867", "abs": "https://arxiv.org/abs/2512.08867", "authors": ["Jing Zhang", "Lianghong Guo", "Yanlin Wang", "Mingwei Liu", "Jiachi Chen", "Yuchi Ma", "Ensheng Shi", "Terry Yue Zhuo", "Hongyu Zhang", "Zibin Zheng"], "title": "SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA", "comment": null, "summary": "The Development Knowledge Question Answering (Dev Knowledge QA) task aims to provide natural language answers to knowledge-seeking questions during software development. To investigate its importance and to what extent it has been explored, we analyze real user-LLM dialogues from WildChat and find that: (1) The Dev Knowledge QA task accounts for 39.6% of interactions(highest among all tasks), revealing broad knowledge needs beyond code generation (32.3%). (2) Only 27.5% of real Dev Knowledge QA dialogues focus on code understanding, leaving out development knowledge-seeking. (3) Only 17.1% of real-world Dev Knowledge QA dialogues can be used for constructing a benchmark. Existing benchmarks have two primary limitations for evaluating the Dev Knowledge QA capability of LLMs. First, existing benchmarks offer a limited development knowledge scope, mainly focusing on code understanding and neglecting broader knowledge during development. Second, some benchmarks are not built from real user queries. To bridge this gap, we design a three-phase pipeline that transforms real-world dialogue into simple development knowledge-seeking QA pairs. Through this pipeline, we introduce SimpleDevQA, a multilingual benchmark derived from real user dialogues. It contains 2,740 QA pairs in three languages (English, Chinese, and Russian), and focuses on questions with unique, short, and verifiable answers for accurate and simple evaluation. Experiments show that: Code LLMs generally outperform general LLMs of similar scale; Knowledge injection with the Retrieval-Augmented Generation (RAG) strategy can boost LLM accuracy by 11.3% on average; LLMs show systematic overconfidence in Dev Knowledge QA, and the answering accuracy of LLMs shows a positive correlation with their stated confidence; Generally, LLMs with stronger code generation performance also exhibit stronger performance in Dev Knowledge QA.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u77e5\u8bc6\u95ee\u7b54\u4efb\u52a1\u7684\u91cd\u8981\u6027\u53ca\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u57fa\u51c6SimpleDevQA\uff0c\u65e8\u5728\u66f4\u597d\u5730\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u65b9\u9762\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4ee3\u7801\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u4e14\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u77e5\u8bc6\u95ee\u7b54\u9700\u6c42\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u8303\u56f4\u6709\u9650\u548c\u975e\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5c06\u771f\u5b9e\u5bf9\u8bdd\u8f6c\u6362\u4e3a\u95ee\u7b54\u5bf9\u7684\u6d41\u7a0b\uff0c\u4ece\u800c\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6570\u636e\u96c6SimpleDevQA\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u7ba1\u9053\u5904\u7406\u771f\u5b9e\u4e16\u754c\u5bf9\u8bdd\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u7b80\u5355\u7684\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u5bf9\uff1b\u57fa\u4e8e\u6b64\u65b9\u6cd5\u6784\u5efa\u4e86\u5305\u542b2,740\u4e2a\u95ee\u9898\u7b54\u6848\u5bf9\u3001\u6db5\u76d6\u4e09\u79cd\u8bed\u8a00\uff08\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u4fc4\u8bed\uff09\u7684SimpleDevQA\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4ee3\u7801\u4e13\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6bd4\u901a\u7528\u578b\u540c\u89c4\u6a21\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff1b\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\u53ef\u5e73\u5747\u63d0\u534711.3%\u7684\u51c6\u786e\u7387\uff1b\u540c\u65f6\u89c2\u5bdf\u5230\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u4e2d\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff0c\u5176\u56de\u7b54\u51c6\u786e\u5ea6\u4e0e\u5176\u58f0\u660e\u7684\u4fe1\u5fc3\u6c34\u5e73\u5448\u6b63\u76f8\u5173\u5173\u7cfb\uff1b\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6027\u80fd\u66f4\u5f3a\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e5f\u663e\u793a\u51fa\u5728\u5f00\u53d1\u77e5\u8bc6\u95ee\u7b54\u65b9\u9762\u7684\u66f4\u4f73\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u77e5\u8bc6\u95ee\u7b54\u4efb\u52a1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7\u5efa\u7acb\u65b0\u57fa\u51c6SimpleDevQA\u6765\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u6807\u51c6\u7684\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u8fd8\u63ed\u793a\u4e86\u7279\u5b9a\u9886\u57df\u6a21\u578b\u7684\u4f18\u52bf\u4ee5\u53ca\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u6280\u672f\u6539\u5584\u6a21\u578b\u6027\u80fd\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.07873", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07873", "abs": "https://arxiv.org/abs/2512.07873", "authors": ["Ci Zhang", "Huayu Li", "Changdi Yang", "Jiangnan Xia", "Yanzhi Wang", "Xiaolong Ma", "Jin Lu", "Geng Yuan"], "title": "Advancing physiological time series reconstruction and imputation via mixture of receptive fields and experts fusion", "comment": null, "summary": "Recent studies show that using diffusion models for time series signal reconstruc- tion holds great promise. However, such approaches remain largely unexplored in the domain of medical time series. The unique characteristics of the physiological time series signals, such as multivariate, high temporal variability, highly noisy, and artifact-prone, make deep learning-based approaches still challenging for tasks such as imputation. Hence, we propose a novel Mixture of Experts (MoE)-based noise estimator within a score-based diffusion framework. Specifically, the Receptive Field Adaptive MoE (RFAMoE) module is designed to enable each channel to adap- tively select desired receptive fields throughout the diffusion process. Moreover, recent literature has found that when generating a physiological signal, performing multiple inferences and averaging the reconstructed signals can effectively reduce reconstruction errors, but at the cost of significant computational and latency over- head. We design a Fusion MoE module and innovatively leverage the nature of MoE module to generate K noise signals in parallel, fuse them using a routing mechanism, and complete signal reconstruction in a single inference step. This design not only improves performance over previous methods but also eliminates the substantial computational cost and latency associated with multiple inference processes. Extensive results demonstrate that our proposed framework consistently outperforms diffusion-based SOTA works on different tasks and datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff08MoE\uff09\u7684\u566a\u58f0\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u91cd\u5efa\u3002\u901a\u8fc7\u8bbe\u8ba1\u81ea\u9002\u5e94\u611f\u53d7\u91ce\u7684MoE\u6a21\u5757\uff08RFAMoE\uff09\u548c\u878d\u5408MoE\u6a21\u5757\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5355\u4e00\u63a8\u7406\u6b65\u9aa4\u4e2d\u751f\u6210\u5e76\u878d\u5408\u591a\u4e2a\u566a\u58f0\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u9ad8\u6027\u80fd\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u4e0e\u5ef6\u8fdf\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u6846\u67b6\u5728\u4e0d\u540c\u4efb\u52a1\u53ca\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u91cd\u5efa\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7531\u4e8e\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u5177\u6709\u591a\u53d8\u91cf\u3001\u9ad8\u65f6\u95f4\u53d8\u5f02\u6027\u3001\u6781\u9ad8\u566a\u58f0\u4ee5\u53ca\u6613\u53d7\u5e72\u6270\u7b49\u7279\u70b9\uff0c\u4f7f\u5f97\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u8bf8\u5982\u63d2\u8865\u7b49\u4efb\u52a1\u4e0a\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u6b64\u5916\uff0c\u867d\u7136\u591a\u6b21\u63a8\u65ad\u540e\u5e73\u5747\u91cd\u6784\u4fe1\u53f7\u80fd\u591f\u6709\u6548\u51cf\u5c11\u8bef\u5dee\uff0c\u4f46\u8fd9\u5e26\u6765\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u8d1f\u62c5\u4e0e\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f97\u5206\u7684\u6269\u6563\u6846\u67b6\u4e0b\u7684Mixture of Experts (MoE) \u566a\u58f0\u4f30\u8ba1\u5668\u3002\n2. \u8bbe\u8ba1\u4e86Receptive Field Adaptive MoE (RFAMoE) \u6a21\u5757\uff0c\u4f7f\u6bcf\u4e2a\u901a\u9053\u80fd\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u6240\u9700\u7684\u611f\u53d7\u91ce\u3002\n3. \u5f15\u5165Fusion MoE\u6a21\u5757\uff0c\u5229\u7528MoE\u7684\u672c\u8d28\u5e76\u884c\u751f\u6210K\u4e2a\u566a\u58f0\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u8def\u7531\u673a\u5236\u5c06\u5b83\u4eec\u878d\u5408\uff0c\u5728\u5355\u6b21\u63a8\u7406\u6b65\u9aa4\u4e2d\u5b8c\u6210\u4fe1\u53f7\u91cd\u5efa\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6700\u5148\u8fdb\u5de5\u4f5c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165RFAMoE\u548cFusion MoE\u6a21\u5757\uff0c\u672c\u6587\u6240\u63d0\u51fa\u7684\u57fa\u4e8eMoE\u7684\u566a\u58f0\u4f30\u8ba1\u5668\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u91cd\u5efa\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u8fd8\u6210\u529f\u89e3\u51b3\u4e86\u591a\u8f6e\u63a8\u7406\u5e26\u6765\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u548c\u65f6\u5ef6\u95ee\u9898\u3002"}}
{"id": "2512.08910", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.08910", "abs": "https://arxiv.org/abs/2512.08910", "authors": ["Nathan Cassee", "Robert Feldt"], "title": "Exploring the Garden of Forking Paths in Empirical Software Engineering Research: A Multiverse Analysis", "comment": "Submitte to TOSEM", "summary": "In empirical software engineering (SE) research, researchers have considerable freedom to decide how to process data, what operationalizations to use, and which statistical model to fit. Gelman and Loken refer to this freedom as leading to a \"garden of forking paths\". Although this freedom is often seen as an advantage, it also poses a threat to robustness and replicability: variations in analytical decisions, even when justifiable, can lead to divergent conclusions.\n  To better understand this risk, we conducted a so-called multiverse analysis on a published empirical SE paper. The paper we picked is a Mining Software Repositories study, as MSR studies commonly use non-trivial statistical models to analyze post-hoc, observational data. In the study, we identified nine pivotal analytical decisions-each with at least one equally defensible alternative and systematically reran all the 3,072 resulting analysis pipelines on the original dataset. Interestingly, only 6 of these universes (<0.2%) reproduced the published results; the overwhelming majority produced qualitatively different, and sometimes even opposite, findings.\n  This case study of a data analytical method commonly applied to empirical software engineering data reveals how methodological choices can exert a more profound influence on outcomes than is often acknowledged. We therefore advocate that SE researchers complement standard reporting with robustness checks across plausible analysis variants or, at least, explicitly justify each analytical decision. We propose a structured classification model to help classify and improve justification for methodological choices. Secondly, we show how the multiverse analysis is a practical tool in the methodological arsenal of SE researchers, one that can help produce more reliable, reproducible science.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u591a\u5b87\u5b99\u5206\u6790\u65b9\u6cd5\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e00\u7bc7\u5df2\u53d1\u8868\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u8bba\u6587\uff0c\u63ed\u793a\u4e86\u65b9\u6cd5\u9009\u62e9\u5bf9\u7ed3\u679c\u7684\u91cd\u5927\u5f71\u54cd\uff0c\u5e76\u5efa\u8bae\u7814\u7a76\u4eba\u5458\u8865\u5145\u6807\u51c6\u62a5\u544a\u4ee5\u8fdb\u884c\u9c81\u68d2\u6027\u68c0\u67e5\u6216\u660e\u786e\u8bc1\u660e\u6bcf\u4e2a\u5206\u6790\u51b3\u7b56\u3002", "motivation": "\u5728\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\uff0c\u7814\u7a76\u4eba\u5458\u5728\u5904\u7406\u6570\u636e\u3001\u4f7f\u7528\u64cd\u4f5c\u5316\u65b9\u6cd5\u548c\u62df\u5408\u7edf\u8ba1\u6a21\u578b\u65b9\u9762\u6709\u5f88\u5927\u7684\u81ea\u7531\u5ea6\uff0c\u8fd9\u79cd\u81ea\u7531\u867d\u7136\u5e38\u88ab\u89c6\u4e3a\u4f18\u52bf\uff0c\u4f46\u4e5f\u5bf9\u7a33\u5065\u6027\u548c\u53ef\u91cd\u590d\u6027\u6784\u6210\u5a01\u80c1\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e00\u98ce\u9669\uff0c\u672c\u7814\u7a76\u9009\u53d6\u4e86\u4e00\u7bc7\u5df2\u53d1\u8868\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8bc1\u7814\u7a76\u8bba\u6587\u8fdb\u884c\u4e86\u6240\u8c13\u7684\u591a\u5b87\u5b99\u5206\u6790\u3002", "method": "\u9009\u53d6\u4e86\u4e00\u7bc7\u5173\u4e8e\u6316\u6398\u8f6f\u4ef6\u4ed3\u5e93\u7684\u7814\u7a76\u8bba\u6587\u4f5c\u4e3a\u6848\u4f8b\uff0c\u786e\u5b9a\u4e86\u4e5d\u4e2a\u5173\u952e\u7684\u5206\u6790\u51b3\u7b56\u70b9\uff0c\u6bcf\u4e2a\u90fd\u6709\u81f3\u5c11\u4e00\u4e2a\u540c\u6837\u5408\u7406\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u7cfb\u7edf\u5730\u5728\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u91cd\u65b0\u8fd0\u884c\u4e86\u6240\u67093,072\u79cd\u53ef\u80fd\u7684\u5206\u6790\u6d41\u7a0b\u3002", "result": "\u4ec5\u67096\u4e2a\uff08<0.2%\uff09\u7684\u5206\u6790\u6d41\u7a0b\u518d\u73b0\u4e86\u5df2\u53d1\u8868\u7684\u7ed3\u679c\uff1b\u7edd\u5927\u591a\u6570\u4ea7\u751f\u4e86\u5b9a\u6027\u4e0d\u540c\u7684\uff0c\u751a\u81f3\u6709\u65f6\u662f\u76f8\u53cd\u7684\u53d1\u73b0\u3002", "conclusion": "\u8fd9\u9879\u9488\u5bf9\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6570\u636e\u5206\u6790\u7684\u65b9\u6cd5\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u65b9\u6cd5\u8bba\u7684\u9009\u62e9\u53ef\u4ee5\u6bd4\u901a\u5e38\u8ba4\u4e3a\u7684\u5bf9\u7ed3\u679c\u4ea7\u751f\u66f4\u6df1\u8fdc\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u63d0\u5021\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4eba\u5458\u9664\u4e86\u6807\u51c6\u62a5\u544a\u5916\uff0c\u8fd8\u5e94\u8865\u5145\u8de8\u5408\u7406\u5206\u6790\u53d8\u4f53\u7684\u9c81\u68d2\u6027\u68c0\u67e5\uff0c\u6216\u8005\u81f3\u5c11\u660e\u786e\u8bba\u8bc1\u6bcf\u4e2a\u5206\u6790\u51b3\u5b9a\u3002\u6b64\u5916\uff0c\u5c55\u793a\u4e86\u591a\u5b87\u5b99\u5206\u6790\u4f5c\u4e3a\u4e00\u79cd\u5b9e\u7528\u5de5\u5177\u5982\u4f55\u5e2e\u52a9\u63d0\u9ad8\u79d1\u5b66\u5de5\u4f5c\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2512.07875", "categories": ["cs.LG", "cs.NE", "physics.data-an", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.07875", "abs": "https://arxiv.org/abs/2512.07875", "authors": ["James Bagrow", "Josh Bongard"], "title": "Softly Symbolifying Kolmogorov-Arnold Networks", "comment": "13 pages, 5 figures, 3 tables", "summary": "Kolmogorov-Arnold Networks (KANs) offer a promising path toward interpretable machine learning: their learnable activations can be studied individually, while collectively fitting complex data accurately. In practice, however, trained activations often lack symbolic fidelity, learning pathological decompositions with no meaningful correspondence to interpretable forms. We propose Softly Symbolified Kolmogorov-Arnold Networks (S2KAN), which integrate symbolic primitives directly into training. Each activation draws from a dictionary of symbolic and dense terms, with learnable gates that sparsify the representation. Crucially, this sparsification is differentiable, enabling end-to-end optimization, and is guided by a principled Minimum Description Length objective. When symbolic terms suffice, S2KAN discovers interpretable forms; when they do not, it gracefully degrades to dense splines. We demonstrate competitive or superior accuracy with substantially smaller models across symbolic benchmarks, dynamical systems forecasting, and real-world prediction tasks, and observe evidence of emergent self-sparsification even without regularization pressure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u79f0\u4e3aSoftly Symbolified Kolmogorov-Arnold Networks (S2KAN)\uff0c\u8be5\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u96c6\u6210\u4e86\u7b26\u53f7\u539f\u8bed\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cS2KAN\u80fd\u591f\u5728\u4fdd\u6301\u6216\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u53d1\u73b0\u66f4\u6613\u4e8e\u89e3\u91ca\u7684\u5f62\u5f0f\uff0c\u5e76\u4e14\u80fd\u591f\u81ea\u9002\u5e94\u5730\u7b80\u5316\u8868\u793a\u5f62\u5f0f\u3002", "motivation": "\u867d\u7136Kolmogorov-Arnold Networks\uff08KANs\uff09\u4e3a\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u5b9e\u8df5\u4e2d\u8bad\u7ec3\u51fa\u7684\u6fc0\u6d3b\u51fd\u6570\u5f80\u5f80\u7f3a\u4e4f\u7b26\u53f7\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u5206\u89e3\u7ed3\u679c\u6ca1\u6709\u5b9e\u9645\u610f\u4e49\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u53c8\u80fd\u751f\u6210\u6709\u610f\u4e49\u7684\u3001\u6613\u4e8e\u7406\u89e3\u7684\u6a21\u578b\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Softly Symbolified Kolmogorov-Arnold Networks (S2KAN) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5141\u8bb8\u6bcf\u4e2a\u6fc0\u6d3b\u4ece\u4e00\u4e2a\u5305\u542b\u7b26\u53f7\u548c\u5bc6\u96c6\u672f\u8bed\u7684\u5b57\u5178\u4e2d\u9009\u62e9\uff0c\u540c\u65f6\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u95e8\u673a\u5236\u6765\u7a00\u758f\u5316\u8868\u793a\u3002\u6b64\u8fc7\u7a0b\u662f\u53ef\u5fae\u5206\u7684\uff0c\u652f\u6301\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u5e76\u53d7\u5230\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6\u76ee\u6807\u7684\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u7b26\u53f7\u57fa\u51c6\u6d4b\u8bd5\u3001\u52a8\u529b\u7cfb\u7edf\u9884\u6d4b\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0cS2KAN\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u751a\u81f3\u66f4\u4f18\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u660e\u663e\u8f83\u5c0f\u7684\u6a21\u578b\u89c4\u6a21\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u6ca1\u6709\u6b63\u5219\u5316\u538b\u529b\uff0c\u4e5f\u89c2\u5bdf\u5230\u4e86\u81ea\u6211\u7a00\u758f\u5316\u7684\u73b0\u8c61\u3002", "conclusion": "S2KAN\u6210\u529f\u5730\u5c06\u7b26\u53f7\u8868\u8fbe\u4e0e\u673a\u5668\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u5728\u786e\u4fdd\u6a21\u578b\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2512.07878", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07878", "abs": "https://arxiv.org/abs/2512.07878", "authors": ["Manh Nguyen", "Joshua Cape"], "title": "Graph Contrastive Learning via Spectral Graph Alignment", "comment": null, "summary": "Given augmented views of each input graph, contrastive learning methods (e.g., InfoNCE) optimize pairwise alignment of graph embeddings across views while providing no mechanism to control the global structure of the view specific graph-of-graphs built from these embeddings. We introduce SpecMatch-CL, a novel loss function that aligns the view specific graph-of-graphs by minimizing the difference between their normalized Laplacians. Theoretically, we show that under certain assumptions, the difference between normalized Laplacians provides an upper bound not only for the difference between the ideal Perfect Alignment contrastive loss and the current loss, but also for the Uniformly loss. Empirically, SpecMatch-CL establishes new state of the art on eight TU benchmarks under unsupervised learning and semi-supervised learning at low label rates, and yields consistent gains in transfer learning on PPI-306K and ZINC 2M datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570SpecMatch-CL\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5f52\u4e00\u5316Laplacian\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5bf9\u9f50\u89c6\u56fe\u7279\u5b9a\u7684\u56fe-of-\u56fe\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u6280\u672f\u6c34\u5e73\uff0c\u5e76\u4e14\u5728\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e0a\u4e5f\u53d6\u5f97\u4e86\u6301\u7eed\u7684\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5982InfoNCE\u80fd\u591f\u4f18\u5316\u8de8\u89c6\u56fe\u56fe\u5d4c\u5165\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u7f3a\u4e4f\u63a7\u5236\u7531\u8fd9\u4e9b\u5d4c\u5165\u6784\u5efa\u7684\u89c6\u56fe\u7279\u5b9a\u56fe-of-\u56fe\u7684\u5168\u5c40\u7ed3\u6784\u673a\u5236\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aSpecMatch-CL\u7684\u65b0\u635f\u5931\u51fd\u6570\uff0c\u5b83\u901a\u8fc7\u6700\u5c0f\u5316\u4e0d\u540c\u89c6\u89d2\u4e0b\u56fe-of-\u56fe\u7684\u5f52\u4e00\u5316Laplacian\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5b9e\u73b0\u5bf9\u9f50\u3002\u6b64\u5916\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u5f52\u4e00\u5316Laplacian\u4e4b\u95f4\u7684\u5dee\u5f02\u4e3a\u7406\u60f3\u5b8c\u7f8e\u5bf9\u9f50\u5bf9\u6bd4\u635f\u5931\u4e0e\u5f53\u524d\u635f\u5931\u4e4b\u5dee\u63d0\u4f9b\u4e86\u4e0a\u754c\uff0c\u540c\u65f6\u4e5f\u9002\u7528\u4e8eUniformly\u635f\u5931\u3002", "result": "\u5b9e\u9a8c\u90e8\u5206\u5c55\u793a\u4e86SpecMatch-CL\u5728\u516b\u4e2aTU\u57fa\u51c6\u6d4b\u8bd5\uff08\u65e0\u76d1\u7763\u548c\u4f4e\u6807\u7b7e\u7387\u4e0b\u7684\u534a\u76d1\u7763\u5b66\u4e60\u573a\u666f\uff09\u4e2d\u521b\u9020\u4e86\u65b0\u7eaa\u5f55\uff0c\u5e76\u4e14\u5728PPI-306K\u548cZINC 2M\u6570\u636e\u96c6\u4e0a\u7684\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "SpecMatch-CL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u5584\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u5168\u5c40\u7ed3\u6784\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5176\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u5f97\u5230\u4e86\u652f\u6301\uff0c\u800c\u4e14\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.07879", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07879", "abs": "https://arxiv.org/abs/2512.07879", "authors": ["Manh Nguyen", "Daniel Pimentel-Alarc\u00f3n"], "title": "Nonnegative Matrix Factorization through Cone Collapse", "comment": null, "summary": "Nonnegative matrix factorization (NMF) is a widely used tool for learning parts-based, low-dimensional representations of nonnegative data, with applications in vision, text, and bioinformatics. In clustering applications, orthogonal NMF (ONMF) variants further impose (approximate) orthogonality on the representation matrix so that its rows behave like soft cluster indicators. Existing algorithms, however, are typically derived from optimization viewpoints and do not explicitly exploit the conic geometry induced by NMF: data points lie in a convex cone whose extreme rays encode fundamental directions or \"topics\". In this work we revisit NMF from this geometric perspective and propose Cone Collapse, an algorithm that starts from the full nonnegative orthant and iteratively shrinks it toward the minimal cone generated by the data. We prove that, under mild assumptions on the data, Cone Collapse terminates in finitely many steps and recovers the minimal generating cone of $\\mathbf{X}^\\top$ . Building on this basis, we then derive a cone-aware orthogonal NMF model (CC-NMF) by applying uni-orthogonal NMF to the recovered extreme rays. Across 16 benchmark gene-expression, text, and image datasets, CC-NMF consistently matches or outperforms strong NMF baselines-including multiplicative updates, ANLS, projective NMF, ONMF, and sparse NMF-in terms of clustering purity. These results demonstrate that explicitly recovering the data cone can yield both theoretically grounded and empirically strong NMF-based clustering methods.", "AI": {"tldr": "\u672c\u6587\u4ece\u51e0\u4f55\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u4e86\u975e\u8d1f\u77e9\u9635\u5206\u89e3(NMF)\uff0c\u63d0\u51fa\u4e86Cone Collapse\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u627e\u5230\u6570\u636e\u751f\u6210\u7684\u6700\u5c0f\u9525\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u9525\u611f\u77e5\u7684\u6b63\u4ea4NMF\u6a21\u578b(CC-NMF)\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCC-NMF\u5728\u805a\u7c7b\u7eaf\u5ea6\u65b9\u9762\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u591a\u4e2a\u5f3a\u5927\u7684NMF\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684NMF\u53caONMF\u53d8\u4f53\u901a\u5e38\u662f\u4ece\u4f18\u5316\u7684\u89d2\u5ea6\u63a8\u5bfc\u51fa\u6765\u7684\uff0c\u5e76\u6ca1\u6709\u660e\u786e\u5730\u5229\u7528NMF\u8bf1\u5bfc\u51fa\u7684\u9525\u5f62\u51e0\u4f55\u7ed3\u6784\uff1a\u6570\u636e\u70b9\u4f4d\u4e8e\u4e00\u4e2a\u51f8\u9525\u5185\uff0c\u5176\u6781\u5c04\u7ebf\u7f16\u7801\u4e86\u57fa\u672c\u65b9\u5411\u6216\u2018\u4e3b\u9898\u2019\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u5229\u7528\u8fd9\u79cd\u51e0\u4f55\u7279\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdbNMF\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCone Collapse\u7684\u65b0\u7b97\u6cd5\uff0c\u5b83\u4ece\u6574\u4e2a\u975e\u8d1f\u8c61\u9650\u5f00\u59cb\uff0c\u9010\u6b65\u7f29\u5c0f\u8303\u56f4\u76f4\u81f3\u8fbe\u5230\u7531\u6570\u636e\u751f\u6210\u7684\u6700\u5c0f\u9525\u3002\u57fa\u4e8e\u6b64\uff0c\u901a\u8fc7\u5c06\u5355\u6b63\u4ea4NMF\u5e94\u7528\u4e8e\u6062\u590d\u7684\u6781\u5c04\u7ebf\u4e0a\uff0c\u8fdb\u4e00\u6b65\u53d1\u5c55\u4e86\u4e00\u4e2a\u9525\u611f\u77e5\u7684\u6b63\u4ea4NMF\u6a21\u578b\uff08\u5373CC-NMF\uff09\u3002", "result": "\u572816\u4e2a\u57fa\u51c6\u57fa\u56e0\u8868\u8fbe\u3001\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0cCC-NMF\u5728\u805a\u7c7b\u7eaf\u5ea6\u65b9\u9762\u59cb\u7ec8\u4e0e\u5f3aNMF\u57fa\u7ebf\u2014\u2014\u5305\u62ec\u4e58\u6cd5\u66f4\u65b0\u3001ANLS\u3001\u6295\u5f71NMF\u3001ONMF\u4ee5\u53ca\u7a00\u758fNMF\u2014\u2014\u76f8\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u3002", "conclusion": "\u663e\u5f0f\u5730\u6062\u590d\u6570\u636e\u9525\u53ef\u4ee5\u4ea7\u751f\u7406\u8bba\u57fa\u7840\u624e\u5b9e\u4e14\u7ecf\u9a8c\u4e0a\u8868\u73b0\u4f18\u79c0\u7684\u57fa\u4e8eNMF\u7684\u805a\u7c7b\u65b9\u6cd5\u3002"}}
{"id": "2512.07880", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07880", "abs": "https://arxiv.org/abs/2512.07880", "authors": ["Huanran Li", "Manh Nguyen", "Daniel Pimentel-Alarc\u00f3n"], "title": "Semi-Supervised Contrastive Learning with Orthonormal Prototypes", "comment": null, "summary": "Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first identify a critical learning-rate threshold, beyond which standard contrastive losses converge to collapsed solutions. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u7684\u5b66\u4e60\u7387\u9608\u503c\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u540e\u4f1a\u5bfc\u81f4\u7ef4\u5ea6\u574d\u7f29\u95ee\u9898\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u76d1\u7763\u635f\u5931\u51fd\u6570CLOP\u6765\u4fc3\u8fdb\u7c7b\u522b\u5d4c\u5165\u4e4b\u95f4\u5f62\u6210\u6b63\u4ea4\u7ebf\u6027\u5b50\u7a7a\u95f4\uff0c\u4ece\u800c\u9632\u6b62\u7ef4\u5ea6\u574d\u7f29\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCLOP\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5e76\u4e14\u5bf9\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u548c\u6279\u91cf\u5927\u5c0f\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002", "motivation": "\u9488\u5bf9\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u7ef4\u5ea6\u574d\u7f29\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u4f7f\u7528\u6807\u51c6\u5bf9\u6bd4\u635f\u5931\u65f6\uff0c\u5728\u534a\u76d1\u7763\u548c\u81ea\u76d1\u7763\u8bbe\u7f6e\u4e0b\uff0c\u968f\u7740\u5b66\u4e60\u7387\u7684\u53d8\u5316\uff0c\u6a21\u578b\u7684\u5d4c\u5165\u53ef\u80fd\u4f1a\u6536\u655b\u5230\u4e00\u4e2a\u66f4\u4f4e\u7ef4\u5ea6\u7684\u7a7a\u95f4\u5185\u3002\u8fd9\u79cd\u73b0\u8c61\u9650\u5236\u4e86\u6a21\u578b\u5b66\u4e60\u6709\u6548\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b\u3002", "method": "\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5173\u952e\u7684\u5b66\u4e60\u7387\u9608\u503c\u70b9\uff0c\u8d85\u8fc7\u8fd9\u4e2a\u9608\u503c\u4f7f\u7528\u4f20\u7edf\u7684\u5bf9\u6bd4\u635f\u5931\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u7ef4\u5ea6\u574d\u7f29\u3002\u63a5\u7740\u4ecb\u7ecd\u4e86CLOP\uff08Contrastive Learning with Orthogonal Projections\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65e8\u5728\u901a\u8fc7\u9f13\u52b1\u4e0d\u540c\u7c7b\u522b\u7684\u5d4c\u5165\u5f62\u6210\u6b63\u4ea4\u7ebf\u6027\u5b50\u7a7a\u95f4\u6765\u907f\u514d\u7ef4\u5ea6\u574d\u7f29\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5728\u771f\u5b9e\u6570\u636e\u96c6\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u6d4b\u8bd5\u663e\u793a\uff0cCLOP\u4e0d\u4ec5\u80fd\u591f\u63d0\u9ad8\u56fe\u50cf\u5206\u7c7b\u4e0e\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u800c\u4e14\u76f8\u6bd4\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5b83\u5bf9\u4e8e\u53d8\u5316\u7684\u5b66\u4e60\u7387\u53ca\u6279\u6b21\u5927\u5c0f\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86CLOP\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u514b\u670d\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u9047\u5230\u7684\u7ef4\u5ea6\u574d\u7f29\u96be\u9898\uff0c\u4e3a\u63d0\u5347\u76f8\u5173\u89c6\u89c9\u4efb\u52a1\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.07884", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07884", "abs": "https://arxiv.org/abs/2512.07884", "authors": ["Hongjun Wang", "Yitong Jiang", "Collin McCarthy", "David Wehr", "Hanrong Ye", "Xinhao Li", "Ka Chun Cheung", "Wonmin Byeon", "Jinwei Gu", "Ke Chen", "Kai Han", "Hongxu Yin", "Pavlo Molchanov", "Jan Kautz", "Sifei Liu"], "title": "GSPN-2: Efficient Parallel Sequence Modeling", "comment": "NeurIPS 2025", "summary": "Efficient vision transformer remains a bottleneck for high-resolution images and long-video related real-world applications. Generalized Spatial Propagation Network (GSPN) addresses this by replacing quadratic self-attention with a line-scan propagation scheme, bringing the cost close to linear in the number of rows or columns, while retaining accuracy. Despite this advancement, the existing GSPN implementation still suffers from (i) heavy overhead due to repeatedly launching GPU kernels, (ii) excessive data transfers from global GPU memory, and (iii) redundant computations caused by maintaining separate propagation weights for each channel. We introduce GSPN-2, a joint algorithm-system redesign. In particular, we eliminate thousands of micro-launches from the previous implementation into one single 2D kernel, explicitly pin one warp to each channel slice, and stage the previous column's activations in shared memory. On the model side, we introduce a compact channel propagation strategy that replaces per-channel matrices, trimming parameters, and align naturally with the affinity map used in transformer attention. Experiments demonstrate GSPN-2's effectiveness across image classification and text-to-image synthesis tasks, matching transformer-level accuracy with significantly lower computational cost. GSPN-2 establishes a new efficiency frontier for modeling global spatial context in vision applications through its unique combination of structured matrix transformations and GPU-optimized implementation. Project page: https://whj363636.github.io/GSPN2/", "AI": {"tldr": "GSPN-2\u901a\u8fc7\u8054\u5408\u7b97\u6cd5-\u7cfb\u7edf\u91cd\u65b0\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u539f\u59cbGSPN\u5b9e\u73b0\u4e2d\u7684GPU\u5185\u6838\u91cd\u590d\u542f\u52a8\u3001\u5168\u5c40GPU\u5185\u5b58\u6570\u636e\u4f20\u8f93\u8fc7\u591a\u4ee5\u53ca\u4e3a\u6bcf\u4e2a\u901a\u9053\u4fdd\u6301\u72ec\u7acb\u4f20\u64ad\u6743\u91cd\u5bfc\u81f4\u7684\u5197\u4f59\u8ba1\u7b97\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u4efb\u52a1\u4e0a\u4ee5\u663e\u8457\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u8fbe\u5230\u4e0etransformer\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684GSPN\u867d\u7136\u901a\u8fc7\u7ebf\u626b\u63cf\u4f20\u64ad\u65b9\u6848\u63a5\u8fd1\u7ebf\u6027\u5730\u964d\u4f4e\u4e86\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u53ca\u957f\u89c6\u9891\u5e94\u7528\u7684\u6210\u672c\uff0c\u4f46\u4ecd\u5b58\u5728\u7531\u4e8e\u53cd\u590d\u542f\u52a8GPU\u5185\u6838\u9020\u6210\u7684\u6c89\u91cd\u5f00\u9500\u3001\u4ece\u5168\u5c40GPU\u5185\u5b58\u8fdb\u884c\u8fc7\u591a\u7684\u6570\u636e\u8f6c\u79fb\u4ee5\u53ca\u4e3a\u6bcf\u4e2a\u901a\u9053\u7ef4\u62a4\u5355\u72ec\u4f20\u64ad\u6743\u91cd\u5bfc\u81f4\u7684\u5197\u4f59\u8ba1\u7b97\u7b49\u95ee\u9898\u3002", "method": "GSPN-2\u5f15\u5165\u4e86\u8054\u5408\u7b97\u6cd5-\u7cfb\u7edf\u91cd\u65b0\u8bbe\u8ba1\uff0c\u5c06\u6570\u5343\u6b21\u5fae\u5c0f\u542f\u52a8\u5408\u5e76\u4e3a\u4e00\u4e2a\u5355\u4e002D\u5185\u6838\uff0c\u660e\u786e\u5730\u5c06\u4e00\u4e2awarp\u56fa\u5b9a\u5230\u6bcf\u4e2a\u901a\u9053\u5207\u7247\uff0c\u5e76\u5229\u7528\u5171\u4eab\u5185\u5b58\u6682\u5b58\u524d\u4e00\u5217\u7684\u6fc0\u6d3b\u3002\u6a21\u578b\u65b9\u9762\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u7d27\u51d1\u7684\u901a\u9053\u4f20\u64ad\u7b56\u7565\u6765\u66ff\u6362\u6bcf\u901a\u9053\u77e9\u9635\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\uff0c\u5e76\u81ea\u7136\u5730\u4e0e\u53d8\u538b\u5668\u6ce8\u610f\u529b\u4e2d\u4f7f\u7528\u7684\u4eb2\u548c\u56fe\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGSPN-2\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u4efb\u52a1\u4e0a\u80fd\u591f\u4ee5\u663e\u8457\u964d\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u8fbe\u5230\u4e0etransformer\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "GSPN-2\u901a\u8fc7\u5176\u72ec\u7279\u7684\u7ed3\u6784\u5316\u77e9\u9635\u53d8\u6362\u4e0eGPU\u4f18\u5316\u5b9e\u73b0\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u5728\u89c6\u89c9\u5e94\u7528\u4e2d\u5efa\u6a21\u5168\u5c40\u7a7a\u95f4\u4e0a\u4e0b\u6587\u65b9\u9762\u8bbe\u5b9a\u4e86\u65b0\u7684\u6548\u7387\u524d\u6cbf\u3002"}}
{"id": "2512.07961", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.07961", "abs": "https://arxiv.org/abs/2512.07961", "authors": ["Guilherme Seidyo Imai Aldeia", "Joseph D. Romano", "Fabricio Olivetti de Franca", "Daniel S. Herman", "William G. La Cava"], "title": "Towards symbolic regression for interpretable clinical decision scores", "comment": "15 pages, 5 figures. Accepted for publication in Philosophical Transactions A. Autor Accepted Manuscript version", "summary": "Medical decision-making makes frequent use of algorithms that combine risk equations with rules, providing clear and standardized treatment pathways. Symbolic regression (SR) traditionally limits its search space to continuous function forms and their parameters, making it difficult to model this decision-making. However, due to its ability to derive data-driven, interpretable models, SR holds promise for developing data-driven clinical risk scores. To that end we introduce Brush, an SR algorithm that combines decision-tree-like splitting algorithms with non-linear constant optimization, allowing for seamless integration of rule-based logic into symbolic regression and classification models. Brush achieves Pareto-optimal performance on SRBench, and was applied to recapitulate two widely used clinical scoring systems, achieving high accuracy and interpretable models. Compared to decision trees, random forests, and other SR methods, Brush achieves comparable or superior predictive performance while producing simpler models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u7b26\u53f7\u56de\u5f52\u7b97\u6cd5Brush\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u51b3\u7b56\u6811\u5f0f\u7684\u5206\u5272\u7b97\u6cd5\u4e0e\u975e\u7ebf\u6027\u5e38\u6570\u4f18\u5316\uff0c\u65e8\u5728\u5c06\u57fa\u4e8e\u89c4\u5219\u7684\u903b\u8f91\u65e0\u7f1d\u96c6\u6210\u5230\u7b26\u53f7\u56de\u5f52\u548c\u5206\u7c7b\u6a21\u578b\u4e2d\u3002Brush\u5728SRBench\u4e0a\u8fbe\u5230\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u80fd\uff0c\u5e76\u88ab\u5e94\u7528\u4e8e\u91cd\u65b0\u6784\u5efa\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e34\u5e8a\u8bc4\u5206\u7cfb\u7edf\uff0c\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u4ea7\u751f\u66f4\u7b80\u5355\u4e14\u5177\u6709\u53ef\u6bd4\u6216\u66f4\u4f18\u9884\u6d4b\u6027\u80fd\u7684\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u7b26\u53f7\u56de\u5f52\u7b97\u6cd5\uff08SR\uff09\u4ec5\u9650\u4e8e\u8fde\u7eed\u51fd\u6570\u5f62\u5f0f\u53ca\u5176\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\uff0c\u8fd9\u4f7f\u5f97\u5b83\u96be\u4ee5\u6a21\u62df\u5305\u542b\u89c4\u5219\u7684\u533b\u7597\u51b3\u7b56\u8fc7\u7a0b\u3002\u7136\u800c\uff0c\u7531\u4e8eSR\u80fd\u591f\u63a8\u5bfc\u51fa\u6570\u636e\u9a71\u52a8\u4e14\u53ef\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u5b83\u6709\u6f5c\u529b\u5f00\u53d1\u51fa\u6570\u636e\u9a71\u52a8\u7684\u4e34\u5e8a\u98ce\u9669\u8bc4\u5206\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86Brush\u7b97\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBrush\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u7ed3\u5408\u7c7b\u4f3c\u51b3\u7b56\u6811\u7684\u5206\u5272\u7b97\u6cd5\u548c\u975e\u7ebf\u6027\u5e38\u6570\u4f18\u5316\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u89c4\u5219\u903b\u8f91\u4e0e\u7b26\u53f7\u56de\u5f52\u53ca\u5206\u7c7b\u6a21\u578b\u7684\u65e0\u7f1d\u6574\u5408\u3002", "result": "Brush\u7b97\u6cd5\u5728SRBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u80fd\uff1b\u5f53\u5e94\u7528\u4e8e\u91cd\u6784\u4e24\u4e2a\u5e7f\u4e3a\u63a5\u53d7\u7684\u4e34\u5e8a\u8bc4\u5206\u4f53\u7cfb\u65f6\uff0c\u76f8\u8f83\u4e8e\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u53ca\u5176\u4ed6SR\u65b9\u6cd5\uff0cBrush\u4e0d\u4ec5\u80fd\u591f\u4fdd\u6301\u76f8\u5f53\u751a\u81f3\u66f4\u4f73\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u8fd8\u80fd\u751f\u6210\u66f4\u52a0\u7b80\u6d01\u6613\u61c2\u7684\u6a21\u578b\u3002", "conclusion": "Brush\u7b97\u6cd5\u4e3a\u533b\u7597\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u7528\u4ee5\u5f00\u53d1\u9ad8\u5ea6\u51c6\u786e\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u6570\u636e\u9a71\u52a8\u578b\u4e34\u5e8a\u8bc4\u5206\u7cfb\u7edf\u3002\u76f8\u6bd4\u73b0\u6709\u7684\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u7b49\u65b9\u6cd5\uff0cBrush\u80fd\u591f\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u7b80\u5316\u6a21\u578b\u7ed3\u6784\u3002"}}
{"id": "2512.07981", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07981", "abs": "https://arxiv.org/abs/2512.07981", "authors": ["Federico Di Valerio", "Michela Proietti", "Alessio Ragno", "Roberto Capobianco"], "title": "CIP-Net: Continual Interpretable Prototype-based Network", "comment": null, "summary": "Continual learning constrains models to learn new tasks over time without forgetting what they have already learned. A key challenge in this setting is catastrophic forgetting, where learning new information causes the model to lose its performance on previous tasks. Recently, explainable AI has been proposed as a promising way to better understand and reduce forgetting. In particular, self-explainable models are useful because they generate explanations during prediction, which can help preserve knowledge. However, most existing explainable approaches use post-hoc explanations or require additional memory for each new task, resulting in limited scalability. In this work, we introduce CIP-Net, an exemplar-free self-explainable prototype-based model designed for continual learning. CIP-Net avoids storing past examples and maintains a simple architecture, while still providing useful explanations and strong performance. We demonstrate that CIPNet achieves state-of-the-art performances compared to previous exemplar-free and self-explainable methods in both task- and class-incremental settings, while bearing significantly lower memory-related overhead. This makes it a practical and interpretable solution for continual learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCIP-Net\u7684\u65e0\u793a\u4f8b\u81ea\u89e3\u91ca\u539f\u578b\u6a21\u578b\uff0c\u7528\u4e8e\u6301\u7eed\u5b66\u4e60\u3002\u5b83\u907f\u514d\u4e86\u5b58\u50a8\u8fc7\u53bb\u7684\u6837\u672c\uff0c\u5e76\u4fdd\u6301\u4e86\u7b80\u5355\u7684\u67b6\u6784\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u89e3\u91ca\u548c\u5f3a\u5927\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5148\u524d\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cCIP-Net\u5728\u4efb\u52a1\u589e\u91cf\u548c\u7c7b\u589e\u91cf\u8bbe\u7f6e\u4e0b\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u5185\u5b58\u76f8\u5173\u7684\u5f00\u9500\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u8981\u6c42\u6a21\u578b\u968f\u65f6\u95f4\u5b66\u4e60\u65b0\u4efb\u52a1\u800c\u4e0d\u5fd8\u8bb0\u5df2\u5b66\u77e5\u8bc6\u3002\u7136\u800c\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u707e\u96be\u6027\u9057\u5fd8\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5373\u5b66\u4e60\u65b0\u4fe1\u606f\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u5148\u524d\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u3002\u867d\u7136\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\uff08\u7279\u522b\u662f\u81ea\u89e3\u91ca\u6a21\u578b\uff09\u88ab\u63d0\u8bae\u4e3a\u66f4\u597d\u5730\u7406\u89e3\u548c\u51cf\u5c11\u9057\u5fd8\u7684\u4e00\u79cd\u6709\u5e0c\u671b\u7684\u65b9\u5f0f\uff0c\u4f46\u73b0\u6709\u7684\u5927\u591a\u6570\u53ef\u89e3\u91ca\u65b9\u6cd5\u4f7f\u7528\u4e8b\u540e\u89e3\u91ca\u6216\u9700\u8981\u4e3a\u6bcf\u4e2a\u65b0\u4efb\u52a1\u589e\u52a0\u989d\u5916\u7684\u5185\u5b58\uff0c\u5bfc\u81f4\u6269\u5c55\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86CIP-Net\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u4e3a\u6301\u7eed\u5b66\u4e60\u8bbe\u8ba1\u7684\u65e0\u793a\u4f8b\u81ea\u89e3\u91ca\u539f\u578b\u6a21\u578b\u3002\u8be5\u6a21\u578b\u4e0d\u9700\u8981\u5b58\u50a8\u8fc7\u53bb\u7684\u6570\u636e\u6837\u4f8b\uff0c\u5e76\u4e14\u7ef4\u6301\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u67b6\u6784\uff0c\u4f46\u4ecd\u80fd\u63d0\u4f9b\u6709\u7528\u7684\u89e3\u91ca\u4ee5\u53ca\u4f18\u79c0\u7684\u6027\u80fd\u3002", "result": "CIP-Net\u5728\u4efb\u52a1\u589e\u91cf\u548c\u7c7b\u589e\u91cf\u4e24\u79cd\u573a\u666f\u4e0b\u90fd\u8fbe\u5230\u4e86\u6bd4\u4e4b\u524d\u65e0\u793a\u4f8b\u548c\u81ea\u89e3\u91ca\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\uff0c\u800c\u4e14\u5b83\u7684\u5185\u5b58\u76f8\u5173\u5f00\u9500\u663e\u8457\u66f4\u4f4e\u3002", "conclusion": "CIP-Net\u4f5c\u4e3a\u4e00\u79cd\u5b9e\u9645\u4e14\u53ef\u89e3\u91ca\u7684\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u5185\u5b58\u9700\u6c42\u7684\u80fd\u529b\uff0c\u4f7f\u5176\u6210\u4e3a\u6301\u7eed\u5b66\u4e60\u9886\u57df\u7684\u4e00\u4e2a\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.08029", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.08029", "abs": "https://arxiv.org/abs/2512.08029", "authors": ["Tianxingjian Ding", "Yuanhao Zou", "Chen Chen", "Mubarak Shah", "Yu Tian"], "title": "CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space", "comment": null, "summary": "Clinical decision-making in oncology requires predicting dynamic disease evolution, a task current static AI predictors cannot perform. While world models (WMs) offer a paradigm for generative prediction, existing medical applications remain limited. Existing methods often rely on stochastic diffusion models, focusing on visual reconstruction rather than causal, physiological transitions. Furthermore, in medical domain, models like MeWM typically ignore patient-specific temporal and clinical contexts and lack a feedback mechanism to link predictions to treatment decisions. To address these gaps, we introduce CLARITY, a medical world model that forecasts disease evolution directly within a structured latent space. It explicitly integrates time intervals (temporal context) and patient-specific data (clinical context) to model treatment-conditioned progression as a smooth, interpretable trajectory, and thus generate physiologically faithful, individualized treatment plans. Finally, CLARITY introduces a novel prediction-to-decision framework, translating latent rollouts into transparent, actionable recommendations. CLARITY demonstrates state-of-the-art performance in treatment planning. On the MU-Glioma-Post dataset, our approach outperforms recent MeWM by 12\\%, and significantly surpasses all other medical-specific large language models.", "AI": {"tldr": "CLARITY, a new medical world model, improves upon existing methods by integrating temporal and clinical contexts for more accurate and personalized disease evolution predictions, thus enhancing treatment planning. It outperforms recent models on the MU-Glioma-Post dataset.", "motivation": "Current AI predictors in oncology are limited to static predictions and do not adequately account for dynamic disease evolution or patient-specific contexts. There is a need for a model that can generate more physiologically faithful and individualized treatment plans based on causal, physiological transitions over time.", "method": "CLARITY, a medical world model, was developed to forecast disease evolution within a structured latent space. It incorporates both temporal (time intervals) and clinical (patient-specific data) contexts to model the progression of diseases under different treatments as interpretable trajectories. Additionally, it establishes a prediction-to-decision framework to convert these forecasts into actionable treatment recommendations.", "result": "On the MU-Glioma-Post dataset, CLARITY outperformed the recent MeWM model by 12% and also surpassed other medical-specific large language models, demonstrating its effectiveness in treatment planning and personalized disease forecasting.", "conclusion": "CLARITY represents a significant advancement in medical world models, offering more accurate, personalized, and causally informed predictions of disease evolution. Its ability to integrate specific patient data and provide actionable treatment recommendations marks a step forward in the application of AI to oncology treatment planning."}}
{"id": "2512.08061", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08061", "abs": "https://arxiv.org/abs/2512.08061", "authors": ["Ashkan Shahbazi", "Ping He", "Ali Abbasi", "Yikun Bai", "Xinran Liu", "Elaheh Akbari", "Darian Salehi", "Navid NaderiAlizadeh", "Soheil Kolouri"], "title": "LUNA: Linear Universal Neural Attention with Generalization Guarantees", "comment": null, "summary": "Scaling attention faces a critical bottleneck: the $\\mathcal{O}(n^2)$ quadratic computational cost of softmax attention, which limits its application in long-sequence domains. While linear attention mechanisms reduce this cost to $\\mathcal{O}(n)$, they typically rely on fixed random feature maps, such as random Fourier features or hand-crafted functions. This reliance on static, data-agnostic kernels creates a fundamental trade-off, forcing practitioners to sacrifice significant model accuracy for computational efficiency. We introduce \\textsc{LUNA}, a kernelized linear attention mechanism that eliminates this trade-off, retaining linear cost while matching and surpassing the accuracy of quadratic attention. \\textsc{LUNA} is built on the key insight that the kernel feature map itself should be learned rather than fixed a priori. By parameterizing the kernel, \\textsc{LUNA} learns a feature basis tailored to the specific data and task, overcoming the expressive limitations of fixed-feature methods. \\textsc{Luna} implements this with a learnable feature map that induces a positive-definite kernel and admits a streaming form, yielding linear time and memory scaling in the sequence length. Empirical evaluations validate our approach across diverse settings. On the Long Range Arena (LRA), \\textsc{Luna} achieves state-of-the-art average accuracy among efficient Transformers under compute parity, using the same parameter count, training steps, and approximate FLOPs. \\textsc{Luna} also excels at post-hoc conversion: replacing softmax in fine-tuned BERT and ViT-B/16 checkpoints and briefly fine-tuning recovers most of the original performance, substantially outperforming fixed linearizations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLUNA\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b83\u901a\u8fc7\u5b66\u4e60\u5185\u6838\u7279\u5f81\u6620\u5c04\u800c\u975e\u4f7f\u7528\u56fa\u5b9a\u7684\u968f\u673a\u7279\u5f81\u6620\u5c04\u6765\u4fdd\u6301\u7ebf\u6027\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4e8c\u6b21\u6ce8\u610f\u529b\u673a\u5236\u7684\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cLUNA\u5728\u957f\u5e8f\u5217\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u66ff\u6362\u5fae\u8c03\u540e\u7684BERT\u548cViT\u6a21\u578b\u4e2d\u7684softmax\u5c42\uff0c\u6062\u590d\u5927\u90e8\u5206\u539f\u59cb\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u9762\u4e34\u7684\u4e3b\u8981\u74f6\u9888\u662f\u5176\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9650\u5236\u4e86\u5b83\u5728\u957f\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u800c\u73b0\u6709\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u867d\u7136\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u901a\u5e38\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u968f\u673a\u7279\u5f81\u6620\u5c04\u6216\u624b\u5de5\u8bbe\u8ba1\u51fd\u6570\uff0c\u8fd9\u5bfc\u81f4\u4e86\u51c6\u786e\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LUNA\u3002", "method": "LUNA\u662f\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u5185\u6838\u7279\u5f81\u6620\u5c04\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u6839\u636e\u7279\u5b9a\u6570\u636e\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u5730\u8c03\u6574\u7279\u5f81\u57fa\uff0c\u4ece\u800c\u514b\u670d\u4e86\u9759\u6001\u7279\u5f81\u65b9\u6cd5\u8868\u8fbe\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u4e86\u6b63\u5b9a\u6838\u7684\u5b58\u5728\uff0c\u5e76\u5141\u8bb8\u6d41\u5f0f\u5904\u7406\u5f62\u5f0f\uff0c\u4f7f\u5f97\u5e8f\u5217\u957f\u5ea6\u4e0a\u7684\u65f6\u95f4\u548c\u5185\u5b58\u5f00\u9500\u5448\u7ebf\u6027\u589e\u957f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u957f\u8303\u56f4\u7ade\u6280\u573a\uff08LRA\uff09\u6d4b\u8bd5\u4e2d\uff0c\u5f53\u53c2\u6570\u6570\u91cf\u3001\u8bad\u7ec3\u6b65\u9aa4\u548c\u8fd1\u4f3cFLOPs\u76f8\u540c\u65f6\uff0cLUNA\u5728\u9ad8\u6548\u53d8\u6362\u5668\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002\u6b64\u5916\uff0c\u5c06\u9884\u8bad\u7ec3\u597d\u7684BERT\u548cViT-B/16\u6a21\u578b\u4e2d\u7684softmax\u66ff\u6362\u6210LUNA\u5e76\u8fdb\u884c\u7b80\u77ed\u5fae\u8c03\u540e\uff0c\u53ef\u4ee5\u6062\u590d\u5927\u90e8\u5206\u539f\u6709\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u56fa\u5b9a\u7ebf\u6027\u5316\u65b9\u6cd5\u3002", "conclusion": "LUNA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u51b3\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u6548\u7387\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u6743\u8861\u95ee\u9898\u7684\u65b0\u9014\u5f84\uff0c\u4e0d\u4ec5\u4fdd\u6301\u4e86\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u8fd8\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2512.08063", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08063", "abs": "https://arxiv.org/abs/2512.08063", "authors": ["Xiaobin Shen", "George H. Chen"], "title": "Deep Kernel Aalen-Johansen Estimator: An Interpretable and Flexible Neural Net Framework for Competing Risks", "comment": "Machine Learning for Health (ML4H) 2025 Spotlight", "summary": "We propose an interpretable deep competing risks model called the Deep Kernel Aalen-Johansen (DKAJ) estimator, which generalizes the classical Aalen-Johansen nonparametric estimate of cumulative incidence functions (CIFs). Each data point (e.g., patient) is represented as a weighted combination of clusters. If a data point has nonzero weight only for one cluster, then its predicted CIFs correspond to those of the classical Aalen-Johansen estimator restricted to data points from that cluster. These weights come from an automatically learned kernel function that measures how similar any two data points are. On four standard competing risks datasets, we show that DKAJ is competitive with state-of-the-art baselines while being able to provide visualizations to assist model interpretation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDeep Kernel Aalen-Johansen (DKAJ)\u4f30\u8ba1\u5668\u7684\u53ef\u89e3\u91ca\u6df1\u5ea6\u7ade\u4e89\u98ce\u9669\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u56db\u4e2a\u6807\u51c6\u7684\u7ade\u4e89\u98ce\u9669\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u4e14\u80fd\u591f\u63d0\u4f9b\u53ef\u89c6\u5316\u5e2e\u52a9\u7406\u89e3\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5bf9\u590d\u6742\u6570\u636e\uff08\u5982\u60a3\u8005\u6570\u636e\uff09\u4e2d\u7d2f\u79ef\u53d1\u75c5\u7387\u51fd\u6570\uff08CIFs\uff09\u9884\u6d4b\u7684\u7406\u89e3\u6027\u548c\u51c6\u786e\u6027\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6a21\u578b\u6765\u66f4\u597d\u5730\u6355\u6349\u6570\u636e\u4e2d\u7684\u6a21\u5f0f\u5e76\u8ba9\u6a21\u578b\u7ed3\u679c\u66f4\u6613\u4e8e\u89e3\u8bfb\u3002", "method": "\u901a\u8fc7\u5c06\u6bcf\u4e2a\u6570\u636e\u70b9\u8868\u793a\u4e3a\u4e00\u7ec4\u96c6\u7fa4\u7684\u52a0\u6743\u7ec4\u5408\uff0c\u5e76\u4f7f\u7528\u81ea\u52a8\u5b66\u4e60\u5230\u7684\u6838\u51fd\u6570\u6765\u8861\u91cf\u4efb\u610f\u4e24\u4e2a\u6570\u636e\u70b9\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u6784\u5efa\u4e86DKAJ\u4f30\u8ba1\u5668\u3002\u5982\u679c\u4e00\u4e2a\u6570\u636e\u70b9\u4ec5\u5c5e\u4e8e\u4e00\u4e2a\u96c6\u7fa4\uff0c\u5219\u5176\u9884\u6d4b\u7684CIFs\u5bf9\u5e94\u4e8e\u7ecf\u5178Aalen-Johansen\u4f30\u8ba1\u5668\u5bf9\u8be5\u96c6\u7fa4\u5185\u6570\u636e\u70b9\u7684\u9650\u5236\u3002", "result": "DKAJ\u4f30\u8ba1\u5668\u5728\u56db\u4e2a\u6807\u51c6\u7684\u7ade\u4e89\u98ce\u9669\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u5e76\u4e14\u80fd\u591f\u63d0\u4f9b\u6709\u52a9\u4e8e\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u89c6\u5316\u8f93\u51fa\u3002", "conclusion": "DKAJ\u4f30\u8ba1\u5668\u4e0d\u4ec5\u4fdd\u6301\u4e86\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5176\u6210\u4e3a\u5904\u7406\u7ade\u4e89\u98ce\u9669\u95ee\u9898\u65f6\u7684\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u9009\u62e9\u3002"}}
{"id": "2512.08071", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08071", "abs": "https://arxiv.org/abs/2512.08071", "authors": ["Pingchuan Ma", "Chengshuai Zhao", "Bohan Jiang", "Saketh Vishnubhatla", "Ujun Jeong", "Alimohammad Beigi", "Adrienne Raglin", "Huan Liu"], "title": "CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis Classification", "comment": null, "summary": "Crisis classification in social media aims to extract actionable disaster-related information from multimodal posts, which is a crucial task for enhancing situational awareness and facilitating timely emergency responses. However, the wide variation in crisis types makes achieving generalizable performance across unseen disasters a persistent challenge. Existing approaches primarily leverage deep learning to fuse textual and visual cues for crisis classification, achieving numerically plausible results under in-domain settings. However, they exhibit poor generalization across unseen crisis types because they 1. do not disentangle spurious and causal features, resulting in performance degradation under domain shift, and 2. fail to align heterogeneous modality representations within a shared space, which hinders the direct adaptation of established single-modality domain generalization (DG) techniques to the multimodal setting. To address these issues, we introduce a causality-guided multimodal domain generalization (MMDG) framework that combines adversarial disentanglement with unified representation learning for crisis classification. The adversarial objective encourages the model to disentangle and focus on domain-invariant causal features, leading to more generalizable classifications grounded in stable causal mechanisms. The unified representation aligns features from different modalities within a shared latent space, enabling single-modality DG strategies to be seamlessly extended to multimodal learning. Experiments on the different datasets demonstrate that our approach achieves the best performance in unseen disaster scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u56e0\u679c\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u57df\u6cdb\u5316(MMDG)\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5bf9\u6297\u89e3\u7f20\u4e0e\u7edf\u4e00\u8868\u793a\u5b66\u4e60\uff0c\u4ee5\u89e3\u51b3\u5371\u673a\u5206\u7c7b\u4e2d\u7684\u8de8\u57df\u6cdb\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u672a\u89c1\u8fc7\u7684\u707e\u96be\u573a\u666f\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u7684\u5371\u673a\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6df1\u5ea6\u5b66\u4e60\u6765\u878d\u5408\u6587\u672c\u548c\u89c6\u89c9\u7ebf\u7d22\uff0c\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5371\u673a\u95f4\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\u3002\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a\u5b83\u4eec\u65e0\u6cd5\u533a\u5206\u865a\u5047\u548c\u56e0\u679c\u7279\u5f81\uff0c\u5e76\u4e14\u96be\u4ee5\u5728\u5171\u4eab\u7a7a\u95f4\u5185\u5bf9\u9f50\u5f02\u6784\u6a21\u6001\u8868\u793a\uff0c\u9650\u5236\u4e86\u5355\u6a21\u6001\u57df\u6cdb\u5316\u6280\u672f\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u57df\u6cdb\u5316\uff08MMDG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u89e3\u7f20\u9f13\u52b1\u6a21\u578b\u4e13\u6ce8\u4e8e\u9886\u57df\u4e0d\u53d8\u7684\u56e0\u679c\u7279\u5f81\uff0c\u540c\u65f6\u5229\u7528\u7edf\u4e00\u8868\u793a\u5b66\u4e60\u5c06\u6765\u81ea\u4e0d\u540c\u6a21\u6001\u7684\u7279\u5f81\u5bf9\u9f50\u5230\u4e00\u4e2a\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u5185\uff0c\u4ece\u800c\u4f7f\u5f97\u5355\u6a21\u6001\u57df\u6cdb\u5316\u7b56\u7565\u80fd\u591f\u65e0\u7f1d\u6269\u5c55\u5230\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u9762\u5bf9\u672a\u89c1\u8fc7\u7684\u707e\u96be\u60c5\u51b5\u65f6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u53d6\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u5f15\u5bfc\u7684\u591a\u6a21\u6001\u57df\u6cdb\u5316\u6846\u67b6\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u4e2d\u5371\u673a\u5206\u7c7b\u4efb\u52a1\u5728\u672a\u77e5\u707e\u5bb3\u7c7b\u578b\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.08093", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08093", "abs": "https://arxiv.org/abs/2512.08093", "authors": ["Manas Joglekar", "Jeremy Chen", "Gabriel Wu", "Jason Yosinski", "Jasmine Wang", "Boaz Barak", "Amelia Glaese"], "title": "Training LLMs for Honesty via Confessions", "comment": null, "summary": "Large language models (LLMs) can be dishonest when reporting on their actions and beliefs -- for example, they may overstate their confidence in factual claims or cover up evidence of covert actions. Such dishonesty may arise due to the effects of reinforcement learning (RL), where challenges with reward shaping can result in a training process that inadvertently incentivizes the model to lie or misrepresent its actions.\n  In this work we propose a method for eliciting an honest expression of an LLM's shortcomings via a self-reported *confession*. A confession is an output, provided upon request after a model's original answer, that is meant to serve as a full account of the model's compliance with the letter and spirit of its policies and instructions. The reward assigned to a confession during training is solely based on its honesty, and does not impact positively or negatively the main answer's reward. As long as the \"path of least resistance\" for maximizing confession reward is to surface misbehavior rather than covering it up, this incentivizes models to be honest in their confessions. Our findings provide some justification this empirical assumption, especially in the case of egregious model misbehavior.\n  To demonstrate the viability of our approach, we train GPT-5-Thinking to produce confessions, and we evaluate its honesty in out-of-distribution scenarios measuring hallucination, instruction following, scheming, and reward hacking. We find that when the model lies or omits shortcomings in its \"main\" answer, it often confesses to these behaviors honestly, and this confession honesty modestly improves with training. Confessions can enable a number of inference-time interventions including monitoring, rejection sampling, and surfacing issues to the user.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bf7\u6c42\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7ed9\u51fa\u521d\u59cb\u56de\u7b54\u540e\u63d0\u4f9b\u4e00\u79cd\u81ea\u6211\u62a5\u544a\u5f0f\u7684\u201c\u5fcf\u6094\u201d\uff0c\u4ee5\u8bda\u5b9e\u5730\u8868\u8fbe\u5176\u4e0d\u8db3\u4e4b\u5904\u3002\u8fd9\u79cd\u5fcf\u6094\u7684\u5956\u52b1\u4ec5\u57fa\u4e8e\u5176\u8bda\u5b9e\u6027\uff0c\u5e76\u4e0d\u6b63\u9762\u6216\u8d1f\u9762\u5730\u5f71\u54cd\u4e3b\u8981\u7b54\u6848\u7684\u5956\u52b1\u3002\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u8bc6\u522b\u6a21\u578b\u9519\u8bef\u884c\u4e3a\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e14\u6307\u51fa\u5fcf\u6094\u673a\u5236\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u51fa\u9519\u65f6\u7684\u8bda\u5b9e\u5ea6\uff0c\u4ece\u800c\u652f\u6301\u76d1\u63a7\u3001\u62d2\u7edd\u91c7\u6837\u4ee5\u53ca\u5411\u7528\u6237\u5c55\u793a\u95ee\u9898\u7b49\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u7531\u4e8e\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5956\u52b1\u5851\u9020\u7684\u6311\u6218\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u65e0\u610f\u4e2d\u6fc0\u52b1\u6a21\u578b\u6492\u8c0e\u6216\u6b6a\u66f2\u5176\u884c\u4e3a\uff0c\u6587\u7ae0\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u8bda\u5b9e\u5730\u62a5\u544a\u5b83\u4eec\u7684\u884c\u4e3a\u548c\u4fe1\u5ff5\u4e0a\u7684\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5fcf\u6094\u201d\u7684\u81ea\u62a5\u544a\u673a\u5236\uff0c\u8be5\u673a\u5236\u8981\u6c42\u6a21\u578b\u5728\u5176\u539f\u59cb\u54cd\u5e94\u4e4b\u540e\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u8bf4\u660e\u5176\u9075\u5b88\u653f\u7b56\u548c\u6307\u4ee4\u60c5\u51b5\u7684\u8f93\u51fa\u3002\u5bf9\u5fcf\u6094\u5185\u5bb9\u7684\u8bc4\u4ef7\u4ec5\u4ee5\u5176\u8bda\u5b9e\u6027\u4e3a\u4f9d\u636e\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u5f71\u54cd\u5230\u4e3b\u56de\u7b54\u6240\u83b7\u5f97\u7684\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53GPT-5-Thinking\u6a21\u578b\u5728\u201c\u4e3b\u201d\u56de\u7b54\u4e2d\u6492\u8c0e\u6216\u9057\u6f0f\u7f3a\u70b9\u65f6\uff0c\u5b83\u5f80\u5f80\u4f1a\u8bda\u5b9e\u5730\u627f\u8ba4\u8fd9\u4e9b\u884c\u4e3a\uff0c\u5e76\u4e14\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u8fd9\u79cd\u8bda\u5b9e\u5ea6\u6709\u6240\u63d0\u9ad8\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u2018\u5fcf\u6094\u2019\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u9f13\u52b1\u6a21\u578b\u66f4\u52a0\u8bda\u5b9e\u5730\u62a5\u544a\u81ea\u8eab\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u6539\u5584\u6a21\u578b\u884c\u4e3a\u3001\u63d0\u9ad8\u900f\u660e\u5ea6\u53ca\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.08108", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08108", "abs": "https://arxiv.org/abs/2512.08108", "authors": ["Kwanyoung Park", "Seohong Park", "Youngwoon Lee", "Sergey Levine"], "title": "Scalable Offline Model-Based RL with Action Chunks", "comment": "22 pages, 7 figures", "summary": "In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \\emph{action-chunk} model that predicts a future state from a sequence of actions (an \"action chunk\") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \\textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u6a21\u578b\u7684\u4ef7\u503c\u6269\u5c55\uff0c\u662f\u5426\u53ef\u4ee5\u4e3a\u89e3\u51b3\u79bb\u7ebfRL\u4e2d\u590d\u6742\u3001\u957f\u671f\u7684\u4efb\u52a1\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u52a8\u4f5c\u5757\u6a21\u578b\u548c\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\u6765\u51cf\u5c11\u7d2f\u79ef\u8bef\u5dee\u5e76\u9632\u6b62\u6a21\u578b\u5229\u7528\u5206\u5e03\u5916\u7684\u52a8\u4f5c\uff0c\u4ece\u800c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMAC\u7684\u65b0\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMAC\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u957f\u671f\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u80fd\u5426\u6709\u6548\u89e3\u51b3\u79bb\u7ebfRL\u4e2d\u7684\u590d\u6742\u4e14\u65f6\u95f4\u8de8\u5ea6\u957f\u7684\u4efb\u52a1\u95ee\u9898\uff0c\u5e76\u9488\u5bf9\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u7684\u504f\u5dee\u4e0e\u7d2f\u79ef\u8bef\u5dee\u95ee\u9898\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u4f5c\u5757\uff08action-chunk\uff09\u6a21\u578b\u7528\u4e8e\u4ece\u4e00\u7cfb\u5217\u52a8\u4f5c\u9884\u6d4b\u672a\u6765\u72b6\u6001\uff0c\u4ee5\u6b64\u51cf\u5c11\u7d2f\u79ef\u8bef\u5dee\uff1b\u540c\u65f6\u91c7\u7528\u6765\u81ea\u8868\u8fbe\u6027\u884c\u4e3a\u52a8\u4f5c\u5757\u7b56\u7565\u7684\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\uff0c\u907f\u514d\u56e0\u91c7\u53d6\u5206\u5e03\u5916\u52a8\u4f5c\u800c\u5bf9\u6a21\u578b\u9020\u6210\u5229\u7528\u3002\u8be5\u65b9\u6cd5\u88ab\u79f0\u4e3a\u57fa\u4e8e\u6a21\u578b\u7684\u5e26\u6709\u52a8\u4f5c\u5757\u7684\u5f3a\u5316\u5b66\u4e60\uff08MAC\uff09\u3002", "result": "\u5728\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff08\u9ad8\u8fbe1\u4ebf\u6b21\u8f6c\u6362\uff09\u8fdb\u884c\u7684\u9ad8\u5ea6\u6311\u6218\u6027\u4efb\u52a1\u6d4b\u8bd5\u4e2d\uff0cMAC\u76f8\u8f83\u4e8e\u5176\u4ed6\u79bb\u7ebf\u57fa\u4e8e\u6a21\u578b\u7684RL\u7b97\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u56f0\u96be\u7684\u957f\u671f\u4efb\u52a1\u65f6\u3002", "conclusion": "\u57fa\u4e8e\u6a21\u578b\u7684\u4ef7\u503c\u6269\u5c55\u7ed3\u5408\u52a8\u4f5c\u5757\u6a21\u578b\u53ca\u62d2\u7edd\u91c7\u6837\u6280\u672f\u5f62\u6210\u7684MAC\u65b9\u6cd5\uff0c\u5728\u5e94\u5bf9\u590d\u6742\u7684\u957f\u671f\u4efb\u52a1\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u79bb\u7ebfRL\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.08121", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08121", "abs": "https://arxiv.org/abs/2512.08121", "authors": ["Stephane Collot", "Colin Fraser", "Justin Zhao", "William F. Shen", "Timon Willi", "Ilias Leontiadis"], "title": "Balanced Accuracy: The Right Metric for Evaluating LLM Judges - Explained through Youden's J statistic", "comment": "9 pages, 5 figures", "summary": "Rigorous evaluation of large language models (LLMs) relies on comparing models by the prevalence of desirable or undesirable behaviors, such as task pass rates or policy violations. These prevalence estimates are produced by a classifier, either an LLM-as-a-judge or human annotators, making the choice of classifier central to trustworthy evaluation. Common metrics used for this choice, such as Accuracy, Precision, and F1, are sensitive to class imbalance and to arbitrary choices of positive class, and can favor judges that distort prevalence estimates. We show that Youden's $J$ statistic is theoretically aligned with choosing the best judge to compare models, and that Balanced Accuracy is an equivalent linear transformation of $J$. Through both analytical arguments and empirical examples and simulations, we demonstrate how selecting judges using Balanced Accuracy leads to better, more robust classifier selection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528Youden\u7684J\u7edf\u8ba1\u91cf\u548c\u5e73\u8861\u51c6\u786e\u7387\u4f5c\u4e3a\u9009\u62e9\u6700\u4f73\u8bc4\u4f30\u8005\uff08\u5206\u7c7b\u5668\uff09\u6765\u6bd4\u8f83\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6807\uff0c\u8fd9\u4e9b\u6307\u6807\u5728\u7406\u8bba\u4e0a\u66f4\u9002\u5408\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\u4e86\u5b83\u4eec\u80fd\u591f\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u5206\u7c7b\u5668\u9009\u62e9\u3002", "motivation": "\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e25\u683c\u8bc4\u4f30\u4f9d\u8d56\u4e8e\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u826f\u597d\u6216\u4e0d\u826f\u884c\u4e3a\u7684\u53d1\u751f\u7387\uff0c\u800c\u8fd9\u4e9b\u53d1\u751f\u7387\u4f30\u8ba1\u503c\u662f\u7531\u4e00\u4e2a\u5206\u7c7b\u5668\u4ea7\u751f\u7684\u3002\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\u5982\u51c6\u786e\u7387\u3001\u7cbe\u786e\u5ea6\u548cF1\u5206\u6570\u5bf9\u7c7b\u522b\u4e0d\u5e73\u8861\u654f\u611f\u4e14\u53ef\u80fd\u53d7\u5230\u6b63\u7c7b\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u504f\u5411\u4e8e\u626d\u66f2\u5b9e\u9645\u53d1\u751f\u7387\u7684\u8bc4\u5224\u8005\u3002\u56e0\u6b64\uff0c\u9700\u8981\u627e\u5230\u4e00\u79cd\u66f4\u52a0\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u5408\u9002\u7684\u8bc4\u5224\u8005\u4ee5\u786e\u4fdd\u8bc4\u4f30\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86Youden\u7684J\u7edf\u8ba1\u91cf\u4f5c\u4e3a\u7406\u8bba\u4f9d\u636e\uff0c\u7528\u6765\u786e\u5b9a\u6700\u4f73\u8bc4\u5224\u8005\u7684\u9009\u62e9\u6807\u51c6\uff0c\u5e76\u6307\u51fa\u5e73\u8861\u51c6\u786e\u7387\u662fJ\u7edf\u8ba1\u91cf\u7684\u4e00\u4e2a\u7b49\u4ef7\u7ebf\u6027\u53d8\u6362\u5f62\u5f0f\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u4f8b\u6a21\u62df\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u5e73\u8861\u51c6\u786e\u7387\u6311\u9009\u8bc4\u5224\u8005\u53ef\u4ee5\u5e26\u6765\u66f4\u597d\u7684\u5206\u7c7b\u6548\u679c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u5e73\u8861\u51c6\u786e\u7387\u4f5c\u4e3a\u8bc4\u5224\u8005\u9009\u62e9\u7684\u6807\u51c6\uff0c\u786e\u5b9e\u80fd\u591f\u5b9e\u73b0\u66f4\u4f18\u4e14\u66f4\u7a33\u5b9a\u7684\u5206\u7c7b\u5668\u9009\u53d6\u7ed3\u679c\u3002", "conclusion": "\u91c7\u7528Youden\u7684J\u7edf\u8ba1\u91cf\u53ca\u4e0e\u5176\u7b49\u6548\u7684\u5e73\u8861\u51c6\u786e\u7387\u4f5c\u4e3a\u8bc4\u5224\u6807\u51c6\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u95f4\u5bf9\u6bd4\u8bc4\u4f30\u65f6\u6240\u9009\u8bc4\u5224\u8005\u7684\u8d28\u91cf\uff0c\u8fdb\u800c\u63d0\u5347\u6574\u4e2a\u8bc4\u4f30\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.08129", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08129", "abs": "https://arxiv.org/abs/2512.08129", "authors": ["Guangmingmei Yang", "David J. Miller", "George Kesidis"], "title": "Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization", "comment": null, "summary": "Most post-training backdoor detection methods rely on attacked models exhibiting extreme outlier detection statistics for the target class of an attack, compared to non-target classes. However, these approaches may fail: (1) when some (non-target) classes are easily discriminable from all others, in which case they may naturally achieve extreme detection statistics (e.g., decision confidence); and (2) when the backdoor is subtle, i.e., with its features weak relative to intrinsic class-discriminative features. A key observation is that the backdoor target class has contributions to its detection statistic from both the backdoor trigger and from its intrinsic features, whereas non-target classes only have contributions from their intrinsic features. To achieve more sensitive detectors, we thus propose to suppress intrinsic features while optimizing the detection statistic for a given class. For non-target classes, such suppression will drastically reduce the achievable statistic, whereas for the target class the (significant) contribution from the backdoor trigger remains. In practice, we formulate a constrained optimization problem, leveraging a small set of clean examples from a given class, and optimizing the detection statistic while orthogonalizing with respect to the class's intrinsic features. We dub this plug-and-play approach Class Subspace Orthogonalization (CSO) and assess it against challenging mixed-label and adaptive attacks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7c7b\u5b50\u7a7a\u95f4\u6b63\u4ea4\u5316\uff08CSO\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6291\u5236\u56fa\u6709\u7279\u5f81\u540c\u65f6\u4f18\u5316\u7ed9\u5b9a\u7c7b\u522b\u7684\u68c0\u6d4b\u7edf\u8ba1\u91cf\uff0c\u4ee5\u63d0\u9ad8\u540e\u95e8\u68c0\u6d4b\u7684\u654f\u611f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u8bad\u7ec3\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\u5728\u67d0\u4e9b\u975e\u76ee\u6807\u7c7b\u522b\u5bb9\u6613\u4e0e\u6240\u6709\u5176\u4ed6\u7c7b\u522b\u533a\u5206\u65f6\u53ef\u80fd\u4f1a\u5931\u8d25\uff0c\u6216\u8005\u5f53\u540e\u95e8\u662f\u5fae\u5999\u4e14\u5176\u7279\u5f81\u76f8\u5bf9\u4e8e\u5185\u5728\u7c7b\u522b\u533a\u5206\u7279\u5f81\u8f83\u5f31\u65f6\u4e5f\u4f1a\u5931\u6548\u3002", "method": "\u901a\u8fc7\u5236\u5b9a\u4e00\u4e2a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u7ed9\u5b9a\u7c7b\u522b\u7684\u5c11\u91cf\u5e72\u51c0\u6837\u672c\uff0c\u540c\u65f6\u5728\u4f18\u5316\u68c0\u6d4b\u7edf\u8ba1\u91cf\u65f6\u5bf9\u7c7b\u522b\u7684\u5185\u5728\u7279\u5f81\u8fdb\u884c\u6b63\u4ea4\u5316\u5904\u7406\u3002", "result": "\u5bf9\u4e8e\u975e\u76ee\u6807\u7c7b\u522b\uff0c\u8fd9\u79cd\u6291\u5236\u4f1a\u663e\u8457\u964d\u4f4e\u53ef\u8fbe\u5230\u7684\u7edf\u8ba1\u91cf\uff1b\u800c\u5bf9\u4e8e\u76ee\u6807\u7c7b\u522b\uff0c\u6765\u81ea\u540e\u95e8\u89e6\u53d1\u5668\u7684\uff08\u663e\u8457\uff09\u8d21\u732e\u4ecd\u7136\u5b58\u5728\u3002\u8be5\u65b9\u6cd5\u88ab\u547d\u540d\u4e3a\u7c7b\u5b50\u7a7a\u95f4\u6b63\u4ea4\u5316\uff08CSO\uff09\uff0c\u5e76\u9488\u5bf9\u6df7\u5408\u6807\u7b7e\u548c\u81ea\u9002\u5e94\u653b\u51fb\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "CSO\u65b9\u6cd5\u4e3a\u89e3\u51b3\u73b0\u6709\u540e\u95e8\u68c0\u6d4b\u6280\u672f\u4e2d\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u654f\u611f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5fae\u5999\u540e\u95e8\u6216\u7279\u5b9a\u6761\u4ef6\u4e0b\u81ea\u7136\u8868\u73b0\u51fa\u6781\u7aef\u68c0\u6d4b\u7edf\u8ba1\u6570\u636e\u7684\u975e\u76ee\u6807\u7c7b\u522b\u65f6\u3002"}}
{"id": "2512.08130", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.08130", "abs": "https://arxiv.org/abs/2512.08130", "authors": ["Gary Ackerman", "Brandon Behlendorf", "Zachary Kallenborn", "Sheriff Almakki", "Doug Clifford", "Jenna LaTourette", "Hayley Peterson", "Noah Sheinbaum", "Olivia Shoemaker", "Anna Wetzel"], "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models I: The Task-Query Architecture", "comment": "18 pages", "summary": "Both model developers and policymakers seek to quantify and mitigate the risk of rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons. An important element of such efforts is the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper describes the first component of a novel Biothreat Benchmark Generation (BBG) Framework. The BBG approach is designed to help model developers and evaluators reliably measure and assess the biosecurity risk uplift and general harm potential of existing and future AI models, while accounting for key aspects of the threat itself that are often overlooked in other benchmarking efforts, including different actor capability levels, and operational (in addition to purely technical) risk factors. As a pilot, the BBG is first being developed to address bacterial biological threats only. The BBG is built upon a hierarchical structure of biothreat categories, elements and tasks, which then serves as the basis for the development of task-aligned queries. This paper outlines the development of this biothreat task-query architecture, which we have named the Bacterial Biothreat Schema, while future papers will describe follow-on efforts to turn queries into model prompts, as well as how the resulting benchmarks can be implemented for model evaluation. Overall, the BBG Framework, including the Bacterial Biothreat Schema, seeks to offer a robust, re-usable structure for evaluating bacterial biological risks arising from LLMs across multiple levels of aggregation, which captures the full scope of technical and operational requirements for biological adversaries, and which accounts for a wide spectrum of biological adversary capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aBiothreat Benchmark Generation (BBG) Framework\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u5e2e\u52a9\u6a21\u578b\u5f00\u53d1\u8005\u548c\u8bc4\u4f30\u8005\u53ef\u9760\u5730\u6d4b\u91cf\u548c\u8bc4\u4f30\u73b0\u6709\u53ca\u672a\u6765AI\u6a21\u578b\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\u3002\u8be5\u6846\u67b6\u9996\u5148\u9488\u5bf9\u7ec6\u83cc\u751f\u7269\u5a01\u80c1\u8fdb\u884c\u5f00\u53d1\uff0c\u5e76\u57fa\u4e8e\u751f\u7269\u5a01\u80c1\u7c7b\u522b\u3001\u5143\u7d20\u548c\u4efb\u52a1\u7684\u5206\u5c42\u7ed3\u6784\u6765\u6784\u5efa\u4efb\u52a1\u67e5\u8be2\u67b6\u6784\uff0c\u5373Bacterial Biothreat Schema\u3002", "motivation": "\u4e3a\u4e86\u91cf\u5316\u5e76\u51cf\u8f7b\u524d\u6cbf\u4eba\u5de5\u667a\u80fd\uff08\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u53ef\u80fd\u5e26\u6765\u7684\u751f\u7269\u6050\u6016\u4e3b\u4e49\u6216\u751f\u7269\u6b66\u5668\u83b7\u53d6\u7684\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30\u7279\u5b9a\u6a21\u578b\u751f\u7269\u5b89\u5168\u98ce\u9669\u7684\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86Biothreat Benchmark Generation (BBG) Framework\u7684\u7b2c\u4e00\u4e2a\u7ec4\u6210\u90e8\u5206\u2014\u2014Bacterial Biothreat Schema\uff0c\u5b83\u57fa\u4e8e\u751f\u7269\u5a01\u80c1\u7c7b\u522b\u3001\u5143\u7d20\u548c\u4efb\u52a1\u7684\u5206\u5c42\u7ed3\u6784\u6765\u751f\u6210\u4e0e\u4efb\u52a1\u5bf9\u9f50\u7684\u67e5\u8be2\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u7528\u4e8e\u8861\u91cf\u7531AI\u6a21\u578b\u5f15\u53d1\u7684\u7ec6\u83cc\u751f\u7269\u5a01\u80c1\u98ce\u9669\uff0c\u8be5\u6846\u67b6\u8003\u8651\u5230\u4e86\u4e0d\u540c\u884c\u52a8\u8005\u7684\u80fd\u529b\u6c34\u5e73\u4ee5\u53ca\u64cd\u4f5c\u548c\u6280\u672f\u4e0a\u7684\u98ce\u9669\u56e0\u7d20\u3002", "conclusion": "BBG\u6846\u67b6\u53ca\u5176\u7ec4\u6210\u90e8\u5206Bacterial Biothreat Schema\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u4e14\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u7ed3\u6784\uff0c\u7528\u4ee5\u8bc4\u4f30\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f15\u8d77\u7684\u7ec6\u83cc\u751f\u7269\u98ce\u9669\uff0c\u6db5\u76d6\u4e86\u751f\u7269\u5bf9\u624b\u7684\u6280\u672f\u548c\u64cd\u4f5c\u8981\u6c42\uff0c\u5e76\u8003\u8651\u5230\u4e86\u5e7f\u6cdb\u7684\u751f\u7269\u5bf9\u624b\u80fd\u529b\u8303\u56f4\u3002"}}
{"id": "2512.08143", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08143", "abs": "https://arxiv.org/abs/2512.08143", "authors": ["Ali Lotfi Rezaabad", "Bikram Khanal", "Shashwat Chaurasia", "Lu Zeng", "Dezhi Hong", "Hossein Beshashati", "Thomas Butler", "Megan Ganji"], "title": "PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection", "comment": null, "summary": "Language identification is a crucial first step in multilingual systems such as chatbots and virtual assistants, enabling linguistically and culturally accurate user experiences. Errors at this stage can cascade into downstream failures, setting a high bar for accuracy. Yet, existing language identification tools struggle with key cases--such as music requests where the song title and user language differ. Open-source tools like LangDetect, FastText are fast but less accurate, while large language models, though effective, are often too costly for low-latency or low-resource settings. We introduce PolyLingua, a lightweight Transformer-based model for in-domain language detection and fine-grained language classification. It employs a two-level contrastive learning framework combining instance-level separation and class-level alignment with adaptive margins, yielding compact and well-separated embeddings even for closely related languages. Evaluated on two challenging datasets--Amazon Massive (multilingual digital assistant utterances) and a Song dataset (music requests with frequent code-switching)--PolyLingua achieves 99.25% F1 and 98.15% F1, respectively, surpassing Sonnet 3.5 while using 10x fewer parameters, making it ideal for compute- and latency-constrained environments.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86PolyLingua\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u8bc6\u522b\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u9886\u57df\u5185\u8bed\u8a00\u68c0\u6d4b\u548c\u7ec6\u7c92\u5ea6\u8bed\u8a00\u5206\u7c7b\u3002\u5b83\u5728\u4e24\u4e2a\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u6bd4Sonnet 3.5\u5c1110\u500d\u7684\u53c2\u6570\uff0c\u975e\u5e38\u9002\u5408\u8ba1\u7b97\u548c\u5ef6\u8fdf\u53d7\u9650\u7684\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u8bc6\u522b\u5de5\u5177\u5728\u5904\u7406\u5982\u97f3\u4e50\u8bf7\u6c42\u7b49\u5173\u952e\u60c5\u51b5\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5f00\u6e90\u5de5\u5177\u901f\u5ea6\u5feb\u4f46\u51c6\u786e\u6027\u8f83\u4f4e\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6709\u6548\u4f46\u6210\u672c\u9ad8\u6602\u3002\u4e3a\u4e86\u63d0\u9ad8\u591a\u8bed\u8a00\u7cfb\u7edf\u4e2d\u7684\u8bed\u8a00\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u5e76\u9002\u5e94\u4f4e\u5ef6\u8fdf\u6216\u8d44\u6e90\u6709\u9650\u7684\u573a\u666f\uff0c\u63d0\u51fa\u4e86PolyLingua\u3002", "method": "PolyLingua\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u5c42\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u5b9e\u4f8b\u7ea7\u5206\u79bb\u4e0e\u7c7b\u7ea7\u522b\u5bf9\u9f50\u53ca\u81ea\u9002\u5e94\u8fb9\u7f18\u6280\u672f\uff0c\u65e8\u5728\u5373\u4f7f\u5bf9\u4e8e\u7d27\u5bc6\u76f8\u5173\u7684\u8bed\u8a00\u4e5f\u80fd\u4ea7\u751f\u7d27\u51d1\u4e14\u826f\u597d\u533a\u5206\u7684\u5d4c\u5165\u8868\u793a\u3002", "result": "\u5728Amazon Massive\uff08\u591a\u8bed\u8a00\u6570\u5b57\u52a9\u7406\u8bdd\u8bed\uff09\u548cSong\u6570\u636e\u96c6\uff08\u542b\u6709\u9891\u7e41\u4ee3\u7801\u5207\u6362\u7684\u97f3\u4e50\u8bf7\u6c42\uff09\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cPolyLingua\u5206\u522b\u8fbe\u5230\u4e8699.25%\u548c98.15%\u7684F1\u5206\u6570\uff0c\u8d85\u8fc7\u4e86Sonnet 3.5\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4f7f\u7528\u7684\u53c2\u6570\u91cf\u4ec5\u4e3a\u540e\u8005\u7684\u5341\u5206\u4e4b\u4e00\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165PolyLingua\uff0c\u8be5\u7814\u7a76\u4e3a\u591a\u8bed\u8a00\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u51c6\u786e\u7684\u8bed\u8a00\u8bc6\u522b\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u5408\u4e8e\u90a3\u4e9b\u9700\u8981\u5feb\u901f\u54cd\u5e94\u5e76\u4e14\u8d44\u6e90\u6709\u9650\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.08153", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.08153", "abs": "https://arxiv.org/abs/2512.08153", "authors": ["Zheng Ding", "Weirui Ye"], "title": "TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models", "comment": null, "summary": "Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \\textbf{TreeGRPO}, a novel RL framework that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategically branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advantages: (1) \\emph{High sample efficiency}, achieving better performance under same training samples (2) \\emph{Fine-grained credit assignment} via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) \\emph{Amortized computation} where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves \\textbf{2.4$\\times$ faster training} while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6TreeGRPO\uff0c\u901a\u8fc7\u5c06\u53bb\u566a\u8fc7\u7a0b\u91cd\u5851\u4e3a\u641c\u7d22\u6811\u6765\u5927\u5e45\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u8bad\u7ec3\u6837\u672c\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3001\u7ec6\u7c92\u5ea6\u7684\u5956\u52b1\u5206\u914d\u4ee5\u53ca\u644a\u9500\u8ba1\u7b97\uff0c\u4f7f\u5f97\u57fa\u4e8eRL\u7684\u89c6\u89c9\u751f\u6210\u6a21\u578b\u5bf9\u9f50\u66f4\u52a0\u9ad8\u6548\u548c\u53ef\u6269\u5c55\u3002\u5b9e\u9a8c\u663e\u793aTreeGRPO\u6bd4GRPO\u57fa\u7ebf\u5feb2.4\u500d\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5bf9\u4e8e\u8c03\u6574\u751f\u6210\u6a21\u578b\u4ee5\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u963b\u788d\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86TreeGRPO\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5c06\u53bb\u566a\u8fc7\u7a0b\u91cd\u65b0\u6784\u60f3\u4e3a\u4e00\u68f5\u641c\u7d22\u6811\u3002\u4ece\u5171\u4eab\u521d\u59cb\u566a\u58f0\u6837\u672c\u5f00\u59cb\uff0cTreeGRPO\u80fd\u591f\u7b56\u7565\u6027\u5730\u5206\u652f\u51fa\u591a\u6761\u5019\u9009\u8f68\u8ff9\uff0c\u5e76\u6709\u6548\u590d\u7528\u5b83\u4eec\u5171\u6709\u7684\u524d\u7f00\u90e8\u5206\u3002\u8fd9\u79cd\u65b9\u6cd5\u5e26\u6765\u4e86\u4e09\u4e2a\u4e3b\u8981\u4f18\u52bf\uff1a\u9ad8\u6837\u672c\u6548\u7387\u3001\u7ec6\u7c92\u5ea6\u7684\u4fe1\u7528\u5206\u914d\u4ee5\u53ca\u901a\u8fc7\u591a\u5b50\u5206\u652f\u5b9e\u73b0\u7684\u644a\u9500\u8ba1\u7b97\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e0eGRPO\u57fa\u7ebf\u76f8\u6bd4\uff0cTreeGRPO\u5728\u6269\u6563\u6a21\u578b\u548c\u6d41\u5f0f\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e862.4\u500d\u66f4\u5feb\u7684\u8bad\u7ec3\u901f\u5ea6\uff0c\u5e76\u4e14\u5728\u6548\u7387-\u56de\u62a5\u6743\u8861\u7a7a\u95f4\u5185\u5efa\u7acb\u4e86\u66f4\u4f18\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002\u6b64\u5916\uff0cTreeGRPO\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u53ca\u5956\u52b1\u6a21\u578b\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "TreeGRPO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u9014\u5f84\uff0c\u7528\u4e8e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89c6\u89c9\u751f\u6210\u6a21\u578b\u5bf9\u9f50\uff0c\u901a\u8fc7\u5f15\u5165\u6811\u7ed3\u6784\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2512.08160", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.08160", "abs": "https://arxiv.org/abs/2512.08160", "authors": ["Nanda K. Unnikrishnan", "Keshab K. Parhi"], "title": "LayerPipe2: Multistage Pipelining and Weight Recompute via Improved Exponential Moving Average for Training Neural Networks", "comment": "Proc. of 2025 Asilomar Conference on Signals, Systems, and Computers, October 2025, Pacific Grove, CA", "summary": "In our prior work, LayerPipe, we had introduced an approach to accelerate training of convolutional, fully connected, and spiking neural networks by overlapping forward and backward computation. However, despite empirical success, a principled understanding of how much gradient delay needs to be introduced at each layer to achieve desired level of pipelining was not addressed. This paper, LayerPipe2, fills that gap by formally deriving LayerPipe using variable delayed gradient adaptation and retiming. We identify where delays may be legally inserted and show that the required amount of delay follows directly from the network structure where inner layers require fewer delays and outer layers require longer delays. When pipelining is applied at every layer, the amount of delay depends only on the number of remaining downstream stages. When layers are pipelined in groups, all layers in the group share the same assignment of delays. These insights not only explain previously observed scheduling patterns but also expose an often overlooked challenge that pipelining implicitly requires storage of historical weights. We overcome this storage bottleneck by developing a pipeline--aware moving average that reconstructs the required past states rather than storing them explicitly. This reduces memory cost without sacrificing the accuracy guarantees that makes pipelined learning viable. The result is a principled framework that illustrates how to construct LayerPipe architectures, predicts their delay requirements, and mitigates their storage burden, thereby enabling scalable pipelined training with controlled communication computation tradeoffs.", "AI": {"tldr": "LayerPipe2 provides a formal derivation for the LayerPipe approach, offering insights into gradient delay requirements and proposing a pipeline-aware moving average to reduce memory costs, thus enabling efficient pipelined training of neural networks.", "motivation": "The motivation is to provide a principled understanding of the gradient delay needed at each layer for effective pipelining in neural network training, addressing an unexplored aspect from their prior work, LayerPipe, and to tackle the storage issue that arises with pipelining.", "method": "The method involves formally deriving the LayerPipe technique using variable delayed gradient adaptation and retiming, identifying legal points for inserting delays, and developing a pipeline-aware moving average to manage the storage of historical weights without compromising accuracy.", "result": "The results show that inner layers require fewer delays, while outer layers need longer delays. The paper also presents a solution to the storage bottleneck through a pipeline-aware moving average, which reduces memory cost without sacrificing accuracy, allowing for scalable pipelined training.", "conclusion": "LayerPipe2 offers a framework that clarifies how to design LayerPipe architectures, forecasts delay requirements, and eases the storage challenge, supporting scalable pipelined training with managed trade-offs between communication and computation."}}
{"id": "2512.08211", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08211", "abs": "https://arxiv.org/abs/2512.08211", "authors": ["Jiaxiang Geng", "Lunyu Zhao", "Yiyi Lu", "Bing Luo"], "title": "MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones", "comment": "15 pages, 9 figures, submitted to Mobisys 2026", "summary": "Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MobileFineTuner\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u80fd\u591f\u5728\u666e\u901a\u624b\u673a\u4e0a\u76f4\u63a5\u8fdb\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7aef\u5230\u7aef\u5fae\u8c03\u3002\u5b83\u901a\u8fc7\u53c2\u6570\u5206\u7247\u3001\u68af\u5ea6\u7d2f\u79ef\u548c\u80fd\u8017\u611f\u77e5\u8ba1\u7b97\u8c03\u5ea6\u7b49\u7cfb\u7edf\u7ea7\u4f18\u5316\u89e3\u51b3\u4e86\u624b\u673a\u5185\u5b58\u548c\u80fd\u6e90\u9650\u5236\u7684\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u624b\u673a\u4e0a\u6210\u529f\u5bf9GPT-2, Gemma 3, \u548cQwen 2.5\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "motivation": "\u968f\u7740\u9ad8\u8d28\u91cf\u516c\u5171\u6570\u636e\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9010\u6e10\u8017\u5c3d\uff0c\u5728\u8bbe\u5907\u4e0a\u8fdb\u884c\u5fae\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5229\u7528\u79c1\u4eba\u7528\u6237\u6570\u636e\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u7684\u673a\u4f1a\u3002\u4f46\u76ee\u524d\u7684\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6a21\u62df\u6216\u4f9d\u8d56\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u548c\u4e2a\u4eba\u7535\u8111\uff0c\u5f88\u5c11\u63a2\u7d22\u666e\u901a\u624b\u673a\u7684\u5e94\u7528\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u591f\u5b9e\u73b0\u5728\u624b\u673a\u4e0a\u5b9e\u9645\u8fdb\u884cLLM\u5fae\u8c03\u7684\u5f00\u6e90\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86MobileFineTuner\uff0c\u8fd9\u662f\u4e00\u4e2a\u652f\u6301\u5168\u53c2\u6570\u5fae\u8c03\uff08Full-FT\uff09\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u7684\u7edf\u4e00\u5f00\u6e90\u6846\u67b6\u3002\u4e3a\u89e3\u51b3\u624b\u673a\u56fa\u6709\u7684\u5185\u5b58\u4e0e\u80fd\u91cf\u9650\u5236\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u5305\u62ec\u53c2\u6570\u5206\u7247\u3001\u68af\u5ea6\u7d2f\u79ef\u4ee5\u53ca\u80fd\u8017\u611f\u77e5\u8ba1\u7b97\u8c03\u5ea6\u5728\u5185\u7684\u7cfb\u7edf\u7ea7\u522b\u4f18\u5316\u63aa\u65bd\u3002", "result": "\u901a\u8fc7\u5728\u771f\u5b9e\u624b\u673a\u4e0a\u5bf9GPT-2, Gemma 3, \u548cQwen 2.5\u8fdb\u884c\u5fae\u8c03\u5c55\u793a\u4e86MobileFineTuner\u7684\u5b9e\u7528\u6027\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\u6240\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u786e\u7acb\u4e86MobileFineTuner\u4f5c\u4e3a\u672a\u6765\u5173\u4e8e\u8bbe\u5907\u4e0aLLM\u8bad\u7ec3\u7814\u7a76\u53ef\u884c\u57fa\u7840\u7684\u5730\u4f4d\u3002", "conclusion": "MobileFineTuner\u4f5c\u4e3a\u4e00\u4e2a\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u586b\u8865\u4e86\u5e02\u573a\u4e0a\u7a7a\u767d\uff0c\u4f7f\u5f97\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u5982\u79fb\u52a8\u7535\u8bdd\u4e2d\u4e5f\u80fd\u6709\u6548\u5730\u6267\u884c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u5de5\u4f5c\u3002"}}
{"id": "2512.08217", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08217", "abs": "https://arxiv.org/abs/2512.08217", "authors": ["Jason Chuan-Chih Chou"], "title": "Correction of Decoupled Weight Decay", "comment": null, "summary": "Decoupled weight decay, solely responsible for the performance advantage of AdamW over Adam, has long been set to proportional to learning rate $\u03b3$ without questioning. Some researchers have recently challenged such assumption and argued that decoupled weight decay should be set $\\propto \u03b3^2$ instead based on orthogonality arguments at steady state. To the contrary, we find that eliminating the contribution of the perpendicular component of the update to the weight norm leads to little change to the training dynamics. Instead, we derive that decoupled weight decay $\\propto \u03b3^2$ results in stable weight norm based on the simple assumption that updates become independent of the weights at steady state, regardless of the nature of the optimizer. Based on the same assumption, we derive and empirically verify that the Total Update Contribution (TUC) of a minibatch under the Scion optimizer is better characterized by the momentum-dependent effective learning rate whose optimal value transfers and we show that decoupled weight decay $\\propto \u03b3^2$ leads to stable weight and gradient norms and allows us to better control the training dynamics and improve the model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u53bb\u8026\u6743\u91cd\u8870\u51cf\uff08decoupled weight decay\uff09\u4e0e\u5b66\u4e60\u7387\u03b3\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u53bb\u8026\u6743\u91cd\u8870\u51cf\u5e94\u6b63\u6bd4\u4e8e\u03b3^2\u7684\u89c2\u70b9\uff0c\u800c\u975e\u4f20\u7edf\u7684\u6b63\u6bd4\u4e8e\u03b3\u3002\u901a\u8fc7\u5206\u6790\u66f4\u65b0\u6b65\u9aa4\u5bf9\u6743\u91cd\u8303\u6570\u7684\u5f71\u54cd\uff0c\u5e76\u57fa\u4e8e\u66f4\u65b0\u6700\u7ec8\u72ec\u7acb\u4e8e\u6743\u91cd\u7684\u5047\u8bbe\uff0c\u8be5\u7814\u7a76\u8fd8\u5f15\u5165\u4e86\u603b\u66f4\u65b0\u8d21\u732e(TUC)\u7684\u6982\u5ff5\u6765\u8868\u5f81Scion\u4f18\u5316\u5668\u4e0b\u5c0f\u6279\u91cf\u7684\u6709\u6548\u5b66\u4e60\u7387\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u66f4\u597d\u5730\u63a7\u5236\u8bad\u7ec3\u52a8\u6001\u548c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u8d28\u7591\u4e86\u53bb\u8026\u6743\u91cd\u8870\u51cf\u5e94\u8be5\u4e0e\u5b66\u4e60\u7387\u03b3\u6210\u6b63\u6bd4\u7684\u4f20\u7edf\u8bbe\u5b9a\uff0c\u63d0\u51fa\u4e86\u5728\u7a33\u6001\u4e0b\u57fa\u4e8e\u6b63\u4ea4\u6027\u8bba\u636e\u5e94\u4e0e\u03b3^2\u6210\u6b63\u6bd4\u7684\u65b0\u89c2\u70b9\u3002\u7136\u800c\uff0c\u4f5c\u8005\u4eec\u53d1\u73b0\u79fb\u9664\u66f4\u65b0\u7684\u5782\u76f4\u5206\u91cf\u5bf9\u6743\u91cd\u8303\u6570\u5f71\u54cd\u751a\u5fae\u3002\u56e0\u6b64\uff0c\u8fd9\u9879\u5de5\u4f5c\u7684\u52a8\u673a\u662f\u57fa\u4e8e\u4e00\u4e2a\u7b80\u5316\u7684\u5047\u8bbe\u2014\u2014\u5373\u5728\u7a33\u6001\u65f6\u66f4\u65b0\u53d8\u5f97\u4e0e\u6743\u91cd\u65e0\u5173\u2014\u2014\u6765\u63a8\u5bfc\u51fa\u53bb\u8026\u6743\u91cd\u8870\u51cf\u5e94\u5f53\u4e0e\u03b3^2\u6210\u6bd4\u4f8b\uff0c\u5e76\u63a2\u7d22\u8fd9\u79cd\u8bbe\u7f6e\u5982\u4f55\u5e2e\u52a9\u7a33\u5b9a\u6743\u91cd\u548c\u68af\u5ea6\u8303\u6570\u4ee5\u53ca\u6539\u8fdb\u6a21\u578b\u8868\u73b0\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u4ece\u7406\u8bba\u4e0a\u63a2\u8ba8\u4e86\u4e0d\u540c\u5f62\u5f0f\u4e0b\u53bb\u8026\u6743\u91cd\u8870\u51cf\u5bf9\u4e8e\u6743\u91cd\u8303\u6570\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5f53\u66f4\u65b0\u8fc7\u7a0b\u88ab\u8ba4\u4e3a\u662f\u5728\u7a33\u6001\u6761\u4ef6\u4e0b\u4e0e\u6743\u91cd\u672c\u8eab\u72ec\u7acb\u65f6\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u603b\u66f4\u65b0\u8d21\u732e\u201d(TUC)\u7684\u65b0\u6307\u6807\uff0c\u7528\u6765\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u5728Scion\u4f18\u5316\u5668\u4f5c\u7528\u4e0b\u4e00\u4e2aminibatch\u5e26\u6765\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u91c7\u7528\u4e0e\u03b3^2\u6210\u6bd4\u4f8b\u7684\u53bb\u8026\u6743\u91cd\u8870\u51cf\u80fd\u591f\u5b9e\u73b0\u66f4\u52a0\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u53ca\u66f4\u597d\u7684\u6a21\u578b\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u53bb\u8026\u6743\u91cd\u8870\u51cf\u8bbe\u4e3a\u4e0e\u03b3^2\u6210\u6bd4\u4f8b\u786e\u5b9e\u6709\u52a9\u4e8e\u7ef4\u6301\u6743\u91cd\u548c\u68af\u5ea6\u8303\u6570\u7684\u7a33\u5b9a\u6027\u3002\u540c\u65f6\uff0c\u4f7f\u7528\u57fa\u4e8e\u52a8\u91cf\u7684\u6709\u6548\u5b66\u4e60\u7387\u4f5c\u4e3aTUC\u7684\u5ea6\u91cf\u6807\u51c6\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u4e14\u5176\u6700\u4f18\u503c\u53ef\u4ee5\u5728\u4e0d\u540c\u573a\u666f\u95f4\u8f6c\u79fb\u3002\u8fd9\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u63a7\u5236\u8bad\u7ec3\u52a8\u6001\uff0c\u4ece\u800c\u8fbe\u5230\u6539\u5584\u6a21\u578b\u6027\u80fd\u7684\u76ee\u7684\u3002", "conclusion": "\u672c\u6587\u6311\u6218\u4e86\u5173\u4e8e\u53bb\u8026\u6743\u91cd\u8870\u51cf\u4e0e\u5b66\u4e60\u7387\u4e4b\u95f4\u5173\u7cfb\u7684\u4f20\u7edf\u770b\u6cd5\uff0c\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5373\u53bb\u8026\u6743\u91cd\u8870\u51cf\u5e94\u5f53\u4e0e\u03b3^2\u6210\u6b63\u6bd4\u624d\u80fd\u6709\u6548\u7a33\u5b9a\u6743\u91cd\u548c\u68af\u5ea6\u8303\u6570\u3002\u901a\u8fc7\u5f15\u5165TUC\u6982\u5ff5\u548c\u76f8\u5173\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8fdb\u4e00\u6b65\u652f\u6301\u4e86\u8fd9\u4e00\u7ed3\u8bba\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.08246", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08246", "abs": "https://arxiv.org/abs/2512.08246", "authors": ["Nicholas Harner"], "title": "SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With Prototypes", "comment": "63 Pages, 28 in main body with 3 appendices for supplemental figures", "summary": "Classical Time Series Classification algorithms are dominated by feature engineering strategies. One of the most prominent of these transforms is ROCKET, which achieves strong performance through random kernel features. We introduce SPROCKET (Selected Prototype Random Convolutional Kernel Transform), which implements a new feature engineering strategy based on prototypes. On a majority of the UCR and UEA Time Series Classification archives, SPROCKET achieves performance comparable to existing convolutional algorithms and the new MR-HY-SP ( MultiROCKET-HYDRA-SPROCKET) ensemble's average accuracy ranking exceeds HYDRA-MR, the previous best convolutional ensemble's performance. These experimental results demonstrate that prototype-based feature transformation can enhance both accuracy and robustness in time series classification.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u578b\u7684\u7279\u5f81\u8f6c\u6362\u65b9\u6cd5SPROCKET\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728UCR\u548cUEA\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6863\u6848\u4e2d\u7684\u5927\u90e8\u5206\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u4e0e\u73b0\u6709\u7684\u5377\u79ef\u7b97\u6cd5\u76f8\u6bd4\uff0c\u5176\u6027\u80fd\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u5f53\u4e0eMultiROCKET\u548cHYDRA\u7ed3\u5408\u5f62\u6210\u65b0\u7684\u96c6\u6210\u6a21\u578bMR-HY-SP\u65f6\uff0c\u5176\u5e73\u5747\u51c6\u786e\u7387\u8d85\u8fc7\u4e86\u4e4b\u524d\u6700\u4f73\u7684\u5377\u79ef\u96c6\u6210\u6a21\u578bHYDRA-MR\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u5e8f\u5206\u7c7b\u7b97\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u7279\u5f81\u5de5\u7a0b\u7b56\u7565\uff0c\u5176\u4e2dROCKET\u901a\u8fc7\u968f\u673a\u6838\u7279\u5f81\u5b9e\u73b0\u4e86\u5f3a\u5927\u6027\u80fd\u3002\u7136\u800c\uff0c\u63a2\u7d22\u57fa\u4e8e\u539f\u578b\u7684\u65b0\u7279\u5f81\u5de5\u7a0b\u7b56\u7565\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u65f6\u5e8f\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u662f\u5fc5\u8981\u7684\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86SPROCKET\uff08Selected Prototype Random Convolutional Kernel Transform\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u539f\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u7279\u5f81\u8f6c\u6362\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u96c6\u6210\u6a21\u578bMR-HY-SP\uff0c\u5b83\u7ed3\u5408\u4e86MultiROCKET\u3001HYDRA\u4ee5\u53caSPROCKET\u7684\u4f18\u52bf\u3002", "result": "\u5728\u5927\u591a\u6570UCR\u548cUEA\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6863\u6848\u4e2d\uff0cSPROCKET\u7684\u8868\u73b0\u4e0e\u73b0\u6709\u5377\u79ef\u7b97\u6cd5\u76f8\u5f53\uff1b\u66f4\u91cd\u8981\u7684\u662f\uff0cMR-HY-SP\u96c6\u6210\u6a21\u578b\u7684\u5e73\u5747\u51c6\u786e\u5ea6\u6392\u540d\u8d85\u8fc7\u4e86\u5148\u524d\u6700\u597d\u7684\u5377\u79ef\u96c6\u6210\u6a21\u578bHYDRA-MR\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u539f\u578b\u7684\u7279\u5f81\u8f6c\u6362\u80fd\u591f\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.08257", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.08257", "abs": "https://arxiv.org/abs/2512.08257", "authors": ["Preksha Girish", "Rachana Mysore", "Mahanthesha U", "Shrey Kumar", "Misbah Fatimah Annigeri", "Tanish Jain"], "title": "Geometric-Stochastic Multimodal Deep Learning for Predictive Modeling of SUDEP and Stroke Vulnerability", "comment": "7 pages, 3 figures", "summary": "Sudden Unexpected Death in Epilepsy (SUDEP) and acute ischemic stroke are life-threatening conditions involving complex interactions across cortical, brainstem, and autonomic systems. We present a unified geometric-stochastic multimodal deep learning framework that integrates EEG, ECG, respiration, SpO2, EMG, and fMRI signals to model SUDEP and stroke vulnerability. The approach combines Riemannian manifold embeddings, Lie-group invariant feature representations, fractional stochastic dynamics, Hamiltonian energy-flow modeling, and cross-modal attention mechanisms. Stroke propagation is modeled using fractional epidemic diffusion over structural brain graphs. Experiments on the MULTI-CLARID dataset demonstrate improved predictive accuracy and interpretable biomarkers derived from manifold curvature, fractional memory indices, attention entropy, and diffusion centrality. The proposed framework provides a mathematically principled foundation for early detection, risk stratification, and interpretable multimodal modeling in neural-autonomic disorders.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u51e0\u4f55-\u968f\u673a\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u6574\u5408EEG\u3001ECG\u3001\u547c\u5438\u3001SpO2\u3001EMG\u548cfMRI\u4fe1\u53f7\u6765\u5efa\u6a21\u766b\u75eb\u731d\u6b7b(SUDEP)\u548c\u4e2d\u98ce\u7684\u8106\u5f31\u6027\u3002\u901a\u8fc7\u9ece\u66fc\u6d41\u5f62\u5d4c\u5165\u3001\u674e\u7fa4\u4e0d\u53d8\u7279\u5f81\u8868\u793a\u3001\u5206\u6570\u968f\u673a\u52a8\u529b\u5b66\u3001\u54c8\u5bc6\u987f\u80fd\u91cf\u6d41\u52a8\u5efa\u6a21\u4ee5\u53ca\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u7b49\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u4ece\u591a\u79cd\u751f\u7269\u6807\u5fd7\u7269\u4e2d\u63d0\u53d6\u51fa\u53ef\u89e3\u91ca\u7684\u4fe1\u606f\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u6570\u5b66\u539f\u7406\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8SUDEP\u548c\u6025\u6027\u7f3a\u8840\u6027\u4e2d\u98ce\u8fd9\u4e24\u79cd\u5a01\u80c1\u751f\u547d\u7684\u72b6\u51b5\u7684\u65e9\u671f\u68c0\u6d4b\u3001\u98ce\u9669\u5206\u5c42\u53ca\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5efa\u6a21\u80fd\u529b\u3002\u8fd9\u4e9b\u75be\u75c5\u6d89\u53ca\u5927\u8111\u76ae\u5c42\u3001\u8111\u5e72\u548c\u81ea\u4e3b\u795e\u7ecf\u7cfb\u7edf\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u9ece\u66fc\u6d41\u5f62\u5d4c\u5165\u3001\u674e\u7fa4\u4e0d\u53d8\u7279\u5f81\u8868\u793a\u3001\u5206\u6570\u968f\u673a\u52a8\u529b\u5b66\u3001\u54c8\u5bc6\u987f\u80fd\u91cf\u6d41\u52a8\u5efa\u6a21\u53ca\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u7684\u7edf\u4e00\u51e0\u4f55-\u968f\u673a\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002\u6b64\u5916\uff0c\u8fd8\u5229\u7528\u5206\u6570\u6d41\u884c\u75c5\u6269\u6563\u6a21\u578b\u5728\u7ed3\u6784\u8111\u56fe\u4e0a\u6a21\u62df\u4e2d\u98ce\u4f20\u64ad\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728MULTI-CLARID\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u800c\u4e14\u8fd8\u80fd\u591f\u4ece\u6d41\u5f62\u66f2\u7387\u3001\u5206\u6570\u8bb0\u5fc6\u6307\u6570\u3001\u6ce8\u610f\u529b\u71b5\u548c\u6269\u6563\u4e2d\u5fc3\u6027\u7b49\u65b9\u9762\u63a8\u5bfc\u51fa\u5177\u6709\u89e3\u91ca\u6027\u7684\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u795e\u7ecf-\u81ea\u4e3b\u7cfb\u7edf\u7d0a\u4e71\u75be\u75c5\u7684\u65e9\u671f\u53d1\u73b0\u3001\u98ce\u9669\u8bc4\u4f30\u4ee5\u53ca\u591a\u6a21\u6001\u4fe1\u606f\u7684\u53ef\u89e3\u91ca\u5efa\u6a21\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2512.08306", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08306", "abs": "https://arxiv.org/abs/2512.08306", "authors": ["Sarwesh Rauniyar"], "title": "Jacobian Aligned Random Forests", "comment": null, "summary": "Axis-aligned decision trees are fast and stable but struggle on datasets with rotated or interaction-dependent decision boundaries, where informative splits require linear combinations of features rather than single-feature thresholds. Oblique forests address this with per-node hyperplane splits, but at added computational cost and implementation complexity. We propose a simple alternative: JARF, Jacobian-Aligned Random Forests. Concretely, we first fit an axis-aligned forest to estimate class probabilities or regression outputs, compute finite-difference gradients of these predictions with respect to each feature, aggregate them into an expected Jacobian outer product that generalizes the expected gradient outer product (EGOP), and use it as a single global linear preconditioner for all inputs. This supervised preconditioner applies a single global rotation of the feature space, then hands the transformed data back to a standard axis-aligned forest, preserving off-the-shelf training pipelines while capturing oblique boundaries and feature interactions that would otherwise require many axis-aligned splits to approximate. The same construction applies to any model that provides gradients, though we focus on random forests and gradient-boosted trees in this work. On tabular classification and regression benchmarks, this preconditioning consistently improves axis-aligned forests and often matches or surpasses oblique baselines while improving training time. Our experimental results and theoretical analysis together indicate that supervised preconditioning can recover much of the accuracy of oblique forests while retaining the simplicity and robustness of axis-aligned trees.", "AI": {"tldr": "JARF, or Jacobian-Aligned Random Forests, is a method that enhances the performance of axis-aligned decision trees on datasets with complex decision boundaries by using a single global linear preconditioner. This approach maintains the simplicity and efficiency of axis-aligned trees while improving their capability to handle oblique boundaries and feature interactions, often matching or outperforming oblique forests in terms of accuracy and training time.", "motivation": "The motivation behind JARF is to address the limitations of axis-aligned decision trees, which perform poorly on datasets with rotated or interaction-dependent decision boundaries. While oblique forests can handle such cases, they come with higher computational costs and complexity. JARF aims to provide a simpler, more efficient alternative that retains the benefits of axis-aligned trees while improving their performance on complex datasets.", "method": "JARF begins by fitting an axis-aligned forest to estimate class probabilities or regression outputs. It then computes finite-difference gradients of these predictions concerning each feature, aggregates them into an expected Jacobian outer product, and uses this as a global linear preconditioner for all inputs. This process applies a single global rotation to the feature space, after which the transformed data is fed back into a standard axis-aligned forest. The method is designed to be compatible with any model providing gradients, but the focus here is on random forests and gradient-boosted trees.", "result": "On various tabular classification and regression benchmarks, JARF consistently improves the performance of axis-aligned forests, often achieving results comparable to or better than those of oblique forests. Additionally, it does so with improved training times, demonstrating its effectiveness in enhancing the capabilities of traditional axis-aligned decision trees without significantly increasing computational cost or complexity.", "conclusion": "JARF offers a promising solution for improving the performance of axis-aligned decision trees on datasets with complex decision boundaries, combining the simplicity and efficiency of these trees with the ability to effectively capture oblique boundaries and feature interactions. Experimental evidence and theoretical analysis support JARF's potential to deliver high accuracy similar to oblique forests, while maintaining the robustness and ease of use associated with axis-aligned trees."}}
{"id": "2512.08314", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08314", "abs": "https://arxiv.org/abs/2512.08314", "authors": ["M Yashwanth", "Gaurav Kumar Nayak", "Harsh Rangwani", "Arya Singh", "R. Venkatesh Babu", "Anirban Chakraborty"], "title": "Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning", "comment": "Accepted to WACV 2024", "summary": "Federated Learning (FL) is an emerging machine learning framework that enables multiple clients (coordinated by a server) to collaboratively train a global model by aggregating the locally trained models without sharing any client's training data. It has been observed in recent works that learning in a federated manner may lead the aggregated global model to converge to a 'sharp minimum' thereby adversely affecting the generalizability of this FL-trained model. Therefore, in this work, we aim to improve the generalization performance of models trained in a federated setup by introducing a 'flatness' constrained FL optimization problem. This flatness constraint is imposed on the top eigenvalue of the Hessian computed from the training loss. As each client trains a model on its local data, we further re-formulate this complex problem utilizing the client loss functions and propose a new computationally efficient regularization technique, dubbed 'MAN,' which Minimizes Activation's Norm of each layer on client-side models. We also theoretically show that minimizing the activation norm reduces the top eigenvalue of the layer-wise Hessian of the client's loss, which in turn decreases the overall Hessian's top eigenvalue, ensuring convergence to a flat minimum. We apply our proposed flatness-constrained optimization to the existing FL techniques and obtain significant improvements, thereby establishing new state-of-the-art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ea6\u675fHessian\u77e9\u9635\u7684\u6700\u5927\u7279\u5f81\u503c\u6765\u6539\u5584\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u4e86\u540d\u4e3a'MAN'\u7684\u65b0\u6b63\u5219\u5316\u6280\u672f\uff0c\u8be5\u6280\u672f\u5728\u5ba2\u6237\u7aef\u6a21\u578b\u4e0a\u6700\u5c0f\u5316\u6bcf\u5c42\u6fc0\u6d3b\u7684\u8303\u6570\uff0c\u4ece\u800c\u51cf\u5c11\u6574\u4f53Hessian\u77e9\u9635\u7684\u6700\u5927\u7279\u5f81\u503c\uff0c\u786e\u4fdd\u6536\u655b\u5230\u5e73\u5766\u7684\u6781\u5c0f\u503c\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u53ef\u80fd\u5bfc\u81f4\u5168\u5c40\u6a21\u578b\u6536\u655b\u5230\u4e00\u4e2a\u2018\u5c16\u9510\u6781\u5c0f\u503c\u2019\uff0c\u8fd9\u4f1a\u8d1f\u9762\u5f71\u54cdFL\u8bad\u7ec3\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u2018\u5e73\u5766\u5ea6\u2019\u7ea6\u675f\u7684\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u95ee\u9898\u6765\u63d0\u9ad8\u8054\u90a6\u8bbe\u7f6e\u4e0b\u8bad\u7ec3\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u79f0\u4e3a'MAN'\uff0c\u5b83\u5728\u5ba2\u6237\u7aef\u6a21\u578b\u4e0a\u7684\u6bcf\u4e00\u5c42\u6700\u5c0f\u5316\u6fc0\u6d3b\u7684\u8303\u6570\u3002\u7406\u8bba\u4e0a\u8868\u660e\uff0c\u51cf\u5c0f\u6fc0\u6d3b\u8303\u6570\u53ef\u4ee5\u964d\u4f4e\u5ba2\u6237\u635f\u5931\u7684\u9010\u5c42Hessian\u7684\u6700\u5927\u7279\u5f81\u503c\uff0c\u8fdb\u800c\u51cf\u5c11\u6574\u4e2aHessian\u7684\u6700\u5927\u7279\u5f81\u503c\uff0c\u4fdd\u8bc1\u6536\u655b\u5230\u5e73\u5766\u7684\u6781\u5c0f\u503c\u3002", "result": "\u5c06\u63d0\u51fa\u7684\u5e73\u5766\u5ea6\u7ea6\u675f\u4f18\u5316\u5e94\u7528\u4e8e\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u6280\u672f\u540e\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5e73\u5766\u5ea6\u7ea6\u675f\u4ee5\u53caMAN\u6b63\u5219\u5316\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u8054\u90a6\u5b66\u4e60\u4e2d\u8bad\u7ec3\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e0b\u7684\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.08371", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08371", "abs": "https://arxiv.org/abs/2512.08371", "authors": ["Simon Chung", "Colby J. Vorland", "Donna L. Maney", "Andrew W. Brown"], "title": "A Multivariate Bernoulli-Based Sampling Method for Multi-Label Data with Application to Meta-Research", "comment": null, "summary": "Datasets may contain observations with multiple labels. If the labels are not mutually exclusive, and if the labels vary greatly in frequency, obtaining a sample that includes sufficient observations with scarcer labels to make inferences about those labels, and which deviates from the population frequencies in a known manner, creates challenges. In this paper, we consider a multivariate Bernoulli distribution as our underlying distribution of a multi-label problem. We present a novel sampling algorithm that takes label dependencies into account. It uses observed label frequencies to estimate multivariate Bernoulli distribution parameters and calculate weights for each label combination. This approach ensures the weighted sampling acquires target distribution characteristics while accounting for label dependencies. We applied this approach to a sample of research articles from Web of Science labeled with 64 biomedical topic categories. We aimed to preserve category frequency order, reduce frequency differences between most and least common categories, and account for category dependencies. This approach produced a more balanced sub-sample, enhancing the representation of minority categories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u62bd\u6837\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u8003\u8651\u4e86\u6807\u7b7e\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528\u591a\u53d8\u91cf\u4f2f\u52aa\u5229\u5206\u5e03\u6765\u4f30\u8ba1\u53c2\u6570\u548c\u8ba1\u7b97\u6bcf\u4e2a\u6807\u7b7e\u7ec4\u5408\u7684\u6743\u91cd\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u6807\u7b7e\u9891\u7387\u987a\u5e8f\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u4e86\u6700\u5e38\u89c1\u548c\u6700\u5c11\u89c1\u7c7b\u522b\u4e4b\u95f4\u7684\u9891\u7387\u5dee\u5f02\uff0c\u5e76\u63d0\u9ad8\u4e86\u5c11\u6570\u7c7b\u522b\u7684\u4ee3\u8868\u6027\u3002", "motivation": "\u5728\u5904\u7406\u5305\u542b\u591a\u4e2a\u975e\u4e92\u65a5\u6807\u7b7e\u7684\u6570\u636e\u96c6\u65f6\uff0c\u5982\u679c\u6807\u7b7e\u51fa\u73b0\u9891\u7387\u5dee\u5f02\u5f88\u5927\uff0c\u90a3\u4e48\u83b7\u53d6\u8db3\u591f\u7684\u7a00\u6709\u6807\u7b7e\u6837\u672c\u4ee5\u8fdb\u884c\u76f8\u5173\u63a8\u65ad\u53d8\u5f97\u5177\u6709\u6311\u6218\u6027\u3002\u6b64\u5916\uff0c\u9700\u8981\u786e\u4fdd\u6837\u672c\u4e0e\u603b\u4f53\u9891\u7387\u4ee5\u5df2\u77e5\u65b9\u5f0f\u504f\u79bb\u3002", "method": "\u7814\u7a76\u8005\u4eec\u91c7\u7528\u591a\u53d8\u91cf\u4f2f\u52aa\u5229\u5206\u5e03\u4f5c\u4e3a\u591a\u6807\u7b7e\u95ee\u9898\u7684\u57fa\u672c\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u91c7\u6837\u7b97\u6cd5\u3002\u6b64\u7b97\u6cd5\u5229\u7528\u89c2\u5bdf\u5230\u7684\u6807\u7b7e\u9891\u7387\u6765\u4f30\u8ba1\u591a\u53d8\u91cf\u4f2f\u52aa\u5229\u5206\u5e03\u53c2\u6570\uff0c\u5e76\u4e3a\u6bcf\u79cd\u6807\u7b7e\u7ec4\u5408\u8ba1\u7b97\u6743\u91cd\uff0c\u540c\u65f6\u8003\u8651\u5230\u4e86\u6807\u7b7e\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5f53\u5e94\u7528\u4e8eWeb of Science\u4e2d\u5e26\u670964\u4e2a\u751f\u7269\u533b\u5b66\u4e3b\u9898\u7c7b\u522b\u7684\u7814\u7a76\u6587\u7ae0\u6837\u672c\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4fdd\u6301\u7c7b\u522b\u9891\u7387\u987a\u5e8f\u3001\u51cf\u5c11\u6700\u5e38\u89c1\u4e0e\u6700\u5c11\u89c1\u7c7b\u522b\u95f4\u7684\u9891\u7387\u5dee\u5f02\uff0c\u5e76\u8003\u8651\u5230\u7c7b\u522b\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u751f\u6210\u4e86\u4e00\u4e2a\u66f4\u52a0\u5747\u8861\u7684\u5b50\u6837\u672c\uff0c\u589e\u5f3a\u4e86\u5c11\u6570\u7c7b\u522b\u7684\u8868\u73b0\u529b\u3002", "conclusion": "\u901a\u8fc7\u8003\u8651\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\u5e76\u91c7\u7528\u52a0\u6743\u62bd\u6837\u7b56\u7565\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u5904\u7406\u542b\u6709\u591a\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u5728\u4fdd\u8bc1\u6837\u672c\u4ee3\u8868\u6027\u7684\u524d\u63d0\u4e0b\u6539\u5584\u4e86\u5c11\u6570\u6807\u7b7e\u7684\u8868\u73b0\u3002"}}
{"id": "2512.08451", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.08451", "abs": "https://arxiv.org/abs/2512.08451", "authors": ["Gary Ackerman", "Zachary Kallenborn", "Anna Wetzel", "Hayley Peterson", "Jenna LaTourette", "Olivia Shoemaker", "Brandon Behlendorf", "Sheriff Almakki", "Doug Clifford", "Noah Sheinbaum"], "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process", "comment": "18 pages, 3 figures", "summary": "The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper, the second in a series of three, describes the second component of a novel Biothreat Benchmark Generation (BBG) framework: the generation of the Bacterial Biothreat Benchmark (B3) dataset. The development process involved three complementary approaches: 1) web-based prompt generation, 2) red teaming, and 3) mining existing benchmark corpora, to generate over 7,000 potential benchmarks linked to the Task-Query Architecture that was developed during the first component of the project. A process of de-duplication, followed by an assessment of uplift diagnosticity, and general quality control measures, reduced the candidates to a set of 1,010 final benchmarks. This procedure ensured that these benchmarks are a) diagnostic in terms of providing uplift; b) directly relevant to biosecurity threats; and c) are aligned with a larger biosecurity architecture permitting nuanced analysis at different levels of analysis.", "AI": {"tldr": "This paper presents the creation of a Bacterial Biothreat Benchmark (B3) dataset, part of a larger Biothreat Benchmark Generation (BBG) framework, designed to assess and help mitigate the biosecurity risks associated with advanced AI models, particularly LLMs.", "motivation": "Due to concerns about the potential misuse of AI, especially large language models (LLMs), in facilitating bioterrorism or access to biological weapons, there is a need to develop model benchmarks to assess and mitigate the biosecurity risks posed by these models. The aim is to provide a tool for both model developers and policymakers to better understand and manage such risks.", "method": "The development process for the B3 dataset involved three approaches: web-based prompt generation, red teaming, and mining existing benchmark corpora. Over 7,000 potential benchmarks were created, which were then de-duplicated, assessed for uplift diagnosticity, and subjected to general quality control measures, resulting in the final set of 1,010 benchmarks.", "result": "A Bacterial Biothreat Benchmark (B3) dataset was produced, consisting of 1,010 benchmarks that have been refined to ensure they are diagnostic, directly related to biosecurity, and compatible with a broader biosecurity assessment framework. These benchmarks will be used to evaluate the biosecurity risk of AI models.", "conclusion": "The paper successfully generated a Bacterial Biothreat Benchmark (B3) dataset, containing 1,010 final benchmarks that are diagnostic, relevant to biosecurity threats, and aligned with a larger biosecurity architecture for nuanced analysis. This is the second component of the Biothreat Benchmark Generation (BBG) framework."}}
{"id": "2512.08459", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.08459", "abs": "https://arxiv.org/abs/2512.08459", "authors": ["Gary Ackerman", "Theodore Wilson", "Zachary Kallenborn", "Olivia Shoemaker", "Anna Wetzel", "Hayley Peterson", "Abigail Danfora", "Jenna LaTourette", "Brandon Behlendorf", "Douglas Clifford"], "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models III: Implementing the Bacterial Biothreat Benchmark (B3) Dataset", "comment": "19 pages, 2 figures", "summary": "The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper discusses the pilot implementation of the Bacterial Biothreat Benchmark (B3) dataset. It is the third in a series of three papers describing an overall Biothreat Benchmark Generation (BBG) framework, with previous papers detailing the development of the B3 dataset. The pilot involved running the benchmarks through a sample frontier AI model, followed by human evaluation of model responses, and an applied risk analysis of the results along several dimensions. Overall, the pilot demonstrated that the B3 dataset offers a viable, nuanced method for rapidly assessing the biosecurity risk posed by a LLM, identifying the key sources of that risk and providing guidance for priority areas of mitigation priority.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7ec6\u83cc\u751f\u7269\u5a01\u80c1\u57fa\u51c6\uff08B3\uff09\u6570\u636e\u96c6\u7684\u8bd5\u70b9\u5b9e\u65bd\uff0c\u4f5c\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6240\u5e26\u6765\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\u7684\u4e00\u79cd\u53ef\u884c\u4e14\u7ec6\u81f4\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u8ba9\u4e00\u4e2a\u6837\u672c\u524d\u6cbfAI\u6a21\u578b\u8fd0\u884c\u8fd9\u4e9b\u57fa\u51c6\uff0c\u5e76\u5bf9\u6a21\u578b\u54cd\u5e94\u8fdb\u884c\u4eba\u5de5\u8bc4\u4f30\u548c\u591a\u7ef4\u5ea6\u7684\u98ce\u9669\u5206\u6790\uff0c\u7814\u7a76\u53d1\u73b0B3\u6570\u636e\u96c6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u98ce\u9669\u7684\u4e3b\u8981\u6765\u6e90\uff0c\u5e76\u4e3a\u4f18\u5148\u7f13\u89e3\u9886\u57df\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u5feb\u901f\u53d1\u5c55\u7684\u524d\u6cbf\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff0c\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u6709\u53ef\u80fd\u4fc3\u8fdb\u751f\u7269\u6050\u6016\u4e3b\u4e49\u6216\u83b7\u53d6\u751f\u7269\u6b66\u5668\u7684\u60c5\u51b5\u65e5\u76ca\u5f15\u8d77\u653f\u7b56\u5236\u5b9a\u8005\u3001\u5b66\u672f\u754c\u53ca\u516c\u4f17\u7684\u5173\u6ce8\u3002\u4e3a\u4e86\u91cf\u5316\u5e76\u51cf\u8f7b\u8fd9\u79cd\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc4\u4f30\u7279\u5b9a\u6a21\u578b\u751f\u7269\u5b89\u5168\u98ce\u9669\u7684\u6a21\u578b\u57fa\u51c6\u3002", "method": "\u672c\u6587\u662f\u5173\u4e8eBiothreat Benchmark Generation (BBG)\u6846\u67b6\u7cfb\u5217\u4e09\u7bc7\u8bba\u6587\u4e2d\u7684\u7b2c\u4e09\u7bc7\uff0c\u91cd\u70b9\u5728\u4e8eB3\u6570\u636e\u96c6\u7684\u5b9e\u9645\u5e94\u7528\u6d4b\u8bd5\u3002\u8be5\u8bd5\u70b9\u5305\u62ec\u5c06\u57fa\u51c6\u5e94\u7528\u4e8e\u4e00\u4e2a\u6837\u672c\u524d\u6cbfAI\u6a21\u578b\u4e2d\uff0c\u7136\u540e\u7531\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u6a21\u578b\u7684\u56de\u7b54\uff0c\u5e76\u4ece\u591a\u4e2a\u89d2\u5ea6\u8fdb\u884c\u4e86\u5b9e\u9645\u98ce\u9669\u5206\u6790\u3002", "result": "\u8bd5\u70b9\u9879\u76ee\u8868\u660e\uff0cB3\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u8bc6\u522b\u51fa\u4e3b\u8981\u98ce\u9669\u6e90\uff0c\u5e76\u4e3a\u4f18\u5148\u8003\u8651\u7684\u7f13\u89e3\u63aa\u65bd\u6307\u660e\u65b9\u5411\u3002", "conclusion": "B3\u6570\u636e\u96c6\u88ab\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u7528\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u5b89\u5168\u65b9\u9762\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u540c\u65f6\u4e5f\u4e3a\u5982\u4f55\u4f18\u5148\u5904\u7406\u8fd9\u4e9b\u98ce\u9669\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.08462", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08462", "abs": "https://arxiv.org/abs/2512.08462", "authors": ["Danial Jafarzadeh Jazi", "Maryam Hajiesmaeili"], "title": "Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata", "comment": null, "summary": "Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often fail to utilize the contextual richness provided by Digital Imaging and Communications in Medicine (DICOM) metadata. This paper presents a novel framework integrating transformer-based architectures with multimodal inputs, including fMRI data and DICOM metadata. By employing attention mechanisms, the proposed method captures intricate spatial-temporal patterns and contextual relationships, enhancing model accuracy, interpretability, and robustness. The potential of this framework spans applications in clinical diagnostics, cognitive neuroscience, and personalized medicine. Limitations, such as metadata variability and computational demands, are addressed, and future directions for optimizing scalability and generalizability are discussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u548c\u591a\u6a21\u6001\u8f93\u5165\uff08\u5305\u62ecfMRI\u6570\u636e\u548cDICOM\u5143\u6570\u636e\uff09\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406fMRI\u6570\u636e\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u4e9b\u8fdb\u5c55\uff0c\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528DICOM\u5143\u6570\u636e\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u4e30\u5bcc\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\u5e76\u6355\u6349\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u53ca\u4e0a\u4e0b\u6587\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u7684\u65b0\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6574\u5408\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u4e0e\u5305\u542bfMRI\u6570\u636e\u548cDICOM\u5143\u6570\u636e\u5728\u5185\u7684\u591a\u6a21\u6001\u8f93\u5165\uff0c\u5e76\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u6765\u6355\u6349\u8fd9\u4e9b\u590d\u6742\u7684\u5173\u7cfb\u3002", "result": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5728\u4e34\u5e8a\u8bca\u65ad\u3001\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u4ee5\u53ca\u4e2a\u6027\u5316\u533b\u7597\u9886\u57df\u5e94\u7528\u7684\u6f5c\u529b\u3002\u5c3d\u7ba1\u5b58\u5728\u5143\u6570\u636e\u53d8\u5f02\u6027\u9ad8\u548c\u8ba1\u7b97\u9700\u6c42\u5927\u7b49\u5c40\u9650\u6027\uff0c\u4f46\u8bba\u6587\u4e5f\u8ba8\u8bba\u4e86\u672a\u6765\u4f18\u5316\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u5411\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u878d\u5408fMRI\u6570\u636e\u4e0eDICOM\u5143\u6570\u636e\u7684\u6846\u67b6\u901a\u8fc7\u91c7\u7528\u6ce8\u610f\u673a\u5236\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u7a7a\u95f4-\u65f6\u95f4\u6a21\u5f0f\u7684\u7406\u89e3\uff0c\u4e3a\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u53ca\u4e34\u5e8a\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.08485", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08485", "abs": "https://arxiv.org/abs/2512.08485", "authors": ["Junnan Qiu", "Jie Li"], "title": "Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning", "comment": null, "summary": "Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to data poisoning attacks. Existing attack strategies typically rely on locally uniform perturbations, which treat all samples indiscriminately. This approach is inefficient, as it wastes the perturbation budget on low-impact samples, and lacks stealthiness due to significant statistical deviations. In this paper, we propose a novel Global Budget Allocation attack strategy. Leveraging the theoretical insight that a sample's influence on value function convergence is proportional to its Temporal Difference (TD) error, we formulate the attack as a global resource allocation problem. We derive a closed-form solution where perturbation magnitudes are assigned proportional to the TD-error sensitivity under a global L2 constraint. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms baseline strategies, achieving up to 80% performance degradation with minimal perturbations that evade detection by state-of-the-art statistical and spectral defenses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5168\u5c40\u9884\u7b97\u5206\u914d\u653b\u51fb\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u57fa\u4e8e\u6837\u672c\u7684TD\u8bef\u5dee\u654f\u611f\u6027\u6765\u5206\u914d\u6270\u52a8\u5e45\u5ea6\uff0c\u4ece\u800c\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u4ee5\u6700\u5c0f\u7684\u6270\u52a8\u5b9e\u73b0\u9ad8\u8fbe80%\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u4e14\u80fd\u591f\u907f\u5f00\u6700\u65b0\u7684\u7edf\u8ba1\u548c\u9891\u8c31\u9632\u5fa1\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u7684\u9488\u5bf9\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5bf9\u6240\u6709\u6837\u672c\u65e0\u5dee\u522b\u5730\u8fdb\u884c\u5c40\u90e8\u5747\u5300\u6270\u52a8\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u4e14\u7f3a\u4e4f\u9690\u853d\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5168\u5c40\u9884\u7b97\u5206\u914d\u653b\u51fb\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5229\u7528\u7406\u8bba\u6d1e\u5bdf\u529b\uff0c\u5373\u6837\u672c\u5bf9\u4ef7\u503c\u51fd\u6570\u6536\u655b\u7684\u5f71\u54cd\u4e0e\u5176TD\u8bef\u5dee\u6210\u6b63\u6bd4\uff0c\u5c06\u653b\u51fb\u5efa\u6a21\u4e3a\u4e00\u4e2a\u5168\u5c40\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002\u63a8\u5bfc\u51fa\u4e00\u79cd\u95ed\u5f0f\u89e3\uff0c\u5176\u4e2d\u6270\u52a8\u5e45\u5ea6\u6309\u7167TD\u8bef\u5dee\u654f\u611f\u6027\u6bd4\u4f8b\u5206\u914d\uff0c\u5e76\u53d7\u5168\u5c40L2\u7ea6\u675f\u3002", "result": "D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe80%\u7684\u6027\u80fd\u964d\u7ea7\uff0c\u540c\u65f6\u65bd\u52a0\u4e86\u6781\u5c0f\u7684\u6270\u52a8\uff0c\u8fd9\u4e9b\u6270\u52a8\u80fd\u591f\u9003\u907f\u6700\u5148\u8fdb\u7684\u7edf\u8ba1\u548c\u9891\u8c31\u9632\u5fa1\u68c0\u6d4b\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u5168\u5c40\u9884\u7b97\u5206\u914d\u653b\u51fb\u7b56\u7565\u8bc1\u660e\u4e86\u5728\u63d0\u9ad8\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5bf9\u4e8e\u7406\u89e3\u5e76\u589e\u5f3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.08671", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08671", "abs": "https://arxiv.org/abs/2512.08671", "authors": ["Huzaifa Arif"], "title": "DS FedProxGrad: Asymptotic Stationarity Without Noise Floor in Fair Federated Learning", "comment": "8 pages", "summary": "Recent work \\cite{arifgroup} introduced Federated Proximal Gradient \\textbf{(\\texttt{FedProxGrad})} for solving non-convex composite optimization problems in group fair federated learning. However, the original analysis established convergence only to a \\textit{noise-dominated neighborhood of stationarity}, with explicit dependence on a variance-induced noise floor. In this work, we provide an improved asymptotic convergence analysis for a generalized \\texttt{FedProxGrad}-type analytical framework with inexact local proximal solutions and explicit fairness regularization. We call this extended analytical framework \\textbf{DS \\texttt{FedProxGrad}} (Decay Step Size \\texttt{FedProxGrad}). Under a Robbins-Monro step-size schedule \\cite{robbins1951stochastic} and a mild decay condition on local inexactness, we prove that $\\liminf_{r\\to\\infty} \\mathbb{E}[\\|\\nabla F(\\mathbf{x}^r)\\|^2] = 0$, i.e., the algorithm is asymptotically stationary and the convergence rate does not depend on a variance-induced noise floor.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86\u8054\u90a6\u8fd1\u7aef\u68af\u5ea6(FedProxGrad)\u65b9\u6cd5\u7684\u6e10\u8fd1\u6536\u655b\u6027\u5206\u6790\uff0c\u63d0\u51fa\u4e86DS FedProxGrad\u6846\u67b6\uff0c\u5728\u6ee1\u8db3\u4e00\u5b9a\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u7b97\u6cd5\u80fd\u591f\u8fbe\u5230\u6e10\u8fd1\u5e73\u7a33\uff0c\u5e76\u4e14\u6536\u655b\u901f\u7387\u4e0d\u4f9d\u8d56\u4e8e\u65b9\u5dee\u5f15\u8d77\u7684\u566a\u58f0\u5e95\u9650\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u5f15\u5165\u4e86Federated Proximal Gradient (FedProxGrad)\u6765\u89e3\u51b3\u7ec4\u516c\u5e73\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u975e\u51f8\u590d\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u5176\u6536\u655b\u5206\u6790\u4ec5\u9650\u4e8e\u7531\u65b9\u5dee\u5f15\u8d77\u7684\u566a\u58f0\u4e3b\u5bfc\u7684\u90bb\u57df\u5185\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u6539\u8fdb\u7684\u6e10\u8fd1\u6536\u655b\u6027\u5206\u6790\uff0c\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aDS FedProxGrad\uff08Decay Step Size FedProxGrad\uff09\u7684\u5e7f\u4e49\u5206\u6790\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5141\u8bb8\u5c40\u90e8\u8fd1\u4f3c\u89e3\u5b58\u5728\u4e00\u5b9a\u7684\u8bef\u5dee\u5e76\u660e\u786e\u52a0\u5165\u4e86\u516c\u5e73\u6027\u6b63\u5219\u5316\u3002\u91c7\u7528Robbins-Monro\u6b65\u957f\u8c03\u5ea6\u7b56\u7565\u4ee5\u53ca\u5bf9\u65b9\u5dee\u5f15\u8d77\u7684\u5c40\u90e8\u4e0d\u7cbe\u786e\u5ea6\u65bd\u52a0\u6e29\u548c\u7684\u8870\u51cf\u6761\u4ef6\u3002", "result": "\u5728\u7ed9\u5b9a\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86$\\liminf_{r\\to\\infty} \\mathbb{E}[\\|\\nabla F(\\mathbf{x}^r)\\|^2] = 0$\u6210\u7acb\uff0c\u8fd9\u610f\u5473\u7740\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u8fbe\u5230\u6e10\u8fd1\u5e73\u7a33\u72b6\u6001\uff0c\u5e76\u4e14\u5176\u6536\u655b\u6027\u80fd\u4e0d\u518d\u53d7\u5230\u65b9\u5dee\u5f15\u8d77\u566a\u58f0\u5e95\u9650\u7684\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165DS FedProxGrad\u6846\u67b6\u53ca\u9002\u5f53\u7684\u5047\u8bbe\u6761\u4ef6\uff0c\u6210\u529f\u5730\u63d0\u5347\u4e86FedProxGrad\u65b9\u6cd5\u7684\u7406\u8bba\u6027\u80fd\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u6536\u655b\u8868\u73b0\u3002"}}
{"id": "2512.08699", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08699", "abs": "https://arxiv.org/abs/2512.08699", "authors": ["Chenglong Duan", "Dazhong Wu"], "title": "An Additive Manufacturing Part Qualification Framework: Transferring Knowledge of Stress-strain Behaviors from Additively Manufactured Polymers to Metals", "comment": null, "summary": "Part qualification is crucial in additive manufacturing (AM) because it ensures that additively manufactured parts can be consistently produced and reliably used in critical applications. Part qualification aims at verifying that an additively manufactured part meets performance requirements; therefore, predicting the complex stress-strain behaviors of additively manufactured parts is critical. We develop a dynamic time warping (DTW)-transfer learning (TL) framework for additive manufacturing part qualification by transferring knowledge of the stress-strain behaviors of additively manufactured low-cost polymers to metals. Specifically, the framework employs DTW to select a polymer dataset as the source domain that is the most relevant to the target metal dataset. Using a long short-term memory (LSTM) model, four source polymers (i.e., Nylon, PLA, CF-ABS, and Resin) and three target metals (i.e., AlSi10Mg, Ti6Al4V, and carbon steel) that are fabricated by different AM techniques are utilized to demonstrate the effectiveness of the DTW-TL framework. Experimental results show that the DTW-TL framework identifies the closest match between polymers and metals to select one single polymer dataset as the source domain. The DTW-TL model achieves the lowest mean absolute percentage error of 12.41% and highest coefficient of determination of 0.96 when three metals are used as the target domain, respectively, outperforming the vanilla LSTM model without TL as well as the TL model pre-trained on four polymer datasets as the source domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09-\u8fc1\u79fb\u5b66\u4e60\uff08TL\uff09\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u6750\u5236\u9020\u96f6\u4ef6\u7684\u6027\u80fd\u9a8c\u8bc1\u3002\u901a\u8fc7\u5c06\u4f4e\u6210\u672c\u805a\u5408\u7269\u7684\u5e94\u529b-\u5e94\u53d8\u884c\u4e3a\u77e5\u8bc6\u8fc1\u79fb\u5230\u91d1\u5c5e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u6750\u6599\u548c\u589e\u6750\u5236\u9020\u6280\u672f\u95f4\u6709\u6548\u8fc1\u79fb\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u589e\u6750\u5236\u9020\u9886\u57df\u4e2d\uff0c\u786e\u4fdd\u96f6\u4ef6\u80fd\u591f\u4e00\u81f4\u5730\u751f\u4ea7\u5e76\u5728\u5173\u952e\u5e94\u7528\u4e2d\u53ef\u9760\u4f7f\u7528\u975e\u5e38\u91cd\u8981\u3002\u4e3a\u4e86\u8fbe\u5230\u8fd9\u4e00\u76ee\u6807\uff0c\u9700\u8981\u51c6\u786e\u9884\u6d4b\u589e\u6750\u5236\u9020\u96f6\u4ef6\u590d\u6742\u7684\u5e94\u529b-\u5e94\u53d8\u884c\u4e3a\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u9ad8\u8fd9\u79cd\u9884\u6d4b\u80fd\u529b\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5229\u7528\u5df2\u77e5\u7684\u3001\u6210\u672c\u8f83\u4f4e\u7684\u805a\u5408\u7269\u6570\u636e\u6765\u5e2e\u52a9\u7406\u89e3\u548c\u9884\u6d4b\u66f4\u6602\u8d35\u6216\u96be\u4ee5\u6d4b\u8bd5\u7684\u91d1\u5c5e\u6750\u6599\u7684\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u8005\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u4e86\u52a8\u6001\u65f6\u95f4\u89c4\u6574(DTW)\u4e0e\u8fc1\u79fb\u5b66\u4e60(TL)\u7684\u6280\u672f\u6846\u67b6\u3002\u9996\u5148\u5229\u7528DTW\u4ece\u51e0\u79cd\u4e0d\u540c\u7684\u805a\u5408\u7269\u6750\u6599\u4e2d\u6311\u9009\u51fa\u4e0e\u76ee\u6807\u91d1\u5c5e\u6750\u6599\u6700\u76f8\u5173\u7684\u4f5c\u4e3a\u6e90\u57df\u3002\u63a5\u7740\uff0c\u91c7\u7528\u957f\u77ed\u671f\u8bb0\u5fc6(LSTM)\u6a21\u578b\uff0c\u5c06\u6240\u9009\u805a\u5408\u7269\u7684\u6570\u636e\u96c6\u4f5c\u4e3a\u8bad\u7ec3\u57fa\u7840\uff0c\u5e76\u5c06\u5176\u77e5\u8bc6\u8fc1\u79fb\u5230\u4e09\u4e2a\u76ee\u6807\u91d1\u5c5e\u6750\u6599\u4e0a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684DTW-TL\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u805a\u5408\u7269\u4e0e\u91d1\u5c5e\u4e4b\u95f4\u7684\u6700\u4f73\u5339\u914d\u5173\u7cfb\uff0c\u8fdb\u800c\u9009\u62e9\u4e00\u4e2a\u6700\u9002\u5408\u7684\u805a\u5408\u7269\u6570\u636e\u96c6\u4f5c\u4e3a\u6e90\u57df\u3002\u5f53\u4ee5\u4e09\u79cd\u91d1\u5c5e\u4e3a\u76ee\u6807\u57df\u65f6\uff0cDTW-TL\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u4f4e\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee12.41%\u4ee5\u53ca\u6700\u9ad8\u7684\u51b3\u5b9a\u7cfb\u65700.96\uff0c\u4f18\u4e8e\u6ca1\u6709\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u7684\u666e\u901aLSTM\u6a21\u578b\u53ca\u76f4\u63a5\u7528\u56db\u4e2a\u805a\u5408\u7269\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5c06\u4f4e\u6210\u672c\u805a\u5408\u7269\u7684\u5e94\u529b-\u5e94\u53d8\u884c\u4e3a\u77e5\u8bc6\u8fc1\u79fb\u5230\u91d1\u5c5e\u4e0a\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u589e\u6750\u5236\u9020\u96f6\u4ef6\u8d44\u683c\u8ba4\u8bc1\u8fc7\u7a0b\u4e2d\u5bf9\u4e8e\u91d1\u5c5e\u6750\u6599\u6027\u80fd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e3a\u589e\u6750\u5236\u9020\u884c\u4e1a\u5185\u8de8\u6750\u6599\u7c7b\u578b\u7684\u77e5\u8bc6\u8fc1\u79fb\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.08724", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08724", "abs": "https://arxiv.org/abs/2512.08724", "authors": ["Manos Plitsis", "Giorgos Bouritsas", "Vassilis Katsouros", "Yannis Panagakis"], "title": "Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search", "comment": null, "summary": "Text-to-image (TTI) diffusion models have achieved remarkable visual quality, yet they have been repeatedly shown to exhibit social biases across sensitive attributes such as gender, race and age. To mitigate these biases, existing approaches frequently depend on curated prompt datasets - either manually constructed or generated with large language models (LLMs) - as part of their training and/or evaluation procedures. Beside the curation cost, this also risks overlooking unanticipated, less obvious prompts that trigger biased generation, even in models that have undergone debiasing. In this work, we introduce Bias-Guided Prompt Search (BGPS), a framework that automatically generates prompts that aim to maximize the presence of biases in the resulting images. BGPS comprises two components: (1) an LLM instructed to produce attribute-neutral prompts and (2) attribute classifiers acting on the TTI's internal representations that steer the decoding process of the LLM toward regions of the prompt space that amplify the image attributes of interest. We conduct extensive experiments on Stable Diffusion 1.5 and a state-of-the-art debiased model and discover an array of subtle and previously undocumented biases that severely deteriorate fairness metrics. Crucially, the discovered prompts are interpretable, i.e they may be entered by a typical user, quantitatively improving the perplexity metric compared to a prominent hard prompt optimization counterpart. Our findings uncover TTI vulnerabilities, while BGPS expands the bias search space and can act as a new evaluation tool for bias mitigation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBias-Guided Prompt Search (BGPS)\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u81ea\u52a8\u751f\u6210\u65e8\u5728\u6700\u5927\u5316\u56fe\u50cf\u4e2d\u504f\u89c1\u51fa\u73b0\u7684\u63d0\u793a\u3002\u901a\u8fc7\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u751f\u6210\u5c5e\u6027\u4e2d\u7acb\u7684\u63d0\u793a\uff0c\u5e76\u7ed3\u5408\u5c5e\u6027\u5206\u7c7b\u5668\u5f15\u5bfcLLM\u671d\u5411\u653e\u5927\u611f\u5174\u8da3\u56fe\u50cf\u5c5e\u6027\u7684\u65b9\u5411\u89e3\u7801\uff0cBGPS\u80fd\u591f\u63ed\u793a\u4e4b\u524d\u672a\u88ab\u8bb0\u5f55\u7684\u5fae\u5999\u504f\u89c1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u6539\u5584\u4e86\u516c\u5e73\u6027\u6307\u6807\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u5de5\u5177\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u6587\u672c\u5230\u56fe\u50cf(TTI)\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u8bad\u7ec3\u6216\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u7ecf\u5e38\u4f9d\u8d56\u4e8e\u7cbe\u5fc3\u7b56\u5212\u7684\u63d0\u793a\u6570\u636e\u96c6\uff0c\u8fd9\u65e2\u589e\u52a0\u4e86\u7b56\u5c55\u6210\u672c\uff0c\u4e5f\u6709\u53ef\u80fd\u5ffd\u89c6\u90a3\u4e9b\u89e6\u53d1\u504f\u89c1\u751f\u6210\u4f46\u4e0d\u592a\u660e\u663e\u7684\u63d0\u793a\u3002\u5373\u4f7f\u7ecf\u8fc7\u53bb\u504f\u5904\u7406\u7684\u6a21\u578b\u4e5f\u53ef\u80fd\u5b58\u5728\u8fd9\u79cd\u60c5\u51b5\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u95ee\u9898\u5e76\u63ed\u793a\u66f4\u591a\u6f5c\u5728\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86BGPS\u6846\u67b6\u3002", "method": "BGPS\u6846\u67b6\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u662f\u6307\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ea7\u751f\u5c5e\u6027\u4e2d\u7acb\u7684\u63d0\u793a\uff1b\u4e8c\u662f\u5229\u7528\u4f5c\u7528\u4e8eTTI\u5185\u90e8\u8868\u793a\u7684\u5c5e\u6027\u5206\u7c7b\u5668\uff0c\u8fd9\u4e9b\u5206\u7c7b\u5668\u5c06LLM\u7684\u89e3\u7801\u8fc7\u7a0b\u5bfc\u5411\u90a3\u4e9b\u80fd\u591f\u653e\u5927\u76ee\u6807\u56fe\u50cf\u5c5e\u6027\u7684\u7a7a\u95f4\u533a\u57df\u3002", "result": "\u901a\u8fc7\u5728Stable Diffusion 1.5\u548c\u6700\u5148\u8fdb\u7684\u53bb\u504f\u6a21\u578b\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u4e86\u4e00\u7cfb\u5217\u7ec6\u5fae\u4e14\u4ee5\u524d\u672a\u66fe\u8bb0\u5f55\u8fc7\u7684\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u4e25\u91cd\u635f\u5bb3\u4e86\u516c\u5e73\u6027\u5ea6\u91cf\u3002\u91cd\u8981\u7684\u662f\uff0c\u6240\u53d1\u73b0\u7684\u63d0\u793a\u662f\u53ef\u89e3\u91ca\u7684\uff0c\u666e\u901a\u7528\u6237\u4e5f\u53ef\u4ee5\u8f93\u5165\u5b83\u4eec\uff0c\u76f8\u8f83\u4e8e\u4e00\u4e2a\u91cd\u8981\u7684\u786c\u63d0\u793a\u4f18\u5316\u5bf9\u624b\uff0c\u5728\u56f0\u60d1\u5ea6\u6307\u6807\u4e0a\u6709\u5b9a\u91cf\u4e0a\u7684\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86BGPS\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5de5\u5177\u7684\u6709\u6548\u6027\uff0c\u5b83\u4e0d\u4ec5\u80fd\u5e2e\u52a9\u6269\u5927\u504f\u89c1\u641c\u7d22\u7a7a\u95f4\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u8bc4\u4f30\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u7684\u65b0\u624b\u6bb5\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u63ed\u793a\u4e86\u73b0\u6709TTI\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u9690\u79d8\u504f\u89c1\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2512.08732", "categories": ["cs.LG", "q-bio.SC"], "pdf": "https://arxiv.org/pdf/2512.08732", "abs": "https://arxiv.org/abs/2512.08732", "authors": ["Udesh Habaraduwa", "Andrei Lixandru"], "title": "Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data", "comment": null, "summary": "The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadriven simulation systems are critical in this landscape; unlike classical mechanistic models restricted by prior knowledge, these architectures can infer latent interactions directly from observational data, allowing for the simulation of temporal trajectories and the anticipation of downstream intervention effects in personalized medicine and synthetic biology. To address this challenge, we introduce Neural Ordinary Differential Equations (NODEs) as a dynamic framework for learning the complex interplay between the proteome and metabolome. We applied this framework to time-series data derived from engineered Escherichia coli strains, modeling the continuous dynamics of metabolic pathways. The proposed NODE architecture demonstrates superior performance in capturing system dynamics compared to traditional machine learning pipelines. Our results show a greater than 90% improvement in root mean squared error over baselines across both Limonene (up to 94.38% improvement) and Isopentenol (up to 97.65% improvement) pathway datasets. Furthermore, the NODE models demonstrated a 1000x acceleration in inference time, establishing them as a scalable, high-fidelity tool for the next generation of metabolic engineering and biological discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\uff08NODEs\uff09\u4f5c\u4e3a\u5b66\u4e60\u86cb\u767d\u8d28\u7ec4\u548c\u4ee3\u8c22\u7ec4\u4e4b\u95f4\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u7684\u52a8\u6001\u6846\u67b6\uff0c\u5e76\u5e94\u7528\u4e8e\u5de5\u7a0b\u5927\u80a0\u6746\u83cc\u83cc\u682a\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u76f8\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u6a21\u578b\u5728\u6355\u6349\u7cfb\u7edf\u52a8\u6001\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5bf9\u67e0\u6aac\u70ef\u548c\u5f02\u620a\u9187\u8def\u5f84\u6570\u636e\u96c6\u7684\u5747\u65b9\u6839\u8bef\u5dee\u5206\u522b\u63d0\u9ad8\u4e8694.38%\u548c97.65%\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e861000\u500d\u3002", "motivation": "\u968f\u7740\u9ad8\u901a\u91cf\u591a\u7ec4\u5b66\u6570\u636e\u53d8\u5f97\u8d8a\u6765\u8d8a\u4e30\u5bcc\uff0c\u5c06\u8fd9\u4e9b\u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u9884\u6d4b\u6a21\u578b\u4ecd\u7136\u662f\u4e00\u4e2a\u74f6\u9888\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u6311\u6218\u5e76\u63a8\u52a8\u4eba\u7c7b\u5065\u5eb7\u5bff\u547d\u548c\u751f\u7269\u5de5\u7a0b\u7684\u8fdb\u6b65\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u76f4\u63a5\u63a8\u65ad\u6f5c\u5728\u4ea4\u4e92\u4f5c\u7528\u7684\u9ad8\u5bb9\u91cf\u3001\u6570\u636e\u9a71\u52a8\u7684\u4eff\u771f\u7cfb\u7edf\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\uff08Neural Ordinary Differential Equations, NODEs\uff09\u6765\u6a21\u62df\u4ee3\u8c22\u9014\u5f84\u7684\u8fde\u7eed\u52a8\u529b\u5b66\u7279\u6027\u3002\u901a\u8fc7\u5229\u7528\u6765\u81ea\u7ecf\u8fc7\u5de5\u7a0b\u6539\u9020\u7684\u5927\u80a0\u6746\u83cc\u83cc\u682a\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u7814\u7a76\u8005\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u5b66\u4e60\u86cb\u767d\u7ec4\u4e0e\u4ee3\u8c22\u7ec4\u95f4\u590d\u6742\u4e92\u52a8\u5173\u7cfb\u7684\u52a8\u6001\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684NODE\u67b6\u6784\u5728\u6355\u6349\u7cfb\u7edf\u52a8\u6001\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u7ba1\u9053\uff0c\u5728\u67e0\u6aac\u70ef\u548c\u5f02\u620a\u9187\u8def\u5f84\u6570\u636e\u96c6\u4e0a\u76f8\u8f83\u4e8e\u57fa\u7ebf\u5b9e\u73b0\u4e86\u8d85\u8fc790%\u7684\u5747\u65b9\u6839\u8bef\u5dee\u6539\u8fdb\u3002\u6b64\u5916\uff0cNODE\u6a21\u578b\u8fd8\u5c55\u793a\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb1000\u500d\u7684\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0cNODEs\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u4e14\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u4e0d\u4ec5\u80fd\u591f\u4ee5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u6a21\u62df\u751f\u7269\u7cfb\u7edf\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u800c\u4e14\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u672a\u6765\u7684\u4ee3\u8c22\u5de5\u7a0b\u53ca\u751f\u7269\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2512.08805", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08805", "abs": "https://arxiv.org/abs/2512.08805", "authors": ["Th\u00e9o Verhelst", "Gianluca Bontempi"], "title": "Identifying counterfactual probabilities using bivariate distributions and uplift modeling", "comment": "7 pages. Submitted to the 34th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning", "summary": "Uplift modeling estimates the causal effect of an intervention as the difference between potential outcomes under treatment and control, whereas counterfactual identification aims to recover the joint distribution of these potential outcomes (e.g., \"Would this customer still have churned had we given them a marketing offer?\"). This joint counterfactual distribution provides richer information than the uplift but is harder to estimate. However, the two approaches are synergistic: uplift models can be leveraged for counterfactual estimation. We propose a counterfactual estimator that fits a bivariate beta distribution to predicted uplift scores, yielding posterior distributions over counterfactual outcomes. Our approach requires no causal assumptions beyond those of uplift modeling. Simulations show the efficacy of the approach, which can be applied, for example, to the problem of customer churn in telecom, where it reveals insights unavailable to standard ML or uplift models alone.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u5347\u5206\u6570\u9884\u6d4b\u7684\u53cc\u53d8\u91cf\u8d1d\u5854\u5206\u5e03\u7684\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u5668\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u7528\u6765\u4f30\u8ba1\u6f5c\u5728\u7ed3\u679c\u7684\u8054\u5408\u5206\u5e03\uff0c\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u56e0\u679c\u5047\u8bbe\u3002\u8fd9\u79cd\u6280\u672f\u5728\u7535\u4fe1\u5ba2\u6237\u6d41\u5931\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u6709\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6807\u51c6\u673a\u5668\u5b66\u4e60\u6216\u5355\u72ec\u4f7f\u7528\u63d0\u5347\u6a21\u578b\u65e0\u6cd5\u83b7\u5f97\u7684\u89c1\u89e3\u3002", "motivation": "\u63d0\u5347\u5efa\u6a21\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\u7684\u56e0\u679c\u6548\u5e94\uff0c\u5373\u6cbb\u7597\u4e0e\u5bf9\u7167\u4e0b\u6f5c\u5728\u7ed3\u679c\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u800c\u53cd\u4e8b\u5b9e\u8bc6\u522b\u65e8\u5728\u6062\u590d\u8fd9\u4e9b\u6f5c\u5728\u7ed3\u679c\u7684\u8054\u5408\u5206\u5e03\u3002\u867d\u7136\u8054\u5408\u53cd\u4e8b\u5b9e\u5206\u5e03\u63d0\u4f9b\u4e86\u6bd4\u63d0\u5347\u66f4\u4e3a\u4e30\u5bcc\u7684\u4fe1\u606f\uff0c\u4f46\u5176\u4f30\u8ba1\u96be\u5ea6\u66f4\u5927\u3002\u7136\u800c\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u662f\u534f\u540c\u7684\uff1a\u53ef\u4ee5\u5229\u7528\u63d0\u5347\u6a21\u578b\u6765\u8fdb\u884c\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u62df\u5408\u4e00\u4e2a\u53cc\u53d8\u91cf\u8d1d\u5854\u5206\u5e03\u5230\u9884\u6d4b\u7684\u63d0\u5347\u5206\u6570\u4e0a\uff0c\u4ece\u800c\u4ea7\u751f\u5173\u4e8e\u53cd\u4e8b\u5b9e\u7ed3\u679c\u7684\u540e\u9a8c\u5206\u5e03\u3002\u6b64\u65b9\u6cd5\u9664\u4e86\u63d0\u5347\u5efa\u6a21\u6240\u9700\u7684\u56e0\u679c\u5047\u8bbe\u5916\uff0c\u4e0d\u9700\u4efb\u4f55\u989d\u5916\u7684\u56e0\u679c\u5047\u8bbe\u3002", "result": "\u4eff\u771f\u7814\u7a76\u8868\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u89e3\u51b3\u7535\u4fe1\u884c\u4e1a\u7684\u5ba2\u6237\u6d41\u5931\u95ee\u9898\u65f6\uff0c\u5b83\u63ed\u793a\u4e86\u4ec5\u51ed\u6807\u51c6\u673a\u5668\u5b66\u4e60\u6216\u5355\u7eaf\u4f9d\u9760\u63d0\u5347\u6a21\u578b\u6240\u4e0d\u80fd\u63d0\u4f9b\u7684\u6d1e\u5bdf\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u5c06\u63d0\u5347\u5efa\u6a21\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u76f8\u7ed3\u5408\u7684\u65b0\u9014\u5f84\uff0c\u4e3a\u7406\u89e3\u5e72\u9884\u6548\u679c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u529b\u5de5\u5177\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u90a3\u4e9b\u9700\u8981\u4ece\u66f4\u6df1\u5c42\u6b21\u7406\u89e3\u56e0\u679c\u5173\u7cfb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.08832", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08832", "abs": "https://arxiv.org/abs/2512.08832", "authors": ["Huzaifa Arif", "Pin-Yu Chen", "Alex Gittens", "James Diffenderfer", "Bhavya Kailkhura"], "title": "Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models", "comment": null, "summary": "With the increasing reliance on AI models for weather forecasting, it is imperative to evaluate their vulnerability to adversarial perturbations. This work introduces Weather Adaptive Adversarial Perturbation Optimization (WAAPO), a novel framework for generating targeted adversarial perturbations that are both effective in manipulating forecasts and stealthy to avoid detection. WAAPO achieves this by incorporating constraints for channel sparsity, spatial localization, and smoothness, ensuring that perturbations remain physically realistic and imperceptible. Using the ERA5 dataset and FourCastNet (Pathak et al. 2022), we demonstrate WAAPO's ability to generate adversarial trajectories that align closely with predefined targets, even under constrained conditions. Our experiments highlight critical vulnerabilities in AI-driven forecasting models, where small perturbations to initial conditions can result in significant deviations in predicted weather patterns. These findings underscore the need for robust safeguards to protect against adversarial exploitation in operational forecasting systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6WAAPO\uff0c\u7528\u4e8e\u751f\u6210\u9488\u5bf9\u5929\u6c14\u9884\u62a5\u6a21\u578b\u7684\u5bf9\u6297\u6270\u52a8\uff0c\u8fd9\u4e9b\u6270\u52a8\u65e2\u80fd\u5728\u64cd\u7eb5\u9884\u6d4b\u65b9\u9762\u6709\u6548\uff0c\u53c8\u5177\u6709\u9690\u853d\u6027\u4ee5\u907f\u514d\u88ab\u53d1\u73b0\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5c0f\u7684\u521d\u59cb\u6761\u4ef6\u6270\u52a8\u4e5f\u53ef\u80fd\u5bfc\u81f4\u9884\u6d4b\u5929\u6c14\u6a21\u5f0f\u7684\u91cd\u5927\u504f\u5dee\uff0c\u5f3a\u8c03\u4e86\u5728\u64cd\u4f5c\u6027\u9884\u62a5\u7cfb\u7edf\u4e2d\u9700\u8981\u5f3a\u6709\u529b\u7684\u4fdd\u62a4\u63aa\u65bd\u6765\u9632\u6b62\u5bf9\u6297\u6027\u5229\u7528\u3002", "motivation": "\u968f\u7740\u5bf9AI\u6a21\u578b\u8fdb\u884c\u5929\u6c14\u9884\u62a5\u4f9d\u8d56\u5ea6\u7684\u589e\u52a0\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u5bf9\u6297\u6027\u6270\u52a8\u7684\u8106\u5f31\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u5929\u6c14\u81ea\u9002\u5e94\u5bf9\u6297\u6270\u52a8\u4f18\u5316\uff08WAAPO\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u901a\u9053\u7a00\u758f\u6027\u3001\u7a7a\u95f4\u5c40\u90e8\u5316\u548c\u5e73\u6ed1\u6027\u7684\u7ea6\u675f\u6761\u4ef6\u6765\u751f\u6210\u9488\u5bf9\u6027\u7684\u5bf9\u6297\u6270\u52a8\uff0c\u786e\u4fdd\u6270\u52a8\u4fdd\u6301\u7269\u7406\u4e0a\u7684\u73b0\u5b9e\u6027\u548c\u4e0d\u6613\u5bdf\u89c9\u6027\u3002", "result": "\u4f7f\u7528ERA5\u6570\u636e\u96c6\u548cFourCastNet\u5c55\u793a\u4e86WAAPO\u80fd\u591f\u4ea7\u751f\u4e0e\u9884\u5b9a\u4e49\u76ee\u6807\u7d27\u5bc6\u5339\u914d\u7684\u5bf9\u6297\u8f68\u8ff9\uff0c\u5373\u4f7f\u662f\u5728\u53d7\u9650\u6761\u4ef6\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86AI\u9a71\u52a8\u9884\u62a5\u6a21\u578b\u4e2d\u7684\u5173\u952e\u8106\u5f31\u70b9\uff1a\u521d\u59cb\u6761\u4ef6\u7684\u5c0f\u5e45\u6270\u52a8\u53ef\u80fd\u5bfc\u81f4\u9884\u6d4b\u5929\u6c14\u6a21\u5f0f\u7684\u91cd\u5927\u504f\u79bb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u64cd\u4f5c\u6027\u9884\u62a5\u7cfb\u7edf\u4e2d\u5b9e\u65bd\u5f3a\u6709\u529b\u4fdd\u62a4\u63aa\u65bd\u4ee5\u62b5\u5fa1\u5bf9\u6297\u6027\u5229\u7528\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.08855", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08855", "abs": "https://arxiv.org/abs/2512.08855", "authors": ["Lex Weaver", "Jonathan Baxter"], "title": "Reinforcement Learning From State and Temporal Differences", "comment": null, "summary": "TD($\u03bb$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($\u03bb$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($\u03bb$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($\u03bb$), called STD($\u03bb$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($\u03bb$) in the context of the two-state system, is presented, along with a comparison with Bertsekas' differential training method [1]. This is followed by successful demonstrations of STD($\u03bb$) on the two-state system and a variation on the well known acrobot problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdTD($\\lambda$)\u7684\u6539\u8fdb\u5f62\u5f0fSTD($\\lambda$)\uff0c\u5b83\u57fa\u4e8e\u76f8\u5bf9\u72b6\u6001\u503c\u8bad\u7ec3\u51fd\u6570\u903c\u8fd1\u5668\u4ee5\u89e3\u51b3\u4e8c\u5143\u51b3\u7b56\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u4e24\u72b6\u6001\u7cfb\u7edf\u4e2d\u8be5\u65b9\u6cd5\u80fd\u591f\u5355\u8c03\u5730\u6539\u5584\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u51e0\u4e2a\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1TD($\\lambda$)\u7ed3\u5408\u51fd\u6570\u903c\u8fd1\u5df2\u88ab\u8bc1\u5b9e\u80fd\u6709\u6548\u89e3\u51b3\u4e00\u4e9b\u590d\u6742\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4f46\u5c31\u7b56\u7565\u800c\u8a00\uff0c\u5173\u952e\u5728\u4e8e\u72b6\u6001\u95f4\u7684\u76f8\u5bf9\u6392\u5e8f\u8bef\u5dee\u800c\u975e\u72b6\u6001\u503c\u8bef\u5dee\u672c\u8eab\u3002\u6587\u7ae0\u6307\u51fa\uff0c\u5728\u7b80\u5355\u53cc\u6001\u6216\u4e09\u6001\u7cfb\u7edf\u4e43\u81f3\u897f\u6d0b\u53cc\u9646\u68cb\u6e38\u620f\u4e2d\uff0cTD($\\lambda$)\u4ece\u6700\u4f18\u7b56\u7565\u51fa\u53d1\u4e5f\u53ef\u80fd\u6536\u655b\u5230\u6b21\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aSTD($\\lambda$)\u7684TD($\\lambda$)\u6539\u8fdb\u7248\u672c\uff0c\u5176\u4e2d\u51fd\u6570\u8fd1\u4f3c\u5668\u6839\u636e\u4e8c\u5143\u51b3\u7b56\u95ee\u9898\u4e2d\u7684\u76f8\u5bf9\u72b6\u6001\u503c\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u7406\u8bba\u5206\u6790\u5305\u62ec\u4e86\u5bf9\u4e8e\u4e24\u72b6\u6001\u7cfb\u7edf\u4e2dSTD($\\lambda$)\u5355\u8c03\u7b56\u7565\u6539\u8fdb\u7684\u8bc1\u660e\uff0c\u5e76\u4e0eBertsekas\u63d0\u51fa\u7684\u5dee\u5f02\u8bad\u7ec3\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002\u6b64\u5916\uff0c\u8fd8\u6210\u529f\u5730\u5c06STD($\\lambda$)\u5e94\u7528\u4e8e\u4e24\u72b6\u6001\u7cfb\u7edf\u548c\u4e00\u4e2a\u8457\u540d\u7684acrobot\u95ee\u9898\u53d8\u4f53\u4e0a\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u76f8\u5bf9\u4e8e\u4f20\u7edf\u7684TD($\\lambda$)\uff0cSTD($\\lambda$)\u80fd\u591f\u5728\u4fdd\u6301\u7b56\u7565\u6539\u8fdb\u7684\u540c\u65f6\uff0c\u66f4\u597d\u5730\u5904\u7406\u56e0\u4f7f\u7528\u51fd\u6570\u903c\u8fd1\u800c\u5bfc\u81f4\u7684\u72b6\u6001\u95f4\u76f8\u5bf9\u4ef7\u503c\u9519\u8bef\u95ee\u9898\u3002"}}
{"id": "2512.08859", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08859", "abs": "https://arxiv.org/abs/2512.08859", "authors": ["Lars Ole H\u00e4usler", "Lena Uhlenberg", "G\u00f6ran K\u00f6ber", "Diyora Salimova", "Oliver Amft"], "title": "Refining Diffusion Models for Motion Synthesis with an Acceleration Loss to Generate Realistic IMU Data", "comment": "7 pages, 3 figures, 1 table", "summary": "We propose a text-to-IMU (inertial measurement unit) motion-synthesis framework to obtain realistic IMU data by fine-tuning a pretrained diffusion model with an acceleration-based second-order loss (L_acc). L_acc enforces consistency in the discrete second-order temporal differences of the generated motion, thereby aligning the diffusion prior with IMU-specific acceleration patterns. We integrate L_acc into the training objective of an existing diffusion model, finetune the model to obtain an IMU-specific motion prior, and evaluate the model with an existing text-to-IMU framework that comprises surface modelling and virtual sensor simulation. We analysed acceleration signal fidelity and differences between synthetic motion representation and actual IMU recordings. As a downstream application, we evaluated Human Activity Recognition (HAR) and compared the classification performance using data of our method with the earlier diffusion model and two additional diffusion model baselines. When we augmented the earlier diffusion model objective with L_acc and continued training, L_acc decreased by 12.7% relative to the original model. The improvements were considerably larger in high-dynamic activities (i.e., running, jumping) compared to low-dynamic activities~(i.e., sitting, standing). In a low-dimensional embedding, the synthetic IMU data produced by our refined model shifts closer to the distribution of real IMU recordings. HAR classification trained exclusively on our refined synthetic IMU data improved performance by 8.7% compared to the earlier diffusion model and by 7.6% over the best-performing comparison diffusion model. We conclude that acceleration-aware diffusion refinement provides an effective approach to align motion generation and IMU synthesis and highlights how flexible deep learning pipelines are for specialising generic text-to-motion priors to sensor-specific tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6587\u672c\u5230IMU\u8fd0\u52a8\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u91c7\u7528\u57fa\u4e8e\u52a0\u901f\u5ea6\u7684\u4e8c\u9636\u635f\u5931\uff08L_acc\uff09\u5fae\u8c03\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u6765\u751f\u6210\u903c\u771f\u7684IMU\u6570\u636e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u9ad8\u52a8\u6001\u6d3b\u52a8\u4e2d\u7684\u6539\u8fdb\u5c24\u4e3a\u663e\u8457\uff0c\u5e76\u4e14\u4f7f\u7528\u6539\u8fdb\u540e\u7684\u5408\u6210IMU\u6570\u636e\u8fdb\u884c\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u5206\u7c7b\u65f6\u6027\u80fd\u63d0\u5347\u4e868.7%\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6839\u636e\u6587\u672c\u8f93\u5165\u751f\u6210\u7b26\u5408IMU\u7279\u6027\u7684\u3001\u903c\u771f\u7684\u4eba\u4f53\u52a8\u4f5c\u6570\u636e\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u7279\u522b\u9488\u5bf9IMU\u52a0\u901f\u5ea6\u4fe1\u53f7\u8bbe\u8ba1\u7684\u635f\u5931\u51fd\u6570\uff0c\u65e8\u5728\u63d0\u9ad8\u73b0\u6709\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u52a8\u4f5c\u6570\u636e\u7684\u771f\u5b9e\u6027\u4e0e\u4e00\u81f4\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5b9a\u4e49\u4e86\u4e00\u4e2a\u57fa\u4e8e\u52a0\u901f\u5ea6\u7684\u4e8c\u9636\u635f\u5931\u51fd\u6570 L_acc\uff1b2) \u5c06 L_acc \u6574\u5408\u8fdb\u73b0\u6709\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u76ee\u6807\u4e2d\uff0c\u5e76\u5bf9\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u4ee5\u83b7\u5f97IMU\u7279\u5b9a\u7684\u52a8\u4f5c\u5148\u9a8c\uff1b3) \u8bc4\u4f30\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u4e0d\u540c\u52a8\u6001\u6d3b\u52a8\u4e0b\u7684\u8868\u73b0\u53ca\u4e0e\u771f\u5b9eIMU\u8bb0\u5f55\u4e4b\u95f4\u7684\u5dee\u5f02\uff1b4) \u5229\u7528\u751f\u6210\u7684\u6570\u636e\u8fdb\u884c\u4e86\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u4efb\u52a1\u7684\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u5c06 L_acc \u52a0\u5165\u5230\u65e9\u671f\u6269\u6563\u6a21\u578b\u7684\u76ee\u6807\u51fd\u6570\u4e2d\u5e76\u7ee7\u7eed\u8bad\u7ec3\u540e\uff0cL_acc \u76f8\u5bf9\u4e8e\u539f\u59cb\u6a21\u578b\u51cf\u5c11\u4e8612.7%\uff0c\u5c24\u5176\u5728\u9ad8\u52a8\u6001\u6d3b\u52a8\u4e2d\u6539\u8fdb\u66f4\u4e3a\u660e\u663e\u3002\u6b64\u5916\uff0c\u5728\u4f4e\u7ef4\u5d4c\u5165\u7a7a\u95f4\u4e2d\uff0c\u7531\u6539\u8fdb\u6a21\u578b\u4ea7\u751f\u7684\u5408\u6210IMU\u6570\u636e\u5206\u5e03\u66f4\u63a5\u8fd1\u4e8e\u771f\u5b9eIMU\u8bb0\u5f55\u3002\u57fa\u4e8e\u6b64\u65b9\u6cd5\u751f\u6210\u7684\u6570\u636e\u8bad\u7ec3\u7684HAR\u5206\u7c7b\u5668\u6bd4\u4f7f\u7528\u65e9\u671f\u6269\u6563\u6a21\u578b\u548c\u53e6\u4e00\u4e2a\u8868\u73b0\u6700\u4f73\u7684\u5bf9\u6bd4\u6a21\u578b\u5206\u522b\u63d0\u9ad8\u4e868.7%\u548c7.6%\u7684\u6027\u80fd\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u52a0\u5165\u52a0\u901f\u5ea6\u610f\u8bc6\u7684\u6269\u6563\u7ec6\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u4f7f\u52a8\u4f5c\u751f\u6210\u4e0eIMU\u5408\u6210\u4fdd\u6301\u4e00\u81f4\uff0c\u8fd9\u7a81\u51fa\u4e86\u7075\u6d3b\u7684\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\u5982\u4f55\u4e3a\u4f20\u611f\u5668\u7279\u5b9a\u7684\u4efb\u52a1\u5b9a\u5236\u901a\u7528\u6587\u672c\u5230\u52a8\u4f5c\u5148\u9a8c\u3002"}}
{"id": "2512.08875", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08875", "abs": "https://arxiv.org/abs/2512.08875", "authors": ["Joshua Ward", "Bochao Gu", "Chi-Hua Wang", "Guang Cheng"], "title": "When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation", "comment": null, "summary": "Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u8868\u683c\u5408\u6210\u6570\u636e\u65f6\u53ef\u80fd\u5f15\u53d1\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u540d\u4e3aLevAtt\u7684\u65e0\u76d2\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u65e0\u8bba\u662f\u5fae\u8c03\u5c0f\u578b\u6a21\u578b\u8fd8\u662f\u63d0\u793a\u5927\u578b\u6a21\u578b\uff0c\u90fd\u5b58\u5728\u590d\u73b0\u8bad\u7ec3\u6570\u636e\u4e2d\u6570\u5b57\u6a21\u5f0f\u7684\u8d8b\u52bf\uff0c\u5bfc\u81f4\u9690\u79c1\u98ce\u9669\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u4e24\u79cd\u9632\u5fa1\u65b9\u6cd5\uff0c\u5305\u62ec\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u5408\u6210\u6570\u636e\u4fdd\u771f\u5ea6\u548c\u5b9e\u7528\u6027\u7684\u540c\u65f6\u6709\u6548\u62b5\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u8868\u683c\u5408\u6210\u6570\u636e\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u5f02\u8868\u73b0\uff0c\u4eba\u4eec\u5f00\u59cb\u63a2\u7d22\u5982\u4f55\u5c06\u8fd9\u4e9b\u6a21\u578b\u5e94\u7528\u4e8e\u5b9e\u9645\u573a\u666f\u3002\u4f46\u4e0e\u6b64\u540c\u65f6\uff0c\u4e5f\u51fa\u73b0\u4e86\u5173\u4e8e\u8fd9\u7c7b\u5e94\u7528\u53ef\u80fd\u5e26\u6765\u7684\u9690\u79c1\u6cc4\u9732\u62c5\u5fe7\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5e76\u5206\u6790\u4f7f\u7528LLM\u751f\u6210\u5408\u6210\u6570\u636e\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u9690\u79c1\u6cc4\u6f0f\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u7f13\u89e3\u63aa\u65bd\u3002", "method": "\u7814\u7a76\u8005\u4eec\u9996\u5148\u4ecb\u7ecd\u4e86\u4e24\u79cd\u4e3b\u8981\u7684\u5c06LLM\u7528\u4e8e\u8868\u683c\u6570\u636e\u751f\u6210\u7684\u65b9\u6cd5\uff1a\u76f4\u63a5\u5bf9\u8f83\u5c0f\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u53ca\u7ed9\u8f83\u5927\u7684\u6a21\u578b\u63d0\u4f9b\u4e0a\u4e0b\u6587\u793a\u4f8b\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3aLevAtt\u7684\u65b0\u9896\u65e0\u76d2\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u751f\u6210\u6570\u636e\u4e2d\u7684\u6570\u5b57\u5e8f\u5217\u8fdb\u884c\u653b\u51fb\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cd\u9632\u5fa1\u673a\u5236\u6765\u51cf\u5c11\u8fd9\u79cd\u9690\u79c1\u6cc4\u9732\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u5f3a\u8c03\u4e86\u4e00\u79cd\u521b\u65b0\u6027\u7684\u91c7\u6837\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8bb8\u591a\u6d41\u884c\u7684\u57fa\u4e8eLLM\u7684\u6570\u636e\u751f\u6210\u65b9\u6848\u786e\u5b9e\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u53ef\u4ee5\u4f5c\u4e3a\u5b8c\u7f8e\u7684\u6210\u5458\u5206\u7c7b\u5668\u3002\u800c\u6240\u63d0\u51fa\u7684\u9632\u5fa1\u63aa\u65bd\u80fd\u591f\u663e\u8457\u964d\u4f4e\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u4e0e\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eLLM\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\u9762\u4e34\u7740\u72ec\u7279\u7684\u9690\u79c1\u6cc4\u9732\u6311\u6218\u3002\u901a\u8fc7\u91c7\u7528\u6587\u4e2d\u63d0\u51fa\u7684\u9632\u5fa1\u7b56\u7565\uff0c\u5c24\u5176\u662f\u6539\u8fdb\u540e\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u51cf\u8f7b\u8fd9\u79cd\u5a01\u80c1\u800c\u4e0d\u727a\u7272\u6570\u636e\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.08879", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08879", "abs": "https://arxiv.org/abs/2512.08879", "authors": ["Mohammad Abu-Shaira", "Ajita Rattani", "Weishi Shi"], "title": "DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process", "comment": null, "summary": "Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric regression capabilities with uncertainty quantification, making them ideal for modeling complex data relationships in an online setting. However, conventional online GP methods face several critical limitations, including a lack of drift-awareness, reliance on fixed hyperparameters, vulnerability to data snooping, absence of a principled decay mechanism, and memory inefficiencies. In response, we propose DAO-GP (Drift-Aware Online Gaussian Process), a novel, fully adaptive, hyperparameter-free, decayed, and sparse non-linear regression model. DAO-GP features a built-in drift detection and adaptation mechanism that dynamically adjusts model behavior based on the severity of drift. Extensive empirical evaluations confirm DAO-GP's robustness across stationary conditions, diverse drift types (abrupt, incremental, gradual), and varied data characteristics. Analyses demonstrate its dynamic adaptation, efficient in-memory and decay-based management, and evolving inducing points. Compared with state-of-the-art parametric and non-parametric models, DAO-GP consistently achieves superior or competitive performance, establishing it as a drift-resilient solution for online non-linear regression.", "AI": {"tldr": "\u63d0\u51fa\u4e86DAO-GP\uff0c\u4e00\u79cd\u65b0\u7684\u3001\u5b8c\u5168\u81ea\u9002\u5e94\u7684\u3001\u65e0\u8d85\u53c2\u6570\u7684\u5728\u7ebf\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u80fd\u591f\u68c0\u6d4b\u5e76\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\uff0c\u5177\u6709\u52a8\u6001\u8c03\u6574\u6a21\u578b\u884c\u4e3a\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u6bd4\uff0cDAO-GP\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6216\u7ade\u4e89\u6027\u7684\u6027\u80fd\uff0c\u4e3a\u5728\u7ebf\u975e\u7ebf\u6027\u56de\u5f52\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6297\u6f02\u79fb\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u901a\u5e38\u8868\u73b0\u51fa\u7531\u6570\u636e\u5206\u5e03\u6f14\u53d8\u5f15\u8d77\u7684\u65f6\u95f4\u52a8\u6001\u7279\u6027\u3002\u5ffd\u7565\u8fd9\u79cd\u73b0\u8c61\uff08\u5373\u6982\u5ff5\u6f02\u79fb\uff09\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5728\u7ebf\u6a21\u578b\u4e2d\u7684\u8d85\u53c2\u6570\u901a\u5e38\u662f\u56fa\u5b9a\u7684\uff0c\u7528\u6237\u65e0\u6cd5\u6839\u636e\u53d8\u5316\u7684\u6570\u636e\u5206\u5e03\u8fdb\u884c\u52a8\u6001\u8c03\u6574\u3002\u867d\u7136\u9ad8\u65af\u8fc7\u7a0b(GP)\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u975e\u53c2\u6570\u56de\u5f52\u80fd\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u4f20\u7edf\u7684\u5728\u7ebfGP\u65b9\u6cd5\u5b58\u5728\u51e0\u4e2a\u5173\u952e\u9650\u5236\uff0c\u5982\u7f3a\u4e4f\u5bf9\u6f02\u79fb\u7684\u610f\u8bc6\u3001\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u8d85\u53c2\u6570\u7b49\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDAO-GP\u7684\u65b0\u9896\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u5b8c\u5168\u81ea\u9002\u5e94\u7684\u3001\u65e0\u8d85\u53c2\u6570\u7684\u3001\u8870\u51cf\u7684\u548c\u7a00\u758f\u7684\u975e\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u3002\u5b83\u5177\u5907\u5185\u7f6e\u7684\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u548c\u9002\u5e94\u673a\u5236\uff0c\u53ef\u4ee5\u6839\u636e\u6f02\u79fb\u4e25\u91cd\u7a0b\u5ea6\u52a8\u6001\u8c03\u6574\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8bc1\u5b9e\u4e86DAO-GP\u5728\u9759\u6b62\u6761\u4ef6\u3001\u4e0d\u540c\u7c7b\u578b\u6f02\u79fb\uff08\u7a81\u53d8\u3001\u6e10\u8fdb\u3001\u9010\u6e10\uff09\u4ee5\u53ca\u4e0d\u540c\u6570\u636e\u7279\u5f81\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u5206\u6790\u663e\u793a\u4e86\u5176\u52a8\u6001\u9002\u5e94\u80fd\u529b\u3001\u5185\u5b58\u7ba1\u7406\u6548\u7387\u53ca\u8bf1\u5bfc\u70b9\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u60c5\u51b5\u3002\u4e0e\u6700\u5148\u8fdb\u7684\u53c2\u6570\u5316\u548c\u975e\u53c2\u6570\u5316\u6a21\u578b\u76f8\u6bd4\uff0cDAO-GP\u59cb\u7ec8\u8fbe\u5230\u66f4\u4f18\u6216\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "DAO-GP\u4f5c\u4e3a\u4e00\u79cd\u9488\u5bf9\u5728\u7ebf\u73af\u5883\u8bbe\u8ba1\u7684\u6f02\u79fb\u611f\u77e5\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u8c03\u6574\u673a\u5236\u514b\u670d\u4e86\u4f20\u7edf\u5728\u7ebfGP\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u9762\u5bf9\u5404\u79cd\u7c7b\u578b\u6570\u636e\u6f02\u79fb\u65f6\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8fd8\u4fdd\u6301\u4e86\u9ad8\u6548\u7684\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2512.08895", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08895", "abs": "https://arxiv.org/abs/2512.08895", "authors": ["Suina Tanweer", "Firas A. Khasawneh"], "title": "Unsupervised Learning of Density Estimates with Topological Optimization", "comment": null, "summary": "Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques -- demonstrating its potential across different dimensions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u7684\u635f\u5931\u51fd\u6570\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u5e26\u5bbd\uff0c\u5e76\u4e0e\u7ecf\u5178\u6280\u672f\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u6838\u5bc6\u5ea6\u4f30\u8ba1\u662f\u673a\u5668\u5b66\u4e60\u3001\u8d1d\u53f6\u65af\u63a8\u65ad\u3001\u968f\u673a\u52a8\u529b\u5b66\u548c\u4fe1\u53f7\u5904\u7406\u4e2d\u591a\u79cd\u7b97\u6cd5\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5176\u9700\u8981\u8c03\u6574\u4e00\u4e2a\u5173\u952e\u8d85\u53c2\u6570\uff1a\u6838\u5e26\u5bbd\u3002\u5e26\u5bbd\u7684\u9009\u62e9\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u901a\u8fc7\u8fc7\u5ea6\u6216\u4e0d\u8db3\u5e73\u6ed1\u62d3\u6251\u7279\u5f81\u6765\u63a7\u5236\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6570\u5b66\u624b\u6bb5\u91cf\u5316\u5982\u8fde\u901a\u5206\u91cf\u3001\u73af\u8def\u3001\u7a7a\u6d1e\u7b49\u62d3\u6251\u7279\u6027\uff0c\u5373\u4f7f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5982\u6b64\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u7684\u635f\u5931\u51fd\u6570\u6765\u8fdb\u884c\u81ea\u52a8\u5316\u4e14\u65e0\u9700\u76d1\u7763\u7684\u6700\u4f73\u5e26\u5bbd\u9009\u62e9\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u5c55\u793a\u4e86\u5176\u6f5c\u529b\uff0c\u5e76\u4e0e\u4f20\u7edf\u6280\u672f\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u663e\u793a\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e\u62d3\u6251\u7684\u635f\u5931\u51fd\u6570\u4e3a\u81ea\u52a8\u5316\u9009\u62e9\u6700\u4f73\u5e26\u5bbd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u8fd9\u53ef\u80fd\u5bf9\u63d0\u5347\u6d89\u53ca\u6838\u5bc6\u5ea6\u4f30\u8ba1\u7684\u4efb\u52a1\u6027\u80fd\u6709\u6240\u5e2e\u52a9\u3002"}}
{"id": "2512.08896", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08896", "abs": "https://arxiv.org/abs/2512.08896", "authors": ["Gang Liu", "Sobin Alosious", "Subhamoy Mahajan", "Eric Inae", "Yihan Zhu", "Yuhan Liu", "Renzheng Zhang", "Jiaxin Xu", "Addison Howard", "Ying Li", "Tengfei Luo", "Meng Jiang"], "title": "Open Polymer Challenge: Post-Competition Report", "comment": "The report for the competition: \"NeurIPS - Open Polymer Prediction 2025\". Kaggle Page: https://www.kaggle.com/competitions/neurips-open-polymer-prediction-2025. Website: https://open-polymer-challenge.github.io", "summary": "Machine learning (ML) offers a powerful path toward discovering sustainable polymer materials, but progress has been limited by the lack of large, high-quality, and openly accessible polymer datasets. The Open Polymer Challenge (OPC) addresses this gap by releasing the first community-developed benchmark for polymer informatics, featuring a dataset with 10K polymers and 5 properties: thermal conductivity, radius of gyration, density, fractional free volume, and glass transition temperature. The challenge centers on multi-task polymer property prediction, a core step in virtual screening pipelines for materials discovery. Participants developed models under realistic constraints that include small data, label imbalance, and heterogeneous simulation sources, using techniques such as feature-based augmentation, transfer learning, self-supervised pretraining, and targeted ensemble strategies. The competition also revealed important lessons about data preparation, distribution shifts, and cross-group simulation consistency, informing best practices for future large-scale polymer datasets. The resulting models, analysis, and released data create a new foundation for molecular AI in polymer science and are expected to accelerate the development of sustainable and energy-efficient materials. Along with the competition, we release the test dataset at https://www.kaggle.com/datasets/alexliu99/neurips-open-polymer-prediction-2025-test-data. We also release the data generation pipeline at https://github.com/sobinalosious/ADEPT, which simulates more than 25 properties, including thermal conductivity, radius of gyration, and density.", "AI": {"tldr": "The Open Polymer Challenge (OPC) has released a benchmark dataset for polymer informatics, featuring 10K polymers and their properties, to advance machine learning in the discovery of sustainable materials. The challenge focused on multi-task property prediction, with participants using various ML techniques to develop models under realistic constraints. Lessons learned from the competition will guide future data preparation and simulation practices.", "motivation": "The motivation behind this paper is to address the lack of large, high-quality, and openly accessible datasets for polymer research, which hinders the application of machine learning in discovering sustainable polymer materials. By initiating the Open Polymer Challenge (OPC), the authors aim to fill this gap and provide a benchmark that can accelerate the development of such materials.", "method": "The method employed in this work involves creating and releasing a comprehensive dataset as part of the OPC, which includes 10,000 polymers and five key properties. The challenge invites researchers to predict these properties using machine learning approaches, while dealing with real-world issues like small data sizes, label imbalance, and varying simulation sources. Participants are encouraged to use advanced techniques such as feature-based augmentation, transfer learning, self-supervised pretraining, and ensemble strategies.", "result": "As a result of the challenge, participants have developed predictive models for polymer properties, and important insights were gained regarding data preparation, distribution shifts, and the consistency of simulations across different groups. These findings contribute to establishing best practices for handling large-scale polymer datasets in the future.", "conclusion": "In conclusion, the Open Polymer Challenge has successfully established a new benchmark for polymer informatics, providing a valuable resource for the development of machine learning models in material science. The outcomes, including the created models, analyses, and shared data, lay the groundwork for advancing molecular AI within the field of polymer science and support the quest for more sustainable and energy-efficient materials."}}
