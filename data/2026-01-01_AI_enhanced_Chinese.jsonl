{"id": "2512.23952", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.23952", "abs": "https://arxiv.org/abs/2512.23952", "authors": ["Yongmin Zhang", "Pengyu Huang", "Mingyi Dong", "Jing Yao"], "title": "Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks", "comment": null, "summary": "Edge computing enables latency-critical applications to process data close to end devices, yet task heterogeneity and limited resources pose significant challenges to efficient orchestration. This paper presents a measurement-driven, container-based resource management framework for intra-node optimization on a single edge server hosting multiple heterogeneous applications. Extensive profiling experiments are conducted to derive a nonlinear fitting model that characterizes the relationship among CPU/memory allocations and processing latency across diverse workloads, enabling reliable estimation of performance under varying configurations and providing quantitative support for subsequent optimization. Using this model and a queueing-based delay formulation, we formulate a mixed-integer nonlinear programming (MINLP) problem to jointly minimize system latency and power consumption, which is shown to be NP-hard. The problem is decomposed into tractable convex subproblems and solved through a two-stage container-based resource management scheme (CRMS) combining convex optimization and greedy refinement. The proposed scheme achieves polynomial-time complexity and supports quasi-dynamic execution under global resource constraints. Simulation results demonstrate that CRMS reduces latency by over 14\\% and improves energy efficiency compared with heuristic and search-based baselines, offering a practical and scalable solution for heterogeneous edge environments with dynamic workload characteristics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4b\u91cf\u548c\u5bb9\u5668\u7684\u8d44\u6e90\u7ba1\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5355\u4e00\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u6258\u7ba1\u7684\u591a\u79cd\u5f02\u6784\u5e94\u7528\u7a0b\u5e8f\u7684\u8d44\u6e90\u5206\u914d\u3002\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u975e\u7ebf\u6027\u62df\u5408\u6a21\u578b\u6765\u63cf\u8ff0CPU/\u5185\u5b58\u5206\u914d\u4e0e\u5904\u7406\u5ef6\u8fdf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u4e86\u4e00\u4e2a\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u4ee5\u6700\u5c0f\u5316\u7cfb\u7edf\u5ef6\u8fdf\u548c\u80fd\u8017\u3002\u8be5\u95ee\u9898\u901a\u8fc7\u4e24\u9636\u6bb5\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\uff08CRMS\uff09\u5f97\u5230\u6709\u6548\u89e3\u51b3\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793aCRMS\u76f8\u6bd4\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u5728\u51cf\u5c11\u5ef6\u8fdf\u548c\u63d0\u9ad8\u80fd\u6548\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u5141\u8bb8\u5bf9\u65f6\u5ef6\u654f\u611f\u7684\u5e94\u7528\u7a0b\u5e8f\u5728\u9760\u8fd1\u7ec8\u7aef\u8bbe\u5907\u7684\u5730\u65b9\u5904\u7406\u6570\u636e\uff0c\u4f46\u4efb\u52a1\u5f02\u6784\u6027\u548c\u6709\u9650\u8d44\u6e90\u7ed9\u9ad8\u6548\u7f16\u6392\u5e26\u6765\u4e86\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u7ba1\u7406\u548c\u4f18\u5316\u5355\u4e2a\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u7684\u591a\u7c7b\u578b\u5e94\u7528\u8d44\u6e90\u4f7f\u7528\u7684\u6846\u67b6\u3002", "method": "1. \u901a\u8fc7\u5e7f\u6cdb\u7684\u6027\u80fd\u6d4b\u8bd5\u5b9e\u9a8c\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u975e\u7ebf\u6027\u62df\u5408\u6a21\u578b\uff0c\u7528\u4ee5\u523b\u753b\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e0bCPU/\u5185\u5b58\u5206\u914d\u4e0e\u5904\u7406\u5ef6\u8fdf\u95f4\u7684\u5173\u7cfb\u3002\n2. \u5229\u7528\u4e0a\u8ff0\u6a21\u578b\u53ca\u57fa\u4e8e\u6392\u961f\u8bba\u7684\u5ef6\u8fdf\u516c\u5f0f\uff0c\u6784\u5efa\u4e86\u76ee\u6807\u4e3a\u540c\u65f6\u6700\u5c0f\u5316\u7cfb\u7edf\u5ef6\u8fdf\u4e0e\u529f\u8017\u7684\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002\n3. \u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u65b9\u6848(CRMS)\uff0c\u9996\u5148\u5c06\u539f\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u89e3\u7684\u51f8\u5b50\u95ee\u9898\uff0c\u7136\u540e\u7ed3\u5408\u51f8\u4f18\u5316\u6280\u672f\u548c\u8d2a\u5a6a\u7ec6\u5316\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e8e\u542f\u53d1\u5f0f\u548c\u5176\u4ed6\u641c\u7d22\u4e3a\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684CRMS\u65b9\u6848\u80fd\u591f\u5728\u964d\u4f4e\u8d85\u8fc714%\u7684\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u5347\u80fd\u6e90\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u5bb9\u5668\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6848CRMS\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5177\u6709\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7684\u5f02\u6784\u8fb9\u7f18\u73af\u5883\uff0c\u5728\u51cf\u5c11\u5ef6\u8fdf\u548c\u63d0\u9ad8\u80fd\u6548\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2512.24449", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24449", "abs": "https://arxiv.org/abs/2512.24449", "authors": ["Bo Jiang", "Taolue Yang", "Youyuan Liu", "Xubin He", "Sheng Di", "Sian Jin"], "title": "PackKV: Reducing KV Cache Memory Footprint through LLM-Aware Lossy Compression", "comment": null, "summary": "Transformer-based large language models (LLMs) have demonstrated remarkable potential across a wide range of practical applications. However, long-context inference remains a significant challenge due to the substantial memory requirements of the key-value (KV) cache, which can scale to several gigabytes as sequence length and batch size increase. In this paper, we present \\textbf{PackKV}, a generic and efficient KV cache management framework optimized for long-context generation. %, which synergistically supports both latency-critical and throughput-critical inference scenarios. PackKV introduces novel lossy compression techniques specifically tailored to the characteristics of KV cache data, featuring a careful co-design of compression algorithms and system architecture. Our approach is compatible with the dynamically growing nature of the KV cache while preserving high computational efficiency. Experimental results show that, under the same and minimum accuracy drop as state-of-the-art quantization methods, PackKV achieves, on average, \\textbf{153.2}\\% higher memory reduction rate for the K cache and \\textbf{179.6}\\% for the V cache. Furthermore, PackKV delivers extremely high execution throughput, effectively eliminating decompression overhead and accelerating the matrix-vector multiplication operation. Specifically, PackKV achieves an average throughput improvement of \\textbf{75.7}\\% for K and \\textbf{171.7}\\% for V across A100 and RTX Pro 6000 GPUs, compared to cuBLAS matrix-vector multiplication kernels, while demanding less GPU memory bandwidth. Code available on https://github.com/BoJiang03/PackKV", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPackKV\u7684\u9ad8\u6548KV\u7f13\u5b58\u7ba1\u7406\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u901a\u8fc7\u5f15\u5165\u4e13\u4e3aKV\u7f13\u5b58\u6570\u636e\u7279\u70b9\u8bbe\u8ba1\u7684\u6709\u635f\u538b\u7f29\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u9ad8\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u6267\u884c\u541e\u5410\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8eTransformer\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f17\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4e86\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u65f6\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u7531\u4e8e\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u548c\u6279\u5904\u7406\u5927\u5c0f\u589e\u52a0\u800c\u8fc5\u901f\u589e\u957f\u7684\u5173\u952e-\u503c(KV)\u7f13\u5b58\u6240\u9700\u7684\u5927\u91cf\u5185\u5b58\u3002", "method": "PackKV\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u9488\u5bf9KV\u7f13\u5b58\u6570\u636e\u7279\u5f81\u5b9a\u5236\u7684\u6709\u635f\u538b\u7f29\u6280\u672f\uff0c\u7ed3\u5408\u4e86\u538b\u7f29\u7b97\u6cd5\u4e0e\u7cfb\u7edf\u67b6\u6784\u7684\u7cbe\u5fc3\u534f\u540c\u8bbe\u8ba1\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u517c\u5bb9KV\u7f13\u5b58\u52a8\u6001\u589e\u957f\u7684\u7279\u70b9\uff0c\u8fd8\u7ef4\u6301\u4e86\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u4e0b\u964d\u5e45\u5ea6\u4e0e\u6700\u5148\u8fdb\u7684\u91cf\u5316\u65b9\u6cd5\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0cPackKV\u5bf9K\u7f13\u5b58\u5e73\u5747\u8fbe\u5230\u4e86153.2%\u66f4\u9ad8\u7684\u5185\u5b58\u7f29\u51cf\u7387\uff0c\u5bf9\u4e8eV\u7f13\u5b58\u5219\u662f179.6%\u3002\u6b64\u5916\uff0cPackKV\u5927\u5e45\u63d0\u5347\u4e86\u6267\u884c\u541e\u5410\u91cf\uff0c\u7279\u522b\u662f\u5728A100\u548cRTX Pro 6000 GPU\u4e0a\u76f8\u5bf9\u4e8ecuBLAS\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\u5185\u6838\u800c\u8a00\uff0cK\u7f13\u5b58\u7684\u5e73\u5747\u541e\u5410\u91cf\u63d0\u9ad8\u4e8675.7%\uff0cV\u7f13\u5b58\u5219\u63d0\u5347\u4e86171.7%\uff0c\u540c\u65f6\u6240\u9700GPU\u5185\u5b58\u5e26\u5bbd\u66f4\u5c11\u3002", "conclusion": "PackKV\u4f5c\u4e3a\u4e00\u79cd\u901a\u7528\u4e14\u9ad8\u6548\u7684KV\u7f13\u5b58\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u652f\u6301\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5b83\u4e0d\u4ec5\u5927\u5e45\u5ea6\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u800c\u4e14\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2512.23925", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.23925", "abs": "https://arxiv.org/abs/2512.23925", "authors": ["Amir Shaikhha"], "title": "Hojabr: Towards a Theory of Everything for AI and Data Analytics", "comment": null, "summary": "Modern data analytics pipelines increasingly combine relational queries, graph processing, and tensor computation within a single application, but existing systems remain fragmented across paradigms, execution models, and research communities. This fragmentation results in repeated optimization efforts, limited interoperability, and strict separation between logical abstractions and physical execution strategies.\n  We propose Hojabr as a unified declarative intermediate language to address this problem. Hojabr integrates relational algebra, tensor algebra, and constraint-based reasoning within a single higher-order algebraic framework, in which joins, aggregations, tensor contractions, and recursive computations are expressed uniformly. Physical choices, such as join algorithms, execution models, and sparse versus dense tensor representations, are handled as constraint-specialization decisions rather than as separate formalisms. Hojabr supports bidirectional translation with existing declarative languages, enabling programs to be both lowered into Hojabr for analysis and optimization and lifted back into their original declarative form. By making semantic, structural, and algebraic properties explicit, and by supporting extensibility across the compilation stack, Hojabr enables systematic reasoning and reuse of optimization techniques across database systems, machine learning frameworks, and compiler infrastructures.", "AI": {"tldr": "Hojabr\u662f\u4e00\u79cd\u7edf\u4e00\u7684\u58f0\u660e\u6027\u4e2d\u95f4\u8bed\u8a00\uff0c\u5b83\u5728\u4e00\u4e2a\u9ad8\u9636\u4ee3\u6570\u6846\u67b6\u4e2d\u6574\u5408\u4e86\u5173\u7cfb\u4ee3\u6570\u3001\u5f20\u91cf\u4ee3\u6570\u548c\u57fa\u4e8e\u7ea6\u675f\u7684\u63a8\u7406\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u636e\u5206\u6790\u6d41\u6c34\u7ebf\u4e2d\u8de8\u8303\u5f0f\u3001\u6267\u884c\u6a21\u578b\u548c\u7814\u7a76\u793e\u533a\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u5904\u7406\u7cfb\u7edf\u5728\u8303\u5f0f\u3001\u6267\u884c\u6a21\u578b\u4ee5\u53ca\u7814\u7a76\u793e\u7fa4\u4e4b\u95f4\u5b58\u5728\u5206\u5272\uff0c\u5bfc\u81f4\u4f18\u5316\u5de5\u4f5c\u91cd\u590d\u3001\u4e92\u64cd\u4f5c\u6027\u53d7\u9650\u4ee5\u53ca\u903b\u8f91\u62bd\u8c61\u4e0e\u7269\u7406\u6267\u884c\u7b56\u7565\u4e4b\u95f4\u7684\u4e25\u683c\u5206\u79bb\u3002", "method": "\u63d0\u51faHojabr\u4f5c\u4e3a\u7edf\u4e00\u7684\u58f0\u660e\u6027\u4e2d\u95f4\u8bed\u8a00\uff0c\u5728\u4e00\u4e2a\u5355\u4e00\u7684\u9ad8\u9636\u4ee3\u6570\u6846\u67b6\u5185\u96c6\u6210\u5173\u7cfb\u4ee3\u6570\u3001\u5f20\u91cf\u4ee3\u6570\u53ca\u57fa\u4e8e\u7ea6\u675f\u7684\u63a8\u7406\uff0c\u4f7f\u5f97\u8fde\u63a5\u3001\u805a\u5408\u3001\u5f20\u91cf\u6536\u7f29\u548c\u9012\u5f52\u8ba1\u7b97\u80fd\u591f\u4ee5\u7edf\u4e00\u7684\u65b9\u5f0f\u8868\u8fbe\u3002", "result": "Hojabr\u901a\u8fc7\u660e\u786e\u8bed\u4e49\u3001\u7ed3\u6784\u548c\u4ee3\u6570\u5c5e\u6027\uff0c\u5e76\u652f\u6301\u7f16\u8bd1\u6808\u4e2d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u5e93\u7cfb\u7edf\u3001\u673a\u5668\u5b66\u4e60\u6846\u67b6\u548c\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\u95f4\u7684\u4f18\u5316\u6280\u672f\u7cfb\u7edf\u5316\u63a8\u7406\u4e0e\u91cd\u7528\u3002", "conclusion": "Hojabr\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u901a\u7528\u7684\u8bed\u8a00\u6765\u63cf\u8ff0\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u5206\u6790\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4e0d\u540c\u9886\u57df\u95f4\u7684\u6280\u672f\u4e92\u901a\u6027\u548c\u4f18\u5316\u6548\u7387\u3002"}}
{"id": "2512.24511", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24511", "abs": "https://arxiv.org/abs/2512.24511", "authors": ["Mikaila J. Gossman", "Avinash Maurya", "Bogdan Nicolae", "Jon C. Calhoun"], "title": "Understanding LLM Checkpoint/Restore I/O Strategies and Patterns", "comment": "SCA/HPCAsia 2026 Workshops: Supercomputing Asia and International Conference on High Performance Computing in the Asia Pacific Region Workshops", "summary": "As LLMs and foundation models scale, checkpoint/restore has become a critical pattern for training and inference. With 3D parallelism (tensor, pipeline, data), checkpointing involves many processes, each managing numerous tensors of varying shapes and sizes, that must be persisted frequently to stable storage (e.g., parallel file systems). This turns checkpoint/restore into a big-data I/O problem characterized by volume, variety, and velocity. The workflow must traverse the full storage stack -- from GPU memory through host memory and local storage to external repositories -- whose tiers differ by orders of magnitude in performance, creating bottlenecks under concurrency even with asynchronous flush/prefetch. Kernel-accelerated I/O libraries such as \\texttt{liburing} may mitigate these issues versus POSIX, but their effectiveness for LLM checkpointing remains underexplored. We develop microbenchmarks to quantify trade-offs when using \\texttt{liburing}, evaluating how aggregation, alignment, and I/O coalescing interact under buffered and direct I/O. We find that uncoalesced small-buffer operations halve throughput relative to synthetic workloads, while file system-aware aggregation restores bandwidth and reduces metadata overhead. Compared to state-of-the-art LLM checkpointing engines, our approach achieves up to $3.9\\times$ higher write throughput than DataStates-LLM and $7.6\\times$ higher than TorchSnapshot. These results highlight the need for aggregation and coalescing strategies that align with modern file systems and I/O backends.", "AI": {"tldr": "\u968f\u7740LLM\u548c\u57fa\u7840\u6a21\u578b\u7684\u6269\u5c55\uff0c\u68c0\u67e5\u70b9/\u6062\u590d\u5df2\u6210\u4e3a\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u5173\u952e\u6a21\u5f0f\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u57283D\u5e76\u884c\u6027\u4e0b\u4f7f\u7528liburing\u8fdb\u884c\u68c0\u67e5\u70b9\u64cd\u4f5c\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u5fae\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u4e86\u805a\u5408\u3001\u5bf9\u9f50\u548cI/O\u5408\u5e76\u7b56\u7565\u7684\u6548\u679c\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0eDataStates-LLM\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u9ad8\u8fbe3.9\u500d\u7684\u5199\u5165\u541e\u5410\u91cf\uff0c\u4e0eTorchSnapshot\u76f8\u6bd4\u5219\u9ad8\u8fbe7.6\u500d\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u57fa\u7840\u6a21\u578b\u7684\u89c4\u6a21\u589e\u957f\uff0c\u68c0\u67e5\u70b9/\u6062\u590d\u673a\u5236\u5bf9\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u5904\u7406\u5927\u91cf\u4e0d\u540c\u5f62\u72b6\u548c\u5927\u5c0f\u7684\u5f20\u91cf\u65f6\uff0c\u8fd9\u79cd\u673a\u5236\u53d8\u6210\u4e86\u4e00\u4e2a\u5927\u6570\u636eI/O\u95ee\u9898\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u5e76\u53d1\u60c5\u51b5\u4e0b\u3002\u5c3d\u7ba1\u50cfliburing\u8fd9\u6837\u7684\u5185\u6838\u52a0\u901fI/O\u5e93\u53ef\u80fd\u6709\u52a9\u4e8e\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u5bf9\u4e8eLLM\u68c0\u67e5\u70b9\u7684\u5b9e\u9645\u6548\u679c\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u5fae\u57fa\u51c6\u6d4b\u8bd5\u6765\u91cf\u5316\u4f7f\u7528liburing\u65f6\u7684\u5404\u79cd\u6743\u8861\uff0c\u7279\u522b\u662f\u8003\u5bdf\u5728\u7f13\u51b2\u548c\u76f4\u63a5I/O\u6761\u4ef6\u4e0b\u805a\u5408\u3001\u5bf9\u9f50\u4ee5\u53caI/O\u5408\u5e76\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u672a\u5408\u5e76\u7684\u5c0f\u7f13\u51b2\u533a\u64cd\u4f5c\u4f1a\u5bfc\u81f4\u5408\u6210\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u541e\u5410\u91cf\u51cf\u534a\uff1b\u800c\u6587\u4ef6\u7cfb\u7edf\u611f\u77e5\u7684\u805a\u5408\u80fd\u591f\u6062\u590d\u5e26\u5bbd\u5e76\u51cf\u5c11\u5143\u6570\u636e\u5f00\u9500\u3002\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u68c0\u67e5\u70b9\u5f15\u64ce\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5206\u522b\u5b9e\u73b0\u4e86\u6bd4DataStates-LLM\u9ad83.9\u500d\u3001\u6bd4TorchSnapshot\u9ad87.6\u500d\u7684\u5199\u5165\u541e\u5410\u91cf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u9700\u8981\u91c7\u7528\u4e0e\u73b0\u4ee3\u6587\u4ef6\u7cfb\u7edf\u548cI/O\u540e\u7aef\u76f8\u9002\u5e94\u7684\u805a\u5408\u548c\u5408\u5e76\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u5927\u89c4\u6a21\u6a21\u578b\u7684\u68c0\u67e5\u70b9/\u6062\u590d\u6548\u7387\u3002"}}
{"id": "2512.24246", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24246", "abs": "https://arxiv.org/abs/2512.24246", "authors": ["Jie Luo", "Wenyu Zhang", "Xinming Zhang", "Yuan Fang"], "title": "Time-Aware Adaptive Side Information Fusion for Sequential Recommendation", "comment": "10 pages. Accepted by WSDM'26", "summary": "Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a \"guide-not-mix\" architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at https://github.com/jluo00/TASIF.", "AI": {"tldr": "\u63d0\u51fa\u4e86TASIF\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u611f\u77e5\u7684\u81ea\u9002\u5e94\u4fa7\u4fe1\u606f\u878d\u5408\u3001\u7b80\u5355\u7684\u63d2\u4ef6\u5f0f\u65f6\u95f4\u8de8\u5ea6\u5212\u5206\u673a\u5236\u548c\u81ea\u9002\u5e94\u9891\u7387\u6ee4\u6ce2\u5668\u6765\u89e3\u51b3\u5e8f\u5217\u63a8\u8350\u4e2d\u5b58\u5728\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTASIF\u5728\u56db\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u5728\u5c06\u5546\u54c1\u4fa7\u4fe1\u606f\uff08\u5982\u7c7b\u522b\u548c\u54c1\u724c\uff09\u878d\u5165\u5e8f\u5217\u63a8\u8350\u65f6\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1a\u5ffd\u89c6\u65f6\u95f4\u6233\u4e2d\u7684\u7ec6\u7c92\u5ea6\u65f6\u95f4\u52a8\u6001\u3001\u5bf9\u7528\u6237\u4ea4\u4e92\u5e8f\u5217\u4e2d\u7684\u566a\u97f3\u654f\u611f\u4ee5\u53ca\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u878d\u5408\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTASIF\uff08Time-Aware Adaptive Side Information Fusion\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u4e09\u4e2a\u534f\u540c\u5de5\u4f5c\u7684\u7ec4\u4ef6\uff1a1) \u4e00\u79cd\u7b80\u5355\u7684\u65f6\u95f4\u8de8\u5ea6\u5206\u5272\u673a\u5236\uff0c\u7528\u4e8e\u6355\u6349\u5168\u5c40\u65f6\u95f4\u6a21\u5f0f\uff1b2) \u4e00\u4e2a\u81ea\u9002\u5e94\u9891\u7387\u8fc7\u6ee4\u5668\uff0c\u5229\u7528\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\u6765\u81ea\u9002\u5e94\u5730\u53bb\u566a\u7279\u5f81\u5e8f\u5217\uff1b3) \u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u4fa7\u4fe1\u606f\u878d\u5408\u5c42\uff0c\u91c7\u7528\u201c\u5f15\u5bfc\u800c\u975e\u6df7\u5408\u201d\u7684\u67b6\u6784\uff0c\u4f7f\u5c5e\u6027\u80fd\u591f\u6307\u5bfc\u6ce8\u610f\u529b\u673a\u5236\u800c\u4e0d\u4e0e\u5185\u5bb9\u8868\u793a\u9879\u5d4c\u5165\u76f8\u6df7\uff0c\u786e\u4fdd\u6df1\u5c42\u4e92\u52a8\u7684\u540c\u65f6\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTASIF\u4e0d\u4ec5\u663e\u8457\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u800c\u4e14\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u4e86\u6781\u9ad8\u7684\u6548\u7387\u3002", "conclusion": "TASIF\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5e8f\u5217\u63a8\u8350\u4e2d\u6d89\u53ca\u7684\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff0c\u5e76\u4e14\u76f8\u6bd4\u4e8e\u73b0\u6709\u6280\u672f\u5c55\u793a\u51fa\u4e86\u66f4\u4f18\u7684\u8868\u73b0\u4e0e\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2512.23745", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23745", "abs": "https://arxiv.org/abs/2512.23745", "authors": ["Hanmo You", "Zan Wang", "Zishuo Dong", "Luanqi Mo", "Jianjun Zhao", "Junjie Chen"], "title": "A Comprehensive Study of Deep Learning Model Fixing Approaches", "comment": null, "summary": "Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.", "AI": {"tldr": "\u672c\u6587\u5bf916\u79cd\u6700\u524d\u6cbf\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4fee\u590d\u65b9\u6cd5\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u6db5\u76d6\u4e86\u6a21\u578b\u7ea7\u3001\u5c42\u7ea7\u548c\u795e\u7ecf\u5143\u7ea7\u4e09\u7c7b\uff0c\u5e76\u5168\u9762\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u4fee\u590d\u6548\u679c\u3001\u9c81\u68d2\u6027\u3001\u516c\u5e73\u6027\u548c\u5411\u540e\u517c\u5bb9\u6027\u7b49\u65b9\u9762\u7684\u8868\u73b0\u3002\u7814\u7a76\u8868\u660e\uff0c\u6a21\u578b\u7ea7\u65b9\u6cd5\u7684\u4fee\u590d\u6548\u679c\u4f18\u4e8e\u5176\u4ed6\u7ea7\u522b\uff0c\u4f46\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u6301\u6240\u6709\u5176\u4ed6\u5c5e\u6027\u4e0d\u53d7\u5f71\u54cd\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "\u9274\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5728\u591a\u4e2a\u5de5\u4e1a\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u6f5c\u5728\u6545\u969c\u53ef\u80fd\u7ed9\u7528\u6237\u5e26\u6765\u7684\u91cd\u5927\u98ce\u9669\uff0c\u6587\u7ae0\u65e8\u5728\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\u5f53\u524d\u4e3b\u6d41\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4fee\u590d\u65b9\u6cd5\u6765\u7406\u89e3\u5176\u6709\u6548\u6027\u53ca\u5bf9\u5176\u4ed6\u5173\u952e\u5c5e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u7684\u65b9\u5f0f\uff0c\u9009\u53d6\u4e8616\u79cd\u4ee3\u8868\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4fee\u590d\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u88ab\u5206\u4e3a\u6a21\u578b\u7ea7\u3001\u5c42\u7ea7\u548c\u795e\u7ecf\u5143\u7ea7\u4e09\u5927\u7c7b\u3002\u4e3a\u4e86\u786e\u4fdd\u8bc4\u4ef7\u7684\u5168\u9762\u6027\u548c\u516c\u6b63\u6027\uff0c\u7814\u7a76\u4f7f\u7528\u4e86\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u3001\u6a21\u578b\u67b6\u6784\u4ee5\u53ca\u5e94\u7528\u573a\u666f\uff0c\u5728\u7edf\u4e00\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u5f00\u5c55\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6a21\u578b\u7ea7\u7684\u65b9\u6cd5\u5728\u4fee\u590d\u6548\u679c\u4e0a\u8868\u73b0\u66f4\u4f73\uff1b\u7136\u800c\uff0c\u4e0d\u5b58\u5728\u80fd\u591f\u540c\u65f6\u8fbe\u5230\u6700\u4f73\u4fee\u590d\u6027\u80fd\u3001\u63d0\u5347\u51c6\u786e\u7387\u5e76\u7ef4\u6301\u5176\u4f59\u6240\u6709\u7279\u6027\u4e0d\u53d8\u7684\u7406\u60f3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4fee\u590d\u6280\u672f\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u5f3a\u8c03\u4e86\u5b66\u672f\u754c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u5982\u4f55\u51cf\u5c11\u8fd9\u4e9b\u526f\u4f5c\u7528\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u4e5f\u4e3a\u672a\u6765\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2512.24667", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24667", "abs": "https://arxiv.org/abs/2512.24667", "authors": ["Mingyi Li", "Xiao Zhang", "Ruisheng Zheng", "Hongjian Shi", "Yuan Yuan", "Xiuzhen Cheng", "Dongxiao Yu"], "title": "Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients", "comment": null, "summary": "With the development of large-scale models, traditional distributed bilevel optimization algorithms cannot be applied directly in low-resource clients. The key reason lies in the excessive computation involved in optimizing both the lower- and upper-level functions. Thus, we present the first resource-adaptive distributed bilevel optimization framework with a second-order free hypergradient estimator, which allows each client to optimize the submodels adapted to the available resources. Due to the coupled influence of partial outer parameters x and inner parameters y, it's challenging to theoretically analyze the upper bound regarding the globally averaged hypergradient for full model parameters. The error bound of inner parameter also needs to be reformulated since the local partial training. The provable theorems show that both RABO and RAFBO can achieve an asymptotically optimal convergence rate of $O(1/\\sqrt{C_x^{\\ast}Q})$, which is dominated by the minimum coverage of the outer parameter $C_x^{\\ast}$. Extensive experiments on two different tasks demonstrate the effectiveness and computation efficiency of our proposed methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u8d44\u6e90\u81ea\u9002\u5e94\u7684\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u91c7\u7528\u65e0\u4e8c\u9636\u8d85\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u4f7f\u6bcf\u4e2a\u5ba2\u6237\u7aef\u80fd\u591f\u6839\u636e\u53ef\u7528\u8d44\u6e90\u4f18\u5316\u5b50\u6a21\u578b\u3002\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86RABO\u548cRAFBO\u65b9\u6cd5\u80fd\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u6536\u655b\u7387\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u7684\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u5728\u8d44\u6e90\u6709\u9650\u7684\u5ba2\u6237\u7aef\u4e0a\u76f4\u63a5\u5e94\u7528\u9047\u5230\u4e86\u6311\u6218\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u540c\u65f6\u4f18\u5316\u4e0b\u5c42\u548c\u4e0a\u5c42\u51fd\u6570\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u8d44\u6e90\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u65e0\u9700\u4e8c\u9636\u5bfc\u6570\u7684\u8d85\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u5141\u8bb8\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6839\u636e\u81ea\u8eab\u8d44\u6e90\u60c5\u51b5\u6765\u4f18\u5316\u9002\u5408\u7684\u5b50\u6a21\u578b\u3002\u9488\u5bf9\u5185\u5916\u53c2\u6570\u90e8\u5206\u8026\u5408\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86\u5185\u53c2\u6570\u7684\u8bef\u5dee\u754c\u9650\u3002", "result": "\u901a\u8fc7\u53ef\u8bc1\u660e\u7684\u5b9a\u7406\u8868\u660e\uff0c\u65e0\u8bba\u662fRABO\u8fd8\u662fRAFBO\u65b9\u6cd5\u90fd\u80fd\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u7684\u6536\u655b\u901f\u5ea6$O(1/\\sqrt{C_x^{\\ast}Q})$\uff0c\u8fd9\u4e00\u7ed3\u679c\u53d7\u5230\u5916\u53c2\u6570\u6700\u5c0f\u8986\u76d6$C_x^{\\ast}$\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u5728\u4e24\u4e2a\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u8d44\u6e90\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4f20\u7edf\u53cc\u5c42\u4f18\u5316\u7b97\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u7684\u95ee\u9898\uff0c\u8fd8\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.24268", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24268", "abs": "https://arxiv.org/abs/2512.24268", "authors": ["Pankayaraj Pathmanathan", "Michael-Andrei Panaitescu-Liess", "Cho-Yu Jason Chiang", "Furong Huang"], "title": "RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation", "comment": "Published at AAAI 2026 Workshop on New Frontiers in Information Retrieval [Oral]", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\u4e2d\u7684\u8bed\u6599\u5e93\u4e2d\u6bd2\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u68c0\u7d22\u9636\u6bb5\u9632\u5fa1\u63aa\u65bd\uff1aRAGPart\u548cRAGMask\u3002\u8fd9\u4e9b\u65b9\u6cd5\u65e8\u5728\u51cf\u8f7b\u6076\u610f\u6587\u6863\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u6027\u6761\u4ef6\u4e0b\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u7531\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u66b4\u9732\u51fa\u9762\u5bf9\u8bed\u6599\u5e93\u4e2d\u6bd2\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5bf9\u6297\u8fd9\u79cd\u5a01\u80c1\uff0c\u65e8\u5728\u51cf\u5c11\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\u4fdd\u6301\u7cfb\u7edf\u5728\u6b63\u5e38\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u76f4\u63a5\u4f5c\u7528\u4e8e\u68c0\u7d22\u5668\u4e0a\u7684\u8f7b\u91cf\u7ea7\u9632\u5fa1\u673a\u5236\uff1aRAGPart\u901a\u8fc7\u5229\u7528\u5bc6\u96c6\u68c0\u7d22\u5668\u8bad\u7ec3\u52a8\u6001\uff0c\u5e76\u91c7\u7528\u6587\u6863\u5206\u533a\u6765\u7f13\u89e3\u4e2d\u6bd2\u70b9\u5f71\u54cd\uff1b\u800cRAGMask\u5219\u901a\u8fc7\u8bc6\u522b\u57fa\u4e8e\u76ee\u6807\u4ee4\u724c\u906e\u853d\u4e0b\u663e\u8457\u76f8\u4f3c\u5ea6\u53d8\u5316\u7684\u53ef\u7591\u4ee4\u724c\u6765\u8fdb\u884c\u9632\u5fa1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3001\u56db\u79cd\u4e2d\u6bd2\u7b56\u7565\u4ee5\u53ca\u56db\u79cd\u6700\u5148\u8fdb\u7684\u68c0\u7d22\u5668\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u9632\u5fa1\u63aa\u65bd\u80fd\u591f\u4e00\u81f4\u5730\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5728\u975e\u6076\u610f\u6761\u4ef6\u4e0b\u7ef4\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u68c0\u7d22\u9636\u6bb5\u9632\u5fa1\u63aa\u65bd\u7684\u6709\u6548\u6027\u548c\u5c40\u9650\u6027\uff0c\u4e3a\u5b9e\u73b0\u66f4\u52a0\u7a33\u5065\u7684RAG\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2512.23746", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23746", "abs": "https://arxiv.org/abs/2512.23746", "authors": ["Wei Li", "Yan Zou", "Yixin Liang", "Jos\u00e9 Moura", "Shawn Blanton"], "title": "DEFT: Differentiable Automatic Test Pattern Generation", "comment": null, "summary": "Modern IC complexity drives test pattern growth, with the majority of patterns targeting a small set of hard-to-detect (HTD) faults. This motivates new ATPG algorithms to improve test effectiveness specifically for HTD faults. This paper presents DEFT (Differentiable Automatic Test Pattern Generation), a new ATPG approach that reformulates the discrete ATPG problem as a continuous optimization task. DEFT introduces a mathematically grounded reparameterization that aligns the expected continuous objective with discrete fault-detection semantics, enabling reliable gradient-based pattern generation. To ensure scalability and stability on deep circuit graphs, DEFT integrates a custom CUDA kernel for efficient forward-backward propagation and applies gradient normalization to mitigate vanishing gradients. Compared to a leading commercial tool on two industrial benchmarks, DEFT improves HTD fault detection by 21.1% and 48.9% on average under the same pattern budget and comparable runtime. DEFT also supports practical ATPG settings such as partial assignment pattern generation, producing patterns with 19.3% fewer 0/1 bits while still detecting 35% more faults. These results indicate DEFT is a promising and effective ATPG engine, offering a valuable complement to existing heuristic.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u6d4b\u8bd5\u6a21\u5f0f\u751f\u6210\u65b9\u6cd5DEFT\uff0c\u901a\u8fc7\u5c06\u79bb\u6563\u7684ATPG\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u8fde\u7eed\u4f18\u5316\u4efb\u52a1\u6765\u63d0\u9ad8\u5bf9\u96be\u4ee5\u68c0\u6d4b\u6545\u969c\u7684\u6d4b\u8bd5\u6548\u679c\u3002DEFT\u5728\u4e24\u4e2a\u5de5\u4e1a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u9886\u5148\u5546\u4e1a\u5de5\u5177\u663e\u8457\u63d0\u9ad8\u4e86\u96be\u68c0\u6545\u969c\u7684\u68c0\u6d4b\u7387\uff0c\u5e76\u4e14\u652f\u6301\u5b9e\u9645ATPG\u8bbe\u7f6e\u5982\u90e8\u5206\u5206\u914d\u6a21\u5f0f\u751f\u6210\uff0c\u663e\u793a\u51fa\u4f5c\u4e3a\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u6709\u4ef7\u503c\u7684\u8865\u5145\u7684\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u73b0\u4ee3\u96c6\u6210\u7535\u8def\u590d\u6742\u6027\u5bfc\u81f4\u6d4b\u8bd5\u6a21\u5f0f\u589e\u957f\uff0c\u5927\u591a\u6570\u6a21\u5f0f\u9488\u5bf9\u4e00\u5c0f\u90e8\u5206\u96be\u4ee5\u68c0\u6d4b\uff08HTD\uff09\u7684\u6545\u969c\u3002\u8fd9\u4fc3\u4f7f\u5f00\u53d1\u65b0\u7684ATPG\u7b97\u6cd5\u4ee5\u4e13\u95e8\u6539\u5584\u5bf9HTD\u6545\u969c\u7684\u6d4b\u8bd5\u6548\u679c\u3002", "method": "DEFT\uff08\u53ef\u5fae\u5206\u81ea\u52a8\u6d4b\u8bd5\u6a21\u5f0f\u751f\u6210\uff09\uff0c\u901a\u8fc7\u6570\u5b66\u4e0a\u5408\u7406\u7684\u91cd\u53c2\u6570\u5316\u5c06\u79bb\u6563ATPG\u95ee\u9898\u8f6c\u6362\u6210\u8fde\u7eed\u4f18\u5316\u4efb\u52a1\uff0c\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u81ea\u5b9a\u4e49CUDA\u5185\u6838\u4ee5\u786e\u4fdd\u6df1\u5ea6\u7535\u8def\u56fe\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u5e94\u7528\u68af\u5ea6\u5f52\u4e00\u5316\u6765\u7f13\u89e3\u6d88\u5931\u68af\u5ea6\u95ee\u9898\u3002", "result": "\u4e0e\u9886\u5148\u7684\u5546\u4e1a\u5de5\u5177\u76f8\u6bd4\uff0c\u5728\u76f8\u540c\u7684\u6a21\u5f0f\u9884\u7b97\u548c\u76f8\u5f53\u7684\u8fd0\u884c\u65f6\u95f4\u4e0b\uff0cDEFT\u5728\u4e24\u4e2a\u5de5\u4e1a\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u5347\u4e8621.1%\u548c48.9%\u7684HTD\u6545\u969c\u68c0\u6d4b\u7387\uff1b\u6b64\u5916\uff0c\u5728\u652f\u6301\u5b9e\u9645ATPG\u8bbe\u7f6e\u5982\u90e8\u5206\u5206\u914d\u6a21\u5f0f\u751f\u6210\u65f6\uff0c\u4ea7\u751f\u7684\u6a21\u5f0f0/1\u4f4d\u51cf\u5c11\u4e8619.3%\uff0c\u540c\u65f6\u4ecd\u80fd\u68c0\u6d4b\u5230\u66f4\u591a\u7684\u6545\u969c\u3002", "conclusion": "DEFT\u662f\u4e00\u79cd\u6709\u524d\u9014\u4e14\u6709\u6548\u7684ATPG\u5f15\u64ce\uff0c\u80fd\u591f\u63d0\u4f9b\u6bd4\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u66f4\u4f18\u7684\u7ed3\u679c\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u96be\u4ee5\u68c0\u6d4b\u7684\u6545\u969c\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2512.24824", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2512.24824", "abs": "https://arxiv.org/abs/2512.24824", "authors": ["Yuzhen Chen", "Bin Yao"], "title": "LMG Index: A Robust Learned Index for Multi-Dimensional Performance Balance", "comment": null, "summary": "Index structures are fundamental for efficient query processing on large-scale datasets. Learned indexes model the indexing process as a prediction problem to overcome the inherent trade-offs of traditional indexes. However, most existing learned indexes optimize only for limited objectives like query latency or space usage, neglecting other practical evaluation dimensions such as update efficiency and stability. Moreover, many learned indexes rely on assumptions about data distributions or workloads, lacking theoretical guarantees when facing unknown or evolving scenarios, which limits their generality in real-world systems.\n  In this paper, we propose LMIndex, a robust framework for learned indexing that leverages a efficient query/update top-layer structure (theoretically $O(1)$ when the key type is fixed) and a efficient optimal error threshold training algorithm (approach $O(1)$ in practice). Building upon this, we develop LMG (LMIndex with gaps), a variant employing a novel gap allocation strategy to enhance update performance and maintain stability under dynamic workloads. Extensive evaluations show that LMG achieves competitive or leading performance, including bulk loading (up to 8.25$\\times$ faster), point queries (up to 1.49$\\times$ faster), range queries (up to 4.02$\\times$ faster than B+Tree), update (up to 1.5$\\times$ faster on read-write workloads), stability (up to 82.59$\\times$ lower coefficient of variation), and space usage (up to 1.38$\\times$ smaller). These results demonstrate that LMG effectively breaks the multi-dimensional performance trade-offs inherent in state-of-the-art approaches, offering a balanced and versatile framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LMIndex\uff0c\u4e00\u79cd\u9c81\u68d2\u7684\u5b66\u4e60\u7d22\u5f15\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u67e5\u8be2/\u66f4\u65b0\u9876\u5c42\u7ed3\u6784\u548c\u6700\u4f18\u8bef\u5dee\u9608\u503c\u8bad\u7ec3\u7b97\u6cd5\u6765\u4f18\u5316\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1\u7684LMG\u53d8\u4f53\u91c7\u7528\u65b0\u7684\u95f4\u9699\u5206\u914d\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u66f4\u65b0\u6027\u80fd\u5e76\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660eLMG\u5728\u6279\u91cf\u52a0\u8f7d\u3001\u70b9\u67e5\u8be2\u3001\u8303\u56f4\u67e5\u8be2\u3001\u66f4\u65b0\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u7a7a\u95f4\u4f7f\u7528\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u6709\u6548\u6253\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u591a\u7ef4\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5b66\u4e60\u578b\u7d22\u5f15\u5927\u591a\u53ea\u9488\u5bf9\u6709\u9650\u7684\u76ee\u6807\u8fdb\u884c\u4f18\u5316\uff0c\u4f8b\u5982\u67e5\u8be2\u5ef6\u8fdf\u6216\u7a7a\u95f4\u4f7f\u7528\uff0c\u800c\u5ffd\u7565\u4e86\u5176\u4ed6\u5b9e\u9645\u8bc4\u4f30\u7ef4\u5ea6\u5982\u66f4\u65b0\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u8bb8\u591a\u5b66\u4e60\u578b\u7d22\u5f15\u4f9d\u8d56\u4e8e\u5173\u4e8e\u6570\u636e\u5206\u5e03\u6216\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5047\u8bbe\uff0c\u5728\u9762\u5bf9\u672a\u77e5\u6216\u4e0d\u65ad\u53d8\u5316\u7684\u60c5\u51b5\u65f6\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u4e2d\u7684\u901a\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLMIndex\u7684\u5b66\u4e60\u7d22\u5f15\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u9ad8\u6548\u7684\u67e5\u8be2/\u66f4\u65b0\u9876\u5c42\u7ed3\u6784\uff08\u5f53\u952e\u7c7b\u578b\u56fa\u5b9a\u65f6\u7406\u8bba\u4e0a\u4e3a$O(1)$\uff09\u548c\u4e00\u4e2a\u63a5\u8fd1$O(1)$\u7684\u5b9e\u9645\u64cd\u4f5c\u6548\u7387\u7684\u6700\u4f73\u8bef\u5dee\u9608\u503c\u8bad\u7ec3\u7b97\u6cd5\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u5f00\u53d1\u4e86LMG\uff08\u5e26\u6709\u95f4\u9699\u7684LMIndex\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u91c7\u7528\u65b0\u9896\u7684\u95f4\u9699\u5206\u914d\u7b56\u7565\u4ee5\u589e\u5f3a\u66f4\u65b0\u6027\u80fd\u5e76\u4fdd\u6301\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u7a33\u5b9a\u6027\u7684\u53d8\u4f53\u3002", "result": "\u5e7f\u6cdb\u7684\u8bc4\u4f30\u663e\u793a\uff0cLMG\u5728\u591a\u4e2a\u65b9\u9762\u5b9e\u73b0\u4e86\u7ade\u4e89\u6216\u9886\u5148\u7684\u6027\u80fd\uff1a\u5305\u62ec\u6279\u91cf\u52a0\u8f7d\u901f\u5ea6\u63d0\u9ad8\u4e86\u6700\u591a8.25\u500d\u3001\u70b9\u67e5\u8be2\u901f\u5ea6\u63d0\u5347\u4e86\u81f3\u591a1.49\u500d\u3001\u8303\u56f4\u67e5\u8be2\u6bd4B+\u6811\u5feb\u8fbe4.02\u500d\u3001\u8bfb\u5199\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684\u66f4\u65b0\u901f\u5ea6\u5feb\u4e86\u9ad8\u8fbe1.5\u500d\u3001\u7a33\u5b9a\u6027\u4e0a\u53d8\u5f02\u7cfb\u6570\u964d\u4f4e\u4e86\u6700\u9ad882.59\u500d\u3001\u4ee5\u53ca\u7a7a\u95f4\u4f7f\u7528\u51cf\u5c11\u4e86\u6700\u591a1.38\u500d\u3002", "conclusion": "LMG\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u591a\u7ef4\u5ea6\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u8861\u4e14\u591a\u529f\u80fd\u7684\u6846\u67b6\u3002"}}
{"id": "2512.23748", "categories": ["cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23748", "abs": "https://arxiv.org/abs/2512.23748", "authors": ["Haley Rosso", "Talea Mayo"], "title": "A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios", "comment": null, "summary": "For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters $\\mathbf\u03b8$ given observed data $\\mathbf{x}_{\\text{o}}$. Recent work has brought attention to diffusion models -- a type of generative model rooted in score matching and reverse-time stochastic dynamics -- as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6a21\u62df\u57fa\u7840\u63a8\u7406\uff08SBI\uff09\u65b9\u6cd5\uff0c\u4ece\u57fa\u672c\u539f\u7406\u5230\u5b9e\u9645\u5e94\u7528\u3002\u6587\u7ae0\u9996\u5148\u56de\u987e\u4e86\u6269\u6563\u6a21\u578b\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5e76\u89e3\u91ca\u4e86\u5982\u4f55\u901a\u8fc7\u6761\u4ef6\u5206\u6570\u5b9e\u73b0\u65e0\u4f3c\u7136\u540e\u9a8c\u62bd\u6837\u3002\u63a5\u7740\u5206\u6790\u4e86\u6269\u6563\u6a21\u578b\u5728\u5904\u7406\u79d1\u5b66\u6570\u636e\u5e38\u89c1\u95ee\u9898\uff08\u5982\u6a21\u578b\u9519\u914d\u3001\u975e\u7ed3\u6784\u5316\u6216\u65e0\u9650\u7ef4\u89c2\u6d4b\u4ee5\u53ca\u7f3a\u5931\u6570\u636e\uff09\u65f6\u76f8\u8f83\u4e8e\u6807\u51c6\u5316\u6d41\u7684\u4f18\u52bf\u4e0e\u6743\u8861\u3002\u6b64\u5916\uff0c\u8fd8\u8ba8\u8bba\u4e86\u8be5\u9886\u57df\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u7279\u522b\u662f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5728\u6982\u7387\u5730\u8d28\u7269\u7406\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002", "motivation": "\u5bf9\u4e8e\u590d\u6742\u7684\u4eff\u771f\u95ee\u9898\uff0c\u7531\u4e8e\u4f3c\u7136\u51fd\u6570\u96be\u4ee5\u5904\u7406\uff0c\u901a\u5e38\u65e0\u6cd5\u4f7f\u7528\u7ecf\u5178\u7684\u57fa\u4e8e\u4f3c\u7136\u7684\u65b9\u6cd5\u6765\u63a8\u65ad\u611f\u5174\u8da3\u7684\u79d1\u5b66\u53c2\u6570\u3002\u57fa\u4e8e\u4eff\u771f\u7684\u63a8\u7406(SBI)\u65b9\u6cd5\u901a\u8fc7\u76f4\u63a5\u5229\u7528\u6765\u81ea\u6a21\u62df\u5668\u7684\u6837\u672c\u6765\u5b66\u4e60\u7ed9\u5b9a\u89c2\u6d4b\u6570\u636e$\\mathbf{x}_{\\text{o}}$\u4e0b\u7684\u53c2\u6570$\\mathbf\u03b8$\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u4ece\u800c\u907f\u514d\u4e86\u663e\u5f0f\u4f3c\u7136\u7684\u9700\u6c42\u3002\u6700\u8fd1\u7684\u5de5\u4f5c\u5f15\u8d77\u4e86\u5bf9\u6269\u6563\u6a21\u578b\u7684\u5173\u6ce8\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u5339\u914d\u548c\u53cd\u5411\u65f6\u95f4\u968f\u673a\u52a8\u529b\u5b66\u7684\u751f\u6210\u6a21\u578b\u2014\u2014\u4f5c\u4e3a\u6267\u884cSBI\u4efb\u52a1\u7684\u4e00\u4e2a\u7075\u6d3b\u6846\u67b6\u3002", "method": "\u672c\u6587\u9996\u5148\u56de\u987e\u4e86\u6269\u6563\u5efa\u6a21\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5305\u62ec\u524d\u5411\u566a\u58f0\u6dfb\u52a0\u3001\u53cd\u5411\u65f6\u95f4SDE/ODE\u3001\u6982\u7387\u6d41\u53ca\u53bb\u566a\u5206\u6570\u5339\u914d\uff0c\u5e76\u89e3\u91ca\u4e86\u6761\u4ef6\u5206\u6570\u5982\u4f55\u4f7f\u65e0\u4f3c\u7136\u540e\u9a8c\u62bd\u6837\u6210\u4e3a\u53ef\u80fd\u3002\u968f\u540e\u63a2\u8ba8\u4e86\u6269\u6563\u6a21\u578b\u5982\u4f55\u89e3\u51b3\u795e\u7ecf\u540e\u9a8c/\u4f3c\u7136\u4f30\u8ba1\u4e2d\u6807\u51c6\u5316\u6d41\u5b58\u5728\u7684\u75db\u70b9\uff0c\u540c\u65f6\u5f15\u5165\u65b0\u7684\u6743\u8861\uff08\u4f8b\u5982\u8fed\u4ee3\u91c7\u6837\u6210\u672c\uff09\u3002\u91cd\u70b9\u5728\u4e8e\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684SBI\u5728\u79d1\u5b66\u6570\u636e\u5e38\u89c1\u7684\u975e\u7406\u60f3\u6761\u4ef6\u4e0b\uff08\u5982\u6a21\u578b\u9519\u914d\u3001\u975e\u7ed3\u6784\u5316\u6216\u65e0\u9650\u7ef4\u5ea6\u89c2\u5bdf\u3001\u6570\u636e\u7f3a\u5931\u7b49\uff09\u7684\u8868\u73b0\u7a33\u5065\u6027\u3002", "result": "\u6587\u7ae0\u7efc\u5408\u4e86\u4ece\u859b\u5b9a\u8c14\u6865\u516c\u5f0f\u51fa\u53d1\u7684\u57fa\u7840\u65b9\u6cd5\u3001\u6761\u4ef6\u548c\u987a\u5e8f\u540e\u9a8c\u62bd\u6837\u5668\u3001\u9002\u7528\u4e8e\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u644a\u9500\u67b6\u6784\u4ee5\u53ca\u63a8\u7406\u65f6\u5148\u9a8c\u9002\u5e94\u7b49\u6280\u672f\u3002\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4e86\u7edf\u4e00\u7684\u7b26\u53f7\u4f53\u7cfb\uff0c\u5e76\u5f3a\u8c03\u4e86\u51c6\u786e\u540e\u9a8c\u6240\u9700\u7684\u6761\u4ef6\u4e0e\u6ce8\u610f\u4e8b\u9879\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4ee5\u8ba8\u8bba\u672a\u89e3\u51b3\u95ee\u9898\u7ed3\u5c3e\uff0c\u7279\u522b\u5173\u6ce8\u4e8e\u90a3\u4e9b\u53ef\u80fd\u53d7\u76ca\u4e8e\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684SBI\u7684\u6982\u7387\u5730\u8d28\u7269\u7406\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5e94\u7528\u3002"}}
{"id": "2512.24914", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24914", "abs": "https://arxiv.org/abs/2512.24914", "authors": ["Vinoth Punniyamoorthy", "Akash Kumar Agarwal", "Bikesh Kumar", "Abhirup Mazumder", "Kabilan Kannan", "Sumit Saha"], "title": "AI-Driven Cloud Resource Optimization for Multi-Cluster Environments", "comment": null, "summary": "Modern cloud-native systems increasingly rely on multi-cluster deployments to support scalability, resilience, and geographic distribution. However, existing resource management approaches remain largely reactive and cluster-centric, limiting their ability to optimize system-wide behavior under dynamic workloads. These limitations result in inefficient resource utilization, delayed adaptation, and increased operational overhead across distributed environments. This paper presents an AI-driven framework for adaptive resource optimization in multi-cluster cloud systems. The proposed approach integrates predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management across clusters. By analyzing cross-cluster telemetry and historical execution patterns, the framework dynamically adjusts resource allocation to balance performance, cost, and reliability objectives. A prototype implementation demonstrates improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional reactive approaches. The results highlight the effectiveness of intelligent, self-adaptive infrastructure management as a key enabler for scalable and resilient cloud platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u81ea\u9002\u5e94\u8d44\u6e90\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u96c6\u7fa4\u4e91\u7cfb\u7edf\u4e2d\u7684\u4e3b\u52a8\u534f\u8c03\u8d44\u6e90\u7ba1\u7406\u3002\u901a\u8fc7\u5206\u6790\u8de8\u96c6\u7fa4\u9065\u6d4b\u548c\u5386\u53f2\u6267\u884c\u6a21\u5f0f\uff0c\u8be5\u6846\u67b6\u52a8\u6001\u8c03\u6574\u8d44\u6e90\u914d\u7f6e\u4ee5\u5e73\u8861\u6027\u80fd\u3001\u6210\u672c\u548c\u53ef\u9760\u6027\u76ee\u6807\u3002\u539f\u578b\u5b9e\u73b0\u8868\u660e\u4e0e\u4f20\u7edf\u53cd\u5e94\u5f0f\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8d44\u6e90\u6548\u7387\uff0c\u52a0\u5feb\u4e86\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u671f\u95f4\u7684\u7a33\u5b9a\u901f\u5ea6\uff0c\u5e76\u51cf\u5c11\u4e86\u6027\u80fd\u53d8\u5316\u3002", "motivation": "\u5f53\u524d\u7684\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u4e3b\u8981\u4e3a\u88ab\u52a8\u4e14\u4ee5\u5355\u4e2a\u96c6\u7fa4\u4e3a\u4e2d\u5fc3\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u4f18\u5316\u6574\u4e2a\u7cfb\u7edf\u884c\u4e3a\u7684\u80fd\u529b\u3002\u8fd9\u6837\u7684\u5c40\u9650\u6027\u5bfc\u81f4\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u4e0b\u3001\u9002\u5e94\u5ef6\u8fdf\u4ee5\u53ca\u8fd0\u8425\u5f00\u9500\u589e\u52a0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u9884\u6d4b\u5b66\u4e60\u3001\u7b56\u7565\u611f\u77e5\u51b3\u7b56\u5236\u5b9a\u53ca\u6301\u7eed\u53cd\u9988\u673a\u5236\u7684\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0\u8de8\u96c6\u7fa4\u7684\u4e3b\u52a8\u548c\u534f\u8c03\u8d44\u6e90\u7ba1\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6848\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u54cd\u5e94\u5f0f\u65b9\u6cd5\uff0c\u5728\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u540c\u65f6\u80fd\u591f\u5728\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u52a8\u65f6\u66f4\u5feb\u8fbe\u5230\u7a33\u5b9a\u72b6\u6001\uff0c\u5e76\u964d\u4f4e\u4e86\u6027\u80fd\u6ce2\u52a8\u5e45\u5ea6\u3002", "conclusion": "\u667a\u80fd\u81ea\u9002\u5e94\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u4f5c\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u548c\u5f39\u6027\u7684\u4e91\u5e73\u53f0\u7684\u5173\u952e\u63a8\u52a8\u56e0\u7d20\uff0c\u5176\u6709\u6548\u6027\u5f97\u5230\u4e86\u8bc1\u660e\u3002"}}
{"id": "2512.23747", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23747", "abs": "https://arxiv.org/abs/2512.23747", "authors": ["Abhinav Parmar", "Abhisek Panigrahi", "Abhishek Kumar Dwivedi", "Abhishek Bhattacharya", "Adarsh Ramachandra", "Aditya Choudhary", "Aditya Garg", "Aditya Raj", "Alankrit Bhatt", "Alpesh Yadav", "Anant Vishnu", "Ananthu Pillai", "Ankush Kumar", "Aryan Patnaik", "Aswatha Narayanan S", "Avanish Raj Singh", "Bhavya Shree Gadda", "Brijesh Pankajbhai Kachhadiya", "Buggala Jahnavi", "Chidurala Nithin Krishna", "Chintan Shah", "Chunduru Akshaya", "Debarshi Banerjee", "Debrup Dey", "Deepa R.", "Deepika B G", "Faiz ur Rahman", "Gagan Gayari", "Gudhi Jagadeesh Kumar Naidu", "Gursimar Singh", "Harshal Tyagi", "Harshini K", "James Mani Vathalloor", "Jayarama Nettar", "Jayashree Gajjam", "Joe Walter Sugil George", "Kamalakara Sri Krishna Tadepalli", "Kamalkumar Rathinasamy", "Karan Chaurasia", "Karthikeyan S", "Kashish Arora", "Kaushal Desai", "Khushboo Buwade", "Kiran Manjrekar", "Malikireddy Venkata Sai Likhitha", "Manjunath A", "Mitali Mahavir Bedmutha", "Mohammed Rafee Tarafdar", "Nikhil Tiwari", "Nikitha K Gigi", "Pavan Ravikumar", "Pendyala Swarnanjali", "Piyush Anand", "Prakash Chandrasekar", "Prasanna Bhalchandra Gawade", "Prasanth Sivan", "Preeti Khurana", "Priyanshi Babbar", "Rajab Ali Mondal", "Rajesh Kumar Vissapragada", "Rajeshwari Ganesan", "Rajeswari Koppisetti", "Ramjee R.", "Ramkumar Thiruppathisamy", "Rani G. S.", "S Reka", "Samarth Gupta", "Sandeep Reddy Kothakota", "Sarathy K", "Sathyanarayana Sampath Kumar", "Saurabh Kumar", "Shashank Khasare", "Shenbaga Devi Venkatesh Kumar", "Shiva Rama Krishna Parvatham", "Shoeb Shaikh", "Shrishanmathi A", "Shubham Pathak", "Sree Samhita Koppaka", "Sreenivasa Raghavan K S", "Sreeram Venkatasubramanian", "Suprabha Desai Bojja", "Swetha R", "Syed Ahmed", "Chinmai Harshitha Thota", "Tushar Yadav", "Veeravelly Kusumitha", "V V S S Prasanth Patnaik", "Vidya Sri Sesetti", "Vijayakeerthi K", "Vikram Raj Bakshi", "Vinay K K", "Vinoth Kumar Loganathan", "Vipin Tiwari", "Vivek Kumar Shrivastav", "V Venkata Sri Datta Charan", "Wasim Akhtar Khan"], "title": "State-of-the-art Small Language Coder Model: Mify-Coder", "comment": null, "summary": "We present Mify-Coder, a 2.5B-parameter code model trained on 4.2T tokens using a compute-optimal strategy built on the Mify-2.5B foundation model. Mify-Coder achieves comparable accuracy and safety while significantly outperforming much larger baseline models on standard coding and function-calling benchmarks, demonstrating that compact models can match frontier-grade models in code generation and agent-driven workflows. Our training pipeline combines high-quality curated sources with synthetic data generated through agentically designed prompts, refined iteratively using enterprise-grade evaluation datasets. LLM-based quality filtering further enhances data density, enabling frugal yet effective training. Through disciplined exploration of CPT-SFT objectives, data mixtures, and sampling dynamics, we deliver frontier-grade code intelligence within a single continuous training trajectory. Empirical evidence shows that principled data and compute discipline allow smaller models to achieve competitive accuracy, efficiency, and safety compliance. Quantized variants of Mify-Coder enable deployment on standard desktop environments without requiring specialized hardware.", "AI": {"tldr": "Mify-Coder, a 2.5B-parameter model, achieves high accuracy and safety on coding tasks, outperforming larger models through efficient training with high-quality data and LLM-based quality filtering. It can be deployed on standard desktops.", "motivation": "The motivation is to demonstrate that a compact model, Mify-Coder, can match or even outperform much larger models in code generation and function-calling benchmarks while maintaining efficiency and safety compliance, making it accessible for deployment on standard computing environments.", "method": "Mify-Coder was trained using a compute-optimal strategy on 4.2T tokens, based on the Mify-2.5B foundation. The process involved combining high-quality curated sources with synthetic data, iteratively refined using enterprise-grade evaluation datasets, and applying LLM-based quality filtering. The training also explored CPT-SFT objectives, data mixtures, and sampling dynamics to enhance performance.", "result": "Mify-Coder showed comparable accuracy and safety to larger baseline models, while significantly outperforming them on coding and function-calling benchmarks. Additionally, quantized versions of Mify-Coder were successfully deployed on standard desktops without needing specialized hardware.", "conclusion": "Through disciplined use of data and compute resources, smaller models like Mify-Coder can achieve competitive results in terms of accuracy, efficiency, and safety, making advanced code intelligence more widely accessible."}}
{"id": "2512.23749", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23749", "abs": "https://arxiv.org/abs/2512.23749", "authors": ["Amin Sadri", "M Maruf Hossain"], "title": "Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents", "comment": "16 pages, 3 figures", "summary": "Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \\vspace*{6pt}\n  Contribution: In this paper, we present the Coordinate Matrix Machine (CM$^2$). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern \"Red AI\" trends rely on massive pre-training and energy-intensive GPU infrastructure, CM$^2$ is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural \"important features\" a human would consider, allowing it to classify very similar documents using only one sample per class.\n  Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM$^2$ offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5750\u6807\u77e9\u9635\u673a\uff08CM$^2$\uff09\u7684\u5c0f\u578b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u6587\u6863\u7ed3\u6784\u5e76\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u6587\u6863\u5206\u7c7b\u6765\u589e\u5f3a\u4eba\u7c7b\u667a\u80fd\u3002\u4e0e\u9700\u8981\u5927\u91cf\u9884\u8bad\u7ec3\u548c\u5f3a\u5927GPU\u652f\u6301\u7684\u73b0\u4ee3'\u7ea2\u8272AI'\u8d8b\u52bf\u4e0d\u540c\uff0cCM$^2$\u4f5c\u4e3a\u4e00\u79cd\u7eff\u8272AI\u89e3\u51b3\u65b9\u6848\uff0c\u4ec5\u9700\u6bcf\u4e2a\u7c7b\u522b\u4e00\u4e2a\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u4eba\u7c7b\u7ea7\u522b\u7684\u6982\u5ff5\u5b66\u4e60\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u3001\u73af\u4fdd\u6027\u3001\u8ba1\u7b97\u6548\u7387\u7b49\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002", "motivation": "\u4f5c\u8005\u6307\u51fa\uff0c\u4eba\u7c7b\u80fd\u591f\u4ece\u5355\u4e2a\u4f8b\u5b50\u4e2d\u5b66\u4e60\u65b0\u6982\u5ff5\uff0c\u800c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u901a\u5e38\u9700\u8981\u6570\u767e\u4e2a\u6837\u672c\u6765\u5b66\u4e60\u5355\u4e00\u6982\u5ff5\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u8fd9\u79cd\u9ad8\u6548\u5b66\u4e60\u65b9\u5f0f\u7684\u65b0\u6a21\u578b\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u8d44\u6e90\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u5750\u6807\u77e9\u9635\u673a\uff08CM$^2$\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u8bc6\u522b\u6587\u6863\u7ed3\u6784\u7279\u5f81\u7684\u5c0f\u578b\u6a21\u578b\u3002\u5b83\u4e13\u6ce8\u4e8e\u63d0\u53d6\u4eba\u7c7b\u53ef\u80fd\u8ba4\u4e3a\u91cd\u8981\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u8be6\u5c3d\u7684\u8bed\u4e49\u5411\u91cf\u6216\u590d\u6742\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCM$^2$\u4e0d\u4ec5\u80fd\u591f\u5728\u975e\u5e38\u5c11\u7684\u6570\u636e\u4e0b\u8fbe\u5230\u9ad8\u7cbe\u5ea6\uff08\u5355\u6837\u672c\u5b66\u4e60\uff09\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u51e0\u4f55\u548c\u7ed3\u6784\u667a\u80fd\u3001\u73af\u5883\u53ef\u6301\u7eed\u6027\u3001\u4e13\u4e3a\u4ec5CPU\u73af\u5883\u4f18\u5316\u3001\u5185\u5728\u53ef\u89e3\u91ca\u6027\u3001\u5feb\u901f\u8ba1\u7b97\u53ca\u4f4e\u5ef6\u8fdf\u7b49\u4f18\u70b9\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u8fd8\u8868\u73b0\u51fa\u5bf9\u6297\u4e0d\u5e73\u8861\u7c7b\u522b\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "conclusion": "\u5750\u6807\u77e9\u9635\u673a\uff08CM$^2$\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u9965\u997f\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6587\u6863\u5206\u7c7b\u4efb\u52a1\u800c\u8a00\u3002\u4f5c\u4e3a\u7eff\u8272AI\u7684\u4e00\u4e2a\u5b9e\u4f8b\uff0cCM$^2$\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u66f4\u52a0\u73af\u4fdd\u548c\u6210\u672c\u6548\u76ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24366", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24366", "abs": "https://arxiv.org/abs/2512.24366", "authors": ["Ben Kabongo", "Vincent Guigue"], "title": "On the Factual Consistency of Text-based Explainable Recommendation Models", "comment": "13 pages, 2 figures, 4 tables", "summary": "Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u57fa\u4e8e\u6587\u672c\u7684\u53ef\u89e3\u91ca\u63a8\u8350\u7cfb\u7edf\u4e2d\u4e8b\u5b9e\u4e00\u81f4\u6027\u7684\u7efc\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u4ece\u8bc4\u8bba\u4e2d\u63d0\u53d6\u539f\u5b50\u89e3\u91ca\u8bed\u53e5\u6765\u6784\u5efa\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65b9\u6cd5\u7684\u5bf9\u9f50\u5ea6\u91cf\u6807\u51c6\u4ee5\u8bc4\u4f30\u751f\u6210\u89e3\u91ca\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u76f8\u5173\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u4fdd\u6301\u9ad8\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u540c\u65f6\uff0c\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u53ef\u89e3\u91ca\u63a8\u8350\u4e2d\u8003\u8651\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u867d\u7136\u6700\u8fd1\u7684\u8fdb\u6b65\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u751f\u6210\u6d41\u7545\u7684\u8f93\u51fa\uff0c\u4f46\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u4ecd\u7136\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff1a\u8fd9\u4e9b\u89e3\u91ca\u662f\u5426\u4e0e\u53ef\u7528\u8bc1\u636e\u5728\u4e8b\u5b9e\u4e0a\u4fdd\u6301\u4e00\u81f4\uff1f", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u57fa\u4e8e\u6587\u672c\u7684\u53ef\u89e3\u91ca\u63a8\u8350\u8005\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\uff1b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528LLMs\u4ece\u8bc4\u8bba\u4e2d\u63d0\u53d6\u539f\u5b50\u89e3\u91ca\u8bed\u53e5\uff0c\u4ece\u800c\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u5b83\u4eec\u4e8b\u5b9e\u5185\u5bb9\u7684\u771f\u5b9e\u57fa\u51c6\uff1b\u63d0\u51fa\u4e86\u7ed3\u5408LLM-\u548cNLI-\u57fa\u7840\u65b9\u6cd5\u7684\u9648\u8ff0\u7ea7\u522b\u5bf9\u9f50\u6307\u6807\uff0c\u4ee5\u8bc4\u4f30\u751f\u6210\u89e3\u91ca\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u76f8\u5173\u6027\u3002", "result": "\u901a\u8fc7\u5bf9\u516d\u79cd\u6700\u5148\u8fdb\u7684\u53ef\u89e3\u91ca\u63a8\u8350\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u53d1\u73b0\u5c3d\u7ba1\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5206\u6570(BERTScore F1: 0.81-0.90)\uff0c\u6240\u6709\u4e8b\u5b9e\u6027\u6307\u6807\u90fd\u663e\u793a\u51fa\u4ee4\u4eba\u62c5\u5fe7\u7684\u4f4e\u6027\u80fd(LLM-based statement-level precision: 4.38%-32.88%)\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u53ef\u89e3\u91ca\u63a8\u8350\u4e2d\u8fdb\u884c\u4e8b\u5b9e\u610f\u8bc6\u8bc4\u4f30\u7684\u9700\u6c42\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u503c\u5f97\u4fe1\u8d56\u7684\u89e3\u91ca\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.23752", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23752", "abs": "https://arxiv.org/abs/2512.23752", "authors": ["Naman Aggarwal", "Siddhartha R. Dalal", "Vishal Misra"], "title": "Geometric Scaling of Bayesian Inference in LLMs", "comment": null, "summary": "Recent work has shown that small transformers trained in controlled \"wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.\n  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u4ee3\u751f\u4ea7\u7ea7\u8bed\u8a00\u6a21\u578b\uff08\u5982Pythia\u3001Phi-2\u3001Llama-3\u548cMistral\u7cfb\u5217\uff09\u4fdd\u7559\u4e86\u5728\u53d7\u63a7\u73af\u5883\u4e0b\u8bad\u7ec3\u7684\u5c0f\u578b\u53d8\u538b\u5668\u6240\u5c55\u793a\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u6240\u9700\u7684\u51e0\u4f55\u57fa\u5e95\u7279\u6027\u3002\u8fd9\u4e9b\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u503c\u8868\u793a\u6cbf\u7740\u4e0e\u9884\u6d4b\u71b5\u9ad8\u5ea6\u76f8\u5173\u7684\u5355\u4e00\u4e3b\u5bfc\u8f74\u7ec4\u7ec7\uff0c\u5e76\u4e14\u9886\u57df\u53d7\u9650\u63d0\u793a\u5c06\u8fd9\u79cd\u7ed3\u6784\u7b80\u5316\u4e3a\u5408\u6210\u8bbe\u7f6e\u4e2d\u89c2\u5bdf\u5230\u7684\u4f4e\u7ef4\u6d41\u5f62\u3002\u901a\u8fc7\u9488\u5bf9Pythia-410M\u4e2d\u7684\u71b5\u5bf9\u9f50\u8f74\u8fdb\u884c\u5e72\u9884\u5b9e\u9a8c\uff0c\u8fdb\u4e00\u6b65\u8868\u660e\u8be5\u51e0\u4f55\u7ed3\u6784\u662f\u4e0d\u786e\u5b9a\u6027\u7684\u4e00\u79cd\u7279\u6743\u8bfb\u51fa\u65b9\u5f0f\uff0c\u800c\u975e\u552f\u4e00\u7684\u8ba1\u7b97\u74f6\u9888\u3002", "motivation": "\u63a2\u7d22\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u5c0f\u578b\u53d8\u538b\u5668\u6240\u5c55\u73b0\u7684\u786e\u5207\u8d1d\u53f6\u65af\u63a8\u7406\u53ca\u51e0\u4f55\u57fa\u5e95\u7279\u5f81\u662f\u5426\u540c\u6837\u5b58\u5728\u4e8e\u5b9e\u9645\u5e94\u7528\u7ea7\u522b\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u3002", "method": "\u901a\u8fc7\u5bf9Pythia\u3001Phi-2\u3001Llama-3\u4ee5\u53caMistral\u5bb6\u65cf\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5206\u6790\uff0c\u7279\u522b\u662f\u7814\u7a76\u5b83\u4eec\u6700\u540e\u4e00\u5c42\u503c\u8868\u793a\u5982\u4f55\u6839\u636e\u9884\u6d4b\u71b5\u6765\u7ec4\u7ec7\uff1b\u540c\u65f6\uff0c\u5728Pythia-410M\u4e0a\u6267\u884c\u7279\u5b9a\u5e72\u9884\u4ee5\u63a2\u7d22\u71b5\u5bf9\u9f50\u8f74\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u4fdd\u7559\u4e86\u652f\u6301\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u51e0\u4f55\u57fa\u5e95\uff0c\u5e76\u4e14\u5b83\u4eec\u4f1a\u6cbf\u6b64\u57fa\u5e95\u7ec4\u7ec7\u8fd1\u4f3c\u8d1d\u53f6\u65af\u66f4\u65b0\u3002\u6b64\u5916\uff0c\u867d\u7136\u9488\u5bf9\u71b5\u5bf9\u9f50\u8f74\u7684\u5e72\u9884\u80fd\u591f\u7834\u574f\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u51e0\u4f55\uff0c\u4f46\u5e76\u672a\u5bfc\u81f4\u76f8\u5e94\u7684\u884c\u4e3a\u9000\u5316\uff0c\u8868\u660e\u8be5\u51e0\u4f55\u7ed3\u6784\u66f4\u591a\u5730\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u7684\u7279\u6b8a\u6307\u793a\u5668\u800c\u975e\u5173\u952e\u8ba1\u7b97\u969c\u788d\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5728\u590d\u6742\u7684\u5e94\u7528\u573a\u666f\u4e0b\uff0c\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u4e5f\u80fd\u591f\u4fdd\u6301\u4e00\u79cd\u6709\u52a9\u4e8e\u5b9e\u73b0\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u5185\u90e8\u51e0\u4f55\u7ed3\u6784\u3002"}}
{"id": "2512.23766", "categories": ["cs.LG", "cs.CG", "cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.23766", "abs": "https://arxiv.org/abs/2512.23766", "authors": ["Karim Salta", "Michael Kirby", "Chris Peterson"], "title": "A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit", "comment": null, "summary": "In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b50\u7a7a\u95f4\u805a\u7c7b\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4f7f\u7528\u53ef\u8bad\u7ec3\u7684\u539f\u578b\uff08\u79f0\u4e3a\u6700\u4f73\u62df\u5408\u8212\u4f2f\u7279\u53d8\u4f53SVBF\uff09\u4ee3\u66ff\u5b50\u7a7a\u95f4\u5747\u503c\uff0c\u4ece\u800c\u5728\u5408\u6210\u6570\u636e\u3001\u56fe\u50cf\u3001\u5149\u8c31\u548c\u89c6\u9891\u52a8\u4f5c\u6570\u636e\u4e0a\u63d0\u9ad8\u4e86\u805a\u7c7b\u7eaf\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0b\u6e38\u5206\u6790\u6240\u9700\u7684\u6570\u5b66\u7ed3\u6784\u3002", "motivation": "\u5728\u8bb8\u591a\u5206\u7c7b\u548c\u805a\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4e3a\u6570\u636e\u96c6\u6216\u4e00\u4e2a\u7c07\u8ba1\u7b97\u51e0\u4f55\u4ee3\u8868\uff08\u5982\u5747\u503c\u6216\u4e2d\u4f4d\u6570\uff09\u662f\u5f88\u6709\u7528\u7684\u3002\u5f53\u6570\u636e\u96c6\u7531\u5b50\u7a7a\u95f4\u8868\u793a\u65f6\uff0c\u8fd9\u4e9b\u4ee3\u8868\u5c31\u6210\u4e3a\u683c\u62c9\u65af\u66fc\u6d41\u5f62\u6216\u6807\u5fd7\u6d41\u5f62\u4e0a\u7684\u70b9\uff0c\u5e76\u4e14\u8ddd\u79bb\u901a\u5e38\u901a\u8fc7\u4e3b\u89d2\u5ea6\u6765\u8bf1\u5bfc\u3002\u7814\u7a76\u8005\u5e0c\u671b\u6539\u8fdb\u73b0\u6709\u7684\u5b50\u7a7a\u95f4\u805a\u7c7b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u805a\u7c7b\u7eaf\u5ea6\u5e76\u4fdd\u7559\u6570\u5b66\u7ed3\u6784\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u5b50\u7a7a\u95f4\u805a\u7c7b\u7b97\u6cd5\uff0c\u5b83\u5229\u7528\u4e00\u4e2a\u53ef\u8bad\u7ec3\u7684\u539f\u578b\u2014\u2014\u6700\u4f73\u62df\u5408\u8212\u4f2f\u7279\u53d8\u4f53(SVBF)\uff0c\u8fd9\u662f\u4e00\u79cd\u5c3d\u53ef\u80fd\u63a5\u8fd1\u4e8e\u4e0e\u6bcf\u4e2a\u7c07\u6210\u5458\u81f3\u5c11\u5728\u4e00\u4e2a\u56fa\u5b9a\u65b9\u5411\u76f8\u4ea4\u7684\u5b50\u7a7a\u95f4\u3002\u6b64SVBF-LBG\u65b9\u6848\u88ab\u96c6\u6210\u5230Linde-Buzo-Grey (LBG)\u6d41\u7a0b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSVBF-LBG\u65b9\u6848\u5728\u5408\u6210\u6570\u636e\u3001\u56fe\u50cf\u3001\u5149\u8c31\u548c\u89c6\u9891\u52a8\u4f5c\u6570\u636e\u7b49\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6599\u4e0a\u90fd\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u805a\u7c7b\u7eaf\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6700\u4f73\u62df\u5408\u8212\u4f2f\u7279\u53d8\u4f53\u7684\u5b50\u7a7a\u95f4\u805a\u7c7b\u7b97\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u805a\u7c7b\u7eaf\u5ea6\uff0c\u8fd8\u7ef4\u6301\u4e86\u5bf9\u540e\u7eed\u5206\u6790\u81f3\u5173\u91cd\u8981\u7684\u6570\u5b66\u7ed3\u6784\u3002"}}
{"id": "2512.24711", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24711", "abs": "https://arxiv.org/abs/2512.24711", "authors": ["Kangyang Luo", "Shuzheng Si", "Yuzhuo Bai", "Cheng Gao", "Zhitong Wang", "Cheng Huang", "Yingli Shen", "Yufeng Han", "Wenhao Li", "Cunliang Kong", "Maosong Sun"], "title": "MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints", "comment": null, "summary": "In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \\textbf{MEIC-DT}, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer's input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\\textbf{SAES}), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\\textbf{IRP}) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMEIC-DT\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u57fa\u4e8e\u8f7b\u91cf\u7ea7Transformer\u7684\u53cc\u9608\u503c\u3001\u5185\u5b58\u9ad8\u6548\u7684\u589e\u91cf\u805a\u7c7b\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5171\u6307\u89e3\u6790\u4e2d\u6548\u7387\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\uff0c\u76d1\u7763\u795e\u7ecf\u65b9\u6cd5\u4ecd\u7136\u662f\u5171\u6307\u89e3\u6790\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u5728\u589e\u91cf\u805a\u7c7b\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5982\u4f55\u5e73\u8861\u6548\u7387\u4e0e\u6027\u80fd\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "MEIC-DT\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u53cc\u9608\u503c\u7ea6\u675f\u673a\u5236\u6765\u7cbe\u786e\u63a7\u5236\u7ed9\u5b9a\u5185\u5b58\u9884\u7b97\u5185\u7684Transformer\u8f93\u5165\u89c4\u6a21\uff0c\u5e76\u7ed3\u5408\u7edf\u8ba1\u611f\u77e5\u9a71\u9010\u7b56\u7565\uff08SAES\uff09\u8fdb\u884c\u667a\u80fd\u7f13\u5b58\u7ba1\u7406\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u5185\u90e8\u6b63\u5219\u5316\u7b56\u7565\uff08IRP\uff09\uff0c\u901a\u8fc7\u5bf9\u6700\u5177\u4ee3\u8868\u6027\u7684\u63d0\u53ca\u8fdb\u884c\u9009\u62e9\u6027\u538b\u7f29\uff0c\u4ece\u800c\u4fdd\u6301\u8bed\u4e49\u5b8c\u6574\u6027\u3002", "result": "\u5728\u5e38\u89c1\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMEIC-DT\u5728\u4e25\u683c\u7684\u5185\u5b58\u9650\u5236\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u975e\u5e38\u6709\u7ade\u4e89\u529b\u7684\u5171\u6307\u89e3\u6790\u8868\u73b0\u3002", "conclusion": "MEIC-DT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u9ad8\u6548\u7387\u7684\u540c\u65f6\u4e5f\u8fbe\u5230\u4e86\u4f18\u79c0\u7684\u5171\u6307\u89e3\u6790\u6548\u679c\uff0c\u4e3a\u5904\u7406\u957f\u6587\u672c\u65f6\u9047\u5230\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24715", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24715", "abs": "https://arxiv.org/abs/2512.24715", "authors": ["Kang Fu", "Honglei Zhang", "Xuechao Zou", "Yidong Li"], "title": "MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation", "comment": null, "summary": "Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMDiffFR\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u91c7\u7528\u57fa\u4e8e\u751f\u6210\u7684\u6a21\u6001\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u6765\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u6001\u7f16\u7801\u5668\u63d0\u53d6\u7279\u5f81\u4f5c\u4e3a\u6761\u4ef6\u4fe1\u53f7\u6307\u5bfc\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\uff0c\u4ee5\u5b9e\u73b0\u9879\u76ee\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cMDiffFR\u80fd\u591f\u63d0\u4f9b\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u4e14\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u56e0\u80fd\u4fdd\u7559\u7528\u6237\u9690\u79c1\u800c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5176\u4e25\u683c\u7684\u9690\u79c1\u9650\u5236\u5bfc\u81f4\u96be\u4ee5\u5b66\u4e60\u5168\u5c40\u6709\u6548\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u65b0\uff08\u51b7\u542f\u52a8\uff09\u9879\u76ee\u800c\u8a00\u6311\u6218\u66f4\u5927\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u65e0\u6cd5\u5f88\u597d\u5730\u5efa\u6a21\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03\uff0c\u5bb9\u6613\u9020\u6210\u5d4c\u5165\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86MDiffFR\uff0c\u4e00\u79cd\u9488\u5bf9\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u9879\u76ee\u7684\u65b0\u578b\u751f\u6210\u5f0f\u6a21\u6001\u5f15\u5bfc\u6269\u6563\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u670d\u52a1\u5668\u7aef\u4f7f\u7528\u5b9a\u5236\u5316\u7684\u6269\u6563\u6a21\u578b\u4e3a\u65b0\u9879\u76ee\u751f\u6210\u5d4c\u5165\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5d4c\u5165\u5206\u53d1\u7ed9\u5ba2\u6237\u7aef\u8fdb\u884c\u51b7\u542f\u52a8\u63a8\u7406\u3002\u6b64\u5916\uff0c\u8fd8\u90e8\u7f72\u4e86\u9884\u8bad\u7ec3\u7684\u6a21\u6001\u7f16\u7801\u5668\u6765\u63d0\u53d6\u6a21\u6001\u7279\u5f81\u4f5c\u4e3a\u6761\u4ef6\u4fe1\u53f7\uff0c\u4ee5\u6307\u5bfc\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u3002", "result": "\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u6620\u5c04\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u969c\u3002\u5728\u56db\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8054\u90a6\u63a8\u8350\u573a\u666f\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "MDiffFR\u901a\u8fc7\u5f15\u5165\u751f\u6210\u5f0f\u7684\u6a21\u6001\u5f15\u5bfc\u6269\u6563\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9690\u79c1\u4fdd\u62a4\u6027\u80fd\u3002"}}
{"id": "2512.23782", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.23782", "abs": "https://arxiv.org/abs/2512.23782", "authors": ["Kessia Nepomuceno", "Fabio Petrillo"], "title": "A Systematic Mapping on Software Fairness: Focus, Trends and Industrial Context", "comment": null, "summary": "Context: Fairness in systems has emerged as a critical concern in software engineering, garnering increasing attention as the field has advanced in recent years. While several guidelines have been proposed to address fairness, achieving a comprehensive understanding of research solutions for ensuring fairness in software systems remains challenging. Objectives: This paper presents a systematic literature mapping to explore and categorize current advancements in fairness solutions within software engineering, focusing on three key dimensions: research trends, research focus, and viability in industrial contexts. Methods: We develop a classification framework to organize research on software fairness from a fresh perspective, applying it to 95 selected studies and analyzing their potential for industrial adoption. Results: Our findings reveal that software fairness research is expanding, yet it remains heavily focused on methods and algorithms. It primarily focuses on post-processing and group fairness, with less emphasis on early-stage interventions, individual fairness metrics, and understanding bias root causes. Additionally fairness research remains largely academic, with limited industry collaboration and low to medium Technology Readiness Level (TRL), indicating that industrial transferability remains distant. Conclusion: Our results underscore the need to incorporate fairness considerations across all stages of the software development life-cycle and to foster greater collaboration between academia and industry. This analysis provides a comprehensive overview of the field, offering a foundation to guide future research and practical applications of fairness in software systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf995\u9879\u7814\u7a76\u7684\u7cfb\u7edf\u6587\u732e\u6620\u5c04\uff0c\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u516c\u5e73\u6027\u89e3\u51b3\u65b9\u6848\u7684\u5f53\u524d\u8fdb\u5c55\uff0c\u63ed\u793a\u4e86\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u65b9\u6cd5\u548c\u7b97\u6cd5\u4e0a\uff0c\u5e76\u4e14\u591a\u4e3a\u540e\u5904\u7406\u548c\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u7f3a\u4e4f\u65e9\u671f\u5e72\u9884\u3001\u4e2a\u4f53\u516c\u5e73\u6027\u548c\u5bf9\u504f\u89c1\u6839\u6e90\u7684\u7406\u89e3\u3002\u6b64\u5916\uff0c\u516c\u5e73\u6027\u7814\u7a76\u4ecd\u4e3b\u8981\u505c\u7559\u5728\u5b66\u672f\u5c42\u9762\uff0c\u4e0e\u5de5\u4e1a\u754c\u7684\u5408\u4f5c\u8f83\u5c11\uff0c\u6280\u672f\u6210\u719f\u5ea6\u8f83\u4f4e\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u8fd1\u5e74\u6765\u7684\u53d1\u5c55\uff0c\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u91cd\u89c6\u3002\u5c3d\u7ba1\u5df2\u7ecf\u63d0\u51fa\u4e86\u82e5\u5e72\u6307\u5bfc\u65b9\u9488\u6765\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\uff0c\u4f46\u8981\u5168\u9762\u7406\u89e3\u786e\u4fdd\u8f6f\u4ef6\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u7814\u7a76\u89e3\u51b3\u65b9\u6848\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u7c7b\u6846\u67b6\uff0c\u4ece\u65b0\u7684\u89d2\u5ea6\u7ec4\u7ec7\u5173\u4e8e\u8f6f\u4ef6\u516c\u5e73\u6027\u7684\u7814\u7a76\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e95\u9879\u9009\u5b9a\u7684\u7814\u7a76\uff0c\u5206\u6790\u5b83\u4eec\u5728\u5de5\u4e1a\u91c7\u7528\u65b9\u9762\u7684\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8f6f\u4ef6\u516c\u5e73\u6027\u7814\u7a76\u6b63\u5728\u6269\u5c55\uff0c\u4f46\u4ecd\u4e3b\u8981\u96c6\u4e2d\u5728\u65b9\u6cd5\u548c\u7b97\u6cd5\u4e0a\uff0c\u7279\u522b\u662f\u540e\u5904\u7406\u548c\u7fa4\u4f53\u516c\u5e73\u6027\u65b9\u9762\u3002\u5bf9\u4e8e\u65e9\u671f\u9636\u6bb5\u5e72\u9884\u63aa\u65bd\u3001\u4e2a\u4f53\u516c\u5e73\u6027\u6307\u6807\u4ee5\u53ca\u7406\u89e3\u504f\u89c1\u7684\u6839\u672c\u539f\u56e0\u7684\u5173\u6ce8\u8f83\u5c11\u3002\u6b64\u5916\uff0c\u516c\u5e73\u6027\u7814\u7a76\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4ecd\u7136\u662f\u5b66\u672f\u6027\u8d28\u7684\uff0c\u4e0e\u884c\u4e1a\u7684\u5408\u4f5c\u6709\u9650\uff0c\u6280\u672f\u5c31\u7eea\u6c34\u5e73\uff08TRL\uff09\u4f4e\u5230\u4e2d\u7b49\uff0c\u8868\u660e\u5411\u5de5\u4e1a\u8f6c\u79fb\u8fd8\u6709\u4e00\u5b9a\u8ddd\u79bb\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u5728\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u8003\u8651\u516c\u5e73\u6027\u7684\u91cd\u8981\u6027\uff0c\u5e76\u547c\u5401\u52a0\u5f3a\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u534f\u4f5c\u3002\u8fd9\u9879\u5206\u6790\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u6982\u89c8\uff0c\u4e3a\u672a\u6765\u5173\u4e8e\u8f6f\u4ef6\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.23755", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23755", "abs": "https://arxiv.org/abs/2512.23755", "authors": ["Sheo Yon Jhin", "Noseong Park"], "title": "HINTS: Extraction of Human Insights from Time-Series Without External Sources", "comment": "AAAI 2026 AI4TS Workshop paper", "summary": "Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHINTS\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u65f6\u95f4\u5e8f\u5217\u6b8b\u5dee\u4e2d\u5185\u751f\u5730\u63d0\u53d6\u6f5c\u5728\u7684\u4eba\u7c7b\u56e0\u7d20\uff0c\u800c\u65e0\u9700\u5916\u90e8\u6570\u636e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eHINTS\u80fd\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u548c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u53ef\u89e3\u91ca\u6027\u53ca\u5b9e\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u8bb8\u591a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u4f9d\u8d56\u4e8e\u65b0\u95fb\u3001\u793e\u4ea4\u5a92\u4f53\u7b49\u5916\u90e8\u6765\u6e90\u6765\u6355\u6349\u4eba\u7c7b\u56e0\u7d20\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u8d22\u52a1\u3001\u8ba1\u7b97\u4ee5\u53ca\u5b9e\u9645\u5e94\u7528\u65b9\u9762\u5e26\u6765\u4e86\u9ad8\u6602\u7684\u6570\u636e\u4f9d\u8d56\u6210\u672c\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0d\u9700\u8981\u5916\u90e8\u6570\u636e\u5c31\u80fd\u4ece\u65f6\u95f4\u5e8f\u5217\u5185\u90e8\u63d0\u53d6\u8fd9\u4e9b\u590d\u6742\u4eba\u7c7b\u56e0\u7d20\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86HINTS\uff0c\u4e00\u4e2a\u5229\u7528Friedkin-Johnsen\u610f\u89c1\u52a8\u6001\u6a21\u578b\u4f5c\u4e3a\u7ed3\u6784\u5f52\u7eb3\u504f\u7f6e\u6765\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4ee5\u4ece\u65f6\u95f4\u5e8f\u5217\u6b8b\u5dee\u4e2d\u63d0\u53d6\u968f\u65f6\u95f4\u53d8\u5316\u7684\u793e\u4f1a\u5f71\u54cd\u3001\u8bb0\u5fc6\u4e0e\u504f\u5dee\u6a21\u5f0f\u7b49\u6f5c\u5728\u4eba\u7c7b\u56e0\u7d20\u3002\u7136\u540e\u5c06\u63d0\u53d6\u5230\u7684\u56e0\u7d20\u4ee5\u6ce8\u610f\u529b\u56fe\u7684\u5f62\u5f0f\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\u4e2d\u3002", "result": "\u901a\u8fc7\u5bf9\u4e5d\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\uff0cHINTS\u88ab\u8bc1\u660e\u53ef\u4ee5\u4e00\u81f4\u5730\u6539\u5584\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u51e0\u4e2a\u6848\u4f8b\u7814\u7a76\u548c\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u53d6\u56e0\u7d20\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e8b\u4ef6\u4e4b\u95f4\u5b58\u5728\u5f3a\u8bed\u4e49\u5bf9\u9f50\uff0c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86HINTS\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "HINTS\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u989d\u5916\u6570\u636e\u4f9d\u8d56\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u672c\u8eab\u4e2d\u63d0\u53d6\u5e76\u6574\u5408\u4eba\u7c7b\u56e0\u7d20\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u3002\u5b83\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8fd8\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2512.24762", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2512.24762", "abs": "https://arxiv.org/abs/2512.24762", "authors": ["Guorui Zhou", "Honghui Bao", "Jiaming Huang", "Jiaxin Deng", "Jinghao Zhang", "Junda She", "Kuo Cai", "Lejian Ren", "Lu Ren", "Qiang Luo", "Qianqian Wang", "Qigen Hu", "Rongzhou Zhang", "Ruiming Tang", "Shiyao Wang", "Wuchao Li", "Xiangyu Wu", "Xinchen Luo", "Xingmei Wang", "Yifei Hu", "Yunfan Wu", "Zhanyu Liu", "Zhiyang Zhang", "Zixing Zhang", "Bo Chen", "Bin Wen", "Chaoyi Ma", "Chengru Song", "Chenglong Chu", "Defu Lian", "Fan Yang", "Feng Jiang", "Hongtao Cheng", "Huanjie Wang", "Kun Gai", "Pengfei Zheng", "Qiang Wang", "Rui Huang", "Siyang Mao", "Tingting Gao", "Wei Yuan", "Yan Wang", "Yang Zhou", "Yi Su", "Zexuan Cheng", "Zhixin Ling", "Ziming Li"], "title": "OpenOneRec Technical Report", "comment": null, "summary": "While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench & Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework & Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RecIF-Bench\uff0c\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u4e86\u4ece\u57fa\u7840\u9884\u6d4b\u5230\u590d\u6742\u63a8\u7406\u76848\u4e2a\u591a\u6837\u5316\u4efb\u52a1\uff0c\u5e76\u5f00\u6e90\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u5f00\u6e90\u4e86\u5b8c\u6574\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5e76\u53d1\u5e03\u4e86OneRec Foundation\u6a21\u578b\u7cfb\u5217\uff0c\u5728\u6240\u6709RecIF-Bench\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u6700\u65b0\u7684\u6700\u4f73\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u5728\u6a21\u5f0f\u5339\u914d\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u4e16\u754c\u77e5\u8bc6\u3001\u63a8\u7406\u80fd\u529b\u548c\u6307\u4ee4\u6267\u884c\u80fd\u529b\uff0c\u4e14\u6ca1\u6709\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u7efc\u5408\u80fd\u529b\u3002", "method": "1) \u63d0\u51faRecIF-Bench\uff0c\u4e00\u4e2a\u6db5\u76d68\u79cd\u4e0d\u540c\u4efb\u52a1\u7684\u7efc\u5408\u6027\u57fa\u51c6\u3002\n2) \u5f00\u6e90\u5305\u542b9600\u4e07\u6b21\u4e92\u52a8\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\u3002\n3) \u5f00\u6e90\u6574\u4e2a\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u5904\u7406\u3001\u534f\u540c\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u3002\n4) \u53d1\u5e03OneRec Foundation\uff081.7B\u548c8B\uff09\u6a21\u578b\u7cfb\u5217\u3002", "result": "OneRec Foundation\u6a21\u578b\u5728RecIF-Bench\u7684\u6240\u6709\u4efb\u52a1\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6210\u679c\uff0c\u5e76\u5728\u8f6c\u79fb\u5230Amazon\u57fa\u51c6\u65f6\uff0c\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad8\u4e8626.8%\u7684Recall@10\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740\u671d\u7740\u6784\u5efa\u771f\u6b63\u667a\u80fd\u7684\u63a8\u8350\u7cfb\u7edf\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5c3d\u7ba1\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u4ecd\u9762\u4e34\u91cd\u5927\u6280\u672f\u548c\u7406\u8bba\u6311\u6218\u3002"}}
{"id": "2512.24787", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24787", "abs": "https://arxiv.org/abs/2512.24787", "authors": ["Yunsheng Pang", "Zijian Liu", "Yudong Li", "Shaojie Zhu", "Zijian Luo", "Chenyun Yu", "Sikai Wu", "Shichen Shen", "Cong Xu", "Bin Wang", "Kai Jiang", "Hongyong Yu", "Chengxiang Zhuo", "Zang Li"], "title": "HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment", "comment": null, "summary": "Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u677f\u63a8\u8350\u6846\u67b6HiGR\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5c42\u6b21\u89c4\u5212\u548c\u5217\u8868\u504f\u597d\u5bf9\u9f50\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u81ea\u56de\u5f52\u65b9\u6cd5\u5728\u8bed\u4e49\u9879\u6807\u8bb0\u5316\u548c\u5e8f\u5217\u89e3\u7801\u4e0a\u7684\u4e0d\u8db3\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHiGR\u4e0d\u4ec5\u5728\u7ebf\u4e0b\u8bc4\u4f30\u4e2d\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8d85\u8fc710%\u7684\u63a8\u8350\u8d28\u91cf\uff0c\u5e76\u4e14\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e865\u500d\uff0c\u800c\u4e14\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5e73\u5747\u89c2\u770b\u65f6\u95f4\u548c\u5e73\u5747\u89c6\u9891\u6d4f\u89c8\u91cf\u5206\u522b\u589e\u52a0\u4e861.22%\u548c1.73%\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u56de\u5f52\u65b9\u6cd5\u5728\u5904\u7406\u677f\u63a8\u8350\u65f6\u5b58\u5728\u8bed\u4e49\u9879\u6807\u8bb0\u5316\u7ea0\u7f20\u4ee5\u53ca\u7f3a\u4e4f\u6574\u4f53\u677f\u89c4\u5212\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u63a8\u8350\u6548\u7387\u548c\u8d28\u91cf\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86HiGR\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u6b8b\u5dee\u91cf\u5316\u4e0e\u5bf9\u6bd4\u7ea6\u675f\u7684\u81ea\u52a8\u7f16\u7801\u5668\u6765\u5b9e\u73b0\u53ef\u63a7\u751f\u6210\uff1b\u5c06\u751f\u6210\u8fc7\u7a0b\u5206\u89e3\u4e3a\u5217\u8868\u7ea7\u89c4\u5212\u9636\u6bb5\u548c\u9879\u76ee\u7ea7\u89e3\u7801\u9636\u6bb5\uff1b\u5e76\u901a\u8fc7\u5217\u8868\u504f\u597d\u5bf9\u9f50\u76ee\u6807\u76f4\u63a5\u5229\u7528\u9690\u5f0f\u7528\u6237\u53cd\u9988\u4f18\u5316\u677f\u7684\u8d28\u91cf\u3002", "result": "HiGR\u5728\u5927\u89c4\u6a21\u5546\u4e1a\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5176\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5728\u79bb\u7ebf\u63a8\u8350\u8d28\u91cf\u4e0a\u63d0\u9ad8\u4e86\u8d85\u8fc710%\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e865\u500d\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u89c2\u770b\u65f6\u95f4\u63d0\u9ad8\u4e861.22%\uff0c\u5e73\u5747\u89c6\u9891\u6d4f\u89c8\u6b21\u6570\u63d0\u9ad8\u4e861.73%\u3002", "conclusion": "HiGR\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u751f\u6210\u5f0f\u677f\u63a8\u8350\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u63a8\u8350\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u6548\u7387\u3002"}}
{"id": "2512.24943", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24943", "abs": "https://arxiv.org/abs/2512.24943", "authors": ["Chenji Lu", "Zhuo Chen", "Hui Zhao", "Zhenyi Wang", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment", "comment": null, "summary": "Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRAIR\u7684\u4e2d\u6587\u6570\u636e\u96c6\uff0c\u65e8\u5728\u4e3a\u641c\u7d22\u76f8\u5173\u6027\u8bc4\u4f30\u63d0\u4f9b\u6807\u51c6\u5316\u6846\u67b6\u3002\u8be5\u6570\u636e\u96c6\u57fa\u4e8e\u771f\u5b9e\u573a\u666f\u6784\u5efa\uff0c\u5e76\u5206\u4e3a\u4e09\u4e2a\u5b50\u96c6\u6765\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684GPT-5\u5728RAIR\u4e0a\u4e5f\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u8bc4\u4f30\u641c\u7d22\u76f8\u5173\u6027\u7684\u57fa\u51c6\u7f3a\u4e4f\u8db3\u591f\u7684\u590d\u6742\u5ea6\u6765\u8fdb\u884c\u5168\u9762\u7684\u6a21\u578b\u8bc4\u4ef7\uff0c\u5bfc\u81f4\u884c\u4e1a\u5185\u7f3a\u4e4f\u7edf\u4e00\u7684\u76f8\u5173\u6027\u8bc4\u4ef7\u6307\u6807\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u79f0\u4e3aRule-Aware benchmark with Image for Relevance assessment (RAIR)\u7684\u6570\u636e\u96c6\uff0c\u5b83\u7531\u4e09\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u822c\u5b50\u96c6\u3001\u957f\u5c3e\u96be\u9898\u5b50\u96c6\u4ee5\u53ca\u89c6\u89c9\u663e\u8457\u6027\u5b50\u96c6\uff0c\u5206\u522b\u7528\u6765\u8bc4\u4f30\u57fa\u672c\u80fd\u529b\u3001\u6781\u9650\u6027\u80fd\u548c\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u4f7f\u752814\u4e2a\u5f00\u6e90\u53ca\u95ed\u6e90\u6a21\u578b\u5bf9RAIR\u8fdb\u884c\u6d4b\u8bd5\u540e\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684GPT-5\u4e5f\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u9047\u5230\u4e86\u76f8\u5f53\u5927\u7684\u6311\u6218\u3002", "conclusion": "RAIR\u4e0d\u4ec5\u4e3a\u641c\u7d22\u76f8\u5173\u6027\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u901a\u7528\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2512.23982", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23982", "abs": "https://arxiv.org/abs/2512.23982", "authors": ["Hung-Fu Chang", "MohammadShokrolah Shirazi", "Lizhou Cao", "Supannika Koolmanojwong Mobasser"], "title": "Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education", "comment": "21 pages, 5 figures", "summary": "Recent advances in large language models (LLMs) have introduced new paradigms in software development, including vibe coding, AI-assisted coding, and agentic coding, fundamentally reshaping how software is designed, implemented, and maintained. Prior research has primarily examined AI-based coding at the individual level or in educational settings, leaving industrial practitioners' perspectives underexplored. This paper addresses this gap by investigating how LLM coding tools are used in professional practice, the associated concerns and risks, and the resulting transformations in development workflows, with particular attention to implications for computing education. We conducted a qualitative analysis of 57 curated YouTube videos published between late 2024 and 2025, capturing reflections and experiences shared by practitioners. Following a filtering and quality assessment process, the selected sources were analyzed to compare LLM-based and traditional programming, identify emerging risks, and characterize evolving workflows. Our findings reveal definitions of AI-based coding practices, notable productivity gains, and lowered barriers to entry. Practitioners also report a shift in development bottlenecks toward code review and concerns regarding code quality, maintainability, security vulnerabilities, ethical issues, erosion of foundational problem-solving skills, and insufficient preparation of entry-level engineers. Building on these insights, we discuss implications for computer science and software engineering education and argue for curricular shifts toward problem-solving, architectural thinking, code review, and early project-based learning that integrates LLM tools. This study offers an industry-grounded perspective on AI-based coding and provides guidance for aligning educational practices with rapidly evolving professional realities.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u679057\u4e2aYouTube\u89c6\u9891\uff0c\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e13\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3001\u76f8\u5173\u98ce\u9669\u4ee5\u53ca\u5bf9\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u7684\u8f6c\u53d8\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u7684\u610f\u4e49\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e2a\u4f53\u5c42\u9762\u6216\u6559\u80b2\u573a\u666f\u4e2d\u57fa\u4e8eAI\u7684\u7f16\u7801\uff0c\u800c\u5de5\u4e1a\u5b9e\u8df5\u8005\u7684\u89c6\u89d2\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76LLM\u7f16\u7801\u5de5\u5177\u5728\u4e13\u4e1a\u5b9e\u8df5\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u3001\u76f8\u5173\u62c5\u5fe7\u4e0e\u98ce\u9669\uff0c\u4ee5\u53ca\u5f00\u53d1\u5de5\u4f5c\u6d41\u7684\u53d8\u5316\uff0c\u7279\u522b\u5173\u6ce8\u5bf9\u8ba1\u7b97\u6559\u80b2\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7b5b\u9009\u5e76\u8bc4\u4f30\u4e862024\u5e74\u672b\u81f32025\u5e74\u95f4\u53d1\u5e03\u768457\u4e2a\u7cbe\u9009YouTube\u89c6\u9891\uff0c\u8fd9\u4e9b\u89c6\u9891\u5305\u542b\u4e86\u4ece\u4e1a\u8005\u5206\u4eab\u7684\u7ecf\u9a8c\u548c\u4e2a\u4eba\u89c1\u89e3\u3002\u901a\u8fc7\u5bf9\u9009\u5b9a\u6765\u6e90\u8fdb\u884c\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8eLLM\u7684\u7f16\u7a0b\u4e0e\u4f20\u7edf\u7f16\u7a0b\u65b9\u5f0f\uff0c\u8bc6\u522b\u65b0\u5174\u98ce\u9669\uff0c\u5e76\u63cf\u7ed8\u51fa\u6f14\u53d8\u4e2d\u7684\u5de5\u4f5c\u6d41\u7a0b\u7279\u5f81\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u57fa\u4e8eAI\u7684\u7f16\u7801\u5b9e\u8df5\u5b9a\u4e49\u3001\u663e\u8457\u7684\u751f\u4ea7\u529b\u63d0\u5347\u53ca\u5165\u95e8\u95e8\u69db\u964d\u4f4e\u73b0\u8c61\u3002\u540c\u65f6\uff0c\u4e5f\u6307\u51fa\u4e86\u5411\u4ee3\u7801\u5ba1\u67e5\u73af\u8282\u8f6c\u79fb\u7684\u53d1\u5c55\u74f6\u9888\u95ee\u9898\uff0c\u4ee5\u53ca\u5173\u4e8e\u4ee3\u7801\u8d28\u91cf\u3001\u53ef\u7ef4\u62a4\u6027\u3001\u5b89\u5168\u6f0f\u6d1e\u3001\u9053\u5fb7\u8bae\u9898\u3001\u57fa\u7840\u95ee\u9898\u89e3\u51b3\u6280\u80fd\u4fb5\u8680\u548c\u521d\u7ea7\u5de5\u7a0b\u5e08\u51c6\u5907\u4e0d\u8db3\u7b49\u65b9\u9762\u7684\u62c5\u5fe7\u3002", "conclusion": "\u57fa\u4e8e\u4ee5\u4e0a\u6d1e\u5bdf\uff0c\u6587\u7ae0\u8ba8\u8bba\u4e86\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u5021\u8bfe\u7a0b\u8f6c\u5411\u6ce8\u91cd\u89e3\u51b3\u95ee\u9898\u80fd\u529b\u3001\u67b6\u6784\u601d\u7ef4\u3001\u4ee3\u7801\u5ba1\u67e5\u53ca\u65e9\u878d\u5165\u9879\u76ee\u5f0f\u5b66\u4e60\u7684\u6559\u5b66\u6a21\u5f0f\uff0c\u4ee5\u6574\u5408LLM\u5de5\u5177\u3002\u672c\u7814\u7a76\u4e3a\u57fa\u4e8eAI\u7684\u7f16\u7801\u63d0\u4f9b\u4e86\u6765\u81ea\u884c\u4e1a\u7684\u89c6\u89d2\uff0c\u5e76\u5c31\u5982\u4f55\u4f7f\u6559\u80b2\u5b9e\u8df5\u4e0e\u5feb\u901f\u53d8\u5316\u7684\u804c\u4e1a\u73b0\u5b9e\u4fdd\u6301\u4e00\u81f4\u63d0\u51fa\u4e86\u6307\u5bfc\u5efa\u8bae\u3002"}}
{"id": "2512.23763", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23763", "abs": "https://arxiv.org/abs/2512.23763", "authors": ["John E. Darges", "Babak Maboudi Afkham", "Matthias Chung"], "title": "Neural Optimal Design of Experiment for Inverse Problems", "comment": null, "summary": "We introduce Neural Optimal Design of Experiments, a learning-based framework for optimal experimental design in inverse problems that avoids classical bilevel optimization and indirect sparsity regularization. NODE jointly trains a neural reconstruction model and a fixed-budget set of continuous design variables representing sensor locations, sampling times, or measurement angles, within a single optimization loop. By optimizing measurement locations directly rather than weighting a dense grid of candidates, the proposed approach enforces sparsity by design, eliminates the need for l1 tuning, and substantially reduces computational complexity. We validate NODE on an analytically tractable exponential growth benchmark, on MNIST image sampling, and illustrate its effectiveness on a real world sparse view X ray CT example. In all cases, NODE outperforms baseline approaches, demonstrating improved reconstruction accuracy and task-specific performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u5b9e\u9a8c\u6700\u4f18\u8bbe\u8ba1\u6846\u67b6\uff08NODE\uff09\uff0c\u8be5\u6846\u67b6\u5728\u5355\u4e2a\u4f18\u5316\u5faa\u73af\u4e2d\u8054\u5408\u8bad\u7ec3\u795e\u7ecf\u91cd\u5efa\u6a21\u578b\u548c\u8868\u793a\u4f20\u611f\u5668\u4f4d\u7f6e\u7b49\u7684\u8fde\u7eed\u8bbe\u8ba1\u53d8\u91cf\uff0c\u4ece\u800c\u76f4\u63a5\u4f18\u5316\u6d4b\u91cf\u4f4d\u7f6e\uff0c\u907f\u514d\u4e86\u7ecf\u5178\u53cc\u5c42\u4f18\u5316\u548c\u95f4\u63a5\u7a00\u758f\u6b63\u5219\u5316\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u53cd\u95ee\u9898\u4e2d\u7684\u6700\u4f18\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u7ecf\u5178\u7684\u53cc\u5c42\u4f18\u5316\u548c\u95f4\u63a5\u7a00\u758f\u6027\u6b63\u5219\u5316\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5f15\u5165Neural Optimal Design of Experiments (NODE)\uff0c\u5728\u4e00\u4e2a\u4f18\u5316\u5faa\u73af\u5185\u5171\u540c\u8bad\u7ec3\u795e\u7ecf\u91cd\u5efa\u6a21\u578b\u4e0e\u4ee3\u8868\u5982\u4f20\u611f\u5668\u4f4d\u7f6e\u3001\u91c7\u6837\u65f6\u95f4\u6216\u6d4b\u91cf\u89d2\u5ea6\u7684\u4e00\u7ec4\u56fa\u5b9a\u9884\u7b97\u4e0b\u7684\u8fde\u7eed\u8bbe\u8ba1\u53d8\u91cf\uff0c\u76f4\u63a5\u9488\u5bf9\u6d4b\u91cf\u4f4d\u7f6e\u8fdb\u884c\u4f18\u5316\u3002", "result": "NODE\u65b9\u6cd5\u5728\u53ef\u89e3\u6790\u6307\u6570\u589e\u957f\u57fa\u51c6\u6d4b\u8bd5\u3001MNIST\u56fe\u50cf\u91c7\u6837\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u7a00\u758f\u89c6\u89d2X\u5c04\u7ebfCT\u793a\u4f8b\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u6539\u8fdb\u7684\u91cd\u5efa\u51c6\u786e\u6027\u548c\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u3002", "conclusion": "NODE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u9700\u8981\u6700\u4f73\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u5404\u79cd\u9006\u95ee\u9898\u573a\u666f\uff0c\u5e76\u4e14\u5728\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u91cd\u5efa\u7cbe\u5ea6\u3002"}}
{"id": "2512.24159", "categories": ["cs.SE", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.24159", "abs": "https://arxiv.org/abs/2512.24159", "authors": ["Natalia Garanina", "Vladimir Zyubin", "Igor Anureev"], "title": "Developing controlled natural language for formal specification patterns using AI assistants", "comment": null, "summary": "Using an AI assistant, we developed a method for systematically constructing controlled natural language for requirements based on formal specification patterns containing logical attributes. The method involves three stages: 1) compiling a generalized natural language requirement pattern that utilizes all attributes of the formal specification template; 2) generating, using the AI assistant, a corpus of natural language requirement patterns, reduced by partially evaluating attributes (the developed prompt utilizes the generalized template, attribute definitions, and specific formal semantics of the requirement patterns); and 3) formalizing the syntax of the controlled natural language based on an analysis of the grammatical structure of the resulting patterns. The method has been tested for event-driven temporal requirements.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u89c4\u8303\u6a21\u5f0f\u7684\u7cfb\u7edf\u5316\u6784\u5efa\u9700\u6c42\u63a7\u5236\u81ea\u7136\u8bed\u8a00\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u5b9e\u73b0\uff1a1\uff09\u7f16\u8bd1\u4e00\u4e2a\u5229\u7528\u5f62\u5f0f\u89c4\u8303\u6a21\u677f\u6240\u6709\u5c5e\u6027\u7684\u4e00\u822c\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6a21\u5f0f\uff1b2\uff09\u4f7f\u7528AI\u52a9\u624b\u6839\u636e\u90e8\u5206\u8bc4\u4f30\u5c5e\u6027\u751f\u6210\u4e00\u7cfb\u5217\u7b80\u5316\u540e\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6a21\u5f0f\uff1b3\uff09\u901a\u8fc7\u5bf9\u7ed3\u679c\u6a21\u5f0f\u8bed\u6cd5\u7ed3\u6784\u7684\u5206\u6790\u6765\u6b63\u5f0f\u5316\u63a7\u5236\u81ea\u7136\u8bed\u8a00\u7684\u8bed\u6cd5\u3002\u6b64\u65b9\u6cd5\u5df2\u5728\u4e8b\u4ef6\u9a71\u52a8\u7684\u65f6\u95f4\u9700\u6c42\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5c06\u590d\u6742\u7684\u5f62\u5f0f\u89c4\u8303\u8f6c\u6362\u4e3a\u6613\u4e8e\u7406\u89e3\u7684\u63a7\u5236\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u63cf\u8ff0\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u9700\u6c42\u89c4\u683c\u8bf4\u660e\u7684\u53ef\u8bfb\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e09\u6b65\u6cd5\uff1a\u9996\u5148\u521b\u5efa\u4e00\u4e2a\u901a\u7528\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6a21\u677f\uff0c\u63a5\u7740\u501f\u52a9AI\u5de5\u5177\u751f\u6210\u591a\u4e2a\u5177\u4f53\u7684\u81ea\u7136\u8bed\u8a00\u8868\u8ff0\u6837\u672c\uff0c\u6700\u540e\u5bf9\u8fd9\u4e9b\u6837\u672c\u6587\u672c\u8fdb\u884c\u8bed\u6cd5\u5206\u6790\u5e76\u636e\u6b64\u5b9a\u4e49\u4e00\u5957\u63a7\u5236\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u3002", "result": "\u6210\u529f\u5730\u4e3a\u4e8b\u4ef6\u9a71\u52a8\u578b\u65f6\u95f4\u8981\u6c42\u5236\u5b9a\u4e86\u63a7\u5236\u81ea\u7136\u8bed\u8a00\uff0c\u5e76\u4e14\u8bc1\u5b9e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u8f6c\u6362\u5f62\u5f0f\u5316\u9700\u6c42\u81f3\u66f4\u6613\u61c2\u683c\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408AI\u6280\u672f\u53ef\u4ee5\u5e2e\u52a9\u6709\u6548\u5730\u4ece\u5f62\u5f0f\u5316\u7684\u9700\u6c42\u6a21\u5f0f\u4e2d\u6d3e\u751f\u51fa\u7528\u6237\u53cb\u597d\u7684\u63a7\u5236\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u65b9\u5f0f\uff0c\u8fd9\u5bf9\u4e8e\u6539\u5584\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u6c9f\u901a\u6548\u7387\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.24462", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24462", "abs": "https://arxiv.org/abs/2512.24462", "authors": ["Yoonha Cha", "Victoria Jackson", "Lauren Shu", "Stacy Branham", "Andr\u00e9 van der Hoek"], "title": "\"Game Changer\" or \"Overenthusiastic Drunk Acquaintance\"? Generative AI Use by Blind and Low Vision Software Professionals in the Workplace", "comment": "13 pages", "summary": "The software development workplace poses numerous technical and collaborative accessibility challenges for blind and low vision software professionals (BLVSPs). Though Generative AI (GenAI) is increasingly adopted within the software development industry and has been a rapidly growing topic of interest in research, to date, the unique perspectives of BLVSPs have yet to be consulted. We report on a qualitative study involving 39 semi-structured interviews with BLVSPs about what the introduction of GenAI has meant for their work. We found that BLVSPs used GenAI for many software development tasks, resulting in benefits such as increased productivity and accessibility. However, significant costs were also accompanied by GenAI use as they were more vulnerable to hallucinations than their sighted colleagues. Sometimes, organizational policies prevented use. Based on our findings, we discuss the higher-risks and higher-returns that BLVSPs had to carefully weigh when deciding whether and when to use GenAI tools for work.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\uff08BLVSPs\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u7684\u60c5\u51b5\uff0c\u53d1\u73b0\u5c3d\u7ba1GenAI\u63d0\u9ad8\u4e86\u4ed6\u4eec\u7684\u751f\u4ea7\u529b\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u8bf8\u5982\u5e7b\u89c9\u95ee\u9898\u7b49\u98ce\u9669\uff0c\u5e76\u4e14\u6709\u65f6\u7ec4\u7ec7\u653f\u7b56\u9650\u5236\u4e86\u5176\u4f7f\u7528\u3002", "motivation": "\u8003\u8651\u5230\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u58eb\u5728\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u9762\u4e34\u7684\u6280\u672f\u4e0e\u5408\u4f5c\u969c\u788d\uff0c\u4ee5\u53ca\u4ed6\u4eec\u5bf9\u751f\u6210\u5f0fAI\u7684\u72ec\u7279\u89c6\u89d2\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u8ba8\uff0c\u672c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u751f\u6210\u5f0fAI\u5bf9\u4e8e\u8fd9\u4e9b\u4e13\u4e1a\u4eba\u58eb\u7684\u5de5\u4f5c\u610f\u5473\u7740\u4ec0\u4e48\u3002", "method": "\u901a\u8fc7\u4e0e39\u540d\u76f2\u4eba\u53ca\u4f4e\u89c6\u529b\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u58eb\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u65b9\u5f0f\uff0c\u6536\u96c6\u5173\u4e8e\u5f15\u5165\u751f\u6210\u5f0fAI\u540e\u5bf9\u4ed6\u4eec\u5de5\u4f5c\u5f71\u54cd\u7684\u7b2c\u4e00\u624b\u8d44\u6599\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u751f\u6210\u5f0fAI\u5e2e\u52a9\u63d0\u5347\u4e86\u8fd9\u90e8\u5206\u7fa4\u4f53\u7684\u5de5\u4f5c\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u4f46\u540c\u65f6\u4e5f\u4f34\u968f\u7740\u7279\u5b9a\u6311\u6218\uff0c\u5982\u66f4\u5bb9\u6613\u53d7\u5230AI\u4ea7\u751f\u7684\u9519\u8bef\u4fe1\u606f\u5f71\u54cd\uff1b\u6b64\u5916\uff0c\u4e00\u4e9b\u7ec4\u7ec7\u5185\u90e8\u7684\u653f\u7b56\u4e5f\u6784\u6210\u4e86\u4f7f\u7528\u4e0a\u7684\u969c\u788d\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u8ba8\u8bba\u4e86\u76f2\u4eba\u548c\u4f4e\u89c6\u529b\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u58eb\u5728\u51b3\u5b9a\u662f\u5426\u4ee5\u53ca\u4f55\u65f6\u91c7\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\u65f6\u5fc5\u987b\u6743\u8861\u7684\u9ad8\u98ce\u9669\u4e0e\u9ad8\u56de\u62a5\u3002"}}
{"id": "2512.24530", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.24530", "abs": "https://arxiv.org/abs/2512.24530", "authors": ["Nikolaos Mavrogeorgis", "Christos Vasiladiotis", "Pei Mu", "Amir Khordadi", "Bj\u00f6rn Franke", "Antonio Barbalace"], "title": "A Magnified View into Heterogeneous-ISA Thread Migration Performance without State Transformation", "comment": null, "summary": "Heterogeneous-ISA processor designs have attracted considerable research interest. However, unlike their homogeneous-ISA counterparts, explicit software support for bridging ISA heterogeneity is required. The lack of a compilation toolchain ready to support heterogeneous-ISA targets has been a major factor hindering research in this exciting emerging area. For any such compiler, \"getting right\" the mechanics involved in state transformation upon migration and doing this efficiently is of critical importance. In particular, any runtime conversion of the current program stack from one architecture to another would be prohibitively expensive. In this paper, we design and develop Unifico, a new multi-ISA compiler that generates binaries that maintain the same stack layout during their execution on either architecture. Unifico avoids the need for runtime stack transformation, thus eliminating overheads associated with ISA migration. Additional responsibilities of the Unifico compiler backend include maintenance of a uniform ABI and virtual address space across ISAs. Unifico is implemented using the LLVM compiler infrastructure, and we are currently targeting the x86-64 and ARMv8 ISAs. We have evaluated Unifico across a range of compute-intensive NAS benchmarks and show its minimal impact on overall execution time, where less than 6% (10%) overhead is introduced on average for high-end (low-end) processors. We also analyze the performance impact of Unifico's key design features and demonstrate that they can be further optimized to mitigate this impact. When compared against the state-of-the-art Popcorn compiler, Unifico reduces binary size overhead from ~200% to ~10%, whilst eliminating the stack transformation overhead during ISA migration.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aUnifico\u7684\u65b0\u578b\u591a\u6307\u4ee4\u96c6\u67b6\u6784\u7f16\u8bd1\u5668\uff0c\u8be5\u7f16\u8bd1\u5668\u5728\u4e0d\u540c\u67b6\u6784\u4e0a\u6267\u884c\u65f6\u80fd\u591f\u4fdd\u6301\u76f8\u540c\u7684\u6808\u5e03\u5c40\uff0c\u4ece\u800c\u907f\u514d\u4e86\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\u7684\u9700\u6c42\uff0c\u5e76\u51cf\u5c11\u4e86\u4e0e\u6307\u4ee4\u96c6\u67b6\u6784\u8fc1\u79fb\u76f8\u5173\u7684\u5f00\u9500\u3002", "motivation": "\u5f02\u6784ISA\u5904\u7406\u5668\u8bbe\u8ba1\u9700\u8981\u663e\u5f0f\u7684\u8f6f\u4ef6\u652f\u6301\u6765\u6865\u63a5ISA\u5f02\u8d28\u6027\uff0c\u4f46\u7f3a\u4e4f\u652f\u6301\u5f02\u6784ISA\u76ee\u6807\u7684\u7f16\u8bd1\u5de5\u5177\u94fe\u963b\u788d\u4e86\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u3002\u7f16\u8bd1\u5668\u5728\u8fc1\u79fb\u65f6\u6709\u6548\u5730\u5904\u7406\u72b6\u6001\u8f6c\u6362\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u7a0b\u5e8f\u6808\u4ece\u4e00\u79cd\u67b6\u6784\u5230\u53e6\u4e00\u79cd\u67b6\u6784\u7684\u8fd0\u884c\u65f6\u8f6c\u6362\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u591aISA\u7f16\u8bd1\u5668Unifico\uff0c\u5b83\u751f\u6210\u5728\u4efb\u4e00\u67b6\u6784\u4e0a\u6267\u884c\u671f\u95f4\u4fdd\u6301\u76f8\u540c\u6808\u5e03\u5c40\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002Unifico\u4f7f\u7528LLVM\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\uff0c\u76ee\u524d\u9488\u5bf9x86-64\u548cARMv8 ISA\u3002", "result": "Unifico\u5728\u4e00\u7cfb\u5217\u8ba1\u7b97\u5bc6\u96c6\u578bNAS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u663e\u793a\u5bf9\u6574\u4f53\u6267\u884c\u65f6\u95f4\u7684\u5f71\u54cd\u6781\u5c0f\uff0c\u9ad8\u7aef\uff08\u4f4e\u7aef\uff09\u5904\u7406\u5668\u5e73\u5747\u5f15\u5165\u7684\u5f00\u9500\u4e0d\u52306%\uff0810%\uff09\u3002\u4e0e\u6700\u5148\u8fdb\u7684Popcorn\u7f16\u8bd1\u5668\u76f8\u6bd4\uff0cUnifico\u5c06\u4e8c\u8fdb\u5236\u5927\u5c0f\u5f00\u9500\u4ece\u7ea6200%\u51cf\u5c11\u5230\u7ea610%\uff0c\u540c\u65f6\u6d88\u9664\u4e86ISA\u8fc1\u79fb\u671f\u95f4\u7684\u6808\u8f6c\u6362\u5f00\u9500\u3002", "conclusion": "\u901a\u8fc7\u907f\u514d\u8fd0\u884c\u65f6\u6808\u8f6c\u6362\uff0cUnifico\u6210\u529f\u5730\u6d88\u9664\u4e86\u4e0eISA\u8fc1\u79fb\u76f8\u5173\u7684\u5f00\u9500\uff0c\u5e76\u4e14\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u4e86\u4e8c\u8fdb\u5236\u5927\u5c0f\u5f00\u9500\u3002"}}
{"id": "2512.24560", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24560", "abs": "https://arxiv.org/abs/2512.24560", "authors": ["David Gros", "Prem Devanbu"], "title": "Localized Calibrated Uncertainty in Code Language Models", "comment": null, "summary": "Large Language models (LLMs) can generate complicated source code from natural language prompts. However, LLMs can generate output that deviates from what the user wants, requiring supervision and editing. To support this process, we offer techniques to localize where generations might be misaligned from user intent. We first create a dataset of \"Minimal Intent Aligning Patches\" of repaired LLM generated programs. Each program uses test cases to verify correctness. After creating a dataset of programs, we measure how well various techniques can assign a well-calibrated probability to indicate which parts of code will be edited in a minimal patch (i.e., give a probability that corresponds with empirical odds it is edited). We compare white-box probing (where we propose a technique for efficient arbitrary-span querying), against black-box reflective and self-consistency based approaches. We find probes with a small supervisor model can achieve low calibration error and Brier Skill Score of approx 0.2 estimating edited lines on code generated by models many orders of magnitude larger. We discuss the generalizability of the techniques, and the connections to AI oversight and control, finding a probe trained only on code shows some signs of generalizing to natural language errors if new probability scaling is allowed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u5b9a\u4f4d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u53ef\u80fd\u504f\u79bb\u7528\u6237\u610f\u56fe\u90e8\u5206\u7684\u6280\u672f\uff0c\u5e76\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5305\u542b\u6d4b\u8bd5\u7528\u4f8b\u9a8c\u8bc1\u6b63\u786e\u6027\u7684\u4fee\u590d\u7a0b\u5e8f\u7684\u6570\u636e\u96c6\u6765\u8861\u91cf\u8fd9\u4e9b\u6280\u672f\u7684\u6709\u6548\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5c0f\u578b\u76d1\u7763\u6a21\u578b\u7684\u63a2\u6d4b\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u4f30\u8ba1\u5927\u578b\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u9700\u8981\u7f16\u8f91\u7684\u90e8\u5206\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u751f\u6210\u590d\u6742\u7684\u6e90\u4ee3\u7801\uff0c\u4f46\u6709\u65f6\u751f\u6210\u7684\u7ed3\u679c\u4f1a\u504f\u79bb\u7528\u6237\u7684\u610f\u56fe\uff0c\u9700\u8981\u76d1\u7763\u548c\u7f16\u8f91\u3002\u4e3a\u4e86\u652f\u6301\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6280\u672f\u6765\u5b9a\u4f4d\u4ee3\u7801\u751f\u6210\u4e2d\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u5730\u65b9\u3002", "method": "\u9996\u5148\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b'\u6700\u5c0f\u610f\u56fe\u5bf9\u9f50\u8865\u4e01'\u7684\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u7a0b\u5e8f\u90fd\u5229\u7528\u6d4b\u8bd5\u7528\u4f8b\u6765\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002\u7136\u540e\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6280\u672f\u5728\u4e3a\u4ee3\u7801\u4e2d\u54ea\u4e9b\u90e8\u5206\u5c06\u88ab\u7f16\u8f91\u5206\u914d\u7ecf\u8fc7\u826f\u597d\u6821\u51c6\u7684\u6982\u7387\u65b9\u9762\u7684\u80fd\u529b\u3002\u6bd4\u8f83\u4e86\u767d\u76d2\u63a2\u6d4b\uff08\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4efb\u610f\u8de8\u5ea6\u67e5\u8be2\u7684\u6280\u672f\uff09\u3001\u9ed1\u76d2\u53cd\u5c04\u4ee5\u53ca\u57fa\u4e8e\u81ea\u4e00\u81f4\u6027\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u5c0f\u578b\u76d1\u7763\u6a21\u578b\u8fdb\u884c\u63a2\u6d4b\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u4f30\u8ba1\u7531\u5927\u5f97\u591a\u7684\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u4e2d\u88ab\u7f16\u8f91\u884c\u6570\u65f6\u8fbe\u5230\u8f83\u4f4e\u7684\u6821\u51c6\u8bef\u5dee\u548c\u7ea60.2\u7684Brier\u6280\u80fd\u5206\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u6cdb\u5316\u80fd\u529b\u53ca\u5176\u4e0eAI\u76d1\u7763\u548c\u63a7\u5236\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u53d1\u73b0\u4ec5\u5728\u4ee3\u7801\u4e0a\u8bad\u7ec3\u7684\u63a2\u6d4b\u5668\u5982\u679c\u5141\u8bb8\u65b0\u7684\u6982\u7387\u7f29\u653e\uff0c\u5219\u663e\u793a\u51fa\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6cdb\u5316\u5230\u81ea\u7136\u8bed\u8a00\u9519\u8bef\u7684\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8868\u660e\uff0c\u901a\u8fc7\u4f7f\u7528\u9002\u5f53\u7684\u6280\u672f\u548c\u8f83\u5c0f\u89c4\u6a21\u7684\u76d1\u7763\u6a21\u578b\uff0c\u6709\u53ef\u80fd\u6709\u6548\u5730\u8bc6\u522b\u51fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u6f5c\u5728\u7684\u95ee\u9898\u533a\u57df\uff0c\u4ece\u800c\u63d0\u9ad8\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002\u540c\u65f6\uff0c\u4e5f\u63ed\u793a\u4e86\u8fd9\u4e9b\u6280\u672f\u53ef\u80fd\u5728\u66f4\u5e7f\u6cdb\u7684AI\u5b89\u5168\u548c\u53ef\u63a7\u6027\u9886\u57df\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2512.23773", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23773", "abs": "https://arxiv.org/abs/2512.23773", "authors": ["Molei Qin", "Xinyu Cai", "Yewen Li", "Haochong Xia", "Chuqiao Zong", "Shuo Sun", "Xinrun Wang", "Bo An"], "title": "FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading", "comment": null, "summary": "Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.", "AI": {"tldr": "A novel reinforcement learning framework, FineFT, is introduced for futures trading, which addresses the challenges of high leverage and market unpredictability. Through a three-stage process, it ensures stable training, proper risk management, and improved profitability, outperforming existing methods in several key financial metrics.", "motivation": "The motivation behind this research is to address the challenges of applying reinforcement learning (RL) to the futures market, which is characterized by high leverage and liquidity. The two main issues are the amplified reward fluctuations due to high leverage, leading to unstable training, and the lack of self-awareness regarding the model's capability limits, which can result in significant losses during unexpected market events.", "method": "The proposed method, FineFT, is a three-stage ensemble RL framework. In the first stage, it uses an ensemble of Q learners selectively updated by ensemble TD errors for better convergence. In the second stage, it filters these Q-learners based on their performance and trains VAEs to recognize the boundaries of the learners' capabilities. In the third stage, it selects from the filtered ensemble or a conservative policy, guided by the trained VAEs, to ensure both profitability and risk management under new market conditions.", "result": "Experimental results show that FineFT excels in a high-frequency trading environment with 5x leverage, surpassing 12 state-of-the-art (SOTA) baselines across six financial metrics. It reduces risk by more than 40% compared to the next best performer while also achieving higher profitability. The study also demonstrates that the selective updating of agents and the use of VAEs for identifying learner capabilities contribute to the reduction of maximum drawdown and the improvement of overall performance.", "conclusion": "FineFT, a novel three-stage ensemble RL framework, outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by over 40% while maintaining superior profitability. The selective update mechanism and VAEs-based routing are key to its success."}}
{"id": "2512.24570", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24570", "abs": "https://arxiv.org/abs/2512.24570", "authors": ["Shiqi Kuang", "Zhao Tian", "Tao Xiao", "Dong Wang", "Junjie Chen"], "title": "On the Effectiveness of Training Data Optimization for LLM-based Code Generation: An Empirical Study", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code generation, largely driven by the availability of high-quality code datasets for effective training. To further improve data quality, numerous training data optimization techniques have been proposed; however, their overall effectiveness has not been systematically evaluated. To bridge this gap, we conduct the first large-scale empirical study, examining five widely-used training data optimization techniques and their pairwise combinations for LLM-based code generation across three benchmarks and four LLMs. Our results show that data synthesis is the most effective technique for improving functional correctness and reducing code smells, although it performs relatively worse on code maintainability compared to data refactoring, cleaning, and selection. Regarding combinations, we find that most combinations do not further improve functional correctness but can effectively enhance code quality (code smells and maintainability). Among all combinations, data synthesis combined with data refactoring achieves the strongest overall performance. Furthermore, our fine-grained analysis reinforces these findings and provides deeper insights into how individual techniques and their combinations influence code generation effectiveness. Overall, this work represents a first step toward a systematic understanding of training data optimization and combination strategies, offering practical guidance for future research and deployment in LLM-based code generation.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u4e86\u4e94\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u6280\u672f\u53ca\u5176\u4e24\u4e24\u7ec4\u5408\u5bf9\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7801\u751f\u6210\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6570\u636e\u5408\u6210\u662f\u6700\u6709\u6548\u7684\u6280\u672f\uff0c\u53ef\u4ee5\u63d0\u9ad8\u529f\u80fd\u6b63\u786e\u6027\u5e76\u51cf\u5c11\u4ee3\u7801\u5f02\u5473\uff0c\u4f46\u5728\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u65b9\u9762\u4e0d\u5982\u6570\u636e\u91cd\u6784\u3001\u6e05\u7406\u548c\u9009\u62e9\u3002\u5927\u591a\u6570\u6280\u672f\u7ec4\u5408\u867d\u7136\u4e0d\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u3002\u5176\u4e2d\uff0c\u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u91cd\u6784\u7684\u7ec4\u5408\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5c3d\u7ba1\u4e3a\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u63d0\u51fa\u4e86\u8bb8\u591a\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u6280\u672f\uff0c\u4f46\u5b83\u4eec\u7684\u6574\u4f53\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u9700\u8981\u8fdb\u884c\u4e00\u9879\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u6765\u8003\u5bdf\u8fd9\u4e9b\u6280\u672f\u53ca\u5b83\u4eec\u7684\u7ec4\u5408\u5bf9\u4e8e\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u7684\u6709\u6548\u6027\u3002", "method": "\u7814\u7a76\u9009\u53d6\u4e86\u4e94\u79cd\u5e7f\u6cdb\u5e94\u7528\u7684\u6570\u636e\u4f18\u5316\u6280\u672f\uff0c\u5e76\u8003\u8651\u4e86\u5b83\u4eec\u7684\u6240\u6709\u4e24\u4e24\u7ec4\u5408\u5f62\u5f0f\uff0c\u901a\u8fc7\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u56db\u4e2a\u4e0d\u540c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4ee3\u7801\u751f\u6210\u4e0a\u7684\u6548\u679c\u3002", "result": "\u6570\u636e\u5408\u6210\u5728\u6539\u5584\u529f\u80fd\u6b63\u786e\u6027\u548c\u964d\u4f4e\u4ee3\u7801\u5f02\u5473\u65b9\u9762\u6700\u4e3a\u6709\u6548\uff1b\u7136\u800c\uff0c\u5728\u589e\u5f3a\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u4e0a\uff0c\u6570\u636e\u91cd\u6784\u3001\u6e05\u7406\u548c\u9009\u62e9\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002\u591a\u6570\u6280\u672f\u7ec4\u5408\u80fd\u591f\u6709\u6548\u6539\u5584\u4ee3\u7801\u8d28\u91cf\uff0c\u7279\u522b\u662f\u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u91cd\u6784\u76f8\u7ed3\u5408\u65f6\u6574\u4f53\u6027\u80fd\u6700\u5f3a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u7cfb\u7edf\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u4f18\u5316\u53ca\u7ec4\u5408\u7b56\u7565\u7684\u7b2c\u4e00\u6b65\uff0c\u4e3a\u672a\u6765\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.24594", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.24594", "abs": "https://arxiv.org/abs/2512.24594", "authors": ["Zhongyi Wang", "Tengjie Lin", "Mingshuai Chen", "Haokun Li", "Mingqi Yang", "Xiao Yi", "Shengchao Qin", "Yixing Luo", "Xiaofeng Li", "Bin Gu", "Liqiang Lu", "Jianwei Yin"], "title": "A Tale of 1001 LoC: Potential Runtime Error-Guided Specification Synthesis for Verifying Large-Scale Programs", "comment": "Accepted at OOPSLA 2026", "summary": "Fully automated verification of large-scale software and hardware systems is arguably the holy grail of formal methods. Large language models (LLMs) have recently demonstrated their potential for enhancing the degree of automation in formal verification by, e.g., generating formal specifications as essential to deductive verification, yet exhibit poor scalability due to long-context reasoning limitations and, more importantly, the difficulty of inferring complex, interprocedural specifications. This paper presents Preguss -- a modular, fine-grained framework for automating the generation and refinement of formal specifications. Preguss synergizes between static analysis and deductive verification by steering two components in a divide-and-conquer fashion: (i) potential runtime error-guided construction and prioritization of verification units, and (ii) LLM-aided synthesis of interprocedural specifications at the unit level. We show that Preguss substantially outperforms state-of-the-art LLM-based approaches and, in particular, it enables highly automated RTE-freeness verification for real-world programs with over a thousand LoC, with a reduction of 80.6%~88.9% human verification effort.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPreguss\u7684\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u6f14\u7ece\u9a8c\u8bc1\u6765\u81ea\u52a8\u5316\u751f\u6210\u548c\u4f18\u5316\u5f62\u5f0f\u5316\u89c4\u8303\u3002\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5e76\u5927\u5e45\u5ea6\u51cf\u5c11\u4e86\u4eba\u5de5\u9a8c\u8bc1\u5de5\u4f5c\u91cf\u3002", "motivation": "\u5168\u81ea\u52a8\u7684\u5927\u89c4\u6a21\u8f6f\u4ef6\u548c\u786c\u4ef6\u7cfb\u7edf\u7684\u9a8c\u8bc1\u662f\u5f62\u5f0f\u5316\u65b9\u6cd5\u8ffd\u6c42\u7684\u76ee\u6807\u4e4b\u4e00\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u63d0\u5347\u5f62\u5f0f\u9a8c\u8bc1\u81ea\u52a8\u5316\u7a0b\u5ea6\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u53ca\u63a8\u65ad\u590d\u6742\u3001\u8de8\u8fc7\u7a0b\u89c4\u8303\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "Preguss\u6846\u67b6\u91c7\u7528\u5206\u800c\u6cbb\u4e4b\u7684\u65b9\u5f0f\uff0c\u534f\u540c\u5229\u7528\u9759\u6001\u5206\u6790\u4e0e\u6f14\u7ece\u9a8c\u8bc1\uff0c\u5177\u4f53\u5305\u62ec\uff1a1) \u4ee5\u6f5c\u5728\u8fd0\u884c\u65f6\u9519\u8bef\u4e3a\u5bfc\u5411\u6784\u5efa\u5e76\u4f18\u5148\u6392\u5e8f\u9a8c\u8bc1\u5355\u5143\uff1b2) \u5229\u7528LLM\u8f85\u52a9\u5408\u6210\u5355\u5143\u7ea7\u522b\u7684\u8de8\u8fc7\u7a0b\u89c4\u8303\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPreguss\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8d85\u8fc7\u4e00\u5343\u884c\u4ee3\u7801\u7684\u771f\u5b9e\u7a0b\u5e8f\u5b9e\u73b0\u9ad8\u5ea6\u81ea\u52a8\u5316\u7684\u65e0\u8fd0\u884c\u65f6\u9519\u8bef\u9a8c\u8bc1\uff0c\u540c\u65f6\u5c06\u4eba\u5de5\u9a8c\u8bc1\u5de5\u4f5c\u91cf\u51cf\u5c11\u4e8680.6%~88.9%\u3002", "conclusion": "Preguss\u4e3a\u89e3\u51b3\u5927\u89c4\u6a21\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u81ea\u52a8\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u65b9\u6848\uff0c\u7279\u522b\u64c5\u957f\u4e8e\u51cf\u5c11\u5bf9\u4eba\u5de5\u5e72\u9884\u7684\u9700\u6c42\u4ee5\u53ca\u63d0\u9ad8\u5904\u7406\u590d\u6742\u8de8\u8fc7\u7a0b\u89c4\u8303\u7684\u80fd\u529b\u3002"}}
{"id": "2512.24635", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24635", "abs": "https://arxiv.org/abs/2512.24635", "authors": ["Zhili Huang", "Ling Xu", "Chao Liu", "Weifeng Sun", "Xu Zhang", "Yan Lei", "Meng Yan", "Hongyu Zhang"], "title": "DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information", "comment": "22 pages, 7 figures, preprint version", "summary": "Automated Program Repair (APR) aims to automatically generate correct patches for buggy programs. Recent approaches leveraging large language models (LLMs) have shown promise but face limitations. Most rely solely on static analysis, ignoring runtime behaviors. Some attempt to incorporate dynamic signals, but these are often restricted to training or fine-tuning, or injected only once into the repair prompt, without iterative use. This fails to fully capture program execution. Current iterative repair frameworks typically rely on coarse-grained feedback, such as pass/fail results or exception types, and do not leverage fine-grained execution-level information effectively. As a result, models struggle to simulate human stepwise debugging, limiting their effectiveness in multi-step reasoning and complex bug repair.\n  To address these challenges, we propose DynaFix, an execution-level dynamic information-driven APR method that iteratively leverages runtime information to refine the repair process. In each repair round, DynaFix captures execution-level dynamic information such as variable states, control-flow paths, and call stacks, transforming them into structured prompts to guide LLMs in generating candidate patches. If a patch fails validation, DynaFix re-executes the modified program to collect new execution information for the next attempt. This iterative loop incrementally improves patches based on updated feedback, similar to the stepwise debugging practices of human developers. We evaluate DynaFix on the Defects4J v1.2 and v2.0 benchmarks. DynaFix repairs 186 single-function bugs, a 10% improvement over state-of-the-art baselines, including 38 bugs previously unrepaired. It achieves correct patches within at most 35 attempts, reducing the patch search space by 70% compared with existing methods, thereby demonstrating both effectiveness and efficiency in repairing complex bugs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5DynaFix\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8fed\u4ee3\u5229\u7528\u8fd0\u884c\u65f6\u4fe1\u606f\u6765\u6539\u8fdb\u4fee\u8865\u8fc7\u7a0b\u3002\u5728Defects4J v1.2\u548cv2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDynaFix\u5c55\u793a\u4e86\u5176\u5728\u4fee\u590d\u590d\u6742\u9519\u8bef\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4fee\u590d\u6210\u529f\u7387\u8fd8\u51cf\u5c11\u4e86\u641c\u7d22\u7a7a\u95f4\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u6280\u672f\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u5206\u6790\uff0c\u5ffd\u89c6\u4e86\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u5373\u4fbf\u5c1d\u8bd5\u6574\u5408\u52a8\u6001\u4fe1\u53f7\u4e5f\u591a\u9650\u4e8e\u8bad\u7ec3\u6216\u5fae\u8c03\u9636\u6bb5\uff0c\u5e76\u4e14\u672a\u5145\u5206\u5229\u7528\u6267\u884c\u7ea7\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\u3002\u8fd9\u79cd\u5c40\u9650\u6027\u5bfc\u81f4\u8fd9\u4e9b\u6a21\u578b\u96be\u4ee5\u6a21\u62df\u4eba\u7c7b\u9010\u6b65\u8c03\u8bd5\u7684\u8fc7\u7a0b\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5b83\u4eec\u5904\u7406\u591a\u6b65\u63a8\u7406\u53ca\u4fee\u590d\u590d\u6742\u9519\u8bef\u7684\u80fd\u529b\u3002", "method": "DynaFix\u662f\u4e00\u79cd\u4ee5\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\u4e3a\u9a71\u52a8\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u6bcf\u6b21\u4fee\u590d\u5faa\u73af\u6355\u83b7\u53d8\u91cf\u72b6\u6001\u3001\u63a7\u5236\u6d41\u8def\u5f84\u53ca\u8c03\u7528\u5806\u6808\u7b49\u8fd0\u884c\u65f6\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u7684\u63d0\u793a\u6765\u6307\u5bfc\u5927\u6a21\u578b\u751f\u6210\u5019\u9009\u8865\u4e01\u3002\u5982\u679c\u8865\u4e01\u9a8c\u8bc1\u5931\u8d25\uff0c\u5219\u91cd\u65b0\u6267\u884c\u4fee\u6539\u540e\u7684\u7a0b\u5e8f\u4ee5\u6536\u96c6\u65b0\u4e00\u8f6e\u7684\u4fe1\u606f\u7528\u4e8e\u4e0b\u4e00\u6b21\u5c1d\u8bd5\u3002", "result": "DynaFix\u5728Defects4J v1.2\u548cv2.0\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u6210\u529f\u4fee\u590d\u4e86186\u4e2a\u5355\u51fd\u6570\u9519\u8bef\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u63d0\u9ad8\u4e8610%\uff0c\u5176\u4e2d\u5305\u62ec\u4ee5\u524d\u672a\u88ab\u4fee\u590d\u768438\u4e2a\u9519\u8bef\u3002\u6b64\u5916\uff0c\u5728\u6700\u591a35\u6b21\u5c1d\u8bd5\u5185\u627e\u5230\u6b63\u786e\u7684\u8865\u4e01\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u51cf\u5c11\u4e8670%\u7684\u8865\u4e01\u641c\u7d22\u7a7a\u95f4\u3002", "conclusion": "DynaFix\u901a\u8fc7\u8fed\u4ee3\u5229\u7528\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6210\u529f\u7387\u548c\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u590d\u6742\u7684\u8f6f\u4ef6\u9519\u8bef\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.23816", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23816", "abs": "https://arxiv.org/abs/2512.23816", "authors": ["Wenqian Weng", "Yi He", "Xingyu Zhou"], "title": "Improved Bounds for Private and Robust Alignment", "comment": null, "summary": "In this paper, we study the private and robust alignment of language models from a theoretical perspective by establishing upper bounds on the suboptimality gap in both offline and online settings. We consider preference labels subject to privacy constraints and/or adversarial corruption, and analyze two distinct interplays between them: privacy-first and corruption-first. For the privacy-only setting, we show that log loss with an MLE-style algorithm achieves near-optimal rates, in contrast to conventional wisdom. For the joint privacy-and-corruption setting, we first demonstrate that existing offline algorithms in fact provide stronger guarantees -- simultaneously in terms of corruption level and privacy parameters -- than previously known, which further yields improved bounds in the corruption-only regime. In addition, we also present the first set of results for private and robust online alignment. Our results are enabled by new uniform convergence guarantees for log loss and square loss under privacy and corruption, which we believe have broad applicability across learning theory and statistics.", "AI": {"tldr": "\u672c\u6587\u4ece\u7406\u8bba\u89d2\u5ea6\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u9690\u79c1\u548c\u9c81\u68d2\u6027\u6761\u4ef6\u4e0b\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5728\u7ebf\u548c\u79bb\u7ebf\u8bbe\u7f6e\u4e2d\u6b21\u4f18\u5dee\u8ddd\u7684\u4e0a\u9650\u3002\u5bf9\u4e8e\u4ec5\u8003\u8651\u9690\u79c1\u7684\u60c5\u51b5\uff0c\u8868\u660e\u4f7f\u7528MLE\u98ce\u683c\u7b97\u6cd5\u7684\u65e5\u5fd7\u635f\u5931\u63a5\u8fd1\u6700\u4f18\u7387\uff1b\u5bf9\u4e8e\u540c\u65f6\u8003\u8651\u9690\u79c1\u548c\u7834\u574f\u7684\u60c5\u51b5\uff0c\u8bc1\u660e\u73b0\u6709\u79bb\u7ebf\u7b97\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u5f3a\u4fdd\u8bc1\uff0c\u5e76\u4e3a\u79c1\u6709\u4e14\u9c81\u68d2\u7684\u5728\u7ebf\u5bf9\u9f50\u63d0\u4f9b\u4e86\u9996\u7ec4\u7ed3\u679c\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u5728\u5b58\u5728\u9690\u79c1\u9650\u5236\u548c/\u6216\u5bf9\u6297\u6027\u7834\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u79c1\u5bc6\u6027\u548c\u9c81\u68d2\u6027\u5bf9\u9f50\uff0c\u7279\u522b\u662f\u5728\u65e5\u5fd7\u635f\u5931\u4e0e\u5e73\u65b9\u635f\u5931\u4e0b\u65b0\u7684\u7edf\u4e00\u6536\u655b\u4fdd\u8bc1\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u5728\u7ebf\u548c\u79bb\u7ebf\u73af\u5883\u4e0b\u7684\u6b21\u4f18\u5dee\u8ddd\u4e0a\u754c\u6765\u5206\u6790\u4e24\u79cd\u4e0d\u540c\u573a\u666f\uff1a\u9996\u5148\u8003\u8651\u9690\u79c1\u7136\u540e\u662f\u7834\u574f\uff08privacy-first and corruption-first\uff09\u3002\u7814\u7a76\u4e86\u9488\u5bf9\u4ec5\u9690\u79c1\u3001\u4ec5\u7834\u574f\u4ee5\u53ca\u4e24\u8005\u7ed3\u5408\u60c5\u51b5\u4e0b\u7684\u5904\u7406\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5bf9\u4e8e\u4ec5\u9690\u79c1\u8bbe\u5b9a\uff0c\u91c7\u7528MLE\u6837\u5f0f\u7684\u7b97\u6cd5\u53ef\u4ee5\u8fbe\u5230\u51e0\u4e4e\u6700\u4f18\u7684\u7ed3\u679c\uff1b\u800c\u5bf9\u4e8e\u9690\u79c1\u52a0\u7834\u574f\u7684\u8054\u5408\u8bbe\u5b9a\uff0c\u5219\u5c55\u793a\u4e86\u73b0\u6709\u79bb\u7ebf\u7b97\u6cd5\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u66f4\u5f3a\u5927\uff0c\u4e0d\u4ec5\u5173\u4e8e\u7834\u574f\u6c34\u5e73\u4e5f\u5173\u4e8e\u9690\u79c1\u53c2\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u79c1\u6709\u548c\u9c81\u68d2\u5728\u7ebf\u5bf9\u9f50\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7edf\u4e00\u6536\u655b\u4fdd\u969c\uff0c\u4e3a\u5b66\u4e60\u7406\u8bba\u548c\u7edf\u8ba1\u5b66\u4e2d\u7684\u79c1\u6709\u53ca\u9c81\u68d2\u6027\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u6570\u636e\u9690\u79c1\u7ea6\u675f\u548c\u6f5c\u5728\u654c\u624b\u5e72\u6270\u65f6\u3002"}}
{"id": "2512.24656", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24656", "abs": "https://arxiv.org/abs/2512.24656", "authors": ["Mir Mohammad Yousuf", "Shabir Ahmad Sofi"], "title": "Characterizing Bugs and Quality Attributes in Quantum Software: A Large-Scale Empirical Study", "comment": null, "summary": "Quantum Software Engineering (QSE) is essential for ensuring the reliability and maintainability of hybrid quantum-classical systems, yet empirical evidence on how bugs emerge and affect quality in real-world quantum projects remains limited. This study presents the first ecosystem-scale longitudinal analysis of software defects across 123 open source quantum repositories from 2012 to 2024, spanning eight functional categories, including full-stack libraries, simulators, annealing, algorithms, compilers, assembly, cryptography, and experimental computing. Using a mixed method approach combining repository mining, static code analysis, issue metadata extraction, and a validated rule-based classification framework, we analyze 32,296 verified bug reports. Results show that full-stack libraries and compilers are the most defect-prone categories due to circuit, gate, and transpilation-related issues, while simulators are mainly affected by measurement and noise modeling errors. Classical bugs primarily impact usability and interoperability, whereas quantum-specific bugs disproportionately degrade performance, maintainability, and reliability. Longitudinal analysis indicates ecosystem maturation, with defect densities peaking between 2017 and 2021 and declining thereafter. High-severity defects cluster in cryptography, experimental computing, and compiler toolchains. Repositories employing automated testing detect more defects and resolve issues faster. A negative binomial regression further shows that automated testing is associated with an approximate 60 percent reduction in expected defect incidence. Overall, this work provides the first large-scale data-driven characterization of quantum software defects and offers empirical guidance for improving testing, documentation, and maintainability practices in QSE.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9123\u4e2a\u5f00\u6e90\u91cf\u5b50\u5b58\u50a8\u5e93\u8fdb\u884c\u4e86\u9996\u6b21\u751f\u6001\u7cfb\u7edf\u89c4\u6a21\u7684\u7eb5\u5411\u5206\u6790\uff0c\u6db5\u76d6\u4e86\u4ece2012\u5e74\u52302024\u5e74\u7684\u8f6f\u4ef6\u7f3a\u9677\u60c5\u51b5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5168\u6808\u5e93\u548c\u7f16\u8bd1\u5668\u7531\u4e8e\u7535\u8def\u3001\u95e8\u53ca\u8f6c\u8bd1\u76f8\u5173\u95ee\u9898\u800c\u6700\u5bb9\u6613\u51fa\u73b0\u7f3a\u9677\uff0c\u800c\u6a21\u62df\u5668\u4e3b\u8981\u53d7\u5230\u6d4b\u91cf\u548c\u566a\u58f0\u5efa\u6a21\u9519\u8bef\u7684\u5f71\u54cd\u3002\u7ecf\u5178bug\u4e3b\u8981\u5f71\u54cd\u53ef\u7528\u6027\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u800c\u7279\u5b9a\u4e8e\u91cf\u5b50\u7684bug\u5219\u4e0d\u6210\u6bd4\u4f8b\u5730\u964d\u4f4e\u4e86\u6027\u80fd\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\u3002\u901a\u8fc7\u81ea\u52a8\u5316\u6d4b\u8bd5\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u9884\u671f\u7684\u7f3a\u9677\u53d1\u751f\u7387\u3002", "motivation": "\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u5bf9\u4e8e\u786e\u4fdd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5173\u4e8ebug\u5982\u4f55\u5728\u5b9e\u9645\u91cf\u5b50\u9879\u76ee\u4e2d\u4ea7\u751f\u53ca\u5176\u5bf9\u8d28\u91cf\u7684\u5f71\u54cd\u7684\u5b9e\u9645\u8bc1\u636e\u4ecd\u7136\u6709\u9650\u3002", "method": "\u91c7\u7528\u7ed3\u5408\u4e86\u4ed3\u5e93\u6316\u6398\u3001\u9759\u6001\u4ee3\u7801\u5206\u6790\u3001\u95ee\u9898\u5143\u6570\u636e\u63d0\u53d6\u4ee5\u53ca\u4e00\u4e2a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5206\u7c7b\u6846\u67b6\u7684\u6df7\u5408\u65b9\u6cd5\u6765\u5206\u679032,296\u4efd\u6838\u5b9e\u8fc7\u7684bug\u62a5\u544a\u3002", "result": "\u5168\u6808\u5e93\u548c\u7f16\u8bd1\u5668\u662f\u6700\u5bb9\u6613\u51fa\u73b0\u7f3a\u9677\u7684\u7c7b\u522b\uff1b\u6a21\u62df\u5668\u4e3b\u8981\u53d7\u6d4b\u91cf\u548c\u566a\u58f0\u5efa\u6a21\u9519\u8bef\u5f71\u54cd\uff1b\u7ecf\u5178bug\u4e3b\u8981\u5f71\u54cd\u53ef\u7528\u6027\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u800c\u91cf\u5b50\u7279\u5b9abug\u5219\u7279\u522b\u635f\u5bb3\u6027\u80fd\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u9760\u6027\u3002\u957f\u671f\u5206\u6790\u663e\u793a\uff0c\u7f3a\u9677\u5bc6\u5ea6\u57282017\u5e74\u81f32021\u5e74\u95f4\u8fbe\u5230\u9876\u5cf0\uff0c\u4e4b\u540e\u4e0b\u964d\u3002\u9ad8\u4e25\u91cd\u6027\u7f3a\u9677\u96c6\u4e2d\u5728\u5bc6\u7801\u5b66\u3001\u5b9e\u9a8c\u8ba1\u7b97\u548c\u7f16\u8bd1\u5de5\u5177\u94fe\u4e2d\u3002\u4f7f\u7528\u81ea\u52a8\u5316\u6d4b\u8bd5\u7684\u5b58\u50a8\u5e93\u80fd\u66f4\u5feb\u68c0\u6d4b\u5e76\u89e3\u51b3\u95ee\u9898\u3002\u8d1f\u4e8c\u9879\u56de\u5f52\u8fdb\u4e00\u6b65\u8868\u660e\uff0c\u81ea\u52a8\u5316\u6d4b\u8bd5\u4e0e\u9884\u671f\u7f3a\u9677\u53d1\u751f\u7387\u5927\u7ea6\u964d\u4f4e60%\u6709\u5173\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u9a71\u52a8\u7684\u91cf\u5b50\u8f6f\u4ef6\u7f3a\u9677\u7279\u5f81\u63cf\u8ff0\uff0c\u5e76\u4e3a\u6539\u8fdb\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6d4b\u8bd5\u3001\u6587\u6863\u7f16\u5236\u548c\u53ef\u7ef4\u62a4\u6027\u5b9e\u8df5\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6307\u5bfc\u3002"}}
{"id": "2512.23832", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23832", "abs": "https://arxiv.org/abs/2512.23832", "authors": ["YuYang Miao", "Chang Li", "Zehua Chen"], "title": "Exploiting the Prior of Generative Time Series Imputation", "comment": null, "summary": "Time series imputation, i.e., filling the missing values of a time recording, finds various applications in electricity, finance, and weather modelling. Previous methods have introduced generative models such as diffusion probabilistic models and Schrodinger bridge models to conditionally generate the missing values from Gaussian noise or directly from linear interpolation results. However, as their prior is not informative to the ground-truth target, their generation process inevitably suffer increased burden and limited imputation accuracy. In this work, we present Bridge-TS, building a data-to-data generation process for generative time series imputation and exploiting the design of prior with two novel designs. Firstly, we propose expert prior, leveraging a pretrained transformer-based module as an expert to fill the missing values with a deterministic estimation, and then taking the results as the prior of ground truth target. Secondly, we explore compositional priors, utilizing several pretrained models to provide different estimation results, and then combining them in the data-to-data generation process to achieve a compositional priors-to-target imputation process. Experiments conducted on several benchmark datasets such as ETT, Exchange, and Weather show that Bridge-TS reaches a new record of imputation accuracy in terms of mean square error and mean absolute error, demonstrating the superiority of improving prior for generative time series imputation.", "AI": {"tldr": "\u63d0\u51fa\u4e86Bridge-TS\uff0c\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e13\u5bb6\u5148\u9a8c\u548c\u7ec4\u5408\u5148\u9a8c\u6765\u63d0\u9ad8\u751f\u6210\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u66f4\u9ad8\u7684\u586b\u8865\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u65b9\u6cd5\u7531\u4e8e\u5176\u5148\u9a8c\u4fe1\u606f\u4e0d\u8db3\u4ee5\u53cd\u6620\u771f\u5b9e\u76ee\u6807\uff0c\u5bfc\u81f4\u751f\u6210\u8fc7\u7a0b\u8d1f\u62c5\u589e\u52a0\u4e14\u586b\u8865\u7cbe\u5ea6\u6709\u9650\u3002", "method": "\u8bbe\u8ba1\u4e86\u540d\u4e3aBridge-TS\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u5305\u62ec\u5229\u7528\u9884\u8bad\u7ec3\u7684\u57fa\u4e8eTransformer\u6a21\u5757\u4f5c\u4e3a\u4e13\u5bb6\u6765\u786e\u5b9a\u6027\u5730\u4f30\u8ba1\u7f3a\u5931\u503c\uff08\u4e13\u5bb6\u5148\u9a8c\uff09\u4ee5\u53ca\u7ed3\u5408\u591a\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u4f9b\u7684\u4e0d\u540c\u4f30\u8ba1\u7ed3\u679c\u4ee5\u5b9e\u73b0\u4ece\u7ec4\u5408\u5148\u9a8c\u5230\u76ee\u6807\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff08\u7ec4\u5408\u5148\u9a8c\uff09\u3002", "result": "\u5728ETT\u3001Exchange\u548cWeather\u7b49\u51e0\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cBridge-TS\u5728\u5747\u65b9\u8bef\u5dee(MSE)\u548c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\u65b9\u9762\u8fbe\u5230\u4e86\u65b0\u7684\u586b\u8865\u51c6\u786e\u5ea6\u8bb0\u5f55\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u7528\u4e8e\u751f\u6210\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u7684\u5148\u9a8c\uff0cBridge-TS\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u586b\u8865\u51c6\u786e\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2512.24858", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.24858", "abs": "https://arxiv.org/abs/2512.24858", "authors": ["Ke Ma", "Jianjun Huang", "Wei You", "Bin Liang", "Jingzheng Wu", "Yanjun Wu", "Yuanjun Gong"], "title": "Feature Slice Matching for Precise Bug Detection", "comment": "Accepted by FSE2026", "summary": "Measuring the function similarity to detect bugs is effective, but the statements unrelated to the bugs can impede the performance due to the noise interference. Suppressing the noise interference in existing works does not manage the tough job, i.e., eliminating the noise in the targets. In this paper, we propose MATUS to mitigate the target noise for precise bug detection based on similarity measurement. Feature slices are extracted from both the buggy query and the targets to represent the semantic feature of (potential) bug logics. In particular, MATUS guides the target slicing with the prior knowledge from the buggy code, in an end-to-end way to pinpoint the slicing criterion in the targets. All feature slices are embedded and compared based on the vector similarity. Buggy candidates are audited to confirm unknown bugs in the targets. Experiments show that MATUS holds advantages in bug detection for real-world projects with acceptable efficiency. In total, MATUS has spotted 31 unknown bugs in the Linux kernel. All of them have been confirmed by the kernel developers, and 11 have been assigned CVEs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMATUS\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u76ee\u6807\u566a\u97f3\u6765\u63d0\u9ad8\u57fa\u4e8e\u76f8\u4f3c\u6027\u5ea6\u91cf\u7684\u7cbe\u786e\u9519\u8bef\u68c0\u6d4b\u3002\u8be5\u65b9\u6cd5\u4ece\u6709\u7f3a\u9677\u7684\u67e5\u8be2\u548c\u76ee\u6807\u4e2d\u63d0\u53d6\u7279\u5f81\u7247\u6bb5\u4ee5\u8868\u793a\uff08\u6f5c\u5728\uff09\u9519\u8bef\u903b\u8f91\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u6700\u7ec8\u5728\u5b9e\u9645\u9879\u76ee\u4e2d\u6709\u6548\u68c0\u6d4b\u5230\u672a\u77e5\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u51fd\u6570\u76f8\u4f3c\u6027\u6d4b\u91cf\u8fdb\u884c\u9519\u8bef\u68c0\u6d4b\u7684\u65b9\u6cd5\u53d7\u5230\u65e0\u5173\u8bed\u53e5\u4ea7\u751f\u7684\u566a\u58f0\u5e72\u6270\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u5230\u5f71\u54cd\u3002\u73b0\u6709\u5de5\u4f5c\u5728\u6291\u5236\u566a\u58f0\u5e72\u6270\u65b9\u9762\u6548\u679c\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u65e0\u6cd5\u6d88\u9664\u76ee\u6807\u4e2d\u7684\u566a\u58f0\u3002", "method": "MATUS\u901a\u8fc7\u4ece\u6709\u7f3a\u9677\u7684\u67e5\u8be2\u548c\u76ee\u6807\u4ee3\u7801\u4e2d\u62bd\u53d6\u7279\u5f81\u7247\u6bb5\u6765\u8868\u793a\u6f5c\u5728\u9519\u8bef\u903b\u8f91\u7684\u8bed\u4e49\u7279\u5f81\u3002\u5b83\u5229\u7528\u4e86\u6709\u7f3a\u9677\u4ee3\u7801\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u6307\u5bfc\u76ee\u6807\u5207\u7247\u8fc7\u7a0b\uff0c\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u786e\u5b9a\u76ee\u6807\u4e2d\u7684\u5207\u7247\u6807\u51c6\u3002\u6240\u6709\u7279\u5f81\u7247\u6bb5\u90fd\u88ab\u5d4c\u5165\u5e76\u901a\u8fc7\u5411\u91cf\u76f8\u4f3c\u6027\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ece\u800c\u5ba1\u8ba1\u53ef\u7591\u9519\u8bef\u5019\u9009\u8005\u786e\u8ba4\u76ee\u6807\u4e2d\u7684\u672a\u77e5\u9519\u8bef\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMATUS\u5728\u771f\u5b9e\u4e16\u754c\u9879\u76ee\u7684\u9519\u8bef\u68c0\u6d4b\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u5e76\u4e14\u6548\u7387\u53ef\u63a5\u53d7\u3002\u5b83\u603b\u5171\u53d1\u73b0\u4e86Linux\u5185\u6838\u4e2d\u768431\u4e2a\u672a\u77e5\u9519\u8bef\uff0c\u8fd9\u4e9b\u9519\u8bef\u90fd\u5f97\u5230\u4e86\u5185\u6838\u5f00\u53d1\u8005\u7684\u786e\u8ba4\uff0c\u5e76\u4e14\u5176\u4e2d11\u4e2a\u88ab\u5206\u914d\u4e86CVE\u7f16\u53f7\u3002", "conclusion": "MATUS\u4e3a\u89e3\u51b3\u57fa\u4e8e\u76f8\u4f3c\u6027\u5ea6\u91cf\u7684\u9519\u8bef\u68c0\u6d4b\u4e2d\u7684\u566a\u58f0\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u8f6f\u4ef6\u4e2d\u7684\u672a\u77e5\u9519\u8bef\u3002"}}
{"id": "2512.23852", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23852", "abs": "https://arxiv.org/abs/2512.23852", "authors": ["Mahdi Karami", "Ali Behrouz", "Praneeth Kacham", "Vahab Mirrokni"], "title": "Trellis: Learning to Compress Key-Value Memory in Attention Models", "comment": "In Second Conference on Language Modeling (COLM) (2025)", "summary": "Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Transformer\u67b6\u6784Trellis\uff0c\u8be5\u67b6\u6784\u5177\u6709\u56fa\u5b9a\u5185\u5b58\u5e76\u80fd\u5728\u6d4b\u8bd5\u65f6\u52a8\u6001\u538b\u7f29\u5176\u952e\u503c\u5185\u5b58\u3002\u901a\u8fc7\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u8fc7\u7a0b\u548c\u9057\u5fd8\u95e8\u673a\u5236\uff0cTrellis\u80fd\u591f\u9012\u5f52\u66f4\u65b0\u538b\u7f29\u540e\u7684\u5185\u5b58\uff0c\u5e76\u5728\u5904\u7406\u957f\u5e8f\u5217\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u7684Transformer\u6a21\u578b\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u53ca\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u952e\u503c\u7f13\u5b58\u4e0d\u65ad\u589e\u957f\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86Trellis\u67b6\u6784\uff0c\u65e8\u5728\u901a\u8fc7\u4f7f\u7528\u56fa\u5b9a\u5927\u5c0f\u7684\u5185\u5b58\u5e76\u5b66\u4e60\u5982\u4f55\u5728\u6d4b\u8bd5\u65f6\u52a8\u6001\u538b\u7f29\u952e\u503c\u5185\u5b58\u6765\u6539\u5584\u6548\u7387\u4e0e\u6027\u80fd\u3002", "method": "Trellis\u67b6\u6784\u7528\u56fa\u5b9a\u5927\u5c0f\u7684\u5185\u5b58\u66ff\u6362\u4e86\u6807\u51c6\u7684\u952e\u503c\u7f13\u5b58\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u5faa\u73af\u538b\u7f29\u673a\u5236\u4ee5\u5c06\u65b0\u952e\u503c\u5b58\u50a8\u5230\u5185\u5b58\u4e2d\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u5e26\u6709\u9057\u5fd8\u95e8\u7684\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u7a0b\u5e8f\uff0c\u4f7f\u5f97\u538b\u7f29\u540e\u7684\u5185\u5b58\u53ef\u4ee5\u9012\u5f52\u5730\u66f4\u65b0\uff0c\u540c\u65f6\u5b66\u4f1a\u4fdd\u7559\u6765\u81ea\u8f93\u5165\u6807\u8bb0\u7684\u91cd\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTrellis\u67b6\u6784\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u5e38\u8bc6\u63a8\u7406\u3001\u53ec\u56de\u5bc6\u96c6\u578b\u4efb\u52a1\u4ee5\u53ca\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7b49\u591a\u4e2a\u9886\u57df\u8d85\u8d8a\u4e86\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u7279\u522b\u662f\u5f53\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u65f6\uff0c\u5176\u6027\u80fd\u63d0\u5347\u66f4\u52a0\u663e\u8457\uff0c\u7a81\u663e\u51fa\u5176\u5728\u957f\u4e0a\u4e0b\u6587\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "Trellis\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684Transformer\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u5904\u7406\u957f\u5e8f\u5217\u7684\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2512.23853", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23853", "abs": "https://arxiv.org/abs/2512.23853", "authors": ["Hussen Abu Hamad", "Dan Rosenbaum"], "title": "Flow Matching Neural Processes", "comment": "NeurIPS 2025. For code, see https://github.com/danrsm/flowNP", "summary": "Neural processes (NPs) are a class of models that learn stochastic processes directly from data and can be used for inference, sampling and conditional sampling. We introduce a new NP model based on flow matching, a generative modeling paradigm that has demonstrated strong performance on various data modalities. Following the NP training framework, the model provides amortized predictions of conditional distributions over any arbitrary points in the data. Compared to previous NP models, our model is simple to implement and can be used to sample from conditional distributions using an ODE solver, without requiring auxiliary conditioning methods. In addition, the model provides a controllable tradeoff between accuracy and running time via the number of steps in the ODE solver. We show that our model outperforms previous state-of-the-art neural process methods on various benchmarks including synthetic 1D Gaussian processes data, 2D images, and real-world weather data.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u65b0\u578b\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6613\u4e8e\u5b9e\u73b0\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7ODE\u6c42\u89e3\u5668\u4ece\u6761\u4ef6\u5206\u5e03\u4e2d\u91c7\u6837\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8c03\u6574ODE\u6c42\u89e3\u5668\u4e2d\u7684\u6b65\u6570\uff0c\u6a21\u578b\u8fd8\u80fd\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e4b\u95f4\u63d0\u4f9b\u53ef\u63a7\u7684\u6743\u8861\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5408\u6210\u7684\u4e00\u7ef4\u9ad8\u65af\u8fc7\u7a0b\u6570\u636e\u3001\u4e8c\u7ef4\u56fe\u50cf\u4ee5\u53ca\u771f\u5b9e\u5929\u6c14\u6570\u636e\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\u5728\u5b9e\u65bd\u590d\u6742\u5ea6\u548c\u91c7\u6837\u6548\u7387\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u7b80\u5316\u4e86\u6a21\u578b\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u8fd8\u5141\u8bb8\u4f7f\u7528ODE\u6c42\u89e3\u5668\u76f4\u63a5\u8fdb\u884c\u6761\u4ef6\u5206\u5e03\u91c7\u6837\uff0c\u65e0\u9700\u989d\u5916\u7684\u6761\u4ef6\u5316\u624b\u6bb5\u3002\u540c\u65f6\uff0c\u65b0\u6a21\u578b\u80fd\u591f\u6839\u636e\u5b9e\u9645\u9700\u8981\u7075\u6d3b\u8c03\u6574\u7cbe\u786e\u5ea6\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u8861\u70b9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\u91c7\u7528\u4e86\u6d41\u5339\u914d\u8fd9\u4e00\u751f\u6210\u5efa\u6a21\u8303\u5f0f\u3002\u8be5\u6a21\u578b\u9075\u5faaNP\u8bad\u7ec3\u6846\u67b6\uff0c\u80fd\u591f\u5bf9\u4efb\u610f\u6570\u636e\u70b9\u4e0a\u7684\u6761\u4ef6\u5206\u5e03\u505a\u51fa\u9884\u4f30\u3002\u7279\u522b\u5730\uff0c\u5b83\u5229\u7528ODE\uff08\u5e38\u5fae\u5206\u65b9\u7a0b\uff09\u6c42\u89e3\u6280\u672f\u6765\u6267\u884c\u6761\u4ef6\u5206\u5e03\u91c7\u6837\u4efb\u52a1\uff0c\u8fd9\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u8c03\u8282ODE\u6c42\u89e3\u6b65\u9aa4\u6570\u76ee\u6765\u63a7\u5236\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u795e\u7ecf\u8fc7\u7a0b\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5305\u62ec\u5408\u6210\u7684\u4e00\u7ef4\u9ad8\u65af\u8fc7\u7a0b\u6570\u636e\u3001\u4e8c\u7ef4\u56fe\u50cf\u5904\u7406\u53ca\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u5929\u6c14\u6570\u636e\u5206\u6790\u4efb\u52a1\u3002", "conclusion": "\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u65b0\u9896\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\u56e0\u5176\u7b80\u6d01\u7684\u8bbe\u8ba1\u7406\u5ff5\u3001\u9ad8\u6548\u7684\u91c7\u6837\u673a\u5236\u4ee5\u53ca\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u5c55\u73b0\u4e86\u5176\u4f5c\u4e3a\u65b0\u4e00\u4ee3\u795e\u7ecf\u8fc7\u7a0b\u89e3\u51b3\u65b9\u6848\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.13749", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13749", "abs": "https://arxiv.org/abs/2512.13749", "authors": ["Joyjit Roy", "Samaresh Kumar Singh"], "title": "Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis", "comment": "6 pages, 2 figures. Submitted to IEEE IATMSI-2026 (Track: AI, IoT and Computer Vision Enabled Technologies)", "summary": "Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u6bd4\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u4f7f\u7528Word2Vec\u3001GloVe\u548c\u53e5\u5b50\u8f6c\u6362\u5668\u7b49\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u8fdb\u884c\u91d1\u878d\u65b0\u95fb\u60c5\u611f\u5206\u7c7b\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u9a8c\u8bc1\u6307\u6807\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u5374\u4f4e\u4e8e\u7b80\u5355\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e14\u9884\u8bad\u7ec3\u7684\u5d4c\u5165\u53ea\u6709\u5728\u8fbe\u5230\u4e00\u5b9a\u6570\u636e\u5145\u8db3\u9608\u503c\u65f6\u624d\u80fd\u4ea7\u751f\u8f83\u597d\u6548\u679c\u3002\u5bf9\u4e8e\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\uff0c\u5efa\u8bae\u8003\u8651\u5c11\u6837\u672c\u5b66\u4e60\u3001\u6570\u636e\u589e\u5f3a\u6216\u8bcd\u5178\u589e\u5f3a\u7684\u6df7\u5408\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u6807\u51c6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5bf9\u91d1\u878d\u65b0\u95fb\u60c5\u611f\u5206\u7c7b\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u4e86Word2Vec\u3001GloVe\u4ee5\u53ca\u53e5\u5b50\u8f6c\u6362\u5668\u4f5c\u4e3a\u6587\u672c\u8868\u793a\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u6765\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u65b0\u95fb\u6807\u9898\u8fdb\u884c\u5206\u6790\u3002", "result": "\u89c2\u5bdf\u5230\u9a8c\u8bc1\u4e0e\u6d4b\u8bd5\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5373\u4f7f\u662f\u5728\u5f3a\u5927\u7684\u9a8c\u8bc1\u6307\u6807\u4e0b\u6a21\u578b\u7684\u8868\u73b0\u4e5f\u5dee\u4e8e\u7b80\u5355\u57fa\u7ebf\uff1b\u9884\u8bad\u7ec3\u7684\u5d4c\u5165\u4ec5\u5728\u8d85\u8fc7\u7279\u5b9a\u7684\u6570\u636e\u5145\u5206\u6027\u9608\u503c\u65f6\u624d\u663e\u793a\u51fa\u4ef7\u503c\uff1b\u5c0f\u578b\u9a8c\u8bc1\u96c6\u5bfc\u81f4\u6a21\u578b\u9009\u62e9\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u3002", "conclusion": "\u5355\u9760\u63d0\u9ad8\u5d4c\u5165\u8d28\u91cf\u65e0\u6cd5\u89e3\u51b3\u60c5\u611f\u5206\u7c7b\u4e2d\u6839\u672c\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u5bf9\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u64cd\u4f5c\u8005\u6765\u8bf4\uff0c\u5728\u6807\u8bb0\u6837\u672c\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u5e94\u8be5\u63a2\u7d22\u5982\u5c11\u6837\u672c\u5b66\u4e60\u3001\u6570\u636e\u6269\u589e\u6216\u8bcd\u5178\u589e\u5f3a\u7684\u6df7\u5408\u65b9\u6cd5\u7b49\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2512.23858", "categories": ["cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.23858", "abs": "https://arxiv.org/abs/2512.23858", "authors": ["Yue Guan", "Changming Yu", "Shihan Fang", "Weiming Hu", "Zaifeng Pan", "Zheng Wang", "Zihan Liu", "Yangjie Zhou", "Yufei Ding", "Minyi Guo", "Jingwen Leng"], "title": "Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding", "comment": "Accepted by NeurIPS 2025", "summary": "Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-optimal speculative decoding through context-aware tree drafting and compiler-friendly execution. Yggdrasil introduces an equal-growth tree structure for static graph compatibility, a latency-aware optimization objective for draft selection, and stage-based scheduling to reduce overhead. Yggdrasil supports unmodified LLMs and achieves up to $3.98\\times$ speedup over state-of-the-art baselines across multiple hardware setups.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Yggdrasil\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6811\u5f62\u8349\u7a3f\u548c\u5bf9\u7f16\u8bd1\u5668\u53cb\u597d\u7684\u6267\u884c\u6765\u5b9e\u73b0\u5ef6\u8fdf\u6700\u4f18\u7684\u63a8\u6d4b\u89e3\u7801\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u63a8\u6d4b\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u7531\u4e8e\u52a8\u6001\u63a8\u6d4b\u4e0e\u9759\u6001\u8fd0\u884c\u65f6\u5047\u8bbe\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u800c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86Yggdrasil\uff0c\u4e00\u4e2a\u5171\u540c\u8bbe\u8ba1\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u4e86\u7b49\u589e\u957f\u6811\u7ed3\u6784\u3001\u5ef6\u8fdf\u611f\u77e5\u4f18\u5316\u76ee\u6807\u4ee5\u53ca\u57fa\u4e8e\u9636\u6bb5\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u4ee5\u652f\u6301\u672a\u4fee\u6539\u7684\u8bed\u8a00\u6a21\u578b\u5e76\u51cf\u5c11\u5f00\u9500\u3002", "result": "Yggdrasil\u5728\u591a\u79cd\u786c\u4ef6\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u9ad8\u8fbe3.98\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "Yggdrasil\u5c55\u793a\u4e86\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u95ee\u9898\u7684\u6709\u6548\u6027\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u901f\u5ea6\u3002"}}
{"id": "2512.23862", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23862", "abs": "https://arxiv.org/abs/2512.23862", "authors": ["Ruizhe Huang", "Kexuan Zhang", "Yihao Fang", "Baifeng Yu"], "title": "Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining", "comment": null, "summary": "This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u7684\u5c0f\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u4ee5\u5b9e\u73b0\u6709\u9650\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u6709\u6548\u5229\u7528\u3001\u63d0\u9ad8\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u53ef\u8bbf\u95ee\u6027\u5e76\u964d\u4f4e\u6210\u672c\u3002\u901a\u8fc7\u4f7f\u7528Infini-attention\u673a\u5236\uff0c\u5373\u4f7f\u5728\u957f\u4e0a\u4e0b\u6587\u68c0\u7d22\u4e2d\u6027\u80fd\u6709\u6240\u4e0b\u964d\uff0c\u8be5\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebf\u4ecd\u80fd\u8868\u73b0\u51fa\u9ad8\u8fbe31%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5c0f\u89c4\u6a21\u9884\u8bad\u7ec3\u6280\u672f\u6765\u63d0\u9ad8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u548c\u7b97\u529b\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u4e14\u901a\u8fc7\u5f15\u5165Infini-attention\u6539\u5584\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u3002", "method": "\u91c7\u75283\u4ebf\u53c2\u6570\u7684LLaMA\u6a21\u578b\u4f5c\u4e3a\u57fa\u7840\uff0c\u7ed3\u5408Infini-attention\u8fdb\u884c\u9884\u8bad\u7ec3\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u5bf9\u8fc7\u53bb\u6bb5\u843d\u6784\u5efa\u538b\u7f29\u8bb0\u5fc6\u540c\u65f6\u4fdd\u6301\u5c40\u90e8\u6ce8\u610f\u529b\uff0c\u4ee5\u589e\u5f3a\u7d27\u51d1\u6a21\u578b\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u5916\u63a8\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u4e0d\u4ec5\u5c55\u793a\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u800c\u4e14\u5728\u957f\u4e0a\u4e0b\u6587\u68c0\u7d22\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u57fa\u7ebf\u6a21\u578b\u3002\u5c3d\u7ba1\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u5bfc\u81f4\u591a\u6b21\u8bb0\u5fc6\u538b\u7f29\u540e\u68c0\u7d22\u51c6\u786e\u6027\u964d\u4f4e\uff0c\u4f46\u603b\u4f53\u4e0aInfini-attention\u663e\u8457\u63d0\u5347\u4e86SLM\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728SLMs\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u53ef\u4ee5\u4ece\u7c7b\u4f3cInfini-attention\u8fd9\u6837\u7684\u67b6\u6784\u8bb0\u5fc6\u4e2d\u53d7\u76ca\u3002"}}
{"id": "2512.23870", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23870", "abs": "https://arxiv.org/abs/2512.23870", "authors": ["Yuyang Zhang", "Yang Hu", "Bo Dai", "Na Li"], "title": "Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR", "comment": null, "summary": "Soft actor-critic (SAC) is a popular algorithm for max-entropy reinforcement learning. In practice, the energy-based policies in SAC are often approximated using simple policy classes for efficiency, sacrificing the expressiveness and robustness. In this paper, we propose a variant of the SAC algorithm that parameterizes the policy with flow-based models, leveraging their rich expressiveness. In the algorithm, we evaluate the flow-based policy utilizing the instantaneous change-of-variable technique and update the policy with an online variant of flow matching developed in this paper. This online variant, termed importance sampling flow matching (ISFM), enables policy update with only samples from a user-specified sampling distribution rather than the unknown target distribution. We develop a theoretical analysis of ISFM, characterizing how different choices of sampling distributions affect the learning efficiency. Finally, we conduct a case study of our algorithm on the max-entropy linear quadratic regulator problems, demonstrating that the proposed algorithm learns the optimal action distribution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u6a21\u578b\u53c2\u6570\u5316\u7684SAC\u7b97\u6cd5\u53d8\u4f53\uff0c\u901a\u8fc7\u5373\u65f6\u53d8\u91cf\u53d8\u6362\u6280\u672f\u8bc4\u4f30\u7b56\u7565\uff0c\u5e76\u4f7f\u7528\u4e00\u79cd\u5728\u7ebf\u53d8\u4f53\u7684\u6d41\u5339\u914d\u65b9\u6cd5\u66f4\u65b0\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u8981\u4ece\u7528\u6237\u6307\u5b9a\u7684\u91c7\u6837\u5206\u5e03\u4e2d\u83b7\u53d6\u6837\u672c\u3002\u7814\u7a76\u8fd8\u5bf9ISFM\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5728\u6700\u5927\u71b5\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u80fd\u591f\u5b66\u4e60\u5230\u6700\u4f18\u52a8\u4f5c\u5206\u5e03\u3002", "motivation": "\u73b0\u6709\u7684\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\uff08SAC\uff09\u7b97\u6cd5\u5728\u5b9e\u8df5\u4e2d\u4e3a\u4e86\u6548\u7387\u800c\u91c7\u7528\u7b80\u5355\u7684\u7b56\u7565\u7c7b\u6765\u8fd1\u4f3c\u80fd\u91cf\u57fa\u7b56\u7565\uff0c\u8fd9\u727a\u7272\u4e86\u8868\u8fbe\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86SAC\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53\uff0c\u8be5\u53d8\u4f53\u5229\u7528\u6d41\u6a21\u578b\u4e30\u5bcc\u7684\u8868\u8fbe\u80fd\u529b\u6765\u53c2\u6570\u5316\u7b56\u7565\u3002\u7b97\u6cd5\u4e2d\uff0c\u901a\u8fc7\u77ac\u65f6\u53d8\u91cf\u53d8\u6362\u6280\u672f\u6765\u8bc4\u4f30\u57fa\u4e8e\u6d41\u7684\u7b56\u7565\uff0c\u5e76\u4e14\u7528\u672c\u8bba\u6587\u5f00\u53d1\u7684\u4e00\u79cd\u79f0\u4e3a\u91cd\u8981\u6027\u91c7\u6837\u6d41\u5339\u914d(ISFM)\u7684\u5728\u7ebf\u6d41\u5339\u914d\u53d8\u4f53\u6765\u66f4\u65b0\u7b56\u7565\u3002", "result": "\u53d1\u5c55\u4e86\u9488\u5bf9ISFM\u7684\u7406\u8bba\u5206\u6790\uff0c\u63cf\u8ff0\u4e86\u4e0d\u540c\u9009\u62e9\u7684\u91c7\u6837\u5206\u5e03\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u6548\u7387\u3002\u6b64\u5916\uff0c\u5728\u6700\u5927\u71b5\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\u95ee\u9898\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u53ef\u4ee5\u5b66\u4e60\u5230\u6700\u4f18\u52a8\u4f5c\u5206\u5e03\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7b56\u7565\u53c2\u6570\u5316\u4e3a\u57fa\u4e8e\u6d41\u7684\u6a21\u578b\u5e76\u5f15\u5165ISFM\u65b9\u6cd5\uff0c\u672c\u6587\u6240\u63d0\u51fa\u7684SAC\u7b97\u6cd5\u53d8\u4f53\u63d0\u9ad8\u4e86\u7b56\u7565\u7684\u8868\u8fbe\u529b\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5b66\u4e60\u8fc7\u7a0b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.23905", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23905", "abs": "https://arxiv.org/abs/2512.23905", "authors": ["Peter Farag"], "title": "Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks", "comment": "16 pages", "summary": "Dense linear layers are a dominant source of computational and parametric cost in modern machine learning models, despite their quadratic complexity and often being misaligned with the compositional structure of learned representations. We introduce Stagewise Pairwise Mixers (SPM), a structured linear operator that replaces dense matrices with a composition of sparse pairwise-mixing stages. An SPM layer implements a global linear transformation in $O(nL)$ time with $O(nL)$ parameters, where $L$ is typically constant or $log_2n$, and admits exact closed-form forward and backward computations. SPM is designed as a drop-in replacement for dense linear layers in feedforward networks, recurrent architectures, attention mechanisms, etc. We derive complete forward and backward expressions for two parameterizations: an orthogonal norm-preserving rotation-based variant and a fully general $2 \\times 2$ mixing variant. Beyond computational savings, the stagewise structure of SPM induces an explicit compositional inductive bias that constrains model capacity and improves generalization when aligned with task structure. We present proof-of-concept experiments demonstrating substantial reductions in wall-clock cost and improved accuracy on structured learning problems, while retaining competitive performance on real-world benchmarks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aStagewise Pairwise Mixers (SPM)\u7684\u7ed3\u6784\u5316\u7ebf\u6027\u8fd0\u7b97\u7b26\uff0c\u5b83\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u53c2\u6570\u91cf\u66ff\u4ee3\u5bc6\u96c6\u578b\u7ebf\u6027\u5c42\uff0c\u5e76\u4e14\u5177\u6709\u663e\u5f0f\u7684\u7ec4\u5408\u5f52\u7eb3\u504f\u7f6e\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u8fd8\u80fd\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7531\u4e8e\u4f7f\u7528\u5bc6\u96c6\u578b\u7ebf\u6027\u5c42\u800c\u5bfc\u81f4\u7684\u9ad8\u8ba1\u7b97\u4e0e\u53c2\u6570\u5f00\u9500\u95ee\u9898\u3002\u8fd9\u4e9b\u5c42\u4e0d\u4ec5\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u800c\u4e14\u5f80\u5f80\u4e0e\u5176\u6240\u5b66\u8868\u793a\u7684\u7ec4\u6210\u7ed3\u6784\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u7ebf\u6027\u7b97\u5b50\u2014\u2014Stagewise Pairwise Mixers (SPPM)\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u7a00\u758f\u6210\u5bf9\u6df7\u5408\u9636\u6bb5\u6765\u4ee3\u66ff\u4f20\u7edf\u7684\u5bc6\u96c6\u77e9\u9635\u3002SPM\u53ef\u4ee5\u5728O(nL)\u65f6\u95f4\u5185\u5b9e\u73b0\u5168\u5c40\u7ebf\u6027\u53d8\u6362\uff0c\u5176\u4e2dL\u901a\u5e38\u662f\u5e38\u6570\u6216log_2n\uff0c\u5e76\u652f\u6301\u7cbe\u786e\u95ed\u5f0f\u524d\u5411\u548c\u540e\u5411\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSPM\u80fd\u591f\u5728\u4fdd\u8bc1\u751a\u81f3\u6539\u5584\u6a21\u578b\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5b9e\u9645\u8fd0\u884c\u65f6\u95f4\u6210\u672c\u3002\u6b64\u5916\uff0cSPM\u8fd8\u5c55\u793a\u4e86\u5728\u7ed3\u6784\u5316\u5b66\u4e60\u95ee\u9898\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "SPM\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u548c\u53c2\u6570\u6210\u672c\uff0c\u540c\u65f6\u901a\u8fc7\u5176\u5c42\u6b21\u7ed3\u6784\u5f15\u5165\u660e\u786e\u7684\u7ec4\u5408\u5f52\u7eb3\u504f\u5dee\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u4e0e\u4efb\u52a1\u7ed3\u6784\u76f8\u5339\u914d\u65f6\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.23924", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23924", "abs": "https://arxiv.org/abs/2512.23924", "authors": ["Yinglun Zhu"], "title": "Interactive Machine Learning: From Theory to Scale", "comment": "Updated Ph.D. dissertation (typos corrected; minor technical and structural revisions)", "summary": "Machine learning has achieved remarkable success across a wide range of applications, yet many of its most effective methods rely on access to large amounts of labeled data or extensive online interaction. In practice, acquiring high-quality labels and making decisions through trial-and-error can be expensive, time-consuming, or risky, particularly in large-scale or high-stakes settings. This dissertation studies interactive machine learning, in which the learner actively influences how information is collected or which actions are taken, using past observations to guide future interactions. We develop new algorithmic principles and establish fundamental limits for interactive learning along three dimensions: active learning with noisy data and rich model classes, sequential decision making with large action spaces, and model selection under partial feedback. Our results include the first computationally efficient active learning algorithms achieving exponential label savings without low-noise assumptions; the first efficient, general-purpose contextual bandit algorithms whose guarantees are independent of the size of the action space; and the first tight characterizations of the fundamental cost of model selection in sequential decision making. Overall, this dissertation advances the theoretical foundations of interactive learning by developing algorithms that are statistically optimal and computationally efficient, while also providing principled guidance for deploying interactive learning methods in large-scale, real-world settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4ea4\u4e92\u5f0f\u673a\u5668\u5b66\u4e60\uff0c\u5f00\u53d1\u4e86\u65b0\u7684\u7b97\u6cd5\u539f\u5219\uff0c\u5e76\u4e3a\u6709\u566a\u58f0\u6570\u636e\u548c\u4e30\u5bcc\u6a21\u578b\u7c7b\u522b\u7684\u4e3b\u52a8\u5b66\u4e60\u3001\u5177\u6709\u5927\u52a8\u4f5c\u7a7a\u95f4\u7684\u5e8f\u5217\u51b3\u7b56\u5236\u5b9a\u4ee5\u53ca\u5728\u90e8\u5206\u53cd\u9988\u4e0b\u7684\u6a21\u578b\u9009\u62e9\u5efa\u7acb\u4e86\u57fa\u672c\u9650\u5236\u3002\u8fd9\u4e9b\u6210\u679c\u5305\u62ec\u9996\u6b21\u5b9e\u73b0\u4e86\u65e0\u9700\u4f4e\u566a\u58f0\u5047\u8bbe\u5373\u53ef\u8fbe\u5230\u6307\u6570\u7ea7\u6807\u7b7e\u8282\u7701\u7684\u8ba1\u7b97\u9ad8\u6548\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff1b\u9996\u4e2a\u4fdd\u8bc1\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u7684\u6709\u6548\u901a\u7528\u4e0a\u4e0b\u6587\u5f3a\u76d7\u7b97\u6cd5\uff1b\u4ee5\u53ca\u9996\u6b21\u5bf9\u5e8f\u5217\u51b3\u7b56\u4e2d\u6a21\u578b\u9009\u62e9\u7684\u57fa\u672c\u6210\u672c\u8fdb\u884c\u4e86\u4e25\u683c\u8868\u5f81\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u5728\u8bb8\u591a\u5e94\u7528\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\uff0c\u4f46\u5176\u6700\u6709\u6548\u7684\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5927\u91cf\u7684\u6807\u8bb0\u6570\u636e\u6216\u5e7f\u6cdb\u7684\u5728\u7ebf\u4e92\u52a8\u3002\u7136\u800c\uff0c\u5728\u5b9e\u8df5\u4e2d\uff0c\u83b7\u53d6\u9ad8\u8d28\u91cf\u6807\u7b7e\u53ca\u901a\u8fc7\u8bd5\u9519\u505a\u51b3\u5b9a\u53ef\u80fd\u662f\u6602\u8d35\u3001\u8017\u65f6\u6216\u6709\u98ce\u9669\u7684\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6216\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u3002", "method": "\u7814\u7a76\u4e86\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4ea4\u4e92\u5f0f\u5b66\u4e60\uff1a\u5904\u7406\u542b\u566a\u58f0\u6570\u636e\u548c\u590d\u6742\u6a21\u578b\u7c7b\u522b\u7684\u4e3b\u52a8\u5b66\u4e60\u3001\u5177\u6709\u5927\u52a8\u4f5c\u7a7a\u95f4\u7684\u987a\u5e8f\u51b3\u7b56\u5236\u5b9a\uff0c\u4ee5\u53ca\u5728\u90e8\u5206\u53cd\u9988\u6761\u4ef6\u4e0b\u7684\u6a21\u578b\u9009\u62e9\u3002", "result": "\u5f00\u53d1\u51fa\u7684\u65b0\u7b97\u6cd5\u539f\u5219\u4e0d\u4ec5\u5728\u7edf\u8ba1\u4e0a\u662f\u6700\u4f73\u7684\uff0c\u800c\u4e14\u8ba1\u7b97\u6548\u7387\u4e5f\u9ad8\uff0c\u5e76\u4e14\u8fd8\u63d0\u4f9b\u4e86\u5c06\u4ea4\u4e92\u5f0f\u5b66\u4e60\u65b9\u6cd5\u90e8\u7f72\u5230\u5927\u89c4\u6a21\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u539f\u5219\u6027\u6307\u5bfc\u3002", "conclusion": "\u672c\u8bba\u6587\u901a\u8fc7\u63d0\u51fa\u7edf\u8ba1\u6700\u4f18\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u63a8\u8fdb\u4e86\u4ea4\u4e92\u5f0f\u5b66\u4e60\u7684\u7406\u8bba\u57fa\u7840\uff0c\u540c\u65f6\u4e3a\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u573a\u666f\u4e2d\u90e8\u7f72\u4ea4\u4e92\u5f0f\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u6307\u5bfc\u3002"}}
{"id": "2512.23947", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23947", "abs": "https://arxiv.org/abs/2512.23947", "authors": ["Corinna Cortes", "Mehryar Mohri", "Yutao Zhong"], "title": "Improved Balanced Classification with Theoretically Grounded Loss Functions", "comment": "NeurIPS 2025", "summary": "The balanced loss is a widely adopted objective for multi-class classification under class imbalance. By assigning equal importance to all classes, regardless of their frequency, it promotes fairness and ensures that minority classes are not overlooked. However, directly minimizing the balanced classification loss is typically intractable, which makes the design of effective surrogate losses a central question. This paper introduces and studies two advanced surrogate loss families: Generalized Logit-Adjusted (GLA) loss functions and Generalized Class-Aware weighted (GCA) losses. GLA losses generalize Logit-Adjusted losses, which shift logits based on class priors, to the broader general cross-entropy loss family. GCA loss functions extend the standard class-weighted losses, which scale losses inversely by class frequency, by incorporating class-dependent confidence margins and extending them to the general cross-entropy family. We present a comprehensive theoretical analysis of consistency for both loss families. We show that GLA losses are Bayes-consistent, but only $H$-consistent for complete (i.e., unbounded) hypothesis sets. Moreover, their $H$-consistency bounds depend inversely on the minimum class probability, scaling at least as $1/\\mathsf p_{\\min}$. In contrast, GCA losses are $H$-consistent for any hypothesis set that is bounded or complete, with $H$-consistency bounds that scale more favorably as $1/\\sqrt{\\mathsf p_{\\min}}$, offering significantly stronger theoretical guarantees in imbalanced settings. We report the results of experiments demonstrating that, empirically, both the GCA losses with calibrated class-dependent confidence margins and GLA losses can greatly outperform straightforward class-weighted losses as well as the LA losses. GLA generally performs slightly better in common benchmarks, whereas GCA exhibits a slight edge in highly imbalanced settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f15\u5165\u5e76\u7814\u7a76\u4e86\u4e24\u79cd\u5148\u8fdb\u7684\u66ff\u4ee3\u635f\u5931\u51fd\u6570\uff1a\u5e7f\u4e49\u5bf9\u6570\u8c03\u6574(GLA)\u635f\u5931\u51fd\u6570\u548c\u5e7f\u4e49\u7c7b\u522b\u611f\u77e5\u52a0\u6743(GCA)\u635f\u5931\uff0c\u4ee5\u89e3\u51b3\u591a\u7c7b\u5206\u7c7b\u4e2d\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002GLA\u635f\u5931\u51fd\u6570\u5bf9\u4e8e\u5b8c\u6574\u5047\u8bbe\u96c6\u662fH-\u4e00\u81f4\u7684\uff0c\u4f46\u5176\u4e00\u81f4\u6027\u754c\u9650\u4f9d\u8d56\u4e8e\u6700\u5c0f\u7c7b\u522b\u6982\u7387\uff1b\u800cGCA\u635f\u5931\u51fd\u6570\u5bf9\u4e8e\u6709\u754c\u6216\u5b8c\u6574\u7684\u5047\u8bbe\u96c6\u90fd\u662f\u4e00\u81f4\u7684\uff0c\u5e76\u4e14\u5728\u975e\u5e38\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u66f4\u5f3a\u7684\u7406\u8bba\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u8005\u5747\u4f18\u4e8e\u7b80\u5355\u7684\u7c7b\u522b\u52a0\u6743\u635f\u5931\uff0c\u5728\u5e38\u89c1\u57fa\u51c6\u6d4b\u8bd5\u4e2dGLA\u8868\u73b0\u7565\u597d\uff0c\u800c\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0bGCA\u5219\u8868\u73b0\u51fa\u5fae\u5f31\u4f18\u52bf\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u7684\u591a\u7c7b\u5206\u7c7b\u95ee\u9898\uff0c\u76f4\u63a5\u6700\u5c0f\u5316\u5e73\u8861\u5206\u7c7b\u635f\u5931\u901a\u5e38\u662f\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u7c7b\u65b0\u7684\u66ff\u4ee3\u635f\u5931\u51fd\u6570\uff1a\u5e7f\u4e49\u5bf9\u6570\u8c03\u6574\uff08GLA\uff09\u635f\u5931\u51fd\u6570\u4e0e\u5e7f\u4e49\u7c7b\u522b\u611f\u77e5\u52a0\u6743\uff08GCA\uff09\u635f\u5931\u51fd\u6570\u3002GLA\u635f\u5931\u6269\u5c55\u4e86\u57fa\u4e8e\u7c7b\u522b\u5148\u9a8c\u8c03\u6574logits\u7684\u65b9\u6cd5\u81f3\u66f4\u5e7f\u6cdb\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u5bb6\u65cf\uff1bGCA\u635f\u5931\u901a\u8fc7\u5f15\u5165\u7c7b\u522b\u4f9d\u8d56\u7f6e\u4fe1\u8fb9\u754c\u6539\u8fdb\u4e86\u6807\u51c6\u7684\u7c7b\u522b\u6743\u91cd\u635f\u5931\u65b9\u6cd5\uff0c\u5e76\u540c\u6837\u6269\u5c55\u5230\u4e86\u4e00\u822c\u4ea4\u53c9\u71b5\u635f\u5931\u5bb6\u65cf\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cGLA\u635f\u5931\u4ec5\u5728\u5b8c\u6574\u5047\u8bbe\u96c6\u4e0a\u662fH-\u4e00\u81f4\u7684\uff0c\u5176\u4e00\u81f4\u6027\u8fb9\u754c\u53cd\u6bd4\u4e8e\u6700\u5c0f\u7c7b\u522b\u6982\u7387\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0cGCA\u635f\u5931\u5bf9\u4e8e\u4efb\u4f55\u6709\u754c\u6216\u5b8c\u6574\u5047\u8bbe\u96c6\u90fd\u662fH-\u4e00\u81f4\u7684\uff0c\u4e14\u5176\u4e00\u81f4\u6027\u8fb9\u754c\u968f$1/\\sqrt{p_{min}}$\u7f29\u653e\uff0c\u63d0\u4f9b\u4e86\u5728\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e0b\u66f4\u5f3a\u6709\u529b\u7684\u7406\u8bba\u4fdd\u969c\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGLA\u635f\u5931\u5728\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u901a\u5e38\u8868\u73b0\u7a0d\u597d\uff0c\u800cGCA\u635f\u5931\u5728\u6781\u7aef\u4e0d\u5e73\u8861\u6761\u4ef6\u4e0b\u663e\u793a\u51fa\u8f7b\u5fae\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165GLA\u548cGCA\u4e24\u79cd\u65b0\u578b\u66ff\u4ee3\u635f\u5931\u51fd\u6570\uff0c\u672c\u7814\u7a76\u4e3a\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002\u7279\u522b\u662fGCA\u635f\u5931\uff0c\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u4e86\u66f4\u597d\u7684\u6027\u80fd\u53ca\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2512.23977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23977", "abs": "https://arxiv.org/abs/2512.23977", "authors": ["Giacinto Paolo Saggese", "Paul Smith"], "title": "Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing", "comment": null, "summary": "We present DataFlow, a computational framework for building, testing, and deploying high-performance machine learning systems on unbounded time-series data. Traditional data science workflows assume finite datasets and require substantial reimplementation when moving from batch prototypes to streaming production systems. This gap introduces causality violations, batch boundary artifacts, and poor reproducibility of real-time failures.\n  DataFlow resolves these issues through a unified execution model based on directed acyclic graphs (DAGs) with point-in-time idempotency: outputs at any time t depend only on a fixed-length context window preceding t. This guarantee ensures that models developed in batch mode execute identically in streaming production without code changes. The framework enforces strict causality by automatically tracking knowledge time across all transformations, eliminating future-peeking bugs.\n  DataFlow supports flexible tiling across temporal and feature dimensions, allowing the same model to operate at different frequencies and memory profiles via configuration alone. It integrates natively with the Python data science stack and provides fit/predict semantics for online learning, caching and incremental computation, and automatic parallelization through DAG-based scheduling. We demonstrate its effectiveness across domains including financial trading, IoT, fraud detection, and real-time analytics.", "AI": {"tldr": "DataFlow \u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u9ad8\u6027\u80fd\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u65e0\u9650\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u5b83\u901a\u8fc7\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u7684\u7edf\u4e00\u6267\u884c\u6a21\u578b\u89e3\u51b3\u4e86\u4ece\u6279\u91cf\u5904\u7406\u5230\u6d41\u5f0f\u751f\u4ea7\u7cfb\u7edf\u8fc1\u79fb\u65f6\u9047\u5230\u7684\u95ee\u9898\uff0c\u5982\u56e0\u679c\u5173\u7cfb\u8fdd\u53cd\u3001\u6279\u5904\u7406\u8fb9\u754c\u95ee\u9898\u4ee5\u53ca\u5b9e\u65f6\u6545\u969c\u518d\u73b0\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u5e76\u652f\u6301\u7075\u6d3b\u7684\u65f6\u95f4\u548c\u7279\u5f81\u7ef4\u5ea6\u5207\u7247\u914d\u7f6e\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u7684\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u5047\u8bbe\u6709\u9650\u7684\u6570\u636e\u96c6\uff0c\u5728\u4ece\u6279\u91cf\u539f\u578b\u8f6c\u79fb\u5230\u6d41\u5f0f\u751f\u4ea7\u7cfb\u7edf\u65f6\u9700\u8981\u5927\u91cf\u7684\u91cd\u65b0\u5b9e\u73b0\u3002\u8fd9\u79cd\u5dee\u8ddd\u5bfc\u81f4\u4e86\u56e0\u679c\u5173\u7cfb\u8fdd\u53cd\u3001\u6279\u5904\u7406\u8fb9\u754c\u95ee\u9898\u4ee5\u53ca\u5b9e\u65f6\u6545\u969c\u518d\u73b0\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "DataFlow \u901a\u8fc7\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\uff08DAGs\uff09\u7684\u7edf\u4e00\u6267\u884c\u6a21\u578b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u786e\u4fdd\u5728\u4efb\u4f55\u65f6\u95f4\u70b9 t \u7684\u8f93\u51fa\u4ec5\u4f9d\u8d56\u4e8e t \u524d\u7684\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002\u8be5\u6846\u67b6\u81ea\u52a8\u8ffd\u8e2a\u6240\u6709\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u7684\u77e5\u8bc6\u65f6\u95f4\uff0c\u4ece\u800c\u5f3a\u5236\u4e25\u683c\u7684\u56e0\u679c\u5173\u7cfb\u3002\u6b64\u5916\uff0cDataFlow \u652f\u6301\u8de8\u65f6\u95f4\u548c\u7279\u5f81\u7ef4\u5ea6\u7684\u7075\u6d3b\u5206\u5757\uff0c\u5e76\u4e0e Python \u6570\u636e\u79d1\u5b66\u6808\u539f\u751f\u96c6\u6210\uff0c\u63d0\u4f9b\u5728\u7ebf\u5b66\u4e60\u7684\u62df\u5408/\u9884\u6d4b\u8bed\u4e49\u3001\u7f13\u5b58\u4e0e\u589e\u91cf\u8ba1\u7b97\u4ee5\u53ca\u57fa\u4e8e DAG \u7684\u8c03\u5ea6\u81ea\u52a8\u5e76\u884c\u5316\u3002", "result": "DataFlow \u80fd\u591f\u4fdd\u8bc1\u5f00\u53d1\u4e8e\u6279\u5904\u7406\u6a21\u5f0f\u4e0b\u7684\u6a21\u578b\u65e0\u9700\u4ee3\u7801\u4fee\u6539\u5373\u53ef\u5728\u6d41\u5f0f\u751f\u4ea7\u73af\u5883\u4e2d\u76f8\u540c\u5730\u6267\u884c\uff0c\u540c\u65f6\u652f\u6301\u76f8\u540c\u7684\u6a21\u578b\u901a\u8fc7\u914d\u7f6e\u64cd\u4f5c\u5728\u4e0d\u540c\u7684\u9891\u7387\u548c\u5185\u5b58\u914d\u7f6e\u4e0b\u8fd0\u884c\u3002\u5176\u6709\u6548\u6027\u5df2\u5728\u91d1\u878d\u4ea4\u6613\u3001\u7269\u8054\u7f51\u3001\u6b3a\u8bc8\u68c0\u6d4b\u548c\u5b9e\u65f6\u5206\u6790\u7b49\u591a\u4e2a\u9886\u57df\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "DataFlow \u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6865\u63a5\u4f20\u7edf\u6279\u5904\u7406\u548c\u6d41\u5f0f\u5904\u7406\u95f4\u7684\u5dee\u8ddd\uff0c\u4f7f\u5f97\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u80fd\u591f\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u5904\u7406\u65e0\u9650\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u4ece\u7814\u53d1\u5230\u751f\u4ea7\u7684\u53ef\u79fb\u690d\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.23978", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23978", "abs": "https://arxiv.org/abs/2512.23978", "authors": ["Tinglong Dai", "David Simchi-Levi", "Michelle Xiao Wu", "Yao Xie"], "title": "Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems", "comment": "Authors are listed alphabetically", "summary": "Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems -- autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR's role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u4ece\u5bf9\u8bdd\u52a9\u624b\u5411\u81ea\u4e3b\u51b3\u7b56\u7cfb\u7edf\u8f6c\u53d8\u8fc7\u7a0b\u4e2d\u6240\u9762\u4e34\u7684\u81ea\u6cbb\u6096\u8bba\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd0\u7b79\u5b66\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u89c6\u89d2\u6765\u786e\u4fdd\u5728\u5b89\u5168\u5173\u952e\u53ca\u53ef\u9760\u6027\u654f\u611f\u64cd\u4f5c\u9886\u57df\u4e2d\u7684\u81ea\u4e3b\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u9010\u6e10\u8f6c\u5411\u80fd\u591f\u611f\u77e5\u3001\u51b3\u7b56\u5e76\u6267\u884c\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u8fd9\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff1a\u5373\u5982\u4f55\u5728\u8d4b\u4e88\u8fd9\u4e9b\u7cfb\u7edf\u66f4\u5927\u8fd0\u4f5c\u81ea\u4e3b\u6743\u7684\u540c\u65f6\uff0c\u4fdd\u8bc1\u5176\u7ed3\u6784\u66f4\u52a0\u6b63\u5f0f\u3001\u7ea6\u675f\u66f4\u52a0\u660e\u786e\u4ee5\u53ca\u5c3e\u90e8\u98ce\u9669\u63a7\u5236\u66f4\u5f3a\u3002\u6587\u7ae0\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u81ea\u6cbb\u6096\u8bba\uff0c\u5e76\u4e3a\u5b89\u5168\u5173\u952e\u4e0e\u53ef\u9760\u6027\u654f\u611f\u7684\u64cd\u4f5c\u9886\u57df\u63d0\u4f9b\u4e00\u79cd\u4fdd\u969c\u81ea\u4e3b\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8fd0\u7b79\u5b66\uff08OR\uff09\u6982\u5ff5\u4e0a\u7684\u4fdd\u969c\u81ea\u4e3b\u6027\u6846\u67b6\uff0c\u5305\u542b\u4e24\u65b9\u9762\u4e92\u8865\u7684\u65b9\u6cd5\uff1a\u4e00\u662f\u5229\u7528\u6d41\u5f0f\u751f\u6210\u6a21\u578b\u5c06\u751f\u6210\u8fc7\u7a0b\u89c6\u4e3a\u7531\u5e38\u5fae\u5206\u65b9\u7a0b\u63cf\u8ff0\u7684\u786e\u5b9a\u6027\u4f20\u8f93\uff0c\u4ece\u800c\u652f\u6301\u53ef\u5ba1\u8ba1\u6027\u3001\u7ea6\u675f\u610f\u8bc6\u751f\u6210\u7b49\uff1b\u4e8c\u662f\u4ece\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u89d2\u5ea6\u6784\u5efa\u8fd0\u8425\u5b89\u5168\u6027\uff0c\u8003\u8651\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u6270\u52a8\u4ee5\u5c06\u672a\u5efa\u6a21\u7684\u98ce\u9669\u7eb3\u5165\u8bbe\u8ba1\u4e4b\u4e2d\u3002", "result": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u9610\u660e\u4e86\u968f\u7740\u81ea\u4e3b\u6027\u589e\u5f3a\uff0c\u8fd0\u7b79\u5b66\u89d2\u8272\u5982\u4f55\u4ece\u5355\u7eaf\u7684\u95ee\u9898\u89e3\u51b3\u8005\u8f6c\u53d8\u4e3a\u62a4\u680f\u4e43\u81f3\u7cfb\u7edf\u67b6\u6784\u5e08\u7684\u8fc7\u7a0b\uff0c\u540c\u65f6\u4e5f\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\uff0c\u65e8\u5728\u4e3a\u5b89\u5168\u5173\u952e\u53ca\u53ef\u9760\u6027\u654f\u611f\u7684\u64cd\u4f5c\u9886\u57df\u63d0\u4f9b\u6709\u4fdd\u969c\u7684\u81ea\u4e3b\u6027\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u4e3a\u4e86\u5e94\u5bf9\u751f\u6210\u5f0fAI\u7cfb\u7edf\u5728\u83b7\u5f97\u66f4\u9ad8\u64cd\u4f5c\u81ea\u4e3b\u6743\u65f6\u53ef\u80fd\u9047\u5230\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u9700\u8981\u7ed3\u5408\u8fd0\u7b79\u5b66\u539f\u7406\u5f00\u53d1\u51fa\u80fd\u591f\u786e\u4fdd\u53ef\u884c\u6027\u9a8c\u8bc1\u3001\u6297\u5206\u5e03\u504f\u79fb\u80fd\u529b\u53ca\u9ad8\u540e\u679c\u60c5\u666f\u4e0b\u538b\u529b\u6d4b\u8bd5\u7684\u65b0\u673a\u5236\u3002"}}
{"id": "2512.23981", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23981", "abs": "https://arxiv.org/abs/2512.23981", "authors": ["Sebasti\u00e1n Guti\u00e9rrez-Bernal", "Hector Medel Cobaxin", "Abiel Galindo Gonz\u00e1lez"], "title": "Information-Theoretic Quality Metric of Low-Dimensional Embeddings", "comment": "18 pages, 6 figures, submitted to Machine Learning (Springer Nature)", "summary": "In this work we study the quality of low-dimensional embeddings from an explicitly information-theoretic perspective. We begin by noting that classical evaluation metrics such as stress, rank-based neighborhood criteria, or Local Procrustes quantify distortions in distances or in local geometries, but do not directly assess how much information is preserved when projecting high-dimensional data onto a lower-dimensional space. To address this limitation, we introduce the Entropy Rank Preservation Measure (ERPM), a local metric based on the Shannon entropy of the singular-value spectrum of neighborhood matrices and on the stable rank, which quantifies changes in uncertainty between the original representation and its reduced projection, providing neighborhood-level indicators and a global summary statistic. To validate the results of the metric, we compare its outcomes with the Mean Relative Rank Error (MRRE), which is distance-based, and with Local Procrustes, which is based on geometric properties, using a financial time series and a manifold commonly studied in the literature. We observe that distance-based criteria exhibit very low correlation with geometric and spectral measures, while ERPM and Local Procrustes show strong average correlation but display significant discrepancies in local regimes, leading to the conclusion that ERPM complements existing metrics by identifying neighborhoods with severe information loss, thereby enabling a more comprehensive assessment of embeddings, particularly in information-sensitive applications such as the construction of early-warning indicators.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u8bba\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u7814\u7a76\u4e86\u4f4e\u7ef4\u5d4c\u5165\u7684\u8d28\u91cf\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u71b5\u79e9\u4fdd\u6301\u5ea6\u91cf\uff08ERPM\uff09\uff0c\u5b83\u57fa\u4e8e\u90bb\u57df\u77e9\u9635\u5947\u5f02\u503c\u8c31\u7684\u9999\u519c\u71b5\u548c\u7a33\u5b9a\u79e9\u6765\u91cf\u5316\u539f\u59cb\u8868\u793a\u4e0e\u5176\u964d\u7ef4\u6295\u5f71\u4e4b\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\u3002\u901a\u8fc7\u4e0e\u57fa\u4e8e\u8ddd\u79bb\u7684\u6807\u51c6\uff08\u5982\u5e73\u5747\u76f8\u5bf9\u79e9\u8bef\u5deeMRRE\uff09\u53ca\u57fa\u4e8e\u51e0\u4f55\u5c5e\u6027\u7684\u6807\u51c6\uff08\u5982\u5c40\u90e8\u666e\u7f57\u514b\u9c81\u65af\u7279\u5206\u6790\uff09\u8fdb\u884c\u5bf9\u6bd4\uff0c\u53d1\u73b0ERPM\u80fd\u591f\u8865\u5145\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\uff0c\u8bc6\u522b\u51fa\u4fe1\u606f\u4e25\u91cd\u4e22\u5931\u7684\u90bb\u57df\uff0c\u4ece\u800c\u4e3a\u5d4c\u5165\u6548\u679c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u6784\u5efa\u9884\u8b66\u6307\u6807\u7b49\u5bf9\u4fe1\u606f\u654f\u611f\u7684\u5e94\u7528\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u4f4e\u7ef4\u5d4c\u5165\u8d28\u91cf\u8bc4\u4ef7\u6307\u6807\u4e3b\u8981\u96c6\u4e2d\u5728\u8ddd\u79bb\u5931\u771f\u6216\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\u7684\u53d8\u5316\u4e0a\uff0c\u5e76\u4e0d\u80fd\u76f4\u63a5\u8861\u91cf\u4ece\u9ad8\u7ef4\u7a7a\u95f4\u5230\u4f4e\u7ef4\u7a7a\u95f4\u6620\u5c04\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u4e86\u591a\u5c11\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u65b9\u5f0f\u6765\u76f4\u63a5\u8bc4\u4f30\u4fe1\u606f\u4fdd\u5b58\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86\u71b5\u79e9\u4fdd\u6301\u5ea6\u91cf(ERPM)\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u90bb\u57df\u77e9\u9635\u5947\u5f02\u503c\u8c31\u7684\u9999\u519c\u71b5\u4e0e\u7a33\u5b9a\u79e9\u7684\u5c40\u90e8\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u6570\u636e\u4ece\u539f\u59cb\u9ad8\u7ef4\u8868\u793a\u5230\u4f4e\u7ef4\u6295\u5f71\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\u3002", "result": "\u901a\u8fc7\u5c06ERPM\u7684\u7ed3\u679c\u4e0e\u57fa\u4e8e\u8ddd\u79bb\u7684\u5e73\u5747\u76f8\u5bf9\u79e9\u8bef\u5dee(MRRE)\u4ee5\u53ca\u57fa\u4e8e\u51e0\u4f55\u7279\u6027\u7684\u5c40\u90e8\u666e\u7f57\u514b\u9c81\u65af\u7279\u65b9\u6cd5\u76f8\u6bd4\u8f83\uff0c\u53d1\u73b0\u5728\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u548c\u6587\u732e\u4e2d\u5e38\u7814\u7a76\u7684\u6d41\u5f62\u4e0a\uff0c\u57fa\u4e8e\u8ddd\u79bb\u7684\u5ea6\u91cf\u4e0e\u51e0\u4f55\u548c\u8c31\u5ea6\u91cf\u4e4b\u95f4\u663e\u793a\u51fa\u975e\u5e38\u4f4e\u7684\u76f8\u5173\u6027\uff1b\u800cERPM\u4e0e\u5c40\u90e8\u666e\u7f57\u514b\u9c81\u65af\u7279\u65b9\u6cd5\u5219\u8868\u73b0\u51fa\u5f3a\u5e73\u5747\u76f8\u5173\u6027\uff0c\u4f46\u5728\u5c40\u90e8\u533a\u57df\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "ERPM\u4f5c\u4e3a\u4e00\u79cd\u8865\u5145\u6027\u7684\u5ea6\u91cf\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u4fe1\u606f\u635f\u5931\u4e25\u91cd\u7684\u90bb\u57df\uff0c\u4e3a\u4f4e\u7ef4\u5d4c\u5165\u7684\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u4e3a\u5168\u9762\u7684\u8bc4\u4f30\u624b\u6bb5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4fe1\u606f\u654f\u611f\u9886\u57df\u5185\u7684\u5e94\u7528\u3002"}}
{"id": "2512.24002", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24002", "abs": "https://arxiv.org/abs/2512.24002", "authors": ["Tan Pan", "Yixuan Sun", "Chen Jiang", "Qiong Gao", "Rui Sun", "Xingmeng Zhang", "Zhenqi Yang", "Limei Han", "Yixiu Liang", "Yuan Cheng", "Kaiyu Guo"], "title": "Tracing the Heart's Pathways: ECG Representation Learning from a Cardiac Conduction Perspective", "comment": "Accepted to AAAI2026", "summary": "The multi-lead electrocardiogram (ECG) stands as a cornerstone of cardiac diagnosis. Recent strides in electrocardiogram self-supervised learning (eSSL) have brightened prospects for enhancing representation learning without relying on high-quality annotations. Yet earlier eSSL methods suffer a key limitation: they focus on consistent patterns across leads and beats, overlooking the inherent differences in heartbeats rooted in cardiac conduction processes, while subtle but significant variations carry unique physiological signatures. Moreover, representation learning for ECG analysis should align with ECG diagnostic guidelines, which progress from individual heartbeats to single leads and ultimately to lead combinations. This sequential logic, however, is often neglected when applying pre-trained models to downstream tasks. To address these gaps, we propose CLEAR-HUG, a two-stage framework designed to capture subtle variations in cardiac conduction across leads while adhering to ECG diagnostic guidelines. In the first stage, we introduce an eSSL model termed Conduction-LEAd Reconstructor (CLEAR), which captures both specific variations and general commonalities across heartbeats. Treating each heartbeat as a distinct entity, CLEAR employs a simple yet effective sparse attention mechanism to reconstruct signals without interference from other heartbeats. In the second stage, we implement a Hierarchical lead-Unified Group head (HUG) for disease diagnosis, mirroring clinical workflow. Experimental results across six tasks show a 6.84% improvement, validating the effectiveness of CLEAR-HUG. This highlights its ability to enhance representations of cardiac conduction and align patterns with expert diagnostic guidelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCLEAR-HUG\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u6355\u6349\u5fc3\u7535\u56fe\u5bfc\u8054\u95f4\u5fc3\u810f\u4f20\u5bfc\u7684\u7ec6\u5fae\u53d8\u5316\uff0c\u5e76\u9075\u5faaECCG\u8bca\u65ad\u6307\u5357\u3002\u8be5\u6846\u67b6\u9996\u5148\u901a\u8fc7Conduction-LEAd Reconstructor (CLEAR)\u6a21\u578b\u6355\u6349\u5fc3\u8df3\u95f4\u7684\u7279\u5f02\u6027\u548c\u5171\u6027\uff0c\u7136\u540e\u4f7f\u7528Hierarchical lead-Unified Group head (HUG)\u8fdb\u884c\u75be\u75c5\u8bca\u65ad\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u516d\u4e2a\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e866.84%\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5fc3\u7535\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5fc3\u810f\u8df3\u52a8\u4e4b\u95f4\u56fa\u6709\u7684\u5dee\u5f02\u4ee5\u53ca\u8fd9\u4e9b\u5dee\u5f02\u6240\u643a\u5e26\u7684\u72ec\u7279\u751f\u7406\u7279\u5f81\u3002\u6b64\u5916\uff0c\u76ee\u524d\u7684\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u65f6\u5f80\u5f80\u5ffd\u7565\u4e86\u4ece\u5355\u4e2a\u5fc3\u8df3\u5230\u5355\u4e2a\u5bfc\u8054\u518d\u5230\u5bfc\u8054\u7ec4\u5408\u8fd9\u4e00\u9010\u6b65\u9012\u8fdb\u7684\u5fc3\u7535\u56fe\u8bca\u65ad\u903b\u8f91\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aCLEAR-HUG\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u5f00\u53d1\u4e86Conduction-LEAd Reconstructor (CLEAR)\uff0c\u5b83\u5c06\u6bcf\u4e2a\u5fc3\u8df3\u89c6\u4e3a\u72ec\u7acb\u5b9e\u4f53\uff0c\u5e76\u91c7\u7528\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\u6765\u91cd\u5efa\u4fe1\u53f7\u800c\u4e0d\u53d7\u5176\u4ed6\u5fc3\u8df3\u5e72\u6270\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5b9e\u73b0\u4e86Hierarchical lead-Unified Group head (HUG)\uff0c\u4ee5\u6a21\u4eff\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u6765\u8fdb\u884c\u75be\u75c5\u8bca\u65ad\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u516d\u4e2a\u4e0d\u540c\u7684\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u5347\u4e866.84%\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86CLEAR-HUG\u80fd\u591f\u6709\u6548\u5730\u589e\u5f3a\u5bf9\u5fc3\u810f\u4f20\u5bfc\u8868\u73b0\u7684\u5b66\u4e60\uff0c\u5e76\u4e14\u4e0e\u4e13\u5bb6\u8bca\u65ad\u6307\u5357\u76f8\u5339\u914d\u3002", "conclusion": "CLEAR-HUG\u6846\u67b6\u4e0d\u4ec5\u80fd\u591f\u6355\u6349\u5230\u5fc3\u7535\u56fe\u4e2d\u8de8\u5bfc\u8054\u7684\u5fc3\u810f\u4f20\u5bfc\u8fc7\u7a0b\u4e2d\u7684\u7ec6\u5fae\u53d8\u5f02\uff0c\u800c\u4e14\u8fd8\u80fd\u786e\u4fdd\u8fd9\u79cd\u6a21\u5f0f\u8bc6\u522b\u7b26\u5408\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u8bca\u65ad\u6307\u5357\u8981\u6c42\u3002"}}
{"id": "2512.24062", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24062", "abs": "https://arxiv.org/abs/2512.24062", "authors": ["Rui Chen", "Junjun Guo", "Hongbin Wang", "Yan Xiang", "Yantuan Xian", "Zhengtao Yu"], "title": "Hyperspherical Graph Representation Learning via Adaptive Neighbor-Mean Alignment and Uniformity", "comment": "Submitted to Pattern Recognition", "summary": "Graph representation learning (GRL) aims to encode structural and semantic dependencies of graph-structured data into low-dimensional embeddings. However, existing GRL methods often rely on surrogate contrastive objectives or mutual information maximization, which typically demand complex architectures, negative sampling strategies, and sensitive hyperparameter tuning. These design choices may induce over-smoothing, over-squashing, and training instability. In this work, we propose HyperGRL, a unified framework for hyperspherical graph representation learning via adaptive neighbor-mean alignment and sampling-free uniformity. HyperGRL embeds nodes on a unit hypersphere through two adversarially coupled objectives: neighbor-mean alignment and sampling-free uniformity. The alignment objective uses the mean representation of each node's local neighborhood to construct semantically grounded, stable targets that capture shared structural and feature patterns. The uniformity objective formulates dispersion via an L2-based hyperspherical regularization, encouraging globally uniform embedding distributions while preserving discriminative information. To further stabilize training, we introduce an entropy-guided adaptive balancing mechanism that dynamically regulates the interplay between alignment and uniformity without requiring manual tuning. Extensive experiments on node classification, node clustering, and link prediction demonstrate that HyperGRL delivers superior representation quality and generalization across diverse graph structures, achieving average improvements of 1.49%, 0.86%, and 0.74% over the strongest existing methods, respectively. These findings highlight the effectiveness of geometrically grounded, sampling-free contrastive objectives for graph representation learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u8868\u793a\u5b66\u4e60\u6846\u67b6HyperGRL\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u90bb\u5c45\u5747\u503c\u5bf9\u9f50\u548c\u65e0\u91c7\u6837\u5747\u5300\u6027\u5728\u8d85\u7403\u9762\u4e0a\u8fdb\u884c\u8282\u70b9\u5d4c\u5165\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e24\u4e2a\u5bf9\u6297\u8026\u5408\u76ee\u6807\u6765\u7a33\u5b9a\u8bad\u7ec3\u5e76\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5728\u8282\u70b9\u5206\u7c7b\u3001\u8282\u70b9\u805a\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u8868\u793a\u5b66\u4e60\uff08GRL\uff09\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u66ff\u4ee3\u5bf9\u6bd4\u76ee\u6807\u6216\u4e92\u4fe1\u606f\u6700\u5927\u5316\u7b56\u7565\uff0c\u8fd9\u9700\u8981\u590d\u6742\u7684\u67b6\u6784\u3001\u8d1f\u91c7\u6837\u7b56\u7565\u4ee5\u53ca\u654f\u611f\u7684\u8d85\u53c2\u6570\u8c03\u6574\u3002\u8fd9\u4e9b\u8bbe\u8ba1\u9009\u62e9\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5e73\u6ed1\u3001\u8fc7\u538b\u7f29\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002", "method": "HyperGRL\u901a\u8fc7\u4e24\u4e2a\u5bf9\u6297\u8026\u5408\u7684\u76ee\u6807\u5c06\u8282\u70b9\u5d4c\u5165\u5355\u4f4d\u8d85\u7403\u9762\uff1a\u90bb\u5c45\u5747\u503c\u5bf9\u9f50\u548c\u65e0\u91c7\u6837\u5747\u5300\u6027\u3002\u5bf9\u9f50\u76ee\u6807\u5229\u7528\u6bcf\u4e2a\u8282\u70b9\u5c40\u90e8\u90bb\u57df\u7684\u5e73\u5747\u8868\u793a\u6784\u5efa\u8bed\u4e49\u57fa\u7840\u7684\u7a33\u5b9a\u76ee\u6807\uff0c\u6355\u6349\u5171\u4eab\u7ed3\u6784\u548c\u7279\u5f81\u6a21\u5f0f\uff1b\u5747\u5300\u6027\u76ee\u6807\u901a\u8fc7\u57fa\u4e8eL2\u8303\u6570\u7684\u8d85\u7403\u9762\u6b63\u5219\u5316\u4fc3\u8fdb\u5168\u5c40\u5747\u5300\u5206\u5e03\u540c\u65f6\u4fdd\u7559\u533a\u5206\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u71b5\u5f15\u5bfc\u81ea\u9002\u5e94\u5e73\u8861\u673a\u5236\u4ee5\u8fdb\u4e00\u6b65\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u8282\u5373\u53ef\u52a8\u6001\u8c03\u8282\u5bf9\u9f50\u4e0e\u5747\u5300\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperGRL\u5728\u8282\u70b9\u5206\u7c7b\u3001\u8282\u70b9\u805a\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u63d0\u4f9b\u4e86\u4f18\u4e8e\u73b0\u6709\u6700\u5f3a\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5206\u522b\u5b9e\u73b0\u4e861.49%\u30010.86%\u548c0.74%\u7684\u5e73\u5747\u6539\u8fdb\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660e\u4e86\u51e0\u4f55\u57fa\u7840\u4e14\u65e0\u9700\u91c7\u6837\u7684\u5bf9\u6bd4\u76ee\u6807\u5bf9\u4e8e\u56fe\u8868\u793a\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.24063", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24063", "abs": "https://arxiv.org/abs/2512.24063", "authors": ["Haoyue Bai", "Yiyou Sun", "Wenjie Hu", "Shi Qiu", "Maggie Ziyu Huan", "Peiyang Song", "Robert Nowak", "Dawn Song"], "title": "How and Why LLMs Generalize: A Fine-Grained Analysis of LLM Reasoning from Cognitive Behaviors to Low-Level Patterns", "comment": null, "summary": "Large Language Models (LLMs) display strikingly different generalization behaviors: supervised fine-tuning (SFT) often narrows capability, whereas reinforcement-learning (RL) tuning tends to preserve it. The reasons behind this divergence remain unclear, as prior studies have largely relied on coarse accuracy metrics. We address this gap by introducing a novel benchmark that decomposes reasoning into atomic core skills such as calculation, fact retrieval, simulation, enumeration, and diagnostic, providing a concrete framework for addressing the fundamental question of what constitutes reasoning in LLMs. By isolating and measuring these core skills, the benchmark offers a more granular view of how specific cognitive abilities emerge, transfer, and sometimes collapse during post-training. Combined with analyses of low-level statistical patterns such as distributional divergence and parameter statistics, it enables a fine-grained study of how generalization evolves under SFT and RL across mathematical, scientific reasoning, and non-reasoning tasks. Our meta-probing framework tracks model behavior at different training stages and reveals that RL-tuned models maintain more stable behavioral profiles and resist collapse in reasoning skills, whereas SFT models exhibit sharper drift and overfit to surface patterns. This work provides new insights into the nature of reasoning in LLMs and points toward principles for designing training strategies that foster broad, robust generalization.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6765\u5206\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u4e3a\u57fa\u672c\u6838\u5fc3\u6280\u80fd\uff0c\u5982\u8ba1\u7b97\u3001\u4e8b\u5b9e\u68c0\u7d22\u7b49\uff0c\u5e76\u7ed3\u5408\u4f4e\u7ea7\u7edf\u8ba1\u6a21\u5f0f\u5206\u6790\uff0c\u8be6\u7ec6\u63a2\u8ba8\u4e86\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4e0e\u5f3a\u5316\u5b66\u4e60\u8c03\u6574\uff08RL\uff09\u4e0b\u6a21\u578b\u6cdb\u5316\u884c\u4e3a\u7684\u5dee\u5f02\u3002\u7ed3\u679c\u8868\u660e\uff0cRL\u8c03\u4f18\u6a21\u578b\u5728\u4fdd\u6301\u7a33\u5b9a\u7684\u884c\u4e3a\u7279\u5f81\u548c\u62b5\u6297\u63a8\u7406\u6280\u80fd\u9000\u5316\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u800cSFT\u6a21\u578b\u5219\u503e\u5411\u4e8e\u8fc7\u5ea6\u62df\u5408\u8868\u9762\u6a21\u5f0f\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u4e8e\u7c97\u7565\u7684\u51c6\u786e\u6027\u6307\u6807\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u53d8\u5316\uff0c\u4f46\u672a\u80fd\u6df1\u5165\u89e3\u91ca\u76d1\u7763\u5fae\u8c03\u5bfc\u81f4\u80fd\u529b\u7f29\u5c0f\u53ca\u5f3a\u5316\u5b66\u4e60\u8c03\u6574\u80fd\u591f\u4fdd\u6301\u80fd\u529b\u7684\u539f\u56e0\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u53ef\u4ee5\u5c06\u63a8\u7406\u80fd\u529b\u5206\u89e3\u6210\u66f4\u5177\u4f53\u7684\u6838\u5fc3\u6280\u80fd\u7684\u65b0\u57fa\u51c6\uff0c\u6765\u66f4\u597d\u5730\u7406\u89e3LLMs\u4e2d\u63a8\u7406\u7684\u672c\u8d28\u53ca\u5176\u5728\u4e0d\u540c\u8bad\u7ec3\u65b9\u6cd5\u4e0b\u7684\u6f14\u53d8\u60c5\u51b5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65b0\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5c06\u63a8\u7406\u4efb\u52a1\u7ec6\u5206\u4e3a\u591a\u4e2a\u539f\u5b50\u5316\u7684\u57fa\u7840\u6280\u80fd\uff0c\u5e76\u901a\u8fc7\u6b64\u6846\u67b6\u8ffd\u8e2a\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u884c\u4e3a\u8868\u73b0\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u8fd8\u5229\u7528\u5bf9\u5e95\u5c42\u7edf\u8ba1\u6a21\u5f0f\uff08\u5305\u62ec\u5206\u5e03\u5dee\u5f02\u6027\u548c\u53c2\u6570\u7edf\u8ba1\u6570\u636e\uff09\u7684\u5206\u6790\uff0c\u4ee5\u66f4\u7ec6\u81f4\u5730\u7814\u7a76\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f\u2014\u2014\u76d1\u7763\u5fae\u8c03(SFT)\u4e0e\u5f3a\u5316\u5b66\u4e60(RL)\u8c03\u4f18\u2014\u2014\u5982\u4f55\u5f71\u54cd\u6570\u5b66\u3001\u79d1\u5b66\u63a8\u7406\u53ca\u5176\u4ed6\u975e\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u5f0f\u8fdb\u884c\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u8f83\u4e8e\u76d1\u7763\u5fae\u8c03\u6a21\u578b\u800c\u8a00\uff0c\u5728\u7ef4\u6301\u7a33\u5b9a\u7684\u884c\u4e3a\u7279\u5f81\u4ee5\u53ca\u9632\u6b62\u63a8\u7406\u6280\u80fd\u8870\u9000\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u66f4\u5f3a\u7684\u4f18\u52bf\uff1b\u76f8\u53cd\uff0c\u76d1\u7763\u5fae\u8c03\u6a21\u578b\u66f4\u5bb9\u6613\u51fa\u73b0\u663e\u8457\u7684\u884c\u4e3a\u6f02\u79fb\uff0c\u5e76\u4e14\u53ef\u80fd\u8fc7\u5ea6\u9002\u5e94\u8868\u9762\u4e0a\u7684\u6570\u636e\u6a21\u5f0f\u800c\u975e\u771f\u6b63\u7406\u89e3\u95ee\u9898\u80cc\u540e\u7684\u903b\u8f91\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u63a8\u7406\u7279\u6027\u7684\u672c\u8d28\uff0c\u5e76\u4e3a\u5f00\u53d1\u65e8\u5728\u4fc3\u8fdb\u5e7f\u6cdb\u4e14\u7a33\u5065\u6cdb\u5316\u80fd\u529b\u7684\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.24075", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24075", "abs": "https://arxiv.org/abs/2512.24075", "authors": ["Jiazhao Shi", "Ziyu Wang", "Yichen Lin", "Shoufeng Lu"], "title": "Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework", "comment": null, "summary": "Lane-change intention prediction is safety-critical for autonomous driving and ADAS, but remains difficult in naturalistic traffic due to noisy kinematics, severe class imbalance, and limited generalization across heterogeneous highway scenarios. We propose Temporal Physics-Informed AI (TPI-AI), a hybrid framework that fuses deep temporal representations with physics-inspired interaction cues. A two-layer bidirectional LSTM (Bi-LSTM) encoder learns compact embeddings from multi-step trajectory histories; we concatenate these embeddings with kinematics-, safety-, and interaction-aware features (e.g., headway, TTC, and safe-gap indicators) and train a LightGBM classifier for three-class intention recognition (No-LC, Left-LC, Right-LC). To improve minority-class reliability, we apply imbalance-aware optimization including resampling/weighting and fold-wise threshold calibration. Experiments on two large-scale drone-based datasets, highD (straight highways) and exiD (ramp-rich environments), use location-based splits and evaluate prediction horizons T = 1, 2, 3 s. TPI-AI outperforms standalone LightGBM and Bi-LSTM baselines, achieving macro-F1 of 0.9562, 0.9124, 0.8345 on highD and 0.9247, 0.8197, 0.7605 on exiD at T = 1, 2, 3 s, respectively. These results show that combining physics-informed interaction features with learned temporal embeddings yields robust multi-scenario lane-change intention prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u65f6\u95f4\u8868\u793a\u548c\u7269\u7406\u542f\u53d1\u4ea4\u4e92\u7ebf\u7d22\u7684TPI-AI\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u8f66\u9053\u53d8\u6362\u610f\u56fe\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528LightGBM\u6216Bi-LSTM\u7684\u65b9\u6cd5\u3002", "motivation": "\u5728\u81ea\u7136\u9a7e\u9a76\u6761\u4ef6\u4e0b\uff0c\u7531\u4e8e\u8fd0\u52a8\u5b66\u566a\u58f0\u3001\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u4ee5\u53ca\u8de8\u5f02\u6784\u9ad8\u901f\u516c\u8def\u573a\u666f\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u8f66\u9053\u53d8\u6362\u610f\u56fe\u9884\u6d4b\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u548cADAS\u6765\u8bf4\u4ecd\u7136\u662f\u4e00\u4e2a\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86Temporal Physics-Informed AI (TPI-AI)\u6df7\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u878d\u5408\u4e86\u6df1\u5c42\u65f6\u95f4\u5e8f\u5217\u8868\u8fbe\u4e0e\u57fa\u4e8e\u7269\u7406\u539f\u7406\u7684\u4ea4\u4e92\u7ebf\u7d22\u3002\u4f7f\u7528\u4e24\u5c42\u53cc\u5411LSTM\u7f16\u7801\u5668\u4ece\u591a\u6b65\u8f68\u8ff9\u5386\u53f2\u4e2d\u5b66\u4e60\u7d27\u51d1\u5d4c\u5165\uff0c\u5e76\u5c06\u5176\u4e0e\u8003\u8651\u8fd0\u52a8\u5b66\u3001\u5b89\u5168\u6027\u548c\u4ea4\u4e92\u6027\u7684\u7279\u5f81\uff08\u5982\u8f66\u5934\u65f6\u8ddd\u3001\u5230\u8fbe\u65f6\u95f4\u4f30\u8ba1\u548c\u5b89\u5168\u95f4\u8ddd\u6307\u6807\uff09\u8fde\u63a5\u8d77\u6765\uff0c\u8bad\u7ec3LightGBM\u5206\u7c7b\u5668\u5b9e\u73b0\u4e09\u7c7b\u610f\u56fe\u8bc6\u522b\uff08\u4e0d\u6362\u9053\u3001\u5de6\u6362\u9053\u3001\u53f3\u6362\u9053\uff09\u3002\u4e3a\u4e86\u6539\u5584\u5c11\u6570\u7c7b\u522b\u7684\u53ef\u9760\u6027\uff0c\u5e94\u7528\u4e86\u5305\u62ec\u91cd\u91c7\u6837/\u52a0\u6743\u548c\u6309\u6298\u6821\u51c6\u9608\u503c\u5728\u5185\u7684\u4e0d\u5e73\u8861\u610f\u8bc6\u4f18\u5316\u6280\u672f\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u5927\u89c4\u6a21\u57fa\u4e8e\u65e0\u4eba\u673a\u7684\u6570\u636e\u96c6highD\uff08\u76f4\u7ebf\u8def\u6bb5\uff09\u548cexiD\uff08\u531d\u9053\u4e30\u5bcc\u73af\u5883\uff09\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u91c7\u7528\u57fa\u4e8e\u4f4d\u7f6e\u7684\u6570\u636e\u5206\u5272\u65b9\u5f0f\u5e76\u8bc4\u4f30\u4e86T=1, 2, 3\u79d2\u7684\u9884\u6d4b\u8303\u56f4\u3002TPI-AI\u5728\u6240\u6709\u6d4b\u8bd5\u6761\u4ef6\u4e0b\u90fd\u8d85\u8fc7\u4e86\u5355\u72ec\u4f7f\u7528LightGBM\u6216Bi-LSTM\u57fa\u7ebf\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5728highD\u4e0a\u5206\u522b\u8fbe\u52300.9562\u30010.9124\u30010.8345\u7684\u5b8f\u89c2F1\u5206\u6570\uff0c\u5728exiD\u4e0a\u5219\u4e3a0.9247\u30010.8197\u30010.7605\u3002", "conclusion": "\u7ed3\u5408\u57fa\u4e8e\u7269\u7406\u539f\u7406\u7684\u4ea4\u4e92\u7279\u5f81\u4e0e\u5b66\u4e60\u5230\u7684\u65f6\u95f4\u5e8f\u5217\u5d4c\u5165\u53ef\u4ee5\u4ea7\u751f\u9c81\u68d2\u6027\u66f4\u5f3a\u7684\u591a\u573a\u666f\u8f66\u9053\u53d8\u6362\u610f\u56fe\u9884\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2512.24102", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24102", "abs": "https://arxiv.org/abs/2512.24102", "authors": ["Yves Ruffenach"], "title": "Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study", "comment": "A focused ablation study analyzing the role of latent autoregression in GP-VAE models", "summary": "This paper provides an ablation-based analysis of latent autoregression in GP-VAE models, building upon our previous work introducing the architecture. Language models typically rely on an autoregressive factorization over tokens. In contrast, our prior work proposed shifting sequential structure to the latent space through a causal Gaussian process, while using a non-autoregressive decoder. Here, we conduct a systematic ablation study of the role played by latent autoregression. We compare (i) a full GP-VAE model with autoregressive latent dynamics, (ii) a non-autoregressive ablation in which latent variables are independent, and (iii) a standard token-level autoregressive Transformer. Our results show that, within the considered regime (medium-scale corpora and short training contexts), latent autoregression induces latent trajectories that are significantly more compatible with the Gaussian-process prior and exhibit greater long-horizon stability. In contrast, removing autoregression leads to degraded latent structure and unstable long-range behavior. These findings highlight the role of latent autoregression as an effective mechanism for organizing long-range structure, while remaining complementary to token-level autoregressive modeling. They should be interpreted as an empirical analysis of representational structure rather than as a proposal for a new architecture.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u6d88\u878d\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86GP-VAE\u6a21\u578b\u4e2d\u6f5c\u5728\u81ea\u56de\u5f52\u7684\u4f5c\u7528\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e2d\u7b49\u89c4\u6a21\u8bed\u6599\u5e93\u548c\u77ed\u8bad\u7ec3\u4e0a\u4e0b\u6587\u7684\u6761\u4ef6\u4e0b\uff0c\u6f5c\u5728\u81ea\u56de\u5f52\u6709\u52a9\u4e8e\u751f\u6210\u66f4\u7b26\u5408\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u4e14\u957f\u65f6\u7a33\u5b9a\u6027\u66f4\u5f3a\u7684\u6f5c\u5728\u8f68\u8ff9\u3002", "motivation": "\u57fa\u4e8e\u4e4b\u524d\u5f15\u5165GP-VAE\u67b6\u6784\u7684\u5de5\u4f5c\uff0c\u672c\u6587\u65e8\u5728\u8fdb\u4e00\u6b65\u7406\u89e3\u5728\u8be5\u7c7b\u6a21\u578b\u4e2d\u6f5c\u53d8\u91cf\u81ea\u56de\u5f52\u6240\u8d77\u7684\u4f5c\u7528\uff0c\u5e76\u4e0e\u975e\u81ea\u56de\u5f52\u53d8\u4f53\u53ca\u6807\u51c6\u7684\u6807\u8bb0\u7ea7\u81ea\u56de\u5f52Transformer\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u91c7\u7528\u4e86\u4e09\u79cd\u5bf9\u6bd4\u65b9\u6848\uff1a\uff08i\uff09\u5177\u6709\u81ea\u56de\u5f52\u6f5c\u5728\u52a8\u6001\u7684\u5b8c\u6574GP-VAE\u6a21\u578b\uff1b\uff08ii\uff09\u6f5c\u53d8\u91cf\u76f8\u4e92\u72ec\u7acb\u7684\u975e\u81ea\u56de\u5f52\u7248\u672c\uff1b\uff08iii\uff09\u6807\u51c6\u7684\u6807\u8bb0\u7ea7\u81ea\u56de\u5f52Transformer\u3002\u901a\u8fc7\u5bf9\u8fd9\u4e9b\u6a21\u578b\u5728\u4e2d\u7b49\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u6d88\u878d\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4fdd\u6301\u6f5c\u5728\u81ea\u56de\u5f52\u53ef\u4ee5\u4ea7\u751f\u4e0e\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u66f4\u52a0\u4e00\u81f4\u7684\u6f5c\u5728\u8f68\u8ff9\uff0c\u5e76\u8868\u73b0\u51fa\u66f4\u597d\u7684\u957f\u65f6\u95f4\u7a33\u5b9a\u6027\u3002\u76f8\u53cd\u5730\uff0c\u53bb\u9664\u81ea\u56de\u5f52\u4f1a\u5bfc\u81f4\u6f5c\u5728\u7ed3\u6784\u9000\u5316\u4ee5\u53ca\u4e0d\u7a33\u5b9a\u7684\u957f\u671f\u884c\u4e3a\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u6f5c\u5728\u81ea\u56de\u5f52\u662f\u7ec4\u7ec7\u957f\u671f\u7ed3\u6784\u7684\u6709\u6548\u673a\u5236\uff0c\u5b83\u4e0e\u6807\u8bb0\u7ea7\u522b\u7684\u81ea\u56de\u5f52\u5efa\u6a21\u76f8\u8f85\u76f8\u6210\uff0c\u4f46\u8fd9\u9879\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u4e8e\u8868\u5f81\u7ed3\u6784\u7684\u7ecf\u9a8c\u6027\u5206\u6790\u800c\u975e\u63d0\u51fa\u65b0\u7684\u67b6\u6784\u3002"}}
{"id": "2512.24103", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24103", "abs": "https://arxiv.org/abs/2512.24103", "authors": ["Bernd Bohnet", "Pierre-Alexandre Kamienny", "Hanie Sedghi", "Dilan Gorur", "Pranjal Awasthi", "Aaron Parisi", "Kevin Swersky", "Rosanne Liu", "Azade Nova", "Noah Fiedel"], "title": "Enhancing LLM Planning Capabilities through Intrinsic Self-Critique", "comment": null, "summary": "We demonstrate an approach for LLMs to critique their \\emph{own} answers with the goal of enhancing their performance that leads to significant improvements over established planning benchmarks. Despite the findings of earlier research that has cast doubt on the effectiveness of LLMs leveraging self critique methods, we show significant performance gains on planning datasets in the Blocksworld domain through intrinsic self-critique, without external source such as a verifier. We also demonstrate similar improvements on Logistics and Mini-grid datasets, exceeding strong baseline accuracies. We employ a few-shot learning technique and progressively extend it to a many-shot approach as our base method and demonstrate that it is possible to gain substantial improvement on top of this already competitive approach by employing an iterative process for correction and refinement. We illustrate how self-critique can significantly boost planning performance. Our empirical results present new state-of-the-art on the class of models considered, namely LLM model checkpoints from October 2024. Our primary focus lies on the method itself, demonstrating intrinsic self-improvement capabilities that are applicable regardless of the specific model version, and we believe that applying our method to more complex search techniques and more capable models will lead to even better performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u81ea\u6211\u6279\u5224\u6765\u6539\u8fdb\u5176\u5728\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728Blocksworld\u3001Logistics\u4ee5\u53caMini-grid\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u51c6\u786e\u7387\u3002", "motivation": "\u5c3d\u7ba1\u65e9\u671f\u7814\u7a76\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5229\u7528\u81ea\u6211\u6279\u5224\u65b9\u6cd5\u7684\u6709\u6548\u6027\u8868\u793a\u6000\u7591\uff0c\u4f46\u672c\u6587\u65e8\u5728\u5c55\u793a\u4e00\u79cd\u901a\u8fc7\u5185\u5728\u81ea\u6211\u6279\u5224\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u671f\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u8fdb\u6b65\u3002", "method": "\u91c7\u7528\u4e86\u5c11\u91cf\u5b66\u4e60\u6280\u672f\u5e76\u9010\u6b65\u6269\u5c55\u81f3\u5927\u91cf\u5b66\u4e60\u65b9\u6cd5\u4f5c\u4e3a\u57fa\u7840\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u8fdb\u884c\u4fee\u6b63\u548c\u7ec6\u5316\uff0c\u4ece\u800c\u5728\u8fd9\u4e00\u5df2\u7ecf\u5177\u6709\u7ade\u4e89\u529b\u7684\u65b9\u6cd5\u4e4b\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\u3002", "result": "\u5728Blocksworld\u9886\u57df\u4e0a\u7684\u89c4\u5212\u6570\u636e\u96c6\u3001Logistics\u4ee5\u53caMini-grid\u6570\u636e\u96c6\u4e0a\u90fd\u663e\u793a\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u8d85\u8fc7\u4e86\u5f3a\u5927\u7684\u57fa\u7ebf\u51c6\u786e\u6027\u3002\u5b9e\u8bc1\u7ed3\u679c\u4e3a\u8003\u8651\u4e2d\u7684\u6a21\u578b\u7c7b\u522b\u6811\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6807\u51c6\u3002", "conclusion": "\u672c\u6587\u4e3b\u8981\u96c6\u4e2d\u5728\u65b9\u6cd5\u672c\u8eab\uff0c\u5c55\u793a\u4e86\u65e0\u8bba\u5177\u4f53\u6a21\u578b\u7248\u672c\u5982\u4f55\uff0c\u90fd\u80fd\u591f\u5e94\u7528\u7684\u5185\u5728\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u5e76\u8ba4\u4e3a\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u641c\u7d22\u6280\u672f\u548c\u66f4\u5f3a\u529b\u7684\u6a21\u578b\u4f1a\u5e26\u6765\u66f4\u597d\u7684\u8868\u73b0\u3002"}}
{"id": "2512.24124", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.24124", "abs": "https://arxiv.org/abs/2512.24124", "authors": ["Advait Gadhikar", "Riccardo Grazzi", "James Hensman"], "title": "OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization", "comment": "25 pages, 10 figures", "summary": "The presence of outliers in Large Language Models (LLMs) weights and activations makes them difficult to quantize. Recent work has leveraged rotations to mitigate these outliers. In this work, we propose methods that learn fusible rotations by minimizing principled and cheap proxy objectives to the weight quantization error. We primarily focus on GPTQ as the quantization method. Our main method is OptRot, which reduces weight outliers simply by minimizing the element-wise fourth power of the rotated weights. We show that OptRot outperforms both Hadamard rotations and more expensive, data-dependent methods like SpinQuant and OSTQuant for weight quantization. It also improves activation quantization in the W4A8 setting. We also propose a data-dependent method, OptRot$^{+}$, that further improves performance by incorporating information on the activation covariance. In the W4A4 setting, we see that both OptRot and OptRot$^{+}$ perform worse, highlighting a trade-off between weight and activation quantization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOptRot\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u65cb\u8f6c\u6743\u91cd\u7684\u56db\u6b21\u5e42\u6765\u51cf\u5c11\u6743\u91cd\u5f02\u5e38\u503c\uff0c\u4ece\u800c\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u91cf\u5316\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u4f9d\u8d56\u65b9\u6cd5OptRot+\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u6743\u91cd\u548c\u6fc0\u6d3b\u5b58\u5728\u5f02\u5e38\u503c\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u96be\u4ee5\u91cf\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5c1d\u8bd5\u4f7f\u7528\u65cb\u8f6c\u6765\u51cf\u8f7b\u8fd9\u4e9b\u5f02\u5e38\u503c\u7684\u5f71\u54cd\u3002", "method": "\u672c\u6587\u4e3b\u8981\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aOptRot\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u65cb\u8f6c\u540e\u6743\u91cd\u7684\u56db\u6b21\u65b9\u6765\u51cf\u5c11\u6743\u91cd\u5f02\u5e38\u503c\u3002\u53e6\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u8003\u8651\u6fc0\u6d3b\u534f\u65b9\u5dee\u7684\u6570\u636e\u4f9d\u8d56\u65b9\u6cd5OptRot+\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOptRot\u5728\u6743\u91cd\u91cf\u5316\u65b9\u9762\u4f18\u4e8eHadamard\u65cb\u8f6c\u548c\u5176\u4ed6\u66f4\u6602\u8d35\u7684\u6570\u636e\u4f9d\u8d56\u65b9\u6cd5\u5982SpinQuant\u548cOSTQuant\uff0c\u5e76\u4e14\u5728W4A8\u8bbe\u7f6e\u4e0b\u4e5f\u6539\u5584\u4e86\u6fc0\u6d3b\u91cf\u5316\u3002\u7136\u800c\uff0c\u5728W4A4\u8bbe\u7f6e\u4e2d\uff0cOptRot\u4e0eOptRot+\u7684\u8868\u73b0\u90fd\u8f83\u5dee\uff0c\u663e\u793a\u4e86\u6743\u91cd\u4e0e\u6fc0\u6d3b\u91cf\u5316\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5b66\u4e60\u53ef\u878d\u5408\u65cb\u8f6c\u6765\u51cf\u5c11\u6743\u91cd\u5f02\u5e38\u503c\u662f\u6709\u6548\u7684\uff0c\u7279\u522b\u662fOptRot\u65b9\u6cd5\u5728\u591a\u4e2a\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002\u540c\u65f6\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u6fc0\u6d3b\u91cf\u5316\u95ee\u9898\u4ecd\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24145", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24145", "abs": "https://arxiv.org/abs/2512.24145", "authors": ["Udit Sharma"], "title": "Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators", "comment": "12 pages, 3 figures", "summary": "Machine learning systems appear stochastic but are deterministically random, as seeded pseudorandom number generators produce identical realisations across executions. Learning-based simulators are widely used to compare algorithms, design choices, and interventions under such dynamics, yet evaluation outcomes often exhibit high variance due to random initialisation and learning stochasticity. We analyse the statistical structure of comparative evaluation in these settings and show that standard independent evaluation designs fail to exploit shared sources of randomness across alternatives. We formalise a paired seed evaluation design in which competing systems are evaluated under identical random seeds, inducing matched realisations of stochastic components and strict variance reduction whenever outcomes are positively correlated at the seed level. This yields tighter confidence intervals, higher statistical power, and effective sample size gains at fixed computational budgets. Empirically, seed-level correlations are typically large and positive, producing order-of-magnitude efficiency gains. Paired seed evaluation is weakly dominant in practice, improving statistical reliability when correlation is present and reducing to independent evaluation without loss of validity when it is not.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u914d\u5bf9\u79cd\u5b50\u8bc4\u4f30\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5728\u76f8\u540c\u7684\u968f\u673a\u79cd\u5b50\u4e0b\u8bc4\u4f30\u7ade\u4e89\u7cfb\u7edf\uff0c\u6765\u51cf\u5c11\u7531\u4e8e\u5b66\u4e60\u968f\u673a\u6027\u548c\u968f\u673a\u521d\u59cb\u5316\u5bfc\u81f4\u7684\u9ad8\u65b9\u5dee\u95ee\u9898\u3002\u8fd9\u79cd\u8bbe\u8ba1\u53ef\u4ee5\u63d0\u9ad8\u7edf\u8ba1\u6548\u80fd\u3001\u83b7\u5f97\u66f4\u7d27\u51d1\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5e76\u4e14\u5f53\u5b58\u5728\u6b63\u76f8\u5173\u65f6\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u867d\u7136\u770b\u4f3c\u968f\u673a\uff0c\u4f46\u5b9e\u9645\u4e0a\u662f\u7531\u786e\u5b9a\u6027\u4f2a\u968f\u673a\u6570\u751f\u6210\u5668\u4ea7\u751f\u7684\uff0c\u56e0\u6b64\u5728\u4e0d\u540c\u6267\u884c\u8fc7\u7a0b\u4e2d\u4f1a\u4ea7\u751f\u76f8\u540c\u7684\u7ed3\u679c\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u5b66\u4e60\u7684\u6a21\u62df\u5668\u5728\u8fdb\u884c\u7b97\u6cd5\u3001\u8bbe\u8ba1\u9009\u62e9\u548c\u5e72\u9884\u6bd4\u8f83\u65f6\uff0c\u7531\u4e8e\u968f\u673a\u521d\u59cb\u5316\u548c\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u968f\u673a\u6027\uff0c\u8bc4\u4f30\u7ed3\u679c\u901a\u5e38\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u65b9\u5dee\u3002\u4f5c\u8005\u5206\u6790\u4e86\u5728\u8fd9\u79cd\u52a8\u6001\u4e0b\u7684\u6bd4\u8f83\u8bc4\u4f30\u7684\u7edf\u8ba1\u7ed3\u6784\uff0c\u53d1\u73b0\u6807\u51c6\u72ec\u7acb\u8bc4\u4f30\u8bbe\u8ba1\u672a\u80fd\u5229\u7528\u8de8\u9009\u9879\u5171\u4eab\u7684\u968f\u673a\u6e90\u3002", "method": "\u7814\u7a76\u8005\u5f62\u5f0f\u5316\u4e86\u4e00\u4e2a\u914d\u5bf9\u79cd\u5b50\u8bc4\u4f30\u8bbe\u8ba1\u65b9\u6848\uff0c\u5176\u4e2d\u7ade\u4e89\u7cfb\u7edf\u5728\u540c\u4e00\u7ec4\u968f\u673a\u79cd\u5b50\u4e0b\u88ab\u8bc4\u4f30\uff0c\u8fd9\u8bf1\u5bfc\u4e86\u968f\u673a\u7ec4\u4ef6\u7684\u5339\u914d\u5b9e\u73b0\uff0c\u5e76\u4e14\u53ea\u8981\u7ed3\u679c\u5728\u79cd\u5b50\u7ea7\u522b\u4e0a\u662f\u6b63\u76f8\u5173\u7684\u5c31\u80fd\u4e25\u683c\u964d\u4f4e\u65b9\u5dee\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u79cd\u5b50\u7ea7\u522b\u7684\u76f8\u5173\u6027\u901a\u5e38\u662f\u5927\u800c\u6b63\u7684\uff0c\u80fd\u591f\u4ea7\u751f\u6570\u91cf\u7ea7\u4e0a\u7684\u6548\u7387\u589e\u76ca\u3002\u914d\u5bf9\u79cd\u5b50\u8bc4\u4f30\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u662f\u5f31\u4e3b\u5bfc\u5730\u4f4d\u7684\uff0c\u5f53\u5b58\u5728\u76f8\u5173\u6027\u65f6\u80fd\u6539\u5584\u7edf\u8ba1\u53ef\u9760\u6027\uff0c\u800c\u5728\u6ca1\u6709\u76f8\u5173\u6027\u7684\u60c5\u51b5\u4e0b\u4e5f\u4e0d\u4f1a\u5931\u53bb\u6709\u6548\u6027\u5730\u9000\u5316\u4e3a\u72ec\u7acb\u8bc4\u4f30\u3002", "conclusion": "\u914d\u5bf9\u79cd\u5b50\u8bc4\u4f30\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u6bd4\u8f83\u8bc4\u4f30\u4e2d\u7684\u65b9\u5dee\uff0c\u4ece\u800c\u5f97\u5230\u66f4\u7d27\u5bc6\u7684\u7f6e\u4fe1\u533a\u95f4\u3001\u66f4\u9ad8\u7684\u7edf\u8ba1\u529f\u6548\u4ee5\u53ca\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u5185\u7684\u6709\u6548\u6837\u672c\u91cf\u589e\u52a0\u3002"}}
{"id": "2512.24253", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24253", "abs": "https://arxiv.org/abs/2512.24253", "authors": ["Alireza Rafiei", "Farshid Hajati", "Alireza Rezaee", "Amirhossien Panahi", "Shahadat Uddin"], "title": "Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm", "comment": null, "summary": "Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u5e76\u8bc4\u4f30\u4e86\u56db\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u901a\u8fc7\u5206\u6790\u5fc3\u7387\u6570\u636e\u6765\u9884\u6d4b\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u8d25\u8840\u75c7\u7684\u53d1\u4f5c\u3002\u6a21\u578b\u67b6\u6784\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u5e76\u4e14\u6700\u521d\u8bbe\u8ba1\u7528\u4e8e\u4e00\u5c0f\u65f6\u7684\u9884\u6d4b\u7a97\u53e3\uff0c\u540e\u6765\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u6269\u5c55\u5230\u56db\u5c0f\u65f6\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u5f00\u53d1\u51fa\u8bb8\u591a\u9488\u5bf9\u91cd\u75c7\u76d1\u62a4\u75c5\u623f\uff08ICU\uff09\u60a3\u8005\u7684\u6a21\u578b\uff0c\u4f46\u5728\u975e\u75c5\u623f\u73af\u5883\u4e2d\u65e9\u671f\u68c0\u6d4b\u8d25\u8840\u75c7\u7684\u65b9\u6cd5\u4ecd\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002\u53ca\u65f6\u9884\u6d4b\u8d25\u8840\u75c7\u7684\u53d1\u5c55\u5bf9\u4e8e\u901a\u8fc7\u65e9\u671f\u5e72\u9884\u51cf\u5c11\u4e0d\u826f\u7ed3\u679c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u56db\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u5206\u6790\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u7684\u5fc3\u7387\u6570\u636e\u6765\u9884\u6d4b\u8d25\u8840\u75c7\u7684\u53d1\u751f\u3002\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u7ed3\u6784\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u4f18\u5316\u6027\u80fd\u3001\u8ba1\u7b97\u590d\u6742\u6027\u548c\u5185\u5b58\u9700\u6c42\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0a\u6709\u5b9e\u65bd\u7684\u53ef\u80fd\u6027\uff0c\u80fd\u591f\u51c6\u786e\u76d1\u6d4b\u5fc3\u7387\uff0c\u4ece\u800c\u4e3a\u975eICU\u548c\u75c5\u623f\u73af\u5883\u4e0b\u7684\u65e9\u671f\u8d25\u8840\u75c7\u68c0\u6d4b\u63d0\u4f9b\u53ef\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u7684\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u7a7f\u6234\u6280\u672f\u6709\u53ef\u80fd\u4fc3\u8fdbICU\u548c\u75c5\u623f\u73af\u5883\u4e4b\u5916\u7684\u65e9\u671f\u8d25\u8840\u75c7\u68c0\u6d4b\u3002"}}
{"id": "2512.24324", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24324", "abs": "https://arxiv.org/abs/2512.24324", "authors": ["Haojin Li", "Anbang Zhang", "Chen Sun", "Chenyuan Feng", "Kaiqian Qu", "Tony Q. S. Quek", "Haijun Zhang"], "title": "Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction", "comment": null, "summary": "The low-altitude economy (LAE) is rapidly expanding driven by urban air mobility, logistics drones, and aerial sensing, while fast and accurate beam prediction in uncrewed aerial vehicles (UAVs) communications is crucial for achieving reliable connectivity. Current research is shifting from single-signal to multi-modal collaborative approaches. However, existing multi-modal methods mostly employ fixed or empirical weights, assuming equal reliability across modalities at any given moment. Indeed, the importance of different modalities fluctuates dramatically with UAV motion scenarios, and static weighting amplifies the negative impact of degraded modalities. Furthermore, modal mismatch and weak alignment further undermine cross-scenario generalization. To this end, we propose a reliability-aware dynamic weighting scheme applied to a semantic-aware multi-modal beam prediction framework, named SaM2B. Specifically, SaM2B leverages lightweight cues such as environmental visual, flight posture, and geospatial data to adaptively allocate contributions across modalities at different time points through reliability-aware dynamic weight updates. Moreover, by utilizing cross-modal contrastive learning, we align the \"multi-source representation beam semantics\" associated with specific beam information to a shared semantic space, thereby enhancing discriminative power and robustness under modal noise and distribution shifts. Experiments on real-world low-altitude UAV datasets show that SaM2B achieves more satisfactory results than baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSaM2B\u7684\u8bed\u4e49\u611f\u77e5\u591a\u6a21\u6001\u6ce2\u675f\u9884\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ebf\u7d22\uff08\u5982\u73af\u5883\u89c6\u89c9\u3001\u98de\u884c\u59ff\u6001\u548c\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff09\u81ea\u9002\u5e94\u5730\u5206\u914d\u4e0d\u540c\u65f6\u95f4\u70b9\u4e0a\u5404\u6a21\u6001\u7684\u8d21\u732e\uff0c\u5e76\u5229\u7528\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6765\u63d0\u9ad8\u5728\u6a21\u6001\u566a\u58f0\u548c\u5206\u5e03\u53d8\u5316\u4e0b\u7684\u5224\u522b\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cSaM2B\u5728\u771f\u5b9e\u4f4e\u7a7a\u65e0\u4eba\u673a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u3001\u7269\u6d41\u65e0\u4eba\u673a\u4ee5\u53ca\u7a7a\u4e2d\u4f20\u611f\u7b49\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u65e0\u4eba\u98de\u884c\u5668\u901a\u4fe1\u4e2d\u5feb\u901f\u51c6\u786e\u7684\u6ce2\u675f\u9884\u6d4b\u5bf9\u4e8e\u5b9e\u73b0\u53ef\u9760\u7684\u8fde\u63a5\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u5927\u591a\u91c7\u7528\u56fa\u5b9a\u6216\u7ecf\u9a8c\u6743\u91cd\uff0c\u5047\u8bbe\u4efb\u4f55\u7ed9\u5b9a\u65f6\u523b\u6240\u6709\u6a21\u6001\u7684\u53ef\u9760\u6027\u76f8\u540c\uff0c\u8fd9\u5ffd\u7565\u4e86\u4e0d\u540c\u8fd0\u52a8\u573a\u666f\u4e0b\u6a21\u6001\u91cd\u8981\u6027\u7684\u663e\u8457\u6ce2\u52a8\uff0c\u9759\u6001\u52a0\u6743\u751a\u81f3\u53ef\u80fd\u653e\u5927\u9000\u5316\u6a21\u6001\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u6a21\u6001\u4e0d\u5339\u914d\u548c\u5f31\u5bf9\u9f50\u95ee\u9898\u8fdb\u4e00\u6b65\u524a\u5f31\u4e86\u8de8\u573a\u666f\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSaM2B\u7684\u8bed\u4e49\u611f\u77e5\u591a\u6a21\u6001\u6ce2\u675f\u9884\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u57fa\u4e8e\u73af\u5883\u89c6\u89c9\u3001\u98de\u884c\u59ff\u6001\u548c\u5730\u7406\u7a7a\u95f4\u7b49\u8f7b\u91cf\u7ea7\u7ebf\u7d22\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u4e0a\u81ea\u9002\u5e94\u5730\u8c03\u6574\u5404\u6a21\u6001\u4e4b\u95f4\u7684\u8d21\u732e\u5ea6\uff1b\u540c\u65f6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u5c06\u4e0e\u7279\u5b9a\u6ce2\u675f\u4fe1\u606f\u76f8\u5173\u7684\u201c\u591a\u6e90\u8868\u793a\u6ce2\u675f\u8bed\u4e49\u201d\u6620\u5c04\u5230\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u5728\u5b58\u5728\u6a21\u6001\u566a\u58f0\u548c\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u7684\u533a\u5206\u529b\u548c\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0cSaM2B\u5728\u5904\u7406\u5b9e\u9645\u4f4e\u7a7a\u65e0\u4eba\u673a\u6570\u636e\u96c6\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u66f4\u4ee4\u4eba\u6ee1\u610f\u7684\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684SaM2B\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u52a8\u6001\u8c03\u6574\u5404\u6a21\u6001\u7684\u91cd\u8981\u6027\uff0c\u8fd8\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6574\u4f53\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u4f4e\u7a7a\u7ecf\u6d4e\u9886\u57df\u4e2d\u7684\u53ef\u9760\u901a\u4fe1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24404", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.24404", "abs": "https://arxiv.org/abs/2512.24404", "authors": ["Soham Pahari", "M. Srinivas"], "title": "Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning", "comment": null, "summary": "Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u667a\u80fd\u5728\u89c6\u89c9\u7406\u89e3\u548c\u9ad8\u7ea7\u63a8\u7406\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aViReLoc\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4ec5\u4f7f\u7528\u89c6\u89c9\u8868\u793a\u6765\u8fdb\u884c\u89c4\u5212\u548c\u5b9a\u4f4d\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u4f18\u5316\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u7279\u5f81\u4ea4\u4e92\uff0cViReLoc\u80fd\u591f\u63d0\u9ad8\u7a7a\u95f4\u63a8\u7406\u51c6\u786e\u6027\u548c\u8de8\u89c6\u56fe\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u5bfc\u822a\u548c\u5b9a\u4f4d\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0d\u4f9d\u8d56\u5b9e\u65f6\u5168\u7403\u5b9a\u4f4d\u7cfb\u7edf\u6570\u636e\u7684\u5f3a\u5927\u8865\u5145\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u591a\u6a21\u6001\u667a\u80fd\u5728\u89c6\u89c9\u7406\u89e3\u548c\u9ad8\u7ea7\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5927\u591a\u6570\u63a8\u7406\u7cfb\u7edf\u4ecd\u7136\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\u8fdb\u884c\u63a8\u65ad\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u89c6\u89c9\u5bfc\u822a\u548c\u5730\u7406\u5b9a\u4f4d\u7b49\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u4e00\u9886\u57df\u7684\u6f5c\u5728\u8303\u56f4\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u89c6\u89c9\u63a8\u7406\u8303\u5f0f\uff0c\u4ee5\u89e3\u51b3\u57fa\u4e8e\u6587\u672c\u7684\u63a8\u7406\u96be\u4ee5\u7406\u89e3\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u51e0\u4f55\u5173\u7cfb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Geo-Consistent Visual Planning\u7684\u6982\u5ff5\u4ee5\u53caVisual Reasoning for Localization (ViReLoc)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5b8c\u5168\u57fa\u4e8e\u89c6\u89c9\u8868\u793a\u6765\u6267\u884c\u89c4\u5212\u4e0e\u5b9a\u4f4d\u4efb\u52a1\u3002ViReLoc\u901a\u8fc7\u5728\u89c6\u89c9\u9886\u57df\u5185\u9010\u6b65\u7f16\u7801\u63a8\u7406\u8fc7\u7a0b\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u5f3a\u5316\u7684\u5b66\u4e60\u76ee\u6807\u8fdb\u884c\u4f18\u5316\uff1b\u540c\u65f6\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u7279\u5f81\u4ea4\u4e92\u6280\u672f\uff0c\u4ee5\u6821\u51c6\u4e0d\u540c\u89c6\u89d2\u95f4\u7684\u5dee\u5f02\u5e76\u51cf\u5c11\u89c6\u89d2\u53d8\u5316\u5e26\u6765\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5404\u79cd\u5bfc\u822a\u548c\u5b9a\u4f4d\u573a\u666f\u4e0b\uff0cViReLoc\u6846\u67b6\u80fd\u6301\u7eed\u63d0\u9ad8\u7a7a\u95f4\u63a8\u7406\u51c6\u786e\u6027\u53ca\u8de8\u89c6\u56fe\u68c0\u7d22\u8868\u73b0\u3002\u8fd9\u4e9b\u53d1\u73b0\u8bc1\u5b9e\u4e86\u89c6\u89c9\u63a8\u7406\u4f5c\u4e3a\u5bfc\u822a\u4e0e\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5f3a\u6709\u529b\u8865\u5145\u624b\u6bb5\u7684\u6709\u6548\u6027\uff0c\u5e76\u6307\u51fa\u8fd9\u7c7b\u4efb\u52a1\u53ef\u4ee5\u65e0\u9700\u4f9d\u8d56\u5b9e\u65f6GPS\u6570\u636e\u5373\u53ef\u5b8c\u6210\uff0c\u4ece\u800c\u4e3a\u66f4\u5b89\u5168\u7684\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u94fa\u5e73\u9053\u8def\u3002", "conclusion": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u521b\u65b0\u6027\u7684\u89c6\u89c9\u63a8\u7406\u6846\u67b6ViReLoc\uff0c\u5b83\u901a\u8fc7\u7eaf\u89c6\u89c9\u65b9\u5f0f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7a7a\u95f4\u63a8\u7406\u4e0e\u5b9a\u4f4d\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5373\u4f7f\u6ca1\u6709\u5b9e\u65f6GPS\u652f\u6301\u4e5f\u80fd\u6210\u529f\u6267\u884c\u76f8\u5173\u4efb\u52a1\u3002\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u7a7a\u95f4\u63a8\u7406\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u8de8\u89c6\u56fe\u68c0\u7d22\u7684\u6548\u679c\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u52a0\u5b89\u5168\u53ef\u9760\u7684\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.24407", "categories": ["cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.24407", "abs": "https://arxiv.org/abs/2512.24407", "authors": ["Lars van der Laan", "Aurelien Bibaut", "Nathan Kallus"], "title": "Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models", "comment": null, "summary": "Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical DDC approaches impose restrictive parametric specifications and often require repeated dynamic programming. We develop a semiparametric framework for debiased inverse reinforcement learning that yields statistically efficient inference for a broad class of reward-dependent functionals in maximum entropy IRL and Gumbel-shock DDC models. We show that the log-behavior policy acts as a pseudo-reward that point-identifies policy value differences and, under a simple normalization, the reward itself. We then formalize these targets, including policy values under known and counterfactual softmax policies and functionals of the normalized reward, as smooth functionals of the behavior policy and transition kernel, establish pathwise differentiability, and derive their efficient influence functions. Building on this characterization, we construct automatic debiased machine-learning estimators that allow flexible nonparametric estimation of nuisance components while achieving $\\sqrt{n}$-consistency, asymptotic normality, and semiparametric efficiency. Our framework extends classical inference for DDC models to nonparametric rewards and modern machine-learning tools, providing a unified and computationally tractable approach to statistical inference in IRL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u534a\u53c2\u6570\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u504f\u9006\u5f3a\u5316\u5b66\u4e60\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u5728\u6700\u5927\u71b5\u9006\u5f3a\u5316\u5b66\u4e60\u548cGumbel-shock DDC\u6a21\u578b\u4e2d\u5bf9\u4e00\u5927\u7c7b\u4f9d\u8d56\u4e8e\u5956\u52b1\u7684\u529f\u80fd\u8fdb\u884c\u7edf\u8ba1\u6709\u6548\u63a8\u65ad\u3002\u901a\u8fc7\u5c06\u884c\u4e3a\u7b56\u7565\u7684\u5bf9\u6570\u89c6\u4e3a\u4f2a\u5956\u52b1\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e00\u7279\u5f81\u6784\u5efa\u81ea\u52a8\u53bb\u504f\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\uff0c\u5141\u8bb8\u7075\u6d3b\u5730\u8fdb\u884c\u975e\u53c2\u6570\u4f30\u8ba1\uff0c\u540c\u65f6\u8fbe\u5230\u6839\u53f7n\u4e00\u81f4\u6027\u3001\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u534a\u53c2\u6570\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u9006\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u673a\u5668\u5b66\u4e60\u6280\u672f\u4f46\u65e0\u6cd5\u4fdd\u8bc1\u6709\u6548\u7684\u7edf\u8ba1\u63a8\u65ad\uff1b\u800c\u4f20\u7edf\u7684\u52a8\u6001\u79bb\u6563\u9009\u62e9\u6a21\u578b\u5219\u65bd\u52a0\u4e86\u4e25\u683c\u7684\u53c2\u6570\u8bbe\u5b9a\u8981\u6c42\u5e76\u4e14\u7ecf\u5e38\u9700\u8981\u91cd\u590d\u6267\u884c\u52a8\u6001\u89c4\u5212\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u534a\u53c2\u6570\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u4e14\u8ba1\u7b97\u4e0a\u53ef\u884c\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u9006\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7edf\u8ba1\u63a8\u65ad\u3002", "method": "\u6587\u7ae0\u9996\u5148\u5c55\u793a\u4e86\u884c\u4e3a\u7b56\u7565\u7684\u5bf9\u6570\u5982\u4f55\u4f5c\u4e3a\u4f2a\u5956\u52b1\u6765\u8bc6\u522b\u653f\u7b56\u4ef7\u503c\u5dee\u5f02\uff0c\u5e76\u5728\u7b80\u5355\u5f52\u4e00\u5316\u540e\u8bc6\u522b\u5956\u52b1\u672c\u8eab\u3002\u63a5\u7740\uff0c\u6b63\u5f0f\u5b9a\u4e49\u4e86\u8fd9\u4e9b\u76ee\u6807\uff08\u5305\u62ec\u5df2\u77e5\u53ca\u53cd\u4e8b\u5b9esoftmax\u653f\u7b56\u4e0b\u7684\u653f\u7b56\u4ef7\u503c\u4ee5\u53ca\u5f52\u4e00\u5316\u5956\u52b1\u7684\u529f\u80fd\uff09\uff0c\u5e76\u5c06\u5176\u89c6\u4e3a\u884c\u4e3a\u7b56\u7565\u548c\u8f6c\u79fb\u6838\u5e73\u6ed1\u529f\u80fd\u7684\u4e00\u90e8\u5206\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u786e\u7acb\u4e86\u8def\u5f84\u53ef\u5fae\u6027\u5e76\u5bfc\u51fa\u4e86\u5b83\u4eec\u7684\u6709\u6548\u5f71\u54cd\u51fd\u6570\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u4e0a\u8ff0\u7279\u5f81\u6784\u5efa\u4e86\u81ea\u52a8\u53bb\u504f\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\u5668\u3002", "result": "\u6240\u63d0\u51fa\u7684\u534a\u53c2\u6570\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5bf9\u4e8e\u5956\u52b1\u76f8\u5173\u529f\u80fd\u7684\u7edf\u8ba1\u9ad8\u6548\u63a8\u65ad\uff0c\u5728\u91c7\u7528\u7075\u6d3b\u7684\u975e\u53c2\u6570\u4f30\u8ba1\u7684\u540c\u65f6\u4fdd\u6301\u6839\u53f7n\u4e00\u81f4\u6027\u3001\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u534a\u53c2\u6570\u6548\u7387\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u6269\u5c55\u4e86\u4f20\u7edfDDC\u6a21\u578b\u5bf9\u4e8e\u975e\u53c2\u6570\u5956\u52b1\u548c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5de5\u5177\u7684\u5e94\u7528\u8303\u56f4\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u53c2\u6570\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u9006\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u5185\u5173\u4e8e\u7edf\u8ba1\u63a8\u65ad\u7684\u5173\u952e\u95ee\u9898\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u7075\u6d3b\u6027\uff0c\u800c\u4e14\u786e\u4fdd\u4e86\u7edf\u8ba1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u4ece\u800c\u4e3a\u9006\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.24443", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24443", "abs": "https://arxiv.org/abs/2512.24443", "authors": ["The Tien Mai", "Mai Anh Nguyen", "Trung Nghia Nguyen"], "title": "Sparse classification with positive-confidence data in high dimensions", "comment": null, "summary": "High-dimensional learning problems, where the number of features exceeds the sample size, often require sparse regularization for effective prediction and variable selection. While established for fully supervised data, these techniques remain underexplored in weak-supervision settings such as Positive-Confidence (Pconf) classification. Pconf learning utilizes only positive samples equipped with confidence scores, thereby avoiding the need for negative data. However, existing Pconf methods are ill-suited for high-dimensional regimes. This paper proposes a novel sparse-penalization framework for high-dimensional Pconf classification. We introduce estimators using convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. Theoretically, we establish estimation and prediction error bounds for the L1-regularized Pconf estimator, proving it achieves near minimax-optimal sparse recovery rates under Restricted Strong Convexity condition. To solve the resulting composite objective, we develop an efficient proximal gradient algorithm. Extensive simulations demonstrate that our proposed methods achieve predictive performance and variable selection accuracy comparable to fully supervised approaches, effectively bridging the gap between weak supervision and high-dimensional statistics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9ad8\u7ef4Positive-Confidence(Pconf)\u5206\u7c7b\u95ee\u9898\u7684\u65b0\u7a00\u758f\u60e9\u7f5a\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528Lasso\u548c\u975e\u51f8(SCAD, MCP)\u60e9\u7f5a\u6765\u89e3\u51b3\u6536\u7f29\u504f\u5dee\u5e76\u6539\u8fdb\u7279\u5f81\u6062\u590d\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u53d7\u9650\u5f3a\u51f8\u6027\u6761\u4ef6\u4e0b\uff0cL1\u6b63\u5219\u5316Pconf\u4f30\u8ba1\u5668\u51e0\u4e4e\u8fbe\u5230\u6700\u5c0f\u6700\u4f18\u7684\u7a00\u758f\u6062\u590d\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u6709\u6548\u7684\u8fd1\u7aef\u68af\u5ea6\u7b97\u6cd5\u6765\u89e3\u51b3\u590d\u5408\u76ee\u6807\u51fd\u6570\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u548c\u53d8\u91cf\u9009\u62e9\u51c6\u786e\u6027\u4e0a\u63a5\u8fd1\u5168\u76d1\u7763\u65b9\u6cd5\u3002", "motivation": "\u9ad8\u7ef4\u5b66\u4e60\u95ee\u9898\u4e2d\u7279\u5f81\u6570\u91cf\u8d85\u8fc7\u6837\u672c\u91cf\u65f6\u9700\u8981\u7a00\u758f\u6b63\u5219\u5316\u6765\u8fdb\u884c\u6709\u6548\u9884\u6d4b\u4e0e\u53d8\u91cf\u9009\u62e9\uff0c\u4f46\u73b0\u6709\u9488\u5bf9\u5f31\u76d1\u7763\u73af\u5883\u5982\u4ec5\u5229\u7528\u5e26\u7f6e\u4fe1\u5ea6\u5f97\u5206\u7684\u6b63\u6837\u672c\u8fdb\u884c\u5b66\u4e60\uff08Pconf\uff09\u7684\u65b9\u6cd5\u5e76\u4e0d\u9002\u5408\u5904\u7406\u9ad8\u7ef4\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u9ad8\u7ef4Pconf\u5206\u7c7b\u7684\u65b0\u7a00\u758f\u60e9\u7f5a\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u91c7\u7528\u51f8\uff08Lasso\uff09\u53ca\u975e\u51f8\uff08SCAD\u3001MCP\uff09\u60e9\u7f5a\u9879\u7684\u4f30\u8ba1\u5668\uff1b\u4e3a\u4e86\u89e3\u51b3\u7531\u6b64\u4ea7\u751f\u7684\u590d\u5408\u76ee\u6807\u51fd\u6570\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u8fd1\u7aef\u68af\u5ea6\u7b97\u6cd5\u3002", "result": "\u5e7f\u6cdb\u7684\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4e0e\u5168\u76d1\u7763\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u7684\u9884\u6d4b\u8868\u73b0\u548c\u53d8\u91cf\u9009\u62e9\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u7f29\u5c0f\u4e86\u5f31\u76d1\u7763\u5b66\u4e60\u4e0e\u9ad8\u7ef4\u7edf\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5904\u7406\u9ad8\u7ef4Pconf\u5206\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24445", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24445", "abs": "https://arxiv.org/abs/2512.24445", "authors": ["Akash Samanta", "Sheldon Williamson"], "title": "Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics", "comment": "This preprint focuses on the theoretical framework and diagnostic behavior. Comprehensive experimental validation in application-specific settings is deferred to a companion experimental study", "summary": "Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Building on this framework, we derive diagnostic-driven instantiations including a stabilized supervised optimizer, a diagnostic-regulated actor-critic scheme, and a diagnostic-conditioned learned optimizer. Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to temporal-difference error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u8bef\u5dee\u5206\u89e3\u4e3a\u504f\u5dee\u3001\u566a\u58f0\u548c\u5bf9\u9f50\u4e09\u90e8\u5206\u6765\u663e\u5f0f\u5efa\u6a21\u8bef\u5dee\u6f14\u53d8\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u591a\u79cd\u5b9e\u4f8b\u5316\u65b9\u6cd5\uff0c\u5e76\u5728\u6807\u51c6\u5e73\u6ed1\u5047\u8bbe\u4e0b\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "motivation": "\u9488\u5bf9\u975e\u5e73\u7a33\u548c\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u7cfb\u7edf\u5b58\u5728\u7684\u4e0d\u7a33\u5b9a\u6027\u3001\u6536\u655b\u7f13\u6162\u6216\u8106\u5f31\u9002\u5e94\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u68af\u5ea6\u7edf\u8ba1\u4fe1\u606f\u800c\u5ffd\u7565\u4e86\u8bef\u5dee\u4fe1\u53f7\u7684\u65f6\u95f4\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8bef\u5dee\u6f14\u53d8\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u5176\u5206\u89e3\u6210\u4e09\u4e2a\u7ec4\u6210\u90e8\u5206\uff1a\u504f\u5dee\uff08\u6301\u7eed\u6f02\u79fb\uff09\u3001\u566a\u58f0\uff08\u968f\u673a\u53d8\u5f02\u6027\uff09\u4ee5\u53ca\u5bf9\u9f50\uff08\u91cd\u590d\u65b9\u5411\u6027\u6fc0\u52b1\u5bfc\u81f4\u7684\u8fc7\u51b2\uff09\u3002\u8fd9\u4e9b\u8bca\u65ad\u6307\u6807\u53ef\u4ee5\u4ece\u635f\u5931\u6216\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u8f68\u8ff9\u7684\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u4e2d\u5728\u7ebf\u8ba1\u7b97\u5f97\u51fa\uff0c\u4e14\u4e0e\u6a21\u578b\u67b6\u6784\u6216\u4efb\u52a1\u9886\u57df\u65e0\u5173\u3002\u57fa\u4e8e\u8fd9\u4e2a\u6846\u67b6\uff0c\u8fdb\u4e00\u6b65\u63a8\u5bfc\u51fa\u5305\u62ec\u7a33\u5b9a\u76d1\u7763\u4f18\u5316\u5668\u3001\u8bca\u65ad\u8c03\u8282\u7684\u6f14\u5458-\u8bc4\u8bba\u5bb6\u65b9\u6848\u4ee5\u53ca\u8bca\u65ad\u6761\u4ef6\u4e0b\u7684\u5b66\u4e60\u4f18\u5316\u5668\u5728\u5185\u7684\u5177\u4f53\u5b9e\u73b0\u5f62\u5f0f\u3002", "result": "\u5728\u6807\u51c6\u5e73\u6ed1\u6761\u4ef6\u4e0b\uff0c\u6240\u6709\u63d0\u51fa\u7684\u7b97\u6cd5\u90fd\u5177\u6709\u6709\u754c\u6709\u6548\u66f4\u65b0\u548c\u7a33\u5b9a\u6027\u5c5e\u6027\u3002\u901a\u8fc7\u6f14\u5458-\u8bc4\u8bba\u5bb6\u5b66\u4e60\u4e2d\u7684\u4ee3\u8868\u6027\u8bca\u65ad\u56fe\u793a\u8bf4\u660e\u4e86\u6240\u63d0\u8bae\u4fe1\u53f7\u5982\u4f55\u6839\u636e\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u7ed3\u6784\u8c03\u6574\u9002\u5e94\u8fc7\u7a0b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u8bef\u5dee\u6f14\u53d8\u63d0\u5347\u4e3a\u81ea\u9002\u5e94\u5b66\u4e60\u4e2d\u7684\u9996\u8981\u5bf9\u8c61\uff0c\u5e76\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u53ef\u9760\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u8f7b\u91cf\u5316\u7684\u57fa\u7840\u3002"}}
{"id": "2512.24446", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.24446", "abs": "https://arxiv.org/abs/2512.24446", "authors": ["Patrick Wyrod", "Ashesh Chattopadhyay", "Daniele Venturi"], "title": "Generative forecasting with joint probability models", "comment": "18 pages, 11 figures", "summary": "Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b8c\u5168\u751f\u6210\u5f0f\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u7cfb\u7edf\u72b6\u6001\u6ede\u540e\u7a97\u53e3\u4e0a\u7684\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u5e76\u5229\u7528\u8fb9\u7f18\u5316\u6765\u83b7\u5f97\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6355\u6349\u975e\u7ebf\u6027\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3001\u8868\u793a\u591a\u6b65\u8f68\u8ff9\u6bb5\uff0c\u5e76\u4e14\u4ea7\u751f\u4e0e\u6240\u5b66\u8054\u5408\u5206\u5e03\u4e00\u81f4\u7684\u4e0b\u4e00\u6b65\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6846\u67b6\u7528\u4e8e\u8054\u5408\u751f\u6210\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6307\u6807\u8bc4\u4f30\u4e86\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002\u5728\u4e24\u4e2a\u7ecf\u5178\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u77ed\u671f\u9884\u6d4b\u51c6\u786e\u6027\u3001\u4fdd\u6301\u5438\u5f15\u5b50\u51e0\u4f55\u5f62\u72b6\u4ee5\u53ca\u5b9e\u73b0\u8fdc\u671f\u7edf\u8ba1\u884c\u4e3a\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684\u6761\u4ef6\u4e0b\u4e00\u6b65\u6a21\u578b\u3002", "motivation": "\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u5bf9\u521d\u59cb\u6761\u4ef6\u9ad8\u5ea6\u654f\u611f\uff0c\u5e76\u4e14\u901a\u5e38\u5305\u542b\u672a\u89e3\u51b3\u7684\u591a\u5c3a\u5ea6\u8fc7\u7a0b\uff0c\u8fd9\u4f7f\u5f97\u786e\u5b9a\u6027\u9884\u6d4b\u672c\u8d28\u4e0a\u53d7\u5230\u9650\u5236\u3002\u73b0\u6709\u7684\u5927\u591a\u6570\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u4e0b\u4e00\u6b65\u6761\u4ef6\u9884\u6d4b\uff0c\u800c\u4e0d\u662f\u5e95\u5c42\u52a8\u6001\u7ed3\u6784\u7684\u5b66\u4e60\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u7cfb\u7edf\u52a8\u6001\u672c\u8d28\u5e76\u63d0\u4f9b\u66f4\u53ef\u9760\u957f\u671f\u9884\u6d4b\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5c06\u9884\u6d4b\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5b8c\u5168\u751f\u6210\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5b66\u4e60\u77ed\u65f6\u95f4\u7a97\u53e3\u5185\u6ede\u540e\u7cfb\u7edf\u72b6\u6001\u7684\u8054\u5408\u6982\u7387\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u8fb9\u7f18\u5316\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\u3002\u540c\u65f6\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u8054\u5408\u751f\u6210\u9884\u6d4b\uff0c\u5e76\u4f7f\u7528\u4e09\u79cd\u8865\u5145\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5ea6\u91cf\uff08\u96c6\u6210\u65b9\u5dee\u3001\u77ed\u65f6\u81ea\u76f8\u5173\u548c\u7d2f\u79efWasserstein\u6f02\u79fb\uff09\u6765\u8bc4\u4f30\u9884\u6d4b\u7684\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728Lorenz-63\u7cfb\u7edf\u548cKuramoto-Sivashinsky\u65b9\u7a0b\u8fd9\u4e24\u4e2a\u5178\u578b\u7684\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u4e0a\uff0c\u63d0\u51fa\u7684\u8054\u5408\u751f\u6210\u6a21\u578b\u76f8\u8f83\u4e8e\u4f20\u7edf\u6761\u4ef6\u4e0b\u4e00\u6b65\u6a21\u578b\uff0c\u5728\u63d0\u9ad8\u77ed\u671f\u9884\u6d4b\u6280\u5de7\u3001\u4fdd\u6301\u5438\u5f15\u5b50\u51e0\u4f55\u5f62\u72b6\u4ee5\u53ca\u8fbe\u5230\u66f4\u51c6\u786e\u7684\u957f\u8303\u56f4\u7edf\u8ba1\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u5408\u751f\u6210\u6a21\u578b\u7684\u65b0\u9896\u9884\u6d4b\u65b9\u6cd5\uff0c\u5b83\u4e0d\u4ec5\u6539\u5584\u4e86\u6df7\u6c8c\u7cfb\u7edf\u7684\u77ed\u671f\u9884\u6d4b\u6027\u80fd\uff0c\u800c\u4e14\u5bf9\u4e8e\u4fdd\u6301\u7cfb\u7edf\u7684\u957f\u671f\u7edf\u8ba1\u7279\u6027\u4e5f\u975e\u5e38\u6709\u6548\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6846\u67b6\uff0c\u8be5\u65b9\u6cd5\u8fd8\u80fd\u6709\u6548\u5730\u8bc4\u4f30\u9884\u6d4b\u7ed3\u679c\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.24478", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24478", "abs": "https://arxiv.org/abs/2512.24478", "authors": ["Hyunjun Kim"], "title": "HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors", "comment": null, "summary": "Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory--representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (<10^{-6}), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [https://github.com/hyunjun1121/holograph](https://github.com/hyunjun1121/holograph).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHOLOGRAPH\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c42\u8bba\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4f5c\u4e3a\u56e0\u679c\u77e5\u8bc6\u6765\u6e90\u8fdb\u884c\u5f62\u5f0f\u5316\u5904\u7406\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHOLOGRAPH\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u57fa\u7840\uff0c\u572850-100\u53d8\u91cf\u7684\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u7684\u65b9\u6cd5\u53d7\u5230\u53ef\u8bc6\u522b\u6027\u7ea6\u675f\u7684\u9650\u5236\uff0c\u800c\u8fd1\u671f\u867d\u7136\u63a2\u7d22\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u5148\u9a8c\u56e0\u679c\u77e5\u8bc6\u6e90\uff0c\u4f46\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u652f\u6301\u7684\u65b9\u6cd5\u6765\u6574\u5408LLM\u63d0\u4f9b\u7684\u56e0\u679c\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86HOLOGRAPH\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u5c42\u8bba\u6765\u8868\u793a\u5c40\u90e8\u56e0\u679c\u4fe1\u5ff5\uff0c\u5e76\u901a\u8fc7\u4ee3\u6570\u6f5c\u5728\u6295\u5f71\u5904\u7406\u9690\u85cf\u6df7\u6dc6\u56e0\u7d20\uff0c\u540c\u65f6\u91c7\u7528\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u6cd5\u5728\u4fe1\u5ff5\u6d41\u5f62\u4e0a\u8fdb\u884c\u4f18\u5316\u3002", "result": "HOLOGRAPH\u6846\u67b6\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u5176\u7ade\u4e89\u529b\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca50\u81f3100\u4e2a\u53d8\u91cf\u7684\u56e0\u679c\u53d1\u73b0\u4efb\u52a1\u4e2d\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5c42\u8bba\u5206\u6790\u63ed\u793a\u4e86\u5728\u8f83\u5927\u56fe\u4e2d\u5c40\u90e8\u6027\u516c\u7406\u5931\u6548\u7684\u73b0\u8c61\uff0c\u63d0\u793a\u6f5c\u5728\u53d8\u91cf\u6295\u5f71\u4e2d\u7684\u57fa\u672c\u975e\u5c40\u90e8\u8026\u5408\u3002", "conclusion": "HOLOGRAPH\u4e3a\u5229\u7528LLM\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u5907\u4e25\u683c\u6570\u5b66\u57fa\u7840\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8bc1\u660e\u4e86\u5b83\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.24545", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24545", "abs": "https://arxiv.org/abs/2512.24545", "authors": ["Yuma Ichikawa", "Yoshihiko Fujisawa", "Yudai Fujimoto", "Akira Sakai", "Katsuki Fujisawa"], "title": "More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization", "comment": "14 pages, 2 figures", "summary": "For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4e8c\u8fdb\u5236\u56e0\u5b50\u5206\u89e3\u65b9\u6cd5\u2014\u2014\u591a\u5305\u7edcDBF\uff08MDBF\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u7b26\u53f7\u77e9\u9635\u5e76\u5728\u6709\u9650\u5185\u5b58\u9884\u7b97\u5185\u63d0\u9ad8\u5e45\u5ea6\u8868\u73b0\u529b\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u76f8\u540c\u90e8\u7f72\u53cb\u597d\u63a8\u7406\u539f\u8bed\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u53cc\u4e8c\u8fdb\u5236\u56e0\u5b50\u5206\u89e3(DBF)\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6781\u4f4e\u6bd4\u7279\u91cf\u5316\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5176\u7f29\u653e\u53c2\u6570\u8fc7\u4e8e\u9650\u5236\uff0c\u5bfc\u81f4\u6240\u6709\u79e9\u5206\u91cf\u5171\u4eab\u76f8\u540c\u7684\u5e45\u5ea6\u5206\u5e03\uff0c\u8fdb\u800c\u5f15\u8d77\u6027\u80fd\u9971\u548c\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u5305\u7edcDBF (MDBF)\uff0c\u4fdd\u7559\u4e86\u5171\u4eab\u7684\u4e00\u5bf91\u4f4d\u7b26\u53f7\u57fa\u4f46\u7528\u4e00\u4e2a\u79e9-l\u5305\u7edc\u66ff\u6362\u5355\u4e00\u5305\u7edc\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u95ed\u5f0f\u521d\u59cb\u5316\u548c\u4ea4\u66ff\u7cbe\u70bc\u65b9\u6cd5\u6765\u4f18\u5316MDBF\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728LLaMA\u548cQwen\u7cfb\u5217\u4e2d\uff0c\u4e0e\u4e4b\u524d\u7684\u4e8c\u8fdb\u5236\u683c\u5f0f\u76f8\u6bd4\uff0cMDBF\u5728\u6bcf\u6743\u91cd\u6bd4\u7279\u6570\u5339\u914d\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u6613\u4e8e\u90e8\u7f72\u7684\u63a8\u7406\u539f\u8bed\u3002", "conclusion": "MDBF\u4e3a\u6781\u7aef\u4f4e\u6bd4\u7279\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u4e0d\u4ec5\u514b\u670d\u4e86\u4f20\u7edfDBF\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u8fd8\u5728\u4e0d\u727a\u7272\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u63a8\u7406\u3002"}}
{"id": "2512.24564", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24564", "abs": "https://arxiv.org/abs/2512.24564", "authors": ["Shunbo Jia", "Caizhi Liao"], "title": "CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts", "comment": null, "summary": "Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5CPR\uff0c\u901a\u8fc7\u5728\u56e0\u679c\u89e3\u7f20\u6846\u67b6\u4e2d\u5f15\u5165\u751f\u7406\u7ed3\u6784\u5148\u9a8c\u6765\u89e3\u51b3ECG\u8bca\u65ad\u6a21\u578b\u5bf9\u5bf9\u6297\u6027\u6270\u52a8\u7684\u8106\u5f31\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCPR\u4e0d\u4ec5\u5728SAP\u653b\u51fb\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u5355\u6b21\u63a8\u7406\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5fc3\u7535\u56fe\u8bca\u65ad\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u51c6\u786e\u6027\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u6a21\u4eff\u751f\u7269\u5f62\u6001\u7684\u5e73\u6ed1\u5bf9\u6297\u6270\u52a8\uff08SAP\uff09\u7684\u5f71\u54cd\u3002\u73b0\u6709\u7684\u9632\u5fa1\u63aa\u65bd\u8981\u4e48\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u8981\u4e48\u5bfc\u81f4\u663e\u8457\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u4e34\u5e8a\u76d1\u6d4b\u3002\u8fd9\u79cd\u8106\u5f31\u6027\u6e90\u4e8e\u6a21\u578b\u4f9d\u8d56\u4e8e\u975e\u7a33\u5065\u7684\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u4e0d\u53d8\u7684\u75c5\u7406\u7279\u5f81\u3002", "method": "\u63d0\u51fa\u4e86Causal Physiological Representation Learning (CPR)\uff0c\u5b83\u5728\u4e00\u4e2a\u56e0\u679c\u89e3\u7f20\u6846\u67b6\u5185\u6574\u5408\u4e86\u751f\u7406\u7ed3\u6784\u5148\u9a8c\u3002\u901a\u8fc7\u4f7f\u7528\u7ed3\u6784\u6027\u56e0\u679c\u6a21\u578b\uff08SCM\uff09\u6a21\u62dfECG\u751f\u6210\u8fc7\u7a0b\uff0cCPR\u5f3a\u5236\u6267\u884c\u4e00\u79cd\u7ed3\u6784\u5e72\u9884\uff0c\u4e25\u683c\u533a\u5206\u4e0d\u53d8\u7684\u75c5\u7406\u5f62\u6001\uff08P-QRS-T\u590d\u5408\u4f53\uff09\u4e0e\u975e\u56e0\u679c\u7684\u4eba\u5de5\u5236\u54c1\u3002", "result": "\u5728PTB-XL\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u9762\u5bf9SAP\u653b\u51fb\u65f6\uff0cCPR\u8fbe\u5230\u4e860.632\u7684F1\u5206\u6570\uff0c\u6bd4\u4e2d\u503c\u5e73\u6ed1\u6cd5\u9ad8\u51fa9.1%\u3002\u6b64\u5916\uff0cCPR\u5728\u4fdd\u6301\u5355\u6b21\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\uff0c\u5339\u914d\u4e86\u968f\u673a\u5e73\u6ed1\u8ba4\u8bc1\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "CPR\u65b9\u6cd5\u4e3a\u63d0\u9ad8ECG\u8bca\u65ad\u6a21\u578b\u5bf9\u6297\u5bf9\u6297\u6027\u6270\u52a8\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u9c81\u68d2\u6027\u548c\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u4e5f\u7ef4\u6301\u4e86\u9ad8\u6548\u6027\u3002"}}
{"id": "2512.24617", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24617", "abs": "https://arxiv.org/abs/2512.24617", "authors": ["Xingwei Qu", "Shaowen Wang", "Zihao Huang", "Kai Hua", "Fan Yin", "Rui-Jie Zhu", "Jundong Zhou", "Qiyang Min", "Zihao Wang", "Yizhi Li", "Tianyu Zhang", "He Xing", "Zheng Zhang", "Yuxuan Song", "Tianyu Zheng", "Zhiyuan Zeng", "Chenghua Lin", "Ge Zhang", "Wenhao Huang"], "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space", "comment": null, "summary": "Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose $\\textbf{Dynamic Large Concept Models (DLCM)}$, a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first $\\textbf{compression-aware scaling law}$, which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a $\\textbf{decoupled $\u03bc$P parametrization}$ that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ($R=4$, corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a $\\textbf{+2.69$\\%$ average improvement}$ across 12 zero-shot benchmarks under matched inference FLOPs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u6846\u67b6DLCM\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5b66\u4e60\u8bed\u4e49\u8fb9\u754c\u5e76\u4ecetoken\u7a7a\u95f4\u538b\u7f29\u5230\u6982\u5ff5\u7a7a\u95f4\u6765\u66f4\u9ad8\u6548\u5730\u8fdb\u884c\u63a8\u7406\u3002\u5f15\u5165\u4e86\u9996\u4e2a\u538b\u7f29\u611f\u77e5\u7f29\u653e\u5b9a\u5f8b\uff0c\u5e76\u5f00\u53d1\u4e86\u89e3\u8026\u7684$\\mu$P\u53c2\u6570\u5316\u65b9\u6cd5\u4ee5\u652f\u6301\u8d85\u53c2\u6570\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002\u5728\u5b9e\u9645\u8bbe\u7f6e\u4e0b\uff0cDLCM\u80fd\u591f\u5c06\u5927\u7ea6\u4e09\u5206\u4e4b\u4e00\u7684\u63a8\u7406\u8ba1\u7b97\u91cd\u65b0\u5206\u914d\u7ed9\u66f4\u9ad8\u5bb9\u91cf\u7684\u63a8\u7406\u4e3b\u5e72\uff0c\u5728\u5339\u914d\u7684\u63a8\u7406FLOPs\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u5e73\u57472.69%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6240\u6709token\u5e94\u7528\u76f8\u540c\u7684\u8ba1\u7b97\u65b9\u5f0f\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5bf9\u4e8e\u5c40\u90e8\u53ef\u9884\u6d4b\u90e8\u5206\u8fc7\u5ea6\u4f7f\u7528\u8ba1\u7b97\u80fd\u529b\uff0c\u800c\u5bf9\u8bed\u4e49\u4e0a\u5173\u952e\u8f6c\u6362\u90e8\u5206\u5219\u8ba1\u7b97\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u5927\u6982\u5ff5\u6a21\u578b\uff08DLCM\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5c42\u6b21\u5316\u7684\u8bed\u8a00\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u6f5c\u5728\u8868\u793a\u4e2d\u5b66\u4e60\u8bed\u4e49\u8fb9\u754c\uff0c\u5e76\u5c06\u8ba1\u7b97\u4ecetoken\u7a7a\u95f4\u8f6c\u79fb\u5230\u66f4\u52a0\u9ad8\u6548\u7684\u538b\u7f29\u6982\u5ff5\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u9996\u4e2a\u538b\u7f29\u611f\u77e5\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u4ee5\u53ca\u4e00\u79cd\u89e3\u8026\u7684$\\mu$P\u53c2\u6570\u5316\u65b9\u6cd5\u3002", "result": "DLCM\u80fd\u591f\u5728\u4fdd\u6301\u76f8\u540c\u63a8\u7406FLOPs\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u7ea6\u4e09\u5206\u4e4b\u4e00\u7684\u63a8\u7406\u8ba1\u7b97\u8d44\u6e90\u91cd\u65b0\u5206\u914d\u7ed9\u4e00\u4e2a\u66f4\u9ad8\u5bb9\u91cf\u7684\u63a8\u7406\u4e3b\u5e72\uff0c\u4ece\u800c\u572812\u4e2a\u96f6\u6837\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u4e86\u5e73\u5747+2.69%\u7684\u8868\u73b0\u63d0\u5347\u3002", "conclusion": "DLCM\u901a\u8fc7\u6709\u6548\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u548c\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u5bc6\u5ea6\u5904\u7406\uff0c\u4e3a\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.24625", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24625", "abs": "https://arxiv.org/abs/2512.24625", "authors": ["Zijian Zhao", "Yitong Shang", "Sen Li"], "title": "AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt", "comment": null, "summary": "Accurate traffic prediction is essential for Intelligent Transportation Systems, including ride-hailing, urban road planning, and vehicle fleet management. However, due to significant privacy concerns surrounding traffic data, most existing methods rely on local training, resulting in data silos and limited knowledge sharing. Federated Learning (FL) offers an efficient solution through privacy-preserving collaborative training; however, standard FL struggles with the non-independent and identically distributed (non-IID) problem among clients. This challenge has led to the emergence of Personalized Federated Learning (PFL) as a promising paradigm. Nevertheless, current PFL frameworks require further adaptation for traffic prediction tasks, such as specialized graph feature engineering, data processing, and network architecture design. A notable limitation of many prior studies is their reliance on hyper-parameter optimization across datasets-information that is often unavailable in real-world scenarios-thus impeding practical deployment. To address this challenge, we propose AutoFed, a novel PFL framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. Inspired by prompt learning, AutoFed introduces a federated representor that employs a client-aligned adapter to distill local data into a compact, globally shared prompt matrix. This prompt then conditions a personalized predictor, allowing each client to benefit from cross-client knowledge while maintaining local specificity. Extensive experiments on real-world datasets demonstrate that AutoFed consistently achieves superior performance across diverse scenarios. The code of this paper is provided at https://github.com/RS2002/AutoFed .", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAutoFed\u7684\u65b0\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\uff0c\u901a\u8fc7\u5f15\u5165\u8054\u5408\u8868\u793a\u5668\u548c\u5ba2\u6237\u7aef\u5bf9\u9f50\u9002\u914d\u5668\u6765\u89e3\u51b3\u975e\u72ec\u7acb\u540c\u5206\u5e03\u95ee\u9898\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u8d85\u53c2\u6570\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u7531\u4e8e\u9690\u79c1\u95ee\u9898\u901a\u5e38\u4f9d\u8d56\u4e8e\u672c\u5730\u8bad\u7ec3\uff0c\u5bfc\u81f4\u6570\u636e\u5b64\u5c9b\u73b0\u8c61\uff1b\u800c\u6807\u51c6\u7684\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u5ba2\u6237\u7aef\u95f4\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u65f6\u5b58\u5728\u56f0\u96be\u3002\u6b64\u5916\uff0c\u5f53\u524d\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u9700\u8981\u8fdb\u4e00\u6b65\u9002\u5e94\u4ea4\u901a\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u4e14\u5f88\u591a\u7814\u7a76\u4f9d\u8d56\u4e8e\u8de8\u6570\u636e\u96c6\u7684\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u5f00\u53d1\u4e86AutoFed\u6846\u67b6\uff0c\u5b83\u5229\u7528\u542f\u53d1\u81ea\u63d0\u793a\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5ba2\u6237\u7aef\u5bf9\u9f50\u9002\u914d\u5668\u5c06\u672c\u5730\u6570\u636e\u63d0\u70bc\u6210\u4e00\u4e2a\u7d27\u51d1\u7684\u3001\u5168\u5c40\u5171\u4eab\u7684\u63d0\u793a\u77e9\u9635\u3002\u8be5\u63d0\u793a\u77e9\u9635\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e2a\u6027\u5316\u7684\u9884\u6d4b\u6761\u4ef6\uff0c\u4ece\u800c\u5141\u8bb8\u5b83\u4eec\u4ece\u8de8\u5ba2\u6237\u7aef\u7684\u77e5\u8bc6\u4e2d\u53d7\u76ca\u540c\u65f6\u4fdd\u6301\u672c\u5730\u7279\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAutoFed\u80fd\u591f\u5728\u591a\u79cd\u573a\u666f\u4e0b\u6301\u7eed\u5730\u8fbe\u5230\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "AutoFed\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u4e3a\u4ea4\u901a\u9884\u6d4b\u8bbe\u8ba1\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e0d\u9700\u8981\u624b\u5de5\u8c03\u8282\u8d85\u53c2\u6570\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u60c5\u51b5\u4e0b\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2512.24695", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.24695", "abs": "https://arxiv.org/abs/2512.24695", "authors": ["Ali Behrouz", "Meisam Razaviyayn", "Peilin Zhong", "Vahab Mirrokni"], "title": "Nested Learning: The Illusion of Deep Learning Architectures", "comment": "A version of this work is published at Neural Information Processing Systems (NeurIPS) 2025", "summary": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\u2014\u2014\u5d4c\u5957\u5b66\u4e60\uff08NL\uff09\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u5d4c\u5957\u3001\u591a\u5c42\u6b21\u548c/\u6216\u5e76\u884c\u7684\u4f18\u5316\u95ee\u9898\u6765\u8868\u793a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u6bcf\u4e2a\u95ee\u9898\u90fd\u6709\u81ea\u5df1\u7684\u4e0a\u4e0b\u6587\u6d41\u3002\u57fa\u4e8e\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e09\u4e2a\u6838\u5fc3\u8d21\u732e\uff1a\u8868\u8fbe\u6027\u4f18\u5316\u5668\u3001\u81ea\u4fee\u6539\u5b66\u4e60\u6a21\u5757\u548c\u8fde\u7eed\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u7684\u826f\u597d\u7ed3\u679c\u3002", "motivation": "\u5c3d\u7ba1\u6700\u8fd1\u5728\u5f00\u53d1\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5173\u4e8e\u6b64\u7c7b\u6a21\u578b\u5982\u4f55\u6301\u7eed\u5b66\u4e60/\u8bb0\u5fc6\u3001\u81ea\u6211\u6539\u8fdb\u5e76\u627e\u5230\u6709\u6548\u89e3\u51b3\u65b9\u6848\u4ecd\u5b58\u5728\u6839\u672c\u6027\u7684\u6311\u6218\u548c\u672a\u89e3\u4e4b\u8c1c\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\u2014\u2014\u5d4c\u5957\u5b66\u4e60\uff08NL\uff09\uff1b2. \u53d1\u73b0\u5df2\u77e5\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u5668\u5b9e\u9645\u4e0a\u662f\u4e00\u79cd\u5173\u8054\u8bb0\u5fc6\u6a21\u5757\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u66f4\u5177\u6709\u8868\u73b0\u529b\u7684\u4f18\u5316\u5668\uff1b3. \u5229\u7528\u5bf9\u5b66\u4e60\u7b97\u6cd5\u7684\u65b0\u89c1\u89e3\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u80fd\u591f\u5b66\u4e60\u5982\u4f55\u81ea\u6211\u4fee\u6539\u7684\u5e8f\u5217\u6a21\u578b\uff1b4. \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u5f62\u5f0f\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u6982\u62ec\u4e86\u4f20\u7edf\u957f/\u77ed\u671f\u8bb0\u5fc6\u7684\u89c2\u70b9\u3002", "result": "\u7ed3\u5408\u81ea\u4fee\u6539\u5e8f\u5217\u6a21\u578b\u4e0e\u8fde\u7eed\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6301\u7eed\u5b66\u4e60\u6a21\u5757Hope\uff0c\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u77e5\u8bc6\u878d\u5408\u3001\u5c11\u91cf\u6837\u672c\u6cdb\u5316\u4efb\u52a1\u3001\u6301\u7eed\u5b66\u4e60\u4ee5\u53ca\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u793a\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "conclusion": "\u5d4c\u5957\u5b66\u4e60\u4e3a\u8bbe\u8ba1\u66f4\u5177\u8868\u73b0\u529b\u7684\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u54f2\u5b66\u6307\u5bfc\uff0c\u4fc3\u8fdb\u4e86\u66f4\u9ad8\u9636\u7684\u60c5\u5883\u5185\u5b66\u4e60\uff0c\u5e76\u53ef\u80fd\u89e3\u9501\u6709\u6548\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2512.24696", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24696", "abs": "https://arxiv.org/abs/2512.24696", "authors": ["Amir Asiaee", "Samhita Pal", "James O'quinn", "James P. Long"], "title": "Causal Discovery with Mixed Latent Confounding via Precision Decomposition", "comment": null, "summary": "We study causal discovery from observational data in linear Gaussian systems affected by \\emph{mixed latent confounding}, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure.\n  We propose \\textsc{DCL-DECOR}, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness.\n  We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDCL-DECOR\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u5b58\u5728\u6df7\u5408\u6f5c\u5728\u6df7\u6dc6\u7684\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\u4e2d\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u89c2\u6d4b\u5230\u7684\u7cbe\u5ea6\u77e9\u9635\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u6210\u5206\u548c\u4f4e\u79e9\u6210\u5206\u6765\u9694\u79bb\u666e\u904d\u5b58\u5728\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u5e76\u4f7f\u7528\u76f8\u5173\u566a\u58f0DAG\u5b66\u4e60\u5668\u6062\u590d\u6709\u5411\u8fb9\uff0c\u540c\u65f6\u5efa\u6a21\u5269\u4f59\u7684\u7ed3\u6784\u5316\u8bef\u5dee\u76f8\u5173\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u6062\u590d\u6709\u5411\u8fb9\u4e0a\u6bd4\u76f4\u63a5\u5e94\u7528\u76f8\u5173\u566a\u58f0DAG\u5b66\u4e60\u4e8e\u6df7\u6dc6\u6570\u636e\u66f4\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u56e0\u679c\u53d1\u73b0\u7684\u65b9\u6cd5\u5728\u5904\u7406\u6df7\u5408\u6f5c\u5728\u6df7\u6dc6\uff08\u5373\u4e00\u4e9b\u672a\u89c2\u5bdf\u5230\u7684\u56e0\u7d20\u5e7f\u6cdb\u4f5c\u7528\u4e8e\u8bb8\u591a\u53d8\u91cf\u800c\u5176\u4ed6\u56e0\u7d20\u53ea\u5f71\u54cd\u5c0f\u90e8\u5206\u53d8\u91cf\uff09\u65f6\u9762\u4e34\u6311\u6218\uff1a\u53ef\u5fae\u5206\u548c\u57fa\u4e8e\u5206\u6570\u7684DAG\u5b66\u4e60\u8005\u53ef\u80fd\u5c06\u5168\u5c40\u6f5c\u5728\u6548\u5e94\u8bef\u89e3\u4e3a\u56e0\u679c\u8fb9\uff0c\u800c\u6f5c\u53d8\u91cf\u56fe\u5f62\u6a21\u578b\u4ec5\u80fd\u6062\u590d\u65e0\u5411\u7ed3\u6784\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u51c6\u786e\u533a\u5206\u8fd9\u4e9b\u5f71\u54cd\u5e76\u6709\u6548\u6062\u590d\u771f\u5b9e\u56e0\u679c\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "DCL-DECOR\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u5206\u89e3\u89c2\u6d4b\u7cbe\u5ea6\u77e9\u9635\u6765\u5206\u79bb\u666e\u904d\u6027\u7684\u6f5c\u5728\u6548\u5e94\u4e0e\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\u3002\u63a5\u7740\uff0c\u5229\u7528\u4e00\u4e2a\u8003\u8651\u4e86\u5269\u4f59\u7ed3\u6784\u5316\u9519\u8bef\u76f8\u5173\u7684\u76f8\u5173\u566a\u58f0DAG\u5b66\u4e60\u7b97\u6cd5\u5bf9\u53bb\u6df7\u6dc6\u540e\u7684\u8868\u793a\u8fdb\u884c\u5206\u6790\uff0c\u4ee5\u6062\u590d\u6709\u5411\u8fb9\u3002\u6700\u540e\uff0c\u5b9e\u65bd\u7b80\u5355\u7684\u8c03\u6574\u6b65\u9aa4\u786e\u4fdd\u7ed3\u679c\u6ee1\u8db3\u5f13\u5f62\u81ea\u7531\u6761\u4ef6\u3002", "result": "\u5408\u6210\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u6539\u53d8\u666e\u904d\u6df7\u6dc6\u5f3a\u5ea6\u548c\u7ef4\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0cDCL-DECOR\u65b9\u6cd5\u5728\u6062\u590d\u6709\u5411\u8fb9\u65b9\u9762\u76f8\u8f83\u4e8e\u76f4\u63a5\u5bf9\u6df7\u6dc6\u6570\u636e\u5e94\u7528\u76f8\u5173\u566a\u58f0DAG\u5b66\u4e60\u5177\u6709\u6301\u7eed\u6539\u8fdb\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8e\u5728\u6df7\u5408\u6df7\u6dc6\u6761\u4ef6\u4e0b\u53ef\u8bc6\u522b\u56e0\u679c\u76ee\u6807\u7684\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "DCL-DECOR\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u56e0\u6df7\u5408\u6f5c\u5728\u6df7\u6dc6\u800c\u5bfc\u81f4\u7684\u56e0\u679c\u53d1\u73b0\u96be\u9898\u3002\u901a\u8fc7\u5206\u79bb\u666e\u904d\u6027\u548c\u5c40\u90e8\u7684\u5f71\u54cd\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6062\u590d\u56e0\u679c\u56fe\u4e2d\u7684\u6709\u5411\u8fb9\u3002"}}
{"id": "2512.24713", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.24713", "abs": "https://arxiv.org/abs/2512.24713", "authors": ["Fen-Yu Hsieh", "Yun-Chang Teng", "Ding-Yong Hong", "Jan-Jan Wu"], "title": "FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on $4096 \\times 4096$ matrices, our approach achieves a reduction of up to $4\\times$ in weight storage and a $1.71\\times$ speedup in matrix multiplication, yielding a $1.29\\times$ end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by $1.36\\times$. These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u6743\u91cd\u526a\u679d\u548c\u4f4e\u4f4d\u91cf\u5316\u6280\u672f\uff0c\u5e76\u901a\u8fc7\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u5728FPGA\u5e73\u53f0\u4e0a\u751f\u6210\u52a0\u901f\u5668\uff0c\u4ee5\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe4\u500d\u7684\u6743\u91cd\u5b58\u50a8\u51cf\u5c11\u548c1.71\u500d\u7684\u77e9\u9635\u4e58\u6cd5\u901f\u5ea6\u63d0\u5347\uff0c\u4ece\u800c\u4f7f\u5f97\u4e0e\u5bc6\u96c6GPU\u57fa\u7ebf\u76f8\u6bd4\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u4e861.29\u500d\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f17\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u8ba1\u7b97\u8d44\u6e90\u548c\u5185\u5b58\u7684\u9700\u6c42\u6781\u5927\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u81ea\u52a8\u5316\u6846\u67b6\u6765\u964d\u4f4eLLM\u7684\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86N:M\u7ed3\u6784\u5316\u526a\u679d\u548c4\u4f4d\u6574\u6570\u91cf\u5316\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002\u968f\u540e\uff0c\u901a\u8fc7\u5bf9\u53bb\u91cf\u5316\u548c\u77e9\u9635\u4e58\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u591a\u79cd\u786c\u4ef6\u5e73\u53f0\uff08\u5305\u62ecCPU\u3001\u5177\u6709Dense\u548c2:4\u7a00\u758f\u5f20\u91cf\u6838\u5fc3\u7684NVIDIA GPU\u4ee5\u53ca\u57fa\u4e8esystolic array\u7684\u81ea\u5b9a\u4e49FPGA\u52a0\u901f\u5668\uff09\u4e0a\u7684LLM\u63a8\u7406\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u6700\u591a\u8fbe4\u500d\u7684\u6743\u91cd\u5b58\u50a8\u51cf\u5c11\u548c1.71\u500d\u7684\u77e9\u9635\u4e58\u6cd5\u52a0\u901f\uff0c\u76f8\u8f83\u4e8e\u4f7f\u7528\u5bc6\u96c6GPU\u4f5c\u4e3a\u57fa\u51c6\u7684\u60c5\u51b5\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u51cf\u5c11\u4e861.29\u500d\u3002\u6b64\u5916\uff0c\u5728LLaMA-7B\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u89c4\u6a21\u5206\u6790\u663e\u793a\uff0c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u53ef\u4f7f\u6bcf\u4ee4\u724c\u541e\u5410\u91cf\u63d0\u9ad81.36\u500d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u7ec6\u7c92\u5ea6N:M\u7a00\u758f\u6027\u548c\u91cf\u5316\u6280\u672f\u76f8\u7ed3\u5408\u5bf9\u4e8e\u5b9e\u73b0\u9ad8\u6548\u4e14\u6613\u4e8e\u90e8\u7f72\u7684LLM\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002\u63d0\u51fa\u7684FPGA\u52a0\u901f\u5668\u4e0d\u4ec5\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u7a00\u758f\u6a21\u5f0f\uff0c\u8fd8\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u67b6\u6784\u65b9\u5411\u3002"}}
{"id": "2512.24767", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24767", "abs": "https://arxiv.org/abs/2512.24767", "authors": ["Yutong Cai", "Hua Wang"], "title": "From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis", "comment": null, "summary": "Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu's Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \\& Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8e\u4e2d\u56fd\u6b66\u6c49\u5b9e\u9645\u8fd0\u8425\u7684\u767e\u5ea6Apollo Robotaxi\u670d\u52a1\uff0c\u901a\u8fc7\u8c03\u67e5\u6570\u636e\u6536\u96c6\u4e86336\u4efd\u6709\u6548\u53cd\u9988\uff0c\u5229\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u8bc6\u522b\u51fa\u4fe1\u4efb\u4e0e\u653f\u7b56\u652f\u6301\u3001\u6210\u672c\u654f\u611f\u6027\u3001\u6027\u80fd\u3001\u884c\u4e3a\u610f\u56fe\u3001\u751f\u6d3b\u65b9\u5f0f\u548c\u6559\u80b2\u8fd9\u516d\u4e2a\u6f5c\u5728\u5fc3\u7406\u56e0\u7d20\uff0c\u5e76\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u7528\u6237\u91c7\u7528\u81ea\u52a8\u9a7e\u9a76\u51fa\u79df\u8f66\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\u6210\u672c\u654f\u611f\u6027\u548c\u884c\u4e3a\u610f\u56fe\u662f\u5f71\u54cd\u91c7\u7528\u884c\u4e3a\u6700\u5f3a\u7684\u6b63\u9762\u9884\u6d4b\u56e0\u5b50\u3002", "motivation": "\u867d\u7136\u73b0\u6709\u6587\u732e\u5df2\u7ecf\u901a\u8fc7\u58f0\u660e\u504f\u597d\u5b9e\u9a8c\u548c\u5047\u8bbe\u60c5\u666f\u63a2\u7d22\u4e86\u7528\u6237\u5bf9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u51fa\u79df\u8f66\u7684\u63a5\u53d7\u5ea6\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u57fa\u4e8e\u5b9e\u9645\u8fd0\u884c\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u670d\u52a1\u6765\u8c03\u67e5\u7528\u6237\u7684\u771f\u5b9e\u884c\u4e3a\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u5173\u4e8e\u7528\u6237\u771f\u5b9e\u884c\u4e3a\u7684\u6570\u636e\u4ee5\u53ca\u5bf9\u81ea\u52a8\u9a7e\u9a76\u51fa\u79df\u8f66\u91c7\u7eb3\u884c\u4e3a\u80cc\u540e\u56e0\u7d20\u7684\u7406\u89e3\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u8bbe\u8ba1\u4e00\u4e2a\u5305\u542b\u5b9e\u9645\u670d\u52a1\u5c5e\u6027\u7684\u73b0\u5b9e\u8c03\u67e5\u95ee\u5377\uff0c\u5e76\u4ece\u4e2d\u56fd\u6b66\u6c49\u5730\u533a\u83b7\u53d6336\u4f4d\u5b9e\u9645\u7528\u6237\u7684\u6709\u6548\u56de\u590d\u3002\u63a5\u7740\uff0c\u4f7f\u7528\u7ed3\u6784\u65b9\u7a0b\u5efa\u6a21\u6280\u672f\u5206\u6790\u4e86\u516d\u4e2a\u6f5c\u5728\u7684\u5fc3\u7406\u6784\u5efa\uff08\u4fe1\u4efb\u4e0e\u653f\u7b56\u652f\u6301\u3001\u6210\u672c\u654f\u611f\u6027\u3001\u6027\u80fd\u3001\u884c\u4e3a\u610f\u56fe\u3001\u751f\u6d3b\u65b9\u5f0f\u3001\u6559\u80b2\uff09\u53ca\u5176\u5bf9\u9009\u62e9\u9891\u7387\u4f5c\u4e3a\u91c7\u7528\u884c\u4e3a\u6307\u6807\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6240\u6709\u8003\u5bdf\u7684\u56e0\u7d20\u4e2d\uff0c\u6210\u672c\u654f\u611f\u6027\u548c\u884c\u4e3a\u610f\u56fe\u662f\u5bf9\u81ea\u52a8\u9a7e\u9a76\u51fa\u79df\u8f66\u91c7\u7528\u884c\u4e3a\u6700\u5f3a\u6709\u529b\u7684\u6b63\u5411\u9884\u6d4b\u56e0\u7d20\u3002\u5176\u4ed6\u6f5c\u5728\u6784\u9020\u5219\u5728\u4e0d\u540c\u7a0b\u5ea6\u4e0a\u53d1\u6325\u7740\u4f5c\u7528\u3002\u6b64\u5916\uff0c\u6240\u5efa\u7acb\u7684\u6a21\u578b\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u62df\u5408\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5236\u5b9a\u76f8\u5173\u653f\u7b56\u3001\u7968\u4ef7\u8bbe\u8ba1\u53ca\u516c\u4f17\u5ba3\u4f20\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u4ee5\u4fc3\u8fdb\u81ea\u52a8\u9a7e\u9a76\u51fa\u79df\u8f66\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2512.24810", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24810", "abs": "https://arxiv.org/abs/2512.24810", "authors": ["Bence Bolg\u00e1r", "Andr\u00e1s Millinghoffer", "P\u00e9ter Antal"], "title": "DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes", "comment": null, "summary": "Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel operations, such as Bayesian classification with rejection, top-$K$ selection, and ranking. We propose a deep kernel learning-based GP architecture (DTI-GP), which incorporates a combined neural embedding module for chemical compounds and protein targets, and a GP module. The workflow continues with sampling from the predictive distribution to estimate a Bayesian precedence matrix, which is used in fast and accurate selection and ranking operations. DTI-GP outperforms state-of-the-art solutions, and it allows (1) the construction of a Bayesian accuracy-confidence enrichment score, (2) rejection schemes for improved enrichment, and (3) estimation and search for top-$K$ selections and ranking with high expected utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u6838\u5b66\u4e60\u7684\u9ad8\u65af\u8fc7\u7a0b\u67b6\u6784\uff08DTI-GP\uff09\uff0c\u7528\u4e8e\u836f\u7269-\u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5316\u5b66\u5316\u5408\u7269\u548c\u86cb\u767d\u8d28\u9776\u70b9\u7684\u795e\u7ecf\u5d4c\u5165\u6a21\u5757\u4ee5\u53ca\u4e00\u4e2a\u9ad8\u65af\u8fc7\u7a0b\u6a21\u5757\uff0c\u80fd\u591f\u63d0\u4f9b\u7cbe\u786e\u7684\u6982\u7387\u4fe1\u606f\uff0c\u5e76\u652f\u6301\u8d1d\u53f6\u65af\u5206\u7c7b\u3001\u524dK\u9009\u62e9\u53ca\u6392\u5e8f\u7b49\u64cd\u4f5c\u3002", "motivation": "\u51c6\u786e\u7684\u6982\u7387\u4fe1\u606f\u5bf9\u4e8e\u7406\u89e3\u836f\u7269-\u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u7684\u5c40\u9650\u6027\u5e76\u63d0\u9ad8\u5176\u9884\u6d4b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6574\u5408\u6700\u5148\u8fdb\u7684DTI\u8868\u793a\u548c\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u6838\u5b66\u4e60\u7684\u9ad8\u65af\u8fc7\u7a0b\u67b6\u6784\uff08DTI-GP\uff09\u3002\u8be5\u67b6\u6784\u5305\u62ec\u4e00\u4e2a\u9488\u5bf9\u5316\u5b66\u5316\u5408\u7269\u548c\u86cb\u767d\u8d28\u9776\u70b9\u7684\u7ec4\u5408\u795e\u7ecf\u5d4c\u5165\u6a21\u5757\u4ee5\u53ca\u4e00\u4e2a\u9ad8\u65af\u8fc7\u7a0b\u6a21\u5757\u3002\u901a\u8fc7\u4ece\u9884\u6d4b\u5206\u5e03\u4e2d\u91c7\u6837\u6765\u4f30\u8ba1\u8d1d\u53f6\u65af\u4f18\u5148\u7ea7\u77e9\u9635\uff0c\u4ee5\u8fdb\u884c\u5feb\u901f\u800c\u51c6\u786e\u7684\u9009\u62e9\u548c\u6392\u540d\u64cd\u4f5c\u3002", "result": "DTI-GP\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5141\u8bb8(1)\u6784\u5efa\u8d1d\u53f6\u65af\u51c6\u786e\u6027-\u7f6e\u4fe1\u5ea6\u5bcc\u96c6\u5206\u6570\uff0c(2)\u91c7\u7528\u62d2\u7edd\u65b9\u6848\u4ee5\u6539\u5584\u5bcc\u96c6\u6548\u679c\uff0c\u4ee5\u53ca(3)\u4f30\u8ba1\u5e76\u641c\u7d22\u5177\u6709\u9ad8\u9884\u671f\u6548\u7528\u7684\u524dK\u9009\u62e9\u4e0e\u6392\u540d\u3002", "conclusion": "DTI-GP\u4e0d\u4ec5\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u8fd8\u63d0\u4f9b\u4e86\u65b0\u7684\u529f\u80fd\u5982\u8d1d\u53f6\u65af\u5206\u7c7b\u5e26\u62d2\u7edd\u3001\u524dK\u9009\u62e9\u53ca\u6709\u6548\u6392\u540d\u7b49\uff0c\u8fd9\u4e9b\u90fd\u5bf9\u836f\u7269\u53d1\u73b0\u9886\u57df\u6709\u7740\u91cd\u8981\u7684\u610f\u4e49\u3002"}}
{"id": "2512.24818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24818", "abs": "https://arxiv.org/abs/2512.24818", "authors": ["Shulun Chen", "Runlong Zhou", "Zihan Zhang", "Maryam Fazel", "Simon S. Du"], "title": "Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback", "comment": "28 pages", "summary": "Aligning large language models (LLMs) with human preferences has proven effective for enhancing model capabilities, yet standard preference modeling using the Bradley-Terry model assumes transitivity, overlooking the inherent complexity of human population preferences. Nash learning from human feedback (NLHF) addresses this by framing non-transitive preferences as a two-player zero-sum game, where alignment reduces to finding the Nash equilibrium (NE). However, existing algorithms typically rely on regularization, incurring unavoidable bias when computing the duality gap in the original game. In this work, we provide the first convergence guarantee for Optimistic Multiplicative Weights Update ($\\mathtt{OMWU}$) in NLHF, showing that it achieves last-iterate linear convergence after a burn-in phase whenever an NE with full support exists, with an instance-dependent linear convergence rate to the original NE, measured by duality gaps. Compared to prior results in Wei et al. (2020), we do not require the assumption of NE uniqueness. Our analysis identifies a novel marginal convergence behavior, where the probability of rarely played actions grows exponentially from exponentially small values, enabling exponentially better dependence on instance-dependent constants than prior results. Experiments corroborate the theoretical strengths of $\\mathtt{OMWU}$ in both tabular and neural policy classes, demonstrating its potential for LLM applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528\u4e50\u89c2\u4e58\u6027\u6743\u91cd\u66f4\u65b0\uff08OMWU\uff09\u7b97\u6cd5\u5728\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u7eb3\u4ec0\u5b66\u4e60\uff08NLHF\uff09\u65f6\u7684\u9996\u4e2a\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u5b58\u5728\u5168\u652f\u6301\u7eb3\u4ec0\u5747\u8861\u7684\u60c5\u51b5\u4e0b\u80fd\u5b9e\u73b0\u7ebf\u6027\u6536\u655b\uff0c\u5e76\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u7eb3\u4ec0\u5747\u8861\u552f\u4e00\u6027\u7684\u5047\u8bbe\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86OMWU\u5728\u8868\u683c\u578b\u548c\u795e\u7ecf\u7b56\u7565\u7c7b\u4e2d\u7684\u7406\u8bba\u4f18\u52bf\u3002", "motivation": "\u6807\u51c6\u7684\u504f\u597d\u5efa\u6a21\u91c7\u7528Bradley-Terry\u6a21\u578b\uff0c\u4f46\u8be5\u6a21\u578b\u5047\u8bbe\u4e86\u4f20\u9012\u6027\uff0c\u5ffd\u89c6\u4e86\u4eba\u7fa4\u504f\u597d\u5185\u5728\u7684\u590d\u6742\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u901a\u8fc7\u5c06\u975e\u4f20\u9012\u6027\u504f\u597d\u89c6\u4e3a\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u6765\u5904\u7406\u7684\u7eb3\u4ec0\u5b66\u4e60\u6cd5\uff08NLHF\uff09\uff0c\u4f46\u662f\u73b0\u6709\u7684\u7b97\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u6b63\u5219\u5316\uff0c\u5728\u8ba1\u7b97\u539f\u535a\u5f08\u4e2d\u7684\u5bf9\u5076\u95f4\u9699\u65f6\u4f1a\u4ea7\u751f\u4e0d\u53ef\u907f\u514d\u7684\u504f\u5dee\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e50\u89c2\u4e58\u6027\u6743\u91cd\u66f4\u65b0($\\mathtt{OMWU}$)\u7b97\u6cd5\u7528\u4e8eNLHF\uff0c\u5e76\u63d0\u4f9b\u4e86\u5176\u5728\u5b58\u5728\u5168\u652f\u6301\u7eb3\u4ec0\u5747\u8861\u60c5\u51b5\u4e0b\u80fd\u591f\u5b9e\u73b0\u6700\u540e\u4e00\u6b21\u8fed\u4ee3\u7ebf\u6027\u6536\u655b\u7684\u9996\u4efd\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u8fb9\u9645\u6536\u655b\u884c\u4e3a\uff0c\u5373\u5f88\u5c11\u88ab\u9009\u62e9\u7684\u52a8\u4f5c\u7684\u6982\u7387\u4f1a\u4ee5\u6307\u6570\u65b9\u5f0f\u589e\u957f\uff0c\u8fd9\u4f7f\u5f97\u4e0e\u5148\u524d\u7ed3\u679c\u76f8\u6bd4\uff0c\u5bf9\u5b9e\u4f8b\u76f8\u5173\u5e38\u6570\u6709\u66f4\u597d\u7684\u4f9d\u8d56\u6027\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86$\\mathtt{OMWU}$\u5728\u8868\u683c\u578b\u548c\u795e\u7ecf\u7b56\u7565\u7c7b\u4e2d\u7684\u7406\u8bba\u4f18\u52bf\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u4e50\u89c2\u4e58\u6027\u6743\u91cd\u66f4\u65b0\u7b97\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u8981\u7eb3\u4ec0\u5747\u8861\u552f\u4e00\u6027\u5047\u8bbe\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u5b66\u4e60\u7eb3\u4ec0\u5747\u8861\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u5177\u6709\u5f88\u597d\u7684\u524d\u666f\u3002"}}
{"id": "2512.24827", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24827", "abs": "https://arxiv.org/abs/2512.24827", "authors": ["Raul D. Steleac", "Mohan Sridharan", "David Abel"], "title": "Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics", "comment": null, "summary": "Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \\textit{Fermat} state, and use it to define a measure of \\textit{spreadness}, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u667a\u80fd\u4f53\u9009\u9879\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u72b6\u6001\u62bd\u8c61\u538b\u7f29\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u4fdd\u6301\u53d1\u73b0\u5f3a\u534f\u8c03\u884c\u4e3a\u6240\u9700\u7684\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u4e00\u79cd\u5f52\u7eb3\u504f\u7f6e\uff0c\u5373\u5728\u6ca1\u6709\u660e\u786e\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u72b6\u6001\u4e4b\u95f4\u7684\u540c\u6b65\u4e3a\u534f\u8c03\u63d0\u4f9b\u4e86\u81ea\u7136\u57fa\u7840\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u968f\u7740\u667a\u80fd\u4f53\u6570\u91cf\u589e\u52a0\uff0c\u8054\u5408\u72b6\u6001\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f\uff0c\u8fd9\u4f7f\u5f97\u534f\u8c03\u884c\u4e3a\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u589e\u957f\u4e5f\u7ed9\u591a\u667a\u80fd\u4f53\u9009\u9879\u7684\u8bbe\u8ba1\u5e26\u6765\u4e86\u6311\u6218\u3002\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u9009\u9879\u53d1\u73b0\u65b9\u6cd5\u5f80\u5f80\u727a\u7272\u4e86\u534f\u8c03\u6027\uff0c\u4ea7\u751f\u677e\u6563\u8026\u5408\u6216\u5b8c\u5168\u72ec\u7acb\u7684\u884c\u4e3a\u3002", "method": "1. \u63d0\u51fa\u4e00\u4e2a\u8054\u5408\u72b6\u6001\u62bd\u8c61\u65b9\u6cd5\u6765\u538b\u7f29\u72b6\u6001\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u7559\u53d1\u73b0\u5f3a\u534f\u8c03\u884c\u4e3a\u6240\u9700\u7684\u4fe1\u606f\u3002\n2. \u901a\u8fc7\u8fd1\u4f3c\u4e00\u4e2a\u4e0e\u56e2\u961f\u6700\u5927\u5bf9\u9f50\u7684\u865a\u6784\u72b6\u6001\uff08Fermat\u72b6\u6001\uff09\uff0c\u5e76\u4f7f\u7528\u5b83\u5b9a\u4e49\u4e00\u4e2a\u8861\u91cf\u201c\u5206\u6563\u5ea6\u201d\u7684\u6307\u6807\uff0c\u6355\u6349\u56e2\u961f\u5c42\u9762\u5728\u6bcf\u4e2a\u5355\u72ec\u72b6\u6001\u7ef4\u5ea6\u4e0a\u7684\u4e0d\u4e00\u81f4\u3002\n3. \u57fa\u4e8e\u4e0a\u8ff0\u8868\u793a\uff0c\u91c7\u7528\u795e\u7ecf\u56fe\u62c9\u666e\u62c9\u65af\u4f30\u8ba1\u5668\u5bfc\u51fa\u80fd\u591f\u6355\u6349\u667a\u80fd\u4f53\u4e4b\u95f4\u72b6\u6001\u540c\u6b65\u6a21\u5f0f\u7684\u9009\u9879\u3002", "result": "\u5728\u4e24\u4e2a\u591a\u667a\u80fd\u4f53\u9886\u57df\u4e2d\u7684\u591a\u4e2a\u573a\u666f\u4e0b\u8bc4\u4f30\u4e86\u6240\u5f97\u5230\u7684\u9009\u9879\uff0c\u7ed3\u679c\u663e\u793a\u4e0e\u66ff\u4ee3\u9009\u9879\u53d1\u73b0\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b83\u4eec\u4ea7\u751f\u4e86\u66f4\u5f3a\u7684\u4e0b\u6e38\u534f\u8c03\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u4ecb\u7ecd\u7684\u65b9\u6cd5\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u53d1\u73b0\u4fc3\u8fdb\u5f3a\u534f\u8c03\u884c\u4e3a\u7684\u9009\u9879\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u662f\u5f53\u9762\u4e34\u56e0\u667a\u80fd\u4f53\u6570\u76ee\u589e\u52a0\u800c\u5bfc\u81f4\u7684\u72b6\u6001\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\u65f6\u3002"}}
{"id": "2512.24847", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.24847", "abs": "https://arxiv.org/abs/2512.24847", "authors": ["Linhao Fan", "Hongqiang Fang", "Jingyang Dai", "Yong Jiang", "Qixing Zhang"], "title": "AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference", "comment": "17 pages, 9 figures", "summary": "High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u8d1d\u53f6\u65af\u63a8\u7406\u7684\u6982\u7387\u91cd\u6784\u6846\u67b6AODDiff\uff0c\u7528\u4e8e\u6c14\u6eb6\u80f6\u5149\u5b66\u539a\u5ea6\uff08AOD\uff09\u573a\u7684\u9ad8\u8d28\u91cf\u91cd\u5efa\u3002\u901a\u8fc7\u4ece\u81ea\u7136\u4e0d\u5b8c\u6574\u6570\u636e\u4e2d\u5b66\u4e60\u65f6\u7a7aAOD\u5148\u9a8c\uff0c\u5e76\u91c7\u7528\u89e3\u8026\u9000\u706b\u540e\u9a8c\u91c7\u6837\u7b56\u7565\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u540c\u7684\u91cd\u5efa\u4efb\u52a1\u4e4b\u95f4\u7075\u6d3b\u9002\u5e94\uff0c\u540c\u65f6\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAODDiff\u5728\u964d\u5c3a\u5ea6\u548c\u56fe\u50cf\u4fee\u590d\u4efb\u52a1\u4e0a\u5177\u6709\u9ad8\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u4fdd\u6301\u9ad8\u7a7a\u95f4\u5149\u8c31\u4fdd\u771f\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u53d7\u9650\u4e8e\u5b8c\u6574\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u7f3a\u6027\u548c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e86AOD\u573a\u91cd\u5efa\u7684\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86AODDiff\u6846\u67b6\uff0c\u5b83\u57fa\u4e8e\u6269\u6563\u8d1d\u53f6\u65af\u63a8\u7406\uff0c\u5229\u7528\u4ece\u81ea\u7136\u4e0d\u5b8c\u6574\u6570\u636e\u4e2d\u5b66\u5230\u7684\u65f6\u7a7aAOD\u6982\u7387\u5206\u5e03\u4f5c\u4e3a\u751f\u6210\u5148\u9a8c\u3002\u91c7\u7528\u4e86\u8003\u8651\u6570\u636e\u635f\u574f\u60c5\u51b5\u4e0b\u7684\u8bad\u7ec3\u7b56\u7565\u53ca\u89e3\u8026\u9000\u706b\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u6574\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u89c2\u6d4b\u4f5c\u4e3a\u7ea6\u675f\u6761\u4ef6\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u518d\u5206\u6790\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u964d\u5c3a\u5ea6\u4e0e\u56fe\u50cf\u4fee\u590d\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u4fdd\u6301\u9ad8\u7a7a\u95f4\u5149\u8c31\u4fdd\u771f\u5ea6\u65b9\u9762\u3002\u6b64\u5916\uff0c\u4f5c\u4e3a\u751f\u6210\u6a21\u578b\uff0cAODDiff\u80fd\u591f\u901a\u8fc7\u591a\u91cd\u91c7\u6837\u81ea\u7136\u5730\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e3a\u4e0b\u6e38\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7f6e\u4fe1\u5ea6\u6307\u6807\u3002", "conclusion": "AODDiff\u6846\u67b6\u5c55\u793a\u4e86\u5728\u591a\u79cd\u91cd\u5efa\u4efb\u52a1\u4e2d\u7684\u7075\u6d3b\u6027\u4ee5\u53ca\u5bf9\u5f02\u6784\u89c2\u6d4b\u6570\u636e\u7684\u6709\u6548\u6574\u5408\u80fd\u529b\uff0c\u540c\u65f6\u5176\u5185\u5728\u652f\u6301\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u7279\u70b9\u4f7f\u5176\u6210\u4e3a\u5927\u6c14\u76d1\u6d4b\u9886\u57df\u7684\u4e00\u9879\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2512.24866", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24866", "abs": "https://arxiv.org/abs/2512.24866", "authors": ["Andr\u00e1s Millinghoffer", "Bence Bolg\u00e1r", "P\u00e9ter Antal"], "title": "Characterization of Transfer Using Multi-task Learning Curves", "comment": null, "summary": "Transfer effects manifest themselves both during training using a fixed data set and in inductive inference using accumulating data. We hypothesize that perturbing the data set by including more samples, instead of perturbing the model by gradient updates, provides a complementary and more fundamental characterization of transfer effects. To capture this phenomenon, we quantitatively model transfer effects using multi-task learning curves approximating the inductive performance over varying sample sizes. We describe an efficient method to approximate multi-task learning curves analogous to the Task Affinity Grouping method applied during training. We compare the statistical and computational approaches to transfer, which indicates considerably higher compute costs for the previous but better power and broader applicability. Evaluations are performed using a benchmark drug-target interaction data set. Our results show that learning curves can better capture the effects of multi-task learning and their multi-task extensions can delineate pairwise and contextual transfer effects in foundation models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u591a\u4efb\u52a1\u5b66\u4e60\u66f2\u7ebf\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u8fc1\u79fb\u6548\u5e94\uff0c\u5e76\u901a\u8fc7\u836f\u7269-\u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\uff0c\u901a\u8fc7\u589e\u52a0\u6837\u672c\u91cf\u6765\u6270\u52a8\u6570\u636e\u96c6\uff0c\u800c\u975e\u901a\u8fc7\u68af\u5ea6\u66f4\u65b0\u6765\u6270\u52a8\u6a21\u578b\uff0c\u4e3a\u8fc1\u79fb\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u52a0\u57fa\u7840\u548c\u4e92\u8865\u7684\u8868\u5f81\u65b9\u5f0f\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8fd1\u4f3c\u591a\u4efb\u52a1\u5b66\u4e60\u66f2\u7ebf\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u7684\u4efb\u52a1\u4eb2\u548c\u5ea6\u5206\u7ec4\u65b9\u6cd5\u3002\u4ed6\u4eec\u8fd8\u6bd4\u8f83\u4e86\u7edf\u8ba1\u5b66\u4e0e\u8ba1\u7b97\u65b9\u6cd5\u5728\u5904\u7406\u8fc1\u79fb\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u5b66\u4e60\u66f2\u7ebf\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u6355\u83b7\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u5176\u6269\u5c55\u7248\u672c\u80fd\u591f\u533a\u5206\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u6210\u5bf9\u53ca\u4e0a\u4e0b\u6587\u8fc1\u79fb\u6548\u5e94\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u5b66\u4e60\u66f2\u7ebf\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8fc1\u79fb\u5b66\u4e60\u7814\u7a76\u7684\u80fd\u529b\uff0c\u4e5f\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u8bc6\u522b\u7279\u5b9a\u7c7b\u578b\u8fc1\u79fb\u6548\u5e94\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2512.24917", "categories": ["cs.LG", "math.AT"], "pdf": "https://arxiv.org/pdf/2512.24917", "abs": "https://arxiv.org/abs/2512.24917", "authors": ["Xinyang Chen", "Ama\u00ebl Broustet", "Guoting Chen"], "title": "Frequent subgraph-based persistent homology for graph classification", "comment": "Preprint. 18 pages, 10 figures", "summary": "Persistent homology (PH) has recently emerged as a powerful tool for extracting topological features. Integrating PH into machine learning and deep learning models enhances topology awareness and interpretability. However, most PH methods on graphs rely on a limited set of filtrations, such as degree-based or weight-based filtrations, which overlook richer features like recurring information across the dataset and thus restrict expressive power. In this work, we propose a novel graph filtration called Frequent Subgraph Filtration (FSF), which is derived from frequent subgraphs and produces stable and information-rich frequency-based persistent homology (FPH) features. We study the theoretical properties of FSF and provide both proofs and experimental validation. Beyond persistent homology itself, we introduce two approaches for graph classification: an FPH-based machine learning model (FPH-ML) and a hybrid framework that integrates FPH with graph neural networks (FPH-GNNs) to enhance topology-aware graph representation learning. Our frameworks bridge frequent subgraph mining and topological data analysis, offering a new perspective on topology-aware feature extraction. Experimental results show that FPH-ML achieves competitive or superior accuracy compared with kernel-based and degree-based filtration methods. When integrated into graph neural networks, FPH yields relative performance gains ranging from 0.4 to 21 percent, with improvements of up to 8.2 percentage points over GCN and GIN backbones across benchmarks.", "AI": {"tldr": "This paper introduces Frequent Subgraph Filtration (FSF), a new graph filtration method, to generate more informative and stable persistent homology (PH) features for graph classification. The authors also propose FPH-ML and FPH-GNNs models that integrate these features into machine learning and deep learning, respectively, showing significant improvements in performance over existing methods.", "motivation": "The motivation of this paper is to address the limitations of current PH methods on graphs, which often rely on simple filtrations like degree or weight, thereby missing out on richer topological information. By introducing FSF, the authors aim to capture more complex and recurring patterns across datasets, enhancing the expressive power and interpretability of PH-based models.", "method": "The authors propose Frequent Subgraph Filtration (FSF) as a novel approach to generate frequency-based persistent homology (FPH) features. They analyze the theoretical properties of FSF and validate it through experiments. Additionally, they develop two models for graph classification: FPH-ML, which uses traditional machine learning techniques, and FPH-GNN, a hybrid model that integrates FPH with graph neural networks (GNNs).", "result": "The experimental results demonstrate that the FPH-ML model achieves competitive or better accuracy compared to kernel-based and degree-based filtration methods. Furthermore, when FPH is integrated into GNNs, the FPH-GNN model shows relative performance gains ranging from 0.4% to 21%, with up to 8.2 percentage points improvement over GCN and GIN backbones across different benchmarks.", "conclusion": "The conclusion of this work highlights the effectiveness of Frequent Subgraph Filtration (FSF) in generating stable and informative persistent homology (PH) features for graph classification. The integration of FPH into both traditional machine learning and deep learning models significantly enhances their performance, suggesting a promising direction for future research in topology-aware feature extraction and graph representation learning."}}
{"id": "2512.24955", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24955", "abs": "https://arxiv.org/abs/2512.24955", "authors": ["Yongwei Zhang", "Yuanzhe Xing", "Quan Quan", "Zhikun She"], "title": "MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control", "comment": null, "summary": "Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions. By introducing Exponential Stability Labels (ESL) and a $\u03bb$-weighted aggregation mechanism, the framework effectively balances the bias-variance trade-off in multi-step learning. Policy optimization is guided by a stability-aware advantage function, ensuring the learned policy promotes rapid Lyapunov descent. We evaluate MSACL across six benchmarks, including stabilization and nonlinear tracking tasks, demonstrating its superiority over state-of-the-art Lyapunov-based RL algorithms. MSACL achieves exponential stability and rapid convergence under simple rewards, while exhibiting significant robustness to uncertainties and generalization to unseen trajectories. Sensitivity analysis establishes the multi-step horizon $n=20$ as a robust default across diverse systems. By linking Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a foundation for verifiably safe learning-based control. Source code and benchmark environments will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMSACL\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u6307\u6570\u7a33\u5b9a\u6027\u7406\u8bba\u4e0e\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u6b65\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\u5b66\u4e60\u6765\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u8bc1\u660e\u7a33\u5b9a\u6027\u3002MSACL\u5229\u7528\u975e\u7b56\u7565\u591a\u6b65\u6570\u636e\u5b66\u4e60\u6ee1\u8db3\u7406\u8bba\u7a33\u5b9a\u6027\u6761\u4ef6\u7684\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u6307\u6570\u7a33\u5b9a\u6027\u6807\u7b7e(ESL)\u548c$\u03bb$-\u52a0\u6743\u805a\u5408\u673a\u5236\u6765\u5e73\u8861\u591a\u6b65\u5b66\u4e60\u4e2d\u7684\u504f\u5dee-\u65b9\u5dee\u6298\u8877\u3002\u5b9e\u9a8c\u8868\u660eMSACL\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5f53\u524d\u57fa\u4e8e\u674e\u96c5\u666e\u8bfa\u592b\u7684RL\u7b97\u6cd5\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u7b80\u5355\u5956\u52b1\u4e0b\u7684\u6307\u6570\u7a33\u5b9a\u6027\u548c\u5feb\u901f\u6536\u655b\u6027\u4ee5\u53ca\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5728\u6a21\u578b\u65e0\u5173\u7684\u5f3a\u5316\u5b66\u4e60(RL)\u4e2d\u5b9e\u73b0\u53ef\u8bc1\u660e\u7684\u7a33\u5b9a\u6027\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u63a2\u7d22\u4e0e\u4e25\u683c\u5b89\u5168\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u65f6\u3002\u4f20\u7edf\u7684\u505a\u6cd5\u4f9d\u8d56\u4e8e\u590d\u6742\u7684\u5956\u52b1\u5de5\u7a0b\u8bbe\u8ba1\uff0c\u800c\u7f3a\u4e4f\u4e00\u79cd\u80fd\u591f\u786e\u4fdd\u7cfb\u7edf\u7a33\u5b9a\u540c\u65f6\u4fc3\u8fdb\u9ad8\u6548\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86MSACL\u6846\u67b6\uff0c\u5b83\u5c06\u6307\u6570\u7a33\u5b9a\u6027\u7406\u8bba\u4e0e\u6700\u5927\u71b5RL\u76f8\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u591a\u6b65\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\u5b66\u4e60\u6765\u8fbe\u6210\u8fd9\u4e00\u76ee\u6807\u3002\u6b64\u65b9\u6cd5\u5229\u7528\u4e86\u975e\u7b56\u7565\u591a\u6b65\u6570\u636e\u6765\u5b66\u4e60\u7b26\u5408\u7406\u8bba\u7a33\u5b9a\u6027\u8981\u6c42\u7684\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u6307\u6570\u7a33\u5b9a\u6027\u6807\u7b7e(ESL)\u548c$\u03bb$-\u52a0\u6743\u805a\u5408\u673a\u5236\u4ee5\u6709\u6548\u5904\u7406\u591a\u6b65\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u504f\u5dee-\u65b9\u5dee\u95ee\u9898\u3002", "result": "MSACL\u5728\u5305\u62ec\u7a33\u5b9a\u5316\u548c\u975e\u7ebf\u6027\u8ddf\u8e2a\u4efb\u52a1\u5728\u5185\u7684\u516d\u4e2a\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u6700\u65b0\u7684\u57fa\u4e8e\u674e\u96c5\u666e\u8bfa\u592b\u7684RL\u7b97\u6cd5\u3002MSACL\u80fd\u591f\u5728\u4f7f\u7528\u7b80\u5355\u7684\u5956\u52b1\u51fd\u6570\u60c5\u51b5\u4e0b\u8fbe\u5230\u6307\u6570\u7ea7\u7a33\u5b9a\u6027\u5e76\u5feb\u901f\u6536\u655b\uff0c\u540c\u65f6\u4e5f\u663e\u793a\u51fa\u4e86\u5bf9\u4e0d\u786e\u5b9a\u6027\u6781\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u5bf9\u4e8e\u672a\u89c1\u8fc7\u8f68\u8ff9\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u674e\u96c5\u666e\u8bfa\u592b\u7406\u8bba\u4e0e\u975e\u7b56\u7565\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6846\u67b6\u8054\u7cfb\u8d77\u6765\uff0cMSACL\u4e3a\u57fa\u4e8e\u5b66\u4e60\u7684\u5b89\u5168\u63a7\u5236\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u57fa\u7840\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u591a\u6b65\u8303\u56f4$n=20$\u662f\u8de8\u4e0d\u540c\u7cfb\u7edf\u7684\u7a33\u5065\u9ed8\u8ba4\u503c\u3002"}}
{"id": "2512.24975", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24975", "abs": "https://arxiv.org/abs/2512.24975", "authors": ["Cristina P. Martin-Linares", "Jonathan P. Ling"], "title": "Attribution-Guided Distillation of Matryoshka Sparse Autoencoders", "comment": null, "summary": "Sparse autoencoders (SAEs) aim to disentangle model activations into monosemantic, human-interpretable features. In practice, learned features are often redundant and vary across training runs and sparsity levels, which makes interpretations difficult to transfer and reuse. We introduce Distilled Matryoshka Sparse Autoencoders (DMSAEs), a training pipeline that distills a compact core of consistently useful features and reuses it to train new SAEs. DMSAEs run an iterative distillation cycle: train a Matryoshka SAE with a shared core, use gradient X activation to measure each feature's contribution to next-token loss in the most nested reconstruction, and keep only the smallest subset that explains a fixed fraction of the attribution. Only the core encoder weight vectors are transferred across cycles; the core decoder and all non-core latents are reinitialized each time. On Gemma-2-2B layer 12 residual stream activations, seven cycles of distillation (500M tokens, 65k width) yielded a distilled core of 197 features that were repeatedly selected. Training using this distilled core improves several SAEBench metrics and demonstrates that consistent sets of latent features can be transferred across sparsity levels", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDMSAEs\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u63d0\u70bc\u8fc7\u7a0b\u6765\u63d0\u53d6\u5e76\u91cd\u7528\u4e00\u7ec4\u4e00\u81f4\u6709\u7528\u7684\u7279\u5f81\uff0c\u4ece\u800c\u63d0\u9ad8\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668(SAE)\u7684\u5b66\u4e60\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8SAE\u7684\u4e00\u4e9b\u6027\u80fd\u6307\u6807\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u4e0d\u540c\u7a00\u758f\u5ea6\u7ea7\u522b\u4e4b\u95f4\u8f6c\u79fb\u4e00\u7ec4\u4e00\u81f4\u7684\u6f5c\u5728\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u5b66\u4e60\u5230\u7684\u7279\u5f81\u5f80\u5f80\u5b58\u5728\u5197\u4f59\u6027\uff0c\u4e14\u5728\u4e0d\u540c\u7684\u8bad\u7ec3\u8fd0\u884c\u548c\u7a00\u758f\u5ea6\u6c34\u5e73\u4e0b\u53d8\u5316\u8f83\u5927\uff0c\u8fd9\u5bfc\u81f4\u4e86\u7279\u5f81\u96be\u4ee5\u88ab\u89e3\u8bfb\u3001\u8f6c\u79fb\u53ca\u91cd\u7528\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u5f15\u5165\u4e86Distilled Matryoshka Sparse Autoencoders (DMSAEs)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u65e8\u5728\u63d0\u70bc\u51fa\u4e00\u7ec4\u7d27\u51d1\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u5e76\u80fd\u591f\u91cd\u590d\u5229\u7528\u8fd9\u4e9b\u6838\u5fc3\u7279\u5f81\u6765\u8bad\u7ec3\u65b0\u7684SAE\u6a21\u578b\u3002DMSAEs\u91c7\u7528\u8fed\u4ee3\u5f0f\u7684\u63d0\u70bc\u5faa\u73af\uff1a\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u5177\u6709\u5171\u4eab\u6838\u5fc3\u7684Matryoshka SAE\uff0c\u7136\u540e\u5229\u7528\u68af\u5ea6\u4e58\u4ee5\u6fc0\u6d3b\u503c\u7684\u65b9\u6cd5\u8861\u91cf\u6bcf\u4e2a\u7279\u5f81\u5bf9\u4e8e\u6700\u5185\u5c42\u91cd\u6784\u4e2d\u4e0b\u4e00\u4e2atoken\u635f\u5931\u7684\u8d21\u732e\uff0c\u5e76\u4ec5\u4fdd\u7559\u80fd\u89e3\u91ca\u56fa\u5b9a\u6bd4\u4f8b\u5f52\u56e0\u7684\u6700\u5c0f\u7279\u5f81\u5b50\u96c6\u3002\u5728\u6bcf\u6b21\u5faa\u73af\u4e2d\uff0c\u4ec5\u6709\u6838\u5fc3\u7f16\u7801\u5668\u6743\u91cd\u5411\u91cf\u88ab\u4f20\u9012\uff1b\u800c\u6838\u5fc3\u89e3\u7801\u5668\u53ca\u6240\u6709\u975e\u6838\u5fc3\u6f5c\u53d8\u91cf\u5219\u6bcf\u6b21\u90fd\u91cd\u65b0\u521d\u59cb\u5316\u3002", "result": "\u901a\u8fc7\u5bf9Gemma-2-2B\u7b2c12\u5c42\u6b8b\u5dee\u6d41\u6fc0\u6d3b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5728\u7ecf\u8fc77\u8f6e\u63d0\u70bc\uff08\u5904\u74065\u4ebf\u4e2atokens\uff0c\u5bbd\u5ea6\u4e3a65,000\uff09\u540e\uff0c\u5f97\u5230\u4e86\u4e00\u4e2a\u7531197\u4e2a\u7279\u5f81\u7ec4\u6210\u7684\u7cbe\u70bc\u6838\u5fc3\uff0c\u8fd9\u4e9b\u7279\u5f81\u5728\u591a\u6b21\u9009\u62e9\u8fc7\u7a0b\u4e2d\u88ab\u53cd\u590d\u6311\u9009\u51fa\u6765\u3002\u4f7f\u7528\u8fd9\u4e2a\u7cbe\u70bc\u6838\u5fc3\u8fdb\u884c\u8bad\u7ec3\u63d0\u9ad8\u4e86\u591a\u4e2aSAEBench\u8bc4\u4ef7\u6307\u6807\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u53ef\u4ee5\u8de8\u4e0d\u540c\u7a00\u758f\u5ea6\u7ea7\u522b\u8fc1\u79fb\u4e00\u7ec4\u4e00\u81f4\u6027\u7684\u6f5c\u5728\u7279\u5f81\u3002", "conclusion": "DMSAEs\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u5b66\u4e60\u7279\u5f81\u7684\u4e00\u81f4\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4e0d\u540c\u7a00\u758f\u5ea6\u8bbe\u7f6e\u95f4\u6210\u529f\u5730\u8f6c\u79fb\u4e00\u7ec4\u6709\u7528\u4e14\u7a33\u5b9a\u7684\u6f5c\u5728\u7279\u5f81\u3002"}}
{"id": "2512.24991", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24991", "abs": "https://arxiv.org/abs/2512.24991", "authors": ["Gyung Hyun Je", "Colin Raffel"], "title": "Efficiently Estimating Data Efficiency for Language Model Fine-tuning", "comment": null, "summary": "While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u7684\u68af\u5ea6\u4f59\u5f26\u76f8\u4f3c\u6027\u65b9\u6cd5\u6765\u9884\u6d4b\u4efb\u52a1\u7684\u6570\u636e\u6548\u7387\uff0c\u4ece\u800c\u907f\u514d\u4e86\u589e\u91cf\u6ce8\u91ca\u548c\u91cd\u65b0\u8bad\u7ec3\u7684\u6210\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6b64\u65b9\u6cd5\u5728\u591a\u79cd\u4e0d\u540c\u6570\u636e\u6548\u7387\u7684\u4efb\u52a1\u4e0a\u80fd\u591f\u8fbe\u52308.6%\u7684\u6574\u4f53\u6570\u636e\u6548\u7387\u9884\u6d4b\u8bef\u5dee\uff0c\u5e76\u4e14\u901a\u5e38\u80fd\u5728\u6bcf\u4e2a\u4efb\u52a1\u4e0a\u51cf\u5c11\u6570\u767e\u4e2a\u4e0d\u5fc5\u8981\u7684\u6ce8\u91ca\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5408\u7406\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u5fae\u8c03\u662f\u63d0\u9ad8\u5176\u6027\u80fd\u7684\u4e00\u79cd\u5e38\u89c1\u505a\u6cd5\u3002\u7136\u800c\uff0c\u4e00\u4e2a\u4efb\u52a1\u7684\u6570\u636e\u6548\u7387\u2014\u2014\u5373\u8fbe\u5230\u6240\u9700\u6027\u80fd\u6c34\u5e73\u6240\u9700\u7684\u5fae\u8c03\u6837\u672c\u6570\u91cf\u2014\u2014\u5f80\u5f80\u662f\u672a\u77e5\u7684\uff0c\u8fd9\u5bfc\u81f4\u4e86\u4ee3\u4ef7\u9ad8\u6602\u7684\u589e\u91cf\u6ce8\u91ca\u4e0e\u91cd\u65b0\u8bad\u7ec3\u5faa\u73af\u3002\u7814\u7a76\u8005\u4eec\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u7684\u9ad8\u6027\u80fdLLMs\uff0c\u901a\u8fc7\u5fae\u8c03\u540e\u4e5f\u80fd\u83b7\u5f97\u66f4\u5f3a\u7684\u6027\u80fd\u3002\u8fd9\u4fc3\u4f7f\u4e86\u5bfb\u627e\u65e0\u9700\u589e\u91cf\u6ce8\u91ca\u5373\u53ef\u9884\u6d4b\u4efb\u52a1\u6570\u636e\u6548\u7387\u7684\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "method": "\u9996\u5148\u5b9a\u4e49\u4e86\u4e00\u4e2a\u5177\u4f53\u5ea6\u91cf\u6765\u91cf\u5316\u4efb\u52a1\u7684\u6570\u636e\u6548\u7387\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528\u4f4e\u7f6e\u4fe1\u5ea6\u4f8b\u5b50\u7684\u68af\u5ea6\u4f59\u5f26\u76f8\u4f3c\u6027\u6765\u57fa\u4e8e\u5c11\u91cf\u6807\u8bb0\u6837\u672c\u9884\u6d4b\u6570\u636e\u6548\u7387\u7684\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e00\u4e2a\u5305\u542b\u4e0d\u540c\u6570\u636e\u6548\u7387\u7684\u591a\u6837\u5316\u4efb\u52a1\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8fbe\u5230\u4e868.6%\u7684\u6570\u636e\u6548\u7387\u9884\u6d4b\u603b\u4f53\u8bef\u5dee\uff0c\u5e76\u4e14\u901a\u5e38\u80fd\u6d88\u9664\u6bcf\u4e2a\u4efb\u52a1\u4e0a\u7684\u6570\u767e\u6b21\u4e0d\u5fc5\u8981\u7684\u6ce8\u91ca\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u9884\u6d4b\u4efb\u52a1\u7684\u6570\u636e\u6548\u7387\u800c\u4e0d\u9700\u8981\u8fdb\u884c\u989d\u5916\u7684\u5927\u91cf\u6ce8\u91ca\u5de5\u4f5c\uff0c\u8fd9\u6709\u52a9\u4e8e\u51cf\u5c11\u76f8\u5173\u6210\u672c\u5e76\u52a0\u901f\u6a21\u578b\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2512.25014", "categories": ["cs.LG", "cs.CC"], "pdf": "https://arxiv.org/pdf/2512.25014", "abs": "https://arxiv.org/abs/2512.25014", "authors": ["Haozhe Jiang", "Nika Haghtalab", "Lijie Chen"], "title": "Diffusion Language Models are Provably Optimal Parallel Samplers", "comment": null, "summary": "Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.", "AI": {"tldr": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u901a\u8fc7\u5e76\u884c\u751f\u6210\u6807\u8bb0\uff0c\u80fd\u591f\u4f5c\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u52a0\u901f\u63a8\u7406\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u5f53\u76ee\u6807\u5206\u5e03\u53ef\u4ee5\u901a\u8fc7\u5c11\u91cf\u987a\u5e8f\u6b65\u9aa4\u751f\u6210\u65f6\uff0cDLMs\u53ef\u4ee5\u5728\u76f8\u540c\u6570\u91cf\u7684\u6700\u4f73\u987a\u5e8f\u6b65\u9aa4\u5185\u751f\u6210\u8be5\u5206\u5e03\u3002\u6b64\u5916\uff0c\u5141\u8bb8\u4fee\u8ba2\u6216\u91cd\u65b0\u906e\u7f69\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u4e14\u5177\u6709\u8fd9\u4e9b\u529f\u80fd\u7684DLMs\u6bd4\u6ca1\u6709\u7684\u66f4\u52a0\u8868\u8fbe\u80fd\u529b\u5f3a\u3002", "motivation": "\u63a2\u8ba8\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u5728\u5e76\u884c\u751f\u6210\u6807\u8bb0\u65b9\u9762\u76f8\u5bf9\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u5141\u8bb8\u4fee\u8ba2\u6216\u91cd\u65b0\u906e\u7f69\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u6548\u7387\u4e0e\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u4e00\u4e2a\u5e76\u884c\u91c7\u6837\u7684\u6a21\u578b\u6765\u5206\u6790DLMs\u7ed3\u5408\u591a\u9879\u5f0f\u957f\u5ea6\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u6a21\u62df\u4efb\u4f55\u5e76\u884c\u91c7\u6837\u7b97\u6cd5\u7684\u80fd\u529b\uff0c\u5e76\u8003\u5bdf\u4fee\u8ba2\u548c\u91cd\u65b0\u906e\u7f69\u5bf9\u4e8e\u4f18\u5316\u7a7a\u95f4\u590d\u6742\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u76ee\u6807\u5206\u5e03\u53ef\u4ee5\u901a\u8fc7\u5c11\u91cf\u987a\u5e8f\u6b65\u9aa4\u751f\u6210\u65f6\uff0cDLMs\u80fd\u4ee5\u6700\u4f18\u987a\u5e8f\u6b65\u9aa4\u6570\u751f\u6210\uff1b\u5e76\u4e14\u542f\u7528\u4fee\u8ba2\u6216\u91cd\u65b0\u906e\u7f69\u53ef\u4ee5\u8ba9DLMs\u5728\u4fdd\u6301\u6700\u4f18\u7a7a\u95f4\u590d\u6742\u5ea6\u7684\u540c\u65f6\u6a21\u62df\u4efb\u4f55\u5e76\u884c\u91c7\u6837\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u8bc1\u5b9e\u4e86\u5177\u5907\u4fee\u8ba2\u6216\u91cd\u65b0\u906e\u7f69\u80fd\u529b\u7684DLMs\u5728\u8868\u8fbe\u529b\u4e0a\u4f18\u4e8e\u4e0d\u5177\u5907\u8fd9\u4e9b\u7279\u6027\u7684\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0cDLMs\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u88ab\u8bc1\u660e\u4e3a\u6700\u6709\u6548\u7684\u5e76\u884c\u91c7\u6837\u5668\uff0c\u800c\u4e14\u5efa\u8bae\u5728\u5b9e\u8df5\u4e2d\u542f\u7528\u4fee\u8ba2\u673a\u5236\u4ee5\u589e\u5f3a\u5176\u6027\u80fd\u3002"}}
{"id": "2512.25034", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.25034", "abs": "https://arxiv.org/abs/2512.25034", "authors": ["Alexander C. Li", "Ananya Kumar", "Deepak Pathak"], "title": "Generative Classifiers Avoid Shortcut Solutions", "comment": "ICLR 2025. Code: https://github.com/alexlioralexli/generative-classifiers", "summary": "Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.", "AI": {"tldr": "\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u901a\u8fc7\u5efa\u6a21\u6240\u6709\u7279\u5f81\u800c\u975e\u4ec5\u4f9d\u8d56\u4e8e\u865a\u5047\u76f8\u5173\u7279\u5f81\uff0c\u80fd\u591f\u5728\u5206\u5e03\u504f\u79fb\u7684\u60c5\u51b5\u4e0b\u907f\u514d\u5224\u522b\u5f0f\u65b9\u6cd5\u5e38\u89c1\u7684\u5931\u6548\u95ee\u9898\uff0c\u5e76\u5728\u56fe\u50cf\u548c\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5224\u522b\u5f0f\u5206\u7c7b\u65b9\u6cd5\u5f80\u5f80\u5b66\u4e60\u5230\u53ea\u5728\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5185\u6709\u6548\u7684\u6377\u5f84\uff0c\u8fd9\u4e9b\u6377\u5f84\u57fa\u4e8e\u4e0e\u6807\u7b7e\u865a\u5047\u76f8\u5173\u7684\u7279\u5f81\uff0c\u5728\u8f7b\u5fae\u7684\u5206\u5e03\u53d8\u5316\u4e0b\u5bb9\u6613\u5931\u8d25\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7c7b\u6761\u4ef6\u751f\u6210\u6a21\u578b\u7684\u751f\u6210\u5f0f\u5206\u7c7b\u5668\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5bf9\u6838\u5fc3\u7279\u5f81\u548c\u865a\u5047\u7279\u5f81\u90fd\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u4e0d\u9700\u8981\u7279\u6b8a\u7684\u589e\u5f3a\u3001\u5f3a\u6b63\u5219\u5316\u3001\u989d\u5916\u7684\u8d85\u53c2\u6570\u8c03\u6574\u6216\u4e8b\u5148\u77e5\u9053\u8981\u907f\u514d\u7684\u5177\u4f53\u865a\u5047\u76f8\u5173\u6027\u3002", "result": "\u6269\u6563\u5f0f\u548c\u81ea\u56de\u5f52\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u5728\u4e94\u4e2a\u6807\u51c6\u56fe\u50cf\u548c\u6587\u672c\u5206\u5e03\u504f\u79fb\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5b9e\u9645\u5e94\u7528\uff08\u5982\u533b\u7597\u6216\u536b\u661f\u6570\u636e\u96c6\uff09\u4e2d\u865a\u5047\u76f8\u5173\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u901a\u8fc7\u5904\u7406\u6240\u6709\u7c7b\u578b\u7684\u7279\u5f81\u6765\u51cf\u8f7b\u865a\u5047\u76f8\u5173\u6027\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5728\u9762\u5bf9\u5206\u5e03\u504f\u79fb\u65f6\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.25060", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.25060", "abs": "https://arxiv.org/abs/2512.25060", "authors": ["Gabriela Moisescu-Pareja", "Gavin McCracken", "Harley Wiltzer", "Vincent L\u00e9tourneau", "Colin Daniels", "Doina Precup", "Jonathan Love"], "title": "On the geometry and topology of representations: the manifolds of modular addition", "comment": null, "summary": "The Clock and Pizza interpretations, associated with architectures differing in either uniform or learnable attention, were introduced to argue that different architectural designs can yield distinct circuits for modular addition. In this work, we show that this is not the case, and that both uniform attention and trainable attention architectures implement the same algorithm via topologically and geometrically equivalent representations. Our methodology goes beyond the interpretation of individual neurons and weights. Instead, we identify all of the neurons corresponding to each learned representation and then study the collective group of neurons as one entity. This method reveals that each learned representation is a manifold that we can study utilizing tools from topology. Based on this insight, we can statistically analyze the learned representations across hundreds of circuits to demonstrate the similarity between learned modular addition circuits that arise naturally from common deep learning paradigms.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u8bba\u662f\u5747\u5300\u6ce8\u610f\u529b\u67b6\u6784\u8fd8\u662f\u53ef\u5b66\u4e60\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u5728\u5b9e\u73b0\u6a21\u5757\u52a0\u6cd5\u65f6\u90fd\u91c7\u7528\u4e86\u62d3\u6251\u548c\u51e0\u4f55\u4e0a\u7b49\u4ef7\u7684\u8868\u793a\u65b9\u6cd5\u3002\u901a\u8fc7\u5c06\u6bcf\u4e2a\u5b66\u4e60\u5230\u7684\u8868\u793a\u89c6\u4e3a\u4e00\u4e2a\u6574\u4f53\u6765\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u8868\u793a\u5f62\u6210\u4e86\u53ef\u4ee5\u5229\u7528\u62d3\u6251\u5de5\u5177\u8fdb\u884c\u5206\u6790\u7684\u6d41\u5f62\uff0c\u4ece\u800c\u8bc1\u660e\u4e86\u4ece\u5e38\u89c1\u6df1\u5ea6\u5b66\u4e60\u8303\u5f0f\u4e2d\u81ea\u7136\u4ea7\u751f\u7684\u5b66\u4e60\u6a21\u5757\u52a0\u6cd5\u7535\u8def\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4e0d\u540c\u7684\u67b6\u6784\u8bbe\u8ba1\uff08\u5373\u5747\u5300\u6ce8\u610f\u529b\u4e0e\u53ef\u8bad\u7ec3\u6ce8\u610f\u529b\uff09\u662f\u5426\u4f1a\u5bfc\u81f4\u5728\u6267\u884c\u6a21\u5757\u52a0\u6cd5\u4efb\u52a1\u65f6\u4ea7\u751f\u6839\u672c\u4e0d\u540c\u7684\u7535\u8def\u3002\u57fa\u4e8e\u5148\u524d\u63d0\u51fa\u7684Clock\u548cPizza\u89e3\u91ca\uff0c\u4f5c\u8005\u5e0c\u671b\u9a8c\u8bc1\u8fd9\u4e9b\u5047\u8bbe\uff0c\u5e76\u8fdb\u4e00\u6b65\u4e86\u89e3\u4e0d\u540c\u7c7b\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u5185\u90e8\u8868\u793a\u7684\u5b66\u4e60\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u8d85\u8d8a\u5355\u4e2a\u795e\u7ecf\u5143\u53ca\u5176\u6743\u91cd\u89e3\u8bfb\u7684\u65b9\u6cd5\u8bba\uff0c\u8be5\u65b9\u6cd5\u9996\u5148\u8bc6\u522b\u51fa\u5bf9\u5e94\u4e8e\u6bcf\u4e00\u4e2a\u5b66\u5230\u8868\u793a\u7684\u6240\u6709\u795e\u7ecf\u5143\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u795e\u7ecf\u5143\u7fa4\u4f53\u4f5c\u4e3a\u4e00\u4e2a\u6574\u4f53\u6765\u8fdb\u884c\u7814\u7a76\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u80fd\u591f\u5229\u7528\u62d3\u6251\u5b66\u4e2d\u7684\u5de5\u5177\u6765\u5206\u6790\u7531\u5927\u91cf\u795e\u7ecf\u5143\u7ec4\u6210\u7684\u6d41\u5f62\uff0c\u8fdb\u800c\u5bf9\u6570\u767e\u4e2a\u7535\u8def\u4e2d\u5b66\u4e60\u5230\u7684\u8868\u793a\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u65e0\u8bba\u662f\u5728\u5747\u5300\u6ce8\u610f\u529b\u8fd8\u662f\u53ef\u8bad\u7ec3\u6ce8\u610f\u529b\u67b6\u6784\u4e0b\uff0c\u6240\u5b66\u5230\u7684\u7528\u4e8e\u6267\u884c\u6a21\u5757\u52a0\u6cd5\u4efb\u52a1\u7684\u8868\u793a\u90fd\u662f\u62d3\u6251\u548c\u51e0\u4f55\u4e0a\u7b49\u4ef7\u7684\u3002\u8fd9\u8868\u660e\uff0c\u4e24\u79cd\u770b\u4f3c\u4e0d\u540c\u7684\u67b6\u6784\u5b9e\u9645\u4e0a\u5b9e\u73b0\u4e86\u76f8\u540c\u7684\u7b97\u6cd5\uff0c\u5e76\u4e14\u751f\u6210\u4e86\u975e\u5e38\u76f8\u4f3c\u7684\u5185\u90e8\u8868\u793a\u7ed3\u6784\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u6a21\u5757\u52a0\u6cd5\u8fd9\u6837\u7684\u4efb\u52a1\u800c\u8a00\uff0c\u5747\u5300\u6ce8\u610f\u529b\u4e0e\u53ef\u8bad\u7ec3\u6ce8\u610f\u529b\u67b6\u6784\u4e4b\u95f4\u5e76\u6ca1\u6709\u672c\u8d28\u4e0a\u7684\u533a\u522b\uff1b\u4e24\u8005\u90fd\u80fd\u591f\u4ee5\u6781\u5176\u76f8\u4f3c\u7684\u65b9\u5f0f\u5b9e\u73b0\u76f8\u540c\u7684\u529f\u80fd\u3002\u8fd9\u4e00\u53d1\u73b0\u6311\u6218\u4e86\u4e4b\u524d\u5173\u4e8e\u7279\u5b9a\u67b6\u6784\u9009\u62e9\u53ef\u80fd\u5e26\u6765\u5b8c\u5168\u4e0d\u540c\u7ed3\u679c\u7684\u89c2\u70b9\u3002"}}
{"id": "2512.25070", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.25070", "abs": "https://arxiv.org/abs/2512.25070", "authors": ["Nikhil Chandak", "Shashwat Goel", "Ameya Prabhu", "Moritz Hardt", "Jonas Geiping"], "title": "Scaling Open-Ended Reasoning to Predict the Future", "comment": "45 pages", "summary": "High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5408\u6210\u9884\u6d4b\u95ee\u9898\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u6765\u8fdb\u884c\u9ad8\u98ce\u9669\u51b3\u7b56\u7684\u672a\u6765\u9884\u6d4b\uff0c\u4f7f\u7528\u79bb\u7ebf\u65b0\u95fb\u8bed\u6599\u5e93\u9632\u6b62\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u4e14\u5f00\u53d1\u4e86OpenForecaster 8B\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u51c6\u786e\u5ea6\u3001\u6821\u51c6\u548c\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u6240\u6709\u6a21\u578b\u3001\u4ee3\u7801\u548c\u6570\u636e\u90fd\u5f00\u6e90\u5171\u4eab\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5bf9\u672a\u6765\u5f00\u653e\u6027\u9884\u6d4b\u95ee\u9898\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u9884\u6d4b\u95ee\u9898\u6765\u6269\u5927\u8bad\u7ec3\u6570\u636e\u96c6\u89c4\u6a21\uff0c\u5e76\u786e\u4fdd\u5728\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u6cc4\u9732\u672a\u6765\u4fe1\u606f\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u5168\u81ea\u52a8\u7cbe\u5fc3\u7b56\u5212\u7684\u65b9\u6cd5\u4ece\u65e5\u5e38\u65b0\u95fb\u4e2d\u7684\u5168\u7403\u4e8b\u4ef6\u5408\u6210\u65b0\u7684\u9884\u6d4b\u95ee\u9898\uff0c\u5229\u7528Qwen3\u601d\u7ef4\u6a21\u578b\u5728\u521b\u5efa\u7684\u6570\u636e\u96c6OpenForesight\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4e3a\u907f\u514d\u672a\u6765\u4fe1\u606f\u6cc4\u9732\uff0c\u6574\u4e2a\u8fc7\u7a0b\u4f7f\u7528\u4e86\u79bb\u7ebf\u65b0\u95fb\u8bed\u6599\u5e93\u4f5c\u4e3a\u6570\u636e\u751f\u6210\u4e0e\u68c0\u7d22\u7684\u57fa\u7840\u3002\u6b64\u5916\uff0c\u8fd8\u57fa\u4e8e\u4e00\u4e2a\u5c0f\u9a8c\u8bc1\u96c6\u4f18\u5316\u4e86\u68c0\u7d22\u673a\u5236\u53ca\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u51fd\u6570\u3002", "result": "\u6700\u7ec8\u5f00\u53d1\u51fa\u7684\u9884\u6d4b\u7cfb\u7edfOpenForecaster 8B\u80fd\u591f\u5728\u4fdd\u6301\u8f83\u5c0f\u89c4\u6a21\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u66f4\u5927\u4e13\u6709\u6a21\u578b\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u6821\u51c6\u4ee5\u53ca\u4e00\u81f4\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002\u8fd9\u4e9b\u6539\u8fdb\u4e0d\u4ec5\u9650\u4e8e\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u5f97\u5230\u4e86\u4f53\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u672a\u6765\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\u7684\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\u800c\u8a00\u3002\u540c\u65f6\uff0c\u516c\u5f00\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
