<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 4]
- [cs.MM](#cs.MM) [Total: 2]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation](https://arxiv.org/abs/2511.19514)
*Yang Wu,Qian Li,Yuling Xiong,Hongbo Tang,Xun Liu,Jun Zhang,Huan Yu,Jie Jiang,Hailong Shi*

Main category: cs.IR

TL;DR: SCoTER框架通过自动化推理模式发现和结构保持集成，将LLM的推理能力高效迁移到推荐系统，在四个基准上提升3.75%-11.59%，并在腾讯广告平台实现2.14%的GMV增长且消除在线LLM推理成本。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统利用LLM推理能力面临两大挑战：缺乏自动化推理模式发现机制（依赖脆弱的手动模板或不稳定的零样本提示），以及结构破坏性集成方法（直接提示导致过高在线成本，特征提取丢弃逐步推理逻辑）。

Method: 提出SCoTER统一框架，包含两部分：1) GVM管道用于自动化推理模式发现；2) 结构保持集成架构，将逐步推理逻辑迁移到高效模型。框架通过信息论证明结构保持迁移比忽略结构的方法有更紧的性能界限。

Result: 在四个基准测试上相比TIGER基线提升3.75%-11.59%；在腾讯广告平台部署中，GMV提升2.14%且完全消除在线LLM推理成本。

Conclusion: SCoTER为将结构化LLM推理迁移到大规模推荐系统提供了原则性且经过生产验证的蓝图，解决了推理模式发现和结构保持集成的核心挑战。

Abstract: Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\%-11.59\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.

</details>


### [2] [LLM-EDT: Large Language Model Enhanced Cross-domain Sequential Recommendation with Dual-phase Training](https://arxiv.org/abs/2511.19931)
*Ziwei Liu,Qidong Liu,Wanyu Wang,Yejing Wang,Tong Xu,Wei Huang,Chong Chen,Peng Chuan,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 提出了LLM-EDT方法，利用大语言模型增强跨域序列推荐，通过可转移项目增强器和双阶段训练解决数据不平衡和转换问题，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有的跨域序列推荐方法存在数据不平衡问题和跨域偏好转换困难的问题，而现有的大语言模型增强方法未能有效处理无关噪声和粗略画像问题。

Method: 提出可转移项目增强器自适应生成跨域行为；采用双阶段训练策略结合领域特定线程和共享背景；设计领域感知画像模块生成全面用户画像。

Result: 在三个公共数据集上的实验验证了LLM-EDT方法的有效性，代码已开源。

Conclusion: LLM-EDT通过智能数据增强和双阶段训练有效解决了跨域推荐的关键问题，为大语言模型在推荐系统的应用提供了新思路。

Abstract: Cross-domain Sequential Recommendation (CDSR) has been proposed to enrich user-item interactions by incorporating information from various domains. Despite current progress, the imbalance issue and transition issue hinder further development of CDSR. The former one presents a phenomenon that the interactions in one domain dominate the entire behavior, leading to difficulty in capturing the domain-specific features in the other domain. The latter points to the difficulty in capturing users' cross-domain preferences within the mixed interaction sequence, resulting in poor next-item prediction performance for specific domains. With world knowledge and powerful reasoning ability, Large Language Models (LLMs) partially alleviate the above issues by performing as a generator and an encoder. However, current LLMs-enhanced CDSR methods are still under exploration, which fail to recognize the irrelevant noise and rough profiling problems. Thus, to make peace with the aforementioned challenges, we proposed an LLMs Enhanced Cross-domain Sequential Recommendation with Dual-phase Training ({LLM-EDT}). To address the imbalance issue while introducing less irrelevant noise, we first propose the transferable item augmenter to adaptively generate possible cross-domain behaviors for users. Then, to alleviate the transition issue, we introduce a dual-phase training strategy to empower the domain-specific thread with a domain-shared background. As for the rough profiling problem, we devise a domain-aware profiling module to summarize the user's preference in each domain and adaptively aggregate them to generate comprehensive user profiles. The experiments on three public datasets validate the effectiveness of our proposed LLM-EDT. To ease reproducibility, we have released the detailed code online at {https://anonymous.4open.science/r/LLM-EDT-583F}.

</details>


### [3] [The 2nd Workshop on Human-Centered Recommender Systems](https://arxiv.org/abs/2511.19979)
*Kaike Zhang,Jiakai Tang,Du Su,Shuchang Liu,Julian McAuley,Lina Yao,Qi Cao,Yue Feng,Fei Sun*

Main category: cs.IR

TL;DR: Recommender systems need shift from engagement metrics to human-centered values (trust, safety, fairness) through interdisciplinary collaboration.


<details>
  <summary>Details</summary>
Motivation: Traditional metrics (accuracy, clicks) fail to capture human values as recommender systems' societal influence grows.

Method: Workshop with keynotes, panels, and papers exploring human values integration via three axes: Human Understanding, Involvement, and Impact.

Result: Fosters collaboration across recommender systems, HCI, AI safety, and social computing to align systems with human welfare.

Conclusion: HCRS aims to drive a paradigm shift toward responsible, human-aligned recommendation research for the next decade.

Abstract: Recommender systems shape how people discover information, form opinions, and connect with society. Yet, as their influence grows, traditional metrics, e.g., accuracy, clicks, and engagement, no longer capture what truly matters to humans. The workshop on Human-Centered Recommender Systems (HCRS) calls for a paradigm shift from optimizing engagement toward designing systems that truly understand, involve, and benefit people. It brings together researchers in recommender systems, human-computer interaction, AI safety, and social computing to explore how human values, e.g., trust, safety, fairness, transparency, and well-being, can be integrated into recommendation processes. Centered around three thematic axes-Human Understanding, Human Involvement, and Human Impact-HCRS features keynotes, panels, and papers covering topics from LLM-based interactive recommenders to societal welfare optimization. By fostering interdisciplinary collaboration, HCRS aims to shape the next decade of responsible and human-aligned recommendation research.

</details>


### [4] [Towards A Tri-View Diffusion Framework for Recommendation](https://arxiv.org/abs/2511.20122)
*Ximing Chen,Pui Ieng Lei,Yijun Sheng,Yanyan Liu,Zhiguo Gong*

Main category: cs.IR

TL;DR: 一篇关于在推荐系统中应用扩散模型的研究论文，提出了一个结合热力学视角的最小化扩散框架，通过最大化亥姆霍兹自由能量和独特的负采样策略来提高推荐性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的推荐系统缺乏严谨的理论分析，特别是从热力学角度对推荐模型完整性的研究不足。作者发现传统推荐模型通过降低熵工作，而扩散模型通过最大化能量工作，这个发现揭示了结合两者的可能性。

Method: 1. 从热力学角度实验研究推荐模型的完整性
2. 提出最大化亥姆霍兹自由能量的最小化扩散框架
3. 在反向过程中使用精心设计的去噪器保持各向异性
4. 采用接受-拒绝Gumbel采样过程(AR-GSP)优先处理未观察的交互

Result: 理论分析和大量实验表明，所提出的框架在准确性和效率方面都优于基线模型。AR-GSP能够确保高质量的硬负样本，并处理扩散模型的自适应采样策略。

Conclusion: 该研究通过热力学视角为扩散模型在推荐系统中的应用提供了严谨的理论基础，提出的框架在性能和效率方面表现出显著优势，为未来的推荐系统研究开辟了新的方向。

Abstract: Diffusion models (DMs) have recently gained significant interest for their exceptional potential in recommendation tasks. This stems primarily from their prominent capability in distilling, modeling, and generating comprehensive user preferences. However, previous work fails to examine DMs in recommendation tasks through a rigorous lens. In this paper, we first experimentally investigate the completeness of recommender models from a thermodynamic view. We reveal that existing DM-based recommender models operate by maximizing the energy, while classic recommender models operate by reducing the entropy. Based on this finding, we propose a minimalistic diffusion framework that incorporates both factors via the maximization of Helmholtz free energy. Meanwhile, to foster the optimization, our reverse process is armed with a well-designed denoiser to maintain the inherent anisotropy, which measures the user-item cross-correlation in the context of bipartite graphs. Finally, we adopt an Acceptance-Rejection Gumbel Sampling Process (AR-GSP) to prioritize the far-outnumbered unobserved interactions for model robustness. AR-GSP integrates an acceptance-rejection sampling to ensure high-quality hard negative samples for general recommendation tasks, and a timestep-dependent Gumbel Softmax to handle an adaptive sampling strategy for diffusion models. Theoretical analyses and extensive experiments demonstrate that our proposed framework has distinct superiority over baselines in terms of accuracy and efficiency.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [5] [It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models](https://arxiv.org/abs/2511.19877)
*Xiangyu Zhao,Yaling Shen,Yiwen Jiang,Zimu Wang,Jiahe Liu,Maxmartwell H Cheng,Guilherme C Oliveira,Robert Desimone,Dominic Dwyer,Zongyuan Ge*

Main category: cs.MM

TL;DR: 提出了一种新型多模态LLM框架，用于抑郁症检测，通过时间戳级别的视听特征对齐，在DAIC-WoZ数据集上表现优于单模态和多模态方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球最普遍的心理健康障碍之一。传统LLM以文本为中心，无法处理心理健康评估中至关重要的音频和视觉模态中的非语言线索。虽然多模态LLM是一个有前景的方向，但很少有针对心理学应用定制。

Method: 提出了一种新颖的多模态LLM框架，通过增强音频语言模型以具备视觉理解能力，并在时间戳级别对齐视听特征。这种细粒度对齐改善了跨模态时间动态建模，同时减少了对大量训练数据和计算资源的需求。

Result: 在DAIC-WoZ数据集上的实验表明，该模型在性能上优于单模态方法和先前多模态方法。

Conclusion: 所提出的框架可以扩展以纳入额外的生理信号，为超越心理健康的更广泛临床应用铺平了道路。

Abstract: Depression is one of the most prevalent mental health disorders globally. In recent years, multi-modal data, such as speech, video, and transcripts, has been increasingly used to develop AI-assisted depression assessment systems. Large language models have further advanced this field due to their strong language understanding and generalization capabilities. However, conventional LLMs remain text-centric and cannot process the rich non-verbal cues found in audio and visual modalities, which are critical components in mental health evaluation. While multi-modal LLMs offer a promising direction, few are tailored for psychological applications. In this study, we propose a novel multi-modal LLM framework for depression detection. Our approach augments an audio language model with visual understanding and aligns audio-visual features at the timestamp level. This fine-grained alignment improves modeling of temporal dynamics across modalities while reducing the need for extensive training data and computational resources. Experiments on the DAIC-WoZ dataset demonstrate that our model outperforms both single-modality approaches and previous multi-modal methods. Moreover, the proposed framework can be extended to incorporate additional physiological signals, paving the way for broader clinical applications beyond mental health.

</details>


### [6] [FINE: Factorized multimodal sentiment analysis via mutual INformation Estimation](https://arxiv.org/abs/2511.20167)
*Yadong Liu,Shangfei Wang*

Main category: cs.MM

TL;DR: 提出一种分解式多模态融合框架，通过模态分解和信息优化解决多模态情感分析中的异构性问题，在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析面临模态异构性挑战，包括异步信号、模态间信息不平衡和任务无关噪声干扰，影响情感表示的鲁棒性和准确性。

Method: 1. 将各模态分解为共享和独特表示；2. 基于互信息的优化策略抑制任务无关噪声；3. 引入Q-Former混合模块进行细粒度特征提取；4. 使用动态对比队列增强长时序建模和类别区分性。

Result: 在多个公开数据集上的实验表明，该方法持续优于现有方法，验证了框架的有效性和鲁棒性。

Conclusion: 该分解式多模态融合框架通过细粒度表示分解和优化策略，有效提升了多模态情感分析的性能，为处理模态异构性问题提供了新思路。

Abstract: Multimodal sentiment analysis remains a challenging task due to the inherent heterogeneity across modalities. Such heterogeneity often manifests as asynchronous signals, imbalanced information between modalities, and interference from task-irrelevant noise, hindering the learning of robust and accurate sentiment representations. To address these issues, we propose a factorized multimodal fusion framework that first disentangles each modality into shared and unique representations, and then suppresses task-irrelevant noise within both to retain only sentiment-critical representations. This fine-grained decomposition improves representation quality by reducing redundancy, prompting cross-modal complementarity, and isolating task-relevant sentiment cues. Rather than manipulating the feature space directly, we adopt a mutual information-based optimization strategy to guide the factorization process in a more stable and principled manner. To further support feature extraction and long-term temporal modeling, we introduce two auxiliary modules: a Mixture of Q-Formers, placed before factorization, which precedes the factorization and uses learnable queries to extract fine-grained affective features from multiple modalities, and a Dynamic Contrastive Queue, placed after factorization, which stores latest high-level representations for contrastive learning, enabling the model to capture long-range discriminative patterns and improve class-level separability. Extensive experiments on multiple public datasets demonstrate that our method consistently outperforms existing approaches, validating the effectiveness and robustness of the proposed framework.

</details>
