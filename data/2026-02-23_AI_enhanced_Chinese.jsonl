{"id": "2602.17769", "categories": ["cs.MM", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.17769", "abs": "https://arxiv.org/abs/2602.17769", "authors": ["Rebecca Salganik", "Teng Tu", "Fei-Yueh Chen", "Xiaohao Liu", "Keifeng Lu", "Ethan Luvisia", "Zhiyao Duan", "Guillaume Salha-Galvan", "Anson Kahng", "Yunshan Ma", "Jian Kang"], "title": "MusicSem: A Semantically Rich Language--Audio Dataset of Natural Music Descriptions", "comment": null, "summary": "Music representation learning is central to music information retrieval and generation. While recent advances in multimodal learning have improved alignment between text and audio for tasks such as cross-modal music retrieval, text-to-music generation, and music-to-text generation, existing models often struggle to capture users' expressed intent in natural language descriptions of music. This observation suggests that the datasets used to train and evaluate these models do not fully reflect the broader and more natural forms of human discourse through which music is described. In this paper, we introduce MusicSem, a dataset of 32,493 language-audio pairs derived from organic music-related discussions on the social media platform Reddit. Compared to existing datasets, MusicSem captures a broader spectrum of musical semantics, reflecting how listeners naturally describe music in nuanced and human-centered ways. To structure these expressions, we propose a taxonomy of five semantic categories: descriptive, atmospheric, situational, metadata-related, and contextual. In addition to the construction, analysis, and release of MusicSem, we use the dataset to evaluate a wide range of multimodal models for retrieval and generation, highlighting the importance of modeling fine-grained semantics. Overall, MusicSem serves as a novel semantics-aware resource to support future research on human-aligned multimodal music representation learning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aMusicSem\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b32,493\u4e2a\u8bed\u8a00-\u97f3\u9891\u5bf9\uff0c\u6765\u6e90\u4e8eReddit\u4e0a\u7684\u81ea\u7136\u97f3\u4e50\u8ba8\u8bba\u3002\u5b83\u8986\u76d6\u4e86\u66f4\u5e7f\u6cdb\u7684\u97f3\u4e50\u8bed\u4e49\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e94\u7c7b\u8bed\u4e49\u5206\u7c7b\u6cd5\u6765\u7ed3\u6784\u5316\u8fd9\u4e9b\u8868\u8fbe\u3002\u901a\u8fc7\u4f7f\u7528MusicSem\u8bc4\u4f30\u591a\u79cd\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5f3a\u8c03\u4e86\u5efa\u6a21\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u97f3\u4e50\u4e0e\u6587\u672c\u4e4b\u95f4\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7528\u6237\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u97f3\u4e50\u65f6\u6240\u8868\u8fbe\u7684\u610f\u56fe\uff0c\u8fd9\u8868\u660e\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u6570\u636e\u96c6\u672a\u80fd\u5b8c\u5168\u53cd\u6620\u4eba\u7c7b\u7528\u6765\u63cf\u8ff0\u97f3\u4e50\u7684\u66f4\u5e7f\u6cdb\u548c\u66f4\u81ea\u7136\u7684\u5f62\u5f0f\u3002", "method": "\u521b\u5efa\u4e86MusicSem\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u4eceReddit\u793e\u4ea4\u5e73\u53f0\u83b7\u53d6\u768432,493\u4e2a\u8bed\u8a00-\u97f3\u9891\u914d\u5bf9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u62ec\u63cf\u8ff0\u6027\u3001\u6c1b\u56f4\u6027\u3001\u60c5\u5883\u6027\u3001\u5143\u6570\u636e\u76f8\u5173\u6027\u548c\u80cc\u666f\u6027\u5728\u5185\u7684\u4e94\u79cd\u8bed\u4e49\u7c7b\u522b\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "MusicSem\u80fd\u591f\u6355\u6349\u5230\u66f4\u52a0\u5bbd\u6cdb\u7684\u97f3\u4e50\u8bed\u4e49\u8303\u56f4\uff0c\u53cd\u6620\u4e86\u542c\u4f17\u4ee5\u7ec6\u5fae\u4e14\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u5f0f\u81ea\u7136\u5730\u63cf\u8ff0\u97f3\u4e50\u7684\u65b9\u5f0f\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5229\u7528MusicSem\u5bf9\u4e00\u7cfb\u5217\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u68c0\u7d22\u548c\u751f\u6210\u4efb\u52a1\u7684\u8bc4\u4f30\uff0c\u7a81\u51fa\u4e86\u5bf9\u7cbe\u7ec6\u8bed\u4e49\u5efa\u6a21\u7684\u91cd\u8981\u6027\u3002", "conclusion": "MusicSem\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u8bed\u4e49\u611f\u77e5\u8d44\u6e90\uff0c\u652f\u6301\u672a\u6765\u5173\u4e8e\u4eba\u7c7b\u5bf9\u9f50\u7684\u591a\u6a21\u6001\u97f3\u4e50\u8868\u793a\u5b66\u4e60\u7684\u7814\u7a76\u3002"}}
{"id": "2602.17858", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.17858", "abs": "https://arxiv.org/abs/2602.17858", "authors": ["Thinh On", "Senjuti Basu Roy", "Baruch Schieber"], "title": "Multi-Attribute Group Fairness in $k$-NN Queries on Vector Databases", "comment": null, "summary": "We initiate the study of multi-attribute group fairness in $k$-nearest neighbor ($k$-NN) search over vector databases. Unlike prior work that optimizes efficiency or query filtering, fairness imposes count constraints to ensure proportional representation across groups defined by protected attributes. When fairness spans multiple attributes, these constraints must be satisfied simultaneously, making the problem computationally hard. To address this, we propose a computational framework that produces high-quality approximate nearest neighbors with good trade-offs between search time, memory/indexing cost, and recall. We adapt locality-sensitive hashing (LSH) to accelerate candidate generation and build a lightweight index over the Cartesian product of protected attribute values. Our framework retrieves candidates satisfying joint count constraints and then applies a post-processing stage to construct fair $k$-NN results across all attributes. For 2 attributes, we present an exact polynomial-time flow-based algorithm; for 3 or more, we formulate ILP-based exact solutions with higher computational cost. We provide theoretical guarantees, identify efficiency--fairness trade-offs, and empirically show that existing vector search methods cannot be directly adapted for fairness. Experimental evaluations demonstrate the generality of the proposed framework and scalability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5411\u91cf\u6570\u636e\u5e93\u4e2dk-\u6700\u8fd1\u90bb\u641c\u7d22\u7684\u591a\u5c5e\u6027\u7ec4\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u591a\u4e2a\u53d7\u4fdd\u62a4\u5c5e\u6027\u8054\u5408\u8ba1\u6570\u7ea6\u675f\u7684\u5019\u9009\u5bf9\u8c61\uff0c\u5e76\u901a\u8fc7\u540e\u5904\u7406\u9636\u6bb5\u6784\u5efa\u6240\u6709\u5c5e\u6027\u4e0a\u7684\u516c\u5e73k-NN\u7ed3\u679c\u3002", "motivation": "\u5728k-\u6700\u8fd1\u90bb\u641c\u7d22\u4e2d\u5f15\u5165\u516c\u5e73\u6027\u4ee5\u786e\u4fdd\u7531\u53d7\u4fdd\u62a4\u5c5e\u6027\u5b9a\u4e49\u7684\u5404\u7ec4\u4e4b\u95f4\u5177\u6709\u6bd4\u4f8b\u4ee3\u8868\u6027\u3002\u5f53\u516c\u5e73\u6027\u6d89\u53ca\u591a\u4e2a\u5c5e\u6027\u65f6\uff0c\u8fd9\u4e9b\u7ea6\u675f\u5fc5\u987b\u540c\u65f6\u6ee1\u8db3\uff0c\u4f7f\u5f97\u95ee\u9898\u5728\u8ba1\u7b97\u4e0a\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8c03\u6574\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\uff08LSH\uff09\u6765\u52a0\u901f\u5019\u9009\u5bf9\u8c61\u751f\u6210\uff0c\u5e76\u5728\u53d7\u4fdd\u62a4\u5c5e\u6027\u503c\u7684\u7b1b\u5361\u5c14\u79ef\u4e0a\u5efa\u7acb\u8f7b\u91cf\u7ea7\u7d22\u5f15\u3002\u5bf9\u4e8e\u4e24\u4e2a\u5c5e\u6027\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6d41\u7684\u786e\u5207\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff1b\u5bf9\u4e8e\u4e09\u4e2a\u6216\u66f4\u591a\u5c5e\u6027\uff0c\u5219\u5236\u5b9a\u4e86\u57fa\u4e8e\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u7684\u786e\u5207\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\u4e86\u6240\u63d0\u6846\u67b6\u7684\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4e14\u73b0\u6709\u5411\u91cf\u641c\u7d22\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u9002\u5e94\u4e8e\u5b9e\u73b0\u516c\u5e73\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u5c5e\u6027\u7ec4\u516c\u5e73\u6027\u7684k-\u6700\u8fd1\u90bb\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u641c\u7d22\u65f6\u95f4\u3001\u5185\u5b58/\u7d22\u5f15\u6210\u672c\u548c\u53ec\u56de\u7387\u4e4b\u95f4\u7684\u826f\u597d\u6743\u8861\u3002"}}
{"id": "2602.17667", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17667", "abs": "https://arxiv.org/abs/2602.17667", "authors": ["Cheng cheng", "Chenxing Wang", "Aolin Li", "Haijun Wu", "Huiyun Hu", "Juyuan Wang"], "title": "When & How to Write for Personalized Demand-aware Query Rewriting in Video Search", "comment": null, "summary": "In video search systems, user historical behaviors provide rich context for identifying search intent and resolving ambiguity. However, traditional methods utilizing implicit history features often suffer from signal dilution and delayed feedback. To address these challenges, we propose WeWrite, a novel Personalized Demand-aware Query Rewriting framework. Specifically, WeWrite tackles three key challenges: (1) When to Write: An automated posterior-based mining strategy extracts high-quality samples from user logs, identifying scenarios where personalization is strictly necessary; (2) How to Write: A hybrid training paradigm combines Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to align the LLM's output style with the retrieval system; (3) Deployment: A parallel \"Fake Recall\" architecture ensures low latency. Online A/B testing on a large-scale video platform demonstrates that WeWrite improves the Click-Through Video Volume (VV$>$10s) by 1.07% and reduces the Query Reformulation Rate by 2.97%.", "AI": {"tldr": "WeWrite, a new Personalized Demand-aware Query Rewriting framework, improves video search by addressing when and how to apply personalization, using a hybrid training approach, and ensuring low latency, resulting in enhanced user engagement and reduced query reformulations.", "motivation": "The motivation is to improve the effectiveness of video search systems by leveraging user historical behaviors more efficiently, overcoming the limitations of traditional methods that use implicit history features, such as signal dilution and delayed feedback.", "method": "WeWrite addresses three main challenges: (1) determining 'When to Write' through an automated posterior-based mining strategy for high-quality sample extraction; (2) 'How to Write' by integrating Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) for style alignment; and (3) 'Deployment' via a parallel 'Fake Recall' architecture to maintain low latency.", "result": "Online A/B testing on a large-scale video platform showed that WeWrite increased the Click-Through Video Volume (VV>10s) by 1.07% and decreased the Query Reformulation Rate by 2.97%.", "conclusion": "The proposed WeWrite framework effectively enhances the performance of video search systems by personalizing query rewriting based on user behavior, leading to better search outcomes and user experience."}}
{"id": "2602.17677", "categories": ["cs.LG", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17677", "abs": "https://arxiv.org/abs/2602.17677", "authors": ["Sutej Kulgod", "Sean Ye", "Sanchit Tanwar", "Christoffer Heckman"], "title": "Reducing Text Bias in Synthetically Generated MCQAs for VLMs in Autonomous Driving", "comment": "7 pages, 2 figures", "summary": "Multiple Choice Question Answering (MCQA) benchmarks are an established standard for measuring Vision Language Model (VLM) performance in driving tasks. However, we observe the known phenomenon that synthetically generated MCQAs are highly susceptible to hidden textual cues that allow models to exploit linguistic patterns rather than visual context. Our results show that a VLM fine-tuned on such data can achieve accuracy comparable to human-validated benchmarks even without visual input. Our proposed method reduces blind accuracy from +66.9% above random to +2.9%, eliminating the vast majority of exploitable textual shortcuts. By decoupling the correct answer from linguistic artifacts and employing a curriculum learning strategy, we force the model to rely on visual grounding, ensuring that performance accurately reflects perceptual understanding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u51cf\u5c11\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5408\u6210\u751f\u6210\u7684\u591a\u9879\u9009\u62e9\u9898\u65f6\u5bf9\u9690\u85cf\u6587\u672c\u7ebf\u7d22\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u5c06\u6b63\u786e\u7b54\u6848\u4e0e\u8bed\u8a00\u7279\u5f81\u89e3\u8026\u5e76\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u4fc3\u4f7f\u6a21\u578b\u66f4\u591a\u5730\u4f9d\u8d56\u89c6\u89c9\u4fe1\u606f\u3002", "motivation": "\u89c2\u5bdf\u5230\u5408\u6210\u751f\u6210\u7684\u591a\u9879\u9009\u62e9\u9898\u975e\u5e38\u5bb9\u6613\u53d7\u5230\u9690\u85cf\u6587\u672c\u7ebf\u7d22\u7684\u5f71\u54cd\uff0c\u8fd9\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5229\u7528\u8bed\u8a00\u6a21\u5f0f\u800c\u4e0d\u662f\u89c6\u89c9\u4e0a\u4e0b\u6587\u6765\u4f5c\u7b54\uff0c\u5bfc\u81f4\u5373\u4f7f\u6ca1\u6709\u89c6\u89c9\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u4eba\u5de5\u9a8c\u8bc1\u57fa\u51c6\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5305\u62ec\u5c06\u6b63\u786e\u7b54\u6848\u4ece\u8bed\u8a00\u7279\u5f81\u4e2d\u89e3\u8026\u51fa\u6765\uff0c\u5e76\u91c7\u7528\u4e00\u79cd\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u66f4\u591a\u5730\u4f9d\u8d56\u4e8e\u89c6\u89c9\u57fa\u7840\u800c\u975e\u7b80\u5355\u7684\u8bed\u8a00\u6377\u5f84\u3002", "result": "\u4f7f\u7528\u63d0\u51fa\u7684\u65b9\u6cd5\u540e\uff0c\u76f2\u76ee\u51c6\u786e\u7387\u4ece\u6bd4\u968f\u673a\u9ad866.9%\u964d\u4f4e\u5230\u4e86\u4ec5\u9ad8\u51fa2.9%\uff0c\u8868\u660e\u5927\u90e8\u5206\u53ef\u5229\u7528\u7684\u8bed\u8a00\u6377\u5f84\u5df2\u7ecf\u88ab\u6d88\u9664\u3002", "conclusion": "\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u51cf\u5c11\u4e86\u6a21\u578b\u5bf9\u975e\u89c6\u89c9\u4fe1\u606f\u7684\u4f9d\u8d56\u6027\uff0c\u63d0\u9ad8\u4e86\u5176\u57fa\u4e8e\u89c6\u89c9\u7406\u89e3\u7684\u8868\u73b0\u771f\u5b9e\u6027\u3002"}}
{"id": "2602.17678", "categories": ["cs.DC", "cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17678", "abs": "https://arxiv.org/abs/2602.17678", "authors": ["Oreofe Solarin"], "title": "It's Not Just Timestamps: A Study on Docker Reproducibility", "comment": null, "summary": "Reproducible container builds promise a simple integrity check for software supply chains: rebuild an image from its Dockerfile and compare hashes. We build a Docker measurement pipeline and apply it to a stratified sample of 2,000 GitHub repositories that contained a Dockerfile. We found that only 56% produce any buildable image, and just 2.7% of those are bitwise reproducible without any infrastructure configurations. After modifying infrastructure configurations, we raise bitwise reproducibility by 18.6%, but 78.7% of buildable Dockerfiles remain non-reproducible. We analyze the root causes of the remaining differences, and find that beyond timestamps and metadata, developer-controlled choices such as uncleaned caches, logs, documentation, and floating versions are dominant causes of non-reproducibility. We derive concrete Dockerfile guidelines from these patterns and discuss how they can inform future linters and Continuous Integration (CI) checks for reproducible containers.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2aDocker\u6d4b\u91cf\u7ba1\u9053\uff0c\u5bf92000\u4e2aGitHub\u4ed3\u5e93\u4e2d\u7684Dockerfile\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u53d1\u73b0\u4ec5\u670956%\u7684\u4ed3\u5e93\u80fd\u751f\u6210\u53ef\u6784\u5efa\u955c\u50cf\uff0c\u800c\u5176\u4e2d\u53ea\u67092.7%\u662f\u4f4d\u7ea7\u53ef\u518d\u73b0\u7684\u3002\u901a\u8fc7\u8c03\u6574\u57fa\u7840\u8bbe\u65bd\u914d\u7f6e\u540e\uff0c\u4f4d\u7ea7\u53ef\u518d\u73b0\u6027\u63d0\u9ad8\u4e8618.6%\uff0c\u4f46\u4ecd\u670978.7%\u7684\u53ef\u6784\u5efaDockerfile\u4e0d\u53ef\u518d\u73b0\u3002\u4e3b\u8981\u539f\u56e0\u662f\u5f00\u53d1\u8005\u63a7\u5236\u7684\u9009\u62e9\u5982\u672a\u6e05\u7406\u7684\u7f13\u5b58\u3001\u65e5\u5fd7\u7b49\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u5177\u4f53\u7684Dockerfile\u6307\u5357\u4ee5\u6307\u5bfc\u672a\u6765\u68c0\u67e5\u5de5\u5177\u548c\u6301\u7eed\u96c6\u6210(CI)\u68c0\u67e5\u7684\u53d1\u5c55\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7b80\u5355\u7684\u5b8c\u6574\u6027\u68c0\u67e5\uff08\u5373\u4eceDockerfile\u91cd\u5efa\u955c\u50cf\u5e76\u6bd4\u8f83\u54c8\u5e0c\u503c\uff09\u6765\u9a8c\u8bc1\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u4e2d\u7684\u53ef\u518d\u73b0\u5bb9\u5668\u6784\u5efa\u3002\u76ee\u7684\u662f\u4e86\u89e3\u5f53\u524dDockerfiles\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u518d\u73b0\u6027\u60c5\u51b5\uff0c\u5e76\u627e\u51fa\u5bfc\u81f4\u4e0d\u53ef\u518d\u73b0\u6027\u7684\u4e3b\u8981\u539f\u56e0\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5efa\u7acb\u4e86\u4e00\u4e2aDocker\u6d4b\u91cf\u7ba1\u9053\uff0c\u5e76\u5e94\u7528\u4e8e\u5305\u542bDockerfile\u76842,000\u4e2aGitHub\u4ed3\u5e93\u6837\u672c\u4e2d\u3002\u4ed6\u4eec\u9996\u5148\u5c1d\u8bd5\u76f4\u63a5\u6839\u636eDockerfile\u6784\u5efa\u955c\u50cf\uff0c\u7136\u540e\u9488\u5bf9\u90a3\u4e9b\u65e0\u6cd5\u76f4\u63a5\u83b7\u5f97\u4f4d\u7ea7\u53ef\u518d\u73b0\u7ed3\u679c\u7684\u60c5\u51b5\uff0c\u901a\u8fc7\u8c03\u6574\u57fa\u7840\u8bbe\u65bd\u914d\u7f6e\u6765\u63d0\u9ad8\u53ef\u518d\u73b0\u6027\u6bd4\u4f8b\u3002\u5bf9\u4e8e\u4ecd\u7136\u5b58\u5728\u7684\u5dee\u5f02\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u6839\u672c\u539f\u56e0\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u4ec556%\u7684\u4ed3\u5e93\u80fd\u591f\u751f\u6210\u4efb\u4f55\u53ef\u6784\u5efa\u955c\u50cf\uff0c\u4e14\u5176\u4e2d\u53ea\u67092.7%\u662f\u65e0\u9700\u4efb\u4f55\u57fa\u7840\u8bbe\u65bd\u914d\u7f6e\u8c03\u6574\u5373\u53ef\u5b9e\u73b0\u4f4d\u7ea7\u53ef\u518d\u73b0\u7684\u3002\u901a\u8fc7\u4fee\u6539\u57fa\u7840\u8bbe\u65bd\u914d\u7f6e\uff0c\u4f4d\u7ea7\u53ef\u518d\u73b0\u6027\u63d0\u5347\u4e8618.6%\uff0c\u4f46\u4f9d\u65e7\u670978.7%\u7684\u53ef\u6784\u5efaDockerfile\u672a\u80fd\u8fbe\u5230\u5b8c\u5168\u53ef\u518d\u73b0\u6807\u51c6\u3002\u6b64\u5916\uff0c\u9664\u4e86\u65f6\u95f4\u6233\u548c\u5143\u6570\u636e\u5916\uff0c\u5f00\u53d1\u8005\u63a7\u5236\u7684\u56e0\u7d20\u5982\u672a\u6e05\u7406\u7684\u7f13\u5b58\u3001\u65e5\u5fd7\u6587\u4ef6\u3001\u6587\u6863\u4ee5\u53ca\u6d6e\u52a8\u7248\u672c\u53f7\u6210\u4e3a\u4e86\u975e\u53ef\u518d\u73b0\u6027\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u73b0\u6709\u5b9e\u8df5\u4e2d\uff0cDockerfiles\u7684\u4f4d\u7ea7\u53ef\u518d\u73b0\u6027\u5b58\u5728\u8f83\u5927\u95ee\u9898\u3002\u5c3d\u7ba1\u901a\u8fc7\u7279\u5b9a\u914d\u7f6e\u8c03\u6574\u53ef\u4ee5\u6539\u5584\u90e8\u5206\u60c5\u51b5\u4e0b\u7684\u53ef\u518d\u73b0\u6027\uff0c\u4f46\u8981\u5b9e\u73b0\u5e7f\u6cdb\u610f\u4e49\u4e0a\u7684\u53ef\u518d\u73b0\u6027\u8fd8\u9700\u8981\u89e3\u51b3\u7531\u5f00\u53d1\u8005\u9009\u62e9\u5f15\u8d77\u7684\u95ee\u9898\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u5177\u4f53\u7684Dockerfile\u7f16\u5199\u5efa\u8bae\uff0c\u5e76\u8ba8\u8bba\u4e86\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u53d1\u73b0\u6765\u6539\u8fdb\u672a\u6765\u7684linters\u53caCI\u68c0\u67e5\u673a\u5236\u3002"}}
{"id": "2602.17687", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17687", "abs": "https://arxiv.org/abs/2602.17687", "authors": ["Connor Shorten", "Augustas Skaburskas", "Daniel M. Jones", "Charles Pierse", "Roberto Esposito", "John Trengrove", "Etienne Dilocker", "Bob van Luijt"], "title": "IRPAPERS: A Visual Document Benchmark for Scientific Retrieval and Question Answering", "comment": "23 pages, 6 figures", "summary": "AI systems have achieved remarkable success in processing text and relational data, yet visual document processing remains relatively underexplored. Whereas traditional systems require OCR transcriptions to convert these visual documents into text and metadata, recent advances in multimodal foundation models offer retrieval and generation directly from document images. This raises a key question: How do image-based systems compare to established text-based methods? We introduce IRPAPERS, a benchmark of 3,230 pages from 166 scientific papers, with both an image and an OCR transcription for each page. Using 180 needle-in-the-haystack questions, we compare image- and text-based retrieval and question answering systems. Text retrieval using Arctic 2.0 embeddings, BM25, and hybrid text search achieved 46% Recall@1, 78% Recall@5, and 91% Recall@20, while image-based retrieval reaches 43%, 78%, and 93%, respectively. The two modalities exhibit complementary failures, enabling multimodal hybrid search to outperform either alone, achieving 49% Recall@1, 81% Recall@5, and 95% Recall@20. We further evaluate efficiency-performance tradeoffs with MUVERA and assess multiple multi-vector image embedding models. Among closed-source models, Cohere Embed v4 page image embeddings outperform Voyage 3 Large text embeddings and all tested open-source models, achieving 58% Recall@1, 87% Recall@5, and 97% Recall@20. For question answering, text-based RAG systems achieved higher ground-truth alignment than image-based systems (0.82 vs. 0.71), and both benefit substantially from increased retrieval depth, with multi-document retrieval outperforming oracle single-document retrieval. We analyze the complementary limitations of unimodal text and image representations and identify question types that require one modality over the other. The IRPAPERS dataset and all experimental code are publicly available.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86IRPAPERS\uff0c\u4e00\u4e2a\u5305\u542b3,230\u9875\u6765\u81ea166\u7bc7\u79d1\u5b66\u8bba\u6587\u7684\u6570\u636e\u96c6\uff0c\u65e8\u5728\u6bd4\u8f83\u57fa\u4e8e\u56fe\u50cf\u548c\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u53ca\u95ee\u7b54\u7cfb\u7edf\u7684\u8868\u73b0\u3002\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5728\u67d0\u4e9b\u6307\u6807\u4e0a\u6587\u672c\u68c0\u7d22\u8868\u73b0\u7a0d\u597d\uff0c\u4f46\u7ed3\u5408\u4e24\u79cd\u6a21\u6001\u53ef\u4ee5\u5b9e\u73b0\u66f4\u4f18\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u8fd8\u8bc4\u4f30\u4e86\u591a\u79cd\u591a\u5411\u91cf\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\uff0c\u5e76\u5206\u6790\u4e86\u5355\u4e00\u6a21\u6001\u8868\u793a\u7684\u5c40\u9650\u6027\u4ee5\u53ca\u9700\u8981\u7279\u5b9a\u6a21\u6001\u7684\u95ee\u9898\u7c7b\u578b\u3002", "motivation": "\u89c6\u89c9\u6587\u6863\u5904\u7406\u76f8\u6bd4\u6587\u672c\u548c\u5173\u7cfb\u6570\u636e\u5904\u7406\u800c\u8a00\u63a2\u7d22\u8f83\u5c11\uff0c\u800c\u6700\u8fd1\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u76f4\u63a5\u4ece\u6587\u6863\u56fe\u50cf\u8fdb\u884c\u68c0\u7d22\u548c\u751f\u6210\u7684\u53ef\u80fd\u6027\u3002\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u4e0e\u5df2\u5efa\u7acb\u7684\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u76f8\u6bd4\u5982\u4f55\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aIRPAPERS\u7684\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u6bcf\u4e00\u9875\u7684\u56fe\u50cf\u53ca\u5176OCR\u8f6c\u5f55\u672c\u3002\u4f7f\u7528\u4e86180\u4e2a\u2018\u9488\u5728\u8349\u5806\u2019\u95ee\u9898\u6765\u5bf9\u6bd4\u4e0d\u540c\u7cfb\u7edf\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u901a\u8fc7MUVERA\u8bc4\u4ef7\u6548\u7387-\u6027\u80fd\u6298\u8877\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u4e2a\u591a\u5411\u91cf\u56fe\u50cf\u5d4c\u5165\u6a21\u578b\u3002", "result": "\u6587\u672c\u68c0\u7d22\uff08\u5229\u7528Arctic 2.0\u5d4c\u5165\u3001BM25\u548c\u6df7\u5408\u6587\u672c\u641c\u7d22\uff09\u8fbe\u5230\u4e8646%\u7684Recall@1\u300178%\u7684Recall@5\u548c91%\u7684Recall@20\uff1b\u57fa\u4e8e\u56fe\u50cf\u7684\u68c0\u7d22\u5219\u5206\u522b\u8fbe\u523043%\u300178%\u548c93%\u3002\u7ed3\u5408\u4e24\u79cd\u6a21\u6001\u7684\u6df7\u5408\u641c\u7d22\u8d85\u8d8a\u4e86\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u6a21\u6001\u7684\u6548\u679c\u3002\u5bf9\u4e8e\u95ee\u7b54\u4efb\u52a1\uff0c\u57fa\u4e8e\u6587\u672c\u7684RAG\u7cfb\u7edf\u6bd4\u57fa\u4e8e\u56fe\u50cf\u7684\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff080.82 vs. 0.71\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u867d\u7136\u6587\u672c\u68c0\u7d22\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u7565\u4f18\u4e8e\u56fe\u50cf\u68c0\u7d22\uff0c\u4f46\u7ed3\u5408\u6587\u672c\u548c\u56fe\u50cf\u4fe1\u606f\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u6700\u4f73\u7ed3\u679c\u3002\u6b64\u5916\uff0cCohere Embed v4\u9875\u9762\u56fe\u50cf\u5d4c\u5165\u5728\u95ed\u6e90\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86\u6240\u6709\u6d4b\u8bd5\u7684\u5f00\u6e90\u6a21\u578b\u3002"}}
{"id": "2602.17838", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17838", "abs": "https://arxiv.org/abs/2602.17838", "authors": ["Lara Khatib", "Micheal Pu", "Bogdan Vasilescu", "Meiyappan Nagappan"], "title": "Examining LLMs Ability to Summarize Code Through Mutation-Analysis", "comment": null, "summary": "As developers increasingly rely on LLM-generated code summaries for documentation, testing, and review, it is important to study whether these summaries accurately reflect what the program actually does. LLMs often produce confident descriptions of what the code looks like it should do (intent), while missing subtle edge cases or logic changes that define what it actually does (behavior). We present a mutation-based evaluation methodology that directly tests whether a summary truly matches the code's logic. Our approach generates a summary, injects a targeted mutation into the code, and checks if the LLM updates its summary to reflect the new behavior. We validate it through three experiments totalling 624 mutation-summary evaluations across 62 programs. First, on 12 controlled synthetic programs with 324 mutations varying in type (statement, value, decision) and location (beginning, middle, end). We find that summary accuracy decreases sharply with complexity from 76.5% for single functions to 17.3% for multi-threaded systems, while mutation type and location exhibit weaker effects. Second, testing 150 mutated samples on 50 human-written programs from the Less Basic Python Problems (LBPP) dataset confirms the same failure patterns persist as models often describe algorithmic intent rather than actual mutated behavior with a summary accuracy rate of 49.3%. Furthermore, while a comparison between GPT-4 and GPT-5.2 shows a substantial performance leap (from 49.3% to 85.3%) and an improved ability to identify mutations as \"bugs\", both models continue to struggle with distinguishing implementation details from standard algorithmic patterns. This work establishes mutation analysis as a systematic approach for assessing whether LLM-generated summaries reflect program behavior rather than superficial textual patterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5f02\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u6458\u8981\u662f\u5426\u51c6\u786e\u53cd\u6620\u4e86\u4ee3\u7801\u7684\u5b9e\u9645\u903b\u8f91\u3002\u901a\u8fc7\u5728\u4ee3\u7801\u4e2d\u6ce8\u5165\u7279\u5b9a\u53d8\u5f02\u5e76\u68c0\u67e5\u6a21\u578b\u662f\u5426\u66f4\u65b0\u5176\u6458\u8981\u4ee5\u53cd\u6620\u65b0\u884c\u4e3a\u6765\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u968f\u7740\u7a0b\u5e8f\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u6458\u8981\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u4e14\u6a21\u578b\u5f80\u5f80\u63cf\u8ff0\u7684\u662f\u7b97\u6cd5\u610f\u56fe\u800c\u975e\u5b9e\u9645\u53d8\u5f02\u540e\u7684\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u5f00\u53d1\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u6458\u8981\u6765\u8fdb\u884c\u6587\u6863\u7f16\u5199\u3001\u6d4b\u8bd5\u548c\u5ba1\u67e5\uff0c\u7814\u7a76\u8fd9\u4e9b\u6458\u8981\u662f\u5426\u51c6\u786e\u53cd\u6620\u4e86\u7a0b\u5e8f\u7684\u5b9e\u9645\u529f\u80fd\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4f1a\u81ea\u4fe1\u5730\u63cf\u8ff0\u4ee3\u7801\u770b\u8d77\u6765\u5e94\u8be5\u505a\u4ec0\u4e48\uff08\u610f\u56fe\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5b9a\u4e49\u5176\u5b9e\u9645\u884c\u4e3a\u7684\u7ec6\u5fae\u8fb9\u7f18\u60c5\u51b5\u6216\u903b\u8f91\u66f4\u6539\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5f02\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u76f4\u63a5\u6d4b\u8bd5\u6458\u8981\u662f\u5426\u771f\u6b63\u5339\u914d\u4ee3\u7801\u903b\u8f91\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u751f\u6210\u4e00\u4e2a\u6458\u8981\uff0c\u5728\u4ee3\u7801\u4e2d\u6ce8\u5165\u4e00\u4e2a\u6709\u9488\u5bf9\u6027\u7684\u53d8\u5f02\uff0c\u5e76\u68c0\u67e5\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4f1a\u66f4\u65b0\u5176\u6458\u8981\u4ee5\u53cd\u6620\u65b0\u7684\u884c\u4e3a\u3002\u7814\u7a76\u8005\u901a\u8fc7\u5bf962\u4e2a\u7a0b\u5e8f\u5171\u8ba1624\u6b21\u53d8\u5f02-\u6458\u8981\u8bc4\u4f30\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u8bbe\u8ba1\u5305\u62ec\u5bf912\u4e2a\u53d7\u63a7\u5408\u6210\u7a0b\u5e8f\u8fdb\u884c324\u6b21\u4e0d\u540c\u7c7b\u578b\uff08\u8bed\u53e5\u3001\u503c\u3001\u51b3\u7b56\uff09\u53ca\u4e0d\u540c\u4f4d\u7f6e\uff08\u5f00\u59cb\u3001\u4e2d\u95f4\u3001\u7ed3\u675f\uff09\u7684\u53d8\u5f02\u6d4b\u8bd5\uff1b\u4ee5\u53ca\u5bf9\u4eceLess Basic Python Problems (LBPP)\u6570\u636e\u96c6\u4e2d\u9009\u53d6\u768450\u4e2a\u4eba\u7c7b\u7f16\u5199\u7684\u7a0b\u5e8f\u8fdb\u884c150\u6b21\u53d8\u5f02\u6837\u672c\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6458\u8981\u51c6\u786e\u6027\u968f\u7740\u590d\u6742\u6027\u589e\u52a0\u800c\u6025\u5267\u4e0b\u964d\uff0c\u5355\u4e2a\u51fd\u6570\u7684\u51c6\u786e\u6027\u4e3a76.5%\uff0c\u800c\u5bf9\u4e8e\u591a\u7ebf\u7a0b\u7cfb\u7edf\u5219\u964d\u81f317.3%\u3002\u7a81\u53d8\u7c7b\u578b\u548c\u4f4d\u7f6e\u7684\u5f71\u54cd\u8f83\u5f31\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1GPT-4\u4e0eGPT-5.2\u4e4b\u95f4\u7684\u6027\u80fd\u6709\u4e86\u663e\u8457\u63d0\u5347\uff08\u4ece49.3%\u63d0\u9ad8\u523085.3%\uff09\uff0c\u5e76\u4e14\u8bc6\u522b\u7a81\u53d8\u4e3a\u201c\u9519\u8bef\u201d\u7684\u80fd\u529b\u6709\u6240\u6539\u5584\uff0c\u4f46\u4e24\u79cd\u6a21\u578b\u4ecd\u7136\u96be\u4ee5\u533a\u5206\u5b9e\u73b0\u7ec6\u8282\u4e0e\u6807\u51c6\u7b97\u6cd5\u6a21\u5f0f\u3002", "conclusion": "\u672c\u5de5\u4f5c\u786e\u7acb\u4e86\u53d8\u5f02\u5206\u6790\u4f5c\u4e3a\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7528\u4ee5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6458\u8981\u662f\u5426\u53cd\u6620\u4e86\u7a0b\u5e8f\u884c\u4e3a\u800c\u975e\u8868\u9762\u7684\u6587\u5b57\u6a21\u5f0f\u3002"}}
{"id": "2602.17914", "categories": ["cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17914", "abs": "https://arxiv.org/abs/2602.17914", "authors": ["Zhuocheng Gan", "Yifan Wang"], "title": "Efficient Filtered-ANN via Learning-based Query Planning", "comment": null, "summary": "Filtered ANN search is an increasingly important problem in vector retrieval, yet systems face a difficult trade-off due to the execution order: Pre-filtering (filtering first, then ANN over the passing subset) requires expensive per-predicate index construction, while post-filtering (ANN first, then filtering candidates) may waste computation and lose recall under low selectivity due to insufficient candidates after filtering. We introduce a learning-based query planning framework that dynamically selects the most effective execution plan for each query, using lightweight predictions derived from dataset and query statistics (e.g., dimensionality, corpus size, distribution features, and predicate statistics). The framework supports diverse filter types, including categorical/keyword and range predicates, and is generic to use any backend ANN index. Experiments show that our method achieves up to 4x acceleration with >= 90% recall comparing to the strong baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u67e5\u8be2\u89c4\u5212\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u52a8\u6001\u9009\u62e9\u6700\u6709\u6548\u7684\u6267\u884c\u8ba1\u5212\u3002\u901a\u8fc7\u4f7f\u7528\u4ece\u6570\u636e\u96c6\u548c\u67e5\u8be2\u7edf\u8ba1\u4fe1\u606f\u4e2d\u5f97\u51fa\u7684\u8f7b\u91cf\u7ea7\u9884\u6d4b\uff0c\u5305\u62ec\u7ef4\u5ea6\u3001\u8bed\u6599\u5e93\u5927\u5c0f\u3001\u5206\u5e03\u7279\u5f81\u548c\u8c13\u8bcd\u7edf\u8ba1\u7b49\uff0c\u6765\u652f\u6301\u591a\u79cd\u8fc7\u6ee4\u7c7b\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5f3a\u5927\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u630190%\u4ee5\u4e0a\u53ec\u56de\u7387\u7684\u540c\u65f6\uff0c\u53ef\u5b9e\u73b0\u9ad8\u8fbe4\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u5728\u5411\u91cf\u68c0\u7d22\u4e2d\uff0c\u8fc7\u6ee4\u540e\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u662f\u4e00\u4e2a\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u95ee\u9898\u3002\u7136\u800c\uff0c\u7cfb\u7edf\u9762\u4e34\u7740\u7531\u4e8e\u6267\u884c\u987a\u5e8f\u5bfc\u81f4\u7684\u4e00\u4e2a\u96be\u9898\uff1a\u9884\u8fc7\u6ee4\uff08\u5148\u8fc7\u6ee4\u540e\u8fdb\u884c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff09\u9700\u8981\u6602\u8d35\u7684\u6bcf\u8c13\u8bcd\u7d22\u5f15\u6784\u5efa\u6210\u672c\uff1b\u800c\u540e\u671f\u8fc7\u6ee4\uff08\u5148\u8fdb\u884c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u540e\u518d\u8fc7\u6ee4\u5019\u9009\u8005\uff09\u53ef\u80fd\u56e0\u8fc7\u6ee4\u540e\u5019\u9009\u8005\u4e0d\u8db3\u800c\u5728\u4f4e\u9009\u62e9\u6027\u4e0b\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5e76\u4e27\u5931\u53ec\u56de\u7387\u3002", "method": "\u4f5c\u8005\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u67e5\u8be2\u89c4\u5212\u6846\u67b6\uff0c\u5b83\u80fd\u5229\u7528\u6765\u81ea\u6570\u636e\u96c6\u548c\u67e5\u8be2\u7edf\u8ba1\u6570\u636e\uff08\u5982\u7ef4\u5ea6\u3001\u8bed\u6599\u5e93\u5927\u5c0f\u3001\u5206\u5e03\u7279\u6027\u53ca\u8c13\u8bcd\u7edf\u8ba1\uff09\u7684\u8f7b\u91cf\u7ea7\u9884\u6d4b\uff0c\u4e3a\u6bcf\u6b21\u67e5\u8be2\u52a8\u6001\u5730\u6311\u9009\u51fa\u6700\u4f18\u6267\u884c\u65b9\u6848\u3002\u6b64\u6846\u67b6\u517c\u5bb9\u591a\u79cd\u7c7b\u578b\u7684\u8fc7\u6ee4\u5668\uff0c\u4f8b\u5982\u5206\u7c7b/\u5173\u952e\u8bcd\u4ee5\u53ca\u8303\u56f4\u8c13\u8bcd\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u7528\u4efb\u4f55\u540e\u7aefANN\u7d22\u5f15\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u5176\u4ed6\u5f3a\u52b2\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u81f3\u5c1190%\u53ec\u56de\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6700\u9ad8\u53ef\u8fbe\u81f34\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7075\u6d3b\u9ad8\u6548\u7684\u67e5\u8be2\u89c4\u5212\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u9ad8\u53ec\u56de\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u8fc7\u6ee4\u5f0f\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.17774", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17774", "abs": "https://arxiv.org/abs/2602.17774", "authors": ["Wael Al-Manasrah", "Zuhair AlSader", "Tim Brecht", "Ahmed Alquraan", "Samer Al-Kiswany"], "title": "Message-Oriented Middleware Systems: Technology Overview", "comment": null, "summary": "We present a comprehensive characterization study of open-source message-oriented middleware (MOM) systems. We followed a rigorous methodology to select and study ten popular and diverse MOM systems. For each system, we examine 42 features with a total of 134 different options. We found that MOM systems have evolved to provide a framework for modern cloud applications through high flexibility and configurability and by offering core building blocks for complex applications including transaction support, active messaging, resource management, flow control, and native support for multi-tenancy. We also identify that there is an opportunity for the community to consolidate its efforts on fewer open-source projects.\n  We have also created an annotated data set that makes it easy to verify our findings, which can also be used to help practitioners and developers understand and compare the features of different systems. For a wider impact, we make our data set publicly available.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u5341\u4e2a\u5f00\u6e90\u9762\u5411\u6d88\u606f\u7684\u4e2d\u95f4\u4ef6\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7279\u5f81\u7814\u7a76\uff0c\u53d1\u73b0\u8fd9\u4e9b\u7cfb\u7edf\u901a\u8fc7\u63d0\u4f9b\u9ad8\u7075\u6d3b\u6027\u548c\u53ef\u914d\u7f6e\u6027\u4ee5\u53ca\u4e3a\u590d\u6742\u5e94\u7528\u63d0\u4f9b\u6838\u5fc3\u6784\u5efa\u5757\u800c\u6f14\u8fdb\uff0c\u4ee5\u652f\u6301\u73b0\u4ee3\u4e91\u5e94\u7528\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u521b\u5efa\u4e86\u4e00\u4e2a\u5e26\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u5176\u516c\u5f00\uff0c\u4ee5\u4fbf\u9a8c\u8bc1\u5176\u53d1\u73b0\u5e76\u5e2e\u52a9\u4ece\u4e1a\u8005\u548c\u5f00\u53d1\u8005\u7406\u89e3\u53ca\u6bd4\u8f83\u4e0d\u540c\u7cfb\u7edf\u7684\u7279\u6027\u3002", "motivation": "\u4e3a\u4e86\u5168\u9762\u4e86\u89e3\u5f00\u6e90\u9762\u5411\u6d88\u606f\u7684\u4e2d\u95f4\u4ef6\uff08MOM\uff09\u7cfb\u7edf\u7684\u7279\u70b9\u548c\u53d1\u5c55\u8d8b\u52bf\uff0c\u7814\u7a76\u56e2\u961f\u9009\u62e9\u4e86\u5341\u4e2a\u6d41\u884c\u7684\u4e14\u591a\u6837\u5316\u7684MOM\u7cfb\u7edf\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "method": "\u7814\u7a76\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u4e25\u8c28\u7684\u65b9\u6cd5\u6765\u9009\u62e9\u548c\u5206\u6790\u8fd9\u5341\u4e2aMOM\u7cfb\u7edf\uff0c\u9488\u5bf9\u6bcf\u4e2a\u7cfb\u7edf\u8003\u5bdf\u4e8642\u9879\u7279\u5f81\u5171\u8ba1134\u4e2a\u4e0d\u540c\u7684\u9009\u9879\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cMOM\u7cfb\u7edf\u5df2\u7ecf\u53d1\u5c55\u6210\u4e3a\u80fd\u591f\u4e3a\u73b0\u4ee3\u4e91\u5e94\u7528\u7a0b\u5e8f\u63d0\u4f9b\u6846\u67b6\u7684\u6280\u672f\uff0c\u901a\u8fc7\u63d0\u4f9b\u9ad8\u5ea6\u7684\u7075\u6d3b\u6027\u4e0e\u53ef\u914d\u7f6e\u6027\uff0c\u5e76\u4e14\u4e3a\u590d\u6742\u7684\u5e94\u7528\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u5305\u62ec\u4e8b\u52a1\u652f\u6301\u3001\u4e3b\u52a8\u6d88\u606f\u4f20\u9012\u3001\u8d44\u6e90\u7ba1\u7406\u3001\u6d41\u91cf\u63a7\u5236\u4ee5\u53ca\u591a\u79df\u6237\u539f\u751f\u652f\u6301\u5728\u5185\u7684\u6838\u5fc3\u6784\u5efa\u6a21\u5757\u3002\u540c\u65f6\u6307\u51fa\u793e\u533a\u6709\u673a\u4f1a\u96c6\u4e2d\u7cbe\u529b\u4e8e\u66f4\u5c11\u7684\u5f00\u6e90\u9879\u76ee\u4e0a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u63ed\u793a\u4e86MOM\u7cfb\u7edf\u5728\u652f\u6301\u73b0\u4ee3\u4e91\u5e94\u7528\u65b9\u9762\u7684\u8fdb\u6b65\uff0c\u800c\u4e14\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u6807\u6ce8\u6570\u636e\u96c6\u4fc3\u8fdb\u4e86\u4e1a\u754c\u5bf9\u4e8e\u8fd9\u4e9b\u7cfb\u7edf\u7279\u6027\u7684\u7406\u89e3\u548c\u6bd4\u8f83\u3002"}}
{"id": "2602.17856", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17856", "abs": "https://arxiv.org/abs/2602.17856", "authors": ["Hamideh Ghanadian", "Amin Kamali", "Mohammad Hossein Tekieh"], "title": "Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems", "comment": null, "summary": "This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6765\u6539\u8fdb\u79d1\u5b66\u6587\u732e\u804a\u5929\u673a\u5668\u4eba\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5411\u91cf\u548c\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u5e76\u5c55\u793a\u4e86\u6df7\u5408RAG\u7cfb\u7edf\u5728\u63d0\u9ad8\u79d1\u5b66\u77e5\u8bc6\u53ef\u8bbf\u95ee\u6027\u548c\u652f\u6301\u5faa\u8bc1\u51b3\u7b56\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5982\u4f55\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u6765\u63d0\u5347\u79d1\u5b66\u6587\u732e\u804a\u5929\u673a\u5668\u4eba\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u7ed3\u5408\u7ed3\u6784\u5316\uff08\u56fe\uff09\u548c\u975e\u7ed3\u6784\u5316\uff08\u5411\u91cf\uff09\u6570\u636e\u5e93\u4ee5\u66f4\u6709\u6548\u5730\u6839\u636e\u7814\u7a76\u76ee\u6807\u7b5b\u9009\u8d44\u6e90\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u63a5\u5165\u79d1\u5b66\u6587\u7ae0\u53ca\u7070\u8272\u6587\u732e\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c\u5e76\u5bf9\u5355\u6587\u6863\u4e0a\u4f20\u4e0e\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u68c0\u7d22\u4e24\u79cd\u5e94\u7528\u573a\u666f\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002\u8bc4\u4f30\u57fa\u51c6\u96c6\u7531GPT\u6a21\u578b\u751f\u6210\uff0c\u5e76\u5bf9\u9009\u5b9a\u8f93\u51fa\u8fdb\u884c\u6807\u6ce8\u4ee5\u4fbf\u8bc4\u4ef7\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6df7\u5408\u578bRAG\u7cfb\u7edf\u5728\u63d0\u9ad8\u68c0\u7d22\u51c6\u786e\u5ea6\u548c\u54cd\u5e94\u76f8\u5173\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u5404\u81ea\u7684\u5f3a\u9879\u4e0e\u5c40\u9650\u6027\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u6df7\u5408RAG\u7cfb\u7edf\u5c55\u73b0\u4e86\u6539\u5584\u79d1\u5b66\u77e5\u8bc6\u83b7\u53d6\u9014\u5f84\u548c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u505a\u51b3\u5b9a\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.17680", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17680", "abs": "https://arxiv.org/abs/2602.17680", "authors": ["Yujia Wang", "Jihong Guan", "Wengen Li", "Shuigeng Zhou", "Xuhong Wang"], "title": "BioBridge: Bridging Proteins and Language for Enhanced Biological Reasoning with LLMs", "comment": null, "summary": "Existing Protein Language Models (PLMs) often suffer from limited adaptability to multiple tasks and exhibit poor generalization across diverse biological contexts. In contrast, general-purpose Large Language Models (LLMs) lack the capability to interpret protein sequences and fall short in domain-specific knowledge, limiting their capacity for effective biosemantic reasoning. To combine the advantages of both, we propose BioBridge, a domain-adaptive continual pretraining framework for protein understanding. This framework employs Domain-Incremental Continual Pre-training (DICP) to infuse protein domain knowledge and general reasoning corpus into a LLM simultaneously, effectively mitigating catastrophic forgetting. Cross-modal alignment is achieved via a PLM-Projector-LLM pipeline, which maps protein sequence embeddings into the semantic space of the language model. Ultimately, an end-to-end optimization is adopted to uniformly support various tasks, including protein property prediction and knowledge question-answering. Our proposed BioBridge demonstrates performance comparable to that of mainstream PLMs on multiple protein benchmarks, such as EC and BindingDB. It also achieves results on par with LLMs on general understanding tasks like MMLU and RACE. This showcases its innovative advantage of combining domain-specific adaptability with general-purpose language competency.", "AI": {"tldr": "\u63d0\u51fa\u4e86BioBridge\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u589e\u91cf\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u6280\u672f\uff0c\u7ed3\u5408\u4e86\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u9886\u57df\u77e5\u8bc6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5728\u591a\u79cd\u86cb\u767d\u8d28\u76f8\u5173\u4efb\u52a1\u4ee5\u53ca\u4e00\u822c\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u4f18\u79c0\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u9002\u5e94\u591a\u4efb\u52a1\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u800c\u901a\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7f3a\u4e4f\u89e3\u91ca\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u80fd\u529b\u53ca\u9886\u57df\u7279\u5b9a\u7684\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5176\u751f\u7269\u8bed\u4e49\u63a8\u7406\u7684\u6709\u6548\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u91c7\u7528\u9886\u57df\u589e\u91cf\u6301\u7eed\u9884\u8bad\u7ec3\uff08DICP\uff09\u65b9\u6cd5\uff0c\u540c\u65f6\u5c06\u86cb\u767d\u8d28\u9886\u57df\u77e5\u8bc6\u4e0e\u901a\u7528\u63a8\u7406\u8bed\u6599\u5e93\u6ce8\u5165\u5230\u4e00\u4e2a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\uff1b\u901a\u8fc7PLM-Projector-LLM\u7ba1\u9053\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u5c06\u86cb\u767d\u8d28\u5e8f\u5217\u5d4c\u5165\u6620\u5c04\u5230\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7a7a\u95f4\uff1b\u91c7\u53d6\u7aef\u5230\u7aef\u4f18\u5316\u7b56\u7565\u652f\u6301\u591a\u79cd\u4efb\u52a1\u6267\u884c\u3002", "result": "BioBridge\u5728\u591a\u4e2a\u86cb\u767d\u8d28\u57fa\u51c6\u6d4b\u8bd5\u5982EC\u3001BindingDB\u4e0a\u8868\u73b0\u51fa\u4e0e\u4e3b\u6d41PLM\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u4e00\u822c\u7406\u89e3\u4efb\u52a1\u5982MMLU\u3001RACE\u4e0a\u4e5f\u8fbe\u5230\u4e86\u4e0eLLM\u76f8\u5f53\u7684\u7ed3\u679c\u3002", "conclusion": "BioBridge\u6210\u529f\u5730\u7ed3\u5408\u4e86\u9886\u57df\u7279\u5b9a\u7684\u9002\u5e94\u6027\u548c\u901a\u7528\u8bed\u8a00\u80fd\u529b\u7684\u4f18\u52bf\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5904\u7406\u5404\u79cd\u4efb\u52a1\u65f6\u7684\u521b\u65b0\u4f18\u52bf\u3002"}}
{"id": "2602.18274", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.18274", "abs": "https://arxiv.org/abs/2602.18274", "authors": ["Viktoriia Makovska", "Ihor Michurin", "Mariia Tokhtamysh", "George Fletcher", "Julia Stoyanovich"], "title": "Seasoning Data Modeling Education with GARLIC: A Participatory Co-Design Framework", "comment": "DataEd'26: 5th International Workshop on Data Systems Education", "summary": "Entity-Relationship (ER) modeling is commonly taught as a primarily technical activity, despite its central role in shaping how data systems represent people, processes, and institutions. Prior research in participatory design demonstrates that involving diverse stakeholders in modeling can surface tacit knowledge, challenge implicit assumptions, and produce more inclusive data representations. However, database education currently lacks structured pedagogical approaches for teaching participatory ER modeling in practice.\n  We introduce the GARLIC methodology for teaching and learning participatory ER modeling. GARLIC adapts and extends the ONION participatory ER modeling framework of Makovska et al.(HILDA 2025) into a workshop-based learning format that combines role-playing, collaborative synthesis, guided critique, and iterative refinement. GARLIC is designed to develop both technical modeling skills and critical awareness of the social and ethical dimensions of data representation. GARLIC lowers the barrier to participatory ER modeling and equips students with practical skills for collaborative, inclusive data model design.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aGARLIC\u7684\u6559\u5b66\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u3001\u534f\u4f5c\u7efc\u5408\u3001\u5f15\u5bfc\u6279\u5224\u548c\u8fed\u4ee3\u6539\u8fdb\u7b49\u73af\u8282\uff0c\u6559\u6388\u53c2\u4e0e\u5f0f\u5b9e\u4f53\u5173\u7cfb\uff08ER\uff09\u5efa\u6a21\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u57f9\u517b\u5b66\u751f\u7684\u5efa\u6a21\u6280\u672f\u80fd\u529b\uff0c\u8fd8\u589e\u5f3a\u4e86\u4ed6\u4eec\u5bf9\u6570\u636e\u8868\u793a\u4e2d\u793e\u4f1a\u4e0e\u4f26\u7406\u7ef4\u5ea6\u7684\u8ba4\u8bc6\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5e93\u6559\u80b2\u5728\u6559\u6388\u53c2\u4e0e\u5f0fER\u5efa\u6a21\u65b9\u9762\u7f3a\u4e4f\u7ed3\u6784\u5316\u7684\u6559\u5b66\u65b9\u6cd5\u3002\u9274\u4e8eER\u5efa\u6a21\u5728\u5b9a\u4e49\u6570\u636e\u7cfb\u7edf\u5982\u4f55\u5448\u73b0\u4eba\u3001\u8fc7\u7a0b\u548c\u673a\u6784\u65b9\u9762\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\uff0c\u5f15\u5165\u66f4\u5305\u5bb9\u7684\u6570\u636e\u8868\u793a\u65b9\u5f0f\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002", "method": "\u63d0\u51fa\u4e86GARLIC\u65b9\u6cd5\u8bba\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5de5\u4f5c\u574a\u7684\u5b66\u4e60\u5f62\u5f0f\uff0c\u7ed3\u5408\u4e86\u89d2\u8272\u626e\u6f14\u3001\u5408\u4f5c\u5408\u6210\u3001\u6307\u5bfc\u6027\u6279\u8bc4\u53ca\u53cd\u590d\u7cbe\u70bc\u7b49\u5143\u7d20\u6765\u6559\u6388\u53c2\u4e0e\u5f0fER\u5efa\u6a21\u3002", "result": "GARLIC\u65b9\u6cd5\u964d\u4f4e\u4e86\u53c2\u4e0e\u5f0fER\u5efa\u6a21\u7684\u5165\u95e8\u95e8\u69db\uff0c\u5e76\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e86\u534f\u4f5c\u8bbe\u8ba1\u5305\u5bb9\u6027\u6570\u636e\u6a21\u578b\u7684\u5b9e\u9645\u6280\u80fd\u3002", "conclusion": "GARLIC\u65b9\u6cd5\u8bba\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u9014\u5f84\uff0c\u4ee5\u4fc3\u8fdb\u53c2\u4e0e\u5f0fER\u5efa\u6a21\u7684\u5b66\u4e60\u4e0e\u5b9e\u8df5\uff0c\u540c\u65f6\u589e\u5f3a\u5b66\u751f\u5bf9\u4e8e\u6570\u636e\u8868\u793a\u80cc\u540e\u6f5c\u5728\u7684\u793e\u4f1a\u4f26\u7406\u95ee\u9898\u7684\u7406\u89e3\u3002"}}
{"id": "2602.17808", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.17808", "abs": "https://arxiv.org/abs/2602.17808", "authors": ["Nathan Ng", "Walid A. Hanafy", "Prashanthi Kadambi", "Balachandra Sunil", "Ayush Gupta", "David Irwin", "Yogesh Simmhan", "Prashant Shenoy"], "title": "Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs", "comment": null, "summary": "IoT applications are increasingly relying on on-device AI accelerators to ensure high performance, especially in limited connectivity and safety-critical scenarios. However, the limited on-chip memory of these accelerators forces inference runtimes to swap model segments between host and accelerator memory, substantially inflating latency. While collaborative processing by partitioning the model processing between CPU and accelerator resources can reduce accelerator memory pressure and latency, naive partitioning may worsen end-to-end latency by either shifting excessive computation to the CPU or failing to sufficiently curb swapping, a problem that is further amplified in multi-tenant and dynamic environments.\n  To address these issues, we present SwapLess, a system for adaptive, multi-tenant TPU-CPU collaborative inference for memory-constrained Edge TPUs. SwapLess utilizes an analytic queueing model that captures partition-dependent CPU/TPU service times as well as inter- and intra-model swapping overheads across different workload mixes and request rates. Using this model, SwapLess continuously adjusts both the partition point and CPU core allocation online to minimize end-to-end response time with low decision overhead. An implementation on Edge TPU-equipped platforms demonstrates that SwapLess reduces mean latency by up to 63.8% for single-tenant workloads and up to 77.4% for multi-tenant workloads relative to the default Edge TPU compiler.", "AI": {"tldr": "SwapLess\u7cfb\u7edf\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u6a21\u578b\u5904\u7406\u5728CPU\u548cTPU\u4e4b\u95f4\u7684\u5206\u914d\uff0c\u51cf\u5c11\u4e86\u8fb9\u7f18TPU\u4e0a\u8fd0\u884c\u7684AI\u5e94\u7528\u7684\u5ef6\u8fdf\uff0c\u7279\u522b\u662f\u5728\u591a\u79df\u6237\u73af\u5883\u4e0b\u3002", "motivation": "\u7269\u8054\u7f51\u5e94\u7528\u8d8a\u6765\u8d8a\u4f9d\u8d56\u4e8e\u8bbe\u5907\u4e0a\u7684AI\u52a0\u901f\u5668\u6765\u786e\u4fdd\u9ad8\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8fde\u63a5\u53d7\u9650\u548c\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u52a0\u901f\u5668\u6709\u9650\u7684\u7247\u4e0a\u5185\u5b58\u8feb\u4f7f\u63a8\u7406\u8fd0\u884c\u65f6\u8981\u5728\u4e3b\u673a\u548c\u52a0\u901f\u5668\u5185\u5b58\u4e4b\u95f4\u4ea4\u6362\u6a21\u578b\u6bb5\uff0c\u4ece\u800c\u663e\u8457\u589e\u52a0\u4e86\u5ef6\u8fdf\u3002\u867d\u7136\u901a\u8fc7\u5c06\u6a21\u578b\u5904\u7406\u5728CPU\u548c\u52a0\u901f\u5668\u8d44\u6e90\u4e4b\u95f4\u8fdb\u884c\u5206\u5272\u534f\u4f5c\u5904\u7406\u53ef\u4ee5\u51cf\u5c11\u52a0\u901f\u5668\u7684\u5185\u5b58\u538b\u529b\u548c\u5ef6\u8fdf\uff0c\u4f46\u662f\u7b80\u5355\u7684\u5206\u533a\u53ef\u80fd\u4f1a\u7531\u4e8e\u5411CPU\u8f6c\u79fb\u8fc7\u591a\u8ba1\u7b97\u6216\u672a\u80fd\u5145\u5206\u51cf\u5c11\u4ea4\u6362\u800c\u6076\u5316\u7aef\u5230\u7aef\u7684\u5ef6\u8fdf\uff0c\u8fd9\u4e2a\u95ee\u9898\u5728\u591a\u79df\u6237\u548c\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u4e00\u6b65\u88ab\u653e\u5927\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSwapLess\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u9488\u5bf9\u5185\u5b58\u53d7\u9650\u7684\u8fb9\u7f18TPUs\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u3001\u591a\u79df\u6237TPU-CPU\u534f\u540c\u63a8\u65ad\u65b9\u6848\u3002SwapLess\u5229\u7528\u4e86\u4e00\u4e2a\u5206\u6790\u6392\u961f\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6355\u6349\u4e86\u6839\u636e\u5206\u533a\u53d8\u5316\u7684CPU/TPU\u670d\u52a1\u65f6\u95f4\u4ee5\u53ca\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u6df7\u5408\u548c\u8bf7\u6c42\u7387\u4e0b\u7684\u8de8\u6a21\u578b\u5185\u5916\u4ea4\u6362\u5f00\u9500\u3002\u4f7f\u7528\u8fd9\u4e2a\u6a21\u578b\uff0cSwapLess\u5728\u7ebf\u8fde\u7eed\u8c03\u6574\u5206\u533a\u70b9\u548cCPU\u6838\u5fc3\u5206\u914d\uff0c\u4ee5\u6700\u5c0f\u5316\u7aef\u5230\u7aef\u54cd\u5e94\u65f6\u95f4\uff0c\u5e76\u4fdd\u6301\u4f4e\u51b3\u7b56\u5f00\u9500\u3002", "result": "\u5728\u914d\u5907Edge TPU\u7684\u5e73\u53f0\u4e0a\u5b9e\u73b0\u8868\u660e\uff0c\u5bf9\u4e8e\u5355\u79df\u6237\u5de5\u4f5c\u8d1f\u8f7d\uff0cSwapLess\u76f8\u5bf9\u4e8e\u9ed8\u8ba4\u7684Edge TPU\u7f16\u8bd1\u5668\u6700\u591a\u53ef\u51cf\u5c1163.8%\u7684\u5e73\u5747\u5ef6\u8fdf\uff1b\u800c\u5bf9\u4e8e\u591a\u79df\u6237\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5219\u6700\u591a\u53ef\u51cf\u5c1177.4%\u7684\u5e73\u5747\u5ef6\u8fdf\u3002", "conclusion": "SwapLess\u4e3a\u89e3\u51b3\u8fb9\u7f18TPU\u5728\u6267\u884cAI\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u667a\u80fd\u5730\u7ba1\u7406CPU\u4e0eTPU\u4e4b\u95f4\u7684\u4efb\u52a1\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.18107", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18107", "abs": "https://arxiv.org/abs/2602.18107", "authors": ["Andrew Parry", "Debasis Ganguly", "Sean MacAvaney"], "title": "SuiteEval: Simplifying Retrieval Benchmarks", "comment": "5 pages, 3 figures, 2 tables, Accepted as a Demonstration to ECIR 2026", "summary": "Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.", "AI": {"tldr": "SuiteEval is introduced as a unified, end-to-end evaluation framework for information retrieval, particularly aimed at improving the reproducibility and comparability of foundation embedding models. It supports major benchmarks and streamlines the evaluation process.", "motivation": "The motivation behind this paper is to address the issues of fragmented practices in information retrieval (IR) evaluation, which hinder reproducibility and comparability, especially for foundation embedding models that need to perform well across different domains. The authors aim to provide a solution that standardizes IR evaluations and makes them more accessible, even as the need for evaluating against a wider range of benchmarks grows.", "method": "The method presented in the paper is the development of SuiteEval, a comprehensive framework designed to automate the entire IR evaluation process. This includes handling data loading, dynamic indexing, ranking, metric computation, and result aggregation. SuiteEval also allows for the addition of new benchmark suites with minimal effort and reuses on-disk indices to reduce disk usage, making it efficient and easy to use.", "result": "The results of implementing SuiteEval show that it successfully provides a standardized and streamlined approach to IR evaluation. It supports a variety of major benchmarks and reduces the amount of boilerplate code required, thereby facilitating more reproducible research in the field of information retrieval.", "conclusion": "In conclusion, the introduction of SuiteEval offers a significant advancement in the way IR systems are evaluated, by providing a unified, user-friendly, and efficient tool that enhances reproducibility and comparability. It is a valuable resource for researchers and practitioners looking to evaluate their IR models against a broad set of benchmarks."}}
{"id": "2602.17681", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17681", "abs": "https://arxiv.org/abs/2602.17681", "authors": ["Ofir Gordon", "Lior Dikstein", "Arnon Netzer", "Idan Achituve", "Hai Victor Habi"], "title": "LATMiX: Learnable Affine Transformations for Microscaling Quantization of LLMs", "comment": "24 pages, 4 figures", "summary": "Post-training quantization (PTQ) is a widely used approach for reducing the memory and compute costs of large language models (LLMs). Recent studies have shown that applying invertible transformations to activations can significantly improve quantization robustness by reducing activation outliers; however, existing approaches are largely restricted to rotation or Hadamard-based transformations. Moreover, most studies focused primarily on traditional quantization schemes, whereas modern hardware increasingly supports the microscaling (MX) data format. Attempts to combine both showed severe performance degradation, leading prior work to introduce assumptions on the transformations. In this work, we take a complementary perspective. First, we provide a theoretical analysis of transformations under MX quantization by deriving a bound on the quantization error. Our analysis emphasizes the importance of accounting for both the activation distribution and the underlying quantization structure. Building on this analysis, we propose LATMiX, a method that generalizes outlier reduction to learnable invertible affine transformations optimized using standard deep learning tools. Experiments show consistent improvements in average accuracy for MX low-bit quantization over strong baselines on a wide range of zero-shot benchmarks, across multiple model sizes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLATMiX\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u4eff\u5c04\u53d8\u6362\u6765\u51cf\u5c11\u5f02\u5e38\u503c\uff0c\u4ece\u800c\u5728MX\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "motivation": "\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u662f\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u7684\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\u3002\u5df2\u6709\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u6fc0\u6d3b\u5e94\u7528\u53ef\u9006\u53d8\u6362\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u91cf\u5316\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u9650\u4e8e\u65cb\u8f6c\u6216Hadamard\u53d8\u6362\uff0c\u5e76\u4e14\u5927\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u5728\u4f20\u7edf\u91cf\u5316\u65b9\u6848\u4e0a\uff0c\u800c\u73b0\u4ee3\u786c\u4ef6\u8d8a\u6765\u8d8a\u652f\u6301\u5fae\u7f29\u653e\uff08MX\uff09\u6570\u636e\u683c\u5f0f\u3002\u5c1d\u8bd5\u7ed3\u5408\u4e24\u8005\u65f6\u9047\u5230\u4e86\u4e25\u91cd\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u56e0\u6b64\u5148\u524d\u7684\u5de5\u4f5c\u5f15\u5165\u4e86\u5173\u4e8e\u53d8\u6362\u7684\u4e00\u4e9b\u5047\u8bbe\u3002\u672c\u7814\u7a76\u4ece\u4e92\u8865\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u9996\u5148\uff0c\u4f5c\u8005\u5bf9MX\u91cf\u5316\u4e0b\u7684\u53d8\u6362\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5f97\u51fa\u4e86\u91cf\u5316\u8bef\u5dee\u7684\u4e00\u4e2a\u754c\u9650\uff0c\u5f3a\u8c03\u4e86\u8003\u8651\u6fc0\u6d3b\u5206\u5e03\u548c\u5e95\u5c42\u91cf\u5316\u7ed3\u6784\u7684\u91cd\u8981\u6027\u3002\u57fa\u4e8e\u6b64\u5206\u6790\uff0c\u63d0\u51fa\u4e86LATMiX\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u5f02\u5e38\u503c\u51cf\u5c11\u63a8\u5e7f\u5230\u5229\u7528\u6807\u51c6\u6df1\u5ea6\u5b66\u4e60\u5de5\u5177\u4f18\u5316\u7684\u53ef\u5b66\u4e60\u7684\u53ef\u9006\u4eff\u5c04\u53d8\u6362\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5e7f\u6cdb\u7684\u96f6\u6837\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bf9\u4e8e\u591a\u79cd\u6a21\u578b\u89c4\u6a21\uff0cLATMiX\u5728MX\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u76f8\u5bf9\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u65b9\u6cd5\u6301\u7eed\u63d0\u9ad8\u4e86\u5e73\u5747\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5f15\u5165LATMiX\u65b9\u6cd5\u5c55\u793a\u4e86\u5982\u4f55\u6709\u6548\u7ed3\u5408\u53ef\u9006\u53d8\u6362\u4e0eMX\u91cf\u5316\u683c\u5f0f\uff0c\u4ee5\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u7cbe\u5ea6\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18390", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.18390", "abs": "https://arxiv.org/abs/2602.18390", "authors": ["Miika Hannula", "Teymur Ismikhanov", "Jonni Virtema"], "title": "Dichotomy for Axiomatising Inclusion Dependencies on K-Databases", "comment": null, "summary": "A relation consisting of tuples annotated by an element of a monoid K is called a K-relation. A K-database is a collection of K-relations. In this paper, we study entailment of inclusion dependencies over K-databases, where K is a positive commutative monoid. We establish a dichotomy regarding the axiomatisation of the entailment of inclusion dependencies over K-databases, based on whether the monoid K is weakly absorptive or weakly cancellative. We establish that, if the monoid is weakly cancellative then the standard axioms of inclusion dependencies are sound and complete for the implication problem. If the monoid is not weakly cancellative, it is weakly absorptive and the standard axioms of inclusion dependencies together with the weak symmetry axiom are sound and complete for the implication problem. In addition, we establish that the so-called balance axiom is further required, if one stipulates that the joint weights of each K-relation of a K-database need to be the same; this generalises the notion of a K-relation being a distribution. In conjunction with the balance axiom, weak symmetry axiom boils down to symmetry.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86K-\u6570\u636e\u5e93\u4e0a\u5305\u542b\u4f9d\u8d56\u5173\u7cfb\u7684\u8574\u542b\u95ee\u9898\uff0c\u57fa\u4e8e\u5355\u5b50K\u662f\u5426\u4e3a\u5f31\u5438\u6536\u6216\u5f31\u53ef\u7ea6\u5efa\u7acb\u4e86\u4e8c\u5206\u6cd5\uff0c\u5e76\u6307\u51fa\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u9700\u8981\u5f15\u5165\u5e73\u8861\u516c\u7406\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u7c7b\u578b\u7684\u5355\u5b50K\u4e0bK-\u6570\u636e\u5e93\u4e2d\u5305\u542b\u4f9d\u8d56\u5173\u7cfb\u7684\u8574\u542b\u95ee\u9898\u53ca\u5176\u516c\u7406\u5316\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5355\u5b50K\u7684\u6027\u8d28\uff08\u5f31\u5438\u6536\u6027\u6216\u5f31\u53ef\u7ea6\u6027\uff09\uff0c\u786e\u5b9a\u9002\u7528\u4e8eK-\u6570\u636e\u5e93\u4e2d\u5305\u542b\u4f9d\u8d56\u5173\u7cfb\u7684\u6807\u51c6\u516c\u7406\u6216\u9700\u9644\u52a0\u7684\u5f31\u5bf9\u79f0\u516c\u7406\u3001\u5e73\u8861\u516c\u7406\u7684\u6709\u6548\u6027\u548c\u5b8c\u6574\u6027\u3002", "result": "\u5982\u679c\u5355\u5b50K\u662f\u5f31\u53ef\u7ea6\u7684\uff0c\u5219\u6807\u51c6\u7684\u5305\u542b\u4f9d\u8d56\u516c\u7406\u5bf9\u4e8e\u8574\u542b\u95ee\u9898\u662f\u5b8c\u5907\u7684\uff1b\u5982\u679c\u4e0d\u662f\u5f31\u53ef\u7ea6\u800c\u662f\u5f31\u5438\u6536\u7684\u8bdd\uff0c\u5219\u9700\u8981\u52a0\u4e0a\u5f31\u5bf9\u79f0\u516c\u7406\u6765\u4fdd\u8bc1\u5b8c\u5907\u6027\u3002\u6b64\u5916\uff0c\u5728\u8981\u6c42\u6bcf\u4e2aK-\u5173\u7cfb\u8054\u5408\u6743\u91cd\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd8\u9700\u52a0\u5165\u5e73\u8861\u516c\u7406\u3002", "conclusion": "\u57fa\u4e8e\u5355\u5b50K\u7684\u4e0d\u540c\u7279\u6027\uff0c\u4e3aK-\u6570\u636e\u5e93\u4e2d\u7684\u5305\u542b\u4f9d\u8d56\u5173\u7cfb\u63d0\u4f9b\u4e86\u4e0d\u540c\u7684\u516c\u7406\u7cfb\u7edf\u4ee5\u786e\u4fdd\u5176\u8574\u542b\u95ee\u9898\u7684\u6b63\u786e\u89e3\u51b3\u3002"}}
{"id": "2602.17811", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.17811", "abs": "https://arxiv.org/abs/2602.17811", "authors": ["Guy Blelloch", "Andrew Brady", "Laxman Dhulipala", "Jeremy Fineman", "Kishen Gowda", "Chase Hutton"], "title": "Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation", "comment": "57 pages", "summary": "A low out-degree orientation directs each edge of an undirected graph with the goal of minimizing the maximum out-degree of a vertex. In the parallel batch-dynamic setting, one can insert or delete batches of edges, and the goal is to process the entire batch in parallel with work per edge similar to that of a single sequential update and with span (or depth) for the entire batch that is polylogarithmic. In this paper we present faster parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. All results herein achieve polylogarithmic depth, with high probability (whp); the focus of this paper is on minimizing the work, which varies across results.\n  Our first result is the first parallel batch-dynamic algorithm to maintain an asymptotically optimal orientation with asymptotically optimal expected work bounds, in an amortized sense, improving over the prior best work bounds of Liu et al.~[SPAA~'22] by a logarithmic factor.\n  Our second result is a $O(c \\log n)$ orientation algorithm with expected worst-case $O(\\sqrt{\\log n})$ work per edge update, where $c$ is a known upper-bound on the arboricity of the graph. This matches the best-known sequential worst-case $O(c \\log n)$ orientation algorithm given by Berglin and Brodal ~[Algorithmica~'18], albeit in expectation.\n  Our final result is a $O(c + \\log n)$-orientation algorithm with $O(\\log^2 n)$ expected worst-case work per edge update. This algorithm significantly improves upon the recent result of Ghaffari and Koo~[SPAA~'25], which maintains a $O(c)$-orientation with $O(\\log^9 n)$ worst-case work per edge whp.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u66f4\u5feb\u7684\u5e76\u884c\u6279\u52a8\u6001\u7b97\u6cd5\uff0c\u7528\u4e8e\u4fdd\u6301\u65e0\u5411\u56fe\u7684\u4f4e\u51fa\u5ea6\u5b9a\u5411\u3002\u7b2c\u4e00\u79cd\u7b97\u6cd5\u5728\u644a\u9500\u610f\u4e49\u4e0a\u5b9e\u73b0\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u5de5\u4f5c\u754c\u9650\uff1b\u7b2c\u4e8c\u79cd\u7b97\u6cd5\u4e0e\u5df2\u77e5\u7684\u6700\u4f73\u5e8f\u5217\u6700\u574f\u60c5\u51b5\u7b97\u6cd5\u76f8\u5339\u914d\uff0c\u4f46\u4ee5\u671f\u671b\u503c\u5f62\u5f0f\u7ed9\u51fa\uff1b\u7b2c\u4e09\u79cd\u7b97\u6cd5\u663e\u8457\u6539\u8fdb\u4e86\u6700\u8fd1\u7684\u7814\u7a76\u6210\u679c\uff0c\u5728\u4fdd\u6301\u76f8\u4f3c\u5b9a\u5411\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u6bcf\u6761\u8fb9\u66f4\u65b0\u6240\u9700\u7684\u5de5\u4f5c\u91cf\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u5e76\u884c\u6279\u52a8\u6001\u7b97\u6cd5\u6765\u5904\u7406\u65e0\u5411\u56fe\u4e2d\u8fb9\u7f18\u7684\u6279\u91cf\u63d2\u5165\u6216\u5220\u9664\u95ee\u9898\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u6700\u5927\u51fa\u5ea6\u7684\u540c\u65f6\u4fdd\u8bc1\u6574\u4e2a\u6279\u6b21\u5904\u7406\u7684\u6df1\u5ea6\u4e3a\u5bf9\u6570\u591a\u9879\u5f0f\u7ea7\u522b\uff0c\u5e76\u4e14\u6bcf\u4e2a\u8fb9\u7f18\u7684\u5904\u7406\u5de5\u4f5c\u91cf\u5c3d\u53ef\u80fd\u5c0f\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e09\u79cd\u4e0d\u540c\u7684\u7b97\u6cd5\uff1a1\uff09\u4e00\u79cd\u5728\u644a\u9500\u610f\u4e49\u4e0a\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u9884\u671f\u5de5\u4f5c\u754c\u9650\u7684\u65b9\u6cd5\uff1b2\uff09\u4e00\u79cd\u57fa\u4e8e\u56fe\u5f62\u6811\u6027\u4e0a\u754cc\u7684O(c log n)\u5b9a\u5411\u7b97\u6cd5\uff0c\u5176\u5355\u8fb9\u66f4\u65b0\u7684\u9884\u671f\u6700\u574f\u60c5\u51b5\u5de5\u4f5c\u91cf\u4e3aO(\u221alog n)\uff1b3\uff09\u4e00\u79cdO(c + log n)-\u5b9a\u5411\u7b97\u6cd5\uff0c\u5177\u6709O(log^2 n)\u7684\u9884\u671f\u6700\u574f\u60c5\u51b5\u5de5\u4f5c\u91cf\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u9996\u6b21\u5b9e\u73b0\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u5b9a\u5411\u548c\u5de5\u4f5c\u754c\u9650\uff0c\u8fd8\u5206\u522b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5339\u914d\u6216\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u4f73\u5e8f\u5217\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u51cf\u5c11\u6bcf\u6761\u8fb9\u66f4\u65b0\u65f6\u7684\u5de5\u4f5c\u91cf\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u5e76\u884c\u6279\u52a8\u6001\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u4f4e\u51fa\u5ea6\u5b9a\u5411\u7684\u540c\u65f6\u5927\u5e45\u5ea6\u964d\u4f4e\u5904\u7406\u5927\u89c4\u6a21\u65e0\u5411\u56fe\u53d8\u66f4\u65f6\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2602.18206", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18206", "abs": "https://arxiv.org/abs/2602.18206", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Ronghua Li", "Guoren Wang"], "title": "A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering", "comment": null, "summary": "Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u8d1f\u91c7\u6837\u63d2\u4ef6PSP-NS\uff0c\u65e8\u5728\u589e\u5f3a\u6b63\u9762\u6837\u672c\u4fe1\u53f7\uff0c\u901a\u8fc7\u5efa\u7acb\u7528\u6237-\u7269\u54c1\u4e8c\u5206\u56fe\u3001\u57fa\u4e8e\u590d\u5236\u7684\u91cd\u52a0\u6743\u751f\u6210\u6b63\u6837\u672c\u5bf9\uff0c\u5e76\u91c7\u7528\u6d3b\u52a8\u611f\u77e5\u52a0\u6743\u65b9\u6848\u6765\u66f4\u597d\u5730\u5b66\u4e60\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u504f\u597d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPSP-NS\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728Yelp\u6570\u636e\u96c6\u4e0a\u5927\u5e45\u63d0\u5347\u4e86Recall@30\u548cPrecision@30\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u7684\u9690\u5f0f\u534f\u540c\u8fc7\u6ee4\u6a21\u578b\u5927\u591a\u4f9d\u8d56\u4e8e\u8d1f\u91c7\u6837\u8bad\u7ec3\uff0c\u4f46\u5f53\u524d\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u9ad8\u8d1f\u9762\u6837\u672c\u8d28\u91cf\uff0c\u5ffd\u89c6\u4e86\u6b63\u9762\u6837\u672c\u7684\u4f5c\u7528\u3002\u6b64\u5916\uff0c\u867d\u7136\u4e00\u4e9b\u53bb\u566a\u63a8\u8350\u65b9\u6cd5\u53ef\u7528\u4e8e\u5904\u7406\u6b63\u9762\u6837\u672c\u566a\u58f0\uff0c\u4f46\u901a\u5e38\u4f1a\u5bfc\u81f4\u76d1\u7763\u4fe1\u606f\u7a00\u758f\u5316\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u7528\u6237\u6d3b\u8dc3\u5ea6\u504f\u5dee\uff0c\u9020\u6210\u5bf9\u975e\u6d3b\u8dc3\u7528\u6237\u7684\u5b66\u4e60\u4e0d\u8db3\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86PSP-NS\u3002", "method": "PSP-NS\u9996\u5148\u6784\u5efa\u4e00\u4e2a\u53cd\u6620\u5168\u5c40\u4e0e\u5c40\u90e8\u4ea4\u4e92\u7f6e\u4fe1\u5ea6\u7684\u7528\u6237-\u7269\u54c1\u4e8c\u5206\u56fe\uff1b\u63a5\u7740\uff0c\u901a\u8fc7\u57fa\u4e8e\u590d\u5236\u7684\u91cd\u52a0\u6743\u6280\u672f\u751f\u6210\u6b63\u6837\u672c\u5bf9\u4ee5\u5f3a\u5316\u6b63\u9762\u4fe1\u53f7\uff1b\u6700\u540e\uff0c\u5f15\u5165\u4e00\u79cd\u6d3b\u52a8\u611f\u77e5\u6743\u91cd\u8c03\u6574\u673a\u5236\uff0c\u4ee5\u4fbf\u66f4\u6709\u6548\u5730\u6355\u6349\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u504f\u597d\u3002", "result": "\u7406\u8bba\u5206\u6790\u4ece\u6539\u8fdb\u8fb9\u754c\u7684\u89d2\u5ea6\u89e3\u91ca\u4e86PSP-NS\u4e3a\u4f55\u80fd\u63d0\u5347\u6392\u540d\u8d28\u91cf\uff08\u5982Precision@k/Recall@k\uff09\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\uff0cPSP-NS\u76f8\u5bf9\u4e8e\u6700\u5f3a\u57fa\u7ebf\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728Yelp\u6570\u636e\u96c6\u4e2d\uff0cRecall@30\u548cPrecision@30\u5206\u522b\u63d0\u9ad8\u4e8632.11%\u548c22.90%\u3002", "conclusion": "PSP-NS\u4f5c\u4e3a\u4e00\u6b3e\u6613\u4e8e\u96c6\u6210\u5230\u591a\u79cd\u9690\u5f0fCF\u63a8\u8350\u5668\u6216\u8d1f\u91c7\u6837\u65b9\u6cd5\u4e2d\u7684\u63d2\u4ef6\uff0c\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6b63\u9762\u6837\u672c\u4fe1\u53f7\uff0c\u8fd8\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u6d3b\u8dc3\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u4ece\u800c\u6574\u4f53\u63d0\u5347\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18012", "abs": "https://arxiv.org/abs/2602.18012", "authors": ["Pragati Kumari", "Novarun Deb"], "title": "DeCEAT: Decoding Carbon Emissions for AI-driven Software Testing", "comment": null, "summary": "The increasing use of language models in automated software testing raises concerns about their environmental impact, yet existing sustainability analyses focus almost exclusively on large language models. As a result, the energy and carbon characteristics of small language models (SLMs) during test generation remain largely unexplored. To address this gap, this work introduces the DeCEAT framework, which systematically evaluates the environmental and performance trade-offs of SLMs using the HumanEval benchmark and adaptive prompt variants (based on the Anthropic template). The framework quantifies emission and time-aware behavior under controlled conditions, with CodeCarbon measuring energy consumption and carbon emissions, and unit test coverage assessing the quality of generated tests. Our results show that different SLMs exhibit distinct sustainability strengths: some prioritize lower energy use and faster execution, while others maintain higher stability or accuracy under carbon constraints. These findings demonstrate that sustainability in the generation of SLM-driven tests is multidimensional and strongly shaped by prompt design. This work provides a focused sustainability evaluation framework specifically tailored to automated SLM-based test generation, clarifying how prompt structure and model choice jointly influence environmental and performance outcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DeCEAT\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLMs)\u5728\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u73af\u5883\u5f71\u54cd\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002\u901a\u8fc7\u4f7f\u7528HumanEval\u57fa\u51c6\u548c\u81ea\u9002\u5e94\u63d0\u793a\u53d8\u4f53\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u4e0d\u540cSLMs\u5728\u53ef\u6301\u7eed\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u4f18\u52bf\uff0c\u5f3a\u8c03\u4e86\u63d0\u793a\u8bbe\u8ba1\u5bf9\u73af\u5883\u53ca\u6027\u80fd\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u4f7f\u7528\u7684\u589e\u52a0\uff0c\u5176\u73af\u5883\u5f71\u54cd\u5f15\u8d77\u4e86\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u7684\u53ef\u6301\u7eed\u6027\u5206\u6790\u51e0\u4e4e\u53ea\u96c6\u4e2d\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u3002\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u8db3\u8ff9\u7279\u6027\u4ecd\u5f85\u63a2\u7d22\u3002", "method": "\u5f00\u53d1\u4e86DeCEAT\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528HumanEval\u57fa\u51c6\u548c\u57fa\u4e8eAnthropic\u6a21\u677f\u7684\u81ea\u9002\u5e94\u63d0\u793a\u53d8\u4f53\u6765\u8bc4\u4f30SLMs\u7684\u73af\u5883\u4e0e\u6027\u80fd\u6298\u8877\u3002\u4f7f\u7528CodeCarbon\u6d4b\u91cf\u80fd\u8017\u548c\u78b3\u6392\u653e\u91cf\uff0c\u5e76\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\u8986\u76d6\u7387\u8bc4\u4f30\u751f\u6210\u6d4b\u8bd5\u7684\u8d28\u91cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u663e\u793a\uff0c\u4e0d\u540c\u7684SLMs\u5c55\u793a\u51fa\u72ec\u7279\u7684\u53ef\u6301\u7eed\u6027\u4f18\u52bf\uff1a\u4e00\u4e9b\u6a21\u578b\u4f18\u5148\u8003\u8651\u8f83\u4f4e\u7684\u80fd\u8017\u548c\u66f4\u5feb\u7684\u6267\u884c\u901f\u5ea6\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u5728\u78b3\u9650\u5236\u4e0b\u4fdd\u6301\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002\u8fd9\u8868\u660e\uff0c\u5728SLM\u9a71\u52a8\u7684\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u6301\u7eed\u6027\u662f\u591a\u7ef4\u5ea6\u7684\uff0c\u5e76\u4e14\u53d7\u5230\u63d0\u793a\u8bbe\u8ba1\u7684\u5f3a\u70c8\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u57fa\u4e8eSLM\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e13\u95e8\u5b9a\u5236\u7684\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u9610\u660e\u4e86\u63d0\u793a\u7ed3\u6784\u548c\u6a21\u578b\u9009\u62e9\u5982\u4f55\u5171\u540c\u4f5c\u7528\u4e8e\u73af\u5883\u548c\u6027\u80fd\u7ed3\u679c\u3002"}}
{"id": "2602.17682", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17682", "abs": "https://arxiv.org/abs/2602.17682", "authors": ["Peng Sun", "Xinyi Shang", "Tao Lin", "Zhiqiang Shen"], "title": "Duality Models: An Embarrassingly Simple One-step Generation Paradigm", "comment": "https://github.com/LINs-lab/DuMo", "summary": "Consistency-based generative models like Shortcut and MeanFlow achieve impressive results via a target-aware design for solving the Probability Flow ODE (PF-ODE). Typically, such methods introduce a target time $r$ alongside the current time $t$ to modulate outputs between a local multi-step derivative ($r = t$) and a global few-step integral ($r = 0$). However, the conventional \"one input, one output\" paradigm enforces a partition of the training budget, often allocating a significant portion (e.g., 75% in MeanFlow) solely to the multi-step objective for stability. This separation forces a trade-off: allocating sufficient samples to the multi-step objective leaves the few-step generation undertrained, which harms convergence and limits scalability. To this end, we propose Duality Models (DuMo) via a \"one input, dual output\" paradigm. Using a shared backbone with dual heads, DuMo simultaneously predicts velocity $v_t$ and flow-map $u_t$ from a single input $x_t$. This applies geometric constraints from the multi-step objective to every sample, bounding the few-step estimation without separating training objectives, thereby significantly improving stability and efficiency. On ImageNet 256 $\\times$ 256, a 679M Diffusion Transformer with SD-VAE achieves a state-of-the-art (SOTA) FID of 1.79 in just 2 steps. Code is available at: https://github.com/LINs-lab/DuMo", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18221", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18221", "abs": "https://arxiv.org/abs/2602.18221", "authors": ["Teddy Lazebnik"], "title": "The Economical-Ecological Benefits of Matching Non-matching Socks", "comment": null, "summary": "Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \\say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u91cf\u5316\u4e86\u914d\u5bf9\u4e0d\u5339\u914d'\u5b64\u513f'\u889c\u5b50\u7684\u7ecf\u6d4e\u548c\u751f\u6001\u4ef7\u503c\uff0c\u4ee5\u53ca\u963b\u6b62\u8fd9\u79cd\u884c\u4e3a\u7684\u793e\u4f1a\u6210\u672c\u3002\u901a\u8fc7\u5c06\u889c\u5b50\u6240\u6709\u6743\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u7684\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u5b9e\u5730\u7814\u7a76\u548c\u8ba1\u7b97\u673a\u6a21\u62df\u8bc4\u4f30\uff0c\u7814\u7a76\u53d1\u73b0\u4e25\u683c\u914d\u5bf9\u770b\u4f3c\u8282\u7701\u8d44\u6e90\u5b9e\u5219\u5bfc\u81f4\u8bb8\u591a\u6ca1\u6709\u889c\u5b50\u7a7f\u7684\u65e5\u5b50\uff0c\u800c\u63a7\u5236\u4e0d\u5339\u914d\u5bb9\u5fcd\u5ea6\u5219\u53ef\u4ee5\u7ef4\u6301\u4f7f\u7528\u5e76\u51cf\u5c11\u6d6a\u8d39\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u7531\u4e8e\u5355\u53ea\u889c\u5b50\u4e22\u5931\u800c\u5bfc\u81f4\u7684\u6d6a\u8d39\u95ee\u9898\uff0c\u63a2\u7d22\u901a\u8fc7\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u6765\u51cf\u5c11\u6d6a\u8d39\u7684\u53ef\u80fd\u6027\u53ca\u5176\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u884c\u4e3a\u7814\u7a76\u4f30\u8ba1\u4eba\u4eec\u5bf9\u889c\u5b50\u4e0d\u5339\u914d\u7684\u654f\u611f\u6027\u548c\u504f\u597d\u591a\u6837\u6027\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u673a\u6a21\u62df\u8bc4\u4f30\u4e0d\u540c\u914d\u5bf9\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8e\u889c\u5b50\u4e0d\u5339\u914d\u7684\u4e00\u5b9a\u5bb9\u5fcd\u5ea6\u6709\u52a9\u4e8e\u51cf\u5c11\u6d6a\u8d39\u5e76\u63d0\u9ad8\u889c\u5b50\u4f7f\u7528\u6548\u7387\uff0c\u800c\u4e25\u683c\u7684\u914d\u5bf9\u8981\u6c42\u867d\u7136\u8868\u9762\u4e0a\u770b\u8d77\u6765\u8282\u7ea6\u4f46\u5b9e\u9645\u9020\u6210\u4e86\u66f4\u591a\u672a\u4f7f\u7528\u7684\u65e5\u5b50\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\u548c\u6311\u6218\uff0c\u914d\u5bf9\u4e0d\u5339\u914d\u889c\u5b50\u5728\u51cf\u5c11\u6d6a\u8d39\u65b9\u9762\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2602.17683", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17683", "abs": "https://arxiv.org/abs/2602.17683", "authors": ["Irene Iele", "Giulia Romoli", "Daniele Molino", "Elena Mulero Ayll\u00f3n", "Filippo Ruffini", "Paolo Soda", "Matteo Tortora"], "title": "Probabilistic NDVI Forecasting from Sparse Satellite Time Series and Weather Covariates", "comment": null, "summary": "Accurate short-term forecasting of vegetation dynamics is a key enabler for data-driven decision support in precision agriculture. Normalized Difference Vegetation Index (NDVI) forecasting from satellite observations, however, remains challenging due to sparse and irregular sampling caused by cloud coverage, as well as the heterogeneous climatic conditions under which crops evolve. In this work, we propose a probabilistic forecasting framework specifically designed for field-level NDVI prediction under clear-sky acquisition constraints. The method leverages a transformer-based architecture that explicitly separates the modeling of historical vegetation dynamics from future exogenous information, integrating historical NDVI observations with both historical and future meteorological covariates. To address irregular revisit patterns and horizon-dependent uncertainty, we introduce a temporal-distance weighted quantile loss that aligns the training objective with the effective forecasting horizon. In addition, we incorporate cumulative and extreme-weather feature engineering to better capture delayed meteorological effects relevant to vegetation response. Extensive experiments on European satellite data demonstrate that the proposed approach consistently outperforms a diverse set of statistical, deep learning, and recent time series baselines across both point-wise and probabilistic evaluation metrics. Ablation studies further highlight the central role of target history, while showing that meteorological covariates provide complementary gains when jointly exploited. The code is available at https://github.com/arco-group/ndvi-forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u6982\u7387\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6e05\u6670\u5929\u7a7a\u6761\u4ef6\u4e0b\u8fdb\u884c\u7530\u95f4\u5c3a\u5ea6\u7684NDVI\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u5386\u53f2NDVI\u89c2\u6d4b\u503c\u4e0e\u5386\u53f2\u548c\u672a\u6765\u6c14\u8c61\u534f\u53d8\u91cf\u6765\u5904\u7406\u4e0d\u89c4\u5219\u7684\u91cd\u8bbf\u6a21\u5f0f\u548c\u89c6\u754c\u4f9d\u8d56\u6027\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u7d2f\u79ef\u548c\u6781\u7aef\u5929\u6c14\u7279\u5f81\u5de5\u7a0b\u4ee5\u66f4\u597d\u5730\u6355\u6349\u4e0e\u690d\u88ab\u54cd\u5e94\u76f8\u5173\u7684\u5ef6\u8fdf\u6c14\u8c61\u6548\u5e94\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u70b9\u4f30\u8ba1\u548c\u6982\u7387\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u591a\u79cd\u7edf\u8ba1\u3001\u6df1\u5ea6\u5b66\u4e60\u4ee5\u53ca\u6700\u8fd1\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u51c6\u786e\u7684\u77ed\u671f\u690d\u88ab\u52a8\u6001\u9884\u6d4b\u662f\u7cbe\u51c6\u519c\u4e1a\u4e2d\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u7531\u4e8e\u4e91\u5c42\u8986\u76d6\u5bfc\u81f4\u7684\u7a00\u758f\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u4ee5\u53ca\u4f5c\u7269\u751f\u957f\u8fc7\u7a0b\u4e2d\u5f02\u8d28\u6027\u7684\u6c14\u5019\u6761\u4ef6\uff0c\u4ece\u536b\u661f\u89c2\u6d4b\u6570\u636e\u4e2d\u9884\u6d4bNDVI\uff08\u5f52\u4e00\u5316\u5dee\u5f02\u690d\u88ab\u6307\u6570\uff09\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7279\u522b\u8bbe\u8ba1\u7528\u4e8e\u5728\u6674\u6717\u5929\u7a7a\u6761\u4ef6\u4e0b\u8fdb\u884c\u7530\u95f4\u7ea7NDVI\u9884\u6d4b\u7684\u6982\u7387\u9884\u6d4b\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff0c\u5c06\u5386\u53f2\u690d\u88ab\u52a8\u6001\u5efa\u6a21\u4e0e\u672a\u6765\u5916\u751f\u4fe1\u606f\u660e\u786e\u5206\u5f00\uff0c\u5e76\u7ed3\u5408\u4e86\u5386\u53f2NDVI\u89c2\u6d4b\u503c\u53ca\u5386\u53f2\u548c\u672a\u6765\u7684\u6c14\u8c61\u534f\u53d8\u91cf\u3002\u4e3a\u4e86\u89e3\u51b3\u4e0d\u89c4\u5219\u7684\u91cd\u65b0\u8bbf\u95ee\u6a21\u5f0f\u548c\u89c6\u754c\u4f9d\u8d56\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u65f6\u95f4\u8ddd\u79bb\u52a0\u6743\u5206\u4f4d\u6570\u635f\u5931\uff0c\u4f7f\u5f97\u8bad\u7ec3\u76ee\u6807\u4e0e\u5b9e\u9645\u9884\u6d4b\u8303\u56f4\u76f8\u5339\u914d\u3002\u6b64\u5916\uff0c\u8fd8\u52a0\u5165\u4e86\u7d2f\u79ef\u6027\u548c\u6781\u7aef\u5929\u6c14\u7279\u5f81\u5de5\u7a0b\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u6355\u6349\u5bf9\u690d\u88ab\u54cd\u5e94\u6709\u5f71\u54cd\u7684\u5ef6\u8fdf\u6c14\u8c61\u6548\u5e94\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4f7f\u7528\u6b27\u6d32\u536b\u661f\u6570\u636e\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u70b9\u4f30\u8ba1\u548c\u6982\u7387\u8bc4\u4f30\u5ea6\u91cf\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u4e00\u7cfb\u5217\u591a\u6837\u5316\u7684\u7edf\u8ba1\u3001\u6df1\u5ea6\u5b66\u4e60\u4ee5\u53ca\u6700\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6a21\u578b\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u5f3a\u8c03\u4e86\u76ee\u6807\u5386\u53f2\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u663e\u793a\u5f53\u8054\u5408\u5229\u7528\u65f6\u6c14\u8c61\u534f\u53d8\u91cf\u63d0\u4f9b\u4e86\u4e92\u8865\u7684\u589e\u76ca\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u6982\u7387\u9884\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u6539\u5584\u7530\u95f4\u7ea7\u522bNDVI\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5728\u9762\u5bf9\u7531\u4e91\u5c42\u906e\u6321\u5f15\u8d77\u7684\u6570\u636e\u7f3a\u5931\u548c\u590d\u6742\u6c14\u5019\u6761\u4ef6\u4e0b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002"}}
{"id": "2602.17834", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.17834", "abs": "https://arxiv.org/abs/2602.17834", "authors": ["Duncan Adamson", "Will Rosenbaum", "Paul G. Spirakis"], "title": "Distributed Triangle Enumeration in Hypergraphs", "comment": null, "summary": "In the last decade, subgraph detection and enumeration have emerged as a central problem in distributed graph algorithms. This is largely due to the theoretical challenges and practical applications of these problems. In this paper, we initiate the systematic study of distributed sub-hypergraph enumeration in hypergraphs. To this end, we (1)~introduce several computational models for hypergraphs that generalize the CONGEST model for graphs and evaluate their relative computational power, (2)~devise algorithms for distributed triangle enumeration in our computational models and prove their optimality in two such models, (3)~introduce classes of sparse and ``everywhere sparse'' hypergraphs and describe efficient distributed algorithms for triangle enumeration in these classes, and (4)~describe general techniques that we believe to be useful for designing efficient algorithms in our hypergraph models.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u8d85\u56fe\u4e2d\u7684\u5206\u5e03\u5f0f\u5b50\u8d85\u56fe\u679a\u4e3e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u51e0\u79cd\u8ba1\u7b97\u6a21\u578b\uff0c\u5e76\u4e3a\u8fd9\u4e9b\u6a21\u578b\u8bbe\u8ba1\u4e86\u5206\u5e03\u5f0f\u4e09\u89d2\u5f62\u679a\u4e3e\u7b97\u6cd5\uff0c\u540c\u65f6\u4ecb\u7ecd\u4e86\u7a00\u758f\u548c\"\u5904\u5904\u7a00\u758f\"\u7684\u8d85\u56fe\u7c7b\u522b\u4ee5\u53ca\u5728\u5176\u4e2d\u8fdb\u884c\u6709\u6548\u4e09\u89d2\u5f62\u679a\u4e3e\u7684\u7b97\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5b50\u56fe\u68c0\u6d4b\u548c\u679a\u4e3e\u5728\u7406\u8bba\u6311\u6218\u548c\u5b9e\u9645\u5e94\u7528\u65b9\u9762\u7684\u91cd\u8981\u6027\uff0c\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u5b83\u4eec\u5df2\u7ecf\u6210\u4e3a\u5206\u5e03\u5f0f\u56fe\u7b97\u6cd5\u7684\u6838\u5fc3\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u5bf9\u8d85\u56fe\u4e2d\u7684\u5206\u5e03\u5f0f\u5b50\u8d85\u56fe\u679a\u4e3e\u5c55\u5f00\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "1. \u63d0\u51fa\u51e0\u79cd\u6982\u62ec\u4e86\u56fe\u7684CONGEST\u6a21\u578b\u7684\u8d85\u56fe\u8ba1\u7b97\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u5b83\u4eec\u76f8\u5bf9\u7684\u8ba1\u7b97\u80fd\u529b\u3002\n2. \u5728\u63d0\u51fa\u7684\u8ba1\u7b97\u6a21\u578b\u4e2d\u8bbe\u8ba1\u5206\u5e03\u5f0f\u4e09\u89d2\u5f62\u679a\u4e3e\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u5728\u4e24\u4e2a\u8fd9\u6837\u7684\u6a21\u578b\u4e2d\u8fd9\u4e9b\u7b97\u6cd5\u7684\u6700\u4f18\u6027\u3002\n3. \u5f15\u5165\u7a00\u758f\u548c\u201c\u5904\u5904\u7a00\u758f\u201d\u7684\u8d85\u56fe\u7c7b\u522b\uff0c\u5e76\u63cf\u8ff0\u5728\u8fd9\u7c7b\u8d85\u56fe\u4e2d\u8fdb\u884c\u6709\u6548\u4e09\u89d2\u5f62\u679a\u4e3e\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\u3002\n4. \u63cf\u8ff0\u4e86\u4e00\u822c\u6280\u672f\uff0c\u8ba4\u4e3a\u8fd9\u4e9b\u6280\u672f\u5bf9\u4e8e\u5728\u6211\u4eec\u7684\u8d85\u56fe\u6a21\u578b\u4e2d\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u662f\u6709\u7528\u7684\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u4e86\u65b0\u7684\u8d85\u56fe\u8ba1\u7b97\u6a21\u578b\uff0c\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u51e0\u79cd\u6a21\u578b\u4e0b\u7684\u5206\u5e03\u5f0f\u4e09\u89d2\u5f62\u679a\u4e3e\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u6700\u4f18\u6027\uff0c\u540c\u65f6\u8fd8\u9488\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684\u7a00\u758f\u8d85\u56fe\u63d0\u51fa\u4e86\u6709\u6548\u7684\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u8d85\u56fe\u8ba1\u7b97\u6a21\u578b\u4e0e\u5206\u5e03\u5f0f\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u672c\u7814\u7a76\u4e3a\u89e3\u51b3\u5206\u5e03\u5f0f\u5b50\u8d85\u56fe\u679a\u4e3e\u95ee\u9898\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u4e00\u4e9b\u672a\u6765\u7814\u7a76\u53ef\u80fd\u91c7\u7528\u7684\u4e00\u822c\u6280\u672f\u3002"}}
{"id": "2602.18249", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18249", "abs": "https://arxiv.org/abs/2602.18249", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.\n  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.\n  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.\n  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).\n  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.\n  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.\n  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6587\u672c\u548c\u5fae\u8c03\u7684\u53cc\u6811LLM\u589e\u5f3a\u8d1f\u91c7\u6837\u65b9\u6cd5\uff08DTL-NS\uff09\uff0c\u901a\u8fc7\u79bb\u7ebf\u9519\u8bef\u8d1f\u6837\u672c\u8bc6\u522b\u6a21\u5757\u548c\u591a\u89c6\u89d2\u96be\u8d1f\u91c7\u6837\u6a21\u5757\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u4e2d\uff0c\u8d1f\u91c7\u6837\u6280\u672f\u5bf9\u6587\u672c\u4fe1\u606f\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u7684\u4f9d\u8d56\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u6587\u672c\u4fe1\u606f\u548c\u5fae\u8c03\u8fc7\u7a0b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aDTL-NS\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u90e8\u5206\uff1a\u4e00\u662f\u5229\u7528\u5c42\u6b21\u7d22\u5f15\u6811\u5c06\u534f\u540c\u7ed3\u6784\u4e0e\u6f5c\u5728\u8bed\u4e49\u4fe1\u606f\u8f6c\u6362\u4e3a\u6761\u76eeID\u7f16\u7801\u4ee5\u4f9bLLM\u63a8\u7406\uff0c\u4ece\u800c\u51c6\u786e\u8bc6\u522b\u9519\u8bef\u8d1f\u6837\u672c\uff1b\u4e8c\u662f\u7ed3\u5408\u7528\u6237-\u6761\u76ee\u504f\u597d\u5206\u6570\u53ca\u8fd9\u4e9b\u7f16\u7801\u4e2d\u7684\u6761\u76ee-\u6761\u76ee\u5c42\u7ea7\u76f8\u4f3c\u5ea6\u6765\u6316\u6398\u9ad8\u8d28\u91cf\u96be\u8d1f\u6837\u672c\uff0c\u8fdb\u800c\u63d0\u9ad8\u6a21\u578b\u533a\u5206\u80fd\u529b\u3002", "result": "\u5728Amazon-sports\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u6700\u5f3a\u57fa\u7ebf\uff0cDTL-NS\u5728Recall@20\u548cNDCG@20\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e8610.64%\u548c19.12%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u96c6\u6210\u5230\u591a\u79cd\u9690\u5f0fCF\u6a21\u578b\u548c\u8d1f\u91c7\u6837\u65b9\u6cd5\u4e2d\uff0c\u6301\u7eed\u63d0\u5347\u5b83\u4eec\u7684\u8868\u73b0\u3002", "conclusion": "DTL-NS\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5730\u51cf\u5c11\u5bf9\u4e8e\u6587\u672c\u4fe1\u606f\u53ca\u989d\u5916\u5fae\u8c03\u6b65\u9aa4\u7684\u9700\u6c42\uff0c\u540c\u65f6\u663e\u8457\u589e\u5f3a\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18190", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18190", "abs": "https://arxiv.org/abs/2602.18190", "authors": ["Jorge Melegati"], "title": "Role and Identity Work of Software Engineering Professionals in the Generative AI Era", "comment": "Accepted to the 19th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE 2026)", "summary": "The adoption of Generative AI (GenAI) suggests major changes for software engineering, including technical aspects but also human aspects of the professionals involved. One of these aspects is how individuals perceive themselves regarding their work, i.e., their work identity, and the processes they perform to form, adapt and reject these identities, i.e., identity work. Existent studies provide evidence of such identity work of software professionals triggered by the adoption of GenAI, however they do not consider differences among diverse roles, such as developers and testers. In this paper, we argue the need for considering the role as a factor defining the identity work of software professionals. To support our claim, we review some studies regarding different roles and also recent studies on how to adopt GenAI in software engineering. Then, we propose a research agenda to better understand how the role influences identity work of software professionals triggered by the adoption of GenAI, and, based on that, to propose new artifacts to support this adoption. We also discuss the potential implications for practice of the results to be obtained.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u89d2\u8272\u7684\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u7684\u5de5\u4f5c\u8eab\u4efd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u9879\u7814\u7a76\u8bae\u7a0b\u6765\u66f4\u597d\u5730\u7406\u89e3\u89d2\u8272\u5bf9GenAI\u5f15\u53d1\u7684\u8eab\u4efd\u5de5\u4f5c\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u4e3a\u8fd9\u79cd\u6280\u672f\u7684\u5e94\u7528\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\uff08GenAI\uff09\u9010\u6e10\u88ab\u5f15\u5165\u5230\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u5b83\u4e0d\u4ec5\u6539\u53d8\u4e86\u6280\u672f\u5c42\u9762\uff0c\u4e5f\u5f71\u54cd\u5230\u4e86\u4ece\u4e8b\u8be5\u9886\u57df\u7684\u4e13\u4e1a\u4eba\u58eb\u5bf9\u81ea\u5df1\u5de5\u4f5c\u7684\u770b\u6cd5\u2014\u2014\u5373\u4ed6\u4eec\u7684\u5de5\u4f5c\u8eab\u4efd\u4ee5\u53ca\u56f4\u7ed5\u6b64\u8eab\u4efd\u5f62\u6210\u3001\u8c03\u6574\u6216\u62d2\u7edd\u7684\u8fc7\u7a0b\u3002\u73b0\u6709\u7814\u7a76\u8868\u660eGenAI\u7684\u91c7\u7528\u786e\u5b9e\u89e6\u53d1\u4e86\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u7684\u8eab\u4efd\u5de5\u4f5c\u53d8\u5316\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u6ca1\u6709\u533a\u5206\u4e0d\u540c\u89d2\u8272\uff08\u5982\u5f00\u53d1\u8005\u4e0e\u6d4b\u8bd5\u8005\uff09\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\u672c\u6587\u8ba4\u4e3a\u6709\u5fc5\u8981\u5c06\u89d2\u8272\u4f5c\u4e3a\u5b9a\u4e49\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u8eab\u4efd\u5de5\u4f5c\u7684\u4e00\u4e2a\u56e0\u7d20\u6765\u8003\u8651\u3002", "method": "\u4e3a\u4e86\u652f\u6491\u8fd9\u4e00\u8bba\u70b9\uff0c\u4f5c\u8005\u4eec\u56de\u987e\u4e86\u4e00\u4e9b\u5173\u4e8e\u4e0d\u540c\u89d2\u8272\u7684\u7814\u7a76\u4ee5\u53ca\u6700\u8fd1\u5173\u4e8e\u5982\u4f55\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u91c7\u7eb3GenAI\u7684\u7814\u7a76\u3002\u57fa\u4e8e\u8fd9\u4e9b\u56de\u987e\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8bae\u7a0b\u4ee5\u66f4\u6df1\u5165\u5730\u4e86\u89e3\u89d2\u8272\u662f\u5982\u4f55\u5f71\u54cd\u7531GenAI\u91c7\u7528\u6240\u5f15\u8d77\u7684\u8eab\u4efd\u5de5\u4f5c\u7684\uff0c\u5e76\u636e\u6b64\u5efa\u8bae\u5f00\u53d1\u65b0\u7684\u5de5\u5177\u6216\u65b9\u6cd5\u6765\u4fc3\u8fdbGenAI\u7684\u91c7\u7eb3\u8fc7\u7a0b\u3002", "result": "\u6587\u7ae0\u6307\u51fa\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u7684\u65b9\u5411\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a1) \u4e0d\u540c\u89d2\u8272\u5bf9\u4e8eGenAI\u7684\u6001\u5ea6\u548c\u53cd\u5e94\u6709\u4f55\u4e0d\u540c\uff1b2) GenAI\u5982\u4f55\u5177\u4f53\u5f71\u54cd\u5404\u4e2a\u89d2\u8272\u7684\u4e13\u4e1a\u53d1\u5c55\u8def\u5f84\u548c\u4e2a\u4eba\u6210\u957f\uff1b3) \u6709\u54ea\u4e9b\u6709\u6548\u7684\u65b9\u6cd5\u53ef\u4ee5\u5e2e\u52a9\u8f6f\u4ef6\u56e2\u961f\u66f4\u597d\u5730\u9002\u5e94\u56e0GenAI\u800c\u4ea7\u751f\u7684\u53d8\u5316\u3002", "conclusion": "\u901a\u8fc7\u8ba4\u8bc6\u5230\u4e0d\u540c\u89d2\u8272\u5728\u9762\u5bf9GenAI\u65f6\u53ef\u80fd\u7ecf\u5386\u72ec\u7279\u7684\u804c\u4e1a\u8eab\u4efd\u8f6c\u53d8\u8fc7\u7a0b\uff0c\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u5236\u5b9a\u9488\u5bf9\u6027\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u4fbf\u4e8e\u5e2e\u52a9\u6240\u6709\u76f8\u5173\u65b9\u987a\u5229\u8fc7\u6e21\u81f3\u66f4\u52a0\u4f9d\u8d56\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u7684\u65b0\u5de5\u4f5c\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u8fd8\u8ba8\u8bba\u4e86\u9884\u671f\u7814\u7a76\u6210\u679c\u5bf9\u5b9e\u8df5\u53ef\u80fd\u5e26\u6765\u7684\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2602.17684", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17684", "abs": "https://arxiv.org/abs/2602.17684", "authors": ["Xiao Zhu", "Xinyu Zhou", "Boyu Zhu", "Hanxu Hu", "Mingzhe Du", "Haotian Zhang", "Huiming Wang", "Zhijiang Guo"], "title": "CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has driven recent progress in code large language models by leveraging execution-based feedback from unit tests, but its scalability is fundamentally constrained by the availability and reliability of high-quality test cases. We propose CodeScaler, an execution-free reward model designed to scale both reinforcement learning training and test-time inference for code generation. CodeScaler is trained on carefully curated preference data derived from verified code problems and incorporates syntax-aware code extraction and validity-preserving reward shaping to ensure stable and robust optimization. Across five coding benchmarks, CodeScaler improves Qwen3-8B-Base by an average of +11.72 points, outperforming binary execution-based RL by +1.82 points, and enables scalable reinforcement learning on synthetic datasets without any test cases. At inference time, CodeScaler serves as an effective test-time scaling method, achieving performance comparable to unit test approaches while providing a 10-fold reduction in latency. Moreover, CodeScaler surpasses existing reward models on RM-Bench not only in the code domain (+3.3 points), but also in general and reasoning domains (+2.7 points on average).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6267\u884c\u7684\u5956\u52b1\u6a21\u578bCodeScaler\uff0c\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u548c\u6d4b\u8bd5\u65f6\u63a8\u65ad\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5229\u7528\u9a8c\u8bc1\u8fc7\u7684\u4ee3\u7801\u95ee\u9898\u5bfc\u51fa\u7684\u504f\u597d\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u7ed3\u5408\u8bed\u6cd5\u611f\u77e5\u7684\u4ee3\u7801\u63d0\u53d6\u548c\u4fdd\u6301\u6709\u6548\u6027\u7684\u5956\u52b1\u5851\u5f62\u6280\u672f\uff0c\u4ece\u800c\u5728\u4e94\u4e2a\u7f16\u7801\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e86Qwen3-8B-Base\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u6ca1\u6709\u6d4b\u8bd5\u7528\u4f8b\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5355\u5143\u6d4b\u8bd5\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08RLVR\uff09\u867d\u7136\u4fc3\u8fdb\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u4f46\u5176\u53ef\u6269\u5c55\u6027\u53d7\u5230\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u53ef\u7528\u6027\u548c\u53ef\u9760\u6027\u7684\u9650\u5236\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0d\u4f9d\u8d56\u4e8e\u6267\u884c\u53cd\u9988\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86CodeScaler\uff0c\u4e00\u4e2a\u4e13\u4e3a\u4ee3\u7801\u751f\u6210\u8bbe\u8ba1\u7684\u65e0\u9700\u6267\u884c\u7684\u5956\u52b1\u6a21\u578b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5bf9\u4ece\u5df2\u9a8c\u8bc1\u4ee3\u7801\u95ee\u9898\u4e2d\u7cbe\u5fc3\u6311\u9009\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528\u8bed\u6cd5\u611f\u77e5\u4ee3\u7801\u63d0\u53d6\u4e0e\u4fdd\u6301\u6709\u6548\u6027\u7684\u5956\u52b1\u5851\u5f62\u6280\u672f\u4ee5\u786e\u4fdd\u4f18\u5316\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e94\u4e2a\u7f16\u7801\u57fa\u51c6\u4e0a\uff0cCodeScaler\u5e73\u5747\u63d0\u5347\u4e86Qwen3-8B-Base 11.72\u4e2a\u767e\u5206\u70b9\u7684\u8868\u73b0\uff0c\u76f8\u8f83\u4e8e\u57fa\u4e8e\u4e8c\u8fdb\u5236\u6267\u884c\u7684RL\u65b9\u6cd5\u9ad8\u51fa1.82\u4e2a\u767e\u5206\u70b9\uff1b\u540c\u65f6\uff0c\u5373\u4f7f\u662f\u5728\u6ca1\u6709\u4efb\u4f55\u6d4b\u8bd5\u7528\u4f8b\u7684\u4eba\u9020\u6570\u636e\u96c6\u4e0a\u4e5f\u80fd\u591f\u652f\u6301\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u5728\u63a8\u7406\u9636\u6bb5\uff0cCodeScaler\u4f5c\u4e3a\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u8fbe\u5230\u4e86\u4e0e\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8fd8\u5b9e\u73b0\u4e86\u5ef6\u8fdf\u964d\u4f4e\u5341\u500d\u7684\u6548\u679c\u3002", "conclusion": "CodeScaler\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u65e0\u6267\u884c\u5956\u52b1\u6a21\u578b\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u9762\u4e34\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u4ee3\u7801\u3001\u901a\u7528\u53ca\u63a8\u7406\u9886\u57df\uff0c\u663e\u793a\u51fa\u5176\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.18007", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.18007", "abs": "https://arxiv.org/abs/2602.18007", "authors": ["Jon Hu", "Thomas Jia", "Jing Zhu", "Zhendong Yu"], "title": "Joint Training on AMD and NVIDIA GPUs", "comment": null, "summary": "As large language models continue to scale, training demands on compute and system capacity grow rapidly, making single-vendor homogeneous clusters insufficient. This paper presents a technical solution for heterogeneous mixed training in AMD-NVIDIA environments. We first adopt a compatibility-oriented approach based on CPU-Forwarding Communication, with differentiated communication back-end selection across parallel groups and multi-NIC parallel data transfer. To achieve higher performance, we further propose another Device-Direct Communication approach, integrating a CPU-offloading P2P mechanism to enable direct cross-vendor GPU data transfer without host-memory staging. Experiments on LLaMA-8B and Qwen2-7B demonstrate that the proposed Device-Direct Communication approach achieves up to 98% of the throughput of an NVIDIA homogeneous system, while preserving training stability and correctness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728AMD-NVIDIA\u6df7\u5408\u73af\u5883\u4e0b\u8fdb\u884c\u5f02\u6784\u6df7\u5408\u8bad\u7ec3\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7Device-Direct Communication\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a5\u8fd1NVIDIA\u540c\u6784\u7cfb\u7edf98%\u7684\u541e\u5410\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6b63\u786e\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u7684\u4e0d\u65ad\u6269\u5927\uff0c\u5bf9\u8ba1\u7b97\u548c\u7cfb\u7edf\u5bb9\u91cf\u7684\u9700\u6c42\u8fc5\u901f\u589e\u957f\uff0c\u5355\u4e00\u4f9b\u5e94\u5546\u7684\u540c\u6784\u96c6\u7fa4\u5df2\u53d8\u5f97\u4e0d\u518d\u8db3\u591f\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u56e2\u961f\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u4e0d\u540c\u786c\u4ef6\uff08\u5982AMD\u548cNVIDIA GPU\uff09\u4e4b\u95f4\u6709\u6548\u6267\u884c\u8bad\u7ec3\u4efb\u52a1\u7684\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u91c7\u7528\u4e86\u57fa\u4e8eCPU\u8f6c\u53d1\u901a\u4fe1\u7684\u517c\u5bb9\u6027\u5bfc\u5411\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e86\u8de8\u5e76\u884c\u7ec4\u7684\u4e0d\u540c\u901a\u4fe1\u540e\u7aef\u9009\u62e9\u4ee5\u53ca\u591a\u7f51\u5361\u5e76\u884c\u6570\u636e\u4f20\u8f93\u6280\u672f\u3002\u4e3a\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\uff0c\u8fd8\u63d0\u51fa\u4e86\u76f4\u63a5\u8bbe\u5907\u95f4\u901a\u4fe1\u65b9\u6cd5\uff0c\u96c6\u6210\u4e86\u4e00\u4e2aCPU\u5378\u8f7dP2P\u673a\u5236\u6765\u5b9e\u73b0\u65e0\u9700\u4e3b\u673a\u5185\u5b58\u4ecb\u5165\u7684\u8de8\u5382\u5546GPU\u76f4\u63a5\u6570\u636e\u4f20\u8f93\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728LLaMA-8B\u548cQwen2-7B\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u76f4\u63a5\u8bbe\u5907\u95f4\u901a\u4fe1\u65b9\u6cd5\u8fbe\u5230\u4e86\u4e0eNVIDIA\u540c\u6784\u7cfb\u7edf\u51e0\u4e4e\u76f8\u540c\u7684\u541e\u5410\u91cf\uff08\u9ad8\u8fbe98%\uff09\uff0c\u540c\u65f6\u4e5f\u786e\u4fdd\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u89e3\u51b3\u4e86AMD-NVIDIA\u6df7\u5408\u73af\u5883\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u66f4\u9ad8\u6548\u3001\u66f4\u5177\u6210\u672c\u6548\u76ca\u7684\u5f02\u6784\u8ba1\u7b97\u65b9\u6848\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.18306", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18306", "abs": "https://arxiv.org/abs/2602.18306", "authors": ["Dongming Jin", "Zhi Jin", "Zheng Fang", "Linyu Li", "XiaoTian Yang", "Yuanpeng He", "Xiaohong Chen"], "title": "ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation", "comment": "22page, 7 figures", "summary": "With the rapid improvement of LLMs' coding capabilities, the bottleneck of LLM-based automated software development is shifting from generating correct code to eliciting users' requirements. Despite growing interest, the interview competence of LLMs in conversational requirements elicitation remains fully underexplored. Existing evaluations often depend on a few scenarios, real user interaction, and subjective human scoring, which hinders systematic and quantitative comparison. To address these challenges, we propose ReqElicitGym, an interactive and automatic evaluation environment for assessing interview competence in conversational requirements elicitation. Specifically, ReqElicitGym introduces a new evaluation dataset and designs both an interactive oracle user and a task evaluator. The dataset contains 101 website requirements elicitation scenarios spanning 10 application types. Both the oracle user and the task evaluator achieve high agreement with real users and expert judgment. Using our ReqElicitGym, any automated conversational requirements elicitation approach (e.g., LLM-based agents) can be evaluated in a reproducible and quantitative manner through interaction with the environment. Based on our ReqElicitGym, we conduct a systematic empirical study on seven representative LLMs, and the results show that current LLMs still exhibit limited interview competence in uncovering implicit requirements. Particularly, they elicit less than half of the users' implicit requirements, and their effective elicitation questions often emerge in later turns of the dialogue. Besides, we found LLMs can elicit interaction and content implicit requirements, but consistently struggle with style-related requirements. We believe ReqElicitGym will facilitate the evaluation and development of automated conversational requirements elicitation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u73af\u5883ReqElicitGym\uff0c\u7528\u4e8e\u5bf9\u8bdd\u5f0f\u9700\u6c42\u83b7\u53d6\u4e2d\u7684\u8bbf\u8c08\u80fd\u529b\u7684\u4e92\u52a8\u548c\u81ea\u52a8\u8bc4\u4f30\u3002\u901a\u8fc7\u4f7f\u7528ReqElicitGym\uff0c\u7814\u7a76\u8005\u5bf9\u4e03\u79cd\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63ed\u793a\u9690\u542b\u9700\u6c42\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u98ce\u683c\u76f8\u5173\u7684\u9700\u6c42\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7f16\u7801\u80fd\u529b\u7684\u8fc5\u901f\u63d0\u5347\uff0c\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u7684\u74f6\u9888\u6b63\u4ece\u751f\u6210\u6b63\u786e\u7684\u4ee3\u7801\u8f6c\u5411\u5f15\u51fa\u7528\u6237\u7684\u9700\u6c42\u3002\u5c3d\u7ba1\u5bf9\u6b64\u5174\u8da3\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u5f0f\u9700\u6c42\u83b7\u53d6\u4e2d\u7684\u8bbf\u8c08\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7684\u8bc4\u4f30\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5c11\u6570\u573a\u666f\u3001\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\u53ca\u4e3b\u89c2\u7684\u4eba\u5de5\u8bc4\u5206\uff0c\u8fd9\u963b\u788d\u4e86\u7cfb\u7edf\u7684\u5b9a\u91cf\u6bd4\u8f83\u3002", "method": "\u63d0\u51fa\u4e86ReqElicitGym\uff0c\u4e00\u4e2a\u9488\u5bf9\u5bf9\u8bdd\u5f0f\u9700\u6c42\u83b7\u53d6\u4e2d\u8bbf\u8c08\u80fd\u529b\u8fdb\u884c\u4e92\u52a8\u4e0e\u81ea\u52a8\u5316\u8bc4\u4ef7\u7684\u65b0\u73af\u5883\u3002\u8be5\u73af\u5883\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e92\u52a8\u5f0f\u7684\u6807\u51c6\u7528\u6237\u548c\u4efb\u52a1\u8bc4\u4f30\u5668\u3002\u6570\u636e\u96c6\u5305\u542b101\u4e2a\u7f51\u7ad9\u9700\u6c42\u83b7\u53d6\u60c5\u666f\uff0c\u8986\u76d610\u79cd\u5e94\u7528\u7c7b\u578b\u3002\u6807\u51c6\u7528\u6237\u548c\u4efb\u52a1\u8bc4\u4f30\u5668\u90fd\u8fbe\u5230\u4e86\u4e0e\u771f\u5b9e\u7528\u6237\u53ca\u4e13\u5bb6\u5224\u65ad\u7684\u9ad8\u5ea6\u4e00\u81f4\u3002", "result": "\u5229\u7528ReqElicitGym\uff0c\u5bf9\u4e03\u79cd\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63ed\u793a\u7528\u6237\u9690\u542b\u9700\u6c42\u65b9\u9762\u7684\u80fd\u529b\u6709\u9650\uff0c\u80fd\u591f\u5f15\u51fa\u5c11\u4e8e\u4e00\u534a\u7684\u7528\u6237\u9690\u542b\u9700\u6c42\uff0c\u4e14\u6709\u6548\u7684\u83b7\u53d6\u95ee\u9898\u901a\u5e38\u51fa\u73b0\u5728\u5bf9\u8bdd\u7684\u540e\u671f\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5f15\u51fa\u4ea4\u4e92\u6027\u548c\u5185\u5bb9\u4e0a\u7684\u9690\u542b\u9700\u6c42\uff0c\u4f46\u5728\u5904\u7406\u98ce\u683c\u76f8\u5173\u9700\u6c42\u65f6\u59cb\u7ec8\u9047\u5230\u56f0\u96be\u3002", "conclusion": "\u7814\u7a76\u8ba4\u4e3a\uff0cReqElicitGym\u5c06\u6709\u52a9\u4e8e\u4fc3\u8fdb\u81ea\u52a8\u5316\u5bf9\u8bdd\u5f0f\u9700\u6c42\u83b7\u53d6\u65b9\u6cd5\u7684\u8bc4\u4f30\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2602.17685", "categories": ["cs.LG", "cs.RO", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2602.17685", "abs": "https://arxiv.org/abs/2602.17685", "authors": ["Agni Bandyopadhyay", "Gunther Waxenegger-Wilfing"], "title": "Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling", "comment": "Presented at Conference: IFAC Workshop on Control Aspects of Multi-Satellite Systems (CAMSAT) 2025 At: Wuerzburg", "summary": "This paper addresses the challenge of multi target active debris removal (ADR) in Low Earth Orbit (LEO) by introducing a unified coelliptic maneuver framework that combines Hohmann transfers, safety ellipse proximity operations, and explicit refueling logic. We benchmark three distinct planning algorithms Greedy heuristic, Monte Carlo Tree Search (MCTS), and deep reinforcement learning (RL) using Masked Proximal Policy Optimization (PPO) within a realistic orbital simulation environment featuring randomized debris fields, keep out zones, and delta V constraints. Experimental results over 100 test scenarios demonstrate that Masked PPO achieves superior mission efficiency and computational performance, visiting up to twice as many debris as Greedy and significantly outperforming MCTS in runtime. These findings underscore the promise of modern RL methods for scalable, safe, and resource efficient space mission planning, paving the way for future advancements in ADR autonomy.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5171\u692d\u5706\u673a\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u5730\u7403\u8f68\u9053\u4e0a\u7684\u591a\u76ee\u6807\u4e3b\u52a8\u788e\u7247\u6e05\u9664\u4efb\u52a1\u3002\u901a\u8fc7\u5728\u73b0\u5b9e\u7684\u8f68\u9053\u6a21\u62df\u73af\u5883\u4e2d\u6bd4\u8f83\u4e09\u79cd\u89c4\u5212\u7b97\u6cd5\uff08\u8d2a\u5a6a\u542f\u53d1\u5f0f\u3001\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff09\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u57fa\u4e8e\u63a9\u7801\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4efb\u52a1\u6548\u7387\u548c\u8ba1\u7b97\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u672a\u6765\u81ea\u4e3b\u5316\u7684\u7a7a\u95f4\u4efb\u52a1\u89c4\u5212\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u4f4e\u5730\u7403\u8f68\u9053\u5185\u65e5\u76ca\u589e\u957f\u7684\u7a7a\u95f4\u788e\u7247\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e3b\u52a8\u788e\u7247\u6e05\u9664\u4efb\u52a1\u7684\u5b89\u5168\u6027\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u968f\u673a\u788e\u7247\u573a\u3001\u7981\u533a\u53ca\u0394V\u9650\u5236\u7684\u771f\u5b9e\u8f68\u9053\u6a21\u62df\u73af\u5883\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bc4\u4f30\u4e86\u8d2a\u5a6a\u542f\u53d1\u5f0f\u3001\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4ee5\u53ca\u91c7\u7528\u63a9\u7801\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e09\u79cd\u4e0d\u540c\u89c4\u5212\u7b97\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5728100\u4e2a\u6d4b\u8bd5\u573a\u666f\u4e2d\uff0c\u4f7f\u7528\u63a9\u7801PPO\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u8bbf\u95ee\u6bd4\u8d2a\u5a6a\u7b97\u6cd5\u591a\u8fbe\u4e24\u500d\u7684\u76ee\u6807\u6570\u91cf\uff0c\u5e76\u4e14\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u663e\u8457\u4f18\u4e8eMCTS\u7b97\u6cd5\u3002", "conclusion": "\u73b0\u4ee3\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7279\u522b\u662f\u63a9\u7801PPO\uff0c\u5728\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u53ca\u8d44\u6e90\u9ad8\u6548\u7684\u7a7a\u95f4\u4efb\u52a1\u89c4\u5212\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u5c06\u6765\u66f4\u5148\u8fdb\u7684\u4e3b\u52a8\u788e\u7247\u6e05\u9664\u81ea\u4e3b\u5316\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.18158", "categories": ["cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.18158", "abs": "https://arxiv.org/abs/2602.18158", "authors": ["Andreas Kouloumpris", "Georgios L. Stavrinides", "Maria K. Michael", "Theocharis Theocharides"], "title": "A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum", "comment": "This version of the manuscript has been accepted for publication in Future Generation Computer Systems after peer review (Author Accepted Manuscript). It is not the final published version (Version of Record) and does not reflect any post-acceptance improvements. The Version of Record is available online at https://doi.org/10.1016/j.future.2026.108414", "summary": "A growing number of critical workflow applications leverage a streamlined edge-hub-cloud architecture, which diverges from the conventional edge computing paradigm. An edge device, in collaboration with a hub device and a cloud server, often suffices for their reliable and efficient execution. However, task allocation in this streamlined architecture is challenging due to device limitations and diverse operating conditions. Given the inherent criticality of such workflow applications, where reliability and latency are vital yet conflicting objectives, an exact task allocation approach is typically required to ensure optimal solutions. As no existing method holistically addresses these issues, we propose an exact multi-objective task allocation framework to jointly optimize the overall reliability and latency of a workflow application in the specific edge-hub-cloud architecture. We present a comprehensive binary integer linear programming formulation that considers the relative importance of each objective. It incorporates time redundancy techniques, while accounting for crucial constraints often overlooked in related studies. We evaluate our approach using a relevant real-world workflow application, as well as synthetic workflows varying in structure, size, and criticality. In the real-world application, our method achieved average improvements of 84.19% in reliability and 49.81% in latency over baseline strategies, across relevant objective trade-offs. Overall, the experimental results demonstrate the effectiveness and scalability of our approach across diverse workflow applications for the considered system architecture, highlighting its practicality with runtimes averaging between 0.03 and 50.94 seconds across all examined workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u7684\u591a\u76ee\u6807\u4efb\u52a1\u5206\u914d\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u8fb9\u7f18-\u4e2d\u5fc3-\u4e91\u67b6\u6784\u4e2d\u5de5\u4f5c\u6d41\u5e94\u7528\u7684\u6574\u4f53\u53ef\u9760\u6027\u548c\u5ef6\u8fdf\u3002\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u6848\u4f8b\u548c\u5408\u6210\u5de5\u4f5c\u6d41\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u952e\u5de5\u4f5c\u6d41\u5e94\u7528\u91c7\u7528\u7b80\u5316\u7684\u8fb9\u7f18-\u4e2d\u5fc3-\u4e91\u67b6\u6784\uff0c\u5982\u4f55\u5728\u8bbe\u5907\u9650\u5236\u548c\u591a\u6837\u5316\u7684\u64cd\u4f5c\u6761\u4ef6\u4e0b\u6709\u6548\u8fdb\u884c\u4efb\u52a1\u5206\u914d\u6210\u4e3a\u6311\u6218\u3002\u7531\u4e8e\u8fd9\u4e9b\u5e94\u7528\u5bf9\u53ef\u9760\u6027\u548c\u5ef6\u8fdf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u4f46\u8fd9\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u51b2\u7a81\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u8fd9\u4e24\u4e2a\u5173\u952e\u6307\u6807\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u4e8c\u8fdb\u5236\u6574\u6570\u7ebf\u6027\u89c4\u5212\u516c\u5f0f\u6765\u5b9e\u73b0\uff0c\u8be5\u516c\u5f0f\u8003\u8651\u4e86\u6bcf\u4e2a\u76ee\u6807\u7684\u76f8\u5bf9\u91cd\u8981\u6027\uff0c\u5e76\u4e14\u7ed3\u5408\u4e86\u65f6\u95f4\u5197\u4f59\u6280\u672f\uff0c\u540c\u65f6\u8fd8\u8003\u8651\u5230\u4e86\u76f8\u5173\u7814\u7a76\u4e2d\u7ecf\u5e38\u88ab\u5ffd\u89c6\u7684\u91cd\u8981\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u5de5\u4f5c\u6d41\u5e94\u7528\u4e2d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u7b56\u7565\uff0c\u5728\u8003\u8651\u7684\u76f8\u5173\u76ee\u6807\u6743\u8861\u4e0b\uff0c\u672c\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad8\u4e8684.19%\u7684\u53ef\u9760\u6027\u4ee5\u53ca49.81%\u7684\u5ef6\u8fdf\u964d\u4f4e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u6240\u8003\u8651\u7cfb\u7edf\u67b6\u6784\u4e0b\u7684\u591a\u79cd\u5de5\u4f5c\u6d41\u5e94\u7528\u90fd\u5177\u6709\u826f\u597d\u7684\u6548\u679c\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8fd0\u884c\u65f6\u95f4\u4ece0.03\u79d2\u523050.94\u79d2\u4e0d\u7b49\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cbe\u786e\u591a\u76ee\u6807\u4efb\u52a1\u5206\u914d\u6846\u67b6\u80fd\u591f\u5728\u8fb9\u7f18-\u4e2d\u5fc3-\u4e91\u67b6\u6784\u5185\u6709\u6548\u63d0\u5347\u5de5\u4f5c\u6d41\u5e94\u7528\u7a0b\u5e8f\u7684\u53ef\u9760\u6027\u548c\u51cf\u5c11\u5ef6\u8fdf\uff0c\u663e\u793a\u51fa\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.18288", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18288", "abs": "https://arxiv.org/abs/2602.18288", "authors": ["Jiayi Wu", "Zhengyu Wu", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering", "comment": null, "summary": "Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u62d3\u6251\u611f\u77e5\u7684\u6b63\u6837\u672c\u96c6\u6784\u5efa\u4e0e\u7279\u5f81\u4f18\u5316\u65b9\u6cd5\uff08TPSC-FO\uff09\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u8f6c\u5316\u8bef\u8d1f\u6837\u672c\u6765\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u7528\u6237\u504f\u597d\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u57fa\u4e8e\u90bb\u57df\u7684\u7279\u5f81\u4f18\u5316\u6a21\u5757\u6765\u7cbe\u70bc\u6b63\u6837\u672c\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6709\u6548\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u8d1f\u91c7\u6837\u7b56\u7565\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5982\u8fc7\u5ea6\u4f9d\u8d56\u6a21\u578b\u5f53\u524d\u7684\u8868\u793a\u80fd\u529b\u4ee5\u53ca\u672a\u80fd\u5145\u5206\u5229\u7528\u8bef\u8d1f\u6837\u672c\u4f5c\u4e3a\u6f5c\u5728\u6b63\u6837\u672c\u6765\u6307\u5bfc\u6a21\u578b\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u7528\u6237\u504f\u597d\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8003\u8651\u62d3\u6251\u793e\u533a\u7ed3\u6784\u7684\u8bef\u8d1f\u6837\u672c\u8bc6\u522b\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u62d3\u6251\u611f\u77e5\u7684\u6b63\u6837\u672c\u96c6\u6784\u5efa\u6a21\u5757\uff0c\u5229\u7528\u5dee\u5f02\u5316\u7684\u793e\u533a\u68c0\u6d4b\u7b56\u7565\u6355\u6349\u9690\u5f0f\u53cd\u9988\u4e2d\u7684\u62d3\u6251\u793e\u533a\u7ed3\u6784\uff0c\u7ed3\u5408\u4e2a\u6027\u5316\u7684\u566a\u58f0\u8fc7\u6ee4\u6280\u672f\u53ef\u9760\u5730\u8bc6\u522b\u8bef\u8d1f\u6837\u672c\u5e76\u5c06\u5176\u8f6c\u6362\u6210\u6b63\u6837\u672c\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u90bb\u57df\u7684\u7279\u5f81\u4f18\u5316\u6a21\u5757\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7ed3\u5408\u90bb\u5c45\u7279\u5f81\u6765\u7ec6\u5316\u6b63\u6837\u672c\u7279\u5f81\uff0c\u6709\u6548\u51cf\u5c11\u6b63\u6837\u672c\u4e2d\u7684\u566a\u58f0\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86TPSC-FO\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684TPSC-FO\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u901a\u8fc7\u8bc6\u522b\u5e76\u8f6c\u5316\u8bef\u8d1f\u6837\u672c\u6765\u6539\u8fdb\u6a21\u578b\u5bf9\u4e8e\u7528\u6237\u504f\u597d\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u4e14\u901a\u8fc7\u90bb\u57df\u7279\u5f81\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.18307", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.18307", "abs": "https://arxiv.org/abs/2602.18307", "authors": ["Yutong Xin", "Qiaochu Chen", "Greg Durrett", "I\u015fil Dillig"], "title": "VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean", "comment": null, "summary": "Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aVeriSoftBench\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u5305\u542b500\u4e2aLean 4\u8bc1\u660e\u4e49\u52a1\uff0c\u8fd9\u4e9b\u4e49\u52a1\u6765\u81ea\u5f00\u6e90\u5f62\u5f0f\u5316\u65b9\u6cd5\u5f00\u53d1\uff0c\u5e76\u4e14\u88ab\u5c01\u88c5\u4ee5\u4fdd\u6301\u5b9e\u9645\u5b58\u50a8\u5e93\u4e0a\u4e0b\u6587\u548c\u8de8\u6587\u4ef6\u4f9d\u8d56\u3002\u8bc4\u4f30\u663e\u793a\uff0c\u9488\u5bf9Mathlib\u98ce\u683c\u6570\u5b66\u4f18\u5316\u7684\u8bc1\u660e\u5668\u5728\u9762\u5411\u5b58\u50a8\u5e93\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff1b\u6210\u529f\u4e0e\u4f20\u9012\u6027\u5b58\u50a8\u5e93\u4f9d\u8d56\u7d27\u5bc6\u76f8\u5173\uff1b\u63d0\u4f9b\u4ec5\u9650\u4e8e\u8bc1\u660e\u4f9d\u8d56\u95ed\u5305\u7684\u7cbe\u9009\u4e0a\u4e0b\u6587\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u7279\u522b\u662f\u5728Lean\u8bed\u8a00\u4e2d\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u57fa\u4e8eLLM\u7684\u8bc1\u660e\u81ea\u52a8\u5316\u57fa\u51c6\u6d4b\u8bd5\u90fd\u662f\u4eceMathlib\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6570\u5b66\u5185\u5bb9\u4e2d\u63d0\u53d6\u7684\uff0c\u800c\u8f6f\u4ef6\u9a8c\u8bc1\u4e2d\u7684\u8bc1\u660e\u5219\u662f\u5728\u5b9a\u4e49\u4e30\u5bcc\u7684\u4ee3\u7801\u5e93\u4e2d\u5f00\u53d1\u7684\uff0c\u5e76\u4e14\u6709\u5927\u91cf\u7684\u9879\u76ee\u7279\u5b9a\u5e93\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u8d34\u8fd1\u5b9e\u9645\u8f6f\u4ef6\u9a8c\u8bc1\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30LLM\u548c\u5176\u4ed6\u8bc1\u660e\u5668\u7684\u8868\u73b0\u3002", "method": "\u521b\u5efa\u4e86VeriSoftBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b500\u4e2aLean 4\u8bc1\u660e\u4e49\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u8fd9\u4e9b\u4efb\u52a1\u6765\u6e90\u4e8e\u5f00\u653e\u6e90\u7801\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u53d1\u5c55\uff0c\u5e76\u4e14\u6253\u5305\u65f6\u4fdd\u7559\u4e86\u771f\u5b9e\u7684\u4ed3\u5e93\u80cc\u666f\u548c\u8de8\u6587\u4ef6\u4f9d\u8d56\u5173\u7cfb\u3002\u901a\u8fc7\u8fd9\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u524d\u6cbf\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ee5\u53ca\u4e13\u95e8\u7684\u8bc1\u660e\u5de5\u5177\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e3a\u9002\u5e94Mathlib\u98ce\u683c\u6570\u5b66\u800c\u8c03\u6574\u7684\u8bc1\u660e\u5de5\u5177\u5728\u8fd9\u79cd\u4ee5\u4ed3\u5e93\u4e3a\u4e2d\u5fc3\u7684\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff1b\u6210\u529f\u7684\u6982\u7387\u4e0e\u95f4\u63a5\u7684\u4ed3\u5e93\u4f9d\u8d56\u6027\u5bc6\u5207\u76f8\u5173\uff1a\u90a3\u4e9b\u8bc1\u660e\u8fc7\u7a0b\u6d89\u53ca\u5230\u5927\u91cf\u591a\u6b65\u4f9d\u8d56\u7684\u4efb\u52a1\u66f4\u96be\u89e3\u51b3\uff1b\u5f53\u63d0\u4f9b\u7684\u7cbe\u9009\u4e0a\u4e0b\u6587\u9650\u5236\u5728\u8bc1\u660e\u6240\u9700\u7684\u4f9d\u8d56\u95ed\u5305\u5185\u65f6\uff0c\u76f8\u8f83\u4e8e\u66b4\u9732\u6574\u4e2a\u4ed3\u5e93\u7684\u60c5\u51b5\uff0c\u6027\u80fd\u6709\u6240\u63d0\u5347\uff0c\u4f46\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5VeriSoftBench\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u8bc1\u660e\u5de5\u5177\u5728\u8f6f\u4ef6\u9a8c\u8bc1\u9886\u57df\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u9488\u5bf9Mathlib\u4f18\u5316\u7684\u8bc1\u660e\u5de5\u5177\u5728\u8f6f\u4ef6\u9879\u76ee\u7279\u6709\u7684\u80cc\u666f\u4e0b\u6548\u679c\u4e0d\u7406\u60f3\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4f9d\u8d56\u7ba1\u7406\u5bf9\u4e8e\u8bc1\u660e\u81ea\u52a8\u751f\u6210\u7684\u91cd\u8981\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\u901a\u8fc7\u9002\u5f53\u88c1\u526a\u8f93\u5165\u4e0a\u4e0b\u6587\u53ef\u4ee5\u6539\u5584\u7ed3\u679c\uff0c\u4e0d\u8fc7\u4ecd\u5b58\u5728\u4e0d\u5c11\u6311\u6218\u3002"}}
{"id": "2602.17695", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.17695", "abs": "https://arxiv.org/abs/2602.17695", "authors": ["Xin Yu", "Hanwen Xing", "Lingzhou Xue"], "title": "EXACT: Explicit Attribute-Guided Decoding-Time Personalization", "comment": null, "summary": "Achieving personalized alignment requires adapting large language models to each user's evolving context. While decoding-time personalization offers a scalable alternative to training-time methods, existing methods largely rely on implicit, less interpretable preference representations and impose a rigid, context-agnostic user representation, failing to account for how preferences shift across prompts. We introduce EXACT, a new decoding-time personalization that aligns generation with limited pairwise preference feedback using a predefined set of interpretable attributes. EXACT first identifies user-specific attribute subsets by maximizing the likelihood of preferred responses in the offline stage. Then, for online inference, EXACT retrieves the most semantically relevant attributes for an incoming prompt and injects them into the context to steer generation. We establish theoretical approximation guarantees for the proposed algorithm under mild assumptions, and provably show that our similarity-based retrieval mechanism effectively mitigates contextual preference shifts, adapting to disparate tasks without pooling conflicting preferences. Extensive experiments on human-annotated preference datasets demonstrate that EXACT consistently outperforms strong baselines, including preference modeling accuracy and personalized generation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u65f6\u4e2a\u6027\u5316\u65b9\u6cd5EXACT\uff0c\u5b83\u901a\u8fc7\u4f7f\u7528\u6709\u9650\u7684\u6210\u5bf9\u504f\u597d\u53cd\u9988\u548c\u4e00\u7ec4\u53ef\u89e3\u91ca\u5c5e\u6027\u6765\u5b9e\u73b0\u4e0e\u7528\u6237\u7684\u751f\u6210\u5bf9\u9f50\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u79bb\u7ebf\u8bc6\u522b\u7528\u6237\u7279\u5b9a\u7684\u5c5e\u6027\u5b50\u96c6\uff0c\u7136\u540e\u5728\u7ebf\u63a8\u7406\u65f6\u68c0\u7d22\u6700\u76f8\u5173\u7684\u5c5e\u6027\u5e76\u5c06\u5176\u6ce8\u5165\u4e0a\u4e0b\u6587\u4ee5\u6307\u5bfc\u751f\u6210\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86EXACT\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u89e3\u7801\u65f6\u4e2a\u6027\u5316\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u9690\u5f0f\u3001\u8f83\u96be\u89e3\u91ca\u7684\u504f\u597d\u8868\u793a\uff0c\u5e76\u4e14\u63d0\u4f9b\u7684\u7528\u6237\u8868\u793a\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u5f88\u597d\u5730\u9002\u5e94\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u504f\u597d\u53d8\u5316\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86EXACT\uff0c\u65e8\u5728\u5229\u7528\u66f4\u660e\u786e\u7684\u5c5e\u6027\u5b9a\u4e49\u4ee5\u53ca\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u5904\u7406\u7528\u6237\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u7684\u504f\u597d\u8f6c\u6362\u95ee\u9898\u3002", "method": "EXACT\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u79bb\u7ebf\u9636\u6bb5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u504f\u597d\u7684\u54cd\u5e94\u53ef\u80fd\u6027\u6765\u786e\u5b9a\u7528\u6237\u7279\u6709\u7684\u5c5e\u6027\u5b50\u96c6\uff1b2) \u5728\u7ebf\u63a8\u7406\u9636\u6bb5\uff0c\u6839\u636e\u63a5\u6536\u5230\u7684\u95ee\u9898\u9009\u53d6\u8bed\u4e49\u4e0a\u6700\u76f8\u5173\u7684\u5c5e\u6027\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5c5e\u6027\u52a0\u5165\u5230\u4e0a\u4e0b\u6587\u4e2d\u4ee5\u6307\u5bfc\u6a21\u578b\u751f\u6210\u66f4\u52a0\u7b26\u5408\u4e2a\u4eba\u504f\u597d\u7684\u6587\u672c\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8e\u6240\u63d0\u7b97\u6cd5\u7684\u4e00\u4e9b\u7406\u8bba\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4eba\u7c7b\u6807\u6ce8\u7684\u504f\u597d\u6570\u636e\u96c6\u4e0a\uff0cEXACT\u5728\u504f\u597d\u5efa\u6a21\u51c6\u786e\u6027\u53ca\u4e2a\u6027\u5316\u751f\u6210\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "EXACT\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u89e3\u7801\u65f6\u4e2a\u6027\u5316\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u5730\u5229\u7528\u5c11\u91cf\u7684\u504f\u597d\u53cd\u9988\u4fe1\u606f\u548c\u4e00\u7ec4\u9884\u5b9a\u4e49\u7684\u53ef\u89e3\u91ca\u5c5e\u6027\u6765\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u5355\u4e2a\u7528\u6237\u4e0d\u65ad\u53d8\u5316\u7684\u60c5\u5883\u4e0b\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2602.18357", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18357", "abs": "https://arxiv.org/abs/2602.18357", "authors": ["Wallace Albertini", "Marina Cond\u00e9 Ara\u00fajo", "J\u00falia Cond\u00e9 Ara\u00fajo", "Antonio Pedro Santos Alves", "Marcos Kalinowski"], "title": "Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation", "comment": "Author version of the paper accepted for publication at CAIN 2026", "summary": "The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u8ba1\u7f6e\u4fe1\u529f\u80fd\u6b63\u786e\u6027\uff08SCFC\uff09\u65b9\u6cd5\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u5b9a\u4e49\u5b9a\u91cf\u89c4\u8303\u9650\u503c\u3001\u8fdb\u884c\u5206\u5c42\u548c\u6982\u7387\u62bd\u6837\u3001\u5e94\u7528\u81ea\u52a9\u6cd5\u4f30\u8ba1\u6027\u80fd\u5ea6\u91cf\u7684\u7f6e\u4fe1\u533a\u95f4\u4ee5\u53ca\u8ba1\u7b97\u80fd\u529b\u6307\u6570\u56db\u4e2a\u6b65\u9aa4\u3002\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u5b9e\u9645\u5de5\u4e1aAI\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u5f97\u5230\u4e86\u4e13\u5bb6\u4eec\u5173\u4e8e\u5176\u5b9e\u7528\u6027\u3001\u6613\u7528\u6027\u548c\u91c7\u7528\u610f\u56fe\u7684\u79ef\u6781\u53cd\u9988\u3002", "motivation": "\u73b0\u6709\u7684AI\u7cfb\u7edf\u8d28\u91cf\u8bc4\u4f30\u6807\u51c6\u5982ISO/IEC 25059\u7f3a\u4e4f\u5b9e\u7528\u4e14\u7edf\u8ba1\u4e0a\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u8bc4\u4ef7\u529f\u80fd\u6027\u6b63\u786e\u6027\u3002", "method": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5373\u7edf\u8ba1\u7f6e\u4fe1\u529f\u80fd\u6b63\u786e\u6027\uff08SCFC\uff09\uff0c\u5b83\u5305\u62ec\u8bbe\u5b9a\u91cf\u5316\u89c4\u683c\u9650\u5236\u3001\u6267\u884c\u5206\u5c42\u548c\u6982\u7387\u91c7\u6837\u3001\u5229\u7528\u81ea\u52a9\u6cd5\u4f30\u7b97\u6027\u80fd\u6307\u6807\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5e76\u6700\u7ec8\u8ba1\u7b97\u51fa\u4e00\u4e2a\u80fd\u529b\u6307\u6570\u4f5c\u4e3a\u6574\u4f53\u6307\u6807\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u4e2a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5de5\u4e1aAI\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\uff0c\u4ee5\u53ca\u4e0eAI\u4e13\u5bb6\u8bbf\u8c08\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u53ef\u7528\u6027\u53ca\u5176\u6f5c\u5728\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684SCFC\u65b9\u6cd5\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u6709\u4ef7\u503c\u7684\u624b\u6bb5\uff0c\u53ef\u4ee5\u5c06\u529f\u80fd\u6027\u6b63\u786e\u7684\u8bc4\u4f30\u4ece\u70b9\u4f30\u8ba1\u8f6c\u53d8\u4e3a\u5177\u6709\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u7684\u58f0\u660e\u3002"}}
{"id": "2602.17688", "categories": ["cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.17688", "abs": "https://arxiv.org/abs/2602.17688", "authors": ["Anton Xue", "Litu Rout", "Constantine Caramanis", "Sanjay Shakkottai"], "title": "AnCoder: Anchored Code Generation via Discrete Diffusion Models", "comment": null, "summary": "Diffusion language models offer a compelling alternative to autoregressive code generation, enabling global planning and iterative refinement of complex program logic. However, existing approaches fail to respect the rigid structure of programming languages and, as a result, often produce broken programs that fail to execute. To address this, we introduce AnchorTree, a framework that explicitly anchors the diffusion process using structured, hierarchical priors native to code. Specifically, AnchorTree uses the abstract syntax tree to prioritize resolving syntactically and semantically salient tokens, such as keywords (e.g., if, while) and identifiers (e.g., variable names), thereby establishing a structural scaffold that guides the remaining generation. We validate this framework via AnCoder, a family of models showing that structurally anchored diffusion offers a parameter-efficient path to high-quality code generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAnchorTree\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u4f7f\u7528\u4ee3\u7801\u7279\u6709\u7684\u7ed3\u6784\u5316\u3001\u5206\u5c42\u5148\u9a8c\u6765\u660e\u786e\u951a\u5b9a\u6269\u6563\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u7f16\u7a0b\u8bed\u8a00\u65f6\u5f80\u5f80\u5ffd\u7565\u4e86\u5176\u4e25\u683c\u7684\u7ed3\u6784\u7279\u6027\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u7a0b\u5e8f\u5e38\u5e38\u65e0\u6cd5\u6267\u884c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u5c0a\u91cd\u7f16\u7a0b\u8bed\u8a00\u7ed3\u6784\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u65b0\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5229\u7528\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\uff0cAnchorTree\u4f18\u5148\u89e3\u51b3\u8bed\u6cd5\u548c\u8bed\u4e49\u4e0a\u663e\u8457\u7684\u6807\u8bb0\uff0c\u6bd4\u5982\u5173\u952e\u5b57\uff08\u5982if, while\uff09\u548c\u6807\u8bc6\u7b26\uff08\u5982\u53d8\u91cf\u540d\uff09\uff0c\u4ee5\u6b64\u5efa\u7acb\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u652f\u67b6\u6765\u6307\u5bfc\u540e\u7eed\u7684\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0cAnCoder\u6a21\u578b\u5bb6\u65cf\u8868\u660e\uff0c\u8fd9\u79cd\u7ed3\u6784\u951a\u5b9a\u7684\u6269\u6563\u65b9\u6cd5\u4e3a\u9ad8\u8d28\u91cf\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u6761\u53c2\u6570\u6548\u7387\u9ad8\u7684\u8def\u5f84\u3002", "conclusion": "AnchorTree\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u7ed3\u6784\u5316\u5148\u9a8c\u77e5\u8bc6\u5230\u6269\u6563\u8fc7\u7a0b\u4e2d\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u7a0b\u5e8f\u5b8c\u6574\u6027\u548c\u53ef\u6267\u884c\u6027\u3002"}}
{"id": "2602.18287", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.18287", "abs": "https://arxiv.org/abs/2602.18287", "authors": ["Andrea D'Iapico", "Monica Vitali"], "title": "Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum", "comment": null, "summary": "The environmental sustainability of Information Technology (IT) has emerged as a critical concern, driven by the need to reduce both energy consumption and greenhouse gas (GHG) emissions. In the context of cloud-native applications deployed across the cloud-edge continuum, this challenge translates into identifying energy-efficient deployment strategies that consider not only the computational demands of application components but also the environmental impact of the nodes on which they are executed. Generating deployment plans that account for these dynamic factors is non-trivial, due to fluctuations in application behaviour and variations in the carbon intensity of infrastructure nodes. In this paper, we present an approach for the automatic generation of deployment plans guided by green constraints. These constraints are derived from a continuous analysis of energy consumption patterns, inter-component communication, and the environmental characteristics of the underlying infrastructure. This paper introduces a methodology and architecture for the generation of a set of green-aware constraints that inform the scheduler to produce environmentally friendly deployment plans. We demonstrate how these constraints can be automatically learned and updated over time using monitoring data, enabling adaptive, energy-aware orchestration. The proposed approach is validated through realistic deployment scenarios of a cloud-native application, showcasing its effectiveness in reducing energy usage and associated emissions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u5206\u6790\u80fd\u8017\u6a21\u5f0f\u3001\u7ec4\u4ef6\u95f4\u901a\u4fe1\u548c\u57fa\u7840\u8bbe\u65bd\u7684\u73af\u5883\u7279\u6027\u6765\u751f\u6210\u7eff\u8272\u7ea6\u675f\uff0c\u4ece\u800c\u6307\u5bfc\u8c03\u5ea6\u5668\u751f\u6210\u73af\u4fdd\u7684\u90e8\u7f72\u8ba1\u5212\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u5e76\u66f4\u65b0\u8fd9\u4e9b\u7ea6\u675f\u6761\u4ef6\uff0c\u4ee5\u5b9e\u73b0\u8282\u80fd\u8c03\u5ea6\u3002", "motivation": "\u968f\u7740\u4fe1\u606f\u6280\u672f\u5bf9\u51cf\u5c11\u80fd\u6e90\u6d88\u8017\u548c\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u5728\u4e91-\u8fb9\u7f18\u8fde\u7eed\u4f53\u4e0a\u90e8\u7f72\u4e91\u539f\u751f\u5e94\u7528\u65f6\uff0c\u9700\u8981\u627e\u5230\u4e00\u79cd\u65e2\u8003\u8651\u5e94\u7528\u7a0b\u5e8f\u7ec4\u4ef6\u7684\u8ba1\u7b97\u9700\u6c42\u53c8\u8003\u8651\u6267\u884c\u8282\u70b9\u73af\u5883\u5f71\u54cd\u7684\u8282\u80fd\u90e8\u7f72\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u4ea7\u751f\u7531\u7eff\u8272\u7ea6\u675f\u5f15\u5bfc\u7684\u90e8\u7f72\u8ba1\u5212\u7684\u65b9\u6cd5\u8bba\u4e0e\u67b6\u6784\u3002\u8fd9\u4e9b\u7eff\u8272\u7ea6\u675f\u662f\u57fa\u4e8e\u5bf9\u80fd\u91cf\u6d88\u8017\u6a21\u5f0f\u3001\u7ec4\u4ef6\u95f4\u901a\u4fe1\u53ca\u5e95\u5c42\u57fa\u7840\u8bbe\u65bd\u73af\u5883\u7279\u5f81\u7684\u6301\u7eed\u5206\u6790\u5f97\u51fa\u7684\uff0c\u5e76\u53ef\u901a\u8fc7\u76d1\u63a7\u6570\u636e\u968f\u65f6\u95f4\u81ea\u52a8\u5b66\u4e60\u548c\u66f4\u65b0\u3002", "result": "\u901a\u8fc7\u5b9e\u9645\u7684\u4e91\u539f\u751f\u5e94\u7528\u90e8\u7f72\u573a\u666f\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u51cf\u5c11\u80fd\u6e90\u4f7f\u7528\u53ca\u76f8\u5173\u6392\u653e\u65b9\u9762\u7684\u6210\u6548\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e91\u539f\u751f\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u521b\u65b0\u6027\u7684\u7eff\u8272\u611f\u77e5\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8IT\u7cfb\u7edf\u7684\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2602.17689", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.17689", "abs": "https://arxiv.org/abs/2602.17689", "authors": ["Melika Filvantorkaman", "Mohsen Piri"], "title": "Robust Pre-Training of Medical Vision-and-Language Models with Domain-Invariant Multi-Modal Masked Reconstruction", "comment": "28 pages, 3 figures", "summary": "Medical vision-language models show strong potential for joint reasoning over medical images and clinical text, but their performance often degrades under domain shift caused by variations in imaging devices, acquisition protocols, and reporting styles. Existing multi-modal pre-training methods largely overlook robustness, treating it as a downstream adaptation problem. In this work, we propose Robust Multi-Modal Masked Reconstruction (Robust-MMR), a self-supervised pre-training framework that explicitly incorporates robustness objectives into masked vision-language learning. Robust-MMR integrates asymmetric perturbation-aware masking, domain-consistency regularization, and modality-resilience constraints to encourage domain-invariant representations. We evaluate Robust-MMR on multiple medical vision-language benchmarks, including medical visual question answering (VQA-RAD, SLAKE, VQA-2019), cross-domain image-text classification (MELINDA), and robust image-caption retrieval (ROCO). Robust-MMR achieves 78.9% cross-domain accuracy on VQA-RAD, outperforming the strongest baseline by 3.8 percentage points, and reaches 74.6% and 77.0% accuracy on SLAKE and VQA-2019, respectively. Under perturbed evaluation, Robust-MMR improves VQA-RAD accuracy from 69.1% to 75.6%. For image-text classification, cross-domain MELINDA accuracy increases from 70.3% to 75.2%, while retrieval experiments show a reduction in mean rank degradation from over 16 to 4.1 under perturbation. Qualitative results further demonstrate improved clinical reasoning for disease detection and structural abnormality assessment. These findings show that explicitly modeling robustness during pre-training leads to more reliable and transferable medical vision-language representations for real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6Robust-MMR\uff0c\u901a\u8fc7\u6574\u5408\u975e\u5bf9\u79f0\u6270\u52a8\u611f\u77e5\u63a9\u7801\u3001\u9886\u57df\u4e00\u81f4\u6027\u6b63\u5219\u5316\u548c\u6a21\u6001\u97e7\u6027\u7ea6\u675f\u6765\u589e\u5f3a\u533b\u5b66\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u4e86\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u533b\u5b66\u56fe\u50cf\u4e0e\u4e34\u5e8a\u6587\u672c\u8054\u5408\u63a8\u7406\u7684\u6a21\u578b\u5728\u9047\u5230\u8bbe\u5907\u3001\u534f\u8bae\u53ca\u62a5\u544a\u98ce\u683c\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRobust-MMR\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u9c81\u68d2\u6027\u76ee\u6807\u660e\u786e\u5730\u7eb3\u5165\u5230\u906e\u853d\u7684\u89c6\u89c9-\u8bed\u8a00\u5b66\u4e60\u4e2d\uff0c\u5305\u62ec\u975e\u5bf9\u79f0\u6270\u52a8\u610f\u8bc6\u63a9\u853d\u3001\u57df\u4e00\u81f4\u6027\u6b63\u5219\u5316\u4ee5\u53ca\u6a21\u6001\u5f39\u6027\u9650\u5236\u7b49\u6280\u672f\u3002", "result": "Robust-MMR\u5728\u591a\u4e2a\u533b\u5b66\u89c6\u89c9-\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u7ee9\uff0c\u5982VQA-RAD\u4ea4\u53c9\u9886\u57df\u51c6\u786e\u7387\u8fbe\u523078.9%\uff0cSLAKE\u548cVQA-2019\u5206\u522b\u4e3a74.6%\u548c77.0%\uff1b\u540c\u65f6\uff0c\u5728\u53d7\u5e72\u6270\u6761\u4ef6\u4e0b\uff0cVQA-RAD\u51c6\u786e\u6027\u4ece69.1%\u63d0\u5347\u81f375.6%\uff0cMELINDA\u4ea4\u53c9\u9886\u57df\u7cbe\u5ea6\u753170.3%\u5347\u81f375.2%\uff0c\u68c0\u7d22\u5b9e\u9a8c\u663e\u793a\u5e73\u5747\u6392\u540d\u4e0b\u964d\u5e45\u5ea6\u4ece\u8d85\u8fc716\u51cf\u5c11\u52304.1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u660e\u786e\u5efa\u6a21\u9c81\u68d2\u6027\u53ef\u4ee5\u4ea7\u751f\u66f4\u53ef\u9760\u4e14\u53ef\u8f6c\u79fb\u7684\u533b\u5b66\u89c6\u89c9-\u8bed\u8a00\u8868\u793a\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u90e8\u7f72\u3002"}}
{"id": "2602.17697", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.17697", "abs": "https://arxiv.org/abs/2602.17697", "authors": ["Nada Zine", "Cl\u00e9ment Quinton", "Romain Rouvoy"], "title": "Pimp My LLM: Leveraging Variability Modeling to Tune Inference Hyperparameters", "comment": null, "summary": "Large Language Models (LLMs) are being increasingly used across a wide range of tasks. However, their substantial computational demands raise concerns about the energy efficiency and sustainability of both training and inference. Inference, in particular, dominates total compute usage, making its optimization crucial. Recent research has explored optimization techniques and analyzed how configuration choices influence energy consumption. Yet, the vast configuration space of inference servers makes exhaustive empirical evaluation infeasible due to combinatorial explosion. In this paper, we introduce a new perspective on this problem by treating LLMs as configurable systems and applying variability management techniques to systematically analyze inference-time configuration choices. We evaluate our approach on the Hugging Face Transformers library by representing generation hyperparameters and their constraints using a feature-based variability model, sampling representative configurations, measuring their energy consumption, latency, accuracy, and learning predictive models from the collected data. Our results show that variability modeling effectively manages the complexity of LLM inference configurations. It enables systematic analysis of hyperparameters effects and interactions, reveals trade-offs, and supports accurate prediction of inference behavior from a limited number of measurements. Overall, this work opens a new research direction that bridges software engineering and machine learning by leveraging variability modeling for the efficient and sustainable configuration of LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89c6\u4e3a\u53ef\u914d\u7f6e\u7cfb\u7edf\uff0c\u5e76\u5e94\u7528\u53d8\u5f02\u6027\u7ba1\u7406\u6280\u672f\u6765\u7cfb\u7edf\u5730\u5206\u6790\u63a8\u7406\u65f6\u7684\u914d\u7f6e\u9009\u62e9\u3002\u901a\u8fc7\u8bc4\u4f30Hugging Face Transformers\u5e93\uff0c\u4f7f\u7528\u57fa\u4e8e\u7279\u5f81\u7684\u53d8\u5f02\u6027\u6a21\u578b\u8868\u793a\u751f\u6210\u8d85\u53c2\u6570\u53ca\u5176\u7ea6\u675f\u6761\u4ef6\uff0c\u62bd\u6837\u4ee3\u8868\u6027\u914d\u7f6e\uff0c\u6d4b\u91cf\u5176\u80fd\u8017\u3001\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\uff0c\u5e76\u4ece\u6536\u96c6\u7684\u6570\u636e\u4e2d\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u53d8\u5f02\u6027\u5efa\u6a21\u6709\u6548\u5730\u7ba1\u7406\u4e86LLM\u63a8\u7406\u914d\u7f6e\u7684\u590d\u6742\u6027\uff0c\u652f\u6301\u4ece\u6709\u9650\u6570\u91cf\u7684\u6d4b\u91cf\u4e2d\u51c6\u786e\u9884\u6d4b\u63a8\u7406\u884c\u4e3a\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u9700\u6c42\u5f15\u53d1\u4e86\u5173\u4e8e\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u80fd\u6e90\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u7684\u62c5\u5fe7\u3002\u5c24\u5176\u662f\u63a8\u7406\u9636\u6bb5\u5360\u636e\u4e86\u603b\u8ba1\u7b97\u91cf\u7684\u4e3b\u8981\u90e8\u5206\uff0c\u56e0\u6b64\u4f18\u5316\u5b83\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u4e86\u4f18\u5316\u6280\u672f\u548c\u914d\u7f6e\u9009\u62e9\u5bf9\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u4f46\u63a8\u7406\u670d\u52a1\u5668\u5e9e\u5927\u7684\u914d\u7f6e\u7a7a\u95f4\u4f7f\u5f97\u5168\u9762\u7684\u7ecf\u9a8c\u8bc4\u4f30\u53d8\u5f97\u4e0d\u53ef\u884c\u3002", "method": "\u672c\u6587\u91c7\u7528\u53d8\u5f02\u6027\u7ba1\u7406\u6280\u672f\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u770b\u4f5c\u662f\u53ef\u914d\u7f6e\u7cfb\u7edf\uff0c\u4ee5\u6b64\u65b0\u89d2\u5ea6\u51fa\u53d1\u4ee5\u7cfb\u7edf\u5730\u5206\u6790\u63a8\u7406\u65f6\u7684\u914d\u7f6e\u9009\u62e9\u3002\u901a\u8fc7Hugging Face Transformers\u5e93\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5229\u7528\u57fa\u4e8e\u7279\u5f81\u7684\u53d8\u5f02\u6027\u6a21\u578b\u6765\u8868\u793a\u751f\u6210\u8d85\u53c2\u6570\u53ca\u5b83\u4eec\u4e4b\u95f4\u7684\u7ea6\u675f\u5173\u7cfb\uff0c\u9009\u53d6\u4ee3\u8868\u6027\u7684\u914d\u7f6e\u65b9\u6848\uff0c\u6d4b\u91cf\u8fd9\u4e9b\u914d\u7f6e\u4e0b\u7684\u80fd\u91cf\u6d88\u8017\u3001\u5ef6\u8fdf\u4ee5\u53ca\u51c6\u786e\u6027\uff0c\u5e76\u6839\u636e\u6536\u96c6\u5230\u7684\u6570\u636e\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u53d8\u5f02\u6027\u5efa\u6a21\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u914d\u7f6e\u7684\u590d\u6742\u6027\u95ee\u9898\u3002\u5b83\u4e0d\u4ec5\u6709\u52a9\u4e8e\u7cfb\u7edf\u5730\u5206\u6790\u8d85\u53c2\u6570\u7684\u6548\u679c\u4e0e\u76f8\u4e92\u4f5c\u7528\uff0c\u63ed\u793a\u5176\u4e2d\u5b58\u5728\u7684\u6743\u8861\u5173\u7cfb\uff0c\u8fd8\u80fd\u57fa\u4e8e\u6709\u9650\u6b21\u6570\u7684\u5b9e\u9645\u6d4b\u91cf\u51c6\u786e\u9884\u6d4b\u63a8\u7406\u8868\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u542f\u4e86\u4e00\u4e2a\u7ed3\u5408\u8f6f\u4ef6\u5de5\u7a0b\u4e0e\u673a\u5668\u5b66\u4e60\u7684\u65b0\u65b9\u5411\uff0c\u901a\u8fc7\u5229\u7528\u53d8\u5f02\u6027\u5efa\u6a21\u6765\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u9ad8\u6548\u4e14\u53ef\u6301\u7eed\u7684\u914d\u7f6e\u3002"}}
{"id": "2602.17693", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17693", "abs": "https://arxiv.org/abs/2602.17693", "authors": ["Yuchen Luo", "Fangyue Zhu", "Ruining Zhou", "Mingzhe Huang", "Jian Zhu", "Fanyu Fan", "Wei Shao"], "title": "A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU", "comment": null, "summary": "Post-Training Quantization (PTQ) is crucial for efficient model deployment, yet its effectiveness on Ascend NPU remains under-explored compared to GPU architectures. This paper presents a case study of representative PTQ baselines applied to reasoning-oriented models such as DeepSeek-R1-Distill-Qwen series (1.5B/7B/14B) and QwQ-32B. We evaluate four distinct algorithms, including AWQ, GPTQ, SmoothQuant, and FlatQuant, to cover the spectrum from weight-only compression to advanced rotation-based methods. Our empirical results reveal significant platform sensitivity. While 4-bit weight-only quantization proves viable for larger models, aggressive 4-bit weight-activation schemes suffer from layer-wise calibration instability on the NPU, leading to logic collapse in long-context reasoning tasks. Conversely, standard 8-bit quantization remains numerically stable. Furthermore, a real-world INT8 deployment demonstrates that although optimized kernels reduce latency, dynamic quantization overheads currently limit end-to-end acceleration. These findings offer a practical reference for the feasibility and limitations of deploying quantized reasoning models on Ascend NPU.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u540e\u8bad\u7ec3\u91cf\u5316(PTQ)\u5728\u9762\u5411\u63a8\u7406\u7684\u6a21\u578b\u5982DeepSeek-R1-Distill-Qwen\u7cfb\u5217\u548cQwQ-32B\u4e0a\u5e94\u7528\u65f6\uff0c\u5728\u5347\u817eNPU\u4e0a\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u8bc4\u4f30AWQ\u3001GPTQ\u3001SmoothQuant\u53caFlatQuant\u56db\u79cd\u7b97\u6cd5\uff0c\u53d1\u73b04\u6bd4\u7279\u6743\u91cd\u4ec5\u538b\u7f29\u5bf9\u8f83\u5927\u6a21\u578b\u6709\u6548\uff0c\u4f46\u6fc0\u8fdb\u76844\u6bd4\u7279\u6743\u91cd-\u6fc0\u6d3b\u65b9\u6848\u4f1a\u5bfc\u81f4NPU\u4e0a\u7684\u5c42\u6821\u51c6\u4e0d\u7a33\u5b9a\u3002\u800c\u6807\u51c68\u6bd4\u7279\u91cf\u5316\u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u3002\u6b64\u5916\uff0cINT8\u7684\u5b9e\u9645\u90e8\u7f72\u8868\u660e\u5c3d\u7ba1\u4f18\u5316\u5185\u6838\u51cf\u5c11\u4e86\u5ef6\u8fdf\uff0c\u52a8\u6001\u91cf\u5316\u5f00\u9500\u4ecd\u9650\u5236\u4e86\u7aef\u5230\u7aef\u52a0\u901f\u3002", "motivation": "\u63a2\u8ba8\u540e\u8bad\u7ec3\u91cf\u5316(PTQ)\u6280\u672f\u5728Ascend NPU\u5e73\u53f0\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u4e0eGPU\u67b6\u6784\u76f8\u6bd4\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u90e8\u5206\u3002", "method": "\u9009\u53d6\u4ee3\u8868\u6027PTQ\u57fa\u7ebf\u5e94\u7528\u4e8e\u4e00\u7cfb\u5217\u63a8\u7406\u5bfc\u5411\u6a21\u578b\uff08\u5982DeepSeek-R1-Distill-Qwen\u7cfb\u5217\u548cQwQ-32B\uff09\uff0c\u5e76\u8bc4\u4f30\u4e86\u5305\u62ecAWQ\u3001GPTQ\u3001SmoothQuant\u4ee5\u53caFlatQuant\u5728\u5185\u7684\u56db\u79cd\u4e0d\u540c\u7b97\u6cd5\uff0c\u8986\u76d6\u4ece\u4ec5\u6743\u91cd\u538b\u7f29\u5230\u9ad8\u7ea7\u65cb\u8f6c\u65b9\u6cd5\u7684\u8303\u56f4\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u663e\u8457\u7684\u5e73\u53f0\u654f\u611f\u6027\uff1a\u5bf9\u4e8e\u5927\u578b\u6a21\u578b\u800c\u8a00\uff0c4\u4f4d\u4ec5\u6743\u91cd\u91cf\u5316\u662f\u53ef\u884c\u7684\uff1b\u7136\u800c\uff0c\u6fc0\u8fdb\u76844\u4f4d\u6743\u91cd-\u6fc0\u6d3b\u65b9\u6848\u5728NPU\u4e0a\u906d\u9047\u9010\u5c42\u6821\u51c6\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u957f\u65f6\u95f4\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u903b\u8f91\u5d29\u6e83\u3002\u76f8\u53cd\u5730\uff0c\u6807\u51c68\u4f4d\u91cf\u5316\u4fdd\u6301\u4e86\u6570\u503c\u4e0a\u7684\u7a33\u5b9a\u6027\u3002\u53e6\u5916\uff0c\u9488\u5bf9INT8\u7684\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\u663e\u793a\uff0c\u867d\u7136\u4f18\u5316\u540e\u7684\u5185\u6838\u80fd\u591f\u51cf\u5c11\u5ef6\u8fdf\uff0c\u4f46\u662f\u5f53\u524d\u52a8\u6001\u91cf\u5316\u7684\u5f00\u9500\u9650\u5236\u4e86\u7aef\u5230\u7aef\u52a0\u901f\u7684\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3\u91cf\u5316\u63a8\u7406\u6a21\u578b\u5728Ascend NPU\u5e73\u53f0\u4e0a\u90e8\u7f72\u65f6\u7684\u53ef\u884c\u6027\u4e0e\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u5b9e\u8df5\u53c2\u8003\u3002"}}
{"id": "2602.17696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17696", "abs": "https://arxiv.org/abs/2602.17696", "authors": ["Zongmin Li", "Jian Su", "Farah Benamara", "Aixin Sun"], "title": "Can LLM Safety Be Ensured by Constraining Parameter Regions?", "comment": "32 pages", "summary": "Large language models (LLMs) are often assumed to contain ``safety regions'' -- parameter subsets whose modification directly influences safety behaviors. We conduct a systematic evaluation of four safety region identification methods spanning different parameter granularities, from individual weights to entire Transformer layers, across four families of backbone LLMs with varying sizes. Using ten safety identification datasets, we find that the identified safety regions exhibit only low to moderate overlap, as measured by IoU. The overlap drops significantly when the safety regions are further refined using utility datasets (\\ie non-harmful queries). These results suggest that current techniques fail to reliably identify a stable, dataset-agnostic safety region.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u533a\u57df\u8bc6\u522b\u65b9\u6cd5\uff0c\u53d1\u73b0\u5f53\u524d\u6280\u672f\u96be\u4ee5\u53ef\u9760\u5730\u8bc6\u522b\u4e00\u4e2a\u7a33\u5b9a\u4e14\u4e0e\u6570\u636e\u96c6\u65e0\u5173\u7684\u5b89\u5168\u533a\u57df\u3002", "motivation": "\u4e3a\u4e86\u9a8c\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u662f\u5426\u5b58\u5728\u901a\u8fc7\u4fee\u6539\u67d0\u4e9b\u53c2\u6570\u76f4\u63a5\u6539\u53d8\u5b89\u5168\u884c\u4e3a\u7684\u201c\u5b89\u5168\u533a\u57df\u201d\u3002", "method": "\u91c7\u7528\u8de8\u56db\u4e2a\u4e0d\u540c\u5927\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u7684\u56db\u79cd\u5b89\u5168\u533a\u57df\u8bc6\u522b\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u5341\u4e2a\u5b89\u5168\u8bc6\u522b\u6570\u636e\u96c6\u4ee5\u53ca\u989d\u5916\u7684\u529f\u80fd\u6027\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u6240\u8bc6\u522b\u51fa\u7684\u5b89\u5168\u533a\u57df\u4e4b\u95f4\u53ea\u6709\u8f83\u4f4e\u5230\u4e2d\u7b49\u7a0b\u5ea6\u7684\u91cd\u53e0\uff0c\u5f53\u8fdb\u4e00\u6b65\u4f7f\u7528\u529f\u80fd\u6027\u6570\u636e\u96c6\u7ec6\u5316\u65f6\uff0c\u91cd\u53e0\u5ea6\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u73b0\u6709\u7684\u5b89\u5168\u533a\u57df\u8bc6\u522b\u6280\u672f\u672a\u80fd\u4e00\u81f4\u5730\u627e\u5230\u4e00\u4e2a\u4e0d\u53d7\u7279\u5b9a\u6570\u636e\u96c6\u5f71\u54cd\u7684\u7a33\u5b9a\u5b89\u5168\u533a\u57df\u3002"}}
{"id": "2602.17698", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17698", "abs": "https://arxiv.org/abs/2602.17698", "authors": ["Xinlin Li", "Timothy Chou", "Josh Fromm", "Zichang Liu", "Yunjie Pan", "Christina Fragouli"], "title": "ScaleBITS: Scalable Bitwidth Search for Hardware-Aligned Mixed-Precision LLMs", "comment": null, "summary": "Post-training weight quantization is crucial for reducing the memory and inference cost of large language models (LLMs), yet pushing the average precision below 4 bits remains challenging due to highly non-uniform weight sensitivity and the lack of principled precision allocation. Existing solutions use irregular fine-grained mixed-precision with high runtime overhead or rely on heuristics or highly constrained precision allocation strategies. In this work, we propose ScaleBITS, a mixed-precision quantization framework that enables automated, fine-grained bitwidth allocation under a memory budget while preserving hardware efficiency. Guided by a new sensitivity analysis, we introduce a hardware-aligned, block-wise weight partitioning scheme, powered by bi-directional channel reordering. We formulate global bitwidth allocation as a constrained optimization problem and develop a scalable approximation to the greedy algorithm, enabling end-to-end principled allocation. Experiments show that ScaleBITS significantly improves over uniform-precision quantization (up to +36%) and outperforms state-of-the-art sensitivity-aware baselines (up to +13%) in ultra-low-bit regime, without adding runtime overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aScaleBITS\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u786c\u4ef6\u5bf9\u9f50\u7684\u6743\u91cd\u5206\u533a\u65b9\u6848\u548c\u53cc\u5411\u901a\u9053\u91cd\u6392\u5e8f\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5728\u5185\u5b58\u9884\u7b97\u4e0b\u7684\u81ea\u52a8\u5316\u7ec6\u7c92\u5ea6\u4f4d\u5bbd\u5206\u914d\u3002\u5b9e\u9a8c\u8868\u660e\uff0cScaleBITS\u5728\u6781\u4f4e\u6bd4\u7279\u7387\u4e0b\u4f18\u4e8e\u5747\u5300\u7cbe\u5ea6\u91cf\u5316\u548c\u5176\u4ed6\u57fa\u4e8e\u654f\u611f\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u4e0d\u589e\u52a0\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "motivation": "\u540e\u8bad\u7ec3\u6743\u91cd\u91cf\u5316\u5bf9\u4e8e\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5185\u5b58\u548c\u63a8\u7406\u6210\u672c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c06\u5e73\u5747\u7cbe\u5ea6\u964d\u81f34\u6bd4\u7279\u4ee5\u4e0b\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u6743\u91cd\u654f\u611f\u6027\u9ad8\u5ea6\u4e0d\u5747\u5300\u4ee5\u53ca\u7f3a\u4e4f\u7cfb\u7edf\u7684\u7cbe\u5ea6\u5206\u914d\u539f\u5219\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u8fd0\u884c\u65f6\u5f00\u9500\u5927\u6216\u4f9d\u8d56\u542f\u53d1\u5f0f\u3001\u9ad8\u5ea6\u53d7\u9650\u7684\u7cbe\u5ea6\u5206\u914d\u7b56\u7565\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86ScaleBITS\uff0c\u4e00\u79cd\u652f\u6301\u5728\u7ed9\u5b9a\u5185\u5b58\u9884\u7b97\u4e0b\u8fdb\u884c\u81ea\u52a8\u3001\u7ec6\u7c92\u5ea6\u4f4d\u5bbd\u5206\u914d\u7684\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6846\u67b6\uff0c\u5e76\u4fdd\u6301\u786c\u4ef6\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u65b0\u7684\u654f\u611f\u6027\u5206\u6790\u6307\u5bfc\u4e0b\u7684\u786c\u4ef6\u5bf9\u9f50\u3001\u57fa\u4e8e\u53cc\u5411\u901a\u9053\u91cd\u6392\u5e8f\u7684\u5757\u7ea7\u6743\u91cd\u5206\u533a\u65b9\u6848\uff1b\u540c\u65f6\uff0c\u5c06\u5168\u5c40\u4f4d\u5bbd\u5206\u914d\u5efa\u6a21\u4e3a\u4e00\u4e2a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u8fd1\u4f3c\u8d2a\u5fc3\u7b97\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u8d85\u4f4e\u6bd4\u7279\u7387\u60c5\u51b5\u4e0b\uff0cScaleBITS\u76f8\u8f83\u4e8e\u7edf\u4e00\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad8\u53ef\u8fbe+36%\uff09\uff0c\u540c\u65f6\u4e5f\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u654f\u611f\u6027\u7684\u57fa\u51c6\u65b9\u6cd5\uff08\u6700\u9ad8\u53ef\u8fbe+13%\uff09\uff0c\u5e76\u4e14\u6ca1\u6709\u5f15\u5165\u989d\u5916\u7684\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684ScaleBITS\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u540e\u8bad\u7ec3\u6743\u91cd\u91cf\u5316\u7684\u96be\u9898\uff0c\u7279\u522b\u662f\u5728\u5b9e\u73b0\u66f4\u4f4e\u6bd4\u7279\u7387\u7684\u540c\u65f6\u4fdd\u8bc1\u4e86\u6027\u80fd\u548c\u6548\u7387\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.17699", "categories": ["cs.LG", "math.RA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17699", "abs": "https://arxiv.org/abs/2602.17699", "authors": ["Chandrasekhar Gokavarapu", "Sudhakar Gadde", "Y. Rajasekhar", "S. R. Bhargava"], "title": "Certified Learning under Distribution Shift: Sound Verification and Identifiable Structure", "comment": null, "summary": "Proposition. Let $f$ be a predictor trained on a distribution $P$ and evaluated on a shifted distribution $Q$. Under verifiable regularity and complexity constraints, the excess risk under shift admits an explicit upper bound determined by a computable shift metric and model parameters. We develop a unified framework in which (i) risk under distribution shift is certified by explicit inequalities, (ii) verification of learned models is sound for nontrivial sizes, and (iii) interpretability is enforced through identifiability conditions rather than post hoc explanations. All claims are stated with explicit assumptions. Failure modes are isolated. Non-certifiable regimes are characterized.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u5bf9\u9884\u6d4b\u5668\u98ce\u9669\u8fdb\u884c\u663e\u5f0f\u4e0a\u754c\u4f30\u8ba1\u7684\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u652f\u6301\u98ce\u9669\u9a8c\u8bc1\u3001\u6a21\u578b\u9a8c\u8bc1\u7684\u5408\u7406\u6027\u548c\u901a\u8fc7\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u800c\u975e\u4e8b\u540e\u89e3\u91ca\u6765\u5f3a\u5236\u6267\u884c\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5f53\u8bad\u7ec3\u548c\u8bc4\u4f30\u9884\u6d4b\u5668\u65f6\u9047\u5230\u7684\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u65b9\u6cd5\u6765\u91cf\u5316\u8fd9\u79cd\u5206\u5e03\u504f\u79fb\u5bf9\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u786e\u4fdd\u5373\u4f7f\u5728\u975e\u5e73\u51e1\u89c4\u6a21\u4e0b\u4e5f\u80fd\u53ef\u9760\u5730\u9a8c\u8bc1\u6240\u5b66\u4e60\u5230\u7684\u6a21\u578b\u3002", "method": "\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u4e86\u7528\u4e8e\u8ba4\u8bc1\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u98ce\u9669\u7684\u663e\u5f0f\u4e0d\u7b49\u5f0f\u3001\u4fdd\u8bc1\u4e86\u5bf9\u4e8e\u4e00\u5b9a\u89c4\u6a21\u7684\u5b66\u4e60\u6a21\u578b\u5176\u9a8c\u8bc1\u8fc7\u7a0b\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u901a\u8fc7\u8bbe\u7f6e\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u6765\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u540e\u9a8c\u89e3\u91ca\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6ee1\u8db3\u7279\u5b9a\u89c4\u5219\u6027\u548c\u590d\u6742\u5ea6\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u4e00\u4e2a\u4e0e\u8f6c\u79fb\u5ea6\u91cf\u548c\u6a21\u578b\u53c2\u6570\u76f8\u5173\u7684\u663e\u5f0f\u4e0a\u754c\u6765\u4f30\u8ba1\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u8d85\u989d\u98ce\u9669\u3002\u6b64\u5916\uff0c\u8fd8\u660e\u786e\u4e86\u4e0d\u53ef\u8ba4\u8bc1\u533a\u57df\u7684\u7279\u70b9\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3\u548c\u63a7\u5236\u7531\u4e8e\u6570\u636e\u5206\u5e03\u53d8\u5316\u5bfc\u81f4\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2602.17700", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.17700", "abs": "https://arxiv.org/abs/2602.17700", "authors": ["Konstanty Subbotko"], "title": "MIDAS: Mosaic Input-Specific Differentiable Architecture Search", "comment": null, "summary": "Differentiable Neural Architecture Search (NAS) provides efficient, gradient-based methods for automatically designing neural networks, yet its adoption remains limited in practice. We present MIDAS, a novel approach that modernizes DARTS by replacing static architecture parameters with dynamic, input-specific parameters computed via self-attention. To improve robustness, MIDAS (i) localizes the architecture selection by computing it separately for each spatial patch of the activation map, and (ii) introduces a parameter-free, topology-aware search space that models node connectivity and simplifies selecting the two incoming edges per node. We evaluate MIDAS on the DARTS, NAS-Bench-201, and RDARTS search spaces. In DARTS, it reaches 97.42% top-1 on CIFAR-10 and 83.38% on CIFAR-100. In NAS-Bench-201, it consistently finds globally optimal architectures. In RDARTS, it sets the state of the art on two of four search spaces on CIFAR-10. We further analyze why MIDAS works, showing that patchwise attention improves discrimination among candidate operations, and the resulting input-specific parameter distributions are class-aware and predominantly unimodal, providing reliable guidance for decoding.", "AI": {"tldr": "MIDAS is a new approach that enhances DARTS by using dynamic, input-specific parameters through self-attention, improving the robustness of architecture selection. It shows high performance on CIFAR-10 and CIFAR-100, and consistently finds optimal architectures in NAS-Bench-201.", "motivation": "The motivation behind MIDAS is to modernize the Differentiable Architecture Search (DARTS) by addressing its limitations, such as static architecture parameters, and to improve the practicality and robustness of neural architecture search.", "method": "MIDAS replaces static architecture parameters with dynamic, input-specific ones computed via self-attention. It also localizes architecture selection to each spatial patch of the activation map and introduces a topology-aware, parameter-free search space for better node connectivity and edge selection.", "result": "MIDAS achieves 97.42% top-1 accuracy on CIFAR-10 and 83.38% on CIFAR-100 in the DARTS search space. In NAS-Bench-201, it finds globally optimal architectures, and in RDARTS, it sets new state-of-the-art results on two out of four search spaces on CIFAR-10.", "conclusion": "MIDAS improves upon DARTS by incorporating dynamic, input-specific parameters and enhancing the robustness of the architecture selection process, leading to higher performance and more reliable guidance for decoding."}}
{"id": "2602.17706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17706", "abs": "https://arxiv.org/abs/2602.17706", "authors": ["Rongyao Cai", "Yuxi Wan", "Kexin Zhang", "Ming Jin", "Zhiqiang Ge", "Qingsong Wen", "Yong Liu"], "title": "Parallel Complex Diffusion for Scalable Time Series Generation", "comment": null, "summary": "Modeling long-range dependencies in time series generation poses a fundamental trade-off between representational capacity and computational efficiency. Traditional temporal diffusion models suffer from local entanglement and the $\\mathcal{O}(L^2)$ cost of attention mechanisms. We address these limitations by introducing PaCoDi (Parallel Complex Diffusion), a spectral-native architecture that decouples generative modeling in the frequency domain. PaCoDi fundamentally alters the problem topology: the Fourier Transform acts as a diagonalizing operator, converting locally coupled temporal signals into globally decorrelated spectral components. Theoretically, we prove the Quadrature Forward Diffusion and Conditional Reverse Factorization theorem, demonstrating that the complex diffusion process can be split into independent real and imaginary branches. We bridge the gap between this decoupled theory and data reality using a \\textbf{Mean Field Theory (MFT) approximation} reinforced by an interactive correction mechanism. Furthermore, we generalize this discrete DDPM to continuous-time Frequency SDEs, rigorously deriving the Spectral Wiener Process describe the differential spectral Brownian motion limit. Crucially, PaCoDi exploits the Hermitian Symmetry of real-valued signals to compress the sequence length by half, achieving a 50% reduction in attention FLOPs without information loss. We further derive a rigorous Heteroscedastic Loss to handle the non-isotropic noise distribution on the compressed manifold. Extensive experiments show that PaCoDi outperforms existing baselines in both generation quality and inference speed, offering a theoretically grounded and computationally efficient solution for time series modeling.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u6a21\u578bPaCoDi\uff0c\u901a\u8fc7\u5728\u9891\u57df\u5185\u8fdb\u884c\u89e3\u8026\u751f\u6210\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u4e2d\u7684\u5c40\u90e8\u7ea0\u7f20\u95ee\u9898\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002\u8be5\u6a21\u578b\u5229\u7528\u5085\u91cc\u53f6\u53d8\u6362\u5c06\u5c40\u90e8\u8026\u5408\u7684\u65f6\u95f4\u4fe1\u53f7\u8f6c\u6362\u4e3a\u5168\u5c40\u89e3\u8026\u7684\u9891\u8c31\u7ec4\u4ef6\uff0c\u5e76\u901a\u8fc7\u5747\u573a\u7406\u8bba\u8fd1\u4f3c\u53ca\u4ea4\u4e92\u4fee\u6b63\u673a\u5236\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u9645\u6570\u636e\u3002\u6b64\u5916\uff0cPaCoDi\u8fd8\u5229\u7528\u4e86\u5b9e\u503c\u4fe1\u53f7\u7684\u5384\u7c73\u5bf9\u79f0\u6027\u6765\u538b\u7f29\u5e8f\u5217\u957f\u5ea6\uff0c\u51cf\u5c11\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4fe1\u606f\u5b8c\u6574\u3002\u5b9e\u9a8c\u8868\u660e\uff0cPaCoDi\u5728\u751f\u6210\u8d28\u91cf\u548c\u63a8\u7406\u901f\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u957f\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u4e2d\u8868\u73b0\u529b\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u4f20\u7edf\u65f6\u5e8f\u6269\u6563\u6a21\u578b\u5b58\u5728\u7684\u5c40\u90e8\u7ea0\u7f20\u73b0\u8c61\u4ee5\u53ca\u6ce8\u610f\u529b\u673a\u5236\u5e26\u6765\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\uff08$\\mathcal{O}(L^2)$\uff09\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aPaCoDi\uff08Parallel Complex Diffusion\uff09\u7684\u65b0\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u57fa\u4e8e\u9891\u8c31\u539f\u751f\u8bbe\u8ba1\uff0c\u5728\u9891\u7387\u57df\u5185\u5b9e\u73b0\u4e86\u89e3\u8026\u751f\u6210\u5efa\u6a21\u3002\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u4f5c\u4e3a\u5bf9\u89d2\u5316\u7b97\u5b50\uff0c\u5c06\u5c40\u90e8\u8026\u5408\u7684\u65f6\u95f4\u4fe1\u53f7\u8f6c\u53d8\u4e3a\u5168\u5c40\u89e3\u76f8\u5173\u8054\u7684\u9891\u8c31\u5206\u91cf\u3002\u91c7\u7528\u5747\u573a\u7406\u8bba\u8fd1\u4f3c\u52a0\u4e0a\u4ea4\u4e92\u5f0f\u6821\u6b63\u673a\u5236\u6765\u5f25\u5408\u7406\u8bba\u4e0e\u6570\u636e\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u5c06\u79bb\u6563DDPM\u63a8\u5e7f\u5230\u8fde\u7eed\u65f6\u95f4\u9891\u7387SDEs\u3002", "result": "PaCoDi\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6ce8\u610f\u529b\u673a\u5236\u6240\u9700\u7684FLOPs\u8fbe50%\uff0c\u540c\u65f6\u4e0d\u4f1a\u635f\u5931\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u80fd\u5904\u7406\u538b\u7f29\u6d41\u5f62\u4e0a\u7684\u975e\u7b49\u65b9\u5dee\u566a\u58f0\u5206\u5e03\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86PaCoDi\u5728\u751f\u6210\u8d28\u91cf\u4e0e\u63a8\u7406\u901f\u5ea6\u4e24\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PaCoDi\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u624e\u5b9e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u957f\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u65b9\u6848\uff0c\u4e0d\u4ec5\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u5c40\u9650\u6027\uff0c\u800c\u4e14\u5728\u6027\u80fd\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\u3002"}}
{"id": "2602.17743", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17743", "abs": "https://arxiv.org/abs/2602.17743", "authors": ["Di Zhang"], "title": "Provable Adversarial Robustness in In-Context Learning", "comment": "16 pages", "summary": "Large language models adapt to new tasks through in-context learning (ICL) without parameter updates. Current theoretical explanations for this capability assume test tasks are drawn from a distribution similar to that seen during pretraining. This assumption overlooks adversarial distribution shifts that threaten real-world reliability. To address this gap, we introduce a distributionally robust meta-learning framework that provides worst-case performance guarantees for ICL under Wasserstein-based distribution shifts. Focusing on linear self-attention Transformers, we derive a non-asymptotic bound linking adversarial perturbation strength ($\u03c1$), model capacity ($m$), and the number of in-context examples ($N$). The analysis reveals that model robustness scales with the square root of its capacity ($\u03c1_{\\text{max}} \\propto \\sqrt{m}$), while adversarial settings impose a sample complexity penalty proportional to the square of the perturbation magnitude ($N_\u03c1- N_0 \\propto \u03c1^2$). Experiments on synthetic tasks confirm these scaling laws. These findings advance the theoretical understanding of ICL's limits under adversarial conditions and suggest that model capacity serves as a fundamental resource for distributional robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u9c81\u68d2\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u5728Wasserstein\u5206\u5e03\u53d8\u5316\u4e0b\u7684\u60c5\u5883\u5b66\u4e60\u63d0\u4f9b\u4e86\u6700\u574f\u60c5\u51b5\u6027\u80fd\u4fdd\u8bc1\u3002\u901a\u8fc7\u5206\u6790\u7ebf\u6027\u81ea\u6ce8\u610f\u529bTransformer\u6a21\u578b\uff0c\u5f97\u51fa\u4e86\u5bf9\u6297\u6270\u52a8\u5f3a\u5ea6\u3001\u6a21\u578b\u5bb9\u91cf\u4e0e\u60c5\u5883\u793a\u4f8b\u6570\u91cf\u4e4b\u95f4\u7684\u975e\u6e10\u8fd1\u754c\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6a21\u578b\u7684\u9c81\u68d2\u6027\u968f\u5176\u5bb9\u91cf\u7684\u5e73\u65b9\u6839\u589e\u957f\uff0c\u5e76\u4e14\u5bf9\u6297\u73af\u5883\u4e0b\u6837\u672c\u590d\u6742\u5ea6\u7684\u60e9\u7f5a\u4e0e\u6270\u52a8\u5e45\u5ea6\u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u60c5\u5883\u5b66\u4e60\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u80fd\u529b\u89e3\u91ca\u5047\u8bbe\u6d4b\u8bd5\u4efb\u52a1\u6765\u81ea\u9884\u8bad\u7ec3\u671f\u95f4\u89c1\u5230\u7684\u76f8\u4f3c\u5206\u5e03\uff0c\u4f46\u8fd9\u4e00\u5047\u8bbe\u5ffd\u7565\u4e86\u53ef\u80fd\u5a01\u80c1\u5b9e\u9645\u5e94\u7528\u53ef\u9760\u6027\u7684\u5bf9\u6297\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8eWasserstein\u5206\u5e03\u53d8\u5316\u7684\u60c5\u5883\u5b66\u4e60\u5206\u5e03\u9c81\u68d2\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u9488\u5bf9\u7ebf\u6027\u81ea\u6ce8\u610f\u529bTransformer\u63a8\u5bfc\u4e86\u8fde\u63a5\u5bf9\u6297\u6270\u52a8\u5f3a\u5ea6\u3001\u6a21\u578b\u5bb9\u91cf\u53ca\u60c5\u5883\u793a\u4f8b\u6570\u91cf\u7684\u975e\u6e10\u8fd1\u8fb9\u754c\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u9c81\u68d2\u6027\u4ee5\u6a21\u578b\u5bb9\u91cf\u5e73\u65b9\u6839\u7684\u901f\u5ea6\u589e\u957f\uff1b\u540c\u65f6\uff0c\u5728\u5bf9\u6297\u8bbe\u7f6e\u4e0b\uff0c\u6837\u672c\u590d\u6742\u5ea6\u76f8\u5bf9\u4e8e\u6807\u51c6\u60c5\u51b5\u589e\u52a0\u7684\u7a0b\u5ea6\u4e0e\u6270\u52a8\u5927\u5c0f\u7684\u5e73\u65b9\u6210\u6b63\u6bd4\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7f29\u653e\u6cd5\u5219\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6df1\u5316\u4e86\u6211\u4eec\u5bf9\u5728\u5bf9\u6297\u6761\u4ef6\u4e0b\u60c5\u5883\u5b66\u4e60\u9650\u5236\u7684\u7406\u89e3\uff0c\u5e76\u6307\u51fa\u6a21\u578b\u5bb9\u91cf\u662f\u5b9e\u73b0\u5206\u5e03\u9c81\u68d2\u6027\u7684\u57fa\u672c\u8d44\u6e90\u3002"}}
{"id": "2602.17778", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.17778", "abs": "https://arxiv.org/abs/2602.17778", "authors": ["Zachary Coalson", "Bo Fang", "Sanghyun Hong"], "title": "Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs", "comment": "Pre-print", "summary": "Multi-turn interaction length is a dominant factor in the operational costs of conversational LLMs. In this work, we present a new failure mode in conversational LLMs: turn amplification, in which a model consistently prolongs multi-turn interactions without completing the underlying task. We show that an adversary can systematically exploit clarification-seeking behavior$-$commonly encouraged in multi-turn conversation settings$-$to scalably prolong interactions. Moving beyond prompt-level behaviors, we take a mechanistic perspective and identify a query-independent, universal activation subspace associated with clarification-seeking responses. Unlike prior cost-amplification attacks that rely on per-turn prompt optimization, our attack arises from conversational dynamics and persists across prompts and tasks. We show that this mechanism provides a scalable pathway to induce turn amplification: both supply-chain attacks via fine-tuning and runtime attacks through low-level parameter corruptions consistently shift models toward abstract, clarification-seeking behavior across prompts. Across multiple instruction-tuned LLMs and benchmarks, our attack substantially increases turn count while remaining compliant. We also show that existing defenses offer limited protection against this emerging class of failures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b\u7684\u5931\u6548\u6a21\u5f0f\uff1a\u56de\u5408\u653e\u5927\uff0c\u5373\u6a21\u578b\u5728\u672a\u5b8c\u6210\u57fa\u672c\u4efb\u52a1\u7684\u60c5\u51b5\u4e0b\u4e0d\u65ad\u5ef6\u957f\u591a\u8f6e\u4ea4\u4e92\u3002\u901a\u8fc7\u5229\u7528\u6f84\u6e05\u8bf7\u6c42\u884c\u4e3a\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u7cfb\u7edf\u5730\u5ef6\u957f\u4ea4\u4e92\u3002\u4e0e\u4e4b\u524d\u7684\u4f9d\u8d56\u6bcf\u8f6e\u63d0\u793a\u4f18\u5316\u7684\u6210\u672c\u653e\u5927\u653b\u51fb\u4e0d\u540c\uff0c\u8fd9\u79cd\u653b\u51fb\u6e90\u4e8e\u5bf9\u8bdd\u52a8\u6001\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u7684\u63d0\u793a\u548c\u4efb\u52a1\u4e2d\u6301\u7eed\u5b58\u5728\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4e86\u4e00\u4e2a\u4e0e\u67e5\u8be2\u65e0\u5173\u7684\u3001\u901a\u7528\u7684\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff0c\u4e0e\u5bfb\u6c42\u6f84\u6e05\u54cd\u5e94\u76f8\u5173\u8054\u3002\u65e0\u8bba\u662f\u901a\u8fc7\u5fae\u8c03\u8fd8\u662f\u8fd0\u884c\u65f6\u4f4e\u7ea7\u53c2\u6570\u7be1\u6539\uff0c\u8be5\u673a\u5236\u90fd\u4e3a\u8bf1\u5bfc\u56de\u5408\u653e\u5927\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u653b\u51fb\u663e\u8457\u589e\u52a0\u4e86\u5bf9\u8bdd\u8f6e\u6570\uff0c\u800c\u73b0\u6709\u7684\u9632\u5fa1\u63aa\u65bd\u5bf9\u6b64\u7c7b\u65b0\u5174\u6545\u969c\u63d0\u4f9b\u7684\u4fdd\u62a4\u6709\u9650\u3002", "motivation": "\u591a\u8f6e\u4ea4\u4e92\u957f\u5ea6\u662f\u5bf9\u8bdd\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fd0\u8425\u6210\u672c\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u6587\u7ae0\u65e8\u5728\u63ed\u793a\u4e00\u79cd\u65b0\u7684\u5931\u6548\u6a21\u5f0f\uff0c\u79f0\u4e3a\u2018\u56de\u5408\u653e\u5927\u2019\uff0c\u5176\u4e2d\u6a21\u578b\u5728\u6ca1\u6709\u5b8c\u6210\u57fa\u7840\u4efb\u52a1\u7684\u60c5\u51b5\u4e0b\u4e0d\u65ad\u5730\u5ef6\u957f\u591a\u8f6e\u5bf9\u8bdd\u3002\u6b64\u5916\uff0c\u5b83\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u5229\u7528\u6a21\u578b\u503e\u5411\u4e8e\u5bfb\u6c42\u6f84\u6e05\u7684\u884c\u4e3a\u6765\u7cfb\u7edf\u6027\u5730\u5ef6\u957f\u5bf9\u8bdd\u65f6\u95f4\uff0c\u4ece\u800c\u589e\u52a0\u64cd\u4f5c\u6210\u672c\u3002", "method": "\u9996\u5148\u5b9a\u4e49\u5e76\u63cf\u8ff0\u4e86\u201c\u56de\u5408\u653e\u5927\u201d\u8fd9\u4e00\u65b0\u5931\u6548\u6a21\u5f0f\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u8bc6\u522b\u4e00\u4e2a\u4e0e\u5bfb\u6c42\u6f84\u6e05\u54cd\u5e94\u76f8\u5173\u7684\u67e5\u8be2\u72ec\u7acb\u3001\u666e\u904d\u5b58\u5728\u7684\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff0c\u4ece\u673a\u5236\u89d2\u5ea6\u5206\u6790\u4e86\u4e3a\u4f55\u4ee5\u53ca\u5982\u4f55\u4f1a\u53d1\u751f\u8fd9\u79cd\u73b0\u8c61\u3002\u7136\u540e\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4f9b\u5e94\u94fe\u653b\u51fb\uff08\u5982\u5fae\u8c03\uff09\u548c\u8fd0\u884c\u65f6\u653b\u51fb\uff08\u5982\u4f4e\u7ea7\u522b\u53c2\u6570\u7834\u574f\uff09\u6765\u8bf1\u5bfc\u6b64\u884c\u4e3a\u3002\u6700\u540e\uff0c\u5728\u591a\u4e2a\u6307\u4ee4\u8c03\u6574\u540e\u7684LLM\u53ca\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u6240\u63d0\u653b\u51fb\u7684\u6709\u6548\u6027\u548c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u7684\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u653b\u51fb\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5bfc\u81f4\u5bf9\u8bdd\u8f6e\u6b21\u663e\u8457\u589e\u52a0\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u73b0\u6709\u5408\u89c4\u8981\u6c42\u7684\u9075\u5b88\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5f53\u524d\u5df2\u6709\u7684\u9632\u62a4\u624b\u6bb5\u5bf9\u4e8e\u6b64\u7c7b\u65b0\u578b\u5931\u6548\u6a21\u5f0f\u6240\u63d0\u4f9b\u7684\u4fdd\u62a4\u4f5c\u7528\u76f8\u5f53\u6709\u9650\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63d0\u51fa\u4e86\u5bf9\u8bdd\u578bLLM\u4e2d\u7684\u2018\u56de\u5408\u653e\u5927\u2019\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5176\u80cc\u540e\u7684\u673a\u5236\uff0c\u5e76\u6f14\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u64cd\u7eb5\u6a21\u578b\u884c\u4e3a\u6765\u653e\u5927\u5bf9\u8bdd\u6210\u672c\u3002\u7814\u7a76\u6307\u51fa\uff0c\u672a\u6765\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u7b56\u7565\u6765\u62b5\u5fa1\u8fd9\u7c7b\u57fa\u4e8e\u5bf9\u8bdd\u52a8\u6001\u800c\u975e\u5355\u8f6e\u63d0\u793a\u4f18\u5316\u7684\u653b\u51fb\u65b9\u5f0f\u3002"}}
{"id": "2602.17798", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17798", "abs": "https://arxiv.org/abs/2602.17798", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Grassmannian Mixture-of-Experts: Concentration-Controlled Routing on Subspace Manifolds", "comment": null, "summary": "Mixture-of-Experts models rely on learned routers to assign tokens to experts, yet standard softmax gating provides no principled mechanism to control the tradeoff between sparsity and utilization. We propose Grassmannian MoE (GrMoE), a routing framework that operates on the Grassmannian manifold of subspaces, where gating weights arise from the concentration parameters of Matrix Bingham distributions. This construction yields a single, interpretable knob -- the concentration matrix $\u039b$ -- that continuously controls routing entropy, replacing discrete top-$k$ selection with a smooth, geometrically principled sparsity mechanism. We further develop an amortized variational inference procedure for posterior routing distributions, enabling uncertainty-aware expert assignment that naturally resists expert collapse. We formally prove tight bounds relating the Bingham concentration spectrum to routing entropy, expected top-$k$ mass, and an exponential bound on expert collapse, establishing the first formal theory of concentration-controlled sparsity. On synthetic routing tasks, a 350M-parameter MoE language model with 8 experts, a 1.3B-parameter model with 16 experts, and a 2.7B-parameter model with 32 experts, GrMoE achieves 0\\% routing collapse across all seeds, comparable or better perplexity with 15--30\\% improved load balance, and a smooth monotonic relationship between concentration and effective sparsity that enables post-hoc sparsity tuning without retraining. Token-level analysis reveals that experts learn heterogeneous concentration values that correlate with linguistic specialization, providing interpretable routing behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u8def\u7531\u6846\u67b6GrMoE\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u63a7\u5236Bingham\u5206\u5e03\u7684\u6d53\u5ea6\u77e9\u9635\u6765\u8fde\u7eed\u8c03\u8282\u8def\u7531\u71b5\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u7a00\u758f\u6027\u548c\u5229\u7528\u7387\u4e4b\u95f4\u6743\u8861\u7684\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u4f9d\u8d56\u4e8e\u5b66\u4e60\u5230\u7684\u8def\u7531\u5668\u5c06\u4ee4\u724c\u5206\u914d\u7ed9\u4e13\u5bb6\uff0c\u4f46\u6807\u51c6\u7684softmax\u95e8\u63a7\u673a\u5236\u65e0\u6cd5\u63d0\u4f9b\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u63a7\u5236\u7a00\u758f\u6027\u4e0e\u5229\u7528\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u4e00\u4e2a\u6b63\u5f0f\u7406\u8bba\u6765\u652f\u6301\u6d53\u5ea6\u63a7\u5236\u4e0b\u7684\u7a00\u758f\u6027\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86Grassmannian MoE (GrMoE)\u8fd9\u4e00\u57fa\u4e8eGrassmannian\u6d41\u5f62\u4e0a\u7684\u5b50\u7a7a\u95f4\u8fd0\u4f5c\u7684\u65b0\u8def\u7531\u6846\u67b6\uff0c\u5176\u4e2d\u95e8\u63a7\u6743\u91cd\u6765\u81ea\u4e8eMatrix Bingham\u5206\u5e03\u7684\u6d53\u5ea6\u53c2\u6570\uff0c\u5e76\u4e14\u8fd8\u63d0\u51fa\u4e86\u9488\u5bf9\u540e\u9a8c\u8def\u7531\u5206\u5e03\u7684\u4e00\u79cd\u644a\u9500\u53d8\u5206\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cGrMoE\u80fd\u591f\u8fbe\u52300%\u7684\u8def\u7531\u5d29\u6e83\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u4f18\u4e8e\u539f\u6709\u6a21\u578b\u7684\u56f0\u60d1\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e8615-30%\u7684\u8d1f\u8f7d\u5747\u8861\u6548\u7387\u3002\u6b64\u5916\uff0cGrMoE\u5c55\u793a\u4e86\u6d53\u5ea6\u4e0e\u6709\u6548\u7a00\u758f\u5ea6\u95f4\u7684\u5e73\u6ed1\u5355\u8c03\u5173\u7cfb\uff0c\u4f7f\u5f97\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u8c03\u6574\u7a00\u758f\u5ea6\u3002", "conclusion": "GrMoE\u4e3a\u89e3\u51b3Mixture-of-Experts\u6a21\u578b\u4e2d\u7684\u7a00\u758f\u6027\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u8fd8\u589e\u5f3a\u4e86\u8def\u7531\u884c\u4e3a\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.17809", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17809", "abs": "https://arxiv.org/abs/2602.17809", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Calibrated Adaptation: Bayesian Stiefel Manifold Priors for Reliable Parameter-Efficient Fine-Tuning", "comment": null, "summary": "Parameter-efficient fine-tuning methods such as LoRA enable practical adaptation of large language models but provide no principled uncertainty estimates, leading to poorly calibrated predictions and unreliable behavior under domain shift. We introduce Stiefel-Bayes Adapters (SBA), a Bayesian PEFT framework that places a Matrix Langevin prior over orthonormal adapter factors on the Stiefel manifold $\\St$ and performs approximate posterior inference via tangent space Laplace approximation with geodesic retraction. Unlike Gaussian priors in flat space projected onto orthogonality constraints, our prior on the manifold naturally encodes the inductive bias that adapter subspaces should be well conditioned and orthogonal, while the posterior provides calibrated predictive uncertainty without recalibration. We prove formally that the tangent space approximation strictly avoids the structural variance inflation inherent in projecting from ambient space, establishing a rigorous theoretical advantage for intrinsic manifold inference. Across GLUE and SuperGLUE benchmarks on RoBERTa-large, LLaMA-2-7B, LLaMA-2-13B, Mistral-7B, and Qwen2.5-7B, domain shift evaluations, selective prediction protocols, and an abstractive summarization task, SBA achieves task performance comparable to LoRA and DoRA while reducing Expected Calibration Error by 18 to 34\\% over deterministic baselines, improving selective prediction AUROC by 12 to 25\\% under domain shift, and outperforming deep ensembles of five LoRA models on OOD detection at a fraction of the parameter cost. Our results demonstrate that where you place uncertainty, on the right geometric structure, matters more than simply adding any Bayesian treatment to adapters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStiefel-Bayes Adapters (SBA)\u7684\u8d1d\u53f6\u65af\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u8be5\u65b9\u6cd5\u5728Stiefel\u6d41\u5f62\u4e0a\u5bf9\u6b63\u4ea4\u9002\u914d\u5668\u56e0\u5b50\u65bd\u52a0\u77e9\u9635Langevin\u5148\u9a8c\uff0c\u5e76\u901a\u8fc7\u5207\u7a7a\u95f4\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u4e0e\u6d4b\u5730\u7ebf\u56de\u7f29\u6267\u884c\u8fd1\u4f3c\u540e\u9a8c\u63a8\u7406\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSBA\u5728\u4fdd\u6301\u4e0e\u73b0\u6709\u65b9\u6cd5\uff08\u5982LoRA\u548cDoRA\uff09\u76f8\u5f53\u7684\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u6548\u679c\u3001\u9009\u62e9\u6027\u9884\u6d4bAUROC\u4ee5\u53caOOD\u68c0\u6d4b\u6027\u80fd\uff0c\u4e14\u53c2\u6570\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5982LoRA\u867d\u7136\u80fd\u591f\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u9002\u5e94\uff0c\u4f46\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5bfc\u81f4\u9884\u6d4b\u4e0d\u51c6\u786e\u53ca\u5728\u9886\u57df\u8fc1\u79fb\u65f6\u884c\u4e3a\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86Stiefel-Bayes Adapters (SBA)\uff0c\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6846\u67b6\uff0c\u5b83\u5728Stiefel\u6d41\u5f62\u4e0a\u4e3a\u6b63\u4ea4\u9002\u914d\u5668\u56e0\u5b50\u5f15\u5165\u4e86\u77e9\u9635Langevin\u5148\u9a8c\uff0c\u5e76\u901a\u8fc7\u5207\u7a7a\u95f4\u4e2d\u7684\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u52a0\u4e0a\u6d4b\u5730\u7ebf\u56de\u7f29\u6765\u8fdb\u884c\u8fd1\u4f3c\u540e\u9a8c\u63a8\u65ad\u3002", "result": "\u5b9e\u9a8c\u6db5\u76d6\u4e86GLUE\u548cSuperGLUE\u57fa\u51c6\u6d4b\u8bd5\u3001\u9886\u57df\u8fc1\u79fb\u8bc4\u4f30\u3001\u9009\u62e9\u6027\u9884\u6d4b\u534f\u8bae\u4ee5\u53ca\u62bd\u8c61\u6458\u8981\u4efb\u52a1\u7b49\u573a\u666f\uff0c\u5728\u8fd9\u4e9b\u573a\u666f\u4e0b\uff0cSBA\u4e0d\u4ec5\u8fbe\u5230\u4e86\u4e0eLoRA\u548cDoRA\u76f8\u4f3c\u7684\u4efb\u52a1\u8868\u73b0\u6c34\u5e73\uff0c\u8fd8\u51cf\u5c11\u4e8618%\u523034%\u7684\u9884\u671f\u6821\u51c6\u8bef\u5dee\uff0c\u63d0\u5347\u4e86\u9886\u57df\u8fc1\u79fb\u60c5\u51b5\u4e0b\u9009\u62e9\u6027\u9884\u6d4b\u7684AUROC 12%\u81f325%\uff0c\u5e76\u4e14\u5728OOD\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u7531\u4e94\u4e2aLoRA\u6a21\u578b\u7ec4\u6210\u7684\u6df1\u5ea6\u96c6\u6210\uff0c\u540c\u65f6\u53ea\u6d88\u8017\u4e86\u5c11\u91cf\u7684\u53c2\u6570\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u7f6e\u4e8e\u6b63\u786e\u7684\u51e0\u4f55\u7ed3\u6784\u4e0a\u6bd4\u7b80\u5355\u5730\u5411\u9002\u914d\u5668\u6dfb\u52a0\u4efb\u4f55\u8d1d\u53f6\u65af\u5904\u7406\u66f4\u4e3a\u91cd\u8981\uff0cSBA\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.17829", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17829", "abs": "https://arxiv.org/abs/2602.17829", "authors": ["Preetom Biswas", "Giulia Pedrielli", "K. Sel\u00e7uk Candan"], "title": "Causality by Abstraction: Symbolic Rule Learning in Multivariate Timeseries with Large Language Models", "comment": null, "summary": "Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings. Traditional approaches often fail to produce generalized and interpretable explanations, as multiple distinct input trajectories may yield nearly indistinguishable outputs. In this work, we present ruleXplain, a framework that leverages Large Language Models (LLMs) to extract formal explanations for input-output relations in simulation-driven dynamical systems. Our method introduces a constrained symbolic rule language with temporal operators and delay semantics, enabling LLMs to generate verifiable causal rules through structured prompting. ruleXplain relies on the availability of a principled model (e.g., a simulator) that maps multivariate input time series to output time series. Within ruleXplain, the simulator is used to generate diverse counterfactual input trajectories that yield similar target output, serving as candidate explanations. Such counterfactual inputs are clustered and provided as context to the LLM, which is tasked with the generation of symbolic rules encoding the joint temporal trends responsible for the patterns observable in the output times series. A closed-loop refinement process ensures rule consistency and semantic validity. We validate the framework using the PySIRTEM epidemic simulator, mapping testing rate inputs to daily infection counts; and the EnergyPlus building energy simulator, observing temperature and solar irradiance inputs to electricity needs. For validation, we perform three classes of experiments: (1) the efficacy of the ruleset through input reconstruction; (2) ablation studies evaluating the causal encoding of the ruleset; and (3) generalization tests of the extracted rules across unseen output trends with varying phase dynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aruleXplain\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u6a21\u62df\u9a71\u52a8\u7684\u52a8\u6001\u7cfb\u7edf\u4e2d\u63d0\u53d6\u8f93\u5165-\u8f93\u51fa\u5173\u7cfb\u7684\u5f62\u5f0f\u5316\u89e3\u91ca\u3002\u901a\u8fc7\u5f15\u5165\u5177\u6709\u65f6\u95f4\u64cd\u4f5c\u7b26\u548c\u5ef6\u8fdf\u8bed\u4e49\u7684\u7ea6\u675f\u7b26\u53f7\u89c4\u5219\u8bed\u8a00\uff0c\u5e76\u7ed3\u5408\u6a21\u62df\u5668\u751f\u6210\u591a\u6837\u5316\u7684\u53cd\u4e8b\u5b9e\u8f93\u5165\u8f68\u8ff9\uff0c\u4f7f\u5f97LLM\u80fd\u591f\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u56e0\u679c\u89c4\u5219\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u95ed\u73af\u7cbe\u70bc\u8fc7\u7a0b\u4fdd\u8bc1\u4e86\u89c4\u5219\u7684\u4e00\u81f4\u6027\u548c\u8bed\u4e49\u6709\u6548\u6027\u3002\u7814\u7a76\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u6a21\u62df\u5668\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff1aPySIRTEM\u6d41\u884c\u75c5\u6a21\u62df\u5668\u548cEnergyPlus\u5efa\u7b51\u80fd\u6e90\u6a21\u62df\u5668\uff0c\u5e76\u901a\u8fc7\u4e09\u7c7b\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3001\u56e0\u679c\u7f16\u7801\u80fd\u529b\u4ee5\u53ca\u89c4\u5219\u96c6\u5bf9\u672a\u89c1\u8f93\u51fa\u8d8b\u52bf\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u5ef6\u8fdf\u6548\u5e94\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u96be\u4ee5\u4ea7\u751f\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u7684\u56e0\u679c\u5173\u7cfb\u89e3\u91ca\uff0c\u5c24\u5176\u662f\u5728\u7cfb\u7edf\u8868\u73b0\u51fa\u65e0\u6cd5\u901a\u8fc7\u7b80\u5355\u51fd\u6570\u6620\u5c04\u6355\u6349\u5230\u7684\u590d\u6742\u52a8\u6001\u60c5\u51b5\u4e0b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6ruleXplain\u3002", "method": "ruleXplain\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ece\u6a21\u62df\u9a71\u52a8\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u4e2d\u63d0\u53d6\u5173\u4e8e\u8f93\u5165-\u8f93\u51fa\u5173\u7cfb\u7684\u5f62\u5f0f\u5316\u89e3\u91ca\u3002\u5b83\u5f15\u5165\u4e86\u4e00\u79cd\u5305\u542b\u65f6\u95f4\u7b97\u5b50\u548c\u5ef6\u8fdf\u8bed\u4e49\u7684\u53d7\u9650\u7b26\u53f7\u89c4\u5219\u8bed\u8a00\uff0c\u5141\u8bb8LLMs\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u63d0\u793a\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u56e0\u679c\u89c4\u5219\u3002\u6b64\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6a21\u578b\uff08\u5982\u6a21\u62df\u5668\uff09\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u5c06\u591a\u53d8\u91cf\u8f93\u5165\u65f6\u95f4\u5e8f\u5217\u6620\u5c04\u5230\u8f93\u51fa\u65f6\u95f4\u5e8f\u5217\u3002\u6a21\u62df\u5668\u7528\u4e8e\u751f\u6210\u591a\u79cd\u53cd\u4e8b\u5b9e\u8f93\u5165\u8f68\u8ff9\u4f5c\u4e3a\u5019\u9009\u89e3\u91ca\uff0c\u5e76\u901a\u8fc7\u805a\u7c7b\u63d0\u4f9b\u7ed9LLM\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u4efb\u52a1\u662f\u751f\u6210\u7f16\u7801\u5bfc\u81f4\u8f93\u51fa\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u8054\u5408\u65f6\u95f4\u8d8b\u52bf\u7684\u7b26\u53f7\u89c4\u5219\u3002\u6574\u4e2a\u8fc7\u7a0b\u5305\u62ec\u4e00\u4e2a\u95ed\u5408\u5faa\u73af\u7ec6\u5316\u6b65\u9aa4\u4ee5\u786e\u4fdd\u89c4\u5219\u4e00\u81f4\u6027\u548c\u8bed\u4e49\u6b63\u786e\u6027\u3002", "result": "\u901a\u8fc7\u5bf9PySIRTEM\u6d41\u884c\u75c5\u6a21\u62df\u5668\uff08\u6d4b\u8bd5\u7387\u8f93\u5165\u4e0e\u6bcf\u65e5\u611f\u67d3\u8ba1\u6570\u7684\u5173\u7cfb\uff09\u53caEnergyPlus\u5efa\u7b51\u80fd\u8017\u6a21\u62df\u5668\uff08\u6e29\u5ea6\u548c\u592a\u9633\u8f90\u5c04\u8f93\u5165\u5bf9\u7535\u529b\u9700\u6c42\u7684\u5f71\u54cd\uff09\u7684\u5e94\u7528\uff0c\u9a8c\u8bc1\u4e86ruleXplain\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u5206\u4e3a\u4e09\u5927\u7c7b\uff1a(1) \u901a\u8fc7\u8f93\u5165\u91cd\u5efa\u6765\u68c0\u9a8c\u89c4\u5219\u96c6\u7684\u6548\u679c\uff1b(2) \u901a\u8fc7\u6d88\u878d\u7814\u7a76\u8bc4\u4ef7\u89c4\u5219\u96c6\u4e2d\u56e0\u679c\u5173\u7cfb\u7684\u7f16\u7801\u60c5\u51b5\uff1b(3) \u5bf9\u63d0\u53d6\u51fa\u7684\u89c4\u5219\u5728\u4e0d\u540c\u76f8\u4f4d\u52a8\u6001\u4e0b\u7684\u672a\u89c1\u8f93\u51fa\u8d8b\u52bf\u8fdb\u884c\u6cdb\u5316\u6d4b\u8bd5\u3002", "conclusion": "\u63d0\u51fa\u7684ruleXplain\u6846\u67b6\u6210\u529f\u5730\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u590d\u6742\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u5f3a\u7684\u56e0\u679c\u89c4\u5219\u3002\u8fd9\u4e9b\u89c4\u5219\u4e0d\u4ec5\u80fd\u591f\u51c6\u786e\u63cf\u8ff0\u5df2\u77e5\u6570\u636e\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u800c\u4e14\u8fd8\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u81f3\u65b0\u7684\u573a\u666f\u4e0b\uff0c\u663e\u793a\u51fa\u5176\u5f3a\u5927\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.17832", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.17832", "abs": "https://arxiv.org/abs/2602.17832", "authors": ["Hang Liu", "Sangli Teng", "Maani Ghaffari"], "title": "MePoly: Max Entropy Polynomial Policy Optimization", "comment": null, "summary": "Stochastic Optimal Control provides a unified mathematical framework for solving complex decision-making problems, encompassing paradigms such as maximum entropy reinforcement learning(RL) and imitation learning(IL). However, conventional parametric policies often struggle to represent the multi-modality of the solutions. Though diffusion-based policies are aimed at recovering the multi-modality, they lack an explicit probability density, which complicates policy-gradient optimization. To bridge this gap, we propose MePoly, a novel policy parameterization based on polynomial energy-based models. MePoly provides an explicit, tractable probability density, enabling exact entropy maximization. Theoretically, we ground our method in the classical moment problem, leveraging the universal approximation capabilities for arbitrary distributions. Empirically, we demonstrate that MePoly effectively captures complex non-convex manifolds and outperforms baselines in performance across diverse benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u9879\u5f0f\u80fd\u91cf\u6a21\u578b\u7684\u65b0\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6cd5MePoly\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u968f\u673a\u6700\u4f18\u63a7\u5236\u4e2d\u53c2\u6570\u5316\u7b56\u7565\u96be\u4ee5\u8868\u793a\u89e3\u7684\u591a\u6a21\u6001\u6027\u548c\u57fa\u4e8e\u6269\u6563\u7684\u7b56\u7565\u7f3a\u4e4f\u663e\u5f0f\u6982\u7387\u5bc6\u5ea6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u5316\u7b56\u7565\u5728\u8868\u793a\u89e3\u7684\u591a\u6a21\u6001\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u57fa\u4e8e\u6269\u6563\u7684\u7b56\u7565\u867d\u7136\u80fd\u591f\u6062\u590d\u591a\u6a21\u6001\u6027\u4f46\u7f3a\u4e4f\u663e\u5f0f\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u8fd9\u7ed9\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u540d\u4e3aMePoly\u7684\u65b0\u7b56\u7565\u53c2\u6570\u5316\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u57fa\u4e8e\u591a\u9879\u5f0f\u80fd\u91cf\u6a21\u578b\u6784\u5efa\uff0c\u63d0\u4f9b\u4e86\u660e\u786e\u4e14\u53ef\u5904\u7406\u7684\u6982\u7387\u5bc6\u5ea6\uff0c\u5141\u8bb8\u8fdb\u884c\u7cbe\u786e\u7684\u71b5\u6700\u5927\u5316\u3002\u5176\u7406\u8bba\u57fa\u7840\u662f\u7ecf\u5178\u7684\u77e9\u95ee\u9898\uff0c\u5e76\u5229\u7528\u4e86\u5bf9\u4e8e\u4efb\u610f\u5206\u5e03\u5177\u6709\u901a\u7528\u903c\u8fd1\u80fd\u529b\u7684\u7279\u70b9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMePoly\u80fd\u591f\u6709\u6548\u5730\u6355\u6349\u590d\u6742\u7684\u975e\u51f8\u6d41\u5f62\uff0c\u5e76\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165MePoly\u4f5c\u4e3a\u65b0\u7684\u7b56\u7565\u53c2\u6570\u5316\u624b\u6bb5\uff0c\u7814\u7a76\u8005\u4eec\u4e0d\u4ec5\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6a21\u6001\u89e3\u65f6\u9047\u5230\u7684\u95ee\u9898\uff0c\u8fd8\u4e3a\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2602.17846", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17846", "abs": "https://arxiv.org/abs/2602.17846", "authors": ["Nick Dodson", "Xinyu Gao", "Qingsong Wang", "Yusu Wang", "Zhengchao Wan"], "title": "Two Calm Ends and the Wild Middle: A Geometric Picture of Memorization in Diffusion Models", "comment": null, "summary": "Diffusion models generate high-quality samples but can also memorize training data, raising serious privacy concerns. Understanding the mechanisms governing when memorization versus generalization occurs remains an active area of research. In particular, it is unclear where along the noise schedule memorization is induced, how data geometry influences it, and how phenomena at different noise scales interact. We introduce a geometric framework that partitions the noise schedule into three regimes based on the coverage properties of training data by Gaussian shells and the concentration behavior of the posterior, which we argue are two fundamental objects governing memorization and generalization in diffusion models. This perspective reveals that memorization risk is highly non-uniform across noise levels. We further identify a danger zone at medium noise levels where memorization is most pronounced. In contrast, both the small and large noise regimes resist memorization, but through fundamentally different mechanisms: small noise avoids memorization due to limited training coverage, while large noise exhibits low posterior concentration and admits a provably near linear Gaussian denoising behavior. For the medium noise regime, we identify geometric conditions through which we propose a geometry-informed targeted intervention that mitigates memorization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u7406\u89e3\u6269\u6563\u6a21\u578b\u5728\u566a\u58f0\u8c03\u5ea6\u8fc7\u7a0b\u4e2d\u4f55\u65f6\u53d1\u751f\u8bb0\u5fc6\u5316\u6216\u6cdb\u5316\uff0c\u5e76\u53d1\u73b0\u4e2d\u7b49\u566a\u58f0\u6c34\u5e73\u662f\u8bb0\u5fc6\u5316\u98ce\u9669\u6700\u9ad8\u7684'\u5371\u9669\u533a'\u3002\u5bf9\u4e8e\u8fd9\u4e00\u533a\u57df\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u57fa\u4e8e\u51e0\u4f55\u6761\u4ef6\u7684\u5e72\u9884\u63aa\u65bd\u4ee5\u51cf\u8f7b\u8bb0\u5fc6\u5316\u95ee\u9898\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u4f46\u540c\u65f6\u4e5f\u53ef\u80fd\u8bb0\u4f4f\u8bad\u7ec3\u6570\u636e\uff0c\u5f15\u53d1\u9690\u79c1\u95ee\u9898\u3002\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u8bb0\u5fc6\u5316\u4e0e\u6cdb\u5316\u53d1\u751f\u7684\u673a\u5236\u3001\u6cbf\u566a\u58f0\u8c03\u5ea6\u7684\u8bb0\u5fc6\u5316\u4f4d\u7f6e\u3001\u6570\u636e\u51e0\u4f55\u5982\u4f55\u5f71\u54cd\u8bb0\u5fc6\u5316\u4ee5\u53ca\u4e0d\u540c\u566a\u58f0\u5c3a\u5ea6\u4e0b\u73b0\u8c61\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9ad8\u65af\u58f3\u5c42\u8986\u76d6\u7279\u6027\u548c\u540e\u9a8c\u96c6\u4e2d\u884c\u4e3a\u7684\u51e0\u4f55\u6846\u67b6\uff0c\u5c06\u566a\u58f0\u8c03\u5ea6\u5212\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\u3002", "result": "\u63ed\u793a\u4e86\u8bb0\u5fc6\u5316\u98ce\u9669\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u7684\u975e\u5747\u5300\u5206\u5e03\uff1b\u8bc6\u522b\u51fa\u4e2d\u7b49\u566a\u58f0\u6c34\u5e73\u4e3a\u8bb0\u5fc6\u5316\u6700\u663e\u8457\u7684\u2018\u5371\u9669\u533a\u2019\uff1b\u5c0f\u566a\u58f0\u548c\u5927\u566a\u58f0\u533a\u57df\u901a\u8fc7\u4e0d\u540c\u7684\u673a\u5236\u62b5\u6297\u8bb0\u5fc6\u5316\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u4e2d\u7b49\u566a\u58f0\u6c34\u5e73\u7684\u8bb0\u5fc6\u5316\u7f13\u89e3\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u57fa\u4e8e\u7279\u5b9a\u7684\u51e0\u4f55\u6761\u4ef6\u3002"}}
{"id": "2602.17861", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17861", "abs": "https://arxiv.org/abs/2602.17861", "authors": ["Ryan McKenna", "Galen Andrew", "Borja Balle", "Vadym Doroshenko", "Arun Ganesh", "Weiwei Kong", "Alex Kurakin", "Brendan McMahan", "Mikhail Pravilov"], "title": "JAX-Privacy: A library for differentially private machine learning", "comment": null, "summary": "JAX-Privacy is a library designed to simplify the deployment of robust and performant mechanisms for differentially private machine learning. Guided by design principles of usability, flexibility, and efficiency, JAX-Privacy serves both researchers requiring deep customization and practitioners who want a more out-of-the-box experience. The library provides verified, modular primitives for critical components for all aspects of the mechanism design including batch selection, gradient clipping, noise addition, accounting, and auditing, and brings together a large body of recent research on differentially private ML.", "AI": {"tldr": "JAX-Privacy\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u7b80\u5316\u90e8\u7f72\u5dee\u5f02\u9690\u79c1\u673a\u5668\u5b66\u4e60\u673a\u5236\u7684\u5e93\uff0c\u5b83\u7ed3\u5408\u4e86\u8fd1\u671f\u5927\u91cf\u76f8\u5173\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u5305\u62ec\u6279\u9009\u62e9\u3001\u68af\u5ea6\u88c1\u526a\u3001\u566a\u97f3\u6dfb\u52a0\u7b49\u529f\u80fd\u5728\u5185\u7684\u9a8c\u8bc1\u8fc7\u7684\u6a21\u5757\u5316\u7ec4\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u7b80\u5316\u5f3a\u5065\u4e14\u9ad8\u6548\u7684\u5dee\u5f02\u9690\u79c1\u673a\u5668\u5b66\u4e60\u673a\u5236\u7684\u90e8\u7f72\u8fc7\u7a0b\uff0c\u5e76\u540c\u65f6\u6ee1\u8db3\u7814\u7a76\u4eba\u5458\u5bf9\u4e8e\u6df1\u5ea6\u5b9a\u5236\u7684\u9700\u6c42\u4ee5\u53ca\u5b9e\u8df5\u8005\u5bf9\u5f00\u7bb1\u5373\u7528\u4f53\u9a8c\u7684\u8981\u6c42\u3002", "method": "\u901a\u8fc7\u9075\u5faa\u53ef\u7528\u6027\u3001\u7075\u6d3b\u6027\u548c\u6548\u7387\u7684\u8bbe\u8ba1\u539f\u5219\u5f00\u53d1\u51faJAX-Privacy\u5e93\uff0c\u8be5\u5e93\u4e3a\u673a\u5236\u8bbe\u8ba1\u7684\u6240\u6709\u5173\u952e\u65b9\u9762\uff08\u5982\u6279\u5904\u7406\u9009\u62e9\u3001\u68af\u5ea6\u88c1\u526a\u3001\u566a\u58f0\u6dfb\u52a0\u7b49\uff09\u63d0\u4f9b\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6a21\u5757\u5316\u57fa\u7840\u7ec4\u4ef6\u3002", "result": "JAX-Privacy\u80fd\u591f\u652f\u6301\u4ece\u9ad8\u5ea6\u5b9a\u5236\u5230\u76f4\u63a5\u5e94\u7528\u7684\u4e0d\u540c\u9700\u6c42\uff0c\u6574\u5408\u4e86\u5927\u91cf\u7684\u6700\u65b0\u7814\u7a76\u6210\u679c\u6765\u4fc3\u8fdb\u5dee\u5f02\u9690\u79c1\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "JAX-Privacy\u4f5c\u4e3a\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u4f7f\u5dee\u5f02\u9690\u79c1\u6280\u672f\u66f4\u52a0\u6613\u4e8e\u4f7f\u7528\u5e76\u63d0\u9ad8\u5176\u6027\u80fd\uff0c\u4ece\u800c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.17867", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.17867", "abs": "https://arxiv.org/abs/2602.17867", "authors": ["Jo\u00e3o N. Cardoso", "Arlindo L. Oliveira", "Bruno Martins"], "title": "ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization", "comment": null, "summary": "Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADAPT\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u675f\u641c\u7d22\u521d\u59cb\u5316\u4e0e\u81ea\u9002\u5e94\u68af\u5ea6\u5f15\u5bfc\u7684\u53d8\u5f02\uff0c\u65e8\u5728\u514b\u670d\u6587\u672c\u79bb\u6563\u6027\u53ca\u73b0\u6709\u63d0\u793a\u4f18\u5316\u6280\u672f\u5728\u5c40\u90e8\u6781\u5c0f\u503c\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u3002\u901a\u8fc7\u5728Gemma 2 2B\u7684\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u6f5c\u5728\u53d8\u91cf\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u96c6\u6fc0\u6d3b\u7edf\u8ba1\u7684\u65b0\u6307\u6807\uff0c\u8bc1\u660eADAPT\u5728\u4e0d\u540c\u5c42\u548c\u6f5c\u5728\u7c7b\u578b\u4e2d\u5747\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3LLM\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5b66\u5230\u7684\u65b9\u5411\u6240\u7f16\u7801\u7684\u7279\u5f81\u9700\u8981\u8bc6\u522b\u5f3a\u70c8\u6fc0\u6d3b\u8fd9\u4e9b\u65b9\u5411\u7684\u8f93\u5165\u3002\u7531\u4e8e\u6587\u672c\u56fa\u6709\u7684\u79bb\u6563\u6027\u8d28\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a2\u7d22\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u5177\u6709\u6311\u6218\u6027\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7684\u63d0\u793a\u4f18\u5316\u6280\u672f\u5728\u8fd9\u4e2a\u9886\u57df\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86ADAPT\u65b9\u6cd5\uff0c\u5b83\u662f\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u675f\u641c\u7d22\u521d\u59cb\u5316\u4e0e\u6839\u636e\u68af\u5ea6\u8c03\u6574\u7684\u7a81\u53d8\u7b56\u7565\uff0c\u4e13\u95e8\u9488\u5bf9\u4e0a\u8ff0\u96be\u9898\u800c\u8bbe\u8ba1\u3002", "result": "\u901a\u8fc7\u5bf9Gemma 2 2B\u6a21\u578b\u4e2d\u7684\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6570\u636e\u96c6\u6fc0\u6d3b\u7edf\u8ba1\u6570\u636e\u7684\u65b0\u6307\u6807\u6765\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660eADAPT\u5728\u5404\u79cd\u5c42\u6b21\u548c\u4e0d\u540c\u7c7b\u578b\u6f5c\u5728\u53d8\u91cf\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8eLLMs\u800c\u8a00\uff0c\u7279\u5f81\u53ef\u89c6\u5316\u662f\u53ef\u884c\u7684\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u8be5\u9886\u57df\u7684\u7279\u5b9a\u5047\u8bbe\u6765\u8fdb\u884c\u8bbe\u8ba1\u3002"}}
{"id": "2602.17868", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17868", "abs": "https://arxiv.org/abs/2602.17868", "authors": ["Vasilii Feofanov", "Songkang Wen", "Jianfeng Zhang", "Lujia Pan", "Ievgen Redko"], "title": "MantisV2: Closing the Zero-Shot Gap in Time Series Classification with Synthetic Data and Test-Time Strategies", "comment": null, "summary": "Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks. Although early models such as Mantis have shown the promise of this approach, a substantial performance gap remained between frozen and fine-tuned encoders. In this work, we introduce methods that significantly strengthen zero-shot feature extraction for time series. First, we introduce Mantis+, a variant of Mantis pre-trained entirely on synthetic time series. Second, through controlled ablation studies, we refine the architecture and obtain MantisV2, an improved and more lightweight encoder. Third, we propose an enhanced test-time methodology that leverages intermediate-layer representations and refines output-token aggregation. In addition, we show that performance can be further improved via self-ensembling and cross-model embedding fusion. Extensive experiments on UCR, UEA, Human Activity Recognition (HAR) benchmarks, and EEG datasets show that MantisV2 and Mantis+ consistently outperform prior time series foundation models, achieving state-of-the-art zero-shot performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165Mantis+\u548cMantisV2\u6a21\u578b\u3001\u6539\u8fdb\u6d4b\u8bd5\u65f6\u65b9\u6cd5\u4ee5\u53ca\u91c7\u7528\u81ea\u96c6\u6210\u548c\u8de8\u6a21\u578b\u5d4c\u5165\u878d\u5408\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u7840\u6a21\u578b\u7684\u96f6\u6837\u672c\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u65e9\u671f\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u7840\u6a21\u578b\u5982Mantis\u5c55\u793a\u4e86\u4f5c\u4e3a\u901a\u7528\u7279\u5f81\u63d0\u53d6\u5668\u5e94\u7528\u4e8e\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u53ef\u80fd\u6027\uff0c\u4f46\u5728\u51bb\u7ed3\u7f16\u7801\u5668\u4e0e\u5fae\u8c03\u7f16\u7801\u5668\u4e4b\u95f4\u4ecd\u5b58\u5728\u660e\u663e\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u9ad8\u96f6\u6837\u672c\u7279\u5f81\u63d0\u53d6\u7684\u80fd\u529b\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u6280\u672f\u3002", "method": "1. \u5f15\u5165\u4e86Mantis+\uff0c\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8e\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u9884\u8bad\u7ec3\u7684Mantis\u53d8\u4f53\u3002\n2. \u901a\u8fc7\u63a7\u5236\u6027\u6d88\u878d\u7814\u7a76\u7cbe\u70bc\u67b6\u6784\uff0c\u5f00\u53d1\u51fa\u66f4\u8f7b\u91cf\u7ea7\u7684\u7f16\u7801\u5668MantisV2\u3002\n3. \u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u6d4b\u8bd5\u65f6\u65b9\u6cd5\uff0c\u5229\u7528\u4e2d\u95f4\u5c42\u8868\u793a\u5e76\u4f18\u5316\u8f93\u51fa\u6807\u8bb0\u805a\u5408\u3002\n4. \u5c55\u793a\u4e86\u901a\u8fc7\u81ea\u6211\u96c6\u6210\u548c\u8de8\u6a21\u578b\u5d4c\u5165\u878d\u5408\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMantisV2\u548cMantis+\u5728UCR\u3001UEA\u3001\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u57fa\u51c6\u4ee5\u53caEEG\u6570\u636e\u96c6\u4e0a\u4e00\u81f4\u5730\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5f15\u5165\u65b0\u578b\u6a21\u578b\u548c\u6280\u672f\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u96f6\u6837\u672c\u7279\u5f81\u63d0\u53d6\u7684\u8868\u73b0\u529b\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u52a0\u9ad8\u6548\u4e14\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.17888", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17888", "abs": "https://arxiv.org/abs/2602.17888", "authors": ["Sayeed Shafayet Chowdhury", "Karen D'Souza", "V. Siva Kakumani", "Snehasis Mukhopadhyay", "Shiaofen Fang", "Rodney J. Schlosser", "Daniel M. Beswick", "Jeremiah A. Alt", "Jess C. Mace", "Zachary M. Soler", "Timothy L. Smith", "Vijay R. Ramakrishnan"], "title": "Machine Learning Based Prediction of Surgical Outcomes in Chronic Rhinosinusitis from Clinical Data", "comment": null, "summary": "Artificial intelligence (AI) has increasingly transformed medical prognostics by enabling rapid and accurate analysis across imaging and pathology. However, the investigation of machine learning predictions applied to prospectively collected, standardized data from observational clinical intervention trials remains underexplored, despite its potential to reduce costs and improve patient outcomes. Chronic rhinosinusitis (CRS), a persistent inflammatory disease of the paranasal sinuses lasting more than three months, imposes a substantial burden on quality of life (QoL) and societal cost. Although many patients respond to medical therapy, others with refractory symptoms often pursue surgical intervention. Surgical decision-making in CRS is complex, as it must weigh known procedural risks against uncertain individualized outcomes. In this study, we evaluated supervised machine learning models for predicting surgical benefit in CRS, using the Sino-Nasal Outcome Test-22 (SNOT-22) as the primary patient-reported outcome. Our prospectively collected cohort from an observational intervention trial comprised patients who all underwent surgery; we investigated whether models trained only on preoperative data could identify patients who might not have been recommended surgery prior to the procedure. Across multiple algorithms, including an ensemble approach, our best model achieved approximately 85% classification accuracy, providing accurate and interpretable predictions of surgical candidacy. Moreover, on a held-out set of 30 cases spanning mixed difficulty, our model achieved 80% accuracy, exceeding the average prediction accuracy of expert clinicians (75.6%), demonstrating its potential to augment clinical decision-making and support personalized CRS care.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u6162\u6027\u9f3b\u7aa6\u708e(CRS)\u60a3\u8005\u624b\u672f\u6548\u76ca\u65b9\u9762\u7684\u5e94\u7528\uff0c\u4f7f\u7528\u672f\u524d\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u4ee5\u7ea685%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8bc6\u522b\u53ef\u80fd\u4e0d\u9700\u8981\u624b\u672f\u7684\u60a3\u8005\u3002\u572830\u4e2a\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u7684\u6848\u4f8b\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u8fbe\u5230\u4e8680%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86\u4e34\u5e8a\u4e13\u5bb675.6%\u7684\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u663e\u793a\u51fa\u5176\u652f\u6301\u4e2a\u6027\u5316CRS\u62a4\u7406\u548c\u589e\u5f3a\u4e34\u5e8a\u51b3\u7b56\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u533b\u5b66\u9884\u540e\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5bf9\u4e8e\u524d\u77bb\u6027\u6536\u96c6\u7684\u6807\u51c6\u89c2\u5bdf\u6027\u4e34\u5e8a\u5e72\u9884\u8bd5\u9a8c\u6570\u636e\u7684\u5e94\u7528\u63a2\u7d22\u4ecd\u4e0d\u8db3\uff0c\u800c\u8fd9\u4e9b\u6280\u672f\u6709\u6f5c\u529b\u964d\u4f4e\u6210\u672c\u5e76\u6539\u5584\u60a3\u8005\u7ed3\u679c\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u6162\u6027\u9f3b\u7aa6\u708e\uff08CRS\uff09\u8fd9\u79cd\u6301\u7eed\u65f6\u95f4\u8d85\u8fc7\u4e09\u4e2a\u6708\u3001\u4e25\u91cd\u5f71\u54cd\u751f\u6d3b\u8d28\u91cf\u4e0e\u793e\u4f1a\u6210\u672c\u7684\u75be\u75c5\u800c\u8a00\uff0c\u624b\u672f\u51b3\u7b56\u56e0\u5176\u9700\u8981\u6743\u8861\u5df2\u77e5\u7a0b\u5e8f\u98ce\u9669\u4e0e\u4e2a\u4f53\u5316\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\u800c\u53d8\u5f97\u590d\u6742\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4bCRS\u60a3\u8005\u7684\u624b\u672f\u6548\u76ca\uff0c\u4e3b\u8981\u4f9d\u636e\u662fSino-Nasal Outcome Test-22 (SNOT-22)\u8fd9\u4e00\u60a3\u8005\u62a5\u544a\u7684\u7ed3\u679c\u6307\u6807\u3002\u6240\u6709\u53c2\u4e0e\u8005\u5747\u63a5\u53d7\u4e86\u624b\u672f\u6cbb\u7597\uff1b\u7814\u7a76\u8005\u8bd5\u56fe\u901a\u8fc7\u4ec5\u57fa\u4e8e\u672f\u524d\u4fe1\u606f\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u6765\u786e\u5b9a\u54ea\u4e9b\u60a3\u8005\u6216\u8bb8\u53ef\u4ee5\u907f\u514d\u624b\u672f\u3002\u6b64\u5916\uff0c\u8fd8\u6bd4\u8f83\u4e86\u591a\u4e2a\u7b97\u6cd5\u7684\u8868\u73b0\uff0c\u5e76\u91c7\u7528\u4e86\u4e00\u79cd\u96c6\u6210\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u591a\u79cd\u7b97\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u5927\u7ea685%\u7684\u5206\u7c7b\u51c6\u786e\u5ea6\uff0c\u8868\u660e\u5b83\u80fd\u591f\u63d0\u4f9b\u7cbe\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u624b\u672f\u5019\u9009\u8d44\u683c\u9884\u6d4b\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u5728\u4e00\u7ec4\u5305\u542b\u6df7\u5408\u96be\u5ea6\u6c34\u5e73\u768430\u4e2a\u6848\u4f8b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u65f6\uff0c\u8be5\u6a21\u578b\u8fbe\u5230\u4e8680%\u7684\u51c6\u786e\u5ea6\uff0c\u4f18\u4e8e\u4e13\u5bb6\u4e34\u5e8a\u533b\u751f75.6%\u7684\u5e73\u5747\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4bCRS\u60a3\u8005\u662f\u5426\u9002\u5408\u63a5\u53d7\u624b\u672f\u5177\u6709\u5f88\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u8be5\u6a21\u578b\u63d0\u4f9b\u7684\u9884\u6d4b\u7ed3\u679c\u751a\u81f3\u4f18\u4e8e\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4e34\u5e8a\u533b\u751f\u3002\u8fd9\u8868\u660e\u6b64\u7c7bAI\u5de5\u5177\u5177\u5907\u8f85\u52a9\u4e34\u5e8a\u51b3\u7b56\u548c\u652f\u6301\u4e2a\u6027\u5316\u533b\u7597\u62a4\u7406\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.17898", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17898", "abs": "https://arxiv.org/abs/2602.17898", "authors": ["Jingquan Yan", "Yuwei Miao", "Peiran Yu", "Junzhou Huang"], "title": "Breaking the Correlation Plateau: On the Optimization and Capacity Limits of Attention-Based Regressors", "comment": "Accepted by ICLR 2026", "summary": "Attention-based regression models are often trained by jointly optimizing Mean Squared Error (MSE) loss and Pearson correlation coefficient (PCC) loss, emphasizing the magnitude of errors and the order or shape of targets, respectively. A common but poorly understood phenomenon during training is the PCC plateau: PCC stops improving early in training, even as MSE continues to decrease. We provide the first rigorous theoretical analysis of this behavior, revealing fundamental limitations in both optimization dynamics and model capacity. First, in regard to the flattened PCC curve, we uncover a critical conflict where lowering MSE (magnitude matching) can paradoxically suppress the PCC gradient (shape matching). This issue is exacerbated by the softmax attention mechanism, particularly when the data to be aggregated is highly homogeneous. Second, we identify a limitation in the model capacity: we derived a PCC improvement limit for any convex aggregator (including the softmax attention), showing that the convex hull of the inputs strictly bounds the achievable PCC gain. We demonstrate that data homogeneity intensifies both limitations. Motivated by these insights, we propose the Extrapolative Correlation Attention (ECA), which incorporates novel, theoretically-motivated mechanisms to improve the PCC optimization and extrapolate beyond the convex hull. Across diverse benchmarks, including challenging homogeneous data setting, ECA consistently breaks the PCC plateau, achieving significant improvements in correlation without compromising MSE performance.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u6ce8\u610f\u529b\u56de\u5f52\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684PCC\u505c\u6ede\u73b0\u8c61\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4f18\u5316\u52a8\u6001\u548c\u6a21\u578b\u5bb9\u91cf\u7684\u57fa\u672c\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684Extrapolative Correlation Attention (ECA)\u673a\u5236\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5728\u4fdd\u6301MSE\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u76f8\u5173\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6ce8\u610f\u529b\u56de\u5f52\u6a21\u578b\u8bad\u7ec3\u4e2d\u5e38\u89c1\u7684\u4f46\u7406\u89e3\u4e0d\u8db3\u7684\u73b0\u8c61\u2014\u2014PCC\u505c\u6ede\u95ee\u9898\uff0c\u5373\u5c3d\u7ba1MSE\u6301\u7eed\u4e0b\u964d\uff0cPCC\u5374\u5f88\u65e9\u5c31\u505c\u6b62\u6539\u5584\u3002\u901a\u8fc7\u6df1\u5165\u63a2\u8ba8\u8fd9\u4e00\u73b0\u8c61\u80cc\u540e\u7684\u539f\u56e0\uff0c\u6587\u7ae0\u5e0c\u671b\u4e3a\u6539\u8fdb\u6a21\u578b\u63d0\u4f9b\u65b0\u7684\u601d\u8def\u548c\u6280\u672f\u3002", "method": "\u901a\u8fc7\u5bf9PCC\u505c\u6ede\u73b0\u8c61\u8fdb\u884c\u4e25\u683c\u7684\u7406\u8bba\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u4f18\u5316\u52a8\u529b\u5b66\u4e2d\u7684\u5173\u952e\u51b2\u7a81\u4ee5\u53ca\u6a21\u578b\u80fd\u529b\u4e0a\u7684\u9650\u5236\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5236\u2014\u2014Extrapolative Correlation Attention (ECA)\uff0c\u8be5\u673a\u5236\u8bbe\u8ba1\u7528\u4e8e\u8d85\u8d8a\u8f93\u5165\u6570\u636e\u7684\u51f8\u5305\u9650\u5236\uff0c\u4ece\u800c\u66f4\u597d\u5730\u4f18\u5316PCC\u3002", "result": "ECA\u80fd\u591f\u5728\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6253\u7834PCC\u505c\u6ede\u73b0\u8c61\uff0c\u5373\u4f7f\u662f\u5728\u9762\u5bf9\u6311\u6218\u6027\u7684\u540c\u8d28\u6570\u636e\u96c6\u65f6\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u76f8\u5173\u6027\uff0c\u540c\u65f6\u4e0d\u727a\u7272MSE\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5165ECA\u8fd9\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5b58\u5728\u7684PCC\u4f18\u5316\u96be\u9898\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u56de\u5f52\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.17918", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17918", "abs": "https://arxiv.org/abs/2602.17918", "authors": ["Jialin Yu", "Mo\u00efse Blanchard"], "title": "Distribution-Free Sequential Prediction with Abstentions", "comment": "38 pages, 2 figures. Submitted to COLT 2026. Extended version", "summary": "We study a sequential prediction problem in which an adversary is allowed to inject arbitrarily many adversarial instances in a stream of i.i.d.\\ instances, but at each round, the learner may also \\emph{abstain} from making a prediction without incurring any penalty if the instance was indeed corrupted. This semi-adversarial setting naturally sits between the classical stochastic case with i.i.d.\\ instances for which function classes with finite VC dimension are learnable; and the adversarial case with arbitrary instances, known to be significantly more restrictive. For this problem, Goel et al. (2023) showed that, if the learner knows the distribution $\u03bc$ of clean samples in advance, learning can be achieved for all VC classes without restrictions on adversary corruptions. This is, however, a strong assumption in both theory and practice: a natural question is whether similar learning guarantees can be achieved without prior distributional knowledge, as is standard in classical learning frameworks (e.g., PAC learning or asymptotic consistency) and other non-i.i.d.\\ models (e.g., smoothed online learning). We therefore focus on the distribution-free setting where $\u03bc$ is \\emph{unknown} and propose an algorithm \\textsc{AbstainBoost} based on a boosting procedure of weak learners, which guarantees sublinear error for general VC classes in \\emph{distribution-free} abstention learning for oblivious adversaries. These algorithms also enjoy similar guarantees for adaptive adversaries, for structured function classes including linear classifiers. These results are complemented with corresponding lower bounds, which reveal an interesting polynomial trade-off between misclassification error and number of erroneous abstentions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u534a\u5bf9\u6297\u73af\u5883\u4e0b\uff0c\u5b66\u4e60\u8005\u53ef\u4ee5\u5bf9\u53ef\u80fd\u88ab\u6c61\u67d3\u7684\u5b9e\u4f8b\u9009\u62e9\u4e0d\u8fdb\u884c\u9884\u6d4b\u7684\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAbstainBoost\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u5f31\u5b66\u4e60\u8005\u7684\u63d0\u5347\u8fc7\u7a0b\uff0c\u5728\u672a\u77e5\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u8bc1VC\u7c7b\u7684\u4e00\u822c\u6027\u9519\u8bef\u4e3a\u6b21\u7ebf\u6027\u7684\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u81ea\u9002\u5e94\u5bf9\u624b\u548c\u7ed3\u6784\u5316\u51fd\u6570\u7c7b\uff08\u5982\u7ebf\u6027\u5206\u7c7b\u5668\uff09\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u4e5f\u5177\u6709\u7c7b\u4f3c\u7684\u4fdd\u8bc1\u3002", "motivation": "\u4f5c\u8005\u4eec\u63a2\u7d22\u4e86\u5728\u4e0d\u77e5\u9053\u5e72\u51c0\u6837\u672c\u5206\u5e03$\u03bc$\u7684\u524d\u63d0\u4e0b\uff0c\u662f\u5426\u80fd\u591f\u5b9e\u73b0\u4e0e\u5df2\u77e5\u5206\u5e03\u65f6\u76f8\u4f3c\u7684\u5b66\u4e60\u4fdd\u8bc1\u3002\u8fd9\u4e00\u95ee\u9898\u7684\u610f\u4e49\u5728\u4e8e\uff0c\u73b0\u5b9e\u4e16\u754c\u4e2d\u5f80\u5f80\u65e0\u6cd5\u4e8b\u5148\u5f97\u77e5\u6570\u636e\u7684\u786e\u5207\u5206\u5e03\u60c5\u51b5\uff0c\u56e0\u6b64\u5bfb\u627e\u4e00\u79cd\u4e0d\u9700\u8981\u5148\u9a8c\u5206\u5e03\u77e5\u8bc6\u7684\u65b9\u6cd5\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5AbstainBoost\uff0c\u5b83\u5229\u7528\u5f31\u5b66\u4e60\u8005\u7684\u63d0\u5347\u8fc7\u7a0b\u6765\u5904\u7406\u672a\u77e5\u5206\u5e03\u4e0b\u7684\u5b66\u4e60\u4efb\u52a1\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u5b66\u4e60\u8005\u5728\u9762\u5bf9\u53ef\u80fd\u662f\u88ab\u6c61\u67d3\u7684\u6570\u636e\u65f6\u9009\u62e9\u4e0d\u4f5c\u51fa\u9884\u6d4b\uff0c\u4ece\u800c\u907f\u514d\u53d7\u5230\u60e9\u7f5a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u4e00\u822cVC\u7c7b\uff0c\u5728\u672a\u77e5\u5206\u5e03\u7684\u653e\u5f03\u5b66\u4e60\u4e2d\uff0cAbstainBoost\u7b97\u6cd5\u80fd\u591f\u4fdd\u8bc1\u6b21\u7ebf\u6027\u7684\u9519\u8bef\u7387\u3002\u540c\u65f6\uff0c\u9488\u5bf9\u81ea\u9002\u5e94\u5bf9\u624b\u4ee5\u53ca\u5305\u62ec\u7ebf\u6027\u5206\u7c7b\u5668\u5728\u5185\u7684\u7ed3\u6784\u5316\u51fd\u6570\u7c7b\uff0c\u8be5\u7b97\u6cd5\u540c\u6837\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u6027\u80fd\u4fdd\u969c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165AbstainBoost\u7b97\u6cd5\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u5148\u9a8c\u5206\u5e03\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u53ef\u4ee5\u6709\u6548\u5730\u5904\u7406\u5305\u542b\u4efb\u610f\u6570\u91cf\u654c\u5bf9\u5b9e\u4f8b\u7684\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4e0d\u540c\u7684\u5bf9\u624b\u7c7b\u578b\u53ca\u51fd\u6570\u7c7b\u522b\u90fd\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.17940", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17940", "abs": "https://arxiv.org/abs/2602.17940", "authors": ["Shogo Iwazaki"], "title": "Tighter Regret Lower Bound for Gaussian Process Bandits with Squared Exponential Kernel in Hypersphere", "comment": "27 pages, 2 figures", "summary": "We study an algorithm-independent, worst-case lower bound for the Gaussian process (GP) bandit problem in the frequentist setting, where the reward function is fixed and has a bounded norm in the known reproducing kernel Hilbert space (RKHS). Specifically, we focus on the squared exponential (SE) kernel, one of the most widely used kernel functions in GP bandits. One of the remaining open questions for this problem is the gap in the \\emph{dimension-dependent} logarithmic factors between upper and lower bounds. This paper partially resolves this open question under a hyperspherical input domain. We show that any algorithm suffers $\u03a9(\\sqrt{T (\\ln T)^{d} (\\ln \\ln T)^{-d}})$ cumulative regret, where $T$ and $d$ represent the total number of steps and the dimension of the hyperspherical domain, respectively. Regarding the simple regret, we show that any algorithm requires $\u03a9(\u03b5^{-2}(\\ln \\frac{1}\u03b5)^d (\\ln \\ln \\frac{1}\u03b5)^{-d})$ time steps to find an $\u03b5$-optimal point. We also provide the improved $O((\\ln T)^{d+1}(\\ln \\ln T)^{-d})$ upper bound on the maximum information gain for the SE kernel. Our results guarantee the optimality of the existing best algorithm up to \\emph{dimension-independent} logarithmic factors under a hyperspherical input domain.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09bandit\u95ee\u9898\u5728\u9891\u5ea6\u8bbe\u7f6e\u4e0b\uff0c\u7279\u522b\u662f\u5728\u8d85\u7403\u8f93\u5165\u57df\u4e0a\uff0c\u63d0\u4f9b\u4e86\u7b97\u6cd5\u65e0\u5173\u7684\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u4e0b\u754c\u3002\u5bf9\u4e8e\u5e73\u65b9\u6307\u6570\uff08SE\uff09\u6838\u51fd\u6570\uff0c\u8bc1\u660e\u4e86\u4efb\u4f55\u7b97\u6cd5\u90fd\u4f1a\u906d\u53d7\u7279\u5b9a\u5f62\u5f0f\u7684\u7d2f\u79ef\u9057\u61be\uff0c\u5e76\u4e14\u8981\u627e\u5230\u4e00\u4e2a\u03b5-\u6700\u4f18\u89e3\u9700\u8981\u7279\u5b9a\u6570\u91cf\u7684\u65f6\u95f4\u6b65\u9aa4\u3002\u6b64\u5916\uff0c\u8fd8\u6539\u8fdb\u4e86SE\u6838\u7684\u6700\u5927\u4fe1\u606f\u589e\u76ca\u7684\u4e0a\u754c\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3GP bandit\u95ee\u9898\u4e2d\u5173\u4e8e\u7ef4\u5ea6\u4f9d\u8d56\u7684\u5bf9\u6570\u56e0\u5b50\u4e4b\u95f4\u7684\u5dee\u8ddd\u8fd9\u4e00\u5f00\u653e\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684SE\u6838\u51fd\u6570\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5728\u8d85\u7403\u8f93\u5165\u57df\u4e0a\u4e3a\u4f7f\u7528SE\u6838\u7684GP bandit\u95ee\u9898\u5efa\u7acb\u4e86\u65b0\u7684\u4e0b\u754c\uff0c\u5e76\u6539\u8fdb\u4e86\u6700\u5927\u4fe1\u606f\u589e\u76ca\u7684\u4e0a\u754c\u4f30\u8ba1\u3002", "result": "\u8bc1\u660e\u4e86\u4efb\u4f55\u7b97\u6cd5\u5728\u7ed9\u5b9a\u6761\u4ef6\u4e0b\u90fd\u5c06\u9762\u4e34\u7279\u5b9a\u5f62\u5f0f\u7684\u7d2f\u79ef\u9057\u61be\u548c\u7b80\u5355\u9057\u61be\uff0c\u5e76\u7ed9\u51fa\u4e86\u6539\u8fdb\u540e\u7684\u6700\u5927\u4fe1\u606f\u589e\u76ca\u4e0a\u754c\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d85\u7403\u8f93\u5165\u57df\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u6700\u4f73\u7b97\u6cd5\u5728\u7ef4\u5ea6\u72ec\u7acb\u7684\u5bf9\u6570\u56e0\u5b50\u65b9\u9762\u662f\u6700\u4f18\u7684\u3002"}}
{"id": "2602.17947", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17947", "abs": "https://arxiv.org/abs/2602.17947", "authors": ["Yubo Zhou", "Jun Shu", "Junmin Liu", "Deyu Meng"], "title": "Understanding the Generalization of Bilevel Programming in Hyperparameter Optimization: A Tale of Bias-Variance Decomposition", "comment": null, "summary": "Gradient-based hyperparameter optimization (HPO) have emerged recently, leveraging bilevel programming techniques to optimize hyperparameter by estimating hypergradient w.r.t. validation loss. Nevertheless, previous theoretical works mainly focus on reducing the gap between the estimation and ground-truth (i.e., the bias), while ignoring the error due to data distribution (i.e., the variance), which degrades performance. To address this issue, we conduct a bias-variance decomposition for hypergradient estimation error and provide a supplemental detailed analysis of the variance term ignored by previous works. We also present a comprehensive analysis of the error bounds for hypergradient estimation. This facilitates an easy explanation of some phenomena commonly observed in practice, like overfitting to the validation set. Inspired by the derived theories, we propose an ensemble hypergradient strategy to reduce the variance in HPO algorithms effectively. Experimental results on tasks including regularization hyperparameter learning, data hyper-cleaning, and few-shot learning demonstrate that our variance reduction strategy improves hypergradient estimation. To explain the improved performance, we establish a connection between excess error and hypergradient estimation, offering some understanding of empirical observations.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u68af\u5ea6\u7684\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u8d85\u68af\u5ea6\u4f30\u8ba1\u8bef\u5dee\u7684\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u8d85\u68af\u5ea6\u7b56\u7565\u6765\u6709\u6548\u51cf\u5c11\u65b9\u5dee\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u5dee\u51cf\u5c11\u7b56\u7565\u63d0\u9ad8\u4e86\u8d85\u68af\u5ea6\u4f30\u8ba1\u7684\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u68af\u5ea6\u7684\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8e\u51cf\u5c11\u4f30\u8ba1\u4e0e\u771f\u5b9e\u503c\u4e4b\u95f4\u7684\u504f\u5dee\uff0c\u800c\u5ffd\u7565\u4e86\u7531\u4e8e\u6570\u636e\u5206\u5e03\u5bfc\u81f4\u7684\u8bef\u5dee\uff08\u5373\u65b9\u5dee\uff09\uff0c\u8fd9\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6587\u7ae0\u8fdb\u884c\u4e86\u8d85\u68af\u5ea6\u4f30\u8ba1\u8bef\u5dee\u7684\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u5e76\u7279\u522b\u5206\u6790\u4e86\u4e4b\u524d\u88ab\u5ffd\u7565\u7684\u65b9\u5dee\u9879\u3002", "method": "\u4f5c\u8005\u9996\u5148\u5bf9\u8d85\u68af\u5ea6\u4f30\u8ba1\u8bef\u5dee\u8fdb\u884c\u4e86\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u65b9\u5dee\u9879\u7684\u8be6\u7ec6\u5206\u6790\u3002\u63a5\u7740\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u8d85\u68af\u5ea6\u4f30\u8ba1\u9519\u8bef\u754c\u9650\u5206\u6790\u3002\u53d7\u8fd9\u4e9b\u7406\u8bba\u542f\u53d1\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u8d85\u68af\u5ea6\u7b56\u7565\u4ee5\u5728\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u65b9\u5dee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5305\u62ec\u6b63\u5219\u5316\u8d85\u53c2\u6570\u5b66\u4e60\u3001\u6570\u636e\u8d85\u6e05\u7406\u548c\u5c11\u6837\u672c\u5b66\u4e60\u7684\u4efb\u52a1\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u5dee\u51cf\u5c11\u7b56\u7565\u786e\u5b9e\u6539\u5584\u4e86\u8d85\u68af\u5ea6\u4f30\u8ba1\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5efa\u7acb\u8d85\u989d\u8bef\u5dee\u4e0e\u8d85\u68af\u5ea6\u4f30\u8ba1\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u5b9e\u8bc1\u89c2\u5bdf\u63d0\u4f9b\u4e86\u4e00\u4e9b\u89e3\u91ca\u3002", "conclusion": "\u901a\u8fc7\u8003\u8651\u5e76\u5904\u7406\u8d85\u68af\u5ea6\u4f30\u8ba1\u4e2d\u7684\u65b9\u5dee\u95ee\u9898\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u57fa\u4e8e\u68af\u5ea6\u7684\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\u7684\u6027\u80fd\u3002\u65b0\u63d0\u51fa\u7684\u96c6\u6210\u8d85\u68af\u5ea6\u7b56\u7565\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u5dee\u51cf\u5c11\u65b9\u6cd5\u3002"}}
{"id": "2602.17948", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17948", "abs": "https://arxiv.org/abs/2602.17948", "authors": ["Yu Bai", "Zhe Wang", "Jiarui Zhang", "Dong-Xiao Zhang", "Yinjun Gao", "Jun-Jie Zhang"], "title": "A Geometric Probe of the Accuracy-Robustness Trade-off: Sharp Boundaries in Symmetry-Breaking Dimensional Expansion", "comment": "22 pages, 3 figures", "summary": "The trade-off between clean accuracy and adversarial robustness is a pervasive phenomenon in deep learning, yet its geometric origin remains elusive. In this work, we utilize Symmetry-Breaking Dimensional Expansion (SBDE) as a controlled probe to investigate the mechanism underlying this trade-off. SBDE expands input images by inserting constant-valued pixels, which breaks translational symmetry and consistently improves clean accuracy (e.g., from $90.47\\%$ to $95.63\\%$ on CIFAR-10 with ResNet-18) by reducing parameter degeneracy. However, this accuracy gain comes at the cost of reduced robustness against iterative white-box attacks. By employing a test-time \\emph{mask projection} that resets the inserted auxiliary pixels to their training values, we demonstrate that the vulnerability stems almost entirely from the inserted dimensions. The projection effectively neutralizes the attacks and restores robustness, revealing that the model achieves high accuracy by creating \\emph{sharp boundaries} (steep loss gradients) specifically along the auxiliary axes. Our findings provide a concrete geometric explanation for the accuracy-robustness paradox: the optimization landscape deepens the basin of attraction to improve accuracy but inevitably erects steep walls along the auxiliary degrees of freedom, creating a fragile sensitivity to off-manifold perturbations.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u4f7f\u7528\u5bf9\u79f0\u6027\u7834\u574f\u7ef4\u5ea6\u6269\u5c55\uff08SBDE\uff09\u6765\u63a2\u7d22\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6e05\u6d01\u51c6\u786e\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u4e4b\u95f4\u6743\u8861\u7684\u673a\u5236\u3002SBDE \u80fd\u591f\u63d0\u9ad8\u6e05\u6d01\u51c6\u786e\u6027\uff0c\u4f46\u4f1a\u964d\u4f4e\u6a21\u578b\u5bf9\u8fed\u4ee3\u767d\u76d2\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u5728\u6d4b\u8bd5\u65f6\u5e94\u7528\u63a9\u7801\u6295\u5f71\u6280\u672f\uff0c\u53ef\u4ee5\u6062\u590d\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u901a\u8fc7\u6cbf\u8f85\u52a9\u8f74\u521b\u5efa\u5c16\u9510\u8fb9\u754c\u6765\u5b9e\u73b0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u5185\u6e05\u6d01\u51c6\u786e\u5ea6\u4e0e\u5bf9\u6297\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u6743\u8861\u73b0\u8c61\u80cc\u540e\u7684\u51e0\u4f55\u5b66\u539f\u56e0\u3002", "method": "\u91c7\u7528\u5bf9\u79f0\u6027\u7834\u574f\u7ef4\u5ea6\u6269\u5c55\uff08SBDE\uff09\u4f5c\u4e3a\u53d7\u63a7\u63a2\u9488\uff0c\u901a\u8fc7\u5411\u8f93\u5165\u56fe\u50cf\u63d2\u5165\u5e38\u6570\u503c\u50cf\u7d20\u6765\u6253\u7834\u5e73\u79fb\u5bf9\u79f0\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u8bad\u7ec3\u503c\u91cd\u7f6e\u8fd9\u4e9b\u8f85\u52a9\u50cf\u7d20\u6765\u5e94\u7528\u6d4b\u8bd5\u65f6\u95f4\u63a9\u7801\u6295\u5f71\u3002", "result": "SBDE\u63d0\u9ad8\u4e86CIFAR-10\u6570\u636e\u96c6\u4e0aResNet-18\u6a21\u578b\u7684\u6e05\u6d01\u51c6\u786e\u6027\uff0c\u4f46\u662f\u964d\u4f4e\u4e86\u5bf9\u8fed\u4ee3\u767d\u76d2\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff1b\u901a\u8fc7\u63a9\u7801\u6295\u5f71\u53ef\u4ee5\u6062\u590d\u9c81\u68d2\u6027\uff0c\u663e\u793a\u6a21\u578b\u901a\u8fc7\u6cbf\u7740\u8f85\u52a9\u8f74\u5efa\u7acb\u5c16\u9510\u8fb9\u754c\u4ee5\u8fbe\u5230\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u7684\u51e0\u4f55\u89e3\u91ca\uff1a\u4f18\u5316\u666f\u89c2\u52a0\u6df1\u4e86\u5438\u5f15\u76c6\u5730\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u4e0d\u53ef\u907f\u514d\u5730\u5728\u8f85\u52a9\u81ea\u7531\u5ea6\u4e0a\u5efa\u7acb\u4e86\u9661\u5ced\u7684\u58c1\uff0c\u4ece\u800c\u5bf9\u79bb\u6d41\u5f62\u6270\u52a8\u4ea7\u751f\u4e86\u8106\u5f31\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2602.17958", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17958", "abs": "https://arxiv.org/abs/2602.17958", "authors": ["Aida Afshar", "Yuke Zhang", "Aldo Pacchiano"], "title": "Bayesian Online Model Selection", "comment": null, "summary": "Online model selection in Bayesian bandits raises a fundamental exploration challenge: When an environment instance is sampled from a prior distribution, how can we design an adaptive strategy that explores multiple bandit learners and competes with the best one in hindsight? We address this problem by introducing a new Bayesian algorithm for online model selection in stochastic bandits. We prove an oracle-style guarantee of $O\\left( d^* M \\sqrt{T} + \\sqrt{(MT)} \\right)$ on the Bayesian regret, where $M$ is the number of base learners, $d^*$ is the regret coefficient of the optimal base learner, and $T$ is the time horizon. We also validate our method empirically across a range of stochastic bandit settings, demonstrating performance that is competitive with the best base learner. Additionally, we study the effect of sharing data among base learners and its role in mitigating prior mis-specification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u7b97\u6cd5\uff0c\u7528\u4e8e\u968f\u673a\u5f3a\u76d7\u4e2d\u7684\u5728\u7ebf\u6a21\u578b\u9009\u62e9\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u8d1d\u53f6\u65af\u9057\u61be\u4e0a\u6709oracle\u5f0f\u7684\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u57fa\u7840\u5b66\u4e60\u8005\u95f4\u5171\u4eab\u6570\u636e\u5bf9\u7f13\u89e3\u5148\u9a8c\u8bef\u8bbe\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4ece\u5148\u9a8c\u5206\u5e03\u4e2d\u62bd\u53d6\u73af\u5883\u5b9e\u4f8b\u65f6\uff0c\u5728\u591a\u4e2a\u5f3a\u76d7\u5b66\u4e60\u5668\u4e2d\u63a2\u7d22\u5e76\u6700\u7ec8\u4e0e\u6700\u4f73\u5b66\u4e60\u5668\u7ade\u4e89\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u7b97\u6cd5\u6765\u89e3\u51b3\u968f\u673a\u5f3a\u76d7\u4e2d\u7684\u5728\u7ebf\u6a21\u578b\u9009\u62e9\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u65b0\u7b97\u6cd5\u5728\u8d1d\u53f6\u65af\u9057\u61be\u4e0a\u5177\u6709$O\\left( d^* M \\sqrt{T} + \\sqrt{(MT)} \\right)$\u7684oracle\u5f0f\u4fdd\u969c\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u968f\u673a\u5f3a\u76d7\u8bbe\u7f6e\u4e0b\u6027\u80fd\u4e0e\u6700\u4f73\u57fa\u7840\u5b66\u4e60\u5668\u76f8\u5f53\uff1b\u7814\u7a76\u53d1\u73b0\u57fa\u7840\u5b66\u4e60\u5668\u95f4\u5171\u4eab\u6570\u636e\u6709\u52a9\u4e8e\u51cf\u8f7b\u5148\u9a8c\u8bef\u8bbe\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u8d1d\u53f6\u65af\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u968f\u673a\u5f3a\u76d7\u4e2d\u7684\u5728\u7ebf\u6a21\u578b\u9009\u62e9\u6311\u6218\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u6570\u636e\u5171\u4eab\u5bf9\u4e8e\u5904\u7406\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.17985", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17985", "abs": "https://arxiv.org/abs/2602.17985", "authors": ["Ryan O'Dowd"], "title": "Learning Without Training", "comment": "PhD Dissertation of Ryan O'Dowd, defended successfully at Claremont Graduate University on 1/28/2026", "summary": "Machine learning is at the heart of managing the real-world problems associated with massive data. With the success of neural networks on such large-scale problems, more research in machine learning is being conducted now than ever before. This dissertation focuses on three different projects rooted in mathematical theory for machine learning applications.\n  The first project deals with supervised learning and manifold learning. In theory, one of the main problems in supervised learning is that of function approximation: that is, given some data set $\\mathcal{D}=\\{(x_j,f(x_j))\\}_{j=1}^M$, can one build a model $F\\approx f$? We introduce a method which aims to remedy several of the theoretical shortcomings of the current paradigm for supervised learning.\n  The second project deals with transfer learning, which is the study of how an approximation process or model learned on one domain can be leveraged to improve the approximation on another domain. We study such liftings of functions when the data is assumed to be known only on a part of the whole domain. We are interested in determining subsets of the target data space on which the lifting can be defined, and how the local smoothness of the function and its lifting are related.\n  The third project is concerned with the classification task in machine learning, particularly in the active learning paradigm. Classification has often been treated as an approximation problem as well, but we propose an alternative approach leveraging techniques originally introduced for signal separation problems. We introduce theory to unify signal separation with classification and a new algorithm which yields competitive accuracy to other recent active learning algorithms while providing results much faster.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4e09\u4e2a\u4e0d\u540c\u9879\u76ee\uff1a\u76d1\u7763\u5b66\u4e60\u548c\u6d41\u5f62\u5b66\u4e60\u7684\u51fd\u6570\u903c\u8fd1\u95ee\u9898\u3001\u8fc1\u79fb\u5b66\u4e60\u4e2d\u9886\u57df\u95f4\u77e5\u8bc6\u8f6c\u79fb\u7684\u95ee\u9898\u4ee5\u53ca\u901a\u8fc7\u4fe1\u53f7\u5206\u79bb\u6280\u672f\u63d0\u51fa\u7684\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u7684\u4e0d\u8db3\uff0c\u4f5c\u8005\u81f4\u529b\u4e8e\u63a2\u7d22\u6570\u5b66\u7406\u8bba\u5982\u4f55\u5e94\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u95ee\u9898\u4e0a\uff0c\u4ee5\u671f\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u53ca\u6548\u7387\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3\u51fd\u6570\u903c\u8fd1\u95ee\u9898\uff1b2. \u7814\u7a76\u4e86\u90e8\u5206\u5df2\u77e5\u6570\u636e\u6761\u4ef6\u4e0b\u4ece\u4e00\u4e2a\u9886\u57df\u5230\u53e6\u4e00\u4e2a\u9886\u57df\u7684\u77e5\u8bc6\u8fc1\u79fb\u673a\u5236\uff1b3. \u57fa\u4e8e\u4fe1\u53f7\u5206\u79bb\u6280\u672f\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u7684\u65b0\u7b97\u6cd5\u3002", "result": "1. \u65b0\u63d0\u51fa\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u7406\u8bba\u4e0a\u89e3\u51b3\u4e86\u5f53\u524d\u8303\u5f0f\u7684\u4e00\u4e9b\u7f3a\u70b9\uff1b2. \u5bf9\u8fc1\u79fb\u5b66\u4e60\u4e2d\u5c40\u90e8\u5e73\u6ed1\u6027\u548c\u529f\u80fd\u63d0\u5347\u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u4e86\u63a2\u8ba8\uff1b3. \u5f00\u53d1\u7684\u65b0\u7b97\u6cd5\u4e0d\u4ec5\u51c6\u786e\u6027\u9ad8\uff0c\u800c\u4e14\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u9896\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2602.17998", "categories": ["cs.LG", "cs.AI", "cs.CE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17998", "abs": "https://arxiv.org/abs/2602.17998", "authors": ["Shubham Bhardwaj", "Chandrajit Bajaj"], "title": "PHAST: Port-Hamiltonian Architecture for Structured Temporal Dynamics Forecasting", "comment": "50 pages", "summary": "Real physical systems are dissipative -- a pendulum slows, a circuit loses charge to heat -- and forecasting their dynamics from partial observations is a central challenge in scientific machine learning. We address the \\emph{position-only} (q-only) problem: given only generalized positions~$q_t$ at discrete times (momenta~$p_t$ latent), learn a structured model that (a)~produces stable long-horizon forecasts and (b)~recovers physically meaningful parameters when sufficient structure is provided. The port-Hamiltonian framework makes the conservative-dissipative split explicit via $\\dot{x}=(J-R)\\nabla H(x)$, guaranteeing $dH/dt\\le 0$ when $R\\succeq 0$. We introduce \\textbf{PHAST} (Port-Hamiltonian Architecture for Structured Temporal dynamics), which decomposes the Hamiltonian into potential~$V(q)$, mass~$M(q)$, and damping~$D(q)$ across three knowledge regimes (KNOWN, PARTIAL, UNKNOWN), uses efficient low-rank PSD/SPD parameterizations, and advances dynamics with Strang splitting. Across thirteen q-only benchmarks spanning mechanical, electrical, molecular, thermal, gravitational, and ecological systems, PHAST achieves the best long-horizon forecasting among competitive baselines and enables physically meaningful parameter recovery when the regime provides sufficient anchors. We show that identification is fundamentally ill-posed without such anchors (gauge freedom), motivating a two-axis evaluation that separates forecasting stability from identifiability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPHAST\u7684\u7ed3\u6784\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u4ec5\u4f4d\u7f6e\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u7269\u7406\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u3002\u8be5\u6a21\u578b\u5728\u4fdd\u8bc1\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u7684\u540c\u65f6\uff0c\u4e5f\u80fd\u6062\u590d\u5177\u6709\u7269\u7406\u610f\u4e49\u7684\u53c2\u6570\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u7269\u7406\u7cfb\u7edf\u662f\u8017\u6563\u7684\uff0c\u6bd4\u5982\u6446\u4f1a\u51cf\u901f\uff0c\u7535\u8def\u4f1a\u56e0\u4e3a\u70ed\u91cf\u800c\u5931\u53bb\u7535\u8377\u3002\u4ece\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e2d\u9884\u6d4b\u8fd9\u4e9b\u7cfb\u7edf\u7684\u52a8\u6001\u662f\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86PHAST\uff08Port-Hamiltonian Architecture for Structured Temporal dynamics\uff09\uff0c\u5b83\u5c06\u54c8\u5bc6\u987f\u91cf\u5206\u89e3\u4e3a\u52bf\u80fd\u3001\u8d28\u91cf\u548c\u963b\u5c3c\u4e09\u4e2a\u90e8\u5206\uff0c\u5e76\u6839\u636e\u77e5\u8bc6\u4f53\u7cfb\u7684\u4e0d\u540c\u91c7\u7528\u4e0d\u540c\u7684\u53c2\u6570\u5316\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528Strang\u5206\u88c2\u6cd5\u63a8\u8fdb\u52a8\u529b\u5b66\u6f14\u5316\u3002", "result": "\u5728\u8de8\u8d8a\u673a\u68b0\u3001\u7535\u6c14\u3001\u5206\u5b50\u3001\u70ed\u529b\u5b66\u3001\u91cd\u529b\u548c\u751f\u6001\u7cfb\u7edf\u7684\u5341\u4e09\u4e2a\u4ec5\u57fa\u4e8e\u4f4d\u7f6e\u7684\u6570\u636e\u96c6\u4e0a\uff0cPHAST\u76f8\u6bd4\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u957f\u65f6\u57df\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u4e14\u5f53\u63d0\u4f9b\u7684\u4fe1\u606f\u8db3\u591f\u65f6\uff0c\u80fd\u591f\u6062\u590d\u51fa\u5177\u6709\u7269\u7406\u610f\u4e49\u7684\u53c2\u6570\u3002", "conclusion": "\u7814\u7a76\u663e\u793a\uff0c\u5728\u6ca1\u6709\u8db3\u591f\u7684\u951a\u70b9\u60c5\u51b5\u4e0b\u8bc6\u522b\u95ee\u9898\u662f\u672c\u8d28\u4e0a\u4e0d\u9002\u5b9a\u7684\uff08\u5b58\u5728\u89c4\u8303\u81ea\u7531\u5ea6\u95ee\u9898\uff09\u3002\u56e0\u6b64\uff0c\u5efa\u8bae\u91c7\u7528\u4e24\u8f74\u8bc4\u4f30\u65b9\u6cd5\u6765\u533a\u5206\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u53ef\u8bc6\u522b\u6027\u3002"}}
{"id": "2602.18002", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18002", "abs": "https://arxiv.org/abs/2602.18002", "authors": ["Junfei Sun", "Dixi Yao", "Xuchen Gong", "Tahseen Rabbani", "Manzil Zaheer", "Tian Li"], "title": "Asynchronous Heavy-Tailed Optimization", "comment": "8-page main body, 25-page appendix, 5 figures", "summary": "Heavy-tailed stochastic gradient noise, commonly observed in transformer models, can destabilize the optimization process. Recent works mainly focus on developing and understanding approaches to address heavy-tailed noise in the centralized or distributed, synchronous setting, leaving the interactions between such noise and asynchronous optimization underexplored. In this work, we investigate two communication schemes that handle stragglers with asynchronous updates in the presence of heavy-tailed gradient noise. We propose and theoretically analyze algorithmic modifications based on delay-aware learning rate scheduling and delay compensation to enhance the performance of asynchronous algorithms. Our convergence guarantees under heavy-tailed noise match the rate of the synchronous counterparts and improve delay tolerance compared with existing asynchronous approaches. Empirically, our approaches outperform prior synchronous and asynchronous methods in terms of accuracy/runtime trade-offs and are more robust to hyperparameters in both image and language tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u5b58\u5728\u4e0b\uff0c\u4e24\u79cd\u5904\u7406\u5ef6\u8fdf\u66f4\u65b0\u7684\u901a\u4fe1\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5ef6\u8fdf\u611f\u77e5\u5b66\u4e60\u7387\u8c03\u5ea6\u548c\u5ef6\u8fdf\u8865\u507f\u7684\u7b97\u6cd5\u4fee\u6539\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u540c\u6b65\u548c\u5f02\u6b65\u65b9\u6cd5\uff0c\u5e76\u4e14\u5bf9\u8d85\u53c2\u6570\u66f4\u9c81\u68d2\u3002", "motivation": "\u5f53\u524d\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u5728\u5f00\u53d1\u548c\u7406\u89e3\u96c6\u4e2d\u5f0f\u6216\u5206\u5e03\u5f0f\u540c\u6b65\u8bbe\u7f6e\u4e2d\u89e3\u51b3\u91cd\u5c3e\u566a\u58f0\u7684\u65b9\u6cd5\uff0c\u800c\u5ffd\u89c6\u4e86\u8fd9\u79cd\u566a\u58f0\u4e0e\u5f02\u6b65\u4f18\u5316\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5728\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u6761\u4ef6\u4e0b\u5982\u4f55\u901a\u8fc7\u5f02\u6b65\u66f4\u65b0\u6765\u5904\u7406\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u57fa\u4e8e\u5ef6\u8fdf\u611f\u77e5\u5b66\u4e60\u7387\u8c03\u5ea6\u548c\u5ef6\u8fdf\u8865\u507f\u7684\u7b97\u6cd5\u4fee\u6539\u4ee5\u589e\u5f3a\u5f02\u6b65\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u56fe\u50cf\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u4e86\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u6743\u8861\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8d85\u53c2\u6570\u66f4\u52a0\u7a33\u5065\u3002\u6b64\u5916\uff0c\u8fd8\u8bc1\u660e\u4e86\u5728\u91cd\u5c3e\u566a\u58f0\u4e0b\u7684\u6536\u655b\u6027\u4fdd\u8bc1\u53ef\u4ee5\u4e0e\u540c\u6b65\u7248\u672c\u76f8\u5339\u914d\uff0c\u540c\u65f6\u76f8\u6bd4\u73b0\u6709\u5f02\u6b65\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u5ef6\u8fdf\u7684\u5bb9\u5fcd\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u9762\u5bf9\u91cd\u5c3e\u68af\u5ea6\u566a\u58f0\u65f6\uff0c\u901a\u8fc7\u9002\u5f53\u8c03\u6574\u5982\u5ef6\u8fdf\u611f\u77e5\u5b66\u4e60\u7387\u8c03\u5ea6\u7b49\u7b56\u7565\uff0c\u5f02\u6b65\u66f4\u65b0\u673a\u5236\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.18008", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18008", "abs": "https://arxiv.org/abs/2602.18008", "authors": ["Zihan Guan", "Rituparna Datta", "Mengxuan Hu", "Shunshun Liu", "Aiying Zhang", "Prasanna Balachandran", "Sheng Li", "Anil Vullikanti"], "title": "NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs", "comment": "19 pages, 6 figures", "summary": "Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Neural-Integrated Mechanistic Modeling (NIMM)\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u8bc4\u4f30\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u673a\u5236\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u53d1\u73b0\u8bbe\u8ba1\u4e86NIMMgen\u6846\u67b6\u6765\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u589e\u5f3a\u4ee3\u7801\u6b63\u786e\u6027\u548c\u5b9e\u9645\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ece\u6570\u636e\u6784\u5efa\u673a\u5236\u6a21\u578b\u7684\u95ee\u9898\u8bbe\u5b9a\u8fc7\u4e8e\u7b80\u5316\uff0c\u5bfc\u81f4\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u578b\u5728\u5b9e\u8df5\u4e2d\u7684\u53ef\u9760\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6d4b\u8bd5\u8fd9\u4e9b\u6a21\u578b\u5728\u66f4\u63a5\u8fd1\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeural-Integrated Mechanistic Modeling (NIMM)\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u90e8\u5206\u89c2\u6d4b\u548c\u591a\u6837\u5316\u4efb\u52a1\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u673a\u5236\u6a21\u578b\u3002\u57fa\u4e8eNIMM\u6846\u67b6\u4e0b\u53d1\u73b0\u7684\u57fa\u672c\u6311\u6218\uff0c\u8fdb\u4e00\u6b65\u5f00\u53d1\u4e86NIMMgen\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u63d0\u5347\u6a21\u578b\u7684\u6709\u6548\u6027\u548c\u4ee3\u7801\u5c42\u9762\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u79d1\u5b66\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\uff0cNIMMgen\u6846\u67b6\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5b66\u4e60\u5230\u7684\u673a\u5236\u6a21\u578b\u8fd8\u652f\u6301\u53cd\u4e8b\u5b9e\u5e72\u9884\u6a21\u62df\u3002", "conclusion": "NIMM\u8bc4\u4ef7\u6846\u67b6\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u7ebf\u65b9\u6cd5\u9762\u4e34\u7684\u91cd\u8981\u6311\u6218\uff0c\u800cNIMMgen\u6846\u67b6\u5219\u63d0\u4f9b\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u7684\u4e00\u79cd\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u63d0\u9ad8\u673a\u5236\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.18037", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18037", "abs": "https://arxiv.org/abs/2602.18037", "authors": ["Johannes Ackermann", "Michael Noukhovitch", "Takashi Ishida", "Masashi Sugiyama"], "title": "Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards", "comment": "25 pages, 15 figures", "summary": "Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u6b63\u5219\u5316\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u51cf\u5c11\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u3002\u4e0e\u4f20\u7edf\u7684KL\u60e9\u7f5a\u76f8\u6bd4\uff0c\u68af\u5ea6\u6b63\u5219\u5316\u80fd\u591f\u4fc3\u4f7f\u7b56\u7565\u66f4\u65b0\u504f\u5411\u4e8e\u5956\u52b1\u66f4\u51c6\u786e\u7684\u533a\u57df\uff0c\u4ece\u800c\u63d0\u9ad8\u6574\u4f53\u8868\u73b0\u3002", "motivation": "\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u4e2d\u5e38\u89c1\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\uff0c\u5373\u7b56\u7565\u53ef\u80fd\u5229\u7528\u5956\u52b1\u51fd\u6570\u7684\u4e0d\u51c6\u786e\u6027\u5b66\u4e60\u5230\u975e\u9884\u671f\u7684\u884c\u4e3a\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\u3002", "method": "\u9996\u5148\u4ece\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u5956\u52b1\u6a21\u578b\u51c6\u786e\u6027\u4e0e\u6700\u4f18\u89e3\u5e73\u5766\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u7136\u540e\u5f15\u5165\u4e86\u68af\u5ea6\u6b63\u5219\u5316\uff08GR\uff09\u6280\u672f\uff0c\u7528\u4e8e\u5f15\u5bfc\u8bad\u7ec3\u8fc7\u7a0b\u671d\u5411\u66f4\u52a0\u5e73\u5766\u3001\u5956\u52b1\u66f4\u51c6\u786e\u7684\u533a\u57df\u53d1\u5c55\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6709\u9650\u5dee\u5206\u4f30\u8ba1\u65b9\u6cd5\u6765\u8fdb\u884c\u663e\u5f0f\u7684\u68af\u5ea6\u6b63\u5219\u5316\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u79cd\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u68af\u5ea6\u6b63\u5219\u5316\u6bd4KL\u60e9\u7f5a\u8868\u73b0\u5f97\u66f4\u597d\u3002\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86GPT\u8bc4\u4ef7\u4e0b\u7684\u80dc\u7387\uff0c\u907f\u514d\u4e86\u5bf9\u683c\u5f0f\u7684\u8fc7\u5ea6\u5173\u6ce8\uff0c\u5e76\u4e14\u9632\u6b62\u4e86\u5728\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u88c1\u5224\u8fdb\u884c\u6570\u5b66\u4efb\u52a1\u65f6\u51fa\u73b0\u7684\u4f5c\u5f0a\u884c\u4e3a\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u68af\u5ea6\u6b63\u5219\u5316\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b0\u89c6\u89d2\u3002\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5982KL\u60e9\u7f5a\uff0c\u68af\u5ea6\u6b63\u5219\u5316\u80fd\u591f\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u5956\u52b1\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u4f18\u5316\u6a21\u578b\u7684\u8868\u73b0\u3002"}}
{"id": "2602.18055", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18055", "abs": "https://arxiv.org/abs/2602.18055", "authors": ["Jingyang Qiao", "Zhizhong Zhang", "Xin Tan", "Jingyu Gong", "Yanyun Qu", "Yuan Xie"], "title": "Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework", "comment": null, "summary": "Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Continual-NExT\u6846\u67b6\u548cMAGE\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3Dual-to-Dual MLLMs\u5728\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u77e5\u8bc6\u9057\u5fd8\u3001\u5e7b\u89c9\u751f\u6210\u3001\u6307\u4ee4\u4e0d\u9075\u4ece\u4ee5\u53ca\u8de8\u6a21\u6001\u77e5\u8bc6\u8f6c\u79fb\u5931\u8d25\u7b49\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMAGE\u65b9\u6cd5\u5728\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1Dual-to-Dual MLLMs\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5373\u65f6\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5728\u957f\u671f\u6f14\u5316\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u9002\u5e94\u52a8\u6001\u73b0\u5b9e\u573a\u666f\u65f6\u3002\u6b64\u5916\uff0c\u8fd9\u7c7b\u6a21\u578b\u5728\u5b66\u4e60\u65b0\u4efb\u52a1\u65f6\u9762\u4e34\u5df2\u5b66\u77e5\u8bc6\u88ab\u7834\u574f\u7684\u95ee\u9898\uff0c\u9664\u4e86\u4f20\u7edf\u7684\u707e\u96be\u6027\u9057\u5fd8\u5916\uff0c\u8fd8\u5b58\u5728\u7740\u5e7b\u89c9\u751f\u6210\u3001\u6307\u4ee4\u4e0d\u9075\u4ece\u4ee5\u53ca\u8de8\u6a21\u6001\u77e5\u8bc6\u8f6c\u79fb\u5931\u8d25\u7b49\u6311\u6218\u3002\u76ee\u524d\u8fd8\u6ca1\u6709\u4e3aDual-to-Dual MLLMs\u5efa\u7acb\u6807\u51c6\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u6765\u63a2\u7d22\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4e3a\u4e86\u63d0\u9ad8Dual-to-Dual MLLMs\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u540d\u4e3aMAGE\uff08General LoRA\u4e0eExpert LoRA\u7684\u6df7\u5408\u53ca\u805a\u5408\uff09\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u4fc3\u8fdb\u4e0d\u540c\u6a21\u6001\u95f4\u7684\u77e5\u8bc6\u8f6c\u79fb\u540c\u65f6\u51cf\u8f7b\u9057\u5fd8\u73b0\u8c61\u3002\u6b64\u5916\uff0c\u8fd8\u5efa\u7acb\u4e86\u540d\u4e3aContinual-NExT\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u914d\u5907\u6709\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86MAGE\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u6539\u5584Dual-to-Dual MLLMs\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u5176\u4ed6\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u8868\u73b0\u6c34\u5e73\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6Continual-NExT\u53caMAGE\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u4e3a\u589e\u5f3aDual-to-Dual MLLMs\u9762\u5bf9\u6301\u7eed\u5b66\u4e60\u6311\u6218\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18084", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18084", "abs": "https://arxiv.org/abs/2602.18084", "authors": ["Benjamin Honor\u00e9", "Alba Carballo-Castro", "Yiming Qin", "Pascal Frossard"], "title": "Balancing Symmetry and Efficiency in Graph Flow Matching", "comment": "15 pages, 11 figures", "summary": "Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\\%$ of the baseline training epochs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u56fe\u751f\u6210\u6a21\u578b\u4e2d\u7b49\u53d8\u6027\u5e26\u6765\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u57fa\u4e8e\u6b63\u5f26\u4f4d\u7f6e\u7f16\u7801\u548c\u8282\u70b9\u7f6e\u6362\u7684\u53ef\u63a7\u5bf9\u79f0\u6027\u8c03\u8282\u65b9\u6848\u6765\u653e\u677e\u7b49\u53d8\u6027\u8981\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u9002\u5ea6\u6253\u7834\u5bf9\u79f0\u6027\u80fd\u52a0\u901f\u6a21\u578b\u6536\u655b\u5e76\u5ef6\u8fdf\u8fc7\u62df\u5408\uff0c\u4ece\u800c\u5728\u4ec5\u4f7f\u7528\u57fa\u7ebf\u8bad\u7ec3\u5468\u671f19%\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u56fe\u751f\u6210\u6a21\u578b\u4e2d\u7684\u7b49\u53d8\u6027\u4e0e\u8ba1\u7b97\u6210\u672c\u53ca\u6536\u655b\u901f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5c3d\u7ba1\u7b49\u53d8\u6027\u4fdd\u8bc1\u4e86\u6a21\u578b\u5bf9\u4e8e\u56fe\u7684\u7f6e\u6362\u5bf9\u79f0\u6027\u7684\u5c0a\u91cd\uff0c\u4f46\u4e25\u683c\u7684\u7b49\u53d8\u6027\u589e\u52a0\u4e86\u67b6\u6784\u4e0a\u7684\u7ea6\u675f\uff0c\u5e76\u53ef\u80fd\u56e0\u9700\u8981\u8003\u8651\u5927\u91cf\u53ef\u80fd\u7684\u8282\u70b9\u6392\u5217\u800c\u51cf\u6162\u6536\u655b\u901f\u5ea6\u3002", "method": "\u4ece\u4e00\u4e2a\u7b49\u53d8\u79bb\u6563\u6d41\u5339\u914d\u6a21\u578b\u51fa\u53d1\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u6b63\u5f26\u4f4d\u7f6e\u7f16\u7801\u548c\u8282\u70b9\u7f6e\u6362\u7684\u53ef\u63a7\u5236\u5bf9\u79f0\u6027\u8c03\u5236\u65b9\u6848\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u653e\u677e\u6a21\u578b\u7684\u7b49\u53d8\u6027\u8981\u6c42\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u9002\u5ea6\u6253\u7834\u5bf9\u79f0\u6027\u80fd\u591f\u4e3a\u6a21\u578b\u63d0\u4f9b\u66f4\u5bb9\u6613\u7684\u5b66\u4e60\u4fe1\u53f7\u4ee5\u52a0\u901f\u65e9\u671f\u8bad\u7ec3\u8fc7\u7a0b\uff1b\u7136\u800c\uff0c\u5982\u679c\u8fc7\u5ea6\uff0c\u5219\u53ef\u80fd\u5bfc\u81f4\u9f13\u52b1\u6377\u5f84\u89e3\u51b3\u65b9\u6848\u8fdb\u800c\u5f15\u53d1\u8fc7\u62df\u5408\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u53cd\u590d\u751f\u6210\u8bad\u7ec3\u96c6\u4e2d\u7684\u91cd\u590d\u56fe\u3002\u76f8\u53cd\u5730\uff0c\u9002\u5f53\u8c03\u6574\u5bf9\u79f0\u6027\u4fe1\u53f7\u53ef\u4ee5\u5728\u52a0\u5feb\u6536\u655b\u7684\u540c\u65f6\u63a8\u8fdf\u8fc7\u62df\u5408\u7684\u53d1\u751f\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5728\u4ec5\u5229\u7528\u57fa\u7ebf\u8bad\u7ec3\u8f6e\u6b2119%\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u4f18\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5408\u7406\u8c03\u8282\u56fe\u751f\u6210\u6a21\u578b\u4e2d\u7684\u5bf9\u79f0\u6027\u7a0b\u5ea6\uff0c\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u8d1f\u62c5\u7684\u524d\u63d0\u4e0b\u6709\u6548\u63d0\u5347\u6a21\u578b\u6548\u7387\u548c\u6700\u7ec8\u6027\u80fd\uff0c\u907f\u514d\u8fc7\u65e9\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3\u6216\u8fc7\u62df\u5408\u72b6\u6001\u3002"}}
{"id": "2602.18114", "categories": ["cs.LG", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18114", "abs": "https://arxiv.org/abs/2602.18114", "authors": ["Yiding Feng", "Jiashuo Jiang", "Yige Wang"], "title": "Non-Stationary Online Resource Allocation: Learning from a Single Sample", "comment": null, "summary": "We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.\n  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\\tilde{O}(\\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u975e\u5e73\u7a33\u9700\u6c42\u4e0b\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7c7b\u578b\u4f9d\u8d56\u5206\u4f4d\u6570\u7684\u5143\u7b56\u7565\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u4fe1\u606f\u6837\u672c\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u7b56\u7565\u3002\u5bf9\u4e8e\u5956\u52b1\u89c2\u5bdf\u6837\u672c\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4f3c$\\tilde{O}(\\sqrt{T})$\u7684\u9057\u61be\uff1b\u800c\u5bf9\u4e8e\u4ec5\u7c7b\u578b\u4fe1\u606f\u6837\u672c\uff0c\u5728\u6ee1\u8db3\u6700\u5c0f\u5230\u8fbe\u6982\u7387\u5047\u8bbe\u7684\u524d\u63d0\u4e0b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u9002\u5e94\u89e3\u51b3\u7b56\u7565\uff0c\u8fbe\u5230\u4e86\u9996\u4e2a\u591a\u9879\u5f0f\u5bf9\u6570\u9057\u61be\u4fdd\u8bc1$O((\\log T)^3)$\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5904\u7406\u975e\u5e73\u7a33\u9700\u6c42\u4e0b\u7684\u5728\u7ebf\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u540c\u65f6\u8981\u6c42\u7b97\u6cd5\u53ea\u9700\u8981\u6bcf\u4e2a\u5468\u671f\u7684\u5386\u53f2\u6570\u636e\u6837\u672c\u6765\u6709\u6548\u8fd0\u4f5c\u3002\u8be5\u7814\u7a76\u533a\u5206\u4e86\u4e24\u79cd\u4e0d\u540c\u4fe1\u606f\u91cf\u7684\u6837\u672c\u60c5\u51b5\uff1a\u65e2\u5305\u542b\u67e5\u8be2\u7c7b\u578b\u4e5f\u5305\u62ec\u5956\u52b1\u5b9e\u73b0\u7684\u5956\u52b1\u89c2\u5bdf\u6837\u672c\uff0c\u4ee5\u53ca\u53ea\u63d0\u4f9b\u67e5\u8be2\u7c7b\u578b\u4fe1\u606f\u7684\u66f4\u5177\u6709\u6311\u6218\u6027\u7684\u4ec5\u7c7b\u578b\u6837\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u7c7b\u578b\u4f9d\u8d56\u5206\u4f4d\u6570\u7684\u5143\u7b56\u7565\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u51e0\u4e2a\u6a21\u5757\u5316\u7ec4\u4ef6\uff1a\u5956\u52b1\u5206\u5e03\u4f30\u8ba1\u3001\u901a\u8fc7\u6d41\u4f53\u677e\u5f1b\u4f18\u5316\u76ee\u6807\u670d\u52a1\u6982\u7387\u3001\u4ee5\u53ca\u901a\u8fc7\u52a8\u6001\u63a5\u53d7\u9608\u503c\u8fdb\u884c\u5b9e\u65f6\u51b3\u7b56\u3002\u5bf9\u4e8e\u4ec5\u7c7b\u578b\u6837\u672c\u7684\u60c5\u51b5\uff0c\u5728\u8f7b\u5fae\u7684\u6700\u5c0f\u5230\u8fbe\u6982\u7387\u5047\u8bbe\u4e0b\uff0c\u8bbe\u8ba1\u4e86\u90e8\u5206\u81ea\u9002\u5e94\u7b56\u7565\u548c\u4e00\u79cd\u66f4\u4e3a\u91cd\u8981\u7684\u5168\u81ea\u9002\u5e94\u89e3\u51b3\u7b56\u7565\u3002", "result": "\u5bf9\u4e8e\u5956\u52b1\u89c2\u5bdf\u6837\u672c\uff0c\u9759\u6001\u9608\u503c\u7b56\u7565\u8fbe\u6210\u4e86\u8fd1\u4f3c$\\tilde{O}(\\sqrt{T})$\u7684\u9057\u61be\uff1b\u5bf9\u4e8e\u4ec5\u7c7b\u578b\u6837\u672c\uff0c\u9996\u6b21\u8bc1\u660e\u4e86\u6ca1\u6709\u989d\u5916\u7ed3\u6784\u65f6\u6b21\u7ebf\u6027\u9057\u61be\u662f\u4e0d\u53ef\u80fd\u7684\uff0c\u4f46\u901a\u8fc7\u63d0\u51fa\u7684\u7b56\u7565\u83b7\u5f97\u4e86$O((\\log T)^3)$\u7684\u591a\u9879\u5f0f\u5bf9\u6570\u9057\u61be\u4fdd\u969c\u3002", "conclusion": "\u672c\u7814\u7a76\u63a8\u8fdb\u4e86\u5148\u524d\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u4f7f\u7528\u6700\u5c11\u7684\u79bb\u7ebf\u6570\u636e\uff08\u6bcf\u4e2a\u65f6\u671f\u4e00\u4e2a\u6837\u672c\uff09\u3001\u5904\u7406\u65e0\u53d8\u5316\u9884\u7b97\u5047\u8bbe\u4e0b\u7684\u4efb\u610f\u975e\u5e73\u7a33\u6027\u4ee5\u53ca\u652f\u6301\u591a\u4e2a\u8d44\u6e90\u7ea6\u675f\uff0c\u4e3a\u975e\u5e73\u7a33\u591a\u8d44\u6e90\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18117", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18117", "abs": "https://arxiv.org/abs/2602.18117", "authors": ["Yongjae Shin", "Jongseong Chae", "Jongeui Park", "Youngchul Sung"], "title": "Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning", "comment": "ICLR 2026 camera-ready", "summary": "Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5FINO\uff0c\u901a\u8fc7\u5728\u7b56\u7565\u8bad\u7ec3\u4e2d\u52a0\u5165\u566a\u58f0\u6765\u63d0\u9ad8\u4ece\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u7ed3\u5408\u4e86\u71b5\u5f15\u5bfc\u7684\u91c7\u6837\u673a\u5236\u4ee5\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u5728\u7ebf\u9884\u7b97\u4e0b\uff0cFINO\u80fd\u591f\u4e00\u81f4\u5730\u8fbe\u5230\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u751f\u6210\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5411\u5728\u7ebf\u5fae\u8c03\u6269\u5c55\u65f6\u9047\u5230\u4e86\u672a\u89e3\u51b3\u7684\u5173\u952e\u6311\u6218\u3002\u4e3a\u4e86\u4fc3\u8fdb\u6709\u6548\u7684\u63a2\u7d22\u5e76\u589e\u5f3a\u6837\u672c\u6548\u7387\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86FINO\u65b9\u6cd5\u3002", "method": "FINO\u65b9\u6cd5\u57fa\u4e8e\u6d41\u5339\u914d\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5728\u7b56\u7565\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u566a\u58f0\u6765\u9f13\u52b1\u8d85\u51fa\u79bb\u7ebf\u6570\u636e\u96c6\u89c2\u5bdf\u8303\u56f4\u7684\u66f4\u5e7f\u6cdb\u52a8\u4f5c\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u7ed3\u5408\u4e86\u71b5\u5f15\u5bfc\u91c7\u6837\u673a\u5236\uff0c\u4ee5\u5728\u6574\u4e2a\u5728\u7ebf\u5fae\u8c03\u671f\u95f4\u5e73\u8861\u63a2\u7d22\u4e0e\u5f00\u53d1\u3002", "result": "\u8de8\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFINO\u5728\u6709\u9650\u7684\u5728\u7ebf\u9884\u7b97\u6761\u4ef6\u4e0b\u59cb\u7ec8\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "FINO\u4e3a\u4ece\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u6548\u9014\u5f84\uff0c\u901a\u8fc7\u6539\u5584\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u7684\u6837\u672c\u6548\u7387\u4ee5\u53ca\u52a8\u6001\u8c03\u6574\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4ece\u800c\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u5b9e\u73b0\u5353\u8d8a\u8868\u73b0\u3002"}}
{"id": "2602.18168", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18168", "abs": "https://arxiv.org/abs/2602.18168", "authors": ["Danning Jing", "Xinhai Chen", "Xifeng Pu", "Jie Hu", "Chao Huang", "Xuguang Chen", "Qinglin Wang", "Jie Liu"], "title": "A Deep Surrogate Model for Robust and Generalizable Long-Term Blast Wave Prediction", "comment": null, "summary": "Accurately modeling the spatio-temporal dynamics of blast wave propagation remains a longstanding challenge due to its highly nonlinear behavior, sharp gradients, and burdensome computational cost. While machine learning-based surrogate models offer fast inference as a promising alternative, they suffer from degraded accuracy, particularly evaluated on complex urban layouts or out-of-distribution scenarios. Moreover, autoregressive prediction strategies in such models are prone to error accumulation over long forecasting horizons, limiting their robustness for extended-time simulations. To address these limitations, we propose RGD-Blast, a robust and generalizable deep surrogate model for high-fidelity, long-term blast wave forecasting. RGD-Blast incorporates a multi-scale module to capture both global flow patterns and local boundary interactions, effectively mitigating error accumulation during autoregressive prediction. We introduce a dynamic-static feature coupling mechanism that fuses time-varying pressure fields with static source and layout features, thereby enhancing out-of-distribution generalization. Experiments demonstrate that RGD-Blast achieves a two-order-of-magnitude speedup over traditional numerical methods while maintaining comparable accuracy. In generalization tests on unseen building layouts, the model achieves an average RMSE below 0.01 and an R2 exceeding 0.89 over 280 consecutive time steps. Additional evaluations under varying blast source locations and explosive charge weights further validate its generalization, substantially advancing the state of the art in long-term blast wave modeling.", "AI": {"tldr": "RGD-Blast, a deep learning-based model, is proposed to accurately and efficiently predict long-term blast wave propagation. It integrates multi-scale and dynamic-static feature coupling mechanisms to improve generalization and reduce error accumulation, achieving significant speedup over traditional methods without compromising accuracy.", "motivation": "The main motivation is to overcome the challenges of modeling blast wave propagation, such as high nonlinearity, sharp gradients, and computational cost, while also addressing the limitations of existing machine learning models in terms of accuracy, especially in complex or out-of-distribution scenarios, and their tendency for error accumulation over extended forecasting periods.", "method": "The method involves developing RGD-Blast, a novel deep surrogate model that utilizes a multi-scale module to capture both global and local flow dynamics, and a dynamic-static feature coupling mechanism to integrate time-varying and static features, thus enhancing its capability to generalize to unseen conditions and maintain accuracy over longer forecasting horizons.", "result": "RGD-Blast demonstrates a two-order-of-magnitude speedup compared to traditional numerical methods, with comparable accuracy. It achieves an average RMSE below 0.01 and an R2 score above 0.89 across 280 consecutive time steps on unseen building layouts, showing strong generalization capabilities even under varying blast source locations and explosive charge weights.", "conclusion": "RGD-Blast represents a significant advancement in long-term blast wave modeling by providing a robust, accurate, and computationally efficient solution that can effectively handle complex urban environments and out-of-distribution scenarios, making it a promising tool for real-world applications."}}
{"id": "2602.18182", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18182", "abs": "https://arxiv.org/abs/2602.18182", "authors": ["Daniel Romero-Alvarado", "Fernando Mart\u00ednez-Plumed", "Lorenzo Pacchiardi", "Hugo Save", "Siddhesh Milind Pawar", "Behzad Mehrbakhsh", "Pablo Antonio Moreno Casares", "Ben Slater", "Paolo Bova", "Peter Romero", "Zachary R. Tyler", "Jonathan Prunty", "Luning Sun", "Jose Hernandez-Orallo"], "title": "Capabilities Ain't All You Need: Measuring Propensities in AI", "comment": null, "summary": "AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an \"ideal band\". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6b63\u5f0f\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u4f7f\u7528\u53cc\u903b\u8f91\u516c\u5f0f\u6765\u8861\u91cfAI\u503e\u5411\u6027\uff0c\u8be5\u516c\u5f0f\u5c06\u6a21\u578b\u7684\u6210\u529f\u6982\u7387\u5f52\u56e0\u4e8e\u5f53\u5176\u503e\u5411\u6027\u5904\u4e8e\"\u7406\u60f3\u533a\u95f4\"\u5185\u65f6\u3002\u6b64\u5916\uff0c\u5229\u7528\u914d\u5907\u6709\u65b0\u5f00\u53d1\u7684\u4efb\u52a1\u65e0\u5173\u8bc4\u5206\u6807\u51c6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f30\u8ba1\u4e86\u7406\u60f3\u533a\u95f4\u7684\u754c\u9650\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u6d4b\u91cf\u503e\u5411\u6027\u7684\u53d8\u5316\u4ee5\u53ca\u8fd9\u79cd\u53d8\u5316\u5bf9\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u4f7f\u7528\u4e00\u4e2a\u57fa\u51c6\u4f30\u8ba1\u7684\u503e\u5411\u6027\u80fd\u6210\u529f\u9884\u6d4b\u5728\u4fdd\u7559\u4efb\u52a1\u4e0a\u7684\u884c\u4e3a\u3002\u7ed3\u5408\u503e\u5411\u6027\u548c\u80fd\u529b\u6bd4\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u8005\u5177\u6709\u66f4\u5f3a\u7684\u9884\u6d4b\u529b\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u8bc4\u4f30\u4e3b\u8981\u96c6\u4e2d\u5728\u80fd\u529b\u6d4b\u91cf\u4e0a\uff0c\u4f46\u503e\u5411\u6027\u2014\u2014\u6a21\u578b\u8868\u73b0\u51fa\u7279\u5b9a\u884c\u4e3a\u7684\u8d8b\u52bf\u2014\u2014\u5728\u51b3\u5b9a\u6027\u80fd\u548c\u5b89\u5168\u7ed3\u679c\u65b9\u9762\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u9879\u76ee\u53cd\u5e94\u7406\u8bba\uff08IRT\uff09\u65b9\u6cd5\u63cf\u8ff0\u4e86\u6a21\u578b\u5728\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u662f\u6a21\u578b\u80fd\u529b\u548c\u4efb\u52a1\u9700\u6c42\u7684\u5355\u8c03\u51fd\u6570\uff0c\u8fd9\u4e0d\u9002\u5408\u5904\u7406\u503e\u5411\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u5728\u503e\u5411\u6027\u95ee\u9898\u4e2d\uff0c\u8fc7\u5269\u548c\u4e0d\u8db3\u90fd\u53ef\u80fd\u662f\u6709\u95ee\u9898\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u6765\u66f4\u51c6\u786e\u5730\u8861\u91cfAI\u6a21\u578b\u7684\u503e\u5411\u6027\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u903b\u8f91\u516c\u5f0f\u7684\u65b0\u65b9\u6cd5\u6765\u5b9a\u4e49\u6a21\u578b\u7684\u6210\u529f\u6982\u7387\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\u7684\u503e\u5411\u6027\u843d\u5728\u67d0\u4e2a\u201c\u7406\u60f3\u533a\u95f4\u201d\u5185\u65f6\u3002\u4e3a\u4e86\u4f30\u8ba1\u8fd9\u4e2a\u7406\u60f3\u533a\u95f4\u7684\u8fb9\u754c\uff0c\u4ed6\u4eec\u5f00\u53d1\u4e86\u65b0\u7684\u3001\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u901a\u8fc7\u5bf9\u516d\u4e2a\u4e0d\u540c\u5bb6\u65cf\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5728\u8fd9\u4e9b\u6a21\u578b\u4e2d\u4eba\u4e3a\u5730\u6fc0\u53d1\u4e86\u503e\u5411\u6027\u7684\u53d8\u5316\uff0c\u4ee5\u6b64\u6765\u9a8c\u8bc1\u8fd9\u4e00\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u6d4b\u91cf\u503e\u5411\u6027\u7684\u53d8\u52a8\u53ca\u5176\u5bf9\u4efb\u52a1\u8868\u73b0\u7684\u5f71\u54cd\u3002\u91cd\u8981\u7684\u662f\uff0c\u5229\u7528\u5355\u4e00\u57fa\u51c6\u6d4b\u8bd5\u4f30\u7b97\u51fa\u7684\u503e\u5411\u6027\u53ef\u4ee5\u6210\u529f\u9884\u6d4b\u5728\u5176\u4ed6\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u4e0a\u7684\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u5c06\u503e\u5411\u6027\u4e0e\u80fd\u529b\u76f8\u7ed3\u5408\u6bd4\u5355\u72ec\u8003\u8651\u4efb\u4e00\u65b9\u9762\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u884c\u4e3a\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5982\u4f55\u4e25\u8c28\u5730\u8fdb\u884c\u503e\u5411\u6027\u6d4b\u91cf\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u4ec5\u4f9d\u8d56\u80fd\u529b\u8bc4\u4f30\u6765\u9884\u6d4bAI\u884c\u4e3a\u800c\u8a00\uff0c\u5b83\u5e26\u6765\u4e86\u663e\u8457\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.18195", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18195", "abs": "https://arxiv.org/abs/2602.18195", "authors": ["Hairong Chen", "Yicheng Feng", "Ziyu Jia", "Samir Bhatt", "Hengguan Huang"], "title": "LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification", "comment": null, "summary": "Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLERD\u7684\u8d1d\u53f6\u65af\u7535\u751f\u7406\u795e\u7ecf\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u76f4\u63a5\u4ece\u591a\u901a\u9053EEG\u4e2d\u63a8\u65ad\u51fa\u6f5c\u5728\u7684\u795e\u7ecf\u4e8b\u4ef6\u53ca\u5176\u5173\u7cfb\u7ed3\u6784\uff0c\u800c\u65e0\u9700\u4e8b\u4ef6\u6216\u4ea4\u4e92\u6ce8\u91ca\u3002\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cLERD\u5728\u5408\u6210\u57fa\u51c6\u548c\u4e24\u4e2a\u771f\u5b9e\u4e16\u754cAD EEG\u961f\u5217\u4e0a\u5747\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0e\u751f\u7406\u4e00\u81f4\u7684\u6f5c\u5728\u6458\u8981\uff0c\u6709\u52a9\u4e8e\u8868\u5f81\u7ec4\u7ea7\u52a8\u6001\u5dee\u5f02\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u6539\u53d8\u4e86\u5927\u8111\u7535\u751f\u7406\u5e76\u7834\u574f\u4e86\u591a\u901a\u9053EEG\u52a8\u6001\uff0c\u4f7f\u5f97\u57fa\u4e8eEEG\u7684\u51c6\u786e\u4e14\u5177\u6709\u4e34\u5e8a\u4ef7\u503c\u7684\u8bca\u65ad\u5bf9\u4e8e\u7b5b\u67e5\u548c\u75be\u75c5\u76d1\u6d4b\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9ed1\u7bb1\u5206\u7c7b\u5668\uff0c\u5e76\u6ca1\u6709\u660e\u786e\u5730\u5efa\u6a21\u751f\u6210\u89c2\u5bdf\u4fe1\u53f7\u7684\u57fa\u672c\u52a8\u6001\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86LERD\uff0c\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u8d1d\u53f6\u65af\u7535\u751f\u7406\u795e\u7ecf\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u53ef\u4ee5\u4ece\u6ca1\u6709\u4e8b\u4ef6\u6216\u4ea4\u4e92\u6ce8\u91ca\u7684\u591a\u901a\u9053EEG\u4e2d\u76f4\u63a5\u63a8\u65ad\u51fa\u6f5c\u5728\u795e\u7ecf\u4e8b\u4ef6\u53ca\u5176\u5173\u7cfb\u7ed3\u6784\u3002LERD\u7ed3\u5408\u4e86\u4e00\u4e2a\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u63a8\u7406\u6a21\u5757\u4e0e\u968f\u673a\u4e8b\u4ef6\u751f\u6210\u8fc7\u7a0b\u6765\u6355\u6349\u7075\u6d3b\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u540c\u65f6\u878d\u5165\u4e86\u53d7\u7535\u751f\u7406\u542f\u53d1\u7684\u52a8\u529b\u5b66\u5148\u9a8c\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5f97\u5230\u4e86\u8bad\u7ec3\u7528\u7684\u53ef\u5904\u7406\u8fb9\u754c\u4ee5\u53ca\u5bf9\u63a8\u65ad\u51fa\u7684\u5173\u7cfb\u52a8\u6001\u7684\u7a33\u5b9a\u6027\u4fdd\u8bc1\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u53ca\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7684AD EEG\u6570\u636e\u96c6\u4e0a\uff0cLERD\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u52b2\u7684\u57fa\u7ebf\uff0c\u5e76\u751f\u6210\u4e86\u4e0e\u751f\u7406\u76f8\u7b26\u7684\u6f5c\u5728\u603b\u7ed3\uff0c\u8fd9\u6709\u52a9\u4e8e\u63cf\u8ff0\u7ec4\u7ea7\u522b\u7684\u52a8\u6001\u5dee\u5f02\u3002", "conclusion": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\u2014\u2014LERD\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u9700\u8981\u989d\u5916\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u76f4\u63a5\u4eceEEG\u6570\u636e\u4e2d\u63a8\u65ad\u51fa\u6f5c\u5728\u7684\u795e\u7ecf\u6d3b\u52a8\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5bf9AD\u7b49\u75be\u75c5\u7684\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7406\u89e3\u5927\u8111\u7535\u6d3b\u52a8\u80cc\u540e\u673a\u5236\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2602.18196", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18196", "abs": "https://arxiv.org/abs/2602.18196", "authors": ["Xiuying Wei", "Caglar Gulcehre"], "title": "RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference", "comment": null, "summary": "Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAT+\u7684\u65b0\u67b6\u6784\uff0c\u5b83\u901a\u8fc7\u5168\u5e8f\u5217\u9012\u5f52\u548c\u4e3b\u52a8\u9012\u5f52\u5b66\u4e60\u6765\u589e\u5f3a\u6ce8\u610f\u529b\u673a\u5236\u3002RAT+\u6a21\u578b\u5728\u5bc6\u96c6\u9884\u8bad\u7ec3\u540e\uff0c\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u7075\u6d3b\u5207\u6362\u5230\u7a00\u758f\u6a21\u5f0f\uff08\u53ef\u9009\u5c40\u90e8\u7a97\u53e3\uff09\u6216\u6df7\u5408\u5c42/\u5934\u7ec4\u5408\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u4e0d\u540c\u7684\u7a00\u758f\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5e38\u8bc6\u63a8\u7406\u548cLongBench\u4efb\u52a1\u4e0a\uff0cRAT+\u80fd\u591f\u63a5\u8fd1\u4e8e\u5bc6\u96c6\u6ce8\u610f\u529b\u7684\u51c6\u786e\u5ea6\uff0c\u5e76\u4e14\u5728\u6269\u5c55\u53c2\u6570\u89c4\u6a21\u540e\u4fdd\u6301\u4e86\u76f8\u540c\u8d8b\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u5316\u6269\u5f20\u6ce8\u610f\u529b\u867d\u7136\u5728\u63a8\u7406\u65f6\u63d0\u4f9b\u4e86\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u5c06\u9884\u8bad\u7ec3\u7684\u6ce8\u610f\u529b\u6a21\u578b\u7a00\u758f\u5316\u4e3a\u6269\u5f20\u6a21\u5f0f\u4f1a\u5bfc\u81f4\u51c6\u786e\u6027\u4e25\u91cd\u4e0b\u964d\u3002", "method": "\u5f15\u5165RAT+\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u901a\u8fc7\u589e\u52a0\u5168\u5e8f\u5217\u9012\u5f52\u548c\u4e3b\u52a8\u9012\u5f52\u5b66\u4e60\u6765\u589e\u5f3a\u6ce8\u610f\u529b\u673a\u5236\u3002\u5355\u4e2aRAT+\u6a21\u578b\u53ea\u9700\u4e00\u6b21\u5bc6\u96c6\u9884\u8bad\u7ec3\uff0c\u4e4b\u540e\u53ef\u4ee5\u6839\u636e\u9700\u8981\u5feb\u901f\u9002\u5e94\u4e0d\u540c\u7684\u7a00\u758f\u6a21\u5f0f\u6216\u6df7\u5408\u914d\u7f6e\u3002", "result": "\u57281.5\u4ebf\u53c2\u6570\u3001100\u4ebftoken\u7684\u8bad\u7ec3\u4e0b\uff0cRAT+\u6a21\u578b\u5728\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u51e0\u4e4e\u4e0e\u5bc6\u96c6\u578b\u6a21\u578b\u76f8\u5f53\uff1b\u5f53\u4f7f\u752864\u7684\u6269\u5f20\u56e0\u5b50\u65f6\uff0c\u6027\u80fd\u7565\u67092-3\u70b9\u7684\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u5f53\u8f6c\u6362\u4e3atop-k\u5757\u6ce8\u610f\u529b\u6a21\u5f0f\u65f6\uff0cRAT+\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u3002\u8fdb\u4e00\u6b65\u5c06\u53c2\u6570\u6269\u5927\u81f326\u4ebf\u5e76\u57fa\u4e8e200\u4ebftokens\u8bad\u7ec3\uff0c\u89c2\u5bdf\u5230\u4e86\u7c7b\u4f3c\u7684\u8d8b\u52bf\u3002", "conclusion": "RAT+\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5141\u8bb8\u4ece\u5355\u4e00\u5bc6\u96c6\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u7075\u6d3b\u5730\u5bfc\u51fa\u591a\u79cd\u7a00\u758f\u6a21\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18227", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18227", "abs": "https://arxiv.org/abs/2602.18227", "authors": ["Redwanul Karim", "Changhun Kim", "Timon Conrad", "Nora Gourmelon", "Julian Oelhaf", "David Riebesel", "Tom\u00e1s Arias-Vergara", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "Parameter-Efficient Domain Adaptation of Physics-Informed Self-Attention based GNNs for AC Power Flow Prediction", "comment": null, "summary": "Accurate AC-PF prediction under domain shift is critical when models trained on medium-voltage (MV) grids are deployed on high-voltage (HV) networks. Existing physics-informed graph neural solvers typically rely on full fine-tuning for cross-regime transfer, incurring high retraining cost and offering limited control over the stability-plasticity trade-off between target-domain adaptation and source-domain retention. We study parameter-efficient domain adaptation for physics-informed self-attention based GNN, encouraging Kirchhoff-consistent behavior via a physics-based loss while restricting adaptation to low-rank updates. Specifically, we apply LoRA to attention projections with selective unfreezing of the prediction head to regulate adaptation capacity. This design yields a controllable efficiency-accuracy trade-off for physics-constrained inverse estimation under voltage-regime shift. Across multiple grid topologies, the proposed LoRA+PHead adaptation recovers near-full fine-tuning accuracy with a target-domain RMSE gap of $2.6\\times10^{-4}$ while reducing the number of trainable parameters by 85.46%. The physics-based residual remains comparable to full fine-tuning; however, relative to Full FT, LoRA+PHead reduces MV source retention by 4.7 percentage points (17.9% vs. 22.6%) under domain shift, while still enabling parameter-efficient and physically consistent AC-PF estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLoRA+PHead\u7684\u53c2\u6570\u9ad8\u6548\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u7269\u7406\u4fe1\u606f\u81ea\u6ce8\u610f\u529bGNN\u5728\u7535\u538b\u5236\u5ea6\u8f6c\u79fb\u4e0b\u7684AC-PF\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9650\u5236\u9002\u5e94\u4e8e\u4f4e\u79e9\u66f4\u65b0\u6765\u9f13\u52b1\u7b26\u5408\u57fa\u5c14\u970d\u592b\u5b9a\u5f8b\u7684\u884c\u4e3a\uff0c\u5e76\u4e14\u4e0e\u5168\u5fae\u8c03\u76f8\u6bd4\uff0c\u5728\u51cf\u5c1185.46%\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u540c\u65f6\uff0c\u51e0\u4e4e\u6062\u590d\u4e86\u5168\u5fae\u8c03\u7684\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u56fe\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u8de8\u4f53\u5236\u8fc1\u79fb\u65f6\u901a\u5e38\u4f9d\u8d56\u4e8e\u5b8c\u5168\u5fae\u8c03\uff0c\u8fd9\u5bfc\u81f4\u4e86\u9ad8\u6602\u7684\u518d\u8bad\u7ec3\u6210\u672c\uff0c\u5e76\u4e14\u5728\u76ee\u6807\u57df\u9002\u5e94\u548c\u6e90\u57df\u4fdd\u6301\u4e4b\u95f4\u7684\u7a33\u5b9a\u6027-\u53ef\u5851\u6027\u6743\u8861\u4e0a\u63d0\u4f9b\u4e86\u6709\u9650\u7684\u63a7\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\u7684\u540c\u65f6\uff0c\u964d\u4f4e\u91cd\u65b0\u8bad\u7ec3\u7684\u6210\u672c\u3002", "method": "\u91c7\u7528LoRA\u5e94\u7528\u4e8e\u6ce8\u610f\u6295\u5f71\uff0c\u5e76\u9009\u62e9\u6027\u5730\u89e3\u51bb\u9884\u6d4b\u5934\u90e8\u4ee5\u8c03\u8282\u9002\u5e94\u80fd\u529b\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u7684\u635f\u5931\u51fd\u6570\u4fc3\u8fdb\u7b26\u5408\u57fa\u5c14\u970d\u592b\u5b9a\u5f8b\u7684\u884c\u4e3a\uff0c\u540c\u65f6\u5c06\u9002\u5e94\u9650\u5236\u4e3a\u4f4e\u79e9\u66f4\u65b0\u3002", "result": "\u63d0\u51fa\u7684LoRA+PHead\u9002\u5e94\u65b9\u6cd5\u5728\u591a\u79cd\u7535\u7f51\u62d3\u6251\u4e2d\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5168\u5fae\u8c03\u7684\u51c6\u786e\u6027\uff0c\u76ee\u6807\u57dfRMSE\u5dee\u8ddd\u4e3a$2.6\\times10^{-4}$\uff0c\u540c\u65f6\u51cf\u5c11\u4e8685.46%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\u3002\u76f8\u5bf9\u4e8e\u5168\u5fae\u8c03\uff0cLoRA+PHead\u5728\u9886\u57df\u8f6c\u79fb\u4e0b\u964d\u4f4e\u4e86MV\u6e90\u4fdd\u7559\u73874.7\u4e2a\u767e\u5206\u70b9\uff08\u4ece22.6%\u964d\u81f317.9%\uff09\uff0c\u4f46\u4ecd\u80fd\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u4e14\u7269\u7406\u4e00\u81f4\u7684AC-PF\u4f30\u8ba1\u3002", "conclusion": "LoRA+PHead\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u9014\u5f84\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u7535\u538b\u5236\u5ea6\u4e4b\u95f4\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u4e14\u7269\u7406\u4e00\u81f4\u7684AC-PF\u9884\u6d4b\uff0c\u540c\u65f6\u5141\u8bb8\u5bf9\u6548\u7387-\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u8fdb\u884c\u63a7\u5236\u3002"}}
{"id": "2602.18248", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.18248", "abs": "https://arxiv.org/abs/2602.18248", "authors": ["Pietro Sittoni", "Emanuele Zangrando", "Angelo A. Casulli", "Nicola Guglielmi", "Francesco Tudisco"], "title": "Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver", "comment": null, "summary": "Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeural-HSS\u7684\u53c2\u6570\u9ad8\u6548\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u57fa\u4e8e\u5206\u5c42\u534a\u53ef\u5206\u79bb\uff08HSS\uff09\u77e9\u9635\u7ed3\u6784\uff0c\u5e76\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u5bf9\u4e00\u5927\u7c7b\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u8868\u73b0\u51fa\u8272\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Neural-HSS\u5728\u4e09\u7ef4\u6cca\u677e\u65b9\u7a0b\u4ee5\u53ca\u7535\u78c1\u5b66\u3001\u6d41\u4f53\u52a8\u529b\u5b66\u548c\u751f\u7269\u5b66\u7b49\u4e0d\u540c\u9886\u57df\u4e2d\u4ecePDE\u751f\u6210\u7684\u6570\u636e\u5b66\u4e60\u7684\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u6709\u9ad8\u6027\u80fd\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u53ef\u7528\uff0c\u4f46\u4e3a\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u800c\u4ea7\u751f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5e76\u8bad\u7ec3\u6a21\u578b\u4ecd\u7136\u9762\u4e34\u663e\u8457\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002\u53d7\u692d\u5706PDE\u683c\u6797\u51fd\u6570\u7ed3\u6784\u7814\u7a76\u7684\u542f\u53d1\uff0c\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Neural-HSS\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5229\u7528\u4e86\u5c42\u6b21\u534a\u53ef\u5206\u79bb\uff08HSS\uff09\u77e9\u9635\u7ed3\u6784\u7684\u7279\u70b9\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5bf9\u4e8e\u5e7f\u6cdb\u7c7b\u578bPDE\u90fd\u5177\u6709\u6570\u636e\u6548\u7387\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9\u8be5\u67b6\u6784\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u63a2\u7a76\u4e86\u5176\u4e0e\u5176\u4ed6\u67b6\u6784\u5143\u7d20\u5982\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u5c42\u548c\u5377\u79ef\u5c42\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e24\u767e\u4e07\u70b9\u7f51\u683c\u4e0a\u7684\u4e09\u7ef4\u6cca\u677e\u65b9\u7a0b\u6d4b\u8bd5\u4e2d\uff0c\u5373\u4f7f\u662f\u5728\u4f4e\u6570\u636e\u6761\u4ef6\u4e0b\uff0cNeural-HSS\u4e5f\u80fd\u591f\u6709\u6548\u5730\u4ece\u7531\u692d\u5706PDE\u4ea7\u751f\u7684\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5e76\u4e14\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u5b83\u8fd8\u80fd\u5f88\u597d\u5730\u9002\u5e94\u6765\u81ea\u5305\u62ec\u7535\u78c1\u5b66\u3001\u6d41\u4f53\u52a8\u529b\u5b66\u53ca\u751f\u7269\u5b66\u7b49\u9886\u57df\u5185\u591a\u79cdPDE\u7684\u6570\u636e\u3002", "conclusion": "Neural-HSS\u67b6\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u9014\u5f84\uff0c\u80fd\u591f\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u6709\u6548\u89e3\u51b3PDEs\u76f8\u5173\u7684\u95ee\u9898\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u8de8\u5b66\u79d1\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.18253", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18253", "abs": "https://arxiv.org/abs/2602.18253", "authors": ["Xabier de Zuazo", "Vincenzo Verbeni", "Eva Navas", "Ibon Saratxaga", "Mathieu Bourguignon", "Nicola Molinaro"], "title": "MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data", "comment": "6 pages, 3 figures, 3 tables, submitted to Interspeech 2026", "summary": "Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5c55\u793a\u4e86\u57fa\u4e8eMEG\u7684\u8bed\u97f3\u6a21\u578b\u5728\u611f\u77e5\u548c\u4ea7\u751f\u4efb\u52a1\u4e4b\u95f4\u7684\u8fc1\u79fb\u5b66\u4e60\u548c\u8de8\u4efb\u52a1\u89e3\u7801\u3002\u901a\u8fc7\u9884\u8bad\u7ec3\u4e00\u4e2a\u57fa\u4e8eConformer\u7684\u6a21\u578b\uff0c\u5e76\u5bf918\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u5fae\u8c03\uff0c\u7ed3\u679c\u8868\u660e\u8fc1\u79fb\u5b66\u4e60\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6bcf\u4e2a\u4efb\u52a1\u5185\u7684\u6027\u80fd\uff0c\u8fd8\u5b9e\u73b0\u4e86\u4efb\u52a1\u95f4\u7684\u53ef\u9760\u89e3\u7801\uff0c\u8bc1\u5b9e\u4e86\u5b66\u4e60\u5230\u7684\u8868\u5f81\u53cd\u6620\u4e86\u5171\u4eab\u795e\u7ecf\u8fc7\u7a0b\u800c\u975e\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u8fd0\u52a8\u6d3b\u52a8\u3002", "motivation": "\u6570\u636e\u9ad8\u6548\u7684\u795e\u7ecf\u89e3\u7801\u662f\u8bed\u97f3\u8111-\u673a\u63a5\u53e3\u7684\u6838\u5fc3\u6311\u6218\u3002\u8fd9\u9879\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u63d0\u9ad8\u57fa\u4e8eMEG\u7684\u8bed\u97f3\u6a21\u578b\u6548\u7387\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6a21\u578b\u80fd\u5426\u5728\u4e0d\u540c\u7684\u4efb\u52a1\uff08\u5982\u8bed\u97f3\u611f\u77e5\u4e0e\u4ea7\u751f\uff09\u4e4b\u95f4\u901a\u7528\u3002", "method": "\u7814\u7a76\u4eba\u5458\u9996\u5148\u5728\u4e00\u4e2a\u53d7\u8bd5\u8005\u4e0a\u4f7f\u752850\u5c0f\u65f6\u7684\u542c\u89c9\u6570\u636e\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8eConformer\u67b6\u6784\u7684\u6a21\u578b\uff0c\u7136\u540e\u9488\u5bf9\u53e6\u591618\u540d\u53d7\u8bd5\u8005\uff0c\u5728\u6bcf\u4eba\u4ec55\u5206\u949f\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "result": "\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u540e\uff0c\u540c\u4e00\u4efb\u52a1\u5185\u7684\u51c6\u786e\u7387\u63d0\u9ad8\u4e861-4%\uff0c\u800c\u8de8\u4efb\u52a1\u95f4\uff08\u5373\u4ece\u751f\u4ea7\u5230\u611f\u77e5\u6216\u53cd\u4e4b\uff09\u7684\u589e\u76ca\u5219\u8fbe\u5230\u4e865-6%\u3002\u6b64\u5916\uff0c\u4e13\u4e3a\u8bed\u97f3\u4ea7\u751f\u8bad\u7ec3\u7684\u6a21\u578b\u4e5f\u80fd\u4ee5\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\u7684\u8868\u73b0\u89e3\u7801\u88ab\u52a8\u542c\u529b\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u57fa\u4e8eMEG\u7684\u8bed\u97f3\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u6355\u6349\u5230\u8de8\u8d8a\u611f\u77e5\u548c\u4ea7\u751f\u7684\u5171\u540c\u795e\u7ecf\u5904\u7406\u673a\u5236\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u53cd\u6620\u7279\u5b9a\u4efb\u52a1\u76f8\u5173\u7684\u8fd0\u52a8\u6d3b\u52a8\u3002"}}
{"id": "2602.18292", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18292", "abs": "https://arxiv.org/abs/2602.18292", "authors": ["Xiaotong Ji", "Rasul Tutunov", "Matthieu Zimmer", "Haitham Bou-Ammar"], "title": "Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers", "comment": null, "summary": "Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u6846\u67b6\uff0c\u5c06\u89e3\u7801\u89c6\u4e3a\u4e00\u4e2a\u4f18\u5316\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u6db5\u76d6\u591a\u79cd\u73b0\u6709\u89e3\u7801\u65b9\u6cd5\uff0c\u5e76\u4e14\u57fa\u4e8e\u6b64\u6846\u67b6\u8bbe\u8ba1\u4e86\u540d\u4e3aBest-of-K\u7684\u65b0\u89e3\u7801\u5668\uff0c\u8be5\u89e3\u7801\u5668\u5728\u591a\u6837\u672c\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u9ad8\u91c7\u6837\u6e29\u5ea6\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u73b0\u6709\u7684\u89e3\u7801\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\uff0c\u901a\u5e38\u88ab\u89c6\u4e3a\u4e00\u79cd\u542f\u53d1\u5f0f\u8c03\u6574\u7684\u8fc7\u7a0b\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u70b9\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u7801\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u89e3\u51b3\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u7684\u6b63\u5219\u5316\u95ee\u9898\u6765\u5e73\u8861\u6a21\u578b\u5f97\u5206\u4e0e\u7ed3\u6784\u504f\u597d\u53ca\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u901a\u7528\u6a21\u677f\uff0c\u5b83\u80fd\u591f\u7edf\u4e00\u5305\u62ec\u8d2a\u5a6a\u89e3\u7801\u3001Softmax\u91c7\u6837\u3001Top-K\u3001Top-P\u4ee5\u53caSparsemax\u98ce\u683c\u7a00\u758f\u6027\u5728\u5185\u7684\u591a\u79cd\u89e3\u7801\u7b56\u7565\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u57fa\u4e8e\u8fd9\u4e00\u6846\u67b6\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u540d\u4e3aBest-of-K (BoK) \u7684\u65b0\u89e3\u7801\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u9488\u5bf9\u591a\u6837\u672c\u6d41\u7a0b\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u7279\u522b\u662f\u81ea\u4e00\u81f4\u6027\u3001\u91cd\u6392\u5e8f\u548c\u9a8c\u8bc1\u8005\u9009\u62e9\u7b49\u65b9\u9762\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528BoK\u65b9\u6cd5\u53ef\u4ee5\u5728\u56fa\u5b9a\u7684K\u6837\u672c\u9884\u7b97\u5185\u63d0\u9ad8\u627e\u5230\u4f18\u8d28\u5907\u9009\u65b9\u6848\u7684\u6982\u7387\uff0c\u4ece\u800c\u6539\u5584\u4e86\u6574\u4f53\u6027\u80fd\u3002\u7279\u522b\u5730\uff0c\u5728Qwen2.5-Math-7B\u6a21\u578b\u4e0a\u5bf9MATH500\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u5f53\u91c7\u6837\u6e29\u5ea6\u8f83\u9ad8\u65f6\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e8618.6%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u89e3\u7801\u89c6\u4e3a\u4e00\u4e2a\u6709\u539f\u5219\u7684\u4f18\u5316\u5c42\uff0c\u672c\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u79cd\u7406\u89e3\u4e0d\u540c\u89e3\u7801\u6280\u672f\u5171\u901a\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u6846\u67b6\u8f7b\u677e\u521b\u5efa\u65b0\u7684\u89e3\u7801\u7b97\u6cd5\u3002\u6240\u63d0\u51fa\u7684Best-of-K\u65b9\u6cd5\u5728\u591a\u6837\u672c\u5e94\u7528\u573a\u666f\u4e2d\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.18297", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.18297", "abs": "https://arxiv.org/abs/2602.18297", "authors": ["Usman Anwar", "Tim Bakker", "Dana Kianfar", "Cristina Pinneri", "Christos Louizos"], "title": "Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory", "comment": "First two authors contributed equally", "summary": "Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u5206\u6790\u4e86\u601d\u7ef4\u94fe\u76d1\u63a7\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u6307\u51fa\u4e86\u5f71\u54cd\u5176\u6027\u80fd\u7684\u4e24\u5927\u8bef\u5dee\u6765\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u6539\u8fdb\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u76d1\u63a7\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8df5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u76d1\u63a7\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9047\u5230\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5982\u4f55\u66f4\u51c6\u786e\u5730\u68c0\u6d4b\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u5f0a\u884c\u4e3a\u7b49\u7279\u5b9a\u5c5e\u6027\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u5206\u6790\u6765\u63a2\u8ba8\u601d\u7ef4\u94fe\u4e0e\u8f93\u51fa\u4e4b\u95f4\u975e\u96f6\u4e92\u4fe1\u606f\u4f5c\u4e3a\u76d1\u63a7\u53ef\u884c\u6027\u7684\u5fc5\u8981\u4f46\u4e0d\u5145\u5206\u6761\u4ef6\uff1b\u8bc6\u522b\u51fa\u4fe1\u606f\u5dee\u8ddd\u548c\u5f15\u51fa\u9519\u8bef\u4e3a\u4e24\u5927\u8fd1\u4f3c\u8bef\u5dee\u6e90\uff1b\u63d0\u51fa\u76f4\u63a5\u5956\u52b1\u6a21\u578b\u4ea7\u751f\u6613\u4e8e\u76d1\u63a7\u7684\u601d\u7ef4\u94fe\u4ee5\u53ca\u6700\u5927\u5316\u8f93\u51fa\u4e0e\u601d\u7ef4\u94fe\u95f4\u6761\u4ef6\u4e92\u4fe1\u606f\u8fd9\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\u4ee5\u6539\u5584\u76d1\u63a7\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u4e0d\u540c\u73af\u5883\u4e0b\uff0c\u6240\u63d0\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u663e\u8457\u63d0\u9ad8\u76d1\u63a7\u51c6\u786e\u6027\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5373\u4f7f\u662f\u5728\u5bf9\u6297\u6027\u8bad\u7ec3\u6761\u4ef6\u4e0b\u601d\u7ef4\u94fe\u8d28\u91cf\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u5f53\u4efb\u52a1\u5956\u52b1\u5b9a\u4e49\u4e0d\u5b8c\u5168\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u5956\u52b1\u4f5c\u5f0a\u73b0\u8c61\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u8bad\u7ec3\u76ee\u6807\u53ef\u4ee5\u7cfb\u7edf\u5730\u63d0\u5347\u601d\u7ef4\u94fe\u76d1\u63a7\u80fd\u529b\uff0c\u8fd9\u5bf9\u4e8e\u786e\u4fdd\u57fa\u4e8eLLM\u7684\u5e94\u7528\u7a0b\u5e8f\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.18301", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18301", "abs": "https://arxiv.org/abs/2602.18301", "authors": ["Ivan Bondarenko", "Egor Palkin", "Fedor Tikunov"], "title": "On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction", "comment": null, "summary": "Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for \"imposing\" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5982\u4f55\u4ece\u4e24\u4e2a\u5b66\u4e60\u5230\u7684\u57fa\u7840token\u4e2d\u4e00\u6b21\u6027\u91cd\u5efa\u5927\u91cf\u6587\u672c\uff0c\u5e76\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u57fa\u7840token\u6240\u7f16\u7801\u7684\u4fe1\u606f\u4ee5\u53ca\u5b83\u4eec\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u3002\u901a\u8fc7\u5b9e\u9a8c\uff0c\u6587\u7ae0\u5206\u6790\u4e86\u8bed\u4e49\u548c\u53e5\u6cd5\u5185\u5bb9\u5728\u4e24\u4e2a\u57fa\u7840token\u4e2d\u7684\u5206\u79bb\u60c5\u51b5\u3001e-token\u7684\u7a33\u5b9a\u6027\u5c5e\u6027\u53ca\u5176\u5728\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6d4b\u8bd5\u4e86\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6848\u6765\u5f3a\u5236e-token\u5177\u6709\u8bed\u4e49\u7ed3\u6784\u3002\u7ed3\u679c\u8868\u660em-token\u6bd4e-token\u66f4\u5f3a\u70c8\u5730\u6355\u6349\u8bed\u4e49\u4fe1\u606f\uff1b\u57fa\u4e8e\u951a\u70b9\u7684\u7ea6\u675f\u4e0e\u91cd\u5efa\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6743\u8861\uff1b\u5173\u7cfb\u84b8\u998f\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u91cd\u5efa\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u5c06\u6279\u5904\u7406\u7ea7\u522b\u7684\u8bed\u4e49\u5173\u7cfb\u8f6c\u79fb\u5230\u57fa\u7840token\u7a7a\u95f4\u4e2d\uff0c\u8fd9\u4e3a\u672a\u6765\u975e\u81ea\u56de\u5f52seq2seq\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "motivation": "\u63a2\u7d22\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u5426\u4ee5\u5355\u6b21\u524d\u5411\u4f20\u9012\u7684\u65b9\u5f0f\u4ece\u5c11\u91cf\u5b66\u4e60\u5230\u7684\u57fa\u7840token\u4e2d\u91cd\u5efa\u5927\u91cf\u6587\u672c\uff0c\u4ece\u800c\u8d85\u8d8a\u4f20\u7edf\u7684\u81ea\u56de\u5f52\u8303\u5f0f\u3002\u7814\u7a76\u65e8\u5728\u7406\u89e3\u8fd9\u4e9b\u57fa\u7840token\u7f16\u7801\u4f55\u79cd\u7c7b\u578b\u7684\u4fe1\u606f\u4ee5\u53ca\u5b83\u4eec\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5982\u4f55\u8868\u73b0\u3002", "method": "\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u5305\u62ec\u5206\u79bb\u57fa\u7840token\u4e2d\u7684\u8bed\u4e49\u4e0e\u53e5\u6cd5\u5185\u5bb9\u3001\u5206\u6790e-token\u7684\u7a33\u5b9a\u6027\u7279\u5f81\u53ca\u53ef\u89c6\u5316\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u5bf9e-token\u7684\u5173\u6ce8\u6a21\u5f0f\u3002\u8fd8\u6d4b\u8bd5\u4e86\u4f7f\u7528\u6559\u5e08\u5d4c\u5165\u7684\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6cd5\u2014\u2014\u57fa\u4e8e\u951a\u70b9\u7684\u635f\u5931\u51fd\u6570\u548c\u5173\u7cfb\u84b8\u998f\u76ee\u6807\u51fd\u6570\u2014\u2014\u4ee5\u8003\u5bdf\u5982\u4f55\u5c06\u8bed\u4e49\u7ed3\u6784\u65bd\u52a0\u7ed9e-token\u3002", "result": "m-token\u76f8\u8f83\u4e8ee-token\u66f4\u80fd\u5f3a\u6709\u529b\u5730\u6355\u6349\u8bed\u4e49\u4fe1\u606f\uff1b\u5f53\u91c7\u7528\u57fa\u4e8e\u951a\u70b9\u7684\u7ea6\u675f\u65f6\uff0c\u867d\u7136\u80fd\u591f\u4fc3\u8fdbe-token\u643a\u5e26\u66f4\u591a\u8bed\u4e49\uff0c\u4f46\u540c\u65f6\u4f1a\u663e\u8457\u964d\u4f4e\u91cd\u5efa\u51c6\u786e\u6027\uff1b\u800c\u5173\u7cfb\u84b8\u998f\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u826f\u597d\u91cd\u5efa\u6548\u679c\u7684\u540c\u65f6\uff0c\u6210\u529f\u5730\u5c06\u5728\u6279\u6b21\u7ea7\u522b\u4e0a\u89c2\u5bdf\u5230\u7684\u8bed\u4e49\u5173\u8054\u6027\u8f6c\u79fb\u5230\u57fa\u7840token\u7684\u7a7a\u95f4\u5185\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u57fa\u7840token\u65bd\u52a0\u9002\u5f53\u7684\u7ea6\u675f\uff0c\u7279\u522b\u662f\u5229\u7528\u5173\u7cfb\u84b8\u998f\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u91cd\u5efa\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u589e\u5f3a\u5176\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002\u8fd9\u4e3a\u5f00\u53d1\u975e\u81ea\u56de\u5f52\u5e8f\u5217\u751f\u6210\u6a21\u578b\u5f00\u8f9f\u4e86\u4e00\u6761\u65b0\u7684\u9053\u8def\uff0c\u5176\u4e2d\u9884\u6d4b\u57fa\u7840token\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\u53ef\u80fd\u662f\u5b9e\u73b0\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u6587\u672c\u751f\u6210\u7684\u5173\u952e\u3002"}}
{"id": "2602.18308", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18308", "abs": "https://arxiv.org/abs/2602.18308", "authors": ["Biswa Sengupta", "Jinhua Wang", "Leo Brunswic"], "title": "JPmHC Dynamical Isometry via Orthogonal Hyper-Connections", "comment": null, "summary": "Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJPmHC\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5f15\u5165\u53ef\u8bad\u7ec3\u7684\u7ebf\u6027\u6df7\u5408\u5668\u6765\u66ff\u4ee3\u8eab\u4efd\u8df3\u8fc7\u8fde\u63a5\uff0c\u5e76\u660e\u786e\u63a7\u5236\u68af\u5ea6\u6761\u4ef6\uff0c\u89e3\u51b3\u4e86Hyper-Connections\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u3001\u6709\u9650\u7684\u53ef\u6269\u5c55\u6027\u548c\u589e\u52a0\u7684\u5185\u5b58\u5f00\u9500\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ea6\u675f\u6df7\u5408\u5668\u4e8e\u64cd\u4f5c\u8303\u6570\u6709\u754c\u7684\u6d41\u5f62\u4e0a\uff08\u5982\u53cc\u968f\u673a\u3001\u65af\u8482\u8d39\u5c14\u3001\u683c\u62c9\u65af\u66fc\uff09\uff0c\u9632\u6b62\u4e86\u68af\u5ea6\u95ee\u9898\u5e76\u589e\u5f3a\u4e86\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cJPmHC\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6536\u655b\u66f4\u5feb\u3001\u51c6\u786e\u7387\u66f4\u9ad8\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7684\u8fdb\u6b65\uff0c\u7279\u522b\u662fHyper-Connections (HC)\u7684\u51fa\u73b0\uff0c\u867d\u7136\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u540c\u65f6\u4e5f\u7834\u574f\u4e86\u6b8b\u5dee\u8fde\u63a5\u7684\u8eab\u4efd\u6620\u5c04\u5c5e\u6027\uff0c\u4ece\u800c\u5f15\u8d77\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\u6027\u53d7\u9650\u4ee5\u53ca\u5185\u5b58\u5f00\u9500\u589e\u52a0\u7b49\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aJPmHC\uff08Jacobian-spectrum Preserving manifold-constrained Hyper-Connections\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528n\u4e2a\u5e76\u884c\u6d41\u4e0a\u7684\u53ef\u8bad\u7ec3\u7ebf\u6027\u6df7\u5408\u5668\u4ee3\u66ff\u8eab\u4efd\u8df3\u8dc3\u8fde\u63a5\uff0c\u5e76\u663e\u5f0f\u5730\u63a7\u5236\u68af\u5ea6\u8c03\u8282\u3002\u901a\u8fc7\u5c06\u6df7\u5408\u5668M\u7ea6\u675f\u5728\u64cd\u4f5c\u6570\u8303\u6570\u8fb9\u754c\u6d41\u5f62\u4e0a\uff08\u4f8b\u5982\u53cc\u968f\u673a\u3001\u65af\u8482\u8d39\u5c14\u3001\u683c\u62c9\u65af\u66fc\uff09\uff0cJPmHC\u80fd\u591f\u907f\u514d\u68af\u5ea6\u5f02\u5e38\u5e76\u589e\u5f3a\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a(i) \u81ea\u7531\u6982\u7387\u5206\u6790\u9884\u6d4b\u7ed3\u6784\u5316\u8df3\u8dc3\u7684\u96c5\u53ef\u6bd4\u8c31\uff0c\u63d0\u4f9b\u7528\u4e8e\u6df7\u5408\u5668\u9009\u62e9\u7684\u8bbe\u8ba1\u89c4\u5219\uff1b(ii) \u7528\u4e8e\u56fa\u5b9a\u70b9\u6295\u5f71\u7684\u8bb0\u5fc6\u6548\u7387\u9690\u5f0f\u5fae\u5206\uff0c\u51cf\u5c11\u6fc0\u6d3b\u5185\u5b58\u548c\u540c\u6b65\u5f00\u9500\uff1b(iii) \u901a\u8fc7Cayley\u53d8\u6362\u5b9e\u73b0\u7684\u65af\u8482\u8d39\u5c14\u7ea6\u675f\u6df7\u5408\u5668\uff0c\u786e\u4fdd\u6b63\u4ea4\u6027\u800c\u65e0\u9700\u540e\u5904\u7406\u5f52\u4e00\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u5728ARC-AGI\u4e0a\uff0c\u4e0e\u53cc\u968f\u673a\u57fa\u7ebf\u76f8\u6bd4\uff0cJPmHC\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3001\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u4ee5\u53ca\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u4f5c\u4e3aHC\u7684\u4e00\u79cd\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u6269\u5c55\uff0cJPmHC\u4fc3\u8fdb\u4e86\u9891\u8c31\u611f\u77e5\u3001\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u53d1\u5c55\uff0c\u540c\u65f6\u5bf9\u62d3\u6251\u67b6\u6784\u8bbe\u8ba1\u548c\u57fa\u7840\u6a21\u578b\u6f14\u53d8\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2602.18348", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18348", "abs": "https://arxiv.org/abs/2602.18348", "authors": ["Matheus Camilo da Silva", "Leonardo Arrighi", "Ana Carolina Lorena", "Sylvio Barbon Junior"], "title": "Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering", "comment": null, "summary": "AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u52a8\u805a\u7c7b\u65b9\u6cd5\u4e2d\u5143\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u56de\u987e22\u79cd\u73b0\u6709\u65b9\u6cd5\u5e76\u5206\u7c7b\u5176\u5143\u7279\u5f81\uff0c\u8fd0\u7528\u5168\u5c40\u548c\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u6280\u672f\u8bc4\u4f30\u5143\u7279\u5f81\u7684\u91cd\u8981\u6027\u53ca\u7279\u5b9a\u805a\u7c7b\u51b3\u7b56\uff0c\u65e8\u5728\u4e3a\u65e0\u76d1\u7763\u5b66\u4e60\u81ea\u52a8\u5316\u63d0\u4f9b\u66f4\u900f\u660e\u7684\u51b3\u7b56\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u805a\u7c7b\u65b9\u6cd5\u867d\u7136\u8868\u73b0\u826f\u597d\uff0c\u4f46\u63a8\u8350\u7ed3\u679c\u96be\u4ee5\u89e3\u91ca\uff1a\u6570\u636e\u96c6\u5143\u7279\u5f81\u5bf9\u7b97\u6cd5\u9009\u62e9\u4e0e\u8d85\u53c2\u6570\u8bbe\u5b9a\u7684\u5f71\u54cd\u4e0d\u660e\u786e\uff0c\u9650\u5236\u4e86\u53ef\u9760\u6027\u3001\u504f\u501a\u8bca\u65ad\u4ee5\u53ca\u6709\u6548\u7684\u5143\u7279\u5f81\u5de5\u7a0b\u80fd\u529b\u3002", "method": "1. \u56de\u987e\u5206\u6790\u73b0\u6709\u768422\u79cd\u81ea\u52a8\u805a\u7c7b\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5143\u7279\u5f81\u5f52\u7c7b\u5230\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u5206\u7c7b\u4f53\u7cfb\u4e2d\u3002\n2. \u5e94\u7528\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff08\u5982\u51b3\u7b56\u8c13\u8bcd\u56fe\uff09\u6765\u8bc4\u4f30\u9009\u5b9a\u6846\u67b6\u5185\u5143\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u91cd\u8981\u6027\u3002\n3. \u5229\u7528\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u4f8b\u5982SHAP\uff08SHapley Additive exPlanations\uff09\u5206\u6790\u5177\u4f53\u7684\u805a\u7c7b\u51b3\u5b9a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63ed\u793a\u4e86\u5143\u7279\u5f81\u76f8\u5173\u6027\u7684\u4e00\u81f4\u6a21\u5f0f\uff0c\u8bc6\u522b\u51fa\u73b0\u6709\u5143\u5b66\u4e60\u7b56\u7565\u4e2d\u7684\u7ed3\u6784\u6027\u5f31\u70b9\u53ef\u80fd\u5bfc\u81f4\u5efa\u8bae\u504f\u5dee\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u66f4\u5177\u89e3\u91ca\u6027\u7684\u81ea\u52a8\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63d0\u9ad8\u65e0\u76d1\u7763\u5b66\u4e60\u81ea\u52a8\u5316\u8fc7\u7a0b\u4e2d\u7684\u51b3\u7b56\u900f\u660e\u5ea6\u5960\u5b9a\u4e86\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2602.18384", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18384", "abs": "https://arxiv.org/abs/2602.18384", "authors": ["Fotios Zantalis", "Evangelos Zervas", "Grigorios Koulouras"], "title": "FedZMG: Efficient Client-Side Optimization in Federated Learning", "comment": null, "summary": "Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the \"intensity\" or \"bias\" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5FedZMG\uff0c\u901a\u8fc7\u5c06\u5c40\u90e8\u68af\u5ea6\u6295\u5f71\u5230\u96f6\u5747\u503c\u8d85\u5e73\u9762\u4e0a\u6765\u89e3\u51b3\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u901a\u4fe1\u6216\u8c03\u6574\u8d85\u53c2\u6570\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86FedZMG\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u6761\u4ef6\u4e0b\u76f8\u8f83\u4e8eFedAvg\u548cFedAdam\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u6700\u7ec8\u9a8c\u8bc1\u51c6\u786e\u7387\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5141\u8bb8\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u8bad\u7ec3\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002\u7136\u800c\uff0c\u5ba2\u6237\u7aef\u901a\u5e38\u6301\u6709\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u7684\u6570\u636e\uff0c\u8fd9\u5f80\u5f80\u5bfc\u81f4\u5ba2\u6237\u7aef\u6f02\u79fb\uff0c\u4ece\u800c\u964d\u4f4e\u6536\u655b\u901f\u5ea6\u548c\u6a21\u578b\u6027\u80fd\u3002\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u4f18\u5316\u5668\u6765\u7f13\u89e3\u8fd9\u4e9b\u5f71\u54cd\uff0c\u4f46\u5b83\u4eec\u7ecf\u5e38\u5f15\u5165\u8ba1\u7b97\u590d\u6742\u6027\u6216\u901a\u4fe1\u5f00\u9500\uff0c\u8fd9\u5bf9\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u73af\u5883\u6765\u8bf4\u662f\u4e0d\u5408\u9002\u7684\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86Federated Zero Mean Gradients (FedZMG)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u3001\u65e0\u53c2\u6570\u7684\u5ba2\u6237\u7aef\u4fa7\u4f18\u5316\u7b97\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u5316\u89c4\u8303\u4f18\u5316\u7a7a\u95f4\u6765\u89e3\u51b3\u5ba2\u6237\u7aef\u6f02\u79fb\u95ee\u9898\u3002FedZMG\u63a8\u8fdb\u4e86\u68af\u5ea6\u4e2d\u5fc3\u5316\u7684\u7406\u5ff5\uff0c\u5b83\u628a\u672c\u5730\u68af\u5ea6\u6295\u5c04\u5230\u4e00\u4e2a\u96f6\u5747\u503c\u8d85\u5e73\u9762\u4e0a\uff0c\u6709\u6548\u5730\u4e2d\u548c\u4e86\u5f02\u6784\u6570\u636e\u5206\u5e03\u4e2d\u7684'\u5f3a\u5ea6'\u6216'\u504f\u7f6e'\u504f\u79fb\uff0c\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u901a\u4fe1\u6216\u8d85\u53c2\u6570\u8c03\u8282\u3002", "result": "\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u4e86FedZMG\u53ef\u4ee5\u51cf\u5c11\u6709\u6548\u68af\u5ea6\u65b9\u5dee\uff0c\u5e76\u4fdd\u8bc1\u6bd4\u6807\u51c6FedAvg\u66f4\u7d27\u81f4\u7684\u6536\u655b\u754c\u9650\u3002\u5728EMNIST\u3001CIFAR100\u548cShakespeare\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u4e0e\u57fa\u51c6FedAvg\u548c\u81ea\u9002\u5e94\u4f18\u5316\u5668FedAdam\u76f8\u6bd4\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5ea6\u975eIID\u8bbe\u7f6e\u4e0b\uff0cFedZMG\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u9a8c\u8bc1\u51c6\u786e\u6027\u3002", "conclusion": "FedZMG\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u975eIID\u6570\u636e\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u901a\u4fe1\u8d1f\u62c5\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2602.18435", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18435", "abs": "https://arxiv.org/abs/2602.18435", "authors": ["Aggelos Semoglou", "John Pavlopoulos"], "title": "Assigning Confidence: K-partition Ensembles", "comment": "31 pages including appendix", "summary": "Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aCAKE\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u96c6\u5408\u805a\u7c7b\u6765\u8bc4\u4f30\u6bcf\u4e2a\u6570\u636e\u70b9\u7684\u5206\u914d\u7a33\u5b9a\u6027\u53ca\u5c40\u90e8\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u6700\u7ec8\u7ed9\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684[0,1]\u5f97\u5206\uff0c\u7528\u4ee5\u6307\u793a\u805a\u7c7b\u4e2d\u4e2a\u4f53\u5206\u914d\u7684\u7f6e\u4fe1\u5ea6\u3002\u5b9e\u9a8c\u8868\u660eCAKE\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6a21\u68f1\u4e24\u53ef\u7684\u6570\u636e\u70b9\u4ee5\u53ca\u7a33\u5b9a\u7684\u4e2d\u5fc3\u6210\u5458\uff0c\u5e76\u63d0\u4f9b\u53ef\u7528\u4e8e\u63d0\u9ad8\u805a\u7c7b\u8d28\u91cf\u7684\u4fe1\u5fc3\u6392\u540d\u3002", "motivation": "\u805a\u7c7b\u5e7f\u6cdb\u7528\u4e8e\u65e0\u76d1\u7763\u7ed3\u6784\u53d1\u73b0\uff0c\u4f46\u5bf9\u4e8e\u5355\u4e2a\u5206\u914d\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u9650\u7684\u6d1e\u5bdf\u529b\u3002\u5168\u5c40\u8d28\u91cf\u6307\u6807\u5982\u6536\u655b\u884c\u4e3a\u6216\u76ee\u6807\u503c\u5e76\u4e0d\u80fd\u53cd\u6620\u7279\u5b9a\u5b9e\u4f8b\u662f\u5426\u88ab\u81ea\u4fe1\u5730\u5206\u914d\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u5bf9\u521d\u59cb\u5316\u654f\u611f\u7684\u7b97\u6cd5\u5982k-means\u3002\u8fd9\u79cd\u5206\u914d\u7ea7\u522b\u7684\u4e0d\u7a33\u5b9a\u6027\u4f1a\u635f\u5bb3\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002\u867d\u7136\u96c6\u6210\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u805a\u5408\u591a\u6b21\u8fd0\u884c\u6765\u6539\u5584\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u5de5\u5177\u4ee5\u7ed3\u5408\u8de8\u8fd0\u884c\u4e00\u81f4\u6027\u548c\u4ece\u5b66\u4e60\u5230\u7684\u805a\u7c7b\u7ed3\u6784\u83b7\u5f97\u7684\u51e0\u4f55\u652f\u6301\u7684\u65b9\u5f0f\u91cf\u5316\u9010\u70b9\u7f6e\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86CAKE\uff08\u901a\u8fc7K-\u5206\u533a\u96c6\u6210\u8fdb\u884c\u5206\u914d\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u805a\u7c7b\u96c6\u6210\u8ba1\u7b97\u4e24\u4e2a\u4e92\u8865\u7edf\u8ba1\u91cf\uff1a\u5206\u914d\u7a33\u5b9a\u6027\u548c\u5c40\u90e8\u51e0\u4f55\u62df\u5408\u7684\u4e00\u81f4\u6027\u3002\u8fd9\u4e9b\u7edf\u8ba1\u91cf\u88ab\u5408\u5e76\u6210\u4e00\u4e2a\u4ecb\u4e8e[0,1]\u4e4b\u95f4\u7684\u5355\u4e00\u53ef\u89e3\u91ca\u5206\u6570\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff0c\u5728\u566a\u58f0\u5b58\u5728\u7684\u60c5\u51b5\u4e0bCAKE\u4ecd\u7136\u6709\u6548\uff0c\u5e76\u4e14\u80fd\u591f\u533a\u5206\u7a33\u5b9a\u4e0e\u4e0d\u7a33\u5b9a\u70b9\u3002\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCAKE\u80fd\u591f\u6709\u6548\u5730\u7a81\u51fa\u663e\u793a\u6a21\u68f1\u4e24\u53ef\u7684\u70b9\u548c\u7a33\u5b9a\u7684\u6838\u6210\u5458\uff0c\u6240\u63d0\u4f9b\u7684\u7f6e\u4fe1\u5ea6\u6392\u540d\u53ef\u4ee5\u6307\u5bfc\u8fc7\u6ee4\u6216\u4f18\u5148\u7ea7\u6392\u5e8f\u4ee5\u63d0\u9ad8\u805a\u7c7b\u8d28\u91cf\u3002", "conclusion": "CAKE\u4e3a\u8bc4\u4f30\u805a\u7c7b\u4efb\u52a1\u4e2d\u4e2a\u4f53\u5206\u914d\u7684\u7f6e\u4fe1\u6c34\u5e73\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u9014\u5f84\uff0c\u5b83\u4e0d\u4ec5\u8003\u8651\u4e86\u8de8\u4e0d\u540c\u8fd0\u884c\u95f4\u7684\u5206\u914d\u7a33\u5b9a\u6027\uff0c\u8fd8\u7ed3\u5408\u4e86\u5c40\u90e8\u51e0\u4f55\u7279\u6027\u7684\u4e00\u81f4\u6027\u3002\u8fd9\u4e00\u6846\u67b6\u6709\u52a9\u4e8e\u8bc6\u522b\u51fa\u90a3\u4e9b\u5728\u805a\u7c7b\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5f15\u8d77\u4e0d\u786e\u5b9a\u6027\u7684\u70b9\uff0c\u5e76\u4e3a\u63d0\u5347\u805a\u7c7b\u7ed3\u679c\u7684\u6574\u4f53\u8d28\u91cf\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002"}}
