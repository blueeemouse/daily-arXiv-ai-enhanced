{"id": "2601.04523", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.04523", "abs": "https://arxiv.org/abs/2601.04523", "authors": ["Ajay Singh", "Nikos Metaxakis", "Panagiota Fatourou"], "title": "Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks", "comment": "extended version of paper in PPoPP 2026", "summary": "We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u963b\u585e\u7ebf\u6027\u5316\u5806\u6808\u5b9e\u73b0\uff0c\u5229\u7528\u5206\u7247\u548c\u53d6&\u589e\u64cd\u4f5c\u8fbe\u5230\u4e86\u6bd4\u73b0\u6709\u5e76\u53d1\u5806\u6808\u66f4\u597d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u8be5\u5806\u6808\u5b9e\u73b0\u7684\u6027\u80fd\u4f18\u4e8e\u6240\u6709\u73b0\u6709\u7684\u5e76\u53d1\u5806\u6808\u9ad8\u8fbe2\u500d\uff0c\u5e76\u4e14\u5728\u652f\u6301\u5927\u91cf\u7ebf\u7a0b\u548c\u9ad8\u7ade\u4e89\u573a\u666f\u4e2d\u7279\u522b\u6709\u6548\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5e76\u53d1\u5806\u6808\u5728\u591a\u7ebf\u7a0b\u73af\u5883\u4e0b\u7684\u6027\u80fd\u4ee5\u53ca\u964d\u4f4e\u8bbf\u95ee\u5171\u4eab\u5806\u6808\u65f6\u7684\u7ade\u4e89\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u6d88\u9664\u673a\u5236\u548c\u4e00\u79cd\u65b0\u7684\u7ec4\u5408\u65b9\u6cd5\u6765\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u5806\u6808\u3002\u4f7f\u7528\u4e86\u5206\u7247\uff08sharding\uff09\u548c\u53d6&\u589e\uff08fetch&increment\uff09\u6280\u672f\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5806\u6808\u5b9e\u73b0\u5728\u5927\u591a\u6570\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u6bd4\u73b0\u6709\u5e76\u53d1\u5806\u6808\u6027\u80fd\u9ad8\u51fa\u6700\u591a2\u500d\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5927\u91cf\u7ebf\u7a0b\u548c\u652f\u6301\u9ad8\u7ade\u4e89\u60c5\u5f62\u65f6\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u65b0\u6d88\u9664\u673a\u5236\u4e0e\u7ec4\u5408\u65b9\u6cd5\u8bbe\u8ba1\u7684\u5806\u6808\u80fd\u591f\u663e\u8457\u63d0\u5347\u5e76\u53d1\u6267\u884c\u6548\u7387\u5e76\u51cf\u5c11\u8d44\u6e90\u7ade\u4e89\u3002"}}
{"id": "2601.04432", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.04432", "abs": "https://arxiv.org/abs/2601.04432", "authors": ["Harshavardhan Kamarthi", "Harshil Shah", "Henry Milner", "Sayan Sinha", "Yan Li", "B. Aditya Prakash", "Vyas Sekar"], "title": "AHA: Scalable Alternative History Analysis for Operational Timeseries Applications", "comment": "To Appear at KDD 2026", "summary": "Many operational systems collect high-dimensional timeseries data about users/systems on key performance metrics. For instance, ISPs, content distribution networks, and video delivery services collect quality of experience metrics for user sessions associated with metadata (e.g., location, device, ISP). Over such historical data, operators and data analysts often need to run retrospective analysis; e.g., analyze anomaly detection algorithms, experiment with different configurations for alerts, evaluate new algorithms, and so on. We refer to this class of workloads as alternative history analysis for operational datasets. We show that in such settings, traditional data processing solutions (e.g., data warehouses, sampling, sketching, big-data systems) either pose high operational costs or do not guarantee accurate replay. We design and implement a system, called AHA (Alternative History Analytics), that overcomes both challenges to provide cost efficiency and fidelity for high-dimensional data. The design of AHA is based on analytical and empirical insights about such workloads: 1) the decomposability of underlying statistics; 2) sparsity in terms of active number of subpopulations over attribute-value combinations; and 3) efficiency structure of aggregation operations in modern analytics databases. Using multiple real-world datasets and as well as case-studies on production pipelines at a large video analytics company, we show that AHA provides 100% accuracy for a broad range of downstream tasks and up to 85x lower total cost of ownership (i.e., compute + storage) compared to conventional methods.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAHA\uff08Alternative History Analytics\uff09\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u9488\u5bf9\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u548c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5229\u7528\u7edf\u8ba1\u5b66\u7684\u53ef\u5206\u89e3\u6027\u3001\u5b50\u7fa4\u4f53\u6d3b\u8dc3\u6570\u91cf\u7684\u7a00\u758f\u6027\u4ee5\u53ca\u73b0\u4ee3\u5206\u6790\u6570\u636e\u5e93\u4e2d\u805a\u5408\u64cd\u4f5c\u7684\u6548\u7387\u7ed3\u6784\uff0cAHA\u80fd\u591f\u4e3a\u5e7f\u6cdb\u7684\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b100%\u7684\u51c6\u786e\u5ea6\uff0c\u5e76\u4e14\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\u603b\u62e5\u6709\u6210\u672c\u964d\u4f4e\u4e86\u9ad8\u8fbe85\u500d\u3002", "motivation": "\u5728\u8bb8\u591a\u8fd0\u8425\u7cfb\u7edf\u4e2d\uff0c\u6536\u96c6\u5173\u4e8e\u7528\u6237/\u7cfb\u7edf\u7684\u5173\u952e\u6027\u80fd\u6307\u6807\u7684\u9ad8\u7ef4\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5df2\u6210\u4e3a\u5e38\u6001\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u8fd9\u4e9b\u5386\u53f2\u6570\u636e\u6267\u884c\u56de\u987e\u6027\u5206\u6790\u65f6\uff0c\u4f20\u7edf\u7684\u6570\u636e\u5904\u7406\u65b9\u6848\u8981\u4e48\u6210\u672c\u9ad8\u6602\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u56de\u653e\u7684\u51c6\u786e\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6709\u6548\u5904\u7406\u6b64\u7c7b\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aAHA\u7684\u65b0\u7cfb\u7edf\uff0c\u5b83\u57fa\u4e8e\u5bf9\u8fd9\u7c7b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u6790\u6027\u548c\u5b9e\u8bc1\u6d1e\u5bdf\uff1a1) \u5e95\u5c42\u7edf\u8ba1\u91cf\u7684\u53ef\u5206\u89e3\u6027\uff1b2) \u5728\u5c5e\u6027\u503c\u7ec4\u5408\u4e0a\u6d3b\u8dc3\u5b50\u7fa4\u4f53\u6570\u91cf\u4e0a\u7684\u7a00\u758f\u6027\uff1b3) \u73b0\u4ee3\u5206\u6790\u6570\u636e\u5e93\u4e2d\u805a\u5408\u64cd\u4f5c\u7684\u6548\u7387\u7ed3\u6784\u3002", "result": "\u4f7f\u7528\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u53ca\u4e00\u5bb6\u5927\u578b\u89c6\u9891\u5206\u6790\u516c\u53f8\u7684\u751f\u4ea7\u7ba1\u9053\u6848\u4f8b\u7814\u7a76\u663e\u793a\uff0cAHA\u80fd\u591f\u4e3a\u5e7f\u6cdb\u8303\u56f4\u5185\u7684\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b100%\u7684\u51c6\u786e\u5ea6\uff0c\u5e76\u4e14\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\u603b\u62e5\u6709\u6210\u672c\uff08\u5373\u8ba1\u7b97+\u5b58\u50a8\uff09\u6700\u9ad8\u53ef\u964d\u4f4e85\u500d\u3002", "conclusion": "AHA\u7cfb\u7edf\u6709\u6548\u5730\u89e3\u51b3\u4e86\u9ad8\u7ef4\u8fd0\u8425\u6570\u636e\u96c6\u4e2d\u7684\u66ff\u4ee3\u5386\u53f2\u5206\u6790\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u6210\u672c\u3002"}}
{"id": "2601.04252", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04252", "abs": "https://arxiv.org/abs/2601.04252", "authors": ["Daoan Zhang", "Shuo Zhang", "Zijian Jin", "Jiebo Luo", "Shengyu Fu", "Elsie Nallipogu"], "title": "Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review", "comment": null, "summary": "Pull request (PR) review is essential for ensuring software quality, yet automating this task remains challenging due to noisy supervision, limited contextual understanding, and inadequate evaluation metrics. We present Sphinx, a unified framework for LLM-based PR review that addresses these limitations through three key components: (1) a structured data generation pipeline that produces context-rich, semantically grounded review comments by comparing pseudo-modified and merged code; (2) a checklist-based evaluation benchmark that assesses review quality based on structured coverage of actionable verification points, moving beyond surface-level metrics like BLEU; and (3) Checklist Reward Policy Optimization (CRPO), a novel training paradigm that uses rule-based, interpretable rewards to align model behavior with real-world review practices. Extensive experiments show that models trained with Sphinx achieve state-of-the-art performance on review completeness and precision, outperforming both proprietary and open-source baselines by up to 40\\% in checklist coverage. Together, Sphinx enables the development of PR review models that are not only fluent but also context-aware, technically precise, and practically deployable in real-world development workflows. The data will be released after review.", "AI": {"tldr": "Sphinx\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u7ba1\u9053\u3001\u57fa\u4e8e\u6e05\u5355\u7684\u8bc4\u4f30\u57fa\u51c6\u4ee5\u53caChecklist Reward Policy Optimization\uff08CRPO\uff09\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u62c9\u53d6\u8bf7\u6c42\u5ba1\u67e5\u81ea\u52a8\u5316\u8fc7\u7a0b\u4e2d\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u548c\u6280\u672f\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u62c9\u53d6\u8bf7\u6c42(PR)\u5ba1\u67e5\u81ea\u52a8\u5316\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u5305\u62ec\u566a\u58f0\u76d1\u7763\u3001\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u4ee5\u53ca\u4e0d\u8db3\u7684\u8bc4\u4f30\u6307\u6807\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u63d0\u9ad8\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\u6548\u7387\uff0c\u63d0\u51fa\u4e86Sphinx\u8fd9\u4e00\u7edf\u4e00\u6846\u67b6\u3002", "method": "Sphinx\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1. \u4e00\u79cd\u80fd\u591f\u751f\u6210\u5bcc\u542b\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u8bed\u4e49\u57fa\u7840\u8bc4\u8bba\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff1b2. \u57fa\u4e8e\u6e05\u5355\u7684\u8bc4\u4ef7\u6807\u51c6\uff0c\u8be5\u6807\u51c6\u4f9d\u636e\u53ef\u64cd\u4f5c\u9a8c\u8bc1\u70b9\u7684\u7ed3\u6784\u5316\u8986\u76d6\u7a0b\u5ea6\u6765\u8861\u91cf\u5ba1\u67e5\u8d28\u91cf\uff1b3. Checklist Reward Policy Optimization (CRPO)\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u8303\u5f0f\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u53ef\u89e3\u91ca\u5956\u52b1\u6765\u4f7f\u6a21\u578b\u884c\u4e3a\u4e0e\u5b9e\u9645\u5ba1\u67e5\u5b9e\u8df5\u76f8\u4e00\u81f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528Sphinx\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5ba1\u67e5\u5b8c\u6574\u6027\u548c\u7cbe\u786e\u5ea6\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u68c0\u67e5\u8868\u8986\u76d6\u7387\u4e0a\u6bd4\u4e13\u6709\u548c\u5f00\u6e90\u57fa\u7ebf\u9ad8\u51fa\u9ad8\u8fbe40%\u3002", "conclusion": "Sphinx\u4e0d\u4ec5\u63d0\u9ad8\u4e86PR\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\u7684\u8bed\u8a00\u6d41\u7545\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u5176\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3001\u6280\u672f\u51c6\u786e\u6027\uff0c\u5e76\u4f7f\u5176\u80fd\u591f\u5728\u5b9e\u9645\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u5f97\u5230\u5e94\u7528\u3002"}}
{"id": "2601.04291", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04291", "abs": "https://arxiv.org/abs/2601.04291", "authors": ["Minglei Yin", "Chuanbo Hu", "Bin Liu", "Neil Zhenqiang Gong", "Yanfang", "Ye", "Xin Li"], "title": "Correct and Weight: A Simple Yet Effective Loss for Implicit Feedback Recommendation", "comment": "arXiv admin note: text overlap with arXiv:2508.05673 by other authors", "summary": "Learning from implicit feedback has become the standard paradigm for modern recommender systems. However, this setting is fraught with the persistent challenge of false negatives, where unobserved user-item interactions are not necessarily indicative of negative preference. To address this issue, this paper introduces a novel and principled loss function, named Corrected and Weighted (CW) loss, that systematically corrects for the impact of false negatives within the training objective. Our approach integrates two key techniques. First, inspired by Positive-Unlabeled learning, we debias the negative sampling process by re-calibrating the assumed negative distribution. By theoretically approximating the true negative distribution (p-) using the observable general data distribution (p) and the positive interaction distribution (p^+), our method provides a more accurate estimate of the likelihood that a sampled unlabeled item is truly negative. Second, we introduce a dynamic re-weighting mechanism that modulates the importance of each negative instance based on the model's current prediction. This scheme encourages the model to enforce a larger ranking margin between positive items and confidently predicted (i.e., easy) negative items, while simultaneously down-weighting the penalty on uncertain negatives that have a higher probability of being false negatives. A key advantage of our approach is its elegance and efficiency; it requires no complex modifications to the data sampling process or significant computational overhead, making it readily applicable to a wide array of existing recommendation models. Extensive experiments conducted on four large-scale, sparse benchmark datasets demonstrate the superiority of our proposed loss. The results show that our method consistently and significantly outperforms a suite of state-of-the-art loss functions across multiple ranking-oriented metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u2014\u2014\u6821\u6b63\u52a0\u6743(CW)\u635f\u5931\uff0c\u65e8\u5728\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u9690\u5f0f\u53cd\u9988\u5b66\u4e60\u65f6\u5b58\u5728\u7684\u5047\u9634\u6027\u95ee\u9898\u3002\u901a\u8fc7\u91cd\u65b0\u6821\u51c6\u5047\u8bbe\u7684\u8d1f\u5206\u5e03\u5e76\u5f15\u5165\u52a8\u6001\u91cd\u52a0\u6743\u673a\u5236\u6765\u8c03\u6574\u6bcf\u4e2a\u8d1f\u6837\u672c\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u533a\u5206\u6b63\u8d1f\u6837\u672c\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6392\u540d\u5bfc\u5411\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4ece\u9690\u5f0f\u53cd\u9988\u4e2d\u5b66\u4e60\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u9762\u4e34\u4e00\u4e2a\u6301\u7eed\u7684\u6311\u6218\uff1a\u672a\u89c2\u5bdf\u5230\u7684\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u5e76\u4e0d\u4e00\u5b9a\u8868\u793a\u8d1f\u9762\u504f\u597d\uff0c\u5373\u5b58\u5728\u5047\u9634\u6027\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u6709\u539f\u5219\u7684\u635f\u5931\u51fd\u6570\u3002", "method": "1. \u91c7\u7528\u7c7b\u4f3c\u4e8e\u6b63\u4f8b-\u672a\u6807\u8bb0\uff08Positive-Unlabeled\uff09\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u8fd1\u4f3c\u771f\u6b63\u7684\u8d1f\u5206\u5e03\u3002\n2. \u5f15\u5165\u4e00\u79cd\u52a8\u6001\u91cd\u52a0\u6743\u673a\u5236\uff0c\u6839\u636e\u6a21\u578b\u5f53\u524d\u9884\u6d4b\u8c03\u6574\u6bcf\u4e2a\u8d1f\u5b9e\u4f8b\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u9f13\u52b1\u6a21\u578b\u5bf9\u6b63\u9879\u548c\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\uff08\u5bb9\u6613\uff09\u7684\u8d1f\u9879\u4e4b\u95f4\u65bd\u52a0\u66f4\u5927\u7684\u6392\u5e8f\u95f4\u9694\uff0c\u5e76\u540c\u65f6\u964d\u4f4e\u5bf9\u53ef\u80fd\u4e3a\u5047\u9634\u6027\u7684\u4e0d\u786e\u5b9a\u8d1f\u9879\u7684\u60e9\u7f5a\u3002", "result": "\u901a\u8fc7\u5bf9\u56db\u4e2a\u5927\u89c4\u6a21\u7a00\u758f\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u5728\u591a\u4e2a\u9762\u5411\u6392\u540d\u7684\u5ea6\u91cf\u6807\u51c6\u4e0a\u4e00\u81f4\u4e14\u663e\u8457\u5730\u4f18\u4e8e\u4e00\u7cfb\u5217\u6700\u5148\u8fdb\u7684\u635f\u5931\u51fd\u6570\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6821\u6b63\u52a0\u6743(CW)\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u8350\u7cfb\u7edf\u4e2d\u7531\u4e8e\u5047\u9634\u6027\u5e26\u6765\u7684\u8bad\u7ec3\u76ee\u6807\u504f\u5dee\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u800c\u4e14\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u63a8\u8350\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u590d\u6742\u7684\u6570\u636e\u91c7\u6837\u8fc7\u7a0b\u4fee\u6539\u6216\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.04199", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04199", "abs": "https://arxiv.org/abs/2601.04199", "authors": ["Jiale Zhao", "Xing Mou", "Jinlin Wu", "Hongyuan Yu", "Mingrui Sun", "Yang Shi", "Xuanwu Yin", "Zhen Chen", "Zhen Lei", "Yaohua Wang"], "title": "The Forgotten Shield: Safety Grafting in Parameter-Space for Medical MLLMs", "comment": null, "summary": "Medical Multimodal Large Language Models (Medical MLLMs) have achieved remarkable progress in specialized medical tasks; however, research into their safety has lagged, posing potential risks for real-world deployment. In this paper, we first establish a multidimensional evaluation framework to systematically benchmark the safety of current SOTA Medical MLLMs. Our empirical analysis reveals pervasive vulnerabilities across both general and medical-specific safety dimensions in existing models, particularly highlighting their fragility against cross-modality jailbreak attacks. Furthermore, we find that the medical fine-tuning process frequently induces catastrophic forgetting of the model's original safety alignment. To address this challenge, we propose a novel \"Parameter-Space Intervention\" approach for efficient safety re-alignment. This method extracts intrinsic safety knowledge representations from original base models and concurrently injects them into the target model during the construction of medical capabilities. Additionally, we design a fine-grained parameter search algorithm to achieve an optimal trade-off between safety and medical performance. Experimental results demonstrate that our approach significantly bolsters the safety guardrails of Medical MLLMs without relying on additional domain-specific safety data, while minimizing degradation to core medical performance.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\u6765\u7cfb\u7edf\u5730\u8861\u91cf\u5f53\u524d\u6700\u5148\u8fdb\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u4e00\u822c\u548c\u7279\u5b9a\u533b\u5b66\u5b89\u5168\u7ef4\u5ea6\u4e0a\u666e\u904d\u5b58\u5728\u8106\u5f31\u6027\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\"\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\"\u65b9\u6cd5\uff0c\u5728\u4e0d\u4f9d\u8d56\u989d\u5916\u9886\u57df\u7279\u5b9a\u5b89\u5168\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u589e\u5f3a\u4e86\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5bf9\u6838\u5fc3\u533b\u5b66\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u533b\u7597\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5b89\u5168\u6027\u7814\u7a76\u6ede\u540e\uff0c\u7ed9\u5b9e\u9645\u90e8\u7f72\u5e26\u6765\u4e86\u6f5c\u5728\u98ce\u9669\u3002\u7279\u522b\u6307\u51fa\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u8de8\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u7684\u8106\u5f31\u6027\u4ee5\u53ca\u533b\u5b66\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bfc\u81f4\u7684\u539f\u59cb\u5b89\u5168\u5bf9\u9f50\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "method": "\u9996\u5148\u5efa\u7acb\u4e00\u4e2a\u591a\u7ef4\u5ea6\u8bc4\u4ef7\u4f53\u7cfb\u5168\u9762\u8bc4\u6d4b\u5f53\u524d\u6700\u4f18\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8868\u73b0\uff1b\u63a5\u7740\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u201c\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u201d\u65b9\u6cd5\uff0c\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u63d0\u53d6\u5185\u5728\u5b89\u5168\u77e5\u8bc6\u8868\u793a\uff0c\u5e76\u5728\u5f00\u53d1\u533b\u5b66\u529f\u80fd\u65f6\u5c06\u5176\u6ce8\u5165\u76ee\u6807\u6a21\u578b\uff1b\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7cbe\u7ec6\u53c2\u6570\u641c\u7d22\u7b97\u6cd5\u4ee5\u5bfb\u627e\u5b89\u5168\u4e0e\u533b\u5b66\u6027\u80fd\u4e4b\u95f4\u7684\u6700\u4f73\u5e73\u8861\u70b9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u52a0\u5f3a\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u9632\u7ebf\uff0c\u65e0\u9700\u4f9d\u8d56\u66f4\u591a\u9886\u57df\u7279\u6709\u7684\u5b89\u5168\u8d44\u6599\uff0c\u540c\u65f6\u6700\u5927\u7a0b\u5ea6\u5730\u51cf\u5c11\u4e86\u5bf9\u4e3b\u8981\u533b\u5b66\u6548\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u53c2\u6570\u7a7a\u95f4\u5e72\u9884\u624b\u6bb5\u53ca\u4f18\u5316\u53c2\u6570\u641c\u7d22\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u533b\u5b66\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u6709\u6548\u63d0\u5347\u533b\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6c34\u5e73\u3002"}}
{"id": "2601.04750", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04750", "abs": "https://arxiv.org/abs/2601.04750", "authors": ["Krishna Chaitanya Sunkara"], "title": "Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers", "comment": "71 pages, 10 figures, 5 tables, 9 chapters including cases study. Published independently under Creative Commons BY 4.0. Includes comprehensive technical diagrams, quantitative models, JSON schema specifications, and production deployment validation.This is comprehensive manuscript synthesizing original research and systems engineering practices in AI Scale data center infrastructure management", "summary": "This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86DCIM 3.0\uff0c\u4e00\u79cd\u7efc\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u667a\u80fd\u3001\u70ed\u5efa\u6a21\u548c\u7edf\u4e00\u8bbe\u5907\u8fde\u63a5\u534f\u8bae\u6765\u89e3\u51b3\u4e0b\u4e00\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u4e2d\u7684\u57fa\u7840\u8bbe\u65bd\u81ea\u52a8\u5316\u3001\u53ef\u6301\u7eed\u6027\u548c\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u7b49\u5173\u952e\u6311\u6218\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4e0b\u4e00\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u4e2d\u9762\u4e34\u7684\u57fa\u7840\u8bbe\u65bd\u81ea\u52a8\u5316\u3001\u53ef\u6301\u7eed\u6027\u4ee5\u53ca\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u8bed\u4e49\u63a8\u7406\u3001\u9884\u6d4b\u5206\u6790\u3001\u81ea\u4e3b\u7f16\u6392\u548c\u7edf\u4e00\u8fde\u63a5\u6027\u7684\u6846\u67b6DCIM 3.0\uff0c\u8be5\u6846\u67b6\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u667a\u80fd\u3001\u70ed\u6a21\u578b\u53ca\u7edf\u4e00\u8bbe\u5907\u8fde\u63a5\u534f\u8bae\uff08UDCP\uff09\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u73b0\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u590d\u6742\u9700\u6c42\u7684\u7efc\u5408\u7ba1\u7406\u7cfb\u7edf\u3002", "conclusion": "DCIM 3.0\u4e3a\u5b9e\u73b0\u66f4\u52a0\u667a\u80fd\u3001\u81ea\u52a8\u5316\u7684\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.04395", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04395", "abs": "https://arxiv.org/abs/2601.04395", "authors": ["Tomer Wullach", "Ori Shapira", "Amir DN Cohen"], "title": "The Overlooked Role of Graded Relevance Thresholds in Multilingual Dense Retrieval", "comment": null, "summary": "Dense retrieval models are typically fine-tuned with contrastive learning objectives that require binary relevance judgments, even though relevance is inherently graded. We analyze how graded relevance scores and the threshold used to convert them into binary labels affect multilingual dense retrieval. Using a multilingual dataset with LLM-annotated relevance scores, we examine monolingual, multilingual mixture, and cross-lingual retrieval scenarios. Our findings show that the optimal threshold varies systematically across languages and tasks, often reflecting differences in resource level. A well-chosen threshold can improve effectiveness, reduce the amount of fine-tuning data required, and mitigate annotation noise, whereas a poorly chosen one can degrade performance. We argue that graded relevance is a valuable but underutilized signal for dense retrieval, and that threshold calibration should be treated as a principled component of the fine-tuning pipeline.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5206\u7ea7\u76f8\u5173\u6027\u8bc4\u5206\u548c\u8f6c\u6362\u4e3a\u4e8c\u5143\u6807\u7b7e\u7684\u9608\u503c\u5bf9\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6700\u4f73\u9608\u503c\u968f\u8bed\u8a00\u548c\u4efb\u52a1\u7684\u4e0d\u540c\u800c\u53d8\u5316\uff0c\u5e76\u6307\u51fa\u6821\u51c6\u9608\u503c\u662f\u5bc6\u96c6\u68c0\u7d22\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u4e00\u4e2a\u91cd\u8981\u7684\u73af\u8282\u3002", "motivation": "\u63a2\u7d22\u5206\u7ea7\u76f8\u5173\u6027\u8bc4\u5206\u4ee5\u53ca\u5c06\u8fd9\u4e9b\u8bc4\u5206\u8f6c\u6362\u6210\u4e8c\u5143\u6807\u7b7e\u65f6\u6240\u4f7f\u7528\u7684\u9608\u503c\u5982\u4f55\u5f71\u54cd\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5bc6\u96c6\u68c0\u7d22\u6a21\u578b\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5e26\u6709LLM\u6807\u6ce8\u7684\u76f8\u5173\u6027\u5206\u6570\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5728\u5355\u8bed\u79cd\u3001\u591a\u8bed\u79cd\u6df7\u5408\u53ca\u8de8\u8bed\u79cd\u68c0\u7d22\u60c5\u5883\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u4e0d\u540c\u8bed\u8a00\u548c\u4efb\u52a1\u7684\u6700\u4f73\u9608\u503c\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff1b\u9009\u62e9\u5408\u9002\u7684\u9608\u503c\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\u3001\u51cf\u5c11\u6240\u9700\u7684\u5fae\u8c03\u6570\u636e\u91cf\u5e76\u51cf\u8f7b\u6807\u6ce8\u566a\u58f0\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff1b\u800c\u4e0d\u5f53\u7684\u9009\u62e9\u5219\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u5206\u7ea7\u76f8\u5173\u6027\u5bf9\u4e8e\u5bc6\u96c6\u68c0\u7d22\u800c\u8a00\u662f\u4e00\u4e2a\u6709\u4ef7\u503c\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u4fe1\u53f7\uff0c\u9608\u503c\u6821\u51c6\u5e94\u5f53\u88ab\u89c6\u4e3a\u5fae\u8c03\u6d41\u7a0b\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u4e14\u6709\u539f\u5219\u6027\u7684\u7ec4\u6210\u90e8\u5206\u3002"}}
{"id": "2601.04250", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04250", "abs": "https://arxiv.org/abs/2601.04250", "authors": ["Mustapha Hamdi", "Mourad Jabou"], "title": "Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding", "comment": "6 pages, 4 figures. Code available at:https://github.com/InnoDeep-repos/Green_MLOps", "summary": "Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u751f\u7269\u542f\u53d1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u86cb\u767d\u8d28\u6298\u53e0\u80fd\u91cf\u76c6\u5730\u6620\u5c04\u5230\u63a8\u7406\u6210\u672c\u666f\u89c2\uff0c\u5e76\u5229\u7528\u4e00\u4e2a\u8870\u51cf\u7684\u95ed\u73af\u9608\u503c\u6765\u63a7\u5236\u6267\u884c\uff0c\u4ee5\u63d0\u9ad8AI\u90e8\u7f72\u4e2d\u7684\u80fd\u6548\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5904\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u5bf9\u51c6\u786e\u6027\u7684\u5f71\u54cd\u6781\u5c0f\u3002", "motivation": "\u968f\u7740\u957f\u671f\u8fd0\u884c\u7684\u63a8\u7406\u5728\u7d2f\u79ef\u78b3\u6392\u653e\u65b9\u9762\u53ef\u80fd\u8d85\u8fc7\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u5347AI\u90e8\u7f72\u4e2d\u7684\u80fd\u6548\u7387\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u7075\u611f\u6765\u6e90\u4e8e\u751f\u7269\u5b66\u7684\u8fc7\u7a0b\u63a7\u5236\u673a\u5236\uff0c\u5b83\u6a21\u4eff\u4e86\u86cb\u767d\u8d28\u6298\u53e0\u65f6\u7684\u80fd\u91cf\u76c6\u5730\u5206\u5e03\u7279\u6027\u5e94\u7528\u4e8e\u63a8\u7406\u6210\u672c\u7684\u7ba1\u7406\u4e0a\uff1b\u901a\u8fc7\u8bbe\u7f6e\u4e00\u4e2a\u9010\u6e10\u51cf\u5f31\u7684\u53cd\u9988\u73af\u8def\u9608\u503c\u6765\u51b3\u5b9a\u662f\u5426\u63a5\u53d7\u65b0\u7684\u8bf7\u6c42\uff0c\u786e\u4fdd\u53ea\u6709\u5f53\u9884\u671f\u7684\u6548\u7528-\u80fd\u8017\u6bd4\u6709\u5229\u65f6\u624d\u4f1a\u7ee7\u7eed\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u7684\u5f00\u73af\u6267\u884c\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u751f\u7269\u63a7\u5236\u5668\u80fd\u591f\u5c06\u5904\u7406\u65f6\u95f4\u51cf\u5c1142%\uff0c\u540c\u65f6\u51c6\u786e\u6027\u7684\u4e0b\u964d\u5c0f\u4e8e0.5%\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u8f7b\u91cf\u7ea7\u672c\u5730\u670d\u52a1\u548c\u7ba1\u7406\u6279\u5904\u7406\u4e4b\u95f4\u7684\u6548\u7387\u754c\u9650\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u4e3a\u7eff\u8272MLOps\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u5b9e\u65bd\u95ed\u73af\u3001\u8282\u80fd\u610f\u8bc6\u5f3a\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u5ba1\u8ba1\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.04757", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.04757", "abs": "https://arxiv.org/abs/2601.04757", "authors": ["Cristian Riveros", "Benjamin Scheidt", "Nicole Schweikardt"], "title": "Structural Indexing of Relational Databases for the Evaluation of Free-Connex Acyclic Conjunctive Queries", "comment": "This paper supersedes the preprint arXiv:2405.12358 by the same authors that only considered the special case of binary schemas", "summary": "We present an index structure to boost the evaluation of free-connex acyclic conjunctive queries (fc-ACQs) over relational databases. The main ingredient of the index associated with a given database $D$ is an auxiliary database $D_{col}$. Our main result states that for any fc-ACQ $Q$ over $D$, we can count the number of answers of $Q$ or enumerate them with constant delay after a preprocessing phase that takes time linear in the size of $D_{col}$.\n  Unlike previous indexing methods based on values or order (e.g., B+ trees), our index is based on structural symmetries among tuples in a database, and the size of $D_{col}$ is related to the number of colors assigned to $D$ by Scheidt and Schweikardt's \"relational color refinement\" (2025). In the particular case of graphs, this coincides with the minimal size of an equitable partition of the graph. For example, the size of $D_{col}$ is logarithmic in the case of binary trees and constant for regular graphs. Even in the worst-case that $D$ has no structural symmetries among tuples at all, the size of $D_{col}$ is still linear in the size of $D$.\n  Given that the size of $D_{col}$ is bounded by the size of $D$ and can be much smaller (even constant for some families of databases), our index is the first foundational result on indexing internal structural symmetries of a database to evaluate all fc-ACQs with performance potentially strictly smaller than the database size.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7d22\u5f15\u7ed3\u6784\uff0c\u7528\u4e8e\u52a0\u901f\u5173\u7cfb\u6570\u636e\u5e93\u4e2d\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u5408\u53d6\u67e5\u8be2(fc-ACQs)\u7684\u8bc4\u4f30\u3002\u8be5\u7d22\u5f15\u57fa\u4e8e\u6570\u636e\u5e93\u5185\u90e8\u7ed3\u6784\u5bf9\u79f0\u6027\uff0c\u5e76\u4e14\u5176\u5927\u5c0f\u4e0e\u901a\u8fc7Scheidt\u548cSchweikardt\u63d0\u51fa\u7684'relational color refinement'\u5206\u914d\u7ed9\u6570\u636e\u5e93\u7684\u989c\u8272\u6570\u91cf\u76f8\u5173\u3002", "motivation": "\u4e3a\u4e86\u52a0\u901f\u5173\u7cfb\u6570\u636e\u5e93\u4e2d\u81ea\u7531\u8fde\u63a5\u65e0\u73af\u5408\u53d6\u67e5\u8be2\uff08fc-ACQs\uff09\u7684\u8bc4\u4f30\uff0c\u540c\u65f6\u51cf\u5c11\u9884\u5904\u7406\u65f6\u95f4\u548c\u67e5\u8be2\u54cd\u5e94\u65f6\u95f4\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578b\u7d22\u5f15\u7ed3\u6784\uff0c\u8be5\u7ed3\u6784\u4f9d\u8d56\u4e8e\u539f\u6570\u636e\u5e93$D$\u7684\u4e00\u4e2a\u8f85\u52a9\u6570\u636e\u5e93$D_{col}$\u3002\u6b64\u7d22\u5f15\u65b9\u6cd5\u4e0d\u540c\u4e8e\u4ee5\u5f80\u57fa\u4e8e\u503c\u6216\u987a\u5e8f\u7684\u65b9\u6cd5\uff0c\u800c\u662f\u5229\u7528\u4e86\u6570\u636e\u5e93\u5185\u5143\u7ec4\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u5bf9\u79f0\u6027\u3002", "result": "\u5bf9\u4e8e\u4efb\u4f55\u5728$D$\u4e0a\u7684fc-ACQ $Q$\uff0c\u53ef\u4ee5\u5728\u7ecf\u8fc7\u7ebf\u6027\u4e8e$D_{col}$\u5927\u5c0f\u7684\u9884\u5904\u7406\u9636\u6bb5\u540e\uff0c\u4ee5\u5e38\u6570\u5ef6\u8fdf\u8ba1\u7b97$Q$\u7684\u7b54\u6848\u6570\u91cf\u6216\u679a\u4e3e\u7b54\u6848\u3002$D_{col}$\u7684\u5927\u5c0f\u4e0e\u6570\u636e\u5e93$D$\u76f8\u6bd4\u53ef\u80fd\u5c0f\u5f97\u591a\uff0c\u751a\u81f3\u5bf9\u4e8e\u67d0\u4e9b\u6570\u636e\u5e93\u5bb6\u65cf\u6765\u8bf4\u662f\u6052\u5b9a\u4e0d\u53d8\u7684\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u8bc1\u660e\u4e86\u901a\u8fc7\u7d22\u5f15\u6570\u636e\u5e93\u5185\u90e8\u7684\u7ed3\u6784\u5bf9\u79f0\u6027\u6765\u8bc4\u4f30\u6240\u6709fc-ACQs\u7684\u53ef\u80fd\u6027\uff0c\u5176\u6027\u80fd\u53ef\u80fd\u4e25\u683c\u5c0f\u4e8e\u6570\u636e\u5e93\u672c\u8eab\u7684\u5927\u5c0f\u3002"}}
{"id": "2601.04455", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04455", "abs": "https://arxiv.org/abs/2601.04455", "authors": ["Chuan Meng", "Jiqun Liu", "Mohammad Aliannejadi", "Fengran Mo", "Jeff Dalton", "Maarten de Rijke"], "title": "Re-Rankers as Relevance Judges", "comment": null, "summary": "Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., \"true\" and \"false\") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.", "AI": {"tldr": "\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u91cd\u7528\u6216\u9002\u5e94\u5df2\u5efa\u7acb\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u6765\u9884\u6d4b\u76f8\u5173\u6027\u5224\u65ad\uff0c\u4ee5\u51cf\u5c11\u8d44\u6e90\u6d6a\u8d39\u548c\u91cd\u590d\u5f00\u53d1\u3002\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8e\u91cd\u6392\u5e8f\u5668\u7684\u76f8\u5173\u6027\u5224\u65ad\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u8d85\u8d8a\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76f8\u5173\u6027\u5224\u65ad\uff0c\u5e76\u4e14\u663e\u793a\u51fa\u5bf9\u81ea\u8eab\u6216\u540c\u7cfb\u5217\u91cd\u6392\u5e8f\u5668\u7684\u5f3a\u70c8\u504f\u597d\u4ee5\u53ca\u8de8\u7cfb\u5217\u504f\u5dee\u3002", "motivation": "\u5c3d\u7ba1\u9884\u6d4b\u76f8\u5173\u6027\u5224\u65ad\u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u76f8\u5173\u6027\u9884\u6d4b\u95ee\u9898\uff0c\u4e0e\u91cd\u6392\u5e8f\u4efb\u52a1\u6709\u6f5c\u5728\u91cd\u53e0\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u63a2\u7d22\u91cd\u7528\u6216\u8c03\u6574\u73b0\u6709\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u6765\u8fdb\u884c\u76f8\u5173\u6027\u5224\u65ad\u9884\u6d4b\uff0c\u8fd9\u5bfc\u81f4\u4e86\u53ef\u80fd\u7684\u8d44\u6e90\u6d6a\u8d39\u548c\u4e0d\u5fc5\u8981\u7684\u5f00\u53d1\u5de5\u4f5c\u3002", "method": "\u7814\u7a76\u8005\u4eec\u91c7\u7528\u4e86\u4e24\u79cd\u9002\u5e94\u7b56\u7565\uff1a(i) \u4f7f\u7528\u91cd\u6392\u5e8f\u5668\u751f\u6210\u7684\u4e8c\u8fdb\u5236\u6807\u8bb0\uff08\u5982\u201c\u771f\u201d\u548c\u201c\u5047\u201d\uff09\u4f5c\u4e3a\u76f4\u63a5\u5224\u65ad\uff1b(ii) \u901a\u8fc7\u9608\u503c\u5904\u7406\u5c06\u8fde\u7eed\u7684\u91cd\u6392\u5e8f\u5206\u6570\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u6807\u7b7e\u3002\u4ed6\u4eec\u4f7f\u7528\u6765\u81ea3\u4e2a\u7cfb\u5217\u3001\u89c4\u6a21\u4ece2.2\u4ebf\u5230320\u4ebf\u4e0d\u7b49\u76848\u4e2a\u91cd\u6392\u5e8f\u5668\uff0c\u5728TREC-DL 2019\u81f32023\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u91cd\u6392\u5e8f\u5668\u7684\u76f8\u5173\u6027\u8bc4\u5224\u8005\u5728\u5927\u7ea640%\u523050%\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u4f18\u4e8eUMBRELA\uff0c\u540e\u8005\u662f\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6700\u5148\u8fdb\u76f8\u5173\u6027\u8bc4\u5224\u5de5\u5177\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u91cd\u6392\u5e8f\u5668\u7684\u8bc4\u5224\u8fd8\u8868\u73b0\u51fa\u5bf9\u81ea\u5df1\u53ca\u540c\u7cfb\u91cd\u6392\u5e8f\u5668\u7684\u5f3a\u5927\u504f\u597d\uff0c\u4ee5\u53ca\u8de8\u7cfb\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u5229\u7528\u73b0\u6709\u91cd\u6392\u5e8f\u6280\u672f\u8fdb\u884c\u76f8\u5173\u6027\u5224\u65ad\u9884\u6d4b\u7684\u6709\u6548\u6027\u548c\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u5b58\u5728\u7684\u4e00\u4e9b\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2601.04262", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04262", "abs": "https://arxiv.org/abs/2601.04262", "authors": ["Wang Cai", "Yilin Wen", "Jinchang Hou", "Du Su", "Guoqiu Wang", "Zhonghou Lv", "Chenfu Bao", "Yunfang Wu"], "title": "Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis", "comment": null, "summary": "Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overlook Modular Heterogeneity within Transformers, specifically that the functional sensitivity and degree of conflict vary substantially across different attention heads. Such global approaches impose uniform update rules across all parameters, often resulting in suboptimal trade-offs by indiscriminately updating utility sensitive heads that exhibit intense gradient conflicts. To address this limitation, we propose Conflict-Aware Sparse Tuning (CAST), a framework that integrates head-level diagnosis with sparse fine-tuning. CAST first constructs a pre-alignment conflict map by synthesizing Optimization Conflict and Functional Sensitivity, which then guides the selective update of parameters. Experiments reveal that alignment conflicts in LLMs are not uniformly distributed. We find that the drop in general capabilities mainly comes from updating a small group of ``high-conflict'' heads. By simply skipping these heads during training, we significantly reduce this loss without compromising safety, offering an interpretable and parameter-efficient approach to improving the safety-utility trade-off.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aConflict-Aware Sparse Tuning (CAST)\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u9884\u5bf9\u9f50\u51b2\u7a81\u56fe\u6765\u6307\u5bfc\u53c2\u6570\u9009\u62e9\u6027\u66f4\u65b0\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5b89\u5168\u5bf9\u9f50\u7684\u591a\u76ee\u6807\u4f18\u5316\u51b2\u7a81\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u8df3\u8fc7\u4e00\u5c0f\u90e8\u5206\u9ad8\u51b2\u7a81\u6ce8\u610f\u529b\u5934\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u7528\u80fd\u529b\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u53c2\u6570\u6548\u7387\u9ad8\u7684\u65b9\u6cd5\u6765\u6539\u5584\u5b89\u5168-\u6548\u7528\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u7f13\u89e3\u7b56\u7565\u901a\u5e38\u4f9d\u8d56\u4e8e\u5168\u5c40\u68af\u5ea6\u51e0\u4f55\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u5b89\u5168\u5bf9\u9f50\u6240\u56fa\u6709\u7684\u591a\u76ee\u6807\u4f18\u5316\u51b2\u7a81\uff0c\u4f46\u5ffd\u7565\u4e86Transformer\u5185\u90e8\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u4e4b\u95f4\u5b58\u5728\u7684\u6a21\u5757\u5f02\u8d28\u6027\uff0c\u5373\u529f\u80fd\u654f\u611f\u6027\u548c\u51b2\u7a81\u7a0b\u5ea6\u5728\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u5f02\u3002\u8fd9\u79cd\u5168\u5c40\u65b9\u6cd5\u5bf9\u6240\u6709\u53c2\u6570\u65bd\u52a0\u7edf\u4e00\u7684\u66f4\u65b0\u89c4\u5219\uff0c\u5f80\u5f80\u5bfc\u81f4\u6b21\u4f18\u6298\u8877\uff0c\u56e0\u4e3a\u5b83\u4eec\u65e0\u5dee\u522b\u5730\u66f4\u65b0\u4e86\u8868\u73b0\u51fa\u5f3a\u70c8\u68af\u5ea6\u51b2\u7a81\u7684\u5b9e\u7528\u654f\u611f\u5934\u90e8\u3002", "method": "\u63d0\u51fa\u4e86Conflict-Aware Sparse Tuning (CAST)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5934\u90e8\u5c42\u9762\u8bca\u65ad\u4e0e\u7a00\u758f\u5fae\u8c03\u3002\u9996\u5148\uff0c\u901a\u8fc7\u7efc\u5408\u4f18\u5316\u51b2\u7a81\u548c\u529f\u80fd\u654f\u611f\u6027\u6765\u6784\u5efa\u4e00\u4e2a\u9884\u5bf9\u9f50\u51b2\u7a81\u56fe\uff0c\u7136\u540e\u4f7f\u7528\u8be5\u56fe\u6307\u5bfc\u53c2\u6570\u7684\u9009\u62e9\u6027\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cLLMs\u4e2d\u7684\u5bf9\u9f50\u51b2\u7a81\u5e76\u975e\u5747\u5300\u5206\u5e03\uff1b\u5927\u90e8\u5206\u901a\u7528\u80fd\u529b\u4e0b\u964d\u6e90\u81ea\u4e8e\u66f4\u65b0\u5c11\u6570\u201c\u9ad8\u51b2\u7a81\u201d\u5934\u90e8\u3002\u7b80\u5355\u5730\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8df3\u8fc7\u8fd9\u4e9b\u5934\u90e8\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8fd9\u79cd\u635f\u5931\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u5b89\u5168\u6027\u3002", "conclusion": "Conflict-Aware Sparse Tuning (CAST) \u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168-\u6548\u7528\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u6709\u9009\u62e9\u5730\u66f4\u65b0\u53c2\u6570\u5e76\u907f\u514d\u66f4\u65b0\u90a3\u4e9b\u5bb9\u6613\u5f15\u8d77\u6027\u80fd\u4e0b\u964d\u7684\u2018\u9ad8\u51b2\u7a81\u2019\u5934\u90e8\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u6a21\u578b\u5b89\u5168\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u6574\u4f53\u6548\u80fd\u3002"}}
{"id": "2601.04820", "categories": ["cs.DB", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.04820", "abs": "https://arxiv.org/abs/2601.04820", "authors": ["Chotanansub Sophaken", "Thanadej Rattanakornphan", "Piyanon Charoenpoonpanich", "Thanapol Phungtua-eng", "Chainarong Amornbunchornvej"], "title": "LGTD: Local-Global Trend Decomposition for Season-Length-Free Time Series Analysis", "comment": "First draft", "summary": "Time series decomposition into trend, seasonal structure, and residual components is a core primitive for downstream analytics such as anomaly detection, change-point detection, and forecasting. However, most existing seasonal-trend decomposition methods rely on user-specified or estimated season lengths and implicitly assume stable periodic structure. These assumptions limit robustness and deployability in large, heterogeneous collections where recurring patterns may drift, appear intermittently, or exist at multiple time scales.\n  We propose LGTD (Local-Global Trend Decomposition), a season-length-free decomposition framework that represents a time series as the sum of a smooth global trend, adaptive local trends whose recurrence induces implicit (emergent) seasonal structure, and a residual component. Rather than explicitly modeling seasonality through a fixed or estimated period, LGTD treats seasonal structure as an emergent property arising from repeated local trend regimes. Concretely, LGTD first estimates a global trend capturing long-term evolution, then applies AutoTrend, an adaptive error-driven local linear trend inference module, to segment the detrended signal into short-lived piecewise-linear regimes. Residuals are obtained after removing both global and local trends.\n  By eliminating manual season-length specification, LGTD supports automated, low-touch deployment across time series with irregular, drifting, or weakly periodic structure. We analyze computational complexity and show that LGTD scales linearly with series length under mild conditions. Experiments on synthetic benchmarks demonstrate robust and balanced decomposition performance across fixed, transitive, and variable season-length settings, especially where period-based methods degrade.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u6846\u67b6LGTD\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u5c40\u90e8\u8d8b\u52bf\u63a8\u65ad\u6a21\u5757AutoTrend\u6765\u5904\u7406\u5468\u671f\u6027\u7ed3\u6784\uff0c\u5e76\u80fd\u591f\u81ea\u52a8\u90e8\u7f72\u5230\u5177\u6709\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\u4e0a\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u7528\u6237\u6307\u5b9a\u6216\u4f30\u8ba1\u7684\u5b63\u8282\u957f\u5ea6\uff0c\u5e76\u5047\u8bbe\u5468\u671f\u7ed3\u6784\u7a33\u5b9a\u3002\u7136\u800c\uff0c\u5728\u5927\u578b\u5f02\u6784\u96c6\u5408\u4e2d\uff0c\u8fd9\u4e9b\u5047\u8bbe\u9650\u5236\u4e86\u9c81\u68d2\u6027\u548c\u53ef\u90e8\u7f72\u6027\uff0c\u56e0\u4e3a\u91cd\u590d\u6a21\u5f0f\u53ef\u80fd\u4f1a\u6f02\u79fb\u3001\u95f4\u6b47\u51fa\u73b0\u6216\u5b58\u5728\u4e8e\u591a\u4e2a\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86LGTD\uff08Local-Global Trend Decomposition\uff09\uff0c\u4e00\u79cd\u4e0d\u9700\u8981\u6307\u5b9a\u5b63\u8282\u957f\u5ea6\u7684\u5206\u89e3\u6846\u67b6\uff0c\u5b83\u5c06\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u4e3a\u5e73\u6ed1\u7684\u5168\u5c40\u8d8b\u52bf\u3001\u81ea\u9002\u5e94\u5c40\u90e8\u8d8b\u52bf\uff08\u5176\u91cd\u590d\u5bfc\u81f4\u9690\u542b\u7684\u5b63\u8282\u7ed3\u6784\uff09\u548c\u6b8b\u5dee\u6210\u5206\u4e4b\u548c\u3002LGTD\u9996\u5148\u4f30\u8ba1\u4e00\u4e2a\u6355\u6349\u957f\u671f\u6f14\u53d8\u7684\u5168\u5c40\u8d8b\u52bf\uff0c\u7136\u540e\u5e94\u7528AutoTrend\u2014\u2014\u4e00\u4e2a\u81ea\u9002\u5e94\u8bef\u5dee\u9a71\u52a8\u7684\u5c40\u90e8\u7ebf\u6027\u8d8b\u52bf\u63a8\u65ad\u6a21\u5757\u2014\u2014\u6765\u5c06\u53bb\u8d8b\u52bf\u4fe1\u53f7\u5206\u5272\u6210\u77ed\u671f\u7684\u5206\u6bb5\u7ebf\u6027\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLGTD\u5728\u56fa\u5b9a\u3001\u8fc7\u6e21\u548c\u53ef\u53d8\u5b63\u8282\u957f\u5ea6\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u51fa\u7a33\u5065\u4e14\u5747\u8861\u7684\u5206\u89e3\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u5468\u671f\u7684\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u4e0b\u3002\u6b64\u5916\uff0c\u5206\u6790\u663e\u793a\u5728\u6e29\u548c\u6761\u4ef6\u4e0bLGTD\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "LGTD\u652f\u6301\u81ea\u52a8\u5316\u4f4e\u63a5\u89e6\u90e8\u7f72\uff0c\u9002\u7528\u4e8e\u5177\u6709\u4e0d\u89c4\u5219\u3001\u6f02\u79fb\u6216\u5f31\u5468\u671f\u6027\u7ed3\u6784\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u548c\u5f3a\u5927\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u624b\u6bb5\u3002"}}
{"id": "2601.04540", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04540", "abs": "https://arxiv.org/abs/2601.04540", "authors": ["Tanghaoran Zhang", "Xinjun Mao", "Shangwen Wang", "Yuxin Zhao", "Yao Lu", "Jin Zhang", "Zhang Zhang", "Kang Yang", "Yue Yu"], "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation", "comment": "13 pages, 7 figures, Accepted by ASE 2025", "summary": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5AdaptEval\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7247\u6bb5\u9002\u5e94\u6027\u65b9\u9762\u7684\u6027\u80fd\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u57fa\u4e8e\u5b9e\u9645\u5f00\u53d1\u60c5\u5883\u3001\u591a\u5c42\u6b21\u6ce8\u91ca\u4ee5\u53ca\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\u8bbe\u8ba1\uff0c\u4ee5\u5168\u9762\u8bc4\u4ef7\u6a21\u578b\u5728\u4e0d\u540c\u9002\u5e94\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u516d\u4e2a\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7247\u6bb5\u9002\u5e94\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u4ee3\u7801\u91cd\u7528\u8fc7\u7a0b\u4e2d\u9002\u5e94\u6027\u8c03\u6574\u8fd9\u4e00\u5173\u952e\u6d3b\u52a8\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8861\u91cf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u8fd9\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86\u540d\u4e3aAdaptEval\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u5177\u6709\u4e09\u4e2a\u72ec\u7279\u7279\u70b9\uff1a1) \u5b9e\u8df5\u80cc\u666f\uff0c\u4efb\u52a1\u6765\u6e90\u4e8e\u5f00\u53d1\u8005\u5b9e\u8df5\uff1b2) \u591a\u5c42\u6b21\u6807\u6ce8\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u6709\u4efb\u52a1\u7ea7\u548c\u9002\u5e94\u7ea7\u7684\u9700\u6c42\u8bf4\u660e\uff1b3) \u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u5305\u542b\u4e24\u5c42\u6d4b\u8bd5\u6846\u67b6\u4ee5\u8bc4\u4f30\u591a\u79cd\u5355\u72ec\u9002\u5e94\u60c5\u51b5\u4e0b\u7684\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAdaptEval\u80fd\u591f\u4ece\u591a\u4e2a\u89d2\u5ea6\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u76ee\u524d\u5b58\u5728\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u96be\u4ee5\u9075\u5faa\u660e\u786e\u6307\u793a\u7684\u95ee\u9898\u3002", "conclusion": "AdaptEval\u4e3a\u7814\u7a76\u548c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7247\u6bb5\u9002\u5e94\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u5176\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.04531", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04531", "abs": "https://arxiv.org/abs/2601.04531", "authors": ["Jessica Ryan", "Alexander I. Gumilang", "Robert Wiliam", "Derwin Suhartono"], "title": "Self-MedRAG: a Self-Reflective Hybrid Retrieval-Augmented Generation Framework for Reliable Medical Question Answering", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in medical Question Answering (QA), yet they remain prone to hallucinations and ungrounded reasoning, limiting their reliability in high-stakes clinical scenarios. While Retrieval-Augmented Generation (RAG) mitigates these issues by incorporating external knowledge, conventional single-shot retrieval often fails to resolve complex biomedical queries requiring multi-step inference. To address this, we propose Self-MedRAG, a self-reflective hybrid framework designed to mimic the iterative hypothesis-verification process of clinical reasoning. Self-MedRAG integrates a hybrid retrieval strategy, combining sparse (BM25) and dense (Contriever) retrievers via Reciprocal Rank Fusion (RRF) to maximize evidence coverage. It employs a generator to produce answers with supporting rationales, which are then assessed by a lightweight self-reflection module using Natural Language Inference (NLI) or LLM-based verification. If the rationale lacks sufficient evidentiary support, the system autonomously reformulates the query and iterates to refine the context. We evaluated Self-MedRAG on the MedQA and PubMedQA benchmarks. The results demonstrate that our hybrid retrieval approach significantly outperforms single-retriever baselines. Furthermore, the inclusion of the self-reflective loop yielded substantial gains, increasing accuracy on MedQA from 80.00% to 83.33% and on PubMedQA from 69.10% to 79.82%. These findings confirm that integrating hybrid retrieval with iterative, evidence-based self-reflection effectively reduces unsupported claims and enhances the clinical reliability of LLM-based systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-MedRAG\u7684\u81ea\u6211\u53cd\u601d\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7a00\u758f\u548c\u5bc6\u96c6\u68c0\u7d22\u5668\u4ee5\u53ca\u8fed\u4ee3\u5047\u8bbe-\u9a8c\u8bc1\u8fc7\u7a0b\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u5b58\u5728\u5e7b\u89c9\u548c\u65e0\u6839\u636e\u63a8\u7406\u7684\u95ee\u9898\uff0c\u5728\u9ad8\u98ce\u9669\u4e34\u5e8a\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027\u53d7\u5230\u9650\u5236\u3002\u4f20\u7edf\u7684\u5355\u6b21\u68c0\u7d22\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u9700\u8981\u591a\u6b65\u9aa4\u63a8\u7406\u7684\u590d\u6742\u751f\u7269\u533b\u5b66\u67e5\u8be2\u3002", "method": "Self-MedRAG\u91c7\u7528\u4e86\u4e00\u79cd\u6df7\u5408\u68c0\u7d22\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u7a00\u758f\u68c0\u7d22\u5668BM25\u4e0e\u5bc6\u96c6\u68c0\u7d22\u5668Contriever\uff0c\u5e76\u901a\u8fc7\u4e92\u60e0\u6392\u540d\u878d\u5408\uff08RRF\uff09\u6280\u672f\u6700\u5927\u5316\u8bc1\u636e\u8986\u76d6\u8303\u56f4\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u751f\u6210\u5668\u521b\u5efa\u5e26\u6709\u652f\u6301\u7406\u7531\u7684\u7b54\u6848\uff0c\u968f\u540e\u7531\u8f7b\u91cf\u7ea7\u81ea\u53cd\u601d\u6a21\u5757\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u6216\u57fa\u4e8eLLM\u7684\u9a8c\u8bc1\u8fdb\u884c\u8bc4\u4f30\u3002\u5f53\u7406\u7531\u7f3a\u4e4f\u8db3\u591f\u8bc1\u636e\u652f\u6301\u65f6\uff0c\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u91cd\u65b0\u8868\u8ff0\u67e5\u8be2\u5e76\u8fed\u4ee3\u4ee5\u4f18\u5316\u4e0a\u4e0b\u6587\u3002", "result": "\u5728MedQA\u548cPubMedQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u68c0\u7d22\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u68c0\u7d22\u57fa\u7ebf\uff1b\u6b64\u5916\uff0c\u52a0\u5165\u81ea\u6211\u53cd\u601d\u5faa\u73af\u540e\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5176\u4e2dMedQA\u4ece80.00%\u63d0\u5347\u81f383.33%\uff0c\u800cPubMedQA\u5219\u4ece69.10%\u589e\u957f\u5230\u4e8679.82%\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u6df7\u5408\u68c0\u7d22\u4e0e\u57fa\u4e8e\u8bc1\u636e\u7684\u8fed\u4ee3\u81ea\u6211\u53cd\u601d\u76f8\u7ed3\u5408\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u4e0d\u652f\u6301\u7684\u58f0\u660e\uff0c\u4ece\u800c\u589e\u5f3a\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u4e34\u5e8a\u53ef\u9760\u6027\u3002"}}
{"id": "2601.04263", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04263", "abs": "https://arxiv.org/abs/2601.04263", "authors": ["Nilushika Udayangani Hewa Dehigahawattage", "Kishor Nandakishor", "Marimuthu Palaniswami"], "title": "Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer", "comment": "In Proceedings of the 27th European Conference on Artificial Intelligence (ECAI 2025), IOS Press", "summary": "Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u2014\u2014\u65f6\u5e8f\u663e\u8457\u6027\u84b8\u998f(Temporal Saliency Distillation)\uff0c\u901a\u8fc7\u4ece\u6559\u5e08\u6a21\u578b\u4f20\u9012\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\uff0c\u4e0d\u4ec5\u4f20\u9012\u6b63\u786e\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u8fd8\u4f20\u9012\u6559\u5e08\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u8fd9\u79cd\u65b9\u6cd5\u63d0\u9ad8\u4e86\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u989d\u5916\u7684\u53c2\u6570\u6216\u7279\u5b9a\u67b6\u6784\u5047\u8bbe\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6700\u521d\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u5f00\u53d1\u7684\u65e5\u5fd7\u548c\u7279\u5f81\u5bf9\u9f50\u6280\u672f\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u6ca1\u6709\u660e\u786e\u8003\u8651\u5230\u65f6\u95f4\u6570\u636e\u7684\u7279\u70b9\uff0c\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4e00\u662f\u8f6c\u79fb\u7684\u77e5\u8bc6\u5982\u4f55\u5e2e\u52a9\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u7684\u8fc7\u7a0b\u4e0d\u6e05\u695a\uff1b\u4e8c\u662f\u8fd9\u4e9b\u65b9\u6cd5\u53ea\u8f6c\u79fb\u4e86\u6709\u9650\u7684\u77e5\u8bc6\uff0c\u4e3b\u8981\u662f\u590d\u5236\u6559\u5e08\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u5b66\u751f\u6a21\u578b\u4ea7\u751f\u7684\u9884\u6d4b\u5206\u5e03\u5f80\u5f80\u4e0e\u6559\u5e08\u6a21\u578b\u6709\u8f83\u5927\u5dee\u5f02\uff0c\u963b\u788d\u4e86\u5b83\u4eec\u5b89\u5168\u5730\u66ff\u4ee3\u6559\u5e08\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u5c06\u4f20\u7edf\u65e5\u5fd7\u8f6c\u79fb\u6269\u5c55\u5230\u4f20\u9012\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\uff0c\u5373\u4e0d\u4ec5\u4f20\u9012\u6b63\u786e\u7684\u9884\u6d4b\uff0c\u8fd8\u4f20\u9012\u6559\u5e08\u7684\u6b63\u786e\u63a8\u7406\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ece\u6559\u5e08\u65e5\u5fd7\u4e2d\u8bf1\u5bfc\u51fa\u6240\u8c13\u7684\u65f6\u5e8f\u663e\u8457\u6027\uff0c\u5b83\u6355\u6349\u4e86\u6bcf\u4e2a\u8f93\u5165\u65f6\u95f4\u6b65\u9aa4\u5bf9\u4e8e\u6559\u5e08\u9884\u6d4b\u7684\u91cd\u8981\u6027\u3002\u901a\u8fc7\u4f7f\u7528\u65f6\u5e8f\u663e\u8457\u6027\u84b8\u998f\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\uff0c\u9f13\u52b1\u5176\u57fa\u4e8e\u4e0e\u6559\u5e08\u76f8\u540c\u7684\u8f93\u5165\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65f6\u5e8f\u663e\u8457\u6027\u84b8\u998f\u6709\u6548\u63d0\u5347\u4e86\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u5916\u4e5f\u8fbe\u5230\u4e86\u7406\u60f3\u7684\u5c5e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5e0c\u671b\u4e3a\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u53ef\u89e3\u91ca\u77e5\u8bc6\u84b8\u998f\u5efa\u7acb\u4e00\u4e2a\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2601.04930", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04930", "abs": "https://arxiv.org/abs/2601.04930", "authors": ["Antonella Del Pozzo", "Achille Desreumaux", "Mathieu Gestin", "Alexandre Rapetti", "Sara Tucci-Piergiovanni"], "title": "Asynchronous Secure Federated Learning with Byzantine aggregators", "comment": null, "summary": "Privacy-preserving federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous communications setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous communication models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous communication model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5f02\u6b65\u901a\u4fe1\u73af\u5883\u4e2d\u5e94\u5bf9\u6076\u610f\u805a\u5408\u5668\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5e73\u5747\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b89\u5168\u805a\u5408\u548c\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u5ba2\u6237\u7aef\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u5b58\u5728\u6076\u610f\u805a\u5408\u670d\u52a1\u5668\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u5728\u5f02\u6b65\u901a\u4fe1\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u7684\u95ee\u9898\u3002\u8fd9\u4e9b\u6076\u610f\u805a\u5408\u670d\u52a1\u5668\u53ef\u80fd\u64cd\u7eb5\u6a21\u578b\u4ee5\u6cc4\u9732\u5ba2\u6237\u6570\u636e\u6216\u505c\u6b62\u8ba1\u7b97\u3002", "method": "\u672c\u6587\u7684\u65b9\u6cd5\u5305\u62ec\u590d\u5236\u805a\u5408\u5668\u4ee5\u5bb9\u5fcd\u90e8\u5206\u88ab\u7834\u574f\u7684\u60c5\u51b5\u3001\u63d0\u51fa\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u534f\u8bae\u8ba9\u5ba2\u6237\u7aef\u5bf9\u503c\u8fdb\u884c\u63a9\u7801\u5e76\u6dfb\u52a0\u9ad8\u65af\u566a\u58f0\u81f3\u5176\u6a21\u578b\u3001\u4ee5\u53ca\u5f15\u5165\u4e00\u79cd\u5305\u542b\u673a\u5236\u6765\u786e\u4fdd\u5ba2\u6237\u7aef\u53c2\u4e0e\u7684\u4e00\u81f4\u6027\u548c\u5e73\u8861\u9690\u79c1\u9884\u7b97\u3002", "result": "\u8be5\u89e3\u51b3\u65b9\u6848\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u540c\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u805a\u5408\u5668\u4e4b\u95f4\u7684\u5171\u8bc6\uff0c\u4ece\u800c\u7ed5\u8fc7\u4e86\u5f02\u6b65\u73af\u5883\u4e2d\u5df2\u77e5\u7684\u4e0d\u53ef\u80fd\u8fbe\u6210\u4e00\u81f4\u7684\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u4e3a\u5728\u5b58\u5728\u6076\u610f\u53ca\u62dc\u5360\u5ead\u5f0f\u805a\u5408\u5668\u7684\u73af\u5883\u4e0b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6d3b\u8dc3\u6027\u4ee5\u53ca\u5ba2\u6237\u7aef\u9690\u79c1\u7684\u5b89\u5168\u3002"}}
{"id": "2601.05108", "categories": ["cs.DB", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.05108", "abs": "https://arxiv.org/abs/2601.05108", "authors": ["Philipp Hanisch", "Markus Kr\u00f6tzsch"], "title": "Rule Rewriting Revisited: A Fresh Look at Static Filtering for Datalog and ASP", "comment": "Technical report of our ICDT'26 paper", "summary": "Static filtering is a data-independent optimisation method for Datalog, which generalises algebraic query rewriting techniques from relational databases. In spite of its early discovery by Kifer and Lozinskii in 1986, the method has been overlooked in recent research and system development, and special cases are being rediscovered independently. We therefore recall the original approach, using updated terminology and more general filter predicates that capture features of modern systems, and we show how to extend its applicability to answer set programming (ASP). The outcome is strictly more general but also more complex than the classical approach: double exponential in general and single exponential even for predicates of bounded arity. As a solution, we propose tractable approximations of the algorithm that can still yield much improved logic programs in typical cases, e.g., it can improve the performance of rule systems over real-world data in the order of magnitude.", "AI": {"tldr": "This paper revisits and updates the static filtering method for Datalog, broadening its application to answer set programming (ASP) while addressing its increased complexity through tractable approximations that improve performance.", "motivation": "The motivation is to revive and enhance the static filtering method for Datalog, which has been overlooked in recent research, and to extend its use to ASP. The aim is also to deal with the higher complexity of the updated method by proposing more manageable approximations that can still significantly improve the performance of logic programs.", "method": "The authors revisit the original static filtering approach, updating it with modern terminology and more general filter predicates. They then expand the technique's applicability to ASP. To address the increased computational complexity, they develop tractable approximation algorithms that maintain the benefits of the method without the full computational cost.", "result": "The result is a more generalized but also more complex static filtering method, with the worst-case complexity being double exponential and single exponential for predicates of bounded arity. The proposed approximations are shown to be effective in improving the performance of rule systems, particularly over real-world data, by an order of magnitude.", "conclusion": "The conclusion suggests that the extended static filtering method, despite its increased complexity, offers significant improvements in the performance of logic programs when applied to ASP, especially with the use of tractable approximations."}}
{"id": "2601.04618", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04618", "abs": "https://arxiv.org/abs/2601.04618", "authors": ["Jongho Kim", "Jaeyoung Kim", "Seung-won Hwang", "Jihyuk Kim", "Yu Jin Kim", "Moontae Lee"], "title": "Adaptive Retrieval for Reasoning-Intensive Retrieval", "comment": null, "summary": "We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREPAIR\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u8ba1\u5212\u91cd\u65b0\u7528\u4f5c\u81ea\u9002\u5e94\u68c0\u7d22\u7684\u5bc6\u96c6\u53cd\u9988\u4fe1\u53f7\u6765\u786e\u4fdd\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u4e2d\u83b7\u53d6\u8db3\u591f\u7684'\u6865\u6881'\u6587\u6863\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u548c\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e0a\u6bd4\u73b0\u6709\u57fa\u7ebf\u9ad8\u51fa5.6\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u63a8\u7406\u7684\u91cd\u6392\u5668\u6d41\u6c34\u7ebf\u8bd5\u56fe\u5728\u6392\u540d\u4e2d\u7a81\u51fa\u8fd9\u4e9b\u6587\u6863\uff0c\u4f46\u5b83\u4eec\u5b58\u5728\u53ec\u56de\u7387\u6709\u9650\u7684\u95ee\u9898\u3002\u76f4\u63a5\u5c06\u81ea\u9002\u5e94\u68c0\u7d22\u5f15\u5165\u8fd9\u4e9b\u6d41\u6c34\u7ebf\u5f80\u5f80\u4f1a\u5bfc\u81f4\u89c4\u5212\u9519\u8bef\u4f20\u64ad\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86REPAIR\u6846\u67b6\u3002", "method": "REPAIR\u6846\u67b6\u901a\u8fc7\u5c06\u63a8\u7406\u8ba1\u5212\u4f5c\u4e3a\u81ea\u9002\u5e94\u68c0\u7d22\u7684\u5bc6\u96c6\u53cd\u9988\u4fe1\u53f7\uff0c\u5e76\u5141\u8bb8\u5728\u91cd\u6392\u5e8f\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u4e2d\u9014\u4fee\u6b63\uff0c\u9009\u62e9\u6027\u5730\u8fdb\u884c\u81ea\u9002\u5e94\u68c0\u7d22\u4ee5\u83b7\u53d6\u652f\u6301\u5173\u952e\u8ba1\u5212\u7684\u6587\u6863\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5904\u7406\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u53ca\u590d\u6742\u7684QA\u4efb\u52a1\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6027\u80fd\u63d0\u9ad8\u4e865.6%\u3002", "conclusion": "REPAIR\u6846\u67b6\u6210\u529f\u5730\u89e3\u51b3\u4e86\u5982\u4f55\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u68c0\u7d22\u8fc7\u7a0b\u4e2d\u6709\u6548\u5229\u7528\u6865\u6881\u6587\u6863\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u8fdb\u81ea\u9002\u5e94\u68c0\u7d22\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.04542", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04542", "abs": "https://arxiv.org/abs/2601.04542", "authors": ["Mengmeng Zhu", "Yuxuan Sun", "Yukuan Jia", "Wei Chen", "Bo Ai", "Sheng Zhou"], "title": "Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u5ef6\u611f\u77e5\u591a\u533a\u57df\u4f18\u5148(TAMP)\u8c03\u5ea6\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u534f\u4f5c\u611f\u77e5\u4e2d\u7684\u52a8\u6001\u8c03\u5ea6\u95ee\u9898\u3002\u901a\u8fc7\u5e73\u8861\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u8d44\u6e90\u4f7f\u7528\uff0cTAMP\u7b97\u6cd5\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u5747\u7cbe\u786e\u5ea6(AP)\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad8\u4e86\u9ad8\u8fbe27%\u3002", "motivation": "\u534f\u4f5c\u611f\u77e5\u6280\u672f\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u6167\u57ce\u5e02\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5b83\u901a\u8fc7\u4f20\u611f\u5668\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u4e0e\u878d\u5408\u6765\u514b\u670d\u5355\u4e2a\u611f\u77e5\u7684\u5c40\u9650\u6027\u3002\u7136\u800c\uff0c\u7531\u4e8e\u73af\u5883\u7684\u52a8\u6001\u53d8\u5316\u5bfc\u81f4\u4fe1\u606f\u65f6\u6548\u6027\u7684\u8981\u6c42\u975e\u5e38\u9ad8\uff0c\u52a0\u4e0a\u4f20\u611f\u5668\u8ba1\u7b97\u80fd\u529b\u548c\u65e0\u7ebf\u5e26\u5bbd\u6709\u9650\uff0c\u5982\u4f55\u8bbe\u8ba1\u6709\u6548\u7684\u901a\u4fe1\u91cf\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u7814\u7a76\u4e86\u591a\u533a\u57df\u534f\u4f5c\u611f\u77e5\u573a\u666f\u4e0b\u7684\u52a8\u6001\u8c03\u5ea6\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aTAMP\uff08Timeliness-Aware Multi-region Prioritized\uff09\u7684\u8c03\u5ea6\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5229\u7528Lyapunov\u4f18\u5316\u7b56\u7565\u5c06\u957f\u671f\u5e73\u5747\u76ee\u6807\u5206\u89e3\u4e3a\u6bcf\u65f6\u9699\u7684\u4f18\u5148\u7ea7\u95ee\u9898\uff0c\u4ece\u800c\u5e73\u8861\u8c03\u5ea6\u4ef7\u503c\u4e0e\u8d44\u6e90\u6210\u672c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u7ecf\u9a8c\u60e9\u7f5a\u51fd\u6570\u6765\u53cd\u6620\u4fe1\u606f\u5e74\u9f84(AoI)\u548c\u901a\u4fe1\u91cf\u5bf9\u611f\u77e5\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5bf9\u4ea4\u53c9\u53e3\u548c\u8d70\u5eca\u4e24\u79cd\u573a\u666f\u4e0b\u771f\u5b9e\u4e16\u754c\u8def\u8fb9\u534f\u540c\u611f\u77e5(RCooper)\u6570\u636e\u96c6\u7684\u9a8c\u8bc1\uff0c\u5e7f\u6cdb\u6a21\u62df\u8868\u660eTAMP\u7b97\u6cd5\u76f8\u8f83\u4e8e\u8868\u73b0\u6700\u597d\u7684\u57fa\u51c6\uff0c\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u5e73\u5747\u7cbe\u5ea6(AP)\u63d0\u5347\u53ef\u8fbe27%\u3002", "conclusion": "\u63d0\u51fa\u7684TAMP\u8c03\u5ea6\u7b97\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u534f\u4f5c\u611f\u77e5\u4e2d\u5b58\u5728\u7684\u4fe1\u606f\u65f6\u6548\u6027\u548c\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u8d44\u6e90\u4f7f\u7528\u7684\u826f\u597d\u6298\u8877\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2601.04841", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04841", "abs": "https://arxiv.org/abs/2601.04841", "authors": ["Jefferson Seide Moll\u00e9ri", "Sami Hyrynsalmi", "Antti Hakkala", "Kai K. Kimppa", "Jouni Smed"], "title": "A Longitudinal Analysis of Gamification in Untappd: Ethical Reflections on a Social Drinking Application", "comment": null, "summary": "This paper presents a longitudinal ethical analysis of Untappd, a social drinking application that gamifies beer consumption through badges, streaks, and social sharing. Building on an exploratory study conducted in 2020, we revisit the platform in 2025 to examine how its gamification features and ethical framings have evolved. Drawing on traditional ethical theory and practical frameworks for Software Engineering, we analyze five categories of badges and their implications for user autonomy and well-being. Our findings show that, despite small adjustments and superficial disclaimers, many of the original ethical issues remain. We argue for continuous ethical reflection built embedded into software lifecycles to prevent the normalization of risky behaviors through design.", "AI": {"tldr": "\u672c\u6587\u5bf9\u793e\u4ea4\u996e\u9152\u5e94\u7528Untappd\u8fdb\u884c\u4e86\u7eb5\u5411\u4f26\u7406\u5206\u6790\uff0c\u7814\u7a76\u5176\u6e38\u620f\u5316\u529f\u80fd\uff08\u5982\u5fbd\u7ae0\u3001\u8fde\u80dc\u548c\u793e\u4f1a\u5206\u4eab\uff09\u5982\u4f55\u5f71\u54cd\u7528\u6237\u81ea\u4e3b\u6743\u548c\u798f\u7949\uff0c\u5e76\u6307\u51fa\u5c3d\u7ba1\u6709\u5c0f\u8c03\u6574\uff0c\u8bb8\u591a\u539f\u59cb\u7684\u4f26\u7406\u95ee\u9898\u4ecd\u7136\u5b58\u5728\u3002", "motivation": "\u901a\u8fc7\u5bf9Untappd\u8fd9\u4e00\u5c06\u5564\u9152\u6d88\u8d39\u6e38\u620f\u5316\u7684\u793e\u4ea4\u5e94\u7528\u7a0b\u5e8f\u8fdb\u884c\u7eb5\u5411\u4f26\u7406\u5206\u6790\uff0c\u65e8\u5728\u63a2\u7d22\u5176\u6e38\u620f\u5316\u7279\u6027\u53ca\u5176\u4f26\u7406\u6846\u67b6\u968f\u65f6\u95f4\u7684\u53d8\u5316\u60c5\u51b5\u3002", "method": "\u57fa\u4e8e2020\u5e74\u7684\u521d\u6b65\u7814\u7a76\uff0c\u57282025\u5e74\u518d\u6b21\u8bbf\u95ee\u8be5\u5e73\u53f0\uff0c\u8fd0\u7528\u4f20\u7edf\u4f26\u7406\u7406\u8bba\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u7528\u6846\u67b6\u5206\u6790\u4e94\u7c7b\u5fbd\u7ae0\u53ca\u5176\u5bf9\u7528\u6237\u81ea\u4e3b\u6027\u548c\u798f\u7949\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4fbf\u7ecf\u8fc7\u4e00\u4e9b\u7ec6\u5fae\u8c03\u6574\u548c\u8868\u9762\u514d\u8d23\u58f0\u660e\uff0c\u8bb8\u591a\u539f\u6709\u7684\u4f26\u7406\u95ee\u9898\u4ecd\u65e7\u5b58\u5728\u3002", "conclusion": "\u5efa\u8bae\u5c06\u6301\u7eed\u6027\u7684\u4f26\u7406\u53cd\u601d\u5d4c\u5165\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u4e2d\uff0c\u4ee5\u9632\u6b62\u901a\u8fc7\u8bbe\u8ba1\u4f7f\u5192\u9669\u884c\u4e3a\u6b63\u5e38\u5316\u3002"}}
{"id": "2601.04646", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04646", "abs": "https://arxiv.org/abs/2601.04646", "authors": ["Prateek Jain", "Shabari S Nair", "Ritesh Goru", "Prakhar Agarwal", "Ajay Yadav", "Yoga Sri Varshan Varadharajan", "Constantine Caramanis"], "title": "Succeeding at Scale: Automated Multi-Retriever Fusion and Query-Side Adaptation for Multi-Tenant Search", "comment": null, "summary": "Large-scale multi-tenant retrieval systems amass vast user query logs yet critically lack the curated relevance labels required for effective domain adaptation. This \"dark data\" problem is exacerbated by the operational cost of model updates: jointly fine-tuning query and document encoders requires re-indexing the entire corpus, which is prohibitive in multi-tenant environments with thousands of isolated indices. To address these dual challenges, we introduce \\textbf{DevRev Search}, a passage retrieval benchmark for technical customer support constructed through a fully automatic pipeline. We employ a \\textbf{fusion-based candidate generation} strategy, pooling results from diverse sparse and dense retrievers, and utilize an LLM-as-a-Judge to perform rigorous \\textbf{consistency filtering} and relevance assignment. We further propose a practical \\textbf{Index-Preserving Adaptation} strategy: by fine-tuning only the query encoder via Low-Rank Adaptation (LoRA), we achieve competitive performance improvements while keeping the document index frozen. Our experiments on DevRev Search and SciFact demonstrate that targeting specific transformer layers in the query encoder yields optimal quality-efficiency trade-offs, offering a scalable path for personalized enterprise search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DevRev Search\uff0c\u4e00\u4e2a\u901a\u8fc7\u5168\u81ea\u52a8\u6d41\u7a0b\u6784\u5efa\u7684\u6280\u672f\u5ba2\u6237\u652f\u6301\u6bb5\u843d\u68c0\u7d22\u57fa\u51c6\u3002\u91c7\u7528\u57fa\u4e8e\u878d\u5408\u7684\u5019\u9009\u751f\u6210\u7b56\u7565\uff0c\u5e76\u5229\u7528LLM\u4f5c\u4e3a\u88c1\u5224\u8fdb\u884c\u4e00\u81f4\u6027\u8fc7\u6ee4\u548c\u76f8\u5173\u6027\u5206\u914d\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u6301\u7d22\u5f15\u4e0d\u53d8\u7684\u9002\u5e94\u7b56\u7565\uff0c\u4ec5\u901a\u8fc7\u5bf9\u67e5\u8be2\u7f16\u7801\u5668\u8fdb\u884c\u5fae\u8c03\u6765\u5b9e\u73b0\u6027\u80fd\u6539\u8fdb\uff0c\u4e3a\u4e2a\u6027\u5316\u4f01\u4e1a\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u8def\u5f84\u3002", "motivation": "\u5927\u89c4\u6a21\u591a\u79df\u6237\u68c0\u7d22\u7cfb\u7edf\u79ef\u7d2f\u4e86\u5927\u91cf\u7684\u7528\u6237\u67e5\u8be2\u65e5\u5fd7\uff0c\u4f46\u4e25\u91cd\u7f3a\u4e4f\u6709\u6548\u9886\u57df\u9002\u5e94\u6240\u9700\u7684\u76f8\u5173\u6807\u7b7e\u3002\u6b64\u5916\uff0c\u6a21\u578b\u66f4\u65b0\u7684\u64cd\u4f5c\u6210\u672c\u9ad8\uff1a\u8054\u5408\u5fae\u8c03\u67e5\u8be2\u548c\u6587\u6863\u7f16\u7801\u5668\u9700\u8981\u91cd\u65b0\u7d22\u5f15\u6574\u4e2a\u8bed\u6599\u5e93\uff0c\u5728\u62e5\u6709\u6570\u5343\u4e2a\u9694\u79bb\u7d22\u5f15\u7684\u591a\u79df\u6237\u73af\u5883\u4e2d\u662f\u4e0d\u53ef\u884c\u7684\u3002", "method": "\u901a\u8fc7\u5168\u81ea\u52a8\u6d41\u7a0b\u6784\u5efa\u4e86\u540d\u4e3aDevRev Search\u7684\u6280\u672f\u5ba2\u6237\u652f\u6301\u6bb5\u843d\u68c0\u7d22\u57fa\u51c6\u3002\u91c7\u7528\u4e86\u57fa\u4e8e\u878d\u5408\u7684\u5019\u9009\u751f\u6210\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u591a\u79cd\u7a00\u758f\u548c\u5bc6\u96c6\u68c0\u7d22\u5668\u7684\u7ed3\u679c\uff0c\u5e76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u88c1\u5224\u6267\u884c\u4e25\u683c\u7684\u4e00\u81f4\u6027\u8fc7\u6ee4\u548c\u76f8\u5173\u6027\u5206\u914d\u3002\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4fdd\u6301\u7d22\u5f15\u4e0d\u53d8\u7684\u9002\u5e94\u7b56\u7565\uff1a\u4ec5\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\u5bf9\u67e5\u8be2\u7f16\u7801\u5668\u8fdb\u884c\u5fae\u8c03\uff0c\u5728\u4fdd\u6301\u6587\u6863\u7d22\u5f15\u51bb\u7ed3\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u6027\u80fd\u63d0\u5347\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9488\u5bf9\u67e5\u8be2\u7f16\u7801\u5668\u4e2d\u7279\u5b9a\u7684\u53d8\u538b\u5668\u5c42\u53ef\u4ee5\u8fbe\u5230\u6700\u4f73\u7684\u8d28\u91cf-\u6548\u7387\u5e73\u8861\uff0c\u4e3a\u4e2a\u6027\u5316\u4f01\u4e1a\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u8def\u5f84\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u591a\u79df\u6237\u68c0\u7d22\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u7684\u95ee\u9898\uff0c\u8fd8\u901a\u8fc7\u53ea\u5fae\u8c03\u67e5\u8be2\u7f16\u7801\u5668\u800c\u4fdd\u6301\u6587\u6863\u7d22\u5f15\u4e0d\u53d8\u7684\u65b9\u5f0f\u964d\u4f4e\u4e86\u64cd\u4f5c\u6210\u672c\uff0c\u4ece\u800c\u4e3a\u4e2a\u6027\u5316\u4f01\u4e1a\u641c\u7d22\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.04674", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04674", "abs": "https://arxiv.org/abs/2601.04674", "authors": ["Chengcheng Guo", "Kuo Cai", "Yu Zhou", "Qiang Luo", "Ruiming Tang", "Han Li", "Kun Gai", "Guorui Zhou"], "title": "PROMISE: Process Reward Models Unlock Test-Time Scaling Laws in Generative Recommendations", "comment": null, "summary": "Generative Recommendation has emerged as a promising paradigm, reformulating recommendation as a sequence-to-sequence generation task over hierarchical Semantic IDs. However, existing methods suffer from a critical issue we term Semantic Drift, where errors in early, high-level tokens irreversibly divert the generation trajectory into irrelevant semantic subspaces. Inspired by Process Reward Models (PRMs) that enhance reasoning in Large Language Models, we propose Promise, a novel framework that integrates dense, step-by-step verification into generative models. Promise features a lightweight PRM to assess the quality of intermediate inference steps, coupled with a PRM-guided Beam Search strategy that leverages dense feedback to dynamically prune erroneous branches. Crucially, our approach unlocks Test-Time Scaling Laws for recommender systems: by increasing inference compute, smaller models can match or surpass larger models. Extensive offline experiments and online A/B tests on a large-scale platform demonstrate that Promise effectively mitigates Semantic Drift, significantly improving recommendation accuracy while enabling efficient deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPromise\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5bc6\u96c6\u7684\u9010\u6b65\u9a8c\u8bc1\u5230\u751f\u6210\u6a21\u578b\u4e2d\u6765\u89e3\u51b3\u73b0\u6709\u751f\u6210\u63a8\u8350\u65b9\u6cd5\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5305\u62ec\u8f7b\u91cf\u7ea7\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4ee5\u8bc4\u4f30\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u8d28\u91cf\uff0c\u5e76\u7ed3\u5408\u4e86\u7531\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5f15\u5bfc\u7684\u675f\u641c\u7d22\u7b56\u7565\uff0c\u5229\u7528\u5bc6\u96c6\u53cd\u9988\u52a8\u6001\u526a\u679d\u9519\u8bef\u8def\u5f84\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u63a8\u8350\u7cfb\u7edf\u5728\u6d4b\u8bd5\u65f6\u7684\u89c4\u6a21\u6cd5\u5219\uff1a\u901a\u8fc7\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\uff0c\u8f83\u5c0f\u7684\u6a21\u578b\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u8f83\u5927\u7684\u6a21\u578b\u3002\u79bb\u7ebf\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u8868\u660ePromise\u6709\u6548\u7f13\u89e3\u4e86\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u8350\u51c6\u786e\u6027\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u63a8\u8350\u65b9\u6cd5\u9762\u4e34\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u2014\u2014\u8bed\u4e49\u6f02\u79fb\uff0c\u5373\u65e9\u671f\u9ad8\u5c42\u4ee4\u724c\u4e2d\u7684\u9519\u8bef\u4f1a\u4e0d\u53ef\u9006\u8f6c\u5730\u5c06\u751f\u6210\u8f68\u8ff9\u5bfc\u5411\u65e0\u5173\u7684\u8bed\u4e49\u5b50\u7a7a\u95f4\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aPromise\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u5c06\u5bc6\u96c6\u3001\u9010\u6b65\u9a8c\u8bc1\u6574\u5408\u8fdb\u751f\u6210\u6a21\u578b\u4e2d\u3002\u6b64\u6846\u67b6\u91c7\u7528\u4e86\u8f7b\u91cf\u7ea7\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u6765\u8bc4\u4f30\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u8d28\u91cf\uff0c\u5e76\u4e14\u7ed3\u5408\u4e86\u7531PRM\u6307\u5bfc\u7684\u675f\u641c\u7d22\u7b56\u7565\uff0c\u4f7f\u7528\u5bc6\u96c6\u53cd\u9988\u673a\u5236\u52a8\u6001\u4fee\u526a\u51fa\u9519\u5206\u652f\u3002", "result": "\u5e7f\u6cdb\u7684\u79bb\u7ebf\u5b9e\u9a8c\u4ee5\u53ca\u5728\u4e00\u4e2a\u5927\u89c4\u6a21\u5e73\u53f0\u4e0a\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0cPromise\u80fd\u6709\u6548\u5730\u51cf\u8f7b\u8bed\u4e49\u6f02\u79fb\u73b0\u8c61\uff0c\u5927\u5927\u63d0\u5347\u4e86\u63a8\u8350\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e5f\u652f\u6301\u4e86\u66f4\u9ad8\u6548\u7684\u90e8\u7f72\u65b9\u5f0f\u3002", "conclusion": "Promise\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u548c\u6539\u8fdb\u7684\u675f\u641c\u7d22\u7b56\u7565\u6210\u529f\u89e3\u51b3\u4e86\u751f\u6210\u63a8\u8350\u4e2d\u5b58\u5728\u7684\u8bed\u4e49\u6f02\u79fb\u95ee\u9898\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u63a8\u8350\u8d28\u91cf\u8fd8\u4fc3\u8fdb\u4e86\u8d44\u6e90\u7684\u6709\u6548\u5229\u7528\u3002"}}
{"id": "2601.04277", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04277", "abs": "https://arxiv.org/abs/2601.04277", "authors": ["Beier Luo", "Cheng Wang", "Hongxin Wei", "Sharon Li", "Xuefeng Du"], "title": "Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs", "comment": null, "summary": "Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDual-Align\u7684\u65e0\u76d1\u7763\u4e8b\u540e\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u6700\u7ec8\u5206\u5e03\u5339\u914d\u548c\u8fc7\u7a0b\u5bf9\u9f50\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u5bfc\u81f4\u7684\u4fe1\u5fc3\u6821\u51c6\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u6821\u51c6\u8bef\u5dee\uff0c\u5e76\u63a5\u8fd1\u6709\u76d1\u7763\u7684\u6700\u4f18\u89e3\u3002", "motivation": "\u540e\u8bad\u7ec3\u867d\u7136\u53ef\u4ee5\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u901a\u5e38\u4f1a\u5bfc\u81f4\u4fe1\u5fc3\u6821\u51c6\u53d8\u5dee\uff0c\u4ea7\u751f\u7cfb\u7edf\u6027\u8fc7\u5ea6\u81ea\u4fe1\u7684\u95ee\u9898\u3002\u73b0\u6709\u9488\u5bf9\u540e\u8bad\u7ec3\u6a21\u578b\uff08PoLMs\uff09\u7684\u4e8b\u540e\u65e0\u76d1\u7763\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u5c06PoLM\u7684\u4fe1\u5fc3\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4fe1\u5fc3\u8fdb\u884c\u5bf9\u9f50\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5ffd\u7565\u4e86\u540e\u8bad\u7ec3\u5f15\u5165\u7684\u63a8\u7406\u65f6\u95f4\u52a8\u6001\u7279\u6027\u3002", "method": "\u63d0\u51fa\u4e86Dual-Align\u6846\u67b6\uff0c\u5b83\u4e0d\u4ec5\u6267\u884c\u4fe1\u5fc3\u5bf9\u9f50\u4ee5\u7ea0\u6b63\u4fe1\u5fc3\u6f02\u79fb\uff0c\u8fd8\u5f15\u5165\u4e86\u8fc7\u7a0b\u5bf9\u9f50\u6765\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u95f4\u63a8\u7406\u8def\u5f84\u53d1\u6563\u7684\u95ee\u9898\u3002Dual-Align\u5b9a\u4f4d\u5230\u8f68\u8ff9\u5f00\u59cb\u5206\u5316\u7684\u5c42\uff0c\u5e76\u91cd\u65b0\u8c03\u6574\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u3002\u6574\u4e2a\u7b56\u7565\u5b66\u4e60\u5355\u4e00\u6e29\u5ea6\u53c2\u6570\uff0c\u5728\u4e0d\u727a\u7272\u540e\u8bad\u7ec3\u6027\u80fd\u589e\u76ca\u7684\u524d\u63d0\u4e0b\u4fee\u6b63\u4e24\u79cd\u6f02\u79fb\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0cDual-Align\u80fd\u591f\u4e00\u81f4\u5730\u51cf\u5c11\u6821\u51c6\u8bef\u5dee\uff0c\u5e76\u4e14\u5176\u8868\u73b0\u63a5\u8fd1\u4e8e\u6709\u76d1\u7763\u7684\u7406\u60f3\u60c5\u51b5\u3002", "conclusion": "Dual-Align\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u6539\u5584\u540e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4fe1\u5fc3\u6821\u51c6\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2601.04922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04922", "abs": "https://arxiv.org/abs/2601.04922", "authors": ["Th\u00e9o Boivin", "Joeffrey Legaux"], "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?", "comment": null, "summary": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u914d\u7f6e\u57fa\u51c6\uff0c\u7528\u4e8e\u63a2\u7d22AVX/NEON\u5185\u5728\u51fd\u6570\u5728\u9700\u8981\u77e2\u91cf\u5316\u7b56\u7565\u4ee5\u4f18\u5316\u4ee3\u7801\u7684\u4e00\u822c\u5f00\u53d1\u9879\u76ee\u4e2d\u7684\u80fd\u529b\u4e0e\u9650\u5236\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6761\u4ef6\u5206\u652f\u4e2d\u4f7f\u7528\u5185\u5728\u51fd\u6570\u975e\u5e38\u9ad8\u6548\uff0c\u6267\u884c\u65f6\u95f4\u4ec5\u4e3a\u666e\u901a\u4ee3\u7801\u7684\u5927\u7ea65%\u3002\u7136\u800c\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u7531\u4e8e\u7f16\u8bd1\u5668\u5df2\u7ecf\u5f88\u597d\u5730\u5b9e\u73b0\u4e86\u81ea\u52a8\u77e2\u91cf\u5316\uff0c\u56e0\u6b64\u4f7f\u7528\u5185\u5728\u51fd\u6570\u662f\u4e0d\u5fc5\u8981\u7684\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u5f00\u53d1\u8005\u6839\u636e\u64cd\u4f5c\u7cfb\u7edf\u3001\u67b6\u6784\u548c/\u6216\u53ef\u7528\u7f16\u8bd1\u5668\u9009\u62e9\u4f55\u65f6\u4f7f\u7528\u5185\u5728\u51fd\u6570\u6765\u4f18\u5316\u4ee3\u7801\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u91c7\u7528\u77e2\u91cf\u5316\u7b56\u7565\u65f6\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u8de8\u914d\u7f6e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86AVX/NEON\u5185\u5728\u51fd\u6570\u5728\u901a\u7528\u5f00\u53d1\u573a\u666f\u4e0b\u7684\u6027\u80fd\u53ca\u5176\u5c40\u9650\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6d89\u53ca\u6761\u4ef6\u5206\u652f\u7684\u60c5\u51b5\u4e0b\uff0c\u5185\u5728\u51fd\u6570\u7684\u6548\u7387\u975e\u5e38\u9ad8\uff0c\u4f46\u540c\u65f6\u6307\u51fa\u5728\u5f88\u591a\u60c5\u5f62\u4e0b\u56e0\u73b0\u4ee3\u7f16\u8bd1\u5668\u7684\u826f\u597d\u81ea\u52a8\u77e2\u91cf\u5316\u529f\u80fd\u4f7f\u5f97\u76f4\u63a5\u5e94\u7528\u5185\u5728\u51fd\u6570\u53d8\u5f97\u4e0d\u5fc5\u8981\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u5728\u4f55\u79cd\u6761\u4ef6\u4e0b\u5229\u7528AVX/NEON\u5185\u5728\u51fd\u6570\u80fd\u591f\u6709\u6548\u63d0\u5347\u7a0b\u5e8f\u6027\u80fd\u7684\u6307\u5bfc\u5efa\u8bae\uff0c\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u4e0d\u5e94\u76f2\u76ee\u4f9d\u8d56\u8fd9\u4e9b\u6280\u672f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.04918", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04918", "abs": "https://arxiv.org/abs/2601.04918", "authors": ["Ziwen Wang", "Shangshang Yang", "Xiaoshan Yu", "Haiping Ma", "Xingyi Zhang"], "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective", "comment": "KDD2026, 15 pages", "summary": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOSCD\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\uff08\u8bad\u7ec3\u548c\u641c\u7d22\uff09\u8fc7\u7a0b\u6765\u4f18\u5316\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u7684\u7ed3\u6784\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8\u5b66\u4e60\u8005\u80fd\u529b\u8bc4\u4f30\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u566a\u58f0\u6570\u636e\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u6559\u80b2\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u63d0\u5347\u6a21\u578b\u6027\u80fd\u800c\u5ffd\u89c6\u4e86\u89c2\u5bdf\u54cd\u5e94\u6570\u636e\u4e2d\u7684\u566a\u58f0\u6c61\u67d3\u95ee\u9898\uff0c\u540c\u65f6\u5f53\u524d\u7684\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u8bbe\u8ba1\u4f9d\u8d56\u4e8e\u7814\u7a76\u4eba\u5458\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u672a\u80fd\u5145\u5206\u63a2\u7d22\u53ef\u80fd\u7684\u67b6\u6784\u6f5c\u529b\u3002", "method": "OSCD\u65b9\u6cd5\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u8bad\u7ec3\u9636\u6bb5\uff0c\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u67b6\u6784\u7ec4\u5408\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u5b8c\u5168\u4e8c\u53c9\u6811\u62d3\u6251\u7ed3\u6784\u8bad\u7ec3\u4e00\u4e2a\u6743\u91cd\u5171\u4eab\u8d85\u7f51\uff1b2) \u641c\u7d22\u9636\u6bb5\uff0c\u5c06\u6700\u4f73\u67b6\u6784\u641c\u7d22\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898(MOP)\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408Pareto\u6700\u4f18\u89e3\u641c\u7d22\u7b56\u7565\u4e0e\u8de8\u573a\u666f\u6027\u80fd\u8bc4\u4f30\u7684\u4f18\u5316\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4e16\u754c\u6559\u80b2\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u7531OSCD\u6a21\u578b\u53d1\u73b0\u7684\u6700\u4f73\u67b6\u6784\u5bf9\u4e8e\u6267\u884c\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u65e2\u6709\u6548\u53c8\u7a33\u5065\u3002", "conclusion": "OSCD\u4f5c\u4e3a\u4e00\u79cd\u8fdb\u5316\u591a\u76ee\u6807\u4e00\u6b21\u6027\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u514b\u670d\u73b0\u6709\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u542b\u566a\u6570\u636e\u65b9\u9762\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.04279", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04279", "abs": "https://arxiv.org/abs/2601.04279", "authors": ["Pau Esteve", "Massimiliano Zanin"], "title": "Generation of synthetic delay time series for air transport applications", "comment": "18 pages, 13 figures", "summary": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u4e09\u79cd\u4e0d\u540c\u6a21\u578b\u751f\u6210\u673a\u573a\u5ef6\u8bef\u65f6\u95f4\u5e8f\u5217\u7684\u5408\u6210\u6570\u636e\uff0c\u53d1\u73b0\u57fa\u4e8e\u7b80\u5316\u9057\u4f20\u7b97\u6cd5\u7684\u65b9\u6cd5\u80fd\u591f\u4ea7\u751f\u4e0e\u771f\u5b9e\u6570\u636e\u51e0\u4e4e\u65e0\u6cd5\u533a\u5206\u7684\u65f6\u95f4\u5e8f\u5217\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u9ad8\u5ea6\u7684\u53d8\u5f02\u6027\u3002\u751f\u6210\u7684\u6570\u636e\u5728\u68c0\u6d4b\u673a\u573a\u95f4\u5ef6\u8bef\u4f20\u64ad\u7684\u95ee\u9898\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5e76\u88ab\u63d0\u4f9b\u7ed9\u79d1\u5b66\u754c\u4f7f\u7528\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u822a\u7a7a\u8fd0\u8f93\u9886\u57df\u4e2d\u751f\u6210\u903c\u771f\u7684\u673a\u573a\u5ef6\u8bef\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "method": "\u6bd4\u8f83\u4e86\u4e24\u79cd\u57fa\u4e8e\u6700\u5148\u8fdb\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u7684\u6a21\u578b\u4e0e\u4e00\u79cd\u7b80\u5316\u7684\u9057\u4f20\u7b97\u6cd5\u65b9\u6cd5\u6765\u751f\u6210\u673a\u573a\u5ef6\u8bef\u65f6\u95f4\u5e8f\u5217\u7684\u5408\u6210\u6570\u636e\u3002", "result": "\u7b80\u5316\u9057\u4f20\u7b97\u6cd5\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u4e0e\u771f\u5b9e\u6570\u636e\u975e\u5e38\u76f8\u4f3c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u53d8\u5f02\u6027\uff1b\u8fd9\u4e9b\u751f\u6210\u7684\u6570\u636e\u4e5f\u88ab\u7528\u4e8e\u9a8c\u8bc1\u5ef6\u8fdf\u4f20\u64ad\u68c0\u6d4b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7b80\u5316\u9057\u4f20\u7b97\u6cd5\u4e3a\u751f\u6210\u903c\u771f\u7684\u673a\u573a\u5ef6\u8bef\u5408\u6210\u6570\u636e\u63d0\u4f9b\u4e86\u6709\u6548\u624b\u6bb5\uff0c\u8fd9\u5bf9\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.05081", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05081", "abs": "https://arxiv.org/abs/2601.05081", "authors": ["Franziska Pradel", "Fabian Haak"], "title": "Dynamics in Search Engine Query Suggestions for European Politicians", "comment": "11 pages; 3 figures; 6 tables; published as a conference paper at WebSci '24 (May 21-24, 2024, Stuttgart, Germany)", "summary": "Search engines are commonly used for online political information seeking. Yet, it remains unclear how search query suggestions for political searches that reflect the latent interest of internet users vary across countries and over time. We provide a systematic analysis of Google search engine query suggestions for European and national politicians. Using an original dataset of search query suggestions for European politicians collected in ten countries, we find that query suggestions are less stable over time in politicians' countries of origin, when the politicians hold a supranational role, and for female politicians. Moreover, query suggestions for political leaders and male politicians are more similar across countries. We conclude by discussing possible future directions for studying information search about European politicians in online search.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u5341\u4e2a\u56fd\u5bb6\u4e2d\u9488\u5bf9\u6b27\u6d32\u548c\u56fd\u5bb6\u653f\u6cbb\u5bb6\u7684\u8c37\u6b4c\u641c\u7d22\u5f15\u64ce\u67e5\u8be2\u5efa\u8bae\uff0c\u53d1\u73b0\u653f\u6cbb\u5bb6\u672c\u56fd\u3001\u62c5\u4efb\u8d85\u56fd\u5bb6\u89d2\u8272\u7684\u653f\u6cbb\u5bb6\u4ee5\u53ca\u5973\u6027\u653f\u6cbb\u5bb6\u7684\u67e5\u8be2\u5efa\u8bae\u968f\u65f6\u95f4\u53d8\u5316\u8f83\u5927\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u653f\u6cbb\u9886\u5bfc\u4eba\u548c\u7537\u6027\u653f\u6cbb\u5bb6\u7684\u67e5\u8be2\u5efa\u8bae\u5728\u4e0d\u540c\u56fd\u5bb6\u4e4b\u95f4\u66f4\u4e3a\u76f8\u4f3c\u3002", "motivation": "\u63a2\u8ba8\u4e0d\u540c\u56fd\u5bb6\u53ca\u65f6\u95f4\u70b9\u4e0a\u53cd\u6620\u4e92\u8054\u7f51\u7528\u6237\u6f5c\u5728\u5174\u8da3\u7684\u653f\u6cbb\u641c\u7d22\u67e5\u8be2\u5efa\u8bae\u7684\u53d8\u5316\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u5341\u4e2a\u56fd\u5bb6\u5185\u5173\u4e8e\u6b27\u6d32\u653f\u6cbb\u4eba\u7269\u7684\u539f\u59cb\u67e5\u8be2\u5efa\u8bae\u6570\u636e\u96c6\u6765\u8fdb\u884c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5728\u653f\u6cbb\u5bb6\u672c\u56fd\u3001\u5bf9\u4e8e\u5177\u6709\u8d85\u56fd\u5bb6\u89d2\u8272\u6216\u4e3a\u5973\u6027\u7684\u653f\u6cbb\u5bb6\uff0c\u5176\u67e5\u8be2\u5efa\u8bae\u968f\u65f6\u95f4\u66f4\u4e0d\u7a33\u5b9a\uff1b\u800c\u5bf9\u9886\u5bfc\u5c42\u4eba\u7269\u548c\u7537\u6027\u653f\u6cbb\u5bb6\u6765\u8bf4\uff0c\u8de8\u56fd\u5bb6\u95f4\u67e5\u8be2\u5efa\u8bae\u8f83\u4e3a\u4e00\u81f4\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u672a\u6765\u5728\u7ebf\u641c\u7d22\u4e2d\u5173\u4e8e\u6b27\u6d32\u653f\u6cbb\u4eba\u7269\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u53ef\u80fd\u7684\u65b9\u5411\u3002"}}
{"id": "2601.04282", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04282", "abs": "https://arxiv.org/abs/2601.04282", "authors": ["Qiang Chen", "Chun-Wun Cheng", "Xiu Su", "Hongyan Xu", "Xi Lin", "Shan You", "Angelica I. Aviles-Rivero", "Yi Chen"], "title": "LEGATO: Good Identity Unlearning Is Continuous", "comment": null, "summary": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLEGATO\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u4e00\u81f4\u7684\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6765\u5b9e\u73b0\u751f\u6210\u6a21\u578b\u4e2d\u8eab\u4efd\u4fe1\u606f\u7684\u8fde\u7eed\u4e14\u53ef\u63a7\u9057\u5fd8\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u673a\u5668\u9057\u5fd8\u6280\u672f\u4e2d\u7684\u4f4e\u6548\u3001\u53ef\u63a7\u6027\u5dee\u4ee5\u53ca\u707e\u96be\u6027\u5d29\u6e83\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u5927\u5e45\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u79fb\u9664\u654f\u611f\u6570\u636e\u7684\u76ee\u6807\u3002", "motivation": "\u5f53\u524d\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u5728\u5904\u7406\u751f\u6210\u6a21\u578b\u4e2d\u7684\u8eab\u4efd\u4fe1\u606f\u5220\u9664\u65f6\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u3001\u63a7\u5236\u529b\u6709\u9650\u548c\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u800c\u4e14\u968f\u7740\u9057\u5fd8\u8fc7\u7a0b\u7684\u63a8\u8fdb\uff0c\u6a21\u578b\u4fdd\u6301\u80fd\u529b\u53ef\u80fd\u4f1a\u51fa\u73b0\u6025\u5267\u4e0b\u964d\u7684\u60c5\u51b5\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u8ba4\u4e3a\u5e94\u8be5\u5c06\u8eab\u4efd\u9057\u5fd8\u5efa\u6a21\u4e3a\u4e00\u4e2a\u8fde\u7eed\u7684\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u540d\u4e3aLEGATO\uff0c\u5b83\u5229\u7528\u4e86\u8f7b\u91cf\u7ea7\u7684\u795e\u7ecfODE\u9002\u914d\u5668\u6765\u589e\u5f3a\u9884\u8bad\u7ec3\u751f\u6210\u5668\uff0c\u4f7f\u5f97\u53ef\u4ee5\u5728\u51bb\u7ed3\u539f\u59cb\u6a21\u578b\u6743\u91cd\u7684\u524d\u63d0\u4e0b\u5e73\u6ed1\u5730\u8fdb\u884c\u53ef\u8c03\u63a7\u7684\u9057\u5fd8\u64cd\u4f5c\u3002\u901a\u8fc7\u8c03\u6574ODE\u6b65\u957f\u5927\u5c0f\u53ef\u4ee5\u7cbe\u786e\u8c03\u8282\u9057\u5fd8\u5f3a\u5ea6\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u8f68\u8ff9\u4e00\u81f4\u6027\u7ea6\u675f\u4ee5\u9632\u6b62\u5728\u89e3\u9664\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u53d1\u751f\u707e\u96be\u6027\u7684\u6027\u80fd\u4e0b\u964d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u9886\u57df\u5185\u5916\u7684\u8eab\u4efd\u89e3\u9664\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLEGATO\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u8868\u73b0\uff0c\u4e0d\u4ec5\u907f\u514d\u4e86\u707e\u96be\u6027\u5d29\u6e83\u8fd8\u51cf\u5c11\u4e86\u9700\u8981\u5fae\u8c03\u7684\u53c2\u6570\u6570\u91cf\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0cLEGATO\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u751f\u6210\u6a21\u578b\u4e2d\u8eab\u4efd\u4fe1\u606f\u53bb\u9664\u95ee\u9898\u7684\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6a21\u578b\u539f\u6709\u529f\u80fd\u4e0d\u53d7\u4e25\u91cd\u5f71\u54cd\u7684\u540c\u65f6\u5b9e\u73b0\u5bf9\u7279\u5b9a\u4fe1\u606f\u7684\u5b89\u5168\u79fb\u9664\u3002"}}
{"id": "2601.05200", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05200", "abs": "https://arxiv.org/abs/2601.05200", "authors": ["Silvio Martinico", "Franco Maria Nardini", "Cosimo Rulli", "Rossano Venturini"], "title": "Multivector Reranking in the Era of Strong First-Stage Retrievers", "comment": "17 pages, 2 figures, ECIR 2026", "summary": "Learned multivector representations power modern search systems with strong retrieval effectiveness, but their real-world use is limited by the high cost of exhaustive token-level retrieval. Therefore, most systems adopt a \\emph{gather-and-refine} strategy, where a lightweight gather phase selects candidates for full scoring. However, this approach requires expensive searches over large token-level indexes and often misses the documents that would rank highest under full similarity. In this paper, we reproduce several state-of-the-art multivector retrieval methods on two publicly available datasets, providing a clear picture of the current multivector retrieval field and observing the inefficiency of token-level gathering. Building on top of that, we show that replacing the token-level gather phase with a single-vector document retriever -- specifically, a learned sparse retriever (LSR) -- produces a smaller and more semantically coherent candidate set. This recasts the gather-and-refine pipeline into the well-established two-stage retrieval architecture. As retrieval latency decreases, query encoding with two neural encoders becomes the dominant computational bottleneck. To mitigate this, we integrate recent inference-free LSR methods, demonstrating that they preserve the retrieval effectiveness of the dual-encoder pipeline while substantially reducing query encoding time. Finally, we investigate multiple reranking configurations that balance efficiency, memory, and effectiveness, and we introduce two optimization techniques that prune low-quality candidates early. Empirical results show that these techniques improve retrieval efficiency by up to 1.8$\\times$ with no loss in quality. Overall, our two-stage approach achieves over $24\\times$ speedup over the state-of-the-art multivector retrieval systems, while maintaining comparable or superior retrieval quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\uff0c\u901a\u8fc7\u7528\u5355\u5411\u91cf\u6587\u6863\u68c0\u7d22\u5668\uff08\u5177\u4f53\u4e3a\u5b66\u4e60\u7a00\u758f\u68c0\u7d22\u5668LSR\uff09\u66ff\u6362\u4f20\u7edf\u7684token-level\u68c0\u7d22\u9636\u6bb5\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u68c0\u7d22\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u4e86\u5019\u9009\u96c6\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u65e0\u9700\u63a8\u7406\u7684LSR\u65b9\u6cd5\u6765\u51cf\u5c11\u67e5\u8be2\u7f16\u7801\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u91cd\u6392\u5e8f\u914d\u7f6e\u548c\u4f18\u5316\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u7387\uff0c\u6700\u7ec8\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u591a\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u5feb24\u500d\u4ee5\u4e0a\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u68c0\u7d22\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5b66\u4e60\u7684\u591a\u5411\u91cf\u8868\u793a\u5728\u73b0\u4ee3\u641c\u7d22\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u68c0\u7d22\u6548\u679c\uff0c\u4f46\u7531\u4e8e\u9010\u6807\u8bb0\u7ea7\u68c0\u7d22\u6210\u672c\u9ad8\u6602\u800c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u8bb8\u591a\u7cfb\u7edf\u91c7\u7528'\u805a\u96c6-\u7ec6\u5316'\u7b56\u7565\u4ee5\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u8fd9\u901a\u5e38\u9700\u8981\u5bf9\u5927\u578b\u6807\u8bb0\u7ea7\u522b\u7d22\u5f15\u8fdb\u884c\u6602\u8d35\u641c\u7d22\u4e14\u5bb9\u6613\u9519\u8fc7\u6700\u4f73\u5339\u914d\u6587\u6863\u3002", "method": "\u7814\u7a76\u8005\u4eec\u9996\u5148\u590d\u73b0\u4e86\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u591a\u5411\u91cf\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u89c2\u5bdf\u5230\u6807\u8bb0\u7ea7\u805a\u96c6\u9636\u6bb5\u7684\u4f4e\u6548\u6027\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u63d0\u51fa\u4f7f\u7528\u5355\u5411\u91cf\u6587\u6863\u68c0\u7d22\u5668\uff08\u5373\u5b66\u4e60\u7a00\u758f\u68c0\u7d22\u5668LSR\uff09\u66ff\u4ee3\u539f\u6709\u7684\u6807\u8bb0\u7ea7\u805a\u96c6\u6b65\u9aa4\uff0c\u5f62\u6210\u4e00\u4e2a\u66f4\u4e3a\u7d27\u51d1\u4e14\u8bed\u4e49\u8fde\u8d2f\u7684\u5019\u9009\u96c6\u5408\u3002\u9488\u5bf9\u7531\u6b64\u4ea7\u751f\u7684\u65b0\u74f6\u9888\u2014\u2014\u53cc\u795e\u7ecf\u7f16\u7801\u5668\u7684\u67e5\u8be2\u7f16\u7801\u8fc7\u7a0b\uff0c\u7814\u7a76\u56e2\u961f\u91c7\u7528\u4e86\u6700\u8fd1\u53d1\u5c55\u7684\u65e0\u63a8\u7406LSR\u6280\u672f\u6765\u7f13\u89e3\u95ee\u9898\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u8fdb\u4e00\u6b65\u4f18\u5316\u6574\u4e2a\u6d41\u7a0b\uff0c\u4f5c\u8005\u63a2\u7d22\u4e86\u591a\u79cd\u91cd\u65b0\u6392\u540d\u8bbe\u7f6e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u80fd\u591f\u53ca\u65e9\u6392\u9664\u4f4e\u8d28\u91cf\u5019\u9009\u8005\u7684\u4f18\u5316\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u68c0\u7d22\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u5c06\u6548\u7387\u63d0\u9ad8\u81f31.8\u500d\u3002\u603b\u4f53\u800c\u8a00\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u591a\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\uff0c\u8fd9\u79cd\u4e24\u9636\u6bb5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc724\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u540c\u751a\u81f3\u66f4\u597d\u7684\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u5411\u91cf\u68c0\u7d22\u4e2d\u5b58\u5728\u7684\u9ad8\u6210\u672c\u4e0e\u4f4e\u6548\u7387\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u7a00\u758f\u68c0\u7d22\u5668\u548c\u5176\u4ed6\u4f18\u5316\u63aa\u65bd\uff0c\u4e0d\u4ec5\u5927\u5e45\u5ea6\u63d0\u9ad8\u4e86\u68c0\u7d22\u901f\u5ea6\uff0c\u540c\u65f6\u4e5f\u786e\u4fdd\u4e86\u9ad8\u8d28\u91cf\u7684\u68c0\u7d22\u7ed3\u679c\u3002"}}
{"id": "2601.04283", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04283", "abs": "https://arxiv.org/abs/2601.04283", "authors": ["Nikolay Yudin"], "title": "Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity", "comment": null, "summary": "Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions (\"position shift\") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.", "AI": {"tldr": "\u672c\u7814\u7a76\u5173\u6ce8\u5b57\u7b26\u7ea7Transformer\u5728\u8ba1\u7b97\u6587\u672c\u4e2d\u7684\u6a21\u52a0\u8fd0\u7b97\u65f6\u5bf9\u8f93\u5165\u683c\u5f0f\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5206\u5e03\u5185\u51c6\u786e\u5ea6\u3002\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u5206\u5e03\u5185\u51c6\u786e\u5ea6\uff0c\u5728\u9762\u5bf9\u4f4d\u7f6e\u504f\u79fb\u6216\u8d85\u51fa\u5206\u5e03\u7684\u81ea\u7136\u8bed\u8a00\u6a21\u677f\u65f6\u4ecd\u53ef\u80fd\u5931\u8d25\u3002\u4e3a\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u660e\u786e\u8868\u8fbe\u8fb9\u754c\u6807\u8bb0\u3001\u4f4d\u7f6e\u8bfe\u7a0b\u3001\u591a\u6837\u6a21\u677f\u6df7\u5408\u53ca\u4e00\u81f4\u6027\u8bad\u7ec3\u7684\u65b0\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u4e8e\u4f4d\u7f6e\u504f\u79fb\u548c\u6a21\u677f\u5206\u5e03\u5916\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u5206\u5e03\u5185\u51c6\u786e\u5ea6\u3002", "motivation": "\u7814\u7a76\u8005\u6ce8\u610f\u5230\u5148\u524d\u88ab\u5ffd\u89c6\u7684\u4e00\u79cd\u5931\u6548\u6a21\u5f0f\uff1a\u5373\u5c3d\u7ba1\u6a21\u578b\u80fd\u5728\u7ed9\u5b9a\u6570\u636e\u5206\u5e03\u4e0b\u8fbe\u5230\u5f88\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u4f46\u5f53\u76f8\u540c\u7684\u8868\u8fbe\u5f0f\u79fb\u52a8\u5230\u4e0d\u540c\u7684\u7edd\u5bf9\u5b57\u7b26\u4f4d\u7f6e\uff08\u4f4d\u7f6e\u504f\u79fb\uff09\u6216\u8005\u4ee5\u4e0d\u540c\u5bfb\u5e38\u7684\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u5448\u73b0\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u4f1a\u4e25\u91cd\u5931\u8d25\u3002\u8fd9\u79cd\u89c2\u5bdf\u4fc3\u4f7f\u7814\u7a76\u56e2\u961f\u63a2\u7d22\u5982\u4f55\u589e\u5f3a\u6a21\u578b\u5728\u9762\u5bf9\u8f93\u5165\u683c\u5f0f\u53d8\u5316\u65f6\u7684\u8868\u73b0\u529b\u3002", "method": "1. \u4f7f\u7528\u4e86\u663e\u5f0f\u7684\u8868\u8fbe\u8fb9\u754c\u6807\u8bb0\u6765\u5e2e\u52a9\u6a21\u578b\u8bc6\u522b\u6709\u6548\u4fe1\u606f\u3002\n2. \u901a\u8fc7\u4f4d\u7f6e\u8bfe\u7a0b\u9010\u6e10\u6269\u5927\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u7edd\u5bf9\u4f4d\u7f6e\u8303\u56f4\u3002\n3. \u5f15\u5165\u591a\u79cd\u4e0d\u540c\u7684\u6a21\u677f\u6df7\u5408\u7b56\u7565\u589e\u52a0\u591a\u6837\u6027\u3002\n4. \u5bf9\u6bcf\u4e2a\u793a\u4f8b\u7684\u4e0d\u540c\u53d8\u4f53\u5b9e\u65bd\u4e00\u81f4\u6027\u8bad\u7ec3\uff0c\u4ee5\u4fc3\u8fdb\u6a21\u578b\u5b66\u4e60\u4e0d\u53d8\u6027\u7279\u5f81\u3002", "result": "\u7ecf\u8fc7\u4e0a\u8ff0\u5e72\u9884\u63aa\u65bd\u540e\uff0c\u6a21\u578b\u4e0d\u4ec5\u7ef4\u6301\u4e86\u9ad8\u6c34\u5e73\u7684\u5206\u5e03\u5185\u51c6\u786e\u6027\uff0c\u800c\u4e14\u5728\u5904\u7406\u4f4d\u7f6e\u504f\u79fb\u548c\u8d85\u51fa\u5206\u5e03\u7684\u6a21\u677f\u65f6\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u63d0\u5347\u7684\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u91c7\u7528ALiBi\u98ce\u683c\u7684\u65b9\u6cd5\u5728\u8fd9\u79cd\u8bbe\u7f6e\u4e0b\u65e0\u6cd5\u6210\u529f\u5b8c\u6210\u4efb\u52a1\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u76d1\u7763\u4fe1\u53f7\u4e2d\u539f\u672c\u7f3a\u5931\u7684\u4e0d\u53d8\u6027\u8fdb\u884c\u663e\u5f0f\u8bad\u7ec3\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u6307\u5bfc\u7a0b\u5e8f\u5316\u6cdb\u5316\u8fc7\u7a0b\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8bc4\u4f30\u534f\u8bae\u53ca\u5176\u5b9e\u9a8c\u6750\u6599\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u5de5\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.04297", "categories": ["cs.LG", "cs.CV", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04297", "abs": "https://arxiv.org/abs/2601.04297", "authors": ["Behrad Binaei-Haghighi", "Nafiseh Sadat Sajadi", "Mehrad Liviyan", "Reyhane Akhavan Kharazi", "Fatemeh Amirkhani", "Behnam Bahrak"], "title": "ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues", "comment": "12 pages, 7 figures", "summary": "The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aArtCognition\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u6570\u5b57\u7ed8\u753b\u4e2d\u7684\u9759\u6001\u89c6\u89c9\u7279\u5f81\u548c\u52a8\u6001\u884c\u4e3a\u8fd0\u52a8\u7ebf\u7d22\u6765\u81ea\u52a8\u5206\u6790\u5e7f\u6cdb\u4f7f\u7528\u7684\u5fc3\u7406\u6d4b\u8bd5\u2014\u2014\u5c4b\u6811\u4eba(HTP)\u6d4b\u8bd5\u3002\u8be5\u7814\u7a76\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u67b6\u6784\u5c06\u4f4e\u7ea7\u7279\u5f81\u4e0e\u9ad8\u7ea7\u5fc3\u7406\u89e3\u91ca\u8054\u7cfb\u8d77\u6765\uff0c\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u5e76\u51cf\u5c11\u4e86\u6a21\u578b\u5e7b\u89c9\u7684\u53ef\u80fd\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u884c\u4e3a\u8fd0\u52a8\u7ebf\u7d22\u53ef\u4ee5\u6bd4\u5355\u72ec\u4f7f\u7528\u4efb\u4f55\u4e00\u79cd\u6a21\u6001\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u8bc4\u4f30\uff0c\u5e76\u4e14\u6240\u63d0\u53d6\u7684\u591a\u6a21\u6001\u7279\u5f81\u4e0e\u6807\u51c6\u5316\u5fc3\u7406\u6307\u6807\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u76f8\u5173\u6027\uff0c\u8fd9\u8868\u660e\u8be5\u6846\u67b6\u4f5c\u4e3a\u652f\u6301\u4e34\u5e8a\u533b\u751f\u7684\u53ef\u6269\u5c55\u5de5\u5177\u6709\u6f5c\u529b\u3002", "motivation": "\u5bf9\u4eba\u7c7b\u60c5\u611f\u548c\u5fc3\u7406\u72b6\u6001\u8fdb\u884c\u5ba2\u89c2\u8bc4\u4f30\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u975e\u8bed\u8a00\u6e20\u9053\u4e0a\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6570\u5b57\u7ed8\u753b\u4f5c\u4e3a\u4e00\u79cd\u4e30\u5bcc\u4f46\u672a\u5145\u5206\u5f00\u53d1\u7684\u60c5\u611f\u611f\u77e5\u6a21\u5f0f\uff0c\u5e76\u4e3a\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4ee5\u671f\u4e3a\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86ArtCognition\u6846\u67b6\uff0c\u5b83\u6574\u5408\u4e86\u4ece\u6700\u7ec8\u827a\u672f\u4f5c\u54c1\u4e2d\u6355\u6349\u5230\u7684\u9759\u6001\u89c6\u89c9\u7279\u5f81\uff08\u7531\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u5b9e\u73b0\uff09\u4ee5\u53ca\u76f4\u63a5\u4ece\u7ed8\u56fe\u8fc7\u7a0b\u4e2d\u83b7\u53d6\u7684\u52a8\u6001\u884c\u4e3a\u8fd0\u52a8\u7ebf\u7d22\uff08\u5982\u7b14\u753b\u901f\u5ea6\u3001\u505c\u987f\u548c\u6d41\u7545\u5ea6\uff09\u3002\u4e3a\u4e86\u8fde\u63a5\u4f4e\u7ea7\u522b\u7279\u5f81\u4e0e\u9ad8\u7ea7\u522b\u5fc3\u7406\u89e3\u8bfb\uff0c\u91c7\u7528\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u67b6\u6784\uff0c\u4ee5\u4fbf\u57fa\u4e8e\u5df2\u5efa\u7acb\u7684\u5fc3\u7406\u5b66\u77e5\u8bc6\u57fa\u7840\u6765\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u89c6\u89c9\u4e0e\u884c\u4e3a\u8fd0\u52a8\u7ebf\u7d22\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u80fd\u591f\u63d0\u4f9b\u6bd4\u5355\u72ec\u4efb\u4e00\u6a21\u6001\u66f4\u52a0\u7ec6\u81f4\u5165\u5fae\u7684\u8bc4\u4f30\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u63d0\u53d6\u51fa\u7684\u591a\u6a21\u6001\u7279\u5f81\u4e0e\u6807\u51c6\u5fc3\u7406\u5b66\u91cf\u8868\u4e4b\u95f4\u5b58\u5728\u7740\u663e\u8457\u7684\u76f8\u5173\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u4f5c\u4e3a\u8f85\u52a9\u4e34\u5e8a\u5de5\u4f5c\u8005\u5de5\u5177\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8d21\u732e\u4e86\u4e00\u79cd\u7528\u4e8e\u975e\u4fb5\u5165\u5f0f\u60c5\u611f\u72b6\u6001\u8bc4\u4f30\u7684\u65b0\u65b9\u6cd5\u8bba\uff0c\u5e76\u4e3a\u6280\u672f\u8f85\u52a9\u4e0b\u7684\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.04286", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04286", "abs": "https://arxiv.org/abs/2601.04286", "authors": ["Niklas Kueper", "Kartik Chari", "Elsa Andrea Kirchner"], "title": "Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles", "comment": null, "summary": "Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u5206\u7c7b\u5668\u96c6\u6210\u548c\u6ed1\u52a8\u7a97\u53e3\u540e\u5904\u7406\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u4eceEEG\u4fe1\u53f7\u4e2d\u5f02\u6b65\u68c0\u6d4b\u8fd0\u52a8\u610f\u56fe\u7684\u9c81\u68d2\u6027\u3002\u5728\u7ebf\u8bc4\u4f30\u4e2d\uff0c\u5206\u7c7b\u5668\u96c6\u6210\u6bd4\u5355\u4e2a\u6700\u4f73\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u9519\u8bef\u68c0\u6d4b\u3002", "motivation": "\u4e3a\u4e86\u6539\u5584\u4e2d\u98ce\u60a3\u8005\u5eb7\u590d\u6cbb\u7597\u7684\u6548\u679c\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8bc6\u522b\u60a3\u8005\u7684\u8fd0\u52a8\u610f\u56fe\u6765\u89e6\u53d1\u673a\u5668\u4eba\u8f85\u52a9\u88c5\u7f6e\u7684\u5e2e\u52a9\u3002\u8be5\u7814\u7a76\u7279\u522b\u5173\u6ce8\u4e8e\u5982\u4f55\u66f4\u51c6\u786e\u5730\u89e3\u7801\u4eba\u7c7b\u8868\u9762\u8111\u7535\u56fe\uff08EEG\uff09\u4fe1\u53f7\u4e2d\u7684\u8fd0\u52a8\u610f\u56fe\uff0c\u5c24\u5176\u662f\u5728\u5728\u7ebf\u548c\u5f02\u6b65\u6761\u4ef6\u4e0b\u8fdb\u884c\u5206\u7c7b\u65f6\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u5206\u6790\u4e86\u5305\u542b14\u540d\u5065\u5eb7\u53d7\u8bd5\u8005\u7684\u4e24\u4e2aEEG\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u53d7\u8bd5\u8005\u6267\u884c\u4e86\u81ea\u53d1\u8d77\u7684\u624b\u81c2\u8fd0\u52a8\u3002\u91c7\u7528\u4e86\u652f\u6301\u5411\u91cf\u673a(SVM)\u3001\u591a\u5c42\u611f\u77e5\u5668(MLP)\u4ee5\u53caEEGNet\u5206\u7c7b\u6a21\u578b\u7684\u96c6\u6210\u7ec4\u5408\uff0c\u5e76\u8fdb\u884c\u4e86\u79bb\u7ebf\u4e0e\u4f2a\u5728\u7ebf\u8bc4\u4f30\u4ee5\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u6ed1\u52a8\u7a97\u53e3\u540e\u5904\u7406\u6280\u672f\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u4f2a\u5728\u7ebf\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6700\u4f18\u6570\u91cf\u7684\u540e\u5904\u7406\u7a97\u53e3\u4e0b\uff0c\u4e24\u79cd\u6a21\u578b\u96c6\u6210\u65b9\u6848\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6700\u4f73\u6a21\u578b\u3002\u5bf9\u4e8e\u5355\u4e2a\u6a21\u578b\u6765\u8bf4\uff0c\u589e\u52a0\u540e\u5904\u7406\u7a97\u53e3\u7684\u6570\u91cf\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002\u4f46\u5728\u7ebf\u4e0b\u8bc4\u4f30\u4e2d\uff0c\u6700\u4f73\u5355\u4e00\u6a21\u578b\u4e0e\u5206\u7c7b\u5668\u96c6\u6210\u4e4b\u95f4\u6ca1\u6709\u89c2\u5bdf\u5230\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5206\u7c7b\u5668\u96c6\u6210\u52a0\u4e0a\u9002\u5f53\u7684\u540e\u5904\u7406\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u4eceEEG\u4fe1\u53f7\u4e2d\u5f02\u6b65\u68c0\u6d4b\u8fd0\u52a8\u610f\u56fe\u7684\u80fd\u529b\u3002\u5c24\u5176\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u7ebf\u5206\u7c7b\u65b9\u9762\uff0c\u5206\u7c7b\u5668\u96c6\u6210\u6bd4\u7ebf\u4e0b\u5206\u7c7b\u8868\u73b0\u51fa\u66f4\u5927\u7684\u6539\u8fdb\uff0c\u5e76\u4e14\u6709\u52a9\u4e8e\u51cf\u5c11\u63d0\u524d\u8bef\u62a5\u7684\u60c5\u51b5\u3002"}}
{"id": "2601.04287", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.04287", "abs": "https://arxiv.org/abs/2601.04287", "authors": ["Ben Carvell", "George De Ath", "Eseoghene Benjamin", "Richard Everson"], "title": "Online Action-Stacking Improves Reinforcement Learning Performance for Air Traffic Control", "comment": null, "summary": "We introduce online action-stacking, an inference-time wrapper for reinforcement learning policies that produces realistic air traffic control commands while allowing training on a much smaller discrete action space. Policies are trained with simple incremental heading or level adjustments, together with an action-damping penalty that reduces instruction frequency and leads agents to issue commands in short bursts. At inference, online action-stacking compiles these bursts of primitive actions into domain-appropriate compound clearances. Using Proximal Policy Optimisation and the BluebirdDT digital twin platform, we train agents to navigate aircraft along lateral routes, manage climb and descent to target flight levels, and perform two-aircraft collision avoidance under a minimum separation constraint. In our lateral navigation experiments, action stacking greatly reduces the number of issued instructions relative to a damped baseline and achieves comparable performance to a policy trained with a 37-dimensional action space, despite operating with only five actions. These results indicate that online action-stacking helps bridge a key gap between standard reinforcement learning formulations and operational ATC requirements, and provides a simple mechanism for scaling to more complex control scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u7684\u65b9\u6cd5\uff0c\u5b83\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u63a8\u7406\u65f6\u95f4\u5c01\u88c5\u5668\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u8f83\u5c0f\u7684\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4ea7\u751f\u73b0\u5b9e\u7684\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u6307\u4ee4\u3002\u901a\u8fc7\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u548cBluebirdDT\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u6267\u884c\u822a\u7ebf\u5bfc\u822a\u3001\u722c\u5347\u4e0e\u4e0b\u964d\u7ba1\u7406\u4ee5\u53ca\u4e24\u673a\u9632\u649e\u7b49\u4efb\u52a1\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4fa7\u5411\u5bfc\u822a\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u53d1\u51fa\u7684\u6307\u4ee4\u6570\u91cf\uff0c\u5e76\u4e14\u5c3d\u7ba1\u53ea\u4f7f\u7528\u4e86\u4e94\u4e2a\u52a8\u4f5c\uff0c\u4f46\u5176\u6027\u80fd\u53ef\u4e0e\u4f7f\u752837\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u8bad\u7ec3\u7684\u7b56\u7565\u76f8\u5ab2\u7f8e\u3002", "motivation": "\u4e3a\u4e86\u5728\u4fdd\u6301\u64cd\u4f5c\u5b9e\u9645\u6027\u7684\u540c\u65f6\u7b80\u5316\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\uff08ATC\uff09\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u7684\u6280\u672f\uff0c\u5141\u8bb8\u5728\u8f83\u5c0f\u7684\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u540c\u65f6\u751f\u6210\u7b26\u5408\u9886\u57df\u9700\u6c42\u7684\u590d\u5408\u8bb8\u53ef\u547d\u4ee4\u3002", "method": "\u91c7\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u7ed3\u5408BluebirdDT\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u5b8c\u6210\u6cbf\u7740\u9884\u5b9a\u8def\u7ebf\u5bfc\u822a\u98de\u673a\u3001\u7ba1\u7406\u81f3\u76ee\u6807\u98de\u884c\u9ad8\u5ea6\u5c42\u7684\u722c\u5347\u4e0e\u4e0b\u964d\u8fc7\u7a0b\u4ee5\u53ca\u6ee1\u8db3\u6700\u5c0f\u95f4\u9694\u7ea6\u675f\u4e0b\u7684\u53cc\u673a\u907f\u78b0\u4efb\u52a1\u3002\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5229\u7528\u7b80\u5355\u7684\u589e\u91cf\u822a\u5411\u6216\u9ad8\u5ea6\u8c03\u6574\u52a0\u4e0a\u4e00\u4e2a\u52a8\u4f5c\u963b\u5c3c\u60e9\u7f5a\u6765\u51cf\u5c11\u6307\u4ee4\u9891\u7387\u3002", "result": "\u5728\u4fa7\u5411\u5bfc\u822a\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u8f83\u4e8e\u57fa\u7840\u7248\u672c\uff0c\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u5927\u5e45\u964d\u4f4e\u4e86\u6240\u9700\u53d1\u51fa\u7684\u6307\u4ee4\u6570\u91cf\uff0c\u5e76\u4e14\u5373\u4f7f\u53ea\u6709\u4e94\u4e2a\u57fa\u672c\u52a8\u4f5c\u9009\u9879\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u4e8e\u4f7f\u752837\u4e2a\u7ef4\u5ea6\u52a8\u4f5c\u7a7a\u95f4\u8bad\u7ec3\u51fa\u6a21\u578b\u7684\u6548\u679c\u3002", "conclusion": "\u5728\u7ebf\u52a8\u4f5c\u5806\u53e0\u6709\u52a9\u4e8e\u586b\u8865\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u4e0e\u5b9e\u9645ATC\u9700\u6c42\u4e4b\u95f4\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u4e3a\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u63a7\u5236\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u673a\u5236\u3002"}}
{"id": "2601.04299", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.04299", "abs": "https://arxiv.org/abs/2601.04299", "authors": ["Pir Bakhsh Khokhar", "Carmine Gravino", "Fabio Palomba", "Sule Yildrim Yayilgan", "Sarang Shaikh"], "title": "Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes", "comment": null, "summary": "Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\u6570\u636e\u548c\u5b9e\u9a8c\u5ba4\u68c0\u6d4b\u7ed3\u679c\uff0c\u4ee5\u8bc6\u522b1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u7684\u4ee3\u8c22\u8868\u578b\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u7814\u7a76\u8005\u4eec\u53d1\u73b0\u4e86\u4e94\u79cd\u6f5c\u5728\u7684\u4ee3\u8c22\u8868\u578b\uff0c\u5e76\u4e14\u8fd9\u4e9b\u8868\u578b\u4e0e\u9ad8\u8840\u538b\u3001\u5fc3\u808c\u6897\u6b7b\u548c\u5fc3\u529b\u8870\u7aed\u6709\u7edf\u8ba1\u5b66\u4e0a\u663e\u8457\u4f46\u9002\u5ea6\u7684\u5173\u8054\u3002", "motivation": "1\u578b\u7cd6\u5c3f\u75c5\u662f\u4e00\u79cd\u4ee3\u8c22\u9ad8\u5ea6\u5f02\u8d28\u6027\u7684\u75be\u75c5\uff0c\u4f20\u7edf\u7684\u751f\u7269\u6807\u5fd7\u7269\u5982\u7cd6\u5316\u8840\u7ea2\u86cb\u767d\uff08HbA1c\uff09\u4e0d\u8db3\u4ee5\u5145\u5206\u63cf\u8ff0\u5176\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u7406\u89e3\u4e2a\u4f53\u95f4\u7684\u4ee3\u8c22\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6574\u5408\u8fde\u7eed\u8840\u7cd6\u76d1\u6d4b\uff08CGM\uff09\u6570\u636e\u548c\u5b9e\u9a8c\u5ba4\u68c0\u67e5\u8d44\u6599\uff0c\u4f7f\u7528Transformer\u7f16\u7801\u5668\u5efa\u6a21\u8de8\u6a21\u6001\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8bc6\u522b\u6f5c\u5728\u7684\u4ee3\u8c22\u8868\u578b\u3002\u5229\u7528Transformer\u6ce8\u610f\u529b\u53ef\u89c6\u5316\u548c\u57fa\u4e8eSHAP\u7684\u65b9\u6cd5\u5b9e\u73b0\u6a21\u578b\u89e3\u91ca\u6027\u3002", "result": "\u5728577\u540d1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u4e2d\u786e\u5b9a\u4e86\u4e94\u4e2a\u4ece\u4ee3\u8c22\u7a33\u5b9a\u5230\u5fc3\u8840\u7ba1\u4ee3\u8c22\u98ce\u9669\u5347\u9ad8\u7684\u6f5c\u5728\u4ee3\u8c22\u8868\u578b\u3002\u8fd9\u4e9b\u8868\u578b\u5177\u6709\u4e0d\u540c\u7684\u751f\u5316\u7279\u5f81\uff0c\u5305\u62ec\u8840\u7cd6\u63a7\u5236\u3001\u8102\u8d28\u4ee3\u8c22\u3001\u80be\u529f\u80fd\u6307\u6807\u53ca\u4fc3\u7532\u72b6\u817a\u6fc0\u7d20\u6c34\u5e73\u7b49\u65b9\u9762\u7684\u4e0d\u540c\u3002\u6ce8\u610f\u529b\u5206\u6790\u8868\u660e\u8461\u8404\u7cd6\u53d8\u5f02\u6027\u662f\u4e3b\u8981\u7684\u65f6\u95f4\u56e0\u7d20\uff1b\u800cSHAP\u5206\u6790\u5219\u6307\u51faHbA1c\u3001\u7518\u6cb9\u4e09\u916f\u3001\u80c6\u56fa\u9187\u3001\u808c\u9150\u4ee5\u53caTSH\u662f\u5bf9\u8868\u578b\u533a\u5206\u7684\u91cd\u8981\u8d21\u732e\u8005\u3002\u8868\u578b\u6210\u5458\u8d44\u683c\u663e\u793a\u51fa\u4e0e\u9ad8\u8840\u538b\u3001\u5fc3\u808c\u6897\u585e\u548c\u5fc3\u529b\u8870\u7aed\u4e4b\u95f4\u5b58\u5728\u7edf\u8ba1\u5b66\u610f\u4e49\u4f46\u7a0b\u5ea6\u8f7b\u5fae\u7684\u8054\u7cfb\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u65f6\u95f4\u5d4c\u5165\u6846\u67b6\u80fd\u591f\u63ed\u793a1\u578b\u7cd6\u5c3f\u75c5\u4e2d\u751f\u7406\u4e00\u81f4\u7684\u4ee3\u8c22\u4e9a\u7fa4\uff0c\u5e76\u652f\u6301\u8d85\u51fa\u5355\u4e00\u751f\u7269\u6807\u8bb0\u7684\u98ce\u9669\u5206\u5c42\u3002"}}
{"id": "2601.04361", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04361", "abs": "https://arxiv.org/abs/2601.04361", "authors": ["Mohammad Ali Javidian"], "title": "Causally-Aware Information Bottleneck for Domain Adaptation", "comment": "An extended abstract version of this work was accepted for the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u56e0\u679c\u7cfb\u7edf\u4e2d\u5904\u7406\u57df\u9002\u5e94\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u7d27\u51d1\u4e14\u673a\u5236\u7a33\u5b9a\u7684\u8868\u793a\u6765\u9884\u6d4b\u76ee\u6807\u53d8\u91cf\u3002\u5bf9\u4e8e\u7ebf\u6027\u9ad8\u65af\u56e0\u679c\u6a21\u578b\u63d0\u4f9b\u4e86\u95ed\u5f0f\u89e3\uff0c\u5e76\u4e3a\u975e\u7ebf\u6027\u6216\u975e\u9ad8\u65af\u6570\u636e\u5f15\u5165\u4e86\u53d8\u5206\u4fe1\u606f\u74f6\u9888\u7f16\u7801\u5668-\u9884\u6d4b\u5668\u65b9\u6cd5\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u663e\u793a\u51fa\u51c6\u786e\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u56e0\u679c\u7cfb\u7edf\u4e2d\u7684\u4e00\u4e2a\u5e38\u89c1\u57df\u9002\u5e94\u95ee\u9898\uff0c\u5373\u76ee\u6807\u53d8\u91cf\u5728\u6e90\u57df\u4e2d\u6709\u89c2\u5bdf\u503c\u4f46\u5728\u76ee\u6807\u57df\u4e2d\u5b8c\u5168\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u4ece\u5269\u4f59\u89c2\u5bdf\u53d8\u91cf\u4e2d\u9884\u6d4b\u76ee\u6807\u53d8\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7d27\u51d1\u4e14\u673a\u5236\u7a33\u5b9a\u8868\u793a\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff1b\u9488\u5bf9\u7ebf\u6027\u9ad8\u65af\u56e0\u679c\u6a21\u578b\u7ed9\u51fa\u4e86\u95ed\u5f0fGaussian Information Bottleneck (GIB) \u89e3\u51b3\u65b9\u6848\uff1b\u5bf9\u4e8e\u975e\u7ebf\u6027\u548c/\u6216\u975e\u9ad8\u65af\u60c5\u51b5\uff0c\u5219\u63d0\u51fa\u4e86Variational Information Bottleneck (VIB) \u7f16\u7801\u5668-\u9884\u6d4b\u5668\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u79cd\u5408\u6210\u4e0e\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u5747\u80fd\u83b7\u5f97\u51c6\u786e\u7684\u76ee\u6807\u53d8\u91cf\u9884\u6d4b\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u53ca\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u8f7b\u91cf\u7ea7\u5de5\u5177\u5305\u7528\u4e8e\u56e0\u679c\u57df\u9002\u5e94\u4efb\u52a1\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u91cd\u8981\u4fe1\u606f\u7684\u540c\u65f6\u53bb\u9664\u65e0\u5173\u53d8\u5316\uff0c\u652f\u6301\u9ad8\u7ef4\u56e0\u679c\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.04366", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.04366", "abs": "https://arxiv.org/abs/2601.04366", "authors": ["Selcuk Koyuncu", "Ronak Nouri", "Stephen Providence"], "title": "Machine Learning Model for Sparse PCM Completion", "comment": null, "summary": "In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7a00\u758f\u6210\u5bf9\u6bd4\u8f83\u77e9\u9635(PCM)\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u7ecf\u5178\u7684PCM\u65b9\u6cd5\u548c\u57fa\u4e8e\u56fe\u7684\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u7a00\u758f\u6210\u5bf9\u6bd4\u8f83\u77e9\u9635\u5904\u7406\u4e0a\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5229\u7528\u7ecf\u5178PCM\u65b9\u6cd5\u548c\u73b0\u4ee3\u57fa\u4e8e\u56fe\u7684\u5b66\u4e60\u6280\u672f\u7684\u4f18\u52bf\u3002", "method": "\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6574\u5408\u4e86\u4f20\u7edf\u7684PCM\u6280\u672f\u548c\u57fa\u4e8e\u56fe\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6709\u6548\u6027\u53ca\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e3a\u7a00\u758fPCM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04392", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.04392", "abs": "https://arxiv.org/abs/2601.04392", "authors": ["Mohsen Jalaeian-Farimani"], "title": "Enhanced-FQL($\u03bb$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay", "comment": "Submitted to ECC26 conference", "summary": "This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($\u03bb$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($\u03bb$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($\u03bb$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u7cca\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Enhanced-FQL(\u03bb)\uff0c\u901a\u8fc7\u7ed3\u5408\u65b0\u9896\u7684\u6a21\u7cca\u8d44\u683c\u8ff9(FET)\u548c\u5206\u6bb5\u7ecf\u9a8c\u56de\u653e(SER)\u673a\u5236\uff0c\u63d0\u9ad8\u4e86\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u65b9\u5dee\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8f83\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u7406\u8bba\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u5e76\u4e14\u7531\u4e8e\u5176\u56fa\u6709\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7279\u522b\u6709\u7528\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6a21\u7ccaQ\u5b66\u4e60\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u63d0\u4f9b\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u7cca\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Enhanced-FQL(\u03bb)\uff0c\u5b83\u5c06\u6a21\u7cca\u8d44\u683c\u8ff9\uff08FET\uff09\u4e0e\u5206\u6bb5\u7ecf\u9a8c\u56de\u653e\uff08SER\uff09\u6574\u5408\u8fdb\u57fa\u4e8e\u6a21\u7cca\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff08FBE\uff09\u7684\u6a21\u7ccaQ\u5b66\u4e60\u4e2d\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u76f8\u8f83\u4e8en\u6b65\u6a21\u7ccaTD\u548c\u6a21\u7ccaSARSA(\u03bb)\u57fa\u7ebf\u7b97\u6cd5\uff0cEnhanced-FQL(\u03bb)\u5728\u8fde\u7eed\u63a7\u5236\u9886\u57df\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\u548c\u66f4\u4f4e\u7684\u65b9\u5dee\uff0c\u540c\u65f6\u76f8\u6bd4\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982DDPG\u62e5\u6709\u663e\u8457\u66f4\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "Enhanced-FQL(\u03bb)\u4e0d\u4ec5\u5728\u6837\u672c\u6548\u7387\u548c\u964d\u4f4e\u65b9\u5dee\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u56e0\u5176\u5185\u5728\u7684\u53ef\u89e3\u91ca\u6027\u548c\u7406\u8bba\u4e0a\u7684\u6536\u655b\u6027\u8bc1\u660e\uff0c\u975e\u5e38\u9002\u5408\u5e94\u7528\u4e8e\u90a3\u4e9b\u9700\u8981\u900f\u660e\u5ea6\u548c\u53d7\u9650\u8d44\u6e90\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\u3002"}}
{"id": "2601.04411", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04411", "abs": "https://arxiv.org/abs/2601.04411", "authors": ["Ali Rad", "Khashayar Filom", "Darioush Keivan", "Peyman Mohajerin Esfahani", "Ehsan Kamalinejad"], "title": "Rate or Fate? RLV$^\\varepsilon$R: Reinforcement Learning with Verifiable Noisy Rewards", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) is a simple but powerful paradigm for training LLMs: sample a completion, verify it, and update. In practice, however, the verifier is almost never clean--unit tests probe only limited corner cases; human and synthetic labels are imperfect; and LLM judges (e.g., RLAIF) are noisy and can be exploited--and this problem worsens on harder domains (especially coding) where tests are sparse and increasingly model-generated. We ask a pragmatic question: does the verification noise merely slow down the learning (rate), or can it flip the outcome (fate)?\n  To address this, we develop an analytically tractable multi-armed bandit view of RLVR dynamics, instantiated with GRPO and validated in controlled experiments. Modeling false positives and false negatives and grouping completions into recurring reasoning modes yields a replicator-style (natural-selection) flow on the probability simplex. The dynamics decouples into within-correct-mode competition and a one-dimensional evolution for the mass on incorrect modes, whose drift is determined solely by Youden's index J=TPR-FPR. This yields a sharp phase transition: when J>0, the incorrect mass is driven toward extinction (learning); when J=0, the process is neutral; and when J<0, incorrect modes amplify until they dominate (anti-learning and collapse). In the learning regime J>0, noise primarily rescales convergence time (\"rate, not fate\"). Experiments on verifiable programming tasks under synthetic noise reproduce the predicted J=0 boundary. Beyond noise, the framework offers a general lens for analyzing RLVR stability, convergence, and algorithmic interventions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u5956\u52b1\u9a8c\u8bc1\u5b58\u5728\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\uff0c\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u5b66\u4e60\u6548\u679c\u3002\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u591a\u81c2\u8d4c\u535a\u673a\u7684\u5206\u6790\u6846\u67b6\u6765\u7814\u7a76RLVR\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u566a\u58f0\u4e3b\u8981\u5f71\u54cd\u6536\u655b\u65f6\u95f4\uff08\u901f\u7387\u800c\u975e\u7ed3\u679c\uff09\u3002\u5f53Youden\u6307\u6570J>0\u65f6\uff0c\u7cfb\u7edf\u8d8b\u5411\u4e8e\u5b66\u4e60\uff1bJ=0\u65f6\uff0c\u8fc7\u7a0b\u662f\u4e2d\u6027\u7684\uff1bJ<0\u65f6\uff0c\u5219\u4f1a\u51fa\u73b0\u53cd\u5b66\u4e60\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5b9e\u9645\u5e94\u7528\u4e2d\u5956\u52b1\u9a8c\u8bc1\u4e0d\u7eaf\u51c0\u7684\u95ee\u9898\uff0c\u5373\u5355\u4f4d\u6d4b\u8bd5\u3001\u4eba\u5de5\u548c\u5408\u6210\u6807\u7b7e\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u90fd\u5b58\u5728\u7f3a\u9677\uff0c\u5c24\u5176\u662f\u5728\u7f16\u7801\u7b49\u590d\u6742\u9886\u57df\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u8fd9\u79cd\u9a8c\u8bc1\u566a\u58f0\u662f\u5426\u4ec5\u51cf\u6162\u5b66\u4e60\u901f\u5ea6\uff0c\u8fd8\u662f\u80fd\u591f\u6539\u53d8\u6700\u7ec8\u5b66\u4e60\u7ed3\u679c\u3002", "method": "\u91c7\u7528\u591a\u81c2\u8d4c\u535a\u673a\u89c6\u89d2\u5bf9RLVR\u52a8\u6001\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u7528GRPO\u65b9\u6cd5\u5b9e\u4f8b\u5316\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002\u901a\u8fc7\u6a21\u62df\u5047\u9633\u6027\u548c\u5047\u9634\u6027\u60c5\u51b5\uff0c\u5e76\u5c06\u5b8c\u6210\u60c5\u51b5\u5206\u4e3a\u91cd\u590d\u51fa\u73b0\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u4ece\u800c\u5f97\u5230\u4e00\u4e2a\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u7684\u590d\u5236\u5f0f\u6d41\u52a8\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728J>0\u7684\u5b66\u4e60\u72b6\u6001\u4e0b\uff0c\u566a\u58f0\u4e3b\u8981\u4f5c\u7528\u4e8e\u8c03\u6574\u6536\u655b\u65f6\u95f4\u800c\u4e0d\u662f\u6539\u53d8\u5b66\u4e60\u7ed3\u5c40\u3002\u5b9e\u9a8c\u8fd8\u8868\u660e\uff0c\u5728\u5408\u6210\u566a\u58f0\u4e0b\u53ef\u9a8c\u8bc1\u7f16\u7a0b\u4efb\u52a1\u7684\u7ed3\u679c\u7b26\u5408\u9884\u671f\u7684J=0\u8fb9\u754c\u6761\u4ef6\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u4e3a\u5206\u6790RLVR\u7a33\u5b9a\u6027\u3001\u6536\u655b\u6027\u548c\u7b97\u6cd5\u5e72\u9884\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\u3002", "conclusion": "\u5bf9\u4e8e\u5e26\u6709\u9a8c\u8bc1\u566a\u58f0\u7684\u5f3a\u5316\u5b66\u4e60\u800c\u8a00\uff0c\u5173\u952e\u6307\u6807Youden\u6307\u6570J\u51b3\u5b9a\u4e86\u5b66\u4e60\u6216\u53cd\u5b66\u4e60\u7684\u53d1\u751f\u3002\u5f53J\u5927\u4e8e\u96f6\u65f6\uff0c\u5c3d\u7ba1\u5b58\u5728\u566a\u58f0\uff0c\u4f46\u6a21\u578b\u4ecd\u80fd\u6709\u6548\u5b66\u4e60\uff1b\u53cd\u4e4b\u5219\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u6a21\u5f0f\u653e\u5927\u76f4\u81f3\u4e3b\u5bfc\u3002"}}
{"id": "2601.04413", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04413", "abs": "https://arxiv.org/abs/2601.04413", "authors": ["Nausherwan Malik", "Zubair Khalid", "Muhammad Faryad"], "title": "Distribution-Guided and Constrained Quantum Machine Unlearning", "comment": "8 pages", "summary": "Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f15\u5bfc\u7684\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u5904\u7406\u7c7b\u522b\u7ea7\u522b\u7684\u6570\u636e\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5728\u4fdd\u7559\u6570\u636e\u4e0a\u7684\u9884\u6d4b\u884c\u4e3a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6291\u5236\u88ab\u9057\u5fd8\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\uff0c\u6700\u5c0f\u5316\u4fdd\u7559\u7c7b\u522b\u6027\u80fd\u7684\u4e0b\u964d\uff0c\u5e76\u4e14\u4e0e\u91cd\u65b0\u8bad\u7ec3\u7684\u6a21\u578b\u57fa\u51c6\u66f4\u52a0\u4e00\u81f4\u3002", "motivation": "\u73b0\u6709\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u9057\u5fd8\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u3001\u5747\u5300\u7684\u76ee\u6807\u5206\u5e03\uff0c\u4e14\u672a\u80fd\u660e\u786e\u63a7\u5236\u9057\u5fd8\u548c\u4fdd\u7559\u6a21\u578b\u884c\u4e3a\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u8c03\u8282\u7684\u76ee\u6807\u5206\u5e03\uff0c\u8be5\u5206\u5e03\u6765\u81ea\u4e8e\u6a21\u578b\u76f8\u4f3c\u6027\u7edf\u8ba1\uff0c\u5c06\u88ab\u9057\u5fd8\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u538b\u5236\u4e0e\u5bf9\u4fdd\u7559\u7c7b\u522b\u4e4b\u95f4\u518d\u5206\u914d\u7684\u5047\u8bbe\u89e3\u8026\u5f00\u6765\u3002\u6b64\u5916\uff0c\u8fd8\u52a0\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u951a\u70b9\u7684\u4fdd\u5b58\u7ea6\u675f\u6761\u4ef6\uff0c\u4ee5\u663e\u5f0f\u5730\u7ef4\u6301\u9009\u5b9a\u4fdd\u7559\u6570\u636e\u4e0a\u7684\u9884\u6d4b\u884c\u4e3a\u3002", "result": "\u901a\u8fc7Iris\u548cCovertype\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u53d8\u5206\u91cf\u5b50\u5206\u7c7b\u5668\u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8e\u88ab\u9057\u5fd8\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u6709\u660e\u663e\u7684\u6291\u5236\u4f5c\u7528\uff0c\u4fdd\u7559\u7c7b\u522b\u7684\u8868\u73b0\u51e0\u4e4e\u6ca1\u6709\u9000\u5316\uff0c\u5e76\u4e14\u6bd4\u4f7f\u7528\u7edf\u4e00\u76ee\u6807\u5206\u5e03\u7684\u9057\u5fd8\u65b9\u6cd5\u66f4\u63a5\u8fd1\u4e8e\u9ec4\u91d1\u91cd\u8bad\u7ec3\u6a21\u578b\u57fa\u7ebf\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u76ee\u6807\u8bbe\u8ba1\u4ee5\u53ca\u57fa\u4e8e\u7ea6\u675f\u6761\u4ef6\u516c\u5f0f\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u91cf\u5b50\u673a\u5668\u9057\u5fd8\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.04447", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04447", "abs": "https://arxiv.org/abs/2601.04447", "authors": ["Gal Fybish", "Teo Susnjak"], "title": "When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning", "comment": null, "summary": "Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix\" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8868\u73b0\u6027\u9884\u6d4b\u7684\u76f8\u5173\u6587\u732e\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a'\u8868\u73b0\u529b\u5f3a\u5ea6\u4e0e\u5f71\u54cd\u77e9\u9635'\u8bc4\u4f30\u6846\u67b6\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u8bc4\u4f30\u5176\u90e8\u7f72\u7684\u9884\u6d4b\u6a21\u578b\u7684\u8868\u73b0\u529b\u6f5c\u5728\u5f71\u54cd\u548c\u4e25\u91cd\u6027\uff0c\u5e76\u9009\u62e9\u9002\u5f53\u7684\u7b97\u6cd5\u6216\u4eba\u4e3a\u5e72\u9884\u6c34\u5e73\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u4f7f\u7528\u589e\u52a0\uff0c\u5b83\u4eec\u7684\u9884\u6d4b\u53ef\u80fd\u4f1a\u4e3b\u52a8\u5851\u9020\u6240\u5904\u73af\u5883\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u8868\u73b0\u6027\u9884\u6d4b\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u7cfb\u7edf\u5316\u77e5\u8bc6\uff08SoK\uff09\u6765\u7efc\u5408\u8fd9\u4e00\u73b0\u8c61\u7684\u6982\u5ff5\u5e76\u63d0\u4f9b\u5b9e\u9645\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u6587\u732e\u56de\u987e\uff0c\u672c\u6587\u6982\u8ff0\u4e86\u8868\u73b0\u6027\u4e3b\u8981\u4f53\u73b0\u673a\u5236\u3001\u76f8\u5173\u98ce\u9669\u7c7b\u578b\u4ee5\u53ca\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'\u8868\u73b0\u529b\u5f3a\u5ea6\u4e0e\u5f71\u54cd\u77e9\u9635'\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u2014\u2014'\u8868\u73b0\u529b\u5f3a\u5ea6\u4e0e\u5f71\u54cd\u77e9\u9635'\uff0c\u7528\u4ee5\u8f85\u52a9\u4ece\u4e1a\u8005\u66f4\u597d\u5730\u7406\u89e3\u548c\u5904\u7406\u6a21\u578b\u4e2d\u7684\u8868\u73b0\u6027\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u5173\u4e8e\u8868\u73b0\u6027\u9884\u6d4b\u7cfb\u7edf\u5316\u77e5\u8bc6\u6574\u7406\u53ca\u5b9e\u7528\u6307\u5357\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002"}}
{"id": "2601.04449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04449", "abs": "https://arxiv.org/abs/2601.04449", "authors": ["Daniel Sierra-Botero", "Ana Molina-Taborda", "Leonardo Espinosa-Leal", "Alexander Karpenko", "Alejandro Hernandez", "Olga Lopez-Acevedo"], "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries", "comment": "23 pages, 6 figures", "summary": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u6839\u636e\u60a3\u8005\u5165\u9662\u548c\u533b\u9662\u7ba1\u7406\u6570\u636e\u9884\u6d4b\u957f\u65f6\u95f4\u4f4f\u9662\uff08pLoS\uff09\uff0c\u901a\u8fc7\u9009\u62e9\u975e\u76f8\u5173\u4e14\u4fe1\u606f\u4ef7\u503c\u9ad8\u7684\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u3002\u5728\u9a8c\u8bc1\u961f\u5217\u4e2d\uff0c\u8be5\u6a21\u578b\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u51cf\u5c11\u957f\u65f6\u95f4\u4f4f\u9662\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002", "motivation": "\u957f\u65f6\u95f4\u4f4f\u9662\u4e0e\u4e0d\u826f\u9662\u5185\u4e8b\u4ef6\u7684\u98ce\u9669\u589e\u52a0\u6709\u5173\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7ba1\u7406\u548c\u51cf\u5c11\u957f\u65f6\u95f4\u4f4f\u9662\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u9884\u6d4b\u957f\u65f6\u95f4\u4f4f\u9662\u7684\u6a21\u578b\u6765\u8bc6\u522b\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u56fe\u8bba\u4e2d\u7684\u56e2\u4ee3\u8868\u65b9\u6cd5\u9009\u53d6\u7279\u5f81\u6743\u91cd\u4f5c\u4e3a\u7279\u5f81\u9009\u62e9\u624b\u6bb5\uff0c\u6784\u5efa\u903b\u8f91\u56de\u5f52\u6a21\u578b\u4ee5\u533a\u5206\u4f4f\u9662\u65f6\u95f4\u662f\u5426\u8d85\u8fc77\u5929\u3002\u4f7f\u7528\u7684\u6570\u636e\u96c6\u6765\u81ea2017\u5e741\u6708\u81f32022\u5e743\u6708\u671f\u95f4\u54e5\u4f26\u6bd4\u4e9a\u5b89\u8482\u5965\u57fa\u4e9a\u5927\u5b66\u9644\u5c5e\u533b\u9662\u7684120,354\u6b21\u4f4f\u9662\u8bb0\u5f55\u3002", "result": "\u6700\u7ec8\u6a21\u578b\u5728\u9a8c\u8bc1\u961f\u5217\u4e0a\u8fbe\u5230\u4e860.83\u7684\u7279\u5f02\u6027\u30010.64\u7684\u654f\u611f\u6027\u30010.76\u7684\u51c6\u786e\u6027\u30010.67\u7684\u7cbe\u786e\u5ea6\u4ee5\u53ca0.82\u7684AUC-ROC\u503c\u3002\u9009\u5b9a\u7684\u4e5d\u4e2a\u53d8\u91cf\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9884\u6d4b\u6a21\u578b\u5c55\u73b0\u4e86\u4f18\u79c0\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5bf9\u4e8e\u7406\u89e3\u5bfc\u81f4\u957f\u65f6\u95f4\u4f4f\u9662\u7684\u56e0\u7d20\u53ca\u672a\u6765\u5e72\u9884\u7814\u7a76\u7684\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u53ef\u4f5c\u4e3a\u533b\u9662\u7ba1\u7406\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.04458", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04458", "abs": "https://arxiv.org/abs/2601.04458", "authors": ["Jiayi Zhang", "Conrad Borchers", "Clayton Cohn", "Namrata Srivastava", "Caitlin Snyder", "Siyuan Guo", "Ashwin T S", "Naveeduddin Mohammed", "Haley Noh", "Gautam Biswas"], "title": "Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning", "comment": "Short research paper accepted at Learning Analytics and Knowledge (LAK '26)", "summary": "The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5d4c\u5165\u5f0f\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u534f\u4f5c\u8ba1\u7b97\u5efa\u6a21\u73af\u5883\u4e2d\u7684\u793e\u4f1a\u5171\u4eab\u5b66\u4e60\u8c03\u8282\u884c\u4e3a\uff0c\u7ed3\u679c\u663e\u793a\u7eaf\u6587\u672c\u5d4c\u5165\u5728\u68c0\u6d4b\u4e0e\u6267\u884c\u6216\u7fa4\u4f53\u52a8\u6001\u76f8\u5173\u7684SSRL\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u4e0a\u4e0b\u6587\u548c\u591a\u6a21\u6001\u7279\u5f81\u5bf9\u89c4\u5212\u548c\u53cd\u601d\u7b49\u7ed3\u6784\u63d0\u4f9b\u4e86\u4e92\u8865\u7684\u597d\u5904\u3002", "motivation": "\u5b66\u4e60\u5206\u6790\u9886\u57df\u5728\u81ea\u52a8\u5316\u68c0\u6d4b\u591a\u6a21\u6001\u6570\u636e\u4e2d\u590d\u6742\u7684\u4e2a\u4eba\u5b66\u4e60\u8fc7\u7a0b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u8f83\u5c11\u5173\u6ce8\u534f\u4f5c\u5f00\u653e\u5f0f\u95ee\u9898\u89e3\u51b3\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u6269\u5c55\u9884\u6d4b\u6a21\u578b\u4ee5\u81ea\u52a8\u68c0\u6d4b\u534f\u4f5c\u8ba1\u7b97\u5efa\u6a21\u73af\u5883\u4e2d\u7684\u793e\u4f1a\u5171\u4eab\u8c03\u8282\u5b66\u4e60\uff08SSRL\uff09\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u6458\u8981\u5de5\u5177\u751f\u6210\u4e0e\u7cfb\u7edf\u65e5\u5fd7\u5bf9\u9f50\u7684\u5b66\u751f\u5bf9\u8bdd\u7684\u4efb\u52a1\u611f\u77e5\u8868\u793a\u3002\u8fd9\u4e9b\u6458\u8981\u7ed3\u5408\u4e86\u4ec5\u6587\u672c\u7684\u5d4c\u5165\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u5d4c\u5165\u4ee5\u53ca\u4ece\u65e5\u5fd7\u5bfc\u51fa\u7684\u529f\u80fd\u6765\u8bad\u7ec3\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u4e0e\u6267\u884c\u6216\u7fa4\u4f53\u52a8\u6001\u6709\u5173\u7684SSRL\u884c\u4e3a\uff0c\u4f8b\u5982\u79bb\u9898\u884c\u4e3a\u6216\u8bf7\u6c42\u5e2e\u52a9\uff0c\u4ec5\u6587\u672c\u5d4c\u5165\u901a\u5e38\u80fd\u591f\u5b9e\u73b0\u66f4\u5f3a\u7684\u6027\u80fd\u3002\u76f8\u53cd\uff0c\u60c5\u5883\u5316\u548c\u591a\u6a21\u6001\u7279\u5f81\u4e3a\u8bf8\u5982\u8ba1\u5212\u548c\u53cd\u601d\u4e4b\u7c7b\u7684\u6784\u5efa\u63d0\u4f9b\u4e86\u8865\u5145\u6027\u76ca\u5904\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u5f3a\u8c03\u4e86\u57fa\u4e8e\u5d4c\u5165\u6a21\u578b\u5728\u901a\u8fc7\u53ef\u6269\u5c55\u5730\u68c0\u6d4bSSRL\u884c\u4e3a\u6765\u6269\u5c55\u5b66\u4e60\u5206\u6790\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u6700\u7ec8\u652f\u6301\u6559\u5e08\u6240\u91cd\u89c6\u7684\u534f\u4f5c\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u53cd\u9988\u548c\u81ea\u9002\u5e94\u652f\u67b6\u3002"}}
{"id": "2601.04480", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04480", "abs": "https://arxiv.org/abs/2601.04480", "authors": ["Wes Gurnee", "Emmanuel Ameisen", "Isaac Kauvar", "Julius Tarng", "Adam Pearce", "Chris Olah", "Joshua Batson"], "title": "When Models Manipulate Manifolds: The Geometry of a Counting Task", "comment": null, "summary": "Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u673a\u5236\u6027\u5730\u63a2\u8ba8Claude 3.5 Haiku\u5982\u4f55\u5b8c\u6210\u56fa\u5b9a\u5bbd\u5ea6\u6587\u672c\u4e2d\u7684\u5206\u884c\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4ec5\u63a5\u6536\u4e00\u7cfb\u5217\u6807\u8bb0\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u611f\u77e5\u6587\u672c\u89c6\u89c9\u5c5e\u6027\u7684\u65b9\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u5b57\u7b26\u8ba1\u6570\u4ee5\u4f4e\u7ef4\u5ea6\u5f2f\u66f2\u6d41\u5f62\u8868\u793a\uff0c\u5e76\u7531\u7a00\u758f\u7279\u5f81\u5bb6\u65cf\u79bb\u6563\u5316\u5904\u7406\uff0c\u7c7b\u4f3c\u4e8e\u751f\u7269\u5b9a\u4f4d\u7ec6\u80de\u3002\u51c6\u786e\u7684\u9884\u6d4b\u6765\u81ea\u4e00\u7cfb\u5217\u51e0\u4f55\u53d8\u6362\uff1a\u6807\u8bb0\u957f\u5ea6\u7d2f\u79ef\u6210\u5b57\u7b26\u8ba1\u6570\u6d41\u5f62\uff0c\u6ce8\u610f\u529b\u5934\u626d\u66f2\u8fd9\u4e9b\u6d41\u5f62\u4ee5\u4f30\u8ba1\u5230\u884c\u8fb9\u754c\u7684\u8ddd\u79bb\uff0c\u5e76\u901a\u8fc7\u6b63\u4ea4\u6392\u5217\u4f30\u8ba1\u503c\u6765\u51b3\u5b9a\u662f\u5426\u5206\u884c\u3002\u7814\u7a76\u7ed3\u679c\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u5f97\u5230\u9a8c\u8bc1\uff0c\u5e76\u53d1\u73b0\u4e86\u80fd\u591f\u52ab\u6301\u8ba1\u6570\u673a\u5236\u7684\u89c6\u89c9\u9519\u89c9\u3002", "motivation": "\u5c3d\u7ba1\u8bed\u8a00\u6a21\u578b\u53ea\u63a5\u6536\u4e00\u4e32\u6807\u8bb0\u5e8f\u5217\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f46\u5b83\u4eec\u80fd\u591f\u7406\u89e3\u6587\u672c\u7684\u67d0\u4e9b\u89c6\u89c9\u5c5e\u6027\u3002\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u7a76\u8fd9\u4e00\u73b0\u8c61\u80cc\u540e\u7684\u673a\u5236\uff0c\u7279\u522b\u662fClaude 3.5 Haiku\u662f\u5982\u4f55\u5b9e\u73b0\u56fa\u5b9a\u5bbd\u5ea6\u6587\u672c\u5185\u6b63\u786e\u5206\u884c\u7684\u8fc7\u7a0b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u673a\u5236\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u9996\u5148\u8bc6\u522b\u51fa\u5b57\u7b26\u8ba1\u6570\u88ab\u8868\u5f81\u4e8e\u4f4e\u7ef4\u66f2\u9762\u4e0a\u4e14\u7531\u7a00\u758f\u7279\u5f81\u65cf\u8fdb\u884c\u79bb\u6563\u5316\u5904\u7406\u7684\u7279\u70b9\uff1b\u63a5\u7740\uff0c\u901a\u8fc7\u89c2\u5bdf\u6a21\u578b\u5185\u90e8\u5bf9\u5b57\u7b26\u957f\u5ea6\u7684\u7d2f\u79ef\u3001\u6ce8\u610f\u529b\u673a\u5236\u5982\u4f55\u626d\u66f2\u4e0a\u8ff0\u66f2\u9762\u4ee5\u4f30\u7b97\u4e0e\u884c\u8fb9\u754c\u95f4\u7684\u8ddd\u79bb\uff0c\u4ee5\u53ca\u6700\u7ec8\u57fa\u4e8e\u6b63\u4ea4\u6392\u5217\u5f62\u6210\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\u7684\u5206\u884c\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6765\u9610\u660e\u6a21\u578b\u7684\u5de5\u4f5c\u539f\u7406\u3002\u6b64\u5916\uff0c\u8fd8\u5229\u7528\u56e0\u679c\u5e72\u9884\u5b9e\u9a8c\u548c\u6784\u9020\u7279\u5b9a\u5b57\u7b26\u5e8f\u5217\u5f15\u53d1\u89c6\u89c9\u9519\u89c9\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u63d0\u51fa\u7684\u7406\u8bba\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u65e9\u671f\u5c42\u5c55\u73b0\u4e86\u4e30\u5bcc\u7684\u611f\u5b98\u5904\u7406\u80fd\u529b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u7b97\u6cd5\u7684\u590d\u6742\u6027\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u5f3a\u8c03\u4e86\u7ed3\u5408\u57fa\u4e8e\u7279\u5f81\u548c\u51e0\u4f55\u89c6\u89d2\u5bf9\u4e8e\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027\u3002\u901a\u8fc7\u6784\u5efa\u7279\u5b9a\u5b57\u7b26\u5e8f\u5217\u6210\u529f\u5236\u9020\u4e86\u53ef\u4ee5\u2018\u52ab\u6301\u2019\u8ba1\u6570\u673a\u5236\u7684\u89c6\u89c9\u9519\u89c9\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u6a21\u578b\u5185\u90e8\u8fd0\u4f5c\u673a\u5236\u7684\u6709\u6548\u6027\u548c\u72ec\u7279\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u4e2d\u65e9\u671f\u5c42\u6b21\u6240\u5177\u6709\u7684\u5f3a\u5927\u611f\u89c9\u5904\u7406\u80fd\u529b\u53ca\u6ce8\u610f\u529b\u7b97\u6cd5\u7684\u7cbe\u5999\u4e4b\u5904\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u7ed3\u5408\u7279\u5f81\u57fa\u7840\u4e0e\u51e0\u4f55\u89c2\u70b9\u5bf9\u4e8e\u589e\u8fdb\u6211\u4eec\u5bf9\u6a21\u578b\u5185\u90e8\u8fd0\u4f5c\u673a\u5236\u7406\u89e3\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2601.04483", "categories": ["cs.LG", "cs.AI", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.04483", "abs": "https://arxiv.org/abs/2601.04483", "authors": ["Yongjun Kim", "Hyeongjun Park", "Hwanjin Kim", "Junil Choi"], "title": "Hybrid Federated Learning for Noise-Robust Training", "comment": null, "summary": "Federated learning (FL) and federated distillation (FD) are distributed learning paradigms that train UE models with enhanced privacy, each offering different trade-offs between noise robustness and learning speed. To mitigate their respective weaknesses, we propose a hybrid federated learning (HFL) framework in which each user equipment (UE) transmits either gradients or logits, and the base station (BS) selects the per-round weights of FL and FD updates. We derive convergence of HFL framework and introduce two methods to exploit degrees of freedom (DoF) in HFL, which are (i) adaptive UE clustering via Jenks optimization and (ii) adaptive weight selection via a damped Newton method. Numerical results show that HFL achieves superior test accuracy at low SNR when both DoF are exploited.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8ba9\u6bcf\u4e2a\u7528\u6237\u8bbe\u5907\u4f20\u8f93\u68af\u5ea6\u6216logits\uff0c\u5e76\u7531\u57fa\u7ad9\u9009\u62e9\u6bcf\u8f6e\u66f4\u65b0\u7684\u6743\u91cd\u6765\u7ed3\u5408\u8054\u90a6\u5b66\u4e60(FL)\u548c\u8054\u90a6\u84b8\u998f(FD)\u7684\u4f18\u52bf\u3002\u5f15\u5165\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u5229\u7528HFL\u4e2d\u7684\u81ea\u7531\u5ea6\uff1a\u81ea\u9002\u5e94UE\u805a\u7c7b\u4ee5\u53ca\u57fa\u4e8e\u963b\u5c3c\u725b\u987f\u6cd5\u7684\u81ea\u9002\u5e94\u6743\u91cd\u9009\u62e9\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\uff0c\u5f53\u540c\u65f6\u5229\u7528\u8fd9\u4e24\u79cd\u81ea\u7531\u5ea6\u65f6\uff0cHFL\u53ef\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u6d4b\u8bd5\u51c6\u786e\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60(FL)\u548c\u8054\u90a6\u84b8\u998f(FD)\u4f5c\u4e3a\u5206\u5e03\u5f0f\u5b66\u4e60\u8303\u5f0f\uff0c\u5728\u589e\u5f3a\u9690\u79c1\u7684\u540c\u65f6\u8bad\u7ec3\u7528\u6237\u8bbe\u5907\u6a21\u578b\uff0c\u4f46\u5b83\u4eec\u5404\u81ea\u5728\u566a\u58f0\u9c81\u68d2\u6027\u548c\u5b66\u4e60\u901f\u5ea6\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002\u4e3a\u4e86\u514b\u670d\u5404\u81ea\u7684\u5f31\u70b9\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u8054\u90a6\u5b66\u4e60(HFL)\u6846\u67b6\uff0c\u5176\u4e2d\u6bcf\u4e2a\u7528\u6237\u8bbe\u5907\u53ef\u4ee5\u9009\u62e9\u53d1\u9001\u68af\u5ea6\u6216logits\u7ed9\u57fa\u7ad9\uff0c\u800c\u57fa\u7ad9\u5219\u8d1f\u8d23\u51b3\u5b9a\u6bcf\u8f6e\u8fed\u4ee3\u4e2dFL\u4e0eFD\u66f4\u65b0\u7684\u6743\u91cd\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u5145\u5206\u5229\u7528HFL\u6846\u67b6\u5185\u7684\u81ea\u7531\u5ea6\uff1a\u4e00\u662f\u4f7f\u7528Jenks\u4f18\u5316\u8fdb\u884c\u81ea\u9002\u5e94UE\u805a\u7c7b\uff1b\u4e8c\u662f\u91c7\u7528\u963b\u5c3c\u725b\u987f\u6cd5\u5b9e\u73b0\u81ea\u9002\u5e94\u6743\u91cd\u9009\u62e9\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u73af\u5883\u4e0b\uff0c\u5f53\u540c\u65f6\u5e94\u7528\u4e0a\u8ff0\u4e24\u79cd\u81ea\u7531\u5ea6\u5229\u7528\u7b56\u7565\u65f6\uff0cHFL\u80fd\u591f\u8fbe\u5230\u66f4\u9ad8\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684HFL\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86FL\u548cFD\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u7075\u6d3b\u8c03\u6574UE\u7684\u6570\u636e\u8d21\u732e\u65b9\u5f0f\u53caBS\u7aef\u7684\u66f4\u65b0\u7b56\u7565\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u901a\u4fe1\u6761\u4ef6\u4e0b\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u7684\u76ee\u7684\u3002"}}
{"id": "2601.04498", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04498", "abs": "https://arxiv.org/abs/2601.04498", "authors": ["Yinghao Tang", "Xueding Liu", "Boyuan Zhang", "Tingfeng Lan", "Yupeng Xie", "Jiale Lao", "Yiyao Wang", "Haoxuan Li", "Tingting Gao", "Bo Pan", "Luoxuan Weng", "Xiuqi Huang", "Minfeng Zhu", "Yingchaojie Feng", "Yuyu Luo", "Wei Chen"], "title": "IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation", "comment": null, "summary": "Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at https://igen-bench.vercel.app/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IGENBENCH\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u8f6c\u4fe1\u606f\u56fe\u751f\u6210\u53ef\u9760\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b600\u4e2a\u7ecf\u8fc7\u7cbe\u5fc3\u6311\u9009\u7684\u6d4b\u8bd5\u6848\u4f8b\uff0c\u8986\u76d6\u4e8630\u79cd\u4fe1\u606f\u56fe\u7c7b\u578b\u3002\u901a\u8fc7\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6765\u9a8c\u8bc1\u6bcf\u4e2a\u95ee\u9898\uff0c\u5e76\u5bf910\u79cd\u6700\u5148\u8fdb\u7684T2I\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "motivation": "\u5c3d\u7ba1\u6700\u8fd1\u7684\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u6a21\u578b\u80fd\u591f\u751f\u6210\u7f8e\u89c2\u7684\u56fe\u50cf\uff0c\u4f46\u5b83\u4eec\u5728\u751f\u6210\u4fe1\u606f\u56fe\u65b9\u9762\u7684\u53ef\u9760\u6027\u4ecd\u4e0d\u6e05\u695a\u3002\u751f\u6210\u7684\u4fe1\u606f\u56fe\u53ef\u80fd\u4e4d\u4e00\u770b\u662f\u6b63\u786e\u7684\uff0c\u4f46\u5b58\u5728\u5bb9\u6613\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\uff0c\u5982\u6570\u636e\u7f16\u7801\u5931\u771f\u6216\u6587\u672c\u5185\u5bb9\u9519\u8bef\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u8861\u91cf\u8fd9\u4e9b\u6a21\u578b\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5c06\u53ef\u9760\u6027\u9a8c\u8bc1\u5206\u89e3\u4e3a\u57fa\u4e8e10\u79cd\u95ee\u9898\u7c7b\u578b\u5206\u7c7b\u7684\u539f\u5b50\u6027\u662f\u975e\u95ee\u9898\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u4f7f\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b(MLLMs)\u6765\u9a8c\u8bc1\u6bcf\u4e2a\u95ee\u9898\uff0c\u4ece\u800c\u5f97\u51fa\u95ee\u9898\u7ea7\u51c6\u786e\u6027(Q-ACC)\u548c\u4fe1\u606f\u56fe\u7ea7\u51c6\u786e\u6027(I-ACC)\u3002", "result": "\u7cfb\u7edf\u5206\u6790\u63ed\u793a\u4e86\u672a\u6765\u6a21\u578b\u5f00\u53d1\u7684\u5173\u952e\u89c1\u89e3\uff1a(i) \u4e09\u5c42\u6b21\u6027\u80fd\u7b49\u7ea7\u4e2d\u9876\u7ea7\u6a21\u578b\u8fbe\u5230Q-ACC 0.90\u4f46I-ACC\u4ec5\u4e3a0.49\uff1b(ii) \u6570\u636e\u76f8\u5173\u7ef4\u5ea6\u6210\u4e3a\u666e\u904d\u74f6\u9888\uff08\u4f8b\u5982\uff0c\u6570\u636e\u5b8c\u6574\u6027\uff1a0.21\uff09\uff1b\u4ee5\u53ca(iii) \u6240\u6709\u6a21\u578b\u7aef\u5230\u7aef\u6b63\u786e\u6027\u7684\u6311\u6218\u3002", "conclusion": "IGENBENCH\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\uff0c\u7528\u6765\u8bc4\u4f30\u5f53\u524d\u53ca\u672a\u6765T2I\u6a21\u578b\u5728\u751f\u6210\u4fe1\u606f\u56fe\u65f6\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u6539\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2601.04506", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04506", "abs": "https://arxiv.org/abs/2601.04506", "authors": ["Fang Wu", "Zhengyuan Zhou", "Shuting Jin", "Xiangxiang Zeng", "Jure Leskovec", "Jinbo Xu"], "title": "Surface-based Molecular Design with Multi-modal Flow Matching", "comment": null, "summary": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSurfFlow\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8003\u8651\u5206\u5b50\u8868\u9762\u7279\u6027\u6765\u751f\u6210\u548c\u8bbe\u8ba1\u80bd\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u80bd\u7684\u7ed3\u5408\u51c6\u786e\u6027\u3002\u5728PepMerge\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSurfFlow\u7684\u8868\u73b0\u4f18\u4e8e\u5168\u539f\u5b50\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u6cbb\u7597\u6027\u80bd\u5728\u9776\u5411\u4ee5\u524d\u96be\u4ee5\u6210\u836f\u7684\u7ed3\u5408\u4f4d\u70b9\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u5e76\u4e14\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u7684\u8fdb\u6b65\u4f7f\u5f97\u80fd\u591f\u4e3a\u7279\u5b9a\u86cb\u767d\u8d28\u53d7\u4f53\u8fdb\u884c\u5168\u9762\u7684\u539f\u5b50\u80bd\u5171\u8bbe\u8ba1\uff0c\u4f46\u5206\u5b50\u8868\u9762\u5728\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSurfFlow\u7684\u5168\u65b9\u4f4d\u80bd\u751f\u6210\u8303\u4f8b\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u8868\u9762\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u80fd\u591f\u5168\u9762\u5730\u5171\u540c\u8bbe\u8ba1\u80bd\u7684\u5e8f\u5217\u3001\u7ed3\u6784\u548c\u8868\u9762\u3002SurfFlow\u91c7\u7528\u591a\u6a21\u6001\u6761\u4ef6\u6d41\u5339\u914d\uff08CFM\uff09\u67b6\u6784\u5b66\u4e60\u8868\u9762\u51e0\u4f55\u5f62\u72b6\u548c\u751f\u5316\u7279\u6027\u7684\u5206\u5e03\uff0c\u4ee5\u63d0\u9ad8\u80bd\u7ed3\u5408\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728\u7efc\u5408\u6027\u7684PepMerge\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSurfFlow\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u6301\u7eed\u4f18\u4e8e\u5168\u539f\u5b50\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u51fa\u4e86\u5728\u4ece\u5934\u5f00\u59cb\u7684\u80bd\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u8003\u8651\u5206\u5b50\u8868\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u5c55\u793a\u4e86\u6574\u5408\u591a\u79cd\u86cb\u767d\u8d28\u6a21\u5f0f\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6cbb\u7597\u6027\u80bd\u53d1\u73b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.04537", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04537", "abs": "https://arxiv.org/abs/2601.04537", "authors": ["Tianle Wang", "Zhongyuan Wu", "Shenghao Jin", "Hao Xu", "Wei Chen", "Ning Miao"], "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training", "comment": "pre-print", "summary": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\uff0c\u5728\u4f7f\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u8fc7\u7a0b\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u7ebf\u6027\u6f14\u5316\u7279\u5f81\u3002\u57fa\u4e8e\u8fd9\u4e00\u89c2\u5bdf\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u901a\u8fc7\u6743\u91cd\u5916\u63a8\u548cLogits\u5916\u63a8\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u6a21\u578b\u672a\u6765\u72b6\u6001\uff0c\u4ece\u800c\u5728\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u6807\u51c6RL\u8bad\u7ec3\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684RLVR\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u7684\u8868\u73b0\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6b65\u9aa4\uff0c\u5bfc\u81f4\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5229\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7ebf\u6027\u7279\u6027\uff0c\u4ee5\u66f4\u9ad8\u6548\u7684\u65b9\u5f0f\u83b7\u5f97\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9\u6a21\u578b\u6743\u91cd\u548c\u8f93\u51falog-probabilities\u4e0eRL\u8bad\u7ec3\u6b65\u9aa4\u4e4b\u95f4\u5173\u7cfb\u7684\u7814\u7a76\uff0c\u53d1\u73b0\u4e86\u4e24\u8005\u5b58\u5728\u5f3a\u7ebf\u6027\u76f8\u5173\u6027\u3002\u57fa\u4e8e\u6b64\u53d1\u73b0\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e24\u79cd\u6280\u672f\uff1a\u6743\u91cd\u5916\u63a8(Weight Extrapolation)\u548cLogits\u5916\u63a8(Logits Extrapolation)\uff0c\u7528\u4e8e\u4ece\u4e2d\u95f4\u68c0\u67e5\u70b9\u9884\u6d4b\u672a\u6765\u7684\u6a21\u578b\u72b6\u6001\uff0c\u65e0\u9700\u7ee7\u7eed\u6267\u884c\u8017\u65f6\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6743\u91cd\u5916\u63a8\u80fd\u591f\u5728\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u91cf\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u4e0e\u6807\u51c6RL\u8bad\u7ec3\u76f8\u5f53\u7684\u7ed3\u679c\uff1b\u800cLogits\u5916\u63a8\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u8fd9\u4e00\u70b9\uff0c\u8fd8\u5728\u6240\u6709\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6301\u7eed\u8fdb\u884c\u7684RL\u8bad\u7ec3\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5229\u7528RLVR\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u7ebf\u6027\u6027\u8d28\uff0c\u53ef\u4ee5\u91c7\u7528\u5916\u63a8\u6cd5\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u6765\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.04555", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04555", "abs": "https://arxiv.org/abs/2601.04555", "authors": ["Shogo Nakayama", "Masahiro Okuda"], "title": "Improving Semi-Supervised Contrastive Learning via Entropy-Weighted Confidence Integration of Anchor-Positive Pairs", "comment": null, "summary": "Conventional semi-supervised contrastive learning methods assign pseudo-labels only to samples whose highest predicted class probability exceeds a predefined threshold, and then perform supervised contrastive learning using those selected samples. In this study, we propose a novel loss function that estimates the confidence of each sample based on the entropy of its predicted probability distribution and applies confidence-based adaptive weighting. This approach enables pseudo-label assignment even to samples that were previously excluded from training and facilitates contrastive learning that accounts for the confidence of both anchor and positive samples in a more principled manner. Experimental results demonstrate that the proposed method improves classification accuracy and achieves more stable learning performance even under low-label conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u57fa\u4e8e\u9884\u6d4b\u6982\u7387\u5206\u5e03\u7684\u71b5\u6765\u4f30\u8ba1\u6bcf\u4e2a\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u5e94\u7528\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u81ea\u9002\u5e94\u52a0\u6743\u3002\u8fd9\u79cd\u65b9\u6cd5\u5373\u4f7f\u5728\u4f4e\u6807\u7b7e\u6761\u4ef6\u4e0b\u4e5f\u80fd\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u5b66\u4e60\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4ec5\u7ed9\u90a3\u4e9b\u6700\u9ad8\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u8d85\u8fc7\u9884\u5b9a\u4e49\u9608\u503c\u7684\u6837\u672c\u5206\u914d\u4f2a\u6807\u7b7e\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u9009\u5b9a\u6837\u672c\u6267\u884c\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u3002\u8fd9\u79cd\u505a\u6cd5\u9650\u5236\u4e86\u53ef\u7528\u4e8e\u8bad\u7ec3\u7684\u6837\u672c\u6570\u91cf\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u6839\u636e\u9884\u6d4b\u6982\u7387\u5206\u5e03\u7684\u71b5\u8bc4\u4f30\u6bcf\u4e2a\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5e76\u5b9e\u884c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u81ea\u9002\u5e94\u6743\u91cd\u8c03\u6574\u3002\u8fd9\u4e00\u65b9\u6cd5\u5141\u8bb8\u4e3a\u4e4b\u524d\u88ab\u6392\u9664\u5728\u5916\u7684\u6837\u672c\u4e5f\u5206\u914d\u4f2a\u6807\u7b7e\uff0c\u5e76\u4e14\u80fd\u591f\u4ee5\u66f4\u52a0\u5408\u7406\u7684\u65b9\u5f0f\u8003\u8651\u951a\u70b9\u548c\u6b63\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\u6765\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5728\u4f4e\u6807\u7b7e\u6761\u4ef6\u4e0b\u4e5f\u80fd\u8fbe\u5230\u66f4\u7a33\u5b9a\u7684\u5b66\u4e60\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u81ea\u9002\u5e94\u52a0\u6743\u673a\u5236\uff0c\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u6269\u5927\u4e86\u53ef\u53c2\u4e0e\u8bad\u7ec3\u7684\u6837\u672c\u8303\u56f4\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u6027\u80fd\u7a33\u5b9a\u6027\u4e0e\u5206\u7c7b\u7cbe\u5ea6\u3002"}}
{"id": "2601.04563", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.04563", "abs": "https://arxiv.org/abs/2601.04563", "authors": ["Paul Pu Liang"], "title": "A Vision for Multisensory Intelligence: Sensing, Synergy, and Science", "comment": null, "summary": "Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see https://mit-mi.github.io/.", "AI": {"tldr": "\u672c\u6587\u6982\u8ff0\u4e86\u672a\u6765\u5341\u5e74\u591a\u611f\u5b98\u4eba\u5de5\u667a\u80fd\u7684\u7814\u7a76\u613f\u666f\uff0c\u901a\u8fc7\u611f\u77e5\u3001\u79d1\u5b66\u548c\u534f\u540c\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u4e3b\u9898\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\uff0c\u65e8\u5728\u8fde\u63a5AI\u4e0e\u4eba\u7c7b\u7684\u611f\u5b98\u53ca\u4e30\u5bcc\u7684\u751f\u7406\u548c\u793e\u4f1a\u4fe1\u53f7\uff0c\u6539\u53d8\u4eba\u4e0eAI\u4e4b\u95f4\u7684\u4f53\u9a8c\u548c\u4e92\u52a8\u65b9\u5f0f\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u6587\u672c\u3001\u89c6\u89c9\u548c\u97f3\u9891\u7b49\u6570\u5b57\u6a21\u6001\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u6a21\u62df\u4eba\u7c7b\u591a\u611f\u5b98\u4f53\u9a8c\uff08\u5982\u89e6\u89c9\u3001\u5473\u89c9\u3001\u55c5\u89c9\uff09\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u611f\u5b98\u4eba\u5de5\u667a\u80fd\u7684\u7814\u7a76\u613f\u666f\uff0c\u65e8\u5728\u901a\u8fc7\u6574\u5408\u66f4\u591a\u7c7b\u578b\u7684\u4fe1\u53f7\u6765\u4e30\u5bccAI\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u7684\u65b9\u5f0f\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u8fc7\u611f\u77e5\u3001\u79d1\u5b66\u548c\u534f\u540c\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u4e3b\u9898\u6765\u63a8\u52a8\u591a\u611f\u5b98AI\u53d1\u5c55\u7684\u6846\u67b6\u3002\u5176\u4e2d\uff0c\u201c\u611f\u77e5\u201d\u7814\u7a76\u5173\u6ce8\u5982\u4f55\u8ba9AI\u4ee5\u66f4\u4e30\u5bcc\u7684\u65b9\u5f0f\u6355\u6349\u4e16\u754c\uff1b\u201c\u79d1\u5b66\u201d\u90e8\u5206\u81f4\u529b\u4e8e\u91cf\u5316\u591a\u6a21\u6001\u5f02\u8d28\u6027\u548c\u4ea4\u4e92\u4f5c\u7528\u3001\u5f00\u53d1\u7edf\u4e00\u5efa\u6a21\u67b6\u6784\u4ee5\u53ca\u7406\u89e3\u8de8\u6a21\u6001\u8fc1\u79fb\uff1b\u800c\u201c\u534f\u540c\u201d\u5219\u805a\u7126\u4e8e\u5b66\u4e60\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u4ee5\u53ca\u4eba\u4e0eAI\u4e4b\u95f4\u7684\u534f\u540c\u6548\u5e94\u3002", "result": "\u6587\u7ae0\u4e0d\u4ec5\u63d0\u51fa\u4e86\u591a\u611f\u5b98AI\u7684\u7814\u7a76\u6846\u67b6\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u7cfb\u5217\u6765\u81eaMIT Media Lab\u591a\u611f\u5b98\u667a\u80fd\u5c0f\u7ec4\u7684\u6700\u65b0\u9879\u76ee\u3001\u8d44\u6e90\u548c\u6f14\u793a\uff0c\u5c55\u793a\u4e86\u5f53\u524d\u9886\u57df\u7684\u8fdb\u6b65\u3002", "conclusion": "\u591a\u611f\u5b98\u4eba\u5de5\u667a\u80fd\u4ee3\u8868\u4e86\u672a\u6765\u5341\u5e74\u5185AI\u53d1\u5c55\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\uff0c\u5b83\u5c06\u901a\u8fc7\u589e\u5f3aAI\u5bf9\u7269\u7406\u4e16\u754c\u548c\u4eba\u7c7b\u611f\u5b98\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4fc3\u8fdb\u4eba\u673a\u4ea4\u4e92\u66f4\u52a0\u81ea\u7136\u548c\u8c10\u3002"}}
{"id": "2601.04572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04572", "abs": "https://arxiv.org/abs/2601.04572", "authors": ["Xiaowei Mao", "Huihu Ding", "Yan Lin", "Tingrui Wu", "Shengnan Guo", "Dazhuo Qiu", "Feiling Fang", "Jilin Hu", "Huaiyu Wan"], "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation", "comment": null, "summary": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance.\n  To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFENCE\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u65f6\u7a7a\u4ea4\u901a\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u53cd\u9988\u673a\u5236\u6765\u8c03\u6574\u6307\u5bfc\u5c3a\u5ea6\uff0c\u5e76\u6839\u636e\u8282\u70b9\u7684\u6ce8\u610f\u529b\u5206\u6570\u5206\u7ec4\u8ba1\u7b97\u6307\u5bfc\u5c3a\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6570\u636e\u586b\u8865\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\uff0c\u586b\u8865\u65f6\u7a7a\u4ea4\u901a\u6570\u636e\u4e2d\u7684\u7f3a\u5931\u503c\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u57fa\u4e8e\u5206\u6570\u7684\u6269\u6563\u6a21\u578b\u5df2\u7ecf\u5c55\u793a\u4e86\u7ade\u4e89\u529b\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u5bf9\u65f6\u7a7a\u7ef4\u5ea6\u91c7\u7528\u7edf\u4e00\u7684\u6307\u5bfc\u5c3a\u5ea6\uff0c\u8fd9\u5728\u9ad8\u7f3a\u5931\u7387\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u7a00\u758f\u89c2\u6d4b\u63d0\u4f9b\u7684\u6761\u4ef6\u6307\u5bfc\u4e0d\u8db3\uff0c\u5bfc\u81f4\u751f\u6210\u8fc7\u7a0b\u504f\u79bb\u4e86\u6761\u4ef6\u89c2\u6d4b\uff0c\u964d\u4f4e\u4e86\u586b\u8865\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86FENCE\uff0c\u4e00\u79cd\u65f6\u7a7a\u53cd\u9988\u6269\u6563\u6307\u5bfc\u65b9\u6cd5\uff0c\u65e8\u5728\u81ea\u9002\u5e94\u5730\u63a7\u5236\u586b\u8865\u8fc7\u7a0b\u4e2d\u7684\u6307\u5bfc\u5c3a\u5ea6\u3002\u9996\u5148\uff0cFENCE\u5f15\u5165\u4e86\u4e00\u4e2a\u52a8\u6001\u53cd\u9988\u673a\u5236\uff0c\u6839\u636e\u540e\u9a8c\u4f3c\u7136\u4f30\u8ba1\u8c03\u6574\u6307\u5bfc\u5c3a\u5ea6\uff1b\u5f53\u751f\u6210\u503c\u4e0e\u89c2\u6d4b\u503c\u5dee\u5f02\u5927\u65f6\u589e\u52a0\u6307\u5bfc\u5c3a\u5ea6\uff0c\u53cd\u4e4b\u5219\u51cf\u5c11\uff0c\u4ee5\u9632\u6b62\u8fc7\u5ea6\u4fee\u6b63\u3002\u5176\u6b21\uff0c\u9274\u4e8e\u4e0d\u540c\u8282\u70b9\u548c\u53bb\u566a\u6b65\u9aa4\u95f4\u5bf9\u89c2\u6d4b\u503c\u7684\u4e00\u81f4\u6027\u5b58\u5728\u5dee\u5f02\uff0cFENCE\u4f9d\u636e\u6ce8\u610f\u529b\u5206\u6570\u5c06\u8282\u70b9\u5206\u7ec4\uff0c\u5728\u96c6\u7fa4\u7ea7\u522b\u4e0a\u8ba1\u7b97\u6307\u5bfc\u5c3a\u5ea6\uff0c\u5229\u7528\u65f6\u7a7a\u5173\u8054\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\uff0cFENCE\u663e\u8457\u63d0\u5347\u4e86\u586b\u8865\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u6307\u5bfc\u5c3a\u5ea6\u5e76\u8003\u8651\u65f6\u7a7a\u76f8\u5173\u6027\uff0cFENCE\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u5177\u6709\u9ad8\u7f3a\u5931\u7387\u7684\u65f6\u7a7a\u4ea4\u901a\u6570\u636e\u586b\u8865\u8d28\u91cf\u3002"}}
{"id": "2601.04587", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04587", "abs": "https://arxiv.org/abs/2601.04587", "authors": ["Quang-Tu Pham", "Hoang-Dieu Vu", "Dinh-Dat Pham", "Hieu H. Pham"], "title": "FedKDX: Federated Learning with Negative Knowledge Distillation for Enhanced Healthcare AI Systems", "comment": null, "summary": "This paper introduces FedKDX, a federated learning framework that addresses limitations in healthcare AI through Negative Knowledge Distillation (NKD). Unlike existing approaches that focus solely on positive knowledge transfer, FedKDX captures both target and non-target information to improve model generalization in healthcare applications. The framework integrates multiple knowledge transfer techniques--including traditional knowledge distillation, contrastive learning, and NKD--within a unified architecture that maintains privacy while reducing communication costs. Through experiments on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2), FedKDX demonstrates improved accuracy (up to 2.53% over state-of-the-art methods), faster convergence, and better performance on non-IID data distributions. Theoretical analysis supports NKD's contribution to addressing statistical heterogeneity in distributed healthcare data. The approach shows promise for privacy-sensitive medical applications under regulatory frameworks like HIPAA and GDPR, offering a balanced solution between performance and practical implementation requirements in decentralized healthcare settings. The code and model are available at https://github.com/phamdinhdat-ai/Fed_2024.", "AI": {"tldr": "FedKDX, a federated learning framework, uses Negative Knowledge Distillation (NKD) to improve AI in healthcare. It combines various knowledge transfer methods and achieves better accuracy, faster convergence, and enhanced performance on non-IID data. The solution is suitable for privacy-sensitive medical applications.", "motivation": "The motivation behind FedKDX is to address the limitations of current healthcare AI, particularly by capturing both target and non-target information, thereby improving model generalization. Additionally, it aims to maintain privacy and reduce communication costs in distributed healthcare settings.", "method": "FedKDX employs a combination of traditional knowledge distillation, contrastive learning, and Negative Knowledge Distillation (NKD) within a unified architecture. This approach not only enhances the model's ability to generalize but also addresses the statistical heterogeneity found in distributed healthcare data, all while preserving privacy and minimizing communication overheads.", "result": "Experiments conducted on healthcare datasets (SLEEP, UCI-HAR, and PAMAP2) show that FedKDX can achieve up to 2.53% higher accuracy compared to state-of-the-art methods, alongside demonstrating faster convergence and superior performance on non-IID data distributions. Theoretical analysis further supports the effectiveness of NKD in tackling statistical heterogeneity.", "conclusion": "FedKDX represents a promising advancement in federated learning for healthcare, offering improved accuracy, better handling of non-IID data, and compliance with strict privacy regulations such as HIPAA and GDPR. This makes it a balanced solution for performance and practical implementation in decentralized healthcare environments."}}
{"id": "2601.04670", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04670", "abs": "https://arxiv.org/abs/2601.04670", "authors": ["Akiyoshi Tomihari"], "title": "Learning Dynamics in RL Post-Training for Language Models", "comment": null, "summary": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u9636\u6bb5\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8f93\u51fa\u591a\u6837\u6027\u51cf\u5c11\u7684\u73b0\u8c61\u3002\u901a\u8fc7\u91c7\u7528\u795e\u7ecf\u5207\u7ebf\u6838(NTK)\u6846\u67b6\u6765\u5206\u6790\u5b66\u4e60\u52a8\u6001\uff0c\u53d1\u73b0\u7279\u5f81\u8868\u793a\u7684\u53d8\u5316\u6709\u9650\u4f1a\u5bfc\u81f4\u6a21\u578b\u4fe1\u5fc3\u7684\u7cfb\u7edf\u6027\u589e\u52a0\uff0c\u4ece\u800c\u89e3\u91ca\u4e86\u8f93\u51fa\u591a\u6837\u6027\u51cf\u5c11\u7684\u539f\u56e0\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u2014\u2014\u5206\u7c7b\u5668\u4f18\u5148\u5f3a\u5316\u5b66\u4e60(CF-RL)\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6RL\u4f18\u5316\u4e4b\u524d\u4f18\u5148\u66f4\u65b0\u5206\u7c7b\u5668\u3002\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86CF-RL\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u540e\u8bad\u7ec3\u9636\u6bb5\u5982\u4f55\u5f71\u54cd\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u63d0\u9ad8\u4e00\u81f4\u6027\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u4f5c\u7528\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u4f1a\u51fa\u73b0\u8f93\u51fa\u591a\u6837\u6027\u51cf\u5c11\u7684\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u4e86\u7ecf\u9a8c\u795e\u7ecf\u5207\u7ebf\u6838(NTK)\u6846\u67b6\u6765\u7814\u7a76RL\u540e\u8bad\u7ec3\u7684\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u5c06NTK\u5206\u89e3\u4e3a\u4e24\u4e2a\u90e8\u5206\u4ee5\u63cf\u8ff0RL\u66f4\u65b0\u662f\u5982\u4f55\u8de8\u8bad\u7ec3\u6837\u672c\u4f20\u64ad\u7684\u3002\u57fa\u4e8e\u6b64\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u5668\u4f18\u5148\u5f3a\u5316\u5b66\u4e60(CF-RL)\u8fd9\u4e00\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7279\u5f81\u8868\u793a\u53d8\u5316\u6709\u9650\u662f\u5bfc\u81f4RL\u540e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6a21\u578b\u4fe1\u5fc3\u589e\u52a0\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u8fdb\u800c\u51cf\u5c11\u4e86\u8f93\u51fa\u591a\u6837\u6027\u3002\u800cCF-RL\u80fd\u591f\u6709\u6548\u5730\u52a0\u5feb\u4f18\u5316\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u4fe1\u5fc3\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0CF-RL\u7684\u5de5\u4f5c\u673a\u5236\u4e0d\u540c\u4e8e\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5148\u7ebf\u6027\u63a2\u6d4b\u518d\u5fae\u8c03\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u5f62\u5f0f\u5316\u5730\u9610\u8ff0\u4e86RL\u540e\u8bad\u7ec3\u7684\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u52a8\u673a\u3002\u63d0\u51fa\u7684CF-RL\u7b56\u7565\u88ab\u8bc1\u5b9e\u662f\u4e00\u79cd\u6709\u6548\u7684\u624b\u6bb5\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u6a21\u578b\u66f4\u5feb\u5730\u6536\u655b\u5e76\u4fdd\u6301\u6216\u63d0\u9ad8\u5176\u6027\u80fd\u3002"}}
{"id": "2601.04673", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04673", "abs": "https://arxiv.org/abs/2601.04673", "authors": ["Aurghya Maiti", "Prateek Jain"], "title": "Estimating Causal Effects in Gaussian Linear SCMs with Finite Data", "comment": "Accepted at the Workshop on Scaling Up Intervention Models at the 42nd International Conference on Machine Learning (ICML 2025)", "summary": "Estimating causal effects from observational data remains a fundamental challenge in causal inference, especially in the presence of latent confounders. This paper focuses on estimating causal effects in Gaussian Linear Structural Causal Models (GL-SCMs), which are widely used due to their analytical tractability. However, parameter estimation in GL-SCMs is often infeasible with finite data, primarily due to overparameterization. To address this, we introduce the class of Centralized Gaussian Linear SCMs (CGL-SCMs), a simplified yet expressive subclass where exogenous variables follow standardized distributions. We show that CGL-SCMs are equally expressive in terms of causal effect identifiability from observational distributions and present a novel EM-based estimation algorithm that can learn CGL-SCM parameters and estimate identifiable causal effects from finite observational samples. Our theoretical analysis is validated through experiments on synthetic data and benchmark causal graphs, demonstrating that the learned models accurately recover causal distributions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u9ad8\u65af\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b\uff08CGL-SCM\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u6807\u51c6\u5316\u5206\u5e03\u7684\u5916\u751f\u53d8\u91cf\u6765\u89e3\u51b3\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\u3002\u57fa\u4e8e\u6b64\u6a21\u578b\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eEM\u7b97\u6cd5\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4ece\u6709\u9650\u7684\u89c2\u5bdf\u6837\u672c\u4e2d\u5b66\u4e60CGL-SCM\u53c2\u6570\u5e76\u4f30\u8ba1\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6548\u5e94\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6240\u5b66\u6a21\u578b\u80fd\u591f\u51c6\u786e\u6062\u590d\u56e0\u679c\u5206\u5e03\u3002", "motivation": "\u5728\u5b58\u5728\u6f5c\u5728\u6df7\u6dc6\u56e0\u7d20\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u662f\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002\u867d\u7136\u9ad8\u65af\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b(GL-SCMs)\u7531\u4e8e\u5176\u5206\u6790\u4e0a\u7684\u53ef\u5904\u7406\u6027\u800c\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u53c2\u6570\u4f30\u8ba1\u901a\u5e38\u56e0\u8fc7\u53c2\u6570\u5316\u800c\u53d8\u5f97\u4e0d\u53ef\u884c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4ece\u6709\u9650\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u7c7b\u540d\u4e3a\u96c6\u4e2d\u5f0f\u9ad8\u65af\u7ebf\u6027\u7ed3\u6784\u56e0\u679c\u6a21\u578b(CGL-SCMs)\u7684\u65b0\u5b50\u7c7b\uff0c\u8be5\u5b50\u7c7b\u7b80\u5316\u4e86\u6a21\u578b\u5e76\u901a\u8fc7\u5047\u8bbe\u5916\u751f\u53d8\u91cf\u9075\u5faa\u6807\u51c6\u5316\u5206\u5e03\u6765\u4fdd\u6301\u8868\u8fbe\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8eEM\u7b97\u6cd5\u7684\u4f30\u8ba1\u7b97\u6cd5\uff0c\u7528\u4e8e\u4ece\u6709\u9650\u89c2\u6d4b\u6837\u672c\u4e2d\u5b66\u4e60CGL-SCM\u53c2\u6570\u4ee5\u53ca\u4f30\u8ba1\u53ef\u8bc6\u522b\u7684\u56e0\u679c\u6548\u5e94\u3002", "result": "\u7406\u8bba\u5206\u6790\u5f97\u5230\u4e86\u5408\u6210\u6570\u636e\u548c\u57fa\u51c6\u56e0\u679c\u56fe\u4e0a\u5b9e\u9a8c\u7684\u652f\u6301\uff0c\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u6a21\u578b\u80fd\u591f\u7cbe\u786e\u5730\u518d\u73b0\u56e0\u679c\u5206\u5e03\u3002\u8fd9\u8868\u660e\u65b0\u63d0\u51fa\u7684CGL-SCMs\u6846\u67b6\u53ca\u5176\u76f8\u5173\u7b97\u6cd5\u5728\u5904\u7406\u5b9e\u9645\u573a\u666f\u4e0b\u7531\u6709\u9650\u6570\u636e\u5e26\u6765\u7684\u6311\u6218\u65f6\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165CGL-SCMs\u53ca\u76f8\u5e94\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u672c\u6587\u4e3a\u4ece\u6709\u9650\u89c2\u5bdf\u6570\u636e\u4e2d\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e00\u8d21\u732e\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6211\u4eec\u5bf9\u590d\u6742\u7cfb\u7edf\u4e2d\u56e0\u679c\u5173\u7cfb\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4e5f\u4e3a\u672a\u6765\u7814\u7a76\u5982\u4f55\u66f4\u597d\u5730\u5229\u7528\u6709\u9650\u6570\u636e\u8fdb\u884c\u51c6\u786e\u56e0\u679c\u63a8\u65ad\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.04686", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.04686", "abs": "https://arxiv.org/abs/2601.04686", "authors": ["Oluwatosin Oseni", "Shengjie Wang", "Jun Zhu", "Micah Corah"], "title": "Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead", "comment": "RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures", "summary": "Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.", "AI": {"tldr": "Nightmare Dreamer, a model-based Safe RL algorithm, uses a learned world model to predict and prevent safety violations, achieving high efficiency and nearly zero safety issues on Safety Gymnasium tasks.", "motivation": "The motivation is to address the limitation of Reinforcement Learning (RL) in real-world applications, particularly the lack of sufficient safety guarantees, which hinders its broader adoption especially in critical areas like robotics control.", "method": "Nightmare Dreamer employs a model-based approach by learning a world model capable of predicting potential safety violations. It then plans actions that avoid these predicted risks while still aiming to maximize rewards.", "result": "On Safety Gymnasium tasks, Nightmare Dreamer demonstrates nearly zero safety violations and shows a significant 20x improvement in efficiency over model-free baselines when using only image observations.", "conclusion": "This paper concludes that Nightmare Dreamer effectively addresses safety concerns in RL, making it a promising solution for increasing the applicability of RL in domains requiring high levels of safety, such as robotics control."}}
{"id": "2601.04690", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04690", "abs": "https://arxiv.org/abs/2601.04690", "authors": ["Mir Rayat Imtiaz Hossain", "Leo Feng", "Leonid Sigal", "Mohamed Osama Ahmed"], "title": "Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?", "comment": "Presented in Multimodal Algorithmic Reasoning Workshop at NeurIPS 2025", "summary": "Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4ece\u534f\u540c\u8fc7\u6ee4\u4e2d\u5b66\u4e60\u5230\u7684\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u6620\u5c04\u5230\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee4\u724c\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u4f7fLLM\u80fd\u591f\u57fa\u4e8e\u8fd9\u4e9b\u6295\u5f71\u5d4c\u5165\u4e0e\u6587\u672c\u4ee4\u724c\u4e00\u8d77\u751f\u6210\u63a8\u8350\u3002\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u7ed3\u6784\u5316\u7684\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u6570\u636e\uff0c\u76f8\u8f83\u4e8e\u4ec5\u4f7f\u7528\u6587\u672c\u7684LLM\u57fa\u7ebf\u63d0\u9ad8\u4e86\u63a8\u8350\u6027\u80fd\uff0c\u5e76\u4e3a\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4e0e\u73b0\u4ee3LLM\u4e4b\u95f4\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u8def\u5f84\u3002", "motivation": "\u5f53\u524d\u8bb8\u591a\u65b9\u6cd5\u5728\u6784\u5efa\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u8350\u7cfb\u7edf\u65f6\uff0c\u5f80\u5f80\u53ea\u4f9d\u8d56\u4e8e\u6587\u672c\u8bed\u4e49\u6216\u4ee5\u6709\u9650\u7684\u65b9\u5f0f\uff08\u5982\u4ec5\u4f7f\u7528\u7528\u6237\u6216\u9879\u76ee\u5d4c\u5165\uff09\u6574\u5408\u534f\u4f5c\u4fe1\u53f7\uff0c\u8fd9\u5bfc\u81f4\u5b83\u4eec\u96be\u4ee5\u5904\u7406\u4ee3\u8868\u7528\u6237\u5386\u53f2\u7684\u591a\u4e2a\u9879\u76ee\u5d4c\u5165\uff0c\u540c\u65f6\u5ffd\u7565\u4e86\u66f4\u4e30\u5bcc\u7684\u534f\u4f5c\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5373\u901a\u8fc7\u72ec\u7acb\u7684\u8f7b\u91cf\u7ea7\u6295\u5f71\u6a21\u5757\u5c06\u4ece\u534f\u540c\u8fc7\u6ee4\u4e2d\u5b66\u5230\u7684\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\u6620\u5c04\u5230LLM\u4ee4\u724c\u7a7a\u95f4\uff1b\u7136\u540e\uff0c\u4e00\u4e2a\u5fae\u8c03\u540e\u7684LLM\u4f1a\u6839\u636e\u8fd9\u4e9b\u6620\u5c04\u540e\u7684\u5d4c\u5165\u4ee5\u53ca\u6587\u672c\u4ee4\u724c\u6765\u751f\u6210\u63a8\u8350\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u5730\u5229\u7528\u7ed3\u6784\u5316\u7684\u7528\u6237-\u9879\u76ee\u4ea4\u4e92\u6570\u636e\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u4ec5\u4f9d\u8d56\u6587\u672c\u7684LLM\u57fa\u7ebf\uff0c\u5728\u63a8\u8350\u6027\u80fd\u4e0a\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u4e00\u79cd\u7ed3\u5408\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u4e0e\u73b0\u4ee3LLM\u7684\u6709\u6548\u65b9\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u7528\u6237\u548c\u9879\u76ee\u5d4c\u5165\u81f3LLM\u4e2d\uff0c\u4e0d\u4ec5\u6539\u5584\u4e86\u63a8\u8350\u8d28\u91cf\u8fd8\u5f00\u8f9f\u4e86\u4e24\u9886\u57df\u878d\u5408\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.04719", "categories": ["cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.04719", "abs": "https://arxiv.org/abs/2601.04719", "authors": ["Maanas Taneja", "Purab Shingvi"], "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models", "comment": null, "summary": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86GPU\u52a0\u901f\u7684INT8\u91cf\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u952e\u503c\u7f13\u5b58\uff0c\u5b9e\u73b0\u4e864\u500d\u7684\u5185\u5b58\u51cf\u5c11\u4e14\u5bf9\u51c6\u786e\u7387\u5f71\u54cd\u6781\u5c0f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u4e00\u4e2a\u4e3b\u8981\u95ee\u9898\u662f\u952e\u503c\u7f13\u5b58\u9020\u6210\u7684\u663e\u8457\u5185\u5b58\u74f6\u9888\uff0c\u8fd9\u4e2a\u95ee\u9898\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u5e76\u4e14\u7ecf\u5e38\u8d85\u8fc7\u6a21\u578b\u6743\u91cd\u672c\u8eab\u7684\u5185\u5b58\u5360\u7528\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5b9e\u65bd\u5e76\u6d4b\u8bd5\u4e86\u9488\u5bf9KV\u7f13\u5b58\u538b\u7f29\u7684GPU\u52a0\u901fINT8\u91cf\u5316\u65b9\u6848\uff0c\u5f00\u53d1\u4e86\u56db\u79cdCUDA\u5185\u6838\u53d8\u4f53\u2014\u2014\u6734\u7d20\u578b\u3001\u5206\u5757\u578b\u3001\u7c97\u7cd9\u578b\u548c\u5411\u91cf\u5316\u578b\u2014\u2014\u5e76\u5728\u8fbe\u523010\u4ebf\u5143\u7d20\u7684\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u89c4\u6a21\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5411\u91cf\u5316\u7684\u5185\u6838\u4e0eCPU\u57fa\u7ebf\u76f8\u6bd4\u6700\u9ad8\u53ef\u8fbe\u52301,694\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u91cd\u6784\u8bef\u5dee\u4f4e\u4e8e0.004\u4ee5\u53ca\u6ce8\u610f\u529b\u5206\u6570\u8bef\u5dee\u4f4e\u4e8e0.1\uff0c\u5373\u4f7f\u662f\u57288K\u7ef4\u5934\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "INT8\u91cf\u5316\u4e3a\u51cf\u5c11LLM\u63a8\u7406\u65f6\u7684\u5185\u5b58\u538b\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u5ffd\u7565\u4e0d\u8ba1\u7684\u8ba1\u7b97\u5f00\u9500\uff086-58\u6beb\u79d2\uff09\u5e76\u5bf9\u4e0b\u6e38\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002"}}
{"id": "2601.04728", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04728", "abs": "https://arxiv.org/abs/2601.04728", "authors": ["Elizabeth Donoway", "Hailey Joren", "Fabien Roger", "Jan Leike"], "title": "Excess Description Length of Learning Generalizable Predictors", "comment": null, "summary": "Understanding whether fine-tuning elicits latent capabilities or teaches new ones is a fundamental question for language model evaluation and safety. We develop a formal information-theoretic framework for quantifying how much predictive structure fine-tuning extracts from the train dataset and writes into a model's parameters. Our central quantity, Excess Description Length (EDL), is defined via prequential coding and measures the gap between the bits required to encode training labels sequentially using an evolving model (trained online) and the residual encoding cost under the final trained model. We establish that EDL is non-negative in expectation, converges to surplus description length in the infinite-data limit, and provides bounds on expected generalization gain. Through a series of toy models, we clarify common confusions about information in learning: why random labels yield EDL near zero, how a single example can eliminate many bits of uncertainty about the underlying rule(s) that describe the data distribution, why structure learned on rare inputs contributes proportionally little to expected generalization, and how format learning creates early transients distinct from capability acquisition. This framework provides rigorous foundations for the empirical observation that capability elicitation and teaching exhibit qualitatively distinct scaling signatures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5fae\u8c03\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u5e76\u5199\u5165\u6a21\u578b\u53c2\u6570\u7684\u9884\u6d4b\u7ed3\u6784\u91cf\u3002\u901a\u8fc7\u5b9a\u4e49\u4e00\u4e2a\u6838\u5fc3\u6570\u91cf\u2014\u2014\u8d85\u989d\u63cf\u8ff0\u957f\u5ea6\uff08EDL\uff09\uff0c\u6765\u8861\u91cf\u4f7f\u7528\u5728\u7ebf\u8bad\u7ec3\u6a21\u578b\u987a\u5e8f\u7f16\u7801\u8bad\u7ec3\u6807\u7b7e\u6240\u9700\u6bd4\u7279\u6570\u4e0e\u6700\u7ec8\u8bad\u7ec3\u6a21\u578b\u4e0b\u5269\u4f59\u7f16\u7801\u6210\u672c\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cEDL\u5728\u671f\u671b\u4e0a\u662f\u975e\u8d1f\u7684\uff0c\u5728\u65e0\u9650\u6570\u636e\u9650\u5236\u4e0b\u6536\u655b\u5230\u5269\u4f59\u63cf\u8ff0\u957f\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u9884\u671f\u6cdb\u5316\u589e\u76ca\u7684\u754c\u9650\u3002\u901a\u8fc7\u4e00\u7cfb\u5217\u73a9\u5177\u6a21\u578b\u5b9e\u9a8c\uff0c\u6587\u7ae0\u6f84\u6e05\u4e86\u5173\u4e8e\u5b66\u4e60\u4e2d\u4fe1\u606f\u7684\u4e00\u4e9b\u5e38\u89c1\u8bef\u89e3\u3002", "motivation": "\u7406\u89e3\u5fae\u8c03\u662f\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u80fd\u529b\u8fd8\u662f\u6559\u6388\u65b0\u7684\u80fd\u529b\u662f\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\u3002\u4e3a\u4e86\u8bc4\u4f30\u548c\u4fdd\u8bc1\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u6765\u91cf\u5316\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u63d0\u53d6\u4ee5\u53ca\u5199\u5165\u6a21\u578b\u53c2\u6570\u4e2d\u7684\u9884\u6d4b\u7ed3\u6784\u91cf\u3002", "method": "\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u201c\u8d85\u989d\u63cf\u8ff0\u957f\u5ea6\u201d(Excess Description Length, EDL)\u4f5c\u4e3a\u4e2d\u5fc3\u5ea6\u91cf\u6307\u6807\u3002EDL\u901a\u8fc7\u9884\u5e8f\u7f16\u7801\u5b9a\u4e49\uff0c\u7528\u4ee5\u6d4b\u91cf\u5229\u7528\u9010\u6b65\u8bad\u7ec3\u6a21\u578b\u5bf9\u8bad\u7ec3\u6807\u7b7e\u8fdb\u884c\u5e8f\u5217\u7f16\u7801\u6240\u9700\u7684\u4f4d\u6570\u4e0e\u6700\u7ec8\u8bad\u7ec3\u5b8c\u6210\u540e\u7684\u6a21\u578b\u4e0b\u5269\u4f59\u7f16\u7801\u6210\u672c\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cEDL\u5728\u6570\u5b66\u671f\u671b\u4e0a\u975e\u8d1f\uff1b\u5f53\u6570\u636e\u91cf\u8d8b\u5411\u65e0\u7a77\u5927\u65f6\uff0c\u5b83\u4f1a\u8d8b\u8fd1\u4e8e\u6240\u8c13\u7684\u2018\u5269\u4f59\u63cf\u8ff0\u957f\u5ea6\u2019\uff1b\u540c\u65f6\uff0c\u5b83\u4e5f\u80fd\u591f\u63d0\u4f9b\u5173\u4e8e\u9884\u671f\u6cdb\u5316\u6536\u76ca\u7684\u8fb9\u754c\u4f30\u8ba1\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u51e0\u4e2a\u7b80\u5316\u7248\u6a21\u578b\u6848\u4f8b\uff0c\u8bba\u6587\u8fdb\u4e00\u6b65\u9610\u660e\u4e86\u4e00\u4e9b\u5173\u4e8e\u673a\u5668\u5b66\u4e60\u4e2d\u4fe1\u606f\u5904\u7406\u65b9\u9762\u5e38\u89c1\u7684\u8bef\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u89c2\u5bdf\u5230\u7684\u80fd\u529b\u6fc0\u53d1\u4e0e\u6559\u5b66\u8868\u73b0\u51fa\u5b9a\u6027\u4e0d\u540c\u7684\u6269\u5c55\u7279\u5f81\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.04741", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04741", "abs": "https://arxiv.org/abs/2601.04741", "authors": ["Kota Nakamura", "Koki Kawabata", "Yasuko Matsubara", "Yasushi Sakurai"], "title": "Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams", "comment": "Accepted by KDD 2026", "summary": "Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTimeCast\u7684\u52a8\u6001\u9884\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u591a\u4f20\u611f\u5668\u6570\u636e\u6d41\u4e2d\u7684\u6a21\u5f0f\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u51c6\u786e\u7684\u5b9e\u65f6\u672a\u6765\u4e8b\u4ef6\u65f6\u95f4\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u52a8\u6001\u6027\u3001\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u9488\u5bf9\u4ece\u673a\u5668\u83b7\u53d6\u7684\u5b9e\u65f6\u4f20\u611f\u5668\u6570\u636e\u6d41\uff0c\u5982\u4f55\u6301\u7eed\u9884\u6d4b\u673a\u5668\u6545\u969c\u7684\u53d1\u751f\u65f6\u95f4\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5206\u6790\u591a\u4f20\u611f\u5668\u6570\u636e\u6d41\u6765\u8fde\u7eed\u9884\u6d4b\u672a\u6765\u4e8b\u4ef6\u7684\u65f6\u95f4\u3002", "method": "\u63d0\u51fa\u4e86TimeCast\uff0c\u4e00\u79cd\u4e3a\u9002\u5e94\u6570\u636e\u6d41\u4e2d\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6a21\u5f0f\u800c\u8bbe\u8ba1\u7684\u52a8\u6001\u9884\u6d4b\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u8bc6\u522b\u4e0d\u540c\u7684\u65f6\u95f4\u6f14\u53d8\u6a21\u5f0f\uff08\u5373\u9636\u6bb5\uff09\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u9636\u6bb5\u5b66\u4e60\u72ec\u7acb\u7684\u6a21\u578b\uff0c\u4ece\u800c\u57fa\u4e8e\u6a21\u5f0f\u7684\u53d8\u5316\u505a\u51fa\u81ea\u9002\u5e94\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cTimeCat\u63d0\u4f9b\u4e86\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u80fd\u591f\u5728\u6570\u636e\u6d41\u4e2d\u53d1\u73b0\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "TimeCast\u4f5c\u4e3a\u4e00\u79cd\u5904\u7406\u52a8\u6001\u6027\u8d28\u6570\u636e\u6d41\u7684\u6709\u6548\u65b9\u6848\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u6a21\u578b\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.04751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04751", "abs": "https://arxiv.org/abs/2601.04751", "authors": ["Luca Lanzilao", "Angela Meyer"], "title": "Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models", "comment": null, "summary": "We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u5149\u4f0f\uff08PV\uff09\u529f\u7387\u9884\u6d4b\u6846\u67b6\uff0c\u5e76\u5229\u7528\u8be5\u6846\u67b6\u8bc4\u4f30\u4e86\u4e03\u79cd\u65e5\u5185PV\u529f\u7387\u4e34\u8fd1\u9884\u62a5\u6a21\u578b\u7684\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u603b\u4f53\u6027\u80fd\u3002\u8fd9\u4e9b\u6a21\u578b\u5305\u62ec\u57fa\u4e8e\u536b\u661f\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u5149\u6d41\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u7269\u7406\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\u6a21\u578b\uff0c\u6db5\u76d6\u4e86\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u4e24\u79cd\u5f62\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u536b\u661f\u7684\u65b9\u6cd5\u5728\u77ed\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u7efc\u5408\u9884\u62a5\u7cfb\u7edf(IFS-ENS)\uff0c\u7279\u522b\u662f\u5728\u77ed\u65f6\u95f4\u63d0\u524d\u671f\u5185\u3002SolarSTEPS\u548cSHADECast\u63d0\u4f9b\u4e86\u6700\u51c6\u786e\u7684SSI\u548cPV\u529f\u7387\u9884\u6d4b\uff0c\u800cSHADECast\u5219\u63d0\u4f9b\u4e86\u6700\u53ef\u9760\u7684\u96c6\u5408\u6269\u5c55\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5bf9\u5149\u4f0f\u7535\u7ad9\u53d1\u7535\u91cf\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u8003\u8651\u65f6\u95f4\u548c\u7a7a\u95f4\u53d8\u5316\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u4e3a\u7535\u7f51\u8c03\u5ea6\u53ca\u80fd\u6e90\u7ba1\u7406\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u652f\u6301\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u5149\u4f0f\u529f\u7387\u9884\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u4f7f\u7528\u57fa\u4e8e\u536b\u661f\u7684\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5149\u6d41\u6280\u672f\u4ee5\u53ca\u57fa\u4e8e\u7269\u7406\u539f\u7406\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\u6a21\u578b\u6765\u8fdb\u884c\u9884\u6d4b\uff1b\u7136\u540e\u5c06\u5f97\u5230\u7684\u8f90\u7167\u5ea6\u573a\u8f6c\u6362\u6210\u5b9e\u9645\u7684\u5149\u4f0f\u53d1\u7535\u91cf\uff0c\u5e76\u4e0e\u745e\u58eb\u5883\u51856434\u4e2a\u5149\u4f0f\u7535\u7ad9\u7684\u5b9e\u9645\u751f\u4ea7\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u77ed\u65f6\u95f4\u5185\uff0c\u57fa\u4e8e\u536b\u661f\u7684\u65b9\u6cd5\u6bd4\u7efc\u5408\u9884\u62a5\u7cfb\u7edf(IFS-ENS)\u8868\u73b0\u66f4\u597d\u3002\u5176\u4e2d\uff0cSolarSTEPS\u548cSHADECast\u80fd\u591f\u63d0\u4f9b\u6700\u7cbe\u786e\u7684\u5730\u8868\u592a\u9633\u8f90\u7167\u5ea6(SSI)\u548c\u5149\u4f0f\u529f\u7387\u9884\u6d4b\uff0c\u4e14SHADECast\u5177\u6709\u6700\u4f73\u7684\u96c6\u5408\u5206\u5e03\u3002\u786e\u5b9a\u6027\u6a21\u578bIrradianceNet\u8fbe\u5230\u4e86\u6700\u4f4e\u7684\u5747\u65b9\u6839\u8bef\u5dee\uff0c\u800cSolarSTEPS\u548cSHADECast\u7684\u6982\u7387\u9884\u6d4b\u5219\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u57fa\u4e8e\u536b\u661f\u7684\u6a21\u578b\u663e\u793a\u51fa\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6f5c\u5728\u7684\u64cd\u4f5c\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u5728\u56fd\u5bb6\u5c42\u9762\u4e0a\u4ee5\u4f4e\u4e8e10%\u7684\u76f8\u5bf9\u8bef\u5dee\u9884\u6d4b\u6bcf\u65e5\u603bPV\u53d1\u7535\u91cf\uff0c\u9002\u7528\u4e8e82%\u76842019-2020\u5e74\u671f\u95f4\u7684\u65e5\u5b50\u3002"}}
{"id": "2601.04873", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04873", "abs": "https://arxiv.org/abs/2601.04873", "authors": ["Elisa Roldan", "Kirstie Andrews", "Stephen M. Richardson", "Reyhaneh Fatahian", "Glen Cooper", "Rasool Erfani", "Tasneem Sabir", "Neil D. Reeves"], "title": "FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions", "comment": null, "summary": "Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships.\n  A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps.\n  Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFibreCastML\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u5e38\u89c4\u62a5\u544a\u7684\u7535\u7eba\u53c2\u6570\u9884\u6d4b\u5b8c\u6574\u7684\u7ea4\u7ef4\u76f4\u5f84\u8c31\uff0c\u5e76\u63d0\u4f9b\u5bf9\u8fc7\u7a0b\u7ed3\u6784\u5173\u7cfb\u7684\u53ef\u89e3\u91ca\u89c1\u89e3\u3002\u901a\u8fc7\u4f7f\u7528\u5305\u542b68538\u4e2a\u5355\u72ec\u7ea4\u7ef4\u76f4\u5f84\u6d4b\u91cf\u503c\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u4e86\u4e03\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u975e\u7ebf\u6027\u6a21\u578b\u5728\u591a\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u805a\u5408\u7269\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6eb6\u6db2\u6d53\u5ea6\u88ab\u8ba4\u4e3a\u662f\u7ea4\u7ef4\u76f4\u5f84\u5206\u5e03\u7684\u4e3b\u8981\u5168\u7403\u9a71\u52a8\u56e0\u7d20\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u9884\u6d4b\u4e0e\u5b9e\u9645\u6d4b\u91cf\u7ed3\u679c\u76f8\u7b26\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u7535\u7eba\u8fc7\u7a0b\u4e2d\uff0c\u867d\u7136\u5df2\u7ecf\u5e94\u7528\u4e86\u673a\u5668\u5b66\u4e60\u6765\u4f18\u5316\u5de5\u827a\uff0c\u4f46\u5927\u591a\u6570\u65b9\u6cd5\u4ec5\u80fd\u9884\u6d4b\u5e73\u5747\u7ea4\u7ef4\u76f4\u5f84\uff0c\u800c\u5ffd\u7565\u4e86\u5f71\u54cd\u652f\u67b6\u6027\u80fd\u7684\u6574\u4e2a\u76f4\u5f84\u5206\u5e03\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u5173\u6ce8\u5206\u5e03\u7279\u6027\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6FibreCastML\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1778\u9879\u7814\u7a76\u4e2d\u63d0\u53d6\u51fa\u768468538\u4e2a\u72ec\u7acb\u7ea4\u7ef4\u76f4\u5f84\u6d4b\u91cf\u503c\u7684\u5927\u89c4\u6a21\u5143\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u516d\u4e2a\u6807\u51c6\u5904\u7406\u53c2\u6570\uff08\u5982\u6eb6\u6db2\u6d53\u5ea6\u3001\u65bd\u52a0\u7535\u538b\u7b49\uff09\u8bad\u7ec3\u4e86\u4e03\u79cd\u4e0d\u540c\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u91c7\u7528\u5d4c\u5957\u4ea4\u53c9\u9a8c\u8bc1\u548c\u7559\u4e00\u7814\u7a76\u5916\u6298\u7684\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002\u4e3a\u4e86\u89e3\u91ca\u6a21\u578b\uff0c\u7814\u7a76\u8005\u8fd0\u7528\u4e86\u53d8\u91cf\u91cd\u8981\u6027\u5206\u6790\u3001SHAP\u503c\u3001\u76f8\u5173\u77e9\u9635\u4ee5\u53ca\u4e09\u7ef4\u53c2\u6570\u56fe\u7b49\u591a\u79cd\u624b\u6bb5\u3002", "result": "\u975e\u7ebf\u6027\u6a21\u578b\u76f8\u6bd4\u7ebf\u6027\u57fa\u51c6\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u5728\u51e0\u79cd\u5e7f\u6cdb\u5e94\u7528\u7684\u751f\u7269\u533b\u5b66\u805a\u5408\u7269\u4e0a\u8fbe\u5230\u4e86\u51b3\u5b9a\u7cfb\u6570\u9ad8\u4e8e0.91\u7684\u7ed3\u679c\u3002\u7814\u7a76\u53d1\u73b0\u6eb6\u6db2\u6d53\u5ea6\u662f\u5f71\u54cd\u7ea4\u7ef4\u76f4\u5f84\u5206\u5e03\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u8de8\u4e0d\u540c\u7535\u7eba\u7cfb\u7edf\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u9884\u6d4b\u5f97\u5230\u7684\u7ea4\u7ef4\u76f4\u5f84\u5206\u5e03\u4e0e\u5b9e\u6d4b\u503c\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "FibreCastML\u6846\u67b6\u80fd\u591f\u66f4\u52a0\u51c6\u786e\u5730\u9884\u6d4b\u7535\u7eba\u7ea4\u7ef4\u76f4\u5f84\u7684\u5168\u5206\u5e03\u60c5\u51b5\uff0c\u4e3a\u7535\u7eba\u652f\u67b6\u67b6\u6784\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6570\u636e\u9a71\u52a8\u4f18\u5316\u624b\u6bb5\u3002\u8fd9\u6709\u52a9\u4e8e\u63d0\u9ad8\u7535\u7eba\u6280\u672f\u5728\u7ec4\u7ec7\u5de5\u7a0b\u3001\u836f\u7269\u9012\u9001\u53ca\u4f24\u53e3\u62a4\u7406\u7b49\u9886\u57df\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002"}}
{"id": "2601.04890", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04890", "abs": "https://arxiv.org/abs/2601.04890", "authors": ["Maksim Velikanov", "Ilyas Chahed", "Jingwei Zuo", "Dhia Eddine Rhaiem", "Younes Belkada", "Hakim Hacid"], "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers", "comment": null, "summary": "Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u4e58\u6570\u6765\u4f18\u5316\u6743\u91cd\u77e9\u9635\u89c4\u6a21\u7684\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u770b\u4f5c\u662fmuP\u4e58\u6570\u7684\u4e00\u79cd\u66f4\u5177\u6709\u8868\u8fbe\u529b\u7684\u6cdb\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u7ecf\u8fc7\u826f\u597d\u8c03\u6574\u7684muP\u57fa\u7ebf\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u4e58\u6570\u8c03\u4f18\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u6b64\u5916\uff0c\u4f7f\u7528Adam\u548cMuon\u4f18\u5316\u5668\u65f6\uff0c\u8be5\u65b9\u6cd5\u5747\u663e\u793a\u4e86\u4e0b\u6e38\u8bc4\u4f30\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u7814\u7a76\u8005\u4eec\u6ce8\u610f\u5230\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6743\u91cd\u8870\u51cf\uff08WD\uff09\u4e0e\u968f\u673a\u68af\u5ea6\u566a\u58f0\u4e4b\u95f4\u7684\u5e73\u8861\u5bfc\u81f4\u6743\u91cd\u77e9\u9635W\u7684\u8303\u6570\u5904\u4e8e\u4e00\u4e2a\u6b21\u4f18\u72b6\u6001\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4eba\u5458\u9996\u5148\u5411\u6743\u91cd\u77e9\u9635W\u6dfb\u52a0\u4e86\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u6807\u91cf\u4e58\u6570\uff0c\u5e76\u53d1\u73b0\u901a\u8fc7\u5b66\u4e60\u5f97\u5230\u7684\u6bd4\u4f8b\u5c3a\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u6570\u636e\u5e76\u63d0\u9ad8\u8868\u73b0\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u89e3\u653e\u5355\u884c\u548c\u5355\u5217\u6bd4\u4f8b\u5c3a\u7684\u60f3\u6cd5\uff0c\u901a\u8fc7\u52a0\u5165\u53ef\u5b66\u4e60\u7684\u6bcf\u884c\u53ca\u6bcf\u5217\u4e58\u6570\u5b9e\u73b0\u8fd9\u4e00\u70b9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u7cbe\u5fc3\u8c03\u6574\u8fc7\u7684muP\u57fa\u51c6\uff0c\u8fd8\u964d\u4f4e\u4e86\u4e58\u6570\u8c03\u8282\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e00\u4e9b\u5b9e\u9645\u95ee\u9898\u5982\u524d\u5411\u4f20\u9012\u5bf9\u79f0\u6027\u548c\u5b66\u4e60\u5230\u7684\u4e58\u6570\u968f\u5bbd\u5ea6\u7684\u53d8\u5316\u60c5\u51b5\u3002", "conclusion": "\u603b\u4e4b\uff0c\u8fd9\u79cd\u5229\u7528\u53ef\u5b66\u4e60\u4e58\u6570\u8c03\u6574\u6743\u91cd\u77e9\u9635\u89c4\u6a21\u7684\u65b0\u65b9\u6cd5\uff0c\u88ab\u8bc1\u660e\u5728\u4e0d\u540c\u4f18\u5316\u5668\u4e0b\u90fd\u80fd\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.04954", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04954", "abs": "https://arxiv.org/abs/2601.04954", "authors": ["Yirong Zeng", "Yufei Liu", "Xiao Ding", "Yutai Hou", "Yuxian Wang", "Haonan Song", "Wu Ning", "Dandan Tu", "Qixun Zhang", "Bibo Cai", "Yuxiang He", "Ting Liu"], "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following", "comment": "ACL under review 13 pages, 8 figures", "summary": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u4f7f\u7528\u786c\u7ea6\u675f\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u6df7\u5408\u7ea6\u675f\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u3002\u5956\u52b1\u7cbe\u5ea6\u800c\u975e\u7ea6\u675f\u591a\u6837\u6027\u662f\u6709\u6548\u5bf9\u9f50\u7684\u5173\u952e\u56e0\u7d20\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c2\u5bdf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u91cd\u5956\u52b1\u7cbe\u5ea6\u7684\u6570\u636e\u4f18\u5316\u7b56\u7565\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u63d0\u9ad8\u4e8613.4%\uff0c\u540c\u65f6\u51cf\u5c11\u4e8658%\u7684\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u6311\u6218\u5173\u4e8e\u6307\u4ee4\u8ddf\u968f(IF)\u4efb\u52a1\u4e2d\u9700\u8981\u6df7\u5408\u786c\u8f6f\u7ea6\u675f\u4ee5\u5b9e\u73b0\u6cdb\u5316\u7684\u666e\u904d\u5171\u8bc6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\u63a2\u7d22\u771f\u6b63\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u7cfb\u5217\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u6765\u6bd4\u8f83\u4ec5\u7528\u786c\u7ea6\u675f\u4e0e\u6df7\u5408\u7ea6\u675f\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5e76\u5206\u6790\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u4f5c\u7528\u4ee5\u53ca\u4f4e\u53ec\u56de\u7387\u5bfc\u81f4\u7684\u95ee\u9898\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f18\u5148\u8003\u8651\u5956\u52b1\u7cbe\u5ea6\u7684\u6570\u636e\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4e13\u6ce8\u4e8e\u63d0\u9ad8\u5956\u52b1\u7cbe\u5ea6\u7684\u65b9\u6cd5\u6bd4\u8ffd\u6c42\u6570\u636e\u591a\u6837\u6027\u7684\u4f20\u7edf\u505a\u6cd5\u66f4\u6709\u6548\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u8fd8\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u6240\u9700\u65f6\u95f4\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\uff0c\u9ad8\u7cbe\u5ea6\u5956\u52b1\u6bd4\u7ea6\u675f\u591a\u6837\u6027\u66f4\u91cd\u8981\u3002\u63d0\u5021\u4ece\u5355\u7eaf\u8ffd\u6c42\u6570\u636e\u591a\u6837\u6027\u8f6c\u5411\u91cd\u89c6\u5956\u52b1\u7cbe\u5ea6\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.04977", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04977", "abs": "https://arxiv.org/abs/2601.04977", "authors": ["James Hinns", "Sofie Goethals", "Stephan Van der Veeken", "Theodoros Evgeniou", "David Martens"], "title": "On the Definition and Detection of Cherry-Picking in Counterfactual Explanations", "comment": null, "summary": "Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e2d\u6311\u9009\u6027\u89e3\u91ca\uff08cherry-picking\uff09\u7684\u95ee\u9898\uff0c\u5b9a\u4e49\u4e86\u5728\u7ed9\u5b9a\u751f\u6210\u7a0b\u5e8f\u548c\u6548\u7528\u51fd\u6570\u4e0b\u7684\u53ef\u63a5\u53d7\u89e3\u91ca\u7a7a\u95f4\u4e2d\u7684\u6311\u9009\u884c\u4e3a\uff0c\u5e76\u7814\u7a76\u4e86\u5916\u90e8\u5ba1\u8ba1\u8005\u5728\u4e09\u79cd\u4e0d\u540c\u8bbf\u95ee\u7ea7\u522b\u4e0b\u68c0\u6d4b\u8fd9\u79cd\u64cd\u4f5c\u7684\u53ef\u80fd\u6027\u3002\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u62e5\u6709\u5b8c\u5168\u7684\u8fc7\u7a0b\u8bbf\u95ee\u6743\u9650\uff0c\u7531\u4e8e\u6709\u6548\u53cd\u4e8b\u5b9e\u7684\u591a\u6837\u6027\u4ee5\u53ca\u89e3\u91ca\u89c4\u683c\u7684\u7075\u6d3b\u6027\uff0c\u4f7f\u5f97\u6545\u610f\u9009\u62e9\u96be\u4ee5\u88ab\u5bdf\u89c9\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u53d8\u5f02\u6027\u901a\u5e38\u8d85\u8fc7\u4e86\u57fa\u4e8e\u6807\u51c6\u53cd\u4e8b\u5b9e\u8d28\u91cf\u6307\u6807\u5982\u63a5\u8fd1\u5ea6\u3001\u53ef\u4fe1\u5ea6\u548c\u7a00\u758f\u6027\u7684\u6311\u9009\u6548\u679c\uff0c\u5bfc\u81f4\u6311\u9009\u51fa\u7684\u89e3\u91ca\u4e0e\u57fa\u51c6\u89e3\u91ca\u5728\u7edf\u8ba1\u4e0a\u65e0\u660e\u663e\u5dee\u5f02\u3002\u56e0\u6b64\uff0c\u5efa\u8bae\u5e94\u4f18\u5148\u8003\u8651\u53ef\u91cd\u590d\u6027\u3001\u6807\u51c6\u5316\u548c\u8fc7\u7a0b\u7ea6\u675f\u800c\u975e\u4e8b\u540e\u68c0\u6d4b\u673a\u5236\uff0c\u5e76\u4e3a\u7b97\u6cd5\u5f00\u53d1\u8005\u3001\u89e3\u91ca\u63d0\u4f9b\u8005\u53ca\u5ba1\u8ba1\u4eba\u5458\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u53cd\u4e8b\u5b9e\u89e3\u91ca\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8bf4\u660e\u6a21\u578b\u9884\u6d4b\u53d8\u5316\u6240\u9700\u7684\u8f93\u5165\u53d8\u66f4\uff0c\u5bf9\u4e8e\u5355\u4e2a\u5b9e\u4f8b\u53ef\u80fd\u5b58\u5728\u8bb8\u591a\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u60c5\u51b5\uff0c\u8fd9\u4e3a\u89e3\u91ca\u63d0\u4f9b\u8005\u7559\u4e0b\u4e86\u9009\u62e9\u6027\u5448\u73b0\u89e3\u91ca\u7684\u7a7a\u95f4\uff0c\u53ef\u80fd\u4f1a\u7a81\u51fa\u6709\u5229\u7684\u884c\u4e3a\u800c\u9690\u85cf\u63ed\u793a\u95ee\u9898\u884c\u4e3a\u7684\u4f8b\u5b50\u3002\u672c\u6587\u65e8\u5728\u6b63\u5f0f\u5b9a\u4e49\u8fd9\u4e00\u6311\u9009\u884c\u4e3a\uff0c\u5e76\u63a2\u7d22\u5176\u68c0\u6d4b\u96be\u5ea6\u53ca\u5176\u5bf9\u4fe1\u4efb\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u4e00\u4e2a\u7531\u751f\u6210\u8fc7\u7a0b\u6307\u5b9a\u7684\u53ef\u63a5\u53d7\u89e3\u91ca\u7a7a\u95f4\u548c\u4e00\u4e2a\u6548\u7528\u51fd\u6570\u6765\u5f62\u5f0f\u5316\u63cf\u8ff0\u53cd\u4e8b\u5b9e\u89e3\u91ca\u4e2d\u7684\u6311\u9009\u884c\u4e3a\uff1b\u7136\u540e\uff0c\u5728\u4e09\u79cd\u4e0d\u540c\u7684\u8bbf\u95ee\u7ea7\u522b\u4e0b\uff08\u5b8c\u5168\u8fc7\u7a0b\u8bbf\u95ee\u3001\u90e8\u5206\u8fc7\u7a0b\u8bbf\u95ee\u3001\u4ec5\u89e3\u91ca\u8bbf\u95ee\uff09\uff0c\u7814\u7a76\u5916\u90e8\u5ba1\u8ba1\u8005\u68c0\u6d4b\u6b64\u7c7b\u64cd\u7eb5\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5b9e\u8df5\u4e2d\u68c0\u6d4b\u6311\u9009\u6027\u89e3\u91ca\u662f\u975e\u5e38\u6709\u9650\u7684\u3002\u5373\u4f7f\u662f\u5728\u5b8c\u5168\u8fc7\u7a0b\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\uff0c\u7531\u4e8e\u6709\u6548\u53cd\u4e8b\u5b9e\u7684\u6570\u91cf\u4f17\u591a\u4ee5\u53ca\u89e3\u91ca\u89c4\u8303\u7684\u7075\u6d3b\u6027\uff0c\u4f7f\u5f97\u6545\u610f\u9009\u53d6\u96be\u4ee5\u533a\u5206\u3002\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff0c\u8fd9\u79cd\u53d8\u5f02\u7a0b\u5ea6\u5f80\u5f80\u8d85\u51fa\u4e86\u6839\u636e\u8bf8\u5982\u63a5\u8fd1\u5ea6\u3001\u5408\u7406\u6027\u53ca\u7a00\u758f\u6027\u7b49\u6807\u51c6\u53cd\u4e8b\u5b9e\u8d28\u91cf\u6307\u6807\u6240\u80fd\u6d4b\u91cf\u5230\u7684\u6311\u9009\u6548\u5e94\uff0c\u4ece\u800c\u8ba9\u7ecf\u8fc7\u6311\u9009\u7684\u89e3\u91ca\u4e0e\u975e\u6311\u9009\u7684\u89e3\u91ca\u5728\u7edf\u8ba1\u4e0a\u53d8\u5f97\u65e0\u6cd5\u533a\u5206\u3002", "conclusion": "\u9274\u4e8e\u4e0a\u8ff0\u53d1\u73b0\uff0c\u672c\u6587\u8ba4\u4e3a\u5e94\u8be5\u66f4\u91cd\u89c6\u53ef\u590d\u73b0\u6027\u3001\u6807\u51c6\u5316\u548c\u7a0b\u5e8f\u9650\u5236\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u4e8b\u540e\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u9488\u5bf9\u7b97\u6cd5\u5f00\u53d1\u4eba\u5458\u3001\u89e3\u91ca\u63d0\u4f9b\u8005\u548c\u5ba1\u6838\u5458\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u5efa\u8bae\u63aa\u65bd\u3002"}}
{"id": "2601.05017", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05017", "abs": "https://arxiv.org/abs/2601.05017", "authors": ["Xiaopeng Luo", "Zexi Tan", "Zhuowei Wang"], "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference", "comment": "Submitted to ICASSP 2026", "summary": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u586b\u8865\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u5185\u660e\u786e\u5efa\u6a21\u4e0d\u540c\u7c7b\u578b\u7279\u5f81\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5904\u7406\u7f3a\u5931\u503c\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u4e86\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u7684\u6570\u636e\u586b\u8865\u65b9\u6cd5\u901a\u5e38\u72ec\u7acb\u5904\u7406\u6570\u503c\u548c\u5206\u7c7b\u5c5e\u6027\uff0c\u5ffd\u7565\u4e86\u5f02\u6784\u7279\u5f81\u4e4b\u95f4\u7684\u91cd\u8981\u76f8\u4e92\u4f9d\u8d56\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u4e0d\u540c\u6570\u636e\u7c7b\u578b\u95f4\u4f9d\u8d56\u5173\u7cfb\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u660e\u786e\u5efa\u6a21\u8de8\u7c7b\u578b\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4e14\u5229\u7528\u5b8c\u6574\u4e0e\u4e0d\u5b8c\u6574\u7684\u5b9e\u4f8b\u6765\u4fdd\u8bc1\u8868\u683c\u6570\u636e\u4e2d\u51c6\u786e\u4e00\u81f4\u7684\u586b\u8865\u6548\u679c\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u73b0\u6709\u6280\u672f\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u4e0b\u6e38\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u8868\u73b0\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u4e2d\u7684\u7f3a\u5931\u6570\u636e\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6539\u8fdb\u5bf9\u8de8\u7c7b\u578b\u7279\u5f81\u4f9d\u8d56\u6027\u7684\u7406\u89e3\uff0c\u63d0\u9ad8\u4e86\u6570\u636e\u586b\u8865\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2601.05033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05033", "abs": "https://arxiv.org/abs/2601.05033", "authors": ["Anees Fatima", "Mohammad Abdus Salam"], "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models", "comment": null, "summary": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5c06\u5916\u90e8\u56e0\u7d20\uff08\u5982\u5de5\u4f5c\u65e5\u3001\u8282\u5047\u65e5\u548c\u9500\u552e\u504f\u5dee\u6307\u6807\uff09\u7eb3\u5165\u8003\u8651\uff0c\u4f7f\u7528\u56db\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08XGBoost\u3001ARIMA\u3001Facebook Prophet \u548c SVR\uff09\u6765\u6539\u8fdb\u96f6\u552e\u548c\u81ea\u52a8\u552e\u8d27\u673a\u9886\u57df\u7684\u9700\u6c42\u6570\u91cf\u9884\u6d4b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5916\u90e8\u53d8\u91cf\u7684XGBoost\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u4f4e\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee22.7\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u4f9b\u5e94\u94fe\u7ba1\u7406\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u4e86\u5929\u6c14\u3001\u8282\u65e5\u53ca\u8bbe\u5907\u6545\u969c\u7b49\u5916\u90e8\u5f71\u54cd\u56e0\u7d20\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u4f18\u5316\u5e93\u5b58\u7ba1\u7406\u3001\u51cf\u5c11\u6d6a\u8d39\u4ee5\u53ca\u63d0\u9ad8\u987e\u5ba2\u6ee1\u610f\u5ea6\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5728\u6539\u5584\u96f6\u552e\u4e0e\u81ea\u52a8\u552e\u8d27\u673a\u9886\u57df\u9700\u6c42\u9884\u6d4b\u65b9\u9762\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u4e86\u56db\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff1a\u6781\u9650\u68af\u5ea6\u63d0\u5347(XGBoost)\u3001\u81ea\u56de\u5f52\u6574\u5408\u79fb\u52a8\u5e73\u5747(ARIMA)\u3001Facebook\u5148\u77e5(Fb Prophet)\u548c\u652f\u6301\u5411\u91cf\u56de\u5f52(SVR)\uff0c\u7528\u4e8e\u9884\u6d4b\u5e93\u5b58\u9700\u6c42\u3002\u7cfb\u7edf\u5730\u5f15\u5165\u4e86\u8bf8\u5982\u5de5\u4f5c\u65e5\u3001\u8282\u5047\u65e5\u4ee5\u53ca\u9500\u552e\u504f\u5dee\u6307\u793a\u5668\u7b49\u5916\u90e8\u56e0\u7d20\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "XGBoost\u6a21\u578b\u5728\u52a0\u5165\u4e86\u5916\u90e8\u53d8\u91cf\u540e\u8868\u73b0\u6700\u4f73\uff0c\u5176\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee(MAE)\u8fbe\u5230\u6700\u4f4e\u503c22.7\uff1b\u540c\u65f6\uff0cARIMAX\u548cFb Prophet\u4e5f\u663e\u793a\u51fa\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u800cSVR\u7684\u8868\u73b0\u5219\u4e0d\u5c3d\u4eba\u610f\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c06\u5916\u90e8\u56e0\u7d20\u878d\u5165\u9700\u6c42\u9884\u6d4b\u6a21\u578b\u4e2d\u53ef\u4ee5\u5927\u5e45\u5ea6\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5176\u4e2dXGBoost\u88ab\u8ba4\u5b9a\u4e3a\u6700\u6709\u6548\u7684\u7b97\u6cd5\u3002\u8fd9\u9879\u7814\u7a76\u8868\u660e\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u589e\u5f3a\u96f6\u552e\u548c\u81ea\u52a8\u552e\u8d27\u673a\u7cfb\u7edf\u7684\u5e93\u5b58\u7ba1\u7406\u6c34\u5e73\u3002"}}
{"id": "2601.05073", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05073", "abs": "https://arxiv.org/abs/2601.05073", "authors": ["Jianlong Chen", "Daocheng Fu", "Shengze Xu", "Jiawei Chen", "Yuan Feng", "Yue Yang", "Junchi Yan", "Hongyuan Zha", "Renqiu Xia"], "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b50\u76ee\u6807\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08SGVR\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u51e0\u4f55\u63a8\u7406\u4e2d\u7684\u95ee\u9898\u3002\u901a\u8fc7GeoGoal\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u9aa8\u67b6\u7387\u7684\u5bc6\u96c6\u5956\u52b1\u673a\u5236\uff0c\u5b9e\u9a8c\u8868\u660eSGVR\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51e0\u4f55\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u5728\u6570\u5b66\u53ca\u5176\u4ed6\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5904\u7406\u590d\u6742\u7684\u51e0\u4f55\u63a8\u7406\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u57fa\u4e8e\u7ed3\u679c\u7684\u2018\u9ed1\u7bb1\u2019\u76d1\u7763\u65b9\u6cd5\u65e0\u6cd5\u533a\u5206\u5e78\u8fd0\u731c\u6d4b\u4e0e\u4e25\u8c28\u63a8\u5bfc\u3002", "method": "\u9996\u5148\u521b\u5efa\u4e86GeoGoal\u8fd9\u4e00\u57fa\u51c6\uff0c\u5b83\u901a\u8fc7\u4e25\u683c\u7684\u5f62\u5f0f\u9a8c\u8bc1\u6570\u636e\u5f15\u64ce\u5c06\u62bd\u8c61\u8bc1\u660e\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u7684\u6570\u503c\u5b50\u76ee\u6807\uff1b\u63a5\u7740\u63d0\u51fa\u4e86\u5b50\u76ee\u6807\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08SGVR\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528Skeleton Rate\u6765\u66ff\u4ee3\u7a00\u758f\u4fe1\u53f7\uff0c\u63d0\u4f9b\u57fa\u4e8e\u5b50\u76ee\u6807\u5b8c\u6210\u5ea6\u7684\u5bc6\u96c6\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cSGVR\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff08+9.7%\uff09\uff0c\u540c\u65f6\u5728\u66f4\u5e7f\u6cdb\u7684\u6570\u5b66(+8.0%)\u548c\u5176\u4ed6\u4e00\u822c\u63a8\u7406\u4efb\u52a1(+2.8%)\u4e2d\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u663e\u793a\uff0c\u901a\u8fc7\u5f15\u5165\u5b50\u76ee\u6807\u7ea7\u522b\u7684\u8bc4\u4f30\u4e0e\u5b66\u4e60\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u6539\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u51e0\u4f55\u63a8\u7406\u53ca\u5176\u4ed6\u76f8\u5173\u9886\u57df\u7684\u63a8\u7406\u8d28\u91cf\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2601.05082", "categories": ["cs.LG", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05082", "abs": "https://arxiv.org/abs/2601.05082", "authors": ["Hayk Asatryan", "Basile Tousside", "Janis Mohr", "Malte Neugebauer", "Hildo Bijl", "Paul Spiegelberg", "Claudia Frohn-Schauf", "J\u00f6rg Frochte"], "title": "Exploring Student Expectations and Confidence in Learning Analytics", "comment": "7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering", "summary": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5b66\u751f\u5b66\u4e60\u5206\u6790\u671f\u671b\u95ee\u5377\uff08SELAQ\uff09\u6765\u8c03\u67e5\u4e0d\u540c\u5b66\u9662\u5b66\u751f\u5bf9\u4e3a\u5b66\u4e60\u5206\u6790\u76ee\u7684\u5904\u7406\u5176\u6570\u636e\u7684\u671f\u671b\u548c\u4fe1\u5fc3\uff0c\u901a\u8fc7\u805a\u7c7b\u7b97\u6cd5\u8bc6\u522b\u51fa\u56db\u79cd\u7c7b\u578b\u7684\u5b66\u751f\uff1a\u70ed\u60c5\u8005\u3001\u73b0\u5b9e\u4e3b\u4e49\u8005\u3001\u8c28\u614e\u8005\u548c\u6f20\u4e0d\u5173\u5fc3\u8005\u3002", "motivation": "\u9274\u4e8e\u5b66\u4e60\u5206\u6790\u5728\u6559\u80b2\u7cfb\u7edf\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u540c\u65f6\u9700\u8981\u9075\u5b88\u9690\u79c1\u7acb\u6cd5\u7684\u8981\u6c42\uff0c\u7814\u7a76\u65e8\u5728\u7406\u89e3\u5b66\u751f\u5bf9\u4e8e\u5229\u7528\u4ed6\u4eec\u7684\u6570\u636e\u8fdb\u884c\u5b66\u4e60\u5206\u6790\u7684\u6001\u5ea6\u4e0e\u671f\u671b\u3002", "method": "\u91c7\u7528\u5b66\u751f\u5b66\u4e60\u5206\u6790\u671f\u671b\u95ee\u5377\uff08SELAQ\uff09\u6536\u96c6\u6570\u636e\uff0c\u5e76\u8fd0\u7528\u805a\u7c7b\u7b97\u6cd5\u5bf9\u5b66\u751f\u7fa4\u4f53\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u56db\u79cd\u7c7b\u522b\u7684\u5b66\u751f\u6001\u5ea6\uff1a\u70ed\u60c5\u8005\u3001\u73b0\u5b9e\u4e3b\u4e49\u8005\u3001\u8c28\u614e\u8005\u4ee5\u53ca\u6f20\u4e0d\u5173\u5fc3\u8005\u3002\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u5b66\u751f\u95f4\u5bf9\u5b66\u4e60\u5206\u6790\u7684\u4e0d\u540c\u63a5\u53d7\u5ea6\u53ca\u6279\u8bc4\u610f\u89c1\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u5b66\u751f\u5173\u4e8e\u5b66\u4e60\u5206\u6790\u7684\u6570\u636e\u5904\u7406\u6001\u5ea6\u7684\u7814\u7a76\uff0c\u6211\u4eec\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316\u5b66\u4e60\u73af\u5883\uff0c\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u5728\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u8003\u8651\u5b66\u751f\u4e2a\u4f53\u5dee\u5f02\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.05134", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05134", "abs": "https://arxiv.org/abs/2601.05134", "authors": ["Polina Dolgova", "Sebastian U. Stich"], "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning", "comment": null, "summary": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,\u03b4)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u8ba4\u8bc1\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u53c2\u6570\u7a7a\u95f4\u7684\u6b63\u4ea4\u5b50\u7a7a\u95f4\u4e2d\u5206\u914d\u566a\u58f0\u9884\u7b97\uff0c\u800c\u4e0d\u662f\u4e00\u6b21\u6027\u6ce8\u5165\u6240\u6709\u566a\u58f0\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u539f\u6709\u8ba4\u8bc1\u4fdd\u8bc1\u7684\u540c\u65f6\u51cf\u8f7b\u4e86\u566a\u58f0\u7684\u7834\u574f\u6027\u5f71\u54cd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9057\u5fd8\u540e\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u8ba4\u8bc1\u9057\u5fd8\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u4fdd\u8bc1\uff0c\u4f46\u4f1a\u4e25\u91cd\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u5e8f\u5217\u566a\u58f0\u8c03\u5ea6\u7684\u65b9\u6cd5\uff0c\u5728\u53c2\u6570\u7a7a\u95f4\u7684\u6b63\u4ea4\u5b50\u7a7a\u95f4\u4e2d\u5206\u5e03\u566a\u58f0\u9884\u7b97\u800c\u975e\u4e00\u6b21\u5168\u90e8\u52a0\u5165\u3002\u8fd8\u6269\u5c55\u4e86\u5bf9\u542b\u566a\u5fae\u8c03\u5230\u5b50\u7a7a\u95f4\u8bbe\u7f6e\u4e0b\u7684\u5206\u6790\uff0c\u8bc1\u660e\u53ef\u4ee5\u4fdd\u6301\u76f8\u540c\u7684(\u03b5,\u03b4)\u9690\u79c1\u9884\u7b97\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6267\u884c\u9057\u5fd8\u540e\u5927\u5927\u63d0\u5347\u4e86\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4ecd\u80fd\u62b5\u6297\u6210\u5458\u63a8\u7406\u653b\u51fb\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u8ba4\u8bc1\u9057\u5fd8\u53ef\u4ee5\u5728\u63d0\u4f9b\u4e25\u683c\u4fdd\u969c\u7684\u540c\u65f6\u5b9e\u73b0\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.05194", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05194", "abs": "https://arxiv.org/abs/2601.05194", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Holley Farley", "Kimia Ghobadi"], "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment", "comment": "arXiv admin note: substantial text overlap with arXiv:2510.20714", "summary": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u7ea6\u675f\u8bc4\u5206\u4f18\u5316\uff08CSO\uff09\u6a21\u578b\uff0c\u6539\u8fdb\u4e86\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\uff08JHFRAT\uff09\u7684\u8868\u73b0\uff0c\u63d0\u9ad8\u4e86\u5bf9\u9ad8\u8dcc\u5012\u98ce\u9669\u60a3\u8005\u7684\u8bc6\u522b\u80fd\u529b\u3002\u5c3d\u7ba1\u9ed1\u76d2\u6a21\u578b\u5982XGBoost\u5728\u6027\u80fd\u6307\u6807\u4e0a\u66f4\u4f18\uff0c\u4f46CSO\u6a21\u578b\u663e\u793a\u51fa\u4e86\u5bf9\u4e8e\u98ce\u9669\u6807\u7b7e\u53d8\u5316\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u5c06\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\u4e0e\u989d\u5916\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u5ea6\u91cf\u6807\u51c6\u76f8\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u63d0\u5347\u5176\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u56de\u987e\u6027\u961f\u5217\u5206\u6790\u6cd5\uff0c\u9488\u5bf92022\u5e743\u6708\u81f32023\u5e7410\u6708\u671f\u95f4\u6765\u81ea\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u536b\u751f\u7cfb\u7edf\u4e09\u5bb6\u533b\u9662\u768454,209\u4f8b\u4f4f\u9662\u75c5\u4f8b\u8fdb\u884c\u7814\u7a76\u3002\u4f7f\u7528\u7ea6\u675f\u8bc4\u5206\u4f18\u5316(CSO)\u6a21\u578b\u91cd\u65b0\u8c03\u6574JHFRAT\u8bc4\u5206\u6743\u91cd\uff0c\u5728\u4fdd\u6301\u5176\u52a0\u6027\u7ed3\u6784\u548c\u4e34\u5e8a\u9608\u503c\u7684\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "result": "CSO\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd(AUC-ROC=0.91)\uff0c\u76f8\u8f83\u4e8e\u539f\u59cbJHFRAT(AUC-ROC=0.86)\u6bcf\u5468\u53ef\u989d\u5916\u4fdd\u62a4\u7ea635\u4f4d\u9ad8\u98ce\u9669\u60a3\u8005\u3002\u867d\u7136\u57fa\u51c6\u9ed1\u76d2\u6a21\u578b(XGBoost)\u5728\u6027\u80fd\u6307\u6807\u4e0a\u7565\u80dc\u4e00\u7b79(AUC-ROC=0.94)\uff0c\u4f46CSO\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u98ce\u9669\u6807\u7b7e\u53d8\u5316\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u4e3a\u533b\u7597\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u57fa\u7840\uff0c\u4ee5\u7cfb\u7edf\u5730\u589e\u5f3a\u4f4f\u9662\u60a3\u8005\u8dcc\u5012\u9884\u9632\u534f\u8bae\u53ca\u60a3\u8005\u5b89\u5168\u63aa\u65bd\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u4f18\u5316\u6280\u672f\u4fc3\u8fdb\u98ce\u9669\u8bc4\u4f30\u548c\u8d44\u6e90\u5206\u914d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.05245", "categories": ["cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05245", "abs": "https://arxiv.org/abs/2601.05245", "authors": ["Natalie Collina", "Jiuyao Lu", "Georgy Noarov", "Aaron Roth"], "title": "Optimal Lower Bounds for Online Multicalibration", "comment": null, "summary": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.\n  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $\u03a9(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.\n  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetilde\u03a9(T^{2/3})$ lower bound for online multicalibration via a $\u0398(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u7ebf\u591a\u6821\u51c6\u7684\u7d27\u81f4\u4e0b\u754c\uff0c\u8868\u660e\u5b83\u4e0e\u8fb9\u9645\u6821\u51c6\u5728\u4fe1\u606f\u7406\u8bba\u4e0a\u662f\u5206\u79bb\u7684\u3002\u5bf9\u4e8e\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u548c\u5b66\u4e60\u8005\u9884\u6d4b\u7684\u7fa4\u7ec4\u51fd\u6570\uff0c\u8bc1\u660e\u4e86\u4e00\u4e2a\u03a9(T^2/3)\u7684\u9884\u671f\u591a\u6821\u51c6\u8bef\u5dee\u4e0b\u754c\uff1b\u5bf9\u4e8e\u4ec5\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u800c\u4e0d\u4f9d\u8d56\u4e8e\u5b66\u4e60\u8005\u9884\u6d4b\u7684\u60c5\u51b5\uff0c\u5219\u5efa\u7acb\u4e86\u03a9~(T^2/3)\u7684\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u7ebf\u591a\u6821\u51c6\uff08\u76f8\u5bf9\u4e8e\u8fb9\u9645\u6821\u51c6\uff09\u7684\u57fa\u672c\u9650\u5236\uff0c\u5e76\u901a\u8fc7\u8bc1\u660e\u7d27\u81f4\u4e0b\u754c\u6765\u5c55\u793a\u4e24\u8005\u4e4b\u95f4\u7684\u4fe1\u606f\u7406\u8bba\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u65b9\u6cd5\u5206\u6790\u5728\u7ebf\u591a\u6821\u51c6\u95ee\u9898\uff0c\u6784\u9020\u7279\u5b9a\u793a\u4f8b\u4ee5\u8bc1\u660e\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u7fa4\u7ec4\u51fd\u6570\uff0c\u591a\u6821\u51c6\u8bef\u5dee\u7684\u7406\u8bba\u4e0b\u754c\u3002", "result": "\u5bf9\u4e8e\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u548c\u9884\u6d4b\u7684\u7fa4\u7ec4\u51fd\u6570\uff0c\u8bc1\u660e\u4e86\u03a9(T^2/3)\u7684\u591a\u6821\u51c6\u8bef\u5dee\u4e0b\u754c\uff1b\u5bf9\u4e8e\u4ec5\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u7684\u60c5\u5f62\uff0c\u5229\u7528\u6b63\u4ea4\u51fd\u6570\u7cfb\u7edf\u6784\u5efa\u4e86\u4e00\u65cf\u5927\u5c0f\u4e3a\u0398(T)\u7684\u7fa4\u7ec4\uff0c\u8bc1\u660e\u4e86\u03a9~(T^2/3)\u7684\u4e0b\u754c\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e0e\u5df2\u77e5\u4e0a\u754c\u76f8\u5339\u914d\uff0c\u9664\u53bb\u4e86\u5bf9\u6570\u56e0\u5b50\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u7ebf\u591a\u6821\u51c6\u4e0e\u8fb9\u9645\u6821\u51c6\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u7684\u533a\u522b\uff0c\u4e14\u5bf9\u4e8e\u8003\u8651\u7684\u4e0d\u540c\u60c5\u51b5\u90fd\u7ed9\u51fa\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u754c\u9650\u3002"}}
