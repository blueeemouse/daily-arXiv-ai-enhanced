{"id": "2601.05296", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.05296", "abs": "https://arxiv.org/abs/2601.05296", "authors": ["Jiyuan Zhang", "Yining Liu", "Siqi Yan", "Lisen Deng", "Jennifer Cao", "Shuqi Yang", "Min Ni", "Bi Xue", "Shen Li"], "title": "MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs", "comment": null, "summary": "The pervasive \"memory wall\" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.", "AI": {"tldr": "MoEBlaze, a memory-efficient MoE training framework, addresses the memory wall bottleneck in large-scale Mixture-of-Experts (MoE) architectures by eliminating intermediate buffers and optimizing data structures, achieving over 4x speedups and over 50% memory savings.", "motivation": "The motivation of this paper is to address the significant 'memory wall' bottleneck that is amplified in modern large-scale Mixture-of-Experts (MoE) architectures, which limits the maximum batch size and sequence length on GPUs and results in excessive data movements, hindering performance and efficient model scaling.", "method": "The authors present MoEBlaze, a memory-efficient MoE training framework. The method involves an end-to-end token dispatch and MoE training approach with optimized data structures to remove the need for intermediate buffers and activation materialization. Additionally, it uses co-designed kernels with smart activation checkpointing to reduce memory footprint while improving performance.", "result": "The result of using MoEBlaze is a significant improvement in both speed and memory usage. Specifically, the framework achieves over 4 times the speed and more than 50% reduction in memory consumption compared to existing MoE frameworks.", "conclusion": "In conclusion, the MoEBlaze framework effectively tackles the memory pressure and performance issues associated with large-scale MoE models, offering substantial improvements in computational efficiency and scalability."}}
{"id": "2601.05300", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05300", "abs": "https://arxiv.org/abs/2601.05300", "authors": ["Susmit Das"], "title": "TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning", "comment": "14 pages, 3 figures with 27 page appendix. See https://github.com/The-Coherence-Initiative/TIME and https://github.com/The-Coherence-Initiative/TIMEBench for associated code", "summary": "Reasoning oriented large language models often expose explicit \"thinking\" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aTIME\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u53ef\u9009\u7684ISO 8601\u65f6\u95f4\u6807\u7b7e\u3001\u8868\u793a\u6c89\u9ed8\u95f4\u9694\u7684tick turns\u4ee5\u53ca\u53ef\u4ee5\u5728\u56de\u590d\u4e2d\u4efb\u610f\u4f4d\u7f6e\u51fa\u73b0\u7684\u77ed<think>\u5757\u6765\u589e\u5f3a\u5bf9\u8bdd\u6a21\u578b\u3002TIME\u80fd\u591f\u4ee5\u66f4\u7d27\u51d1\u7684\u65b9\u5f0f\u89e6\u53d1\u660e\u786e\u63a8\u7406\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u89c4\u6a21\u4e0b\u90fd\u63d0\u9ad8\u4e86TIMEBench\u57fa\u51c6\u6d4b\u8bd5\u5f97\u5206\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u63a8\u7406\u6807\u8bb0\u4f7f\u7528\u91cf\u3002", "motivation": "\u5f53\u524d\u9762\u5411\u63a8\u7406\u7684\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u5728\u6bcf\u4e2a\u54cd\u5e94\u5f00\u59cb\u65f6\u66b4\u9732\u663e\u5f0f\u201c\u601d\u8003\u201d\u8fc7\u7a0b\uff0c\u8fd9\u867d\u7136\u6709\u52a9\u4e8e\u7b97\u672f\u3001\u7f16\u7a0b\u548c\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u6210\u672c\u9ad8\u6602\u3001\u6a21\u7cca\u4e86\u58f0\u660e\u7ea7\u522b\u7684\u53ef\u5ba1\u8ba1\u6027\uff0c\u4e14\u4e00\u65e6\u6a21\u578b\u5f00\u59cb\u5c55\u793a\u4fbf\u65e0\u6cd5\u91cd\u65b0\u89e6\u53d1\u663e\u5f0f\u63a8\u7406\u3002\u6b64\u5916\uff0c\u5bf9\u8bdd\u6a21\u578b\u5bf9\u65f6\u95f4\u7ed3\u6784\u4e0d\u591f\u654f\u611f\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86TIME\u6846\u67b6\u3002", "method": "TIME\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u53ef\u9009\u7684ISO 8601 <time>\u6807\u7b7e\u3001\u4ee3\u8868\u9759\u9ed8\u95f4\u9699\u7684tick turns\u53ca\u53ef\u5728\u4efb\u4f55\u4f4d\u7f6e\u51fa\u73b0\u7684\u77ed<think>\u5757\u6765\u589e\u5f3a\u5bf9\u8bdd\u5185\u5bb9\u3002\u91c7\u7528\u56db\u9636\u6bb5\u8bfe\u7a0b\u8bad\u7ec3Qwen3\u5bc6\u96c6\u6a21\u578b\uff0c\u5305\u62ec\u4e00\u4e2a\u5c0f\u6279\u91cf\u6700\u5927\u591a\u6837\u5316\u5168\u6279\u6b21\u5bf9\u9f50\u6b65\u9aa4\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u9700\u8981\u7684\u5730\u65b9\u8c03\u7528\u7b80\u77ed\u7684\u63a8\u7406\u7206\u53d1\u5e76\u4fdd\u6301\u7528\u6237\u53ef\u89c1\u6587\u672c\u7d27\u51d1\u3002", "result": "\u8de84B\u523032B\u89c4\u6a21\uff0cTIME\u76f8\u6bd4\u57fa\u7840Qwen3\u5728\u601d\u8003\u4e0e\u975e\u601d\u8003\u6a21\u5f0f\u4e0b\u5747\u63d0\u9ad8\u4e86TIMEBench\u5206\u6570\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u6807\u8bb0\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u5de6\u53f3\u3002", "conclusion": "TIME\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u654f\u611f\u548c\u65f6\u95f4\u7ebf\u7d22\u9a71\u52a8\u7684\u663e\u5f0f\u63a8\u7406\u673a\u5236\u6539\u8fdb\u4e86\u5bf9\u8bdd\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f7f\u5176\u66f4\u52a0\u9ad8\u6548\u548c\u7075\u6d3b\u3002"}}
{"id": "2601.05385", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05385", "abs": "https://arxiv.org/abs/2601.05385", "authors": ["Debangshu Banerjee", "Olivier Bouissou", "Stefan Zetzsche"], "title": "DafnyPro: LLM-Assisted Automated Verification for Dafny Programs", "comment": null, "summary": "We present DafnyPro, an inference-time framework that enhances LLMs for generating verification annotations in Dafny. DafnyPro comprises three key components: a diff-checker that prevents modifications to base program logic, a pruner that removes unnecessary invariants, and a hint-augmentation system that retrieves and applies predefined, problem-independent proof strategies. We evaluate DafnyPro using Claude Sonnet 3.5 and 3.7 on four benchmarks: Clover, MBPP-Dafny, HumanEval-Dafny, and DafnyBench, achieving consistent performance gains in all cases. Notably, on DafnyBench, the most challenging benchmark, Claude Sonnet 3.5 enhanced with DafnyPro achieves 86% correct proofs, a 16 pp improvement over the base model. We also fine-tune two Qwen models on training data derived from verification attempts by larger models enhanced with DafnyPro. Our 7B and 14B models achieve 68% and 70% correct proofs on DafnyBench, respectively, demonstrating that smaller models can maintain high verification accuracy.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86DafnyPro\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5305\u542b\u5dee\u5f02\u68c0\u67e5\u5668\u3001\u526a\u679d\u5668\u548c\u63d0\u793a\u589e\u5f3a\u7cfb\u7edf\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u6765\u63d0\u9ad8LLM\u5728\u751f\u6210Dafny\u9a8c\u8bc1\u6ce8\u91ca\u65b9\u9762\u7684\u80fd\u529b\u3002\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86Claude Sonnet 3.5\u548c3.7\u6a21\u578b\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u7ecf\u8fc7DafnyPro\u589e\u5f3a\u7684\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u5fae\u8c03\u540e\u7684\u8f83\u5c0fQwen\u6a21\u578b\u4e5f\u8fbe\u5230\u4e86\u8f83\u9ad8\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210Dafny\u7a0b\u5e8f\u9a8c\u8bc1\u6ce8\u89e3\u65f6\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDafnyPro\u7684\u65b0\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u4e86DafnyPro\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u62ec\uff1a\u9632\u6b62\u4fee\u6539\u57fa\u7840\u7a0b\u5e8f\u903b\u8f91\u7684\u5dee\u5f02\u68c0\u67e5\u5668\u3001\u53bb\u9664\u4e0d\u5fc5\u8981\u4e0d\u53d8\u91cf\u7684\u526a\u679d\u5668\u4ee5\u53ca\u5e94\u7528\u9884\u5b9a\u4e49\u8bc1\u660e\u7b56\u7565\u7684\u63d0\u793a\u589e\u5f3a\u7cfb\u7edf\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9\u4e24\u4e2aQwen\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u4e8eDafnyPro\u589e\u5f3a\u540e\u5927\u6a21\u578b\u5c1d\u8bd5\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6700\u5177\u6311\u6218\u6027\u7684DafnyBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528DafnyPro\u589e\u5f3a\u7684Claude Sonnet 3.5\u6a21\u578b\u6bd4\u57fa\u7840\u6a21\u578b\u6b63\u786e\u8bc1\u660e\u7684\u6bd4\u4f8b\u63d0\u9ad8\u4e8616\u4e2a\u767e\u5206\u70b9\uff0c\u8fbe\u523086%\u3002\u53e6\u5916\uff0c\u7ecf\u8fc7\u5fae\u8c03\u76847B\u548c14B Qwen\u6a21\u578b\u5206\u522b\u5b9e\u73b0\u4e8668%\u548c70%\u7684\u6b63\u786e\u8bc1\u660e\u7387\u3002", "conclusion": "DafnyPro\u6709\u6548\u5730\u63d0\u5347\u4e86\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5728Dafny\u7a0b\u5e8f\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u662f\u8f83\u5c0f\u89c4\u6a21\u7684\u6a21\u578b\u4e5f\u80fd\u4fdd\u6301\u8f83\u9ad8\u7684\u9a8c\u8bc1\u51c6\u786e\u6027\u3002"}}
{"id": "2601.05352", "categories": ["cs.LG", "cs.CR", "cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.05352", "abs": "https://arxiv.org/abs/2601.05352", "authors": ["Tianrun Yu", "Kaixiang Zhao", "Cheng Zhang", "Anjun Gao", "Yueyang Quan", "Zhuqing Liu", "Minghong Fang"], "title": "When the Server Steps In: Calibrated Updates for Fair Federated Learning", "comment": null, "summary": "Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u670d\u52a1\u5668\u7aef\u53bb\u504f\u65b9\u6cd5EquFL\uff0c\u7528\u4e8e\u51cf\u5c11\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u504f\u7f6e\u3002\u901a\u8fc7\u5141\u8bb8\u670d\u52a1\u5668\u5728\u63a5\u6536\u5ba2\u6237\u7aef\u6a21\u578b\u66f4\u65b0\u540e\u751f\u6210\u4e00\u4e2a\u6821\u51c6\u66f4\u65b0\uff0c\u5e76\u5c06\u5176\u4e0e\u805a\u5408\u7684\u5ba2\u6237\u7aef\u66f4\u65b0\u96c6\u6210\uff0c\u4ece\u800c\u4ea7\u751f\u4e00\u4e2a\u8c03\u6574\u540e\u7684\u5168\u5c40\u6a21\u578b\u4ee5\u51cf\u5c11\u504f\u7f6e\u3002\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cEquFL\u80fd\u591f\u6709\u6548\u51cf\u5c11\u516c\u5e73\u6027\u635f\u5931\u5e76\u663e\u8457\u7f13\u89e3\u7cfb\u7edf\u5185\u7684\u504f\u7f6e\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4f46\u5728\u786e\u4fdd\u4e0d\u540c\u4eba\u7fa4\u7ec4\u4e4b\u95f4\u7684\u516c\u5e73\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u7684\u8bb8\u591a\u516c\u5e73\u611f\u77e5\u53bb\u504f\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u4fee\u6539\u5ba2\u6237\u7aef\u7684\u8bad\u7ec3\u534f\u8bae\uff0c\u8981\u4e48\u5728\u805a\u5408\u7b56\u7565\u4e0a\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEquFL\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u670d\u52a1\u5668\u7aef\u53bb\u504f\u6280\u672f\uff0c\u65e8\u5728\u901a\u8fc7\u751f\u6210\u4e00\u4e2a\u7ecf\u8fc7\u6821\u51c6\u7684\u66f4\u65b0\u6765\u51cf\u8f7b\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u504f\u7f6e\u3002\u6b64\u6821\u51c6\u66f4\u65b0\u968f\u540e\u4e0e\u6765\u81ea\u5ba2\u6237\u7aef\u7684\u805a\u5408\u66f4\u65b0\u76f8\u7ed3\u5408\uff0c\u4ee5\u521b\u5efa\u4e00\u4e2a\u65e8\u5728\u51cf\u5c11\u504f\u7f6e\u7684\u8c03\u6574\u540e\u5168\u7403\u6a21\u578b\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86EquFL\u53ef\u4ee5\u6536\u655b\u5230FedAvg\u6240\u8fbe\u5230\u7684\u6700\u4f73\u5168\u5c40\u6a21\u578b\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u8bad\u7ec3\u8f6e\u6b21\u4e2d\u6709\u6548\u5730\u51cf\u5c11\u516c\u5e73\u6027\u635f\u5931\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cEquFL\u80fd\u591f\u663e\u8457\u5730\u51cf\u8f7b\u7cfb\u7edf\u5185\u90e8\u7684\u504f\u7f6e\u95ee\u9898\u3002", "conclusion": "EquFL\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u670d\u52a1\u5668\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u9700\u8981\u5bf9\u5ba2\u6237\u7aef\u8fdb\u884c\u989d\u5916\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u504f\u7f6e\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.05449", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05449", "abs": "https://arxiv.org/abs/2601.05449", "authors": ["Theodore Chambers", "Arturo Miguel Russell Bernal", "Michael Vierhauser", "Jane Cleland-Huang"], "title": "Uncovering Failures in Cyber-Physical System State Transitions: A Fuzzing-Based Approach Applied to sUAS", "comment": "13 pages, ~7 figures; author-accepted manuscript accepted for ICSE 2026", "summary": "The increasing deployment of small Uncrewed Aerial Systems (sUAS) in diverse and often safety-critical environments demands rigorous validation of onboard decision logic under various conditions. In this paper, we present SaFUZZ, a state-aware fuzzing pipeline that validates core behavior associated with state transitions, automated failsafes, and human operator interactions in sUAS applications operating under various timing conditions and environmental disturbances. We create fuzzing specifications to detect behavioral deviations, and then dynamically generate associated Fault Trees to visualize states, modes, and environmental factors that contribute to the failure, thereby helping project stakeholders to analyze the failure and identify its root causes. We validated SaFUZZ against a real-world sUAS system and were able to identify several points of failure not previously detected by the system's development team. The fuzzing was conducted in a high-fidelity simulation environment, and outcomes were validated on physical sUAS in a real-world field testing setting. The findings from the study demonstrated SaFUZZ's ability to provide a practical and scalable approach to uncovering diverse state transition failures in a real-world sUAS application.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSaFUZZ\u7684\u72b6\u6001\u611f\u77e5\u6a21\u7cca\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u7528\u4e8e\u9a8c\u8bc1\u5c0f\u578b\u65e0\u4eba\u9a7e\u9a76\u822a\u7a7a\u7cfb\u7edf(sUAS)\u5728\u4e0d\u540c\u65f6\u95f4\u548c\u73af\u5883\u6761\u4ef6\u4e0b\u7684\u6838\u5fc3\u884c\u4e3a\u3002\u901a\u8fc7\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u89c4\u8303\u6765\u68c0\u6d4b\u884c\u4e3a\u504f\u5dee\uff0c\u5e76\u751f\u6210\u6545\u969c\u6811\u4ee5\u5e2e\u52a9\u5206\u6790\u5931\u8d25\u539f\u56e0\u3002\u7ecf\u7531\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\u548c\u5b9e\u9645sUAS\u5b9e\u5730\u6d4b\u8bd5\u9a8c\u8bc1\uff0cSaFUZZ\u80fd\u591f\u6709\u6548\u63ed\u793a\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u591a\u79cd\u72b6\u6001\u8f6c\u6362\u5931\u8d25\u60c5\u51b5\u3002", "motivation": "\u968f\u7740\u5c0f\u578b\u65e0\u4eba\u9a7e\u9a76\u822a\u7a7a\u7cfb\u7edf(sUAS)\u5728\u5404\u79cd\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72\uff0c\u5bf9\u5176\u673a\u8f7d\u51b3\u7b56\u903b\u8f91\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u4e25\u683c\u9a8c\u8bc1\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86SaFUZZ\uff0c\u4e00\u79cd\u72b6\u6001\u611f\u77e5\u7684\u6a21\u7cca\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u5b83\u80fd\u591f\u9a8c\u8bc1\u4e0e\u72b6\u6001\u8f6c\u6362\u3001\u81ea\u52a8\u6545\u969c\u4fdd\u62a4\u4ee5\u53ca\u4eba\u7c7b\u64cd\u4f5c\u5458\u4ea4\u4e92\u76f8\u5173\u7684\u6838\u5fc3\u884c\u4e3a\uff1b\u521b\u5efa\u4e86\u7528\u4e8e\u68c0\u6d4b\u884c\u4e3a\u504f\u5dee\u7684\u6a21\u7cca\u6d4b\u8bd5\u89c4\u8303\uff0c\u5e76\u52a8\u6001\u751f\u6210\u76f8\u5173\u7684\u6545\u969c\u6811\u6765\u53ef\u89c6\u5316\u5bfc\u81f4\u5931\u8d25\u7684\u72b6\u6001\u3001\u6a21\u5f0f\u53ca\u73af\u5883\u56e0\u7d20\u3002", "result": "\u901a\u8fc7\u5bf9\u4e00\u4e2a\u73b0\u5b9e\u4e16\u754c\u7684sUAS\u7cfb\u7edf\u8fdb\u884cSaFUZZ\u9a8c\u8bc1\uff0c\u53d1\u73b0\u4e86\u5f00\u53d1\u56e2\u961f\u4e4b\u524d\u672a\u68c0\u6d4b\u5230\u7684\u591a\u4e2a\u6545\u969c\u70b9\u3002\u6a21\u7cca\u6d4b\u8bd5\u5728\u4e00\u4e2a\u9ad8\u4fdd\u771f\u5ea6\u7684\u6a21\u62df\u73af\u5883\u4e2d\u6267\u884c\uff0c\u5e76\u4e14\u7ed3\u679c\u5728\u7269\u7406sUAS\u7684\u771f\u5b9e\u4e16\u754c\u573a\u5730\u6d4b\u8bd5\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cSaFUZZ\u80fd\u591f\u4e3a\u53d1\u73b0\u771f\u5b9e\u4e16\u754csUAS\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684\u591a\u6837\u5316\u72b6\u6001\u8f6c\u6362\u5931\u8d25\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.05253", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05253", "abs": "https://arxiv.org/abs/2601.05253", "authors": ["Hadi Hosseini", "Debmalya Mandal", "Amrit Puhan"], "title": "SP-Rank: A Dataset for Ranked Preferences with Secondary Information", "comment": null, "summary": "We introduce $\\mathbf{SP-Rank}$, the first large-scale, publicly available dataset for benchmarking algorithms that leverage both first-order preferences and second-order predictions in ranking tasks. Each datapoint includes a personal vote (first-order signal) and a meta-prediction of how others will vote (second-order signal), allowing richer modeling than traditional datasets that capture only individual preferences. SP-Rank contains over 12,000 human-generated datapoints across three domains -- geography, movies, and paintings, and spans nine elicitation formats with varying subset sizes. This structure enables empirical analysis of preference aggregation when expert identities are unknown but presumed to exist, and individual votes represent noisy estimates of a shared ground-truth ranking. We benchmark SP-Rank by comparing traditional aggregation methods that use only first-order votes against SP-Voting, a second-order method that jointly reasons over both signals to infer ground-truth rankings. While SP-Rank also supports models that rely solely on second-order predictions, our benchmarks emphasize the gains from combining both signals. We evaluate performance across three core tasks: (1) full ground-truth rank recovery, (2) subset-level rank recovery, and (3) probabilistic modeling of voter behavior. Results show that incorporating second-order signals substantially improves accuracy over vote-only methods. Beyond social choice, SP-Rank supports downstream applications in learning-to-rank, extracting expert knowledge from noisy crowds, and training reward models in preference-based fine-tuning pipelines. We release the dataset, code, and baseline evaluations (available at https://github.com/amrit19/SP-Rank-Dataset ) to foster research in human preference modeling, aggregation theory, and human-AI alignment.", "AI": {"tldr": "This paper introduces SP-Rank, a large-scale, publicly available dataset for benchmarking ranking algorithms that utilize both first-order preferences and second-order predictions. The dataset is evaluated across three domains with nine elicitation formats, showing that incorporating second-order signals improves accuracy over traditional vote-only methods. It supports applications in learning-to-rank, expert knowledge extraction, and preference-based AI fine-tuning.", "motivation": "The motivation behind this paper is to provide a new, rich dataset (SP-Rank) that allows for the evaluation of ranking algorithms capable of leveraging both individual votes (first-order signals) and predictions about how others will vote (second-order signals). Traditional datasets only capture individual preferences, whereas SP-Rank aims to support more complex modeling by including both types of signals, enabling better analysis of preference aggregation and supporting various downstream applications.", "method": "The authors created SP-Rank, a dataset containing over 12,000 human-generated data points covering three domains: geography, movies, and paintings, with data collected using nine different elicitation formats. They then benchmarked the dataset by comparing the performance of traditional aggregation methods, which use only first-order votes, against SP-Voting, a method that combines both first- and second-order signals to infer ground-truth rankings. The evaluation focused on three core tasks: full ground-truth rank recovery, subset-level rank recovery, and probabilistic modeling of voter behavior.", "result": "Results indicated that incorporating second-order signals into the ranking process significantly enhances the accuracy of inferring ground-truth rankings compared to using only first-order votes. This improvement was observed across all three core tasks examined in the study. Additionally, the dataset's structure and diversity enable its application in various fields such as learning-to-rank, extracting expert knowledge from crowds, and training reward models in AI fine-tuning pipelines.", "conclusion": "The introduction of SP-Rank provides researchers and practitioners with a valuable resource for developing and evaluating more sophisticated ranking algorithms that can effectively integrate both first- and second-order signals. By demonstrating the benefits of combining these two types of information, the work paves the way for advancements in human preference modeling, aggregation theory, and human-AI alignment, while also supporting practical applications in areas like expert knowledge extraction and preference-based AI training."}}
{"id": "2601.05347", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05347", "abs": "https://arxiv.org/abs/2601.05347", "authors": ["Ziyang Men", "Bo Huang", "Yan Gu", "Yihan Sun"], "title": "Parallel Dynamic Spatial Indexes", "comment": null, "summary": "Maintaining spatial data (points in two or three dimensions) is crucial and has a wide range of applications, such as graphics, GIS, and robotics. To handle spatial data, many data structures, called spatial indexes, have been proposed, e.g. kd-trees, oct/quadtrees (also called Orth-trees), R-trees, and bounding volume hierarchies (BVHs). In real-world applications, spatial datasets tend to be highly dynamic, requiring batch updates of points with low latency. This calls for efficient parallel batch updates on spatial indexes. Unfortunately, there is very little work that achieves this.\n  In this paper, we systematically study parallel spatial indexes, with a special focus on achieving high-performance update performance for highly dynamic workloads. We select two types of spatial indexes that are considered optimized for low-latency updates: Orth-tree and R-tree/BVH. We propose two data structures: the P-Orth tree, a parallel Orth-tree, and the SPaC-tree family, a parallel R-tree/BVH. Both the P-Orth tree and the SPaC-tree deliver superior performance in batch updates compared to existing parallel kd-trees and Orth-trees, while preserving better or competitive query performance relative to their corresponding Orth-tree and R-tree counterparts. We also present comprehensive experiments comparing the performance of various parallel spatial indexes and share our findings at the end of the paper.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5e76\u884c\u7a7a\u95f4\u7d22\u5f15\uff0c\u7279\u522b\u5173\u6ce8\u5728\u9ad8\u5ea6\u52a8\u6001\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u66f4\u65b0\u6027\u80fd\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u6570\u636e\u7ed3\u6784\uff1aP-Orth\u6811\u548cSPaC\u6811\u65cf\uff0c\u5b83\u4eec\u5728\u6279\u91cf\u66f4\u65b0\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6216\u5177\u6709\u7ade\u4e89\u529b\u7684\u67e5\u8be2\u6027\u80fd\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7a7a\u95f4\u6570\u636e\u96c6\u5f80\u5f80\u662f\u9ad8\u5ea6\u52a8\u6001\u7684\uff0c\u9700\u8981\u4f4e\u5ef6\u8fdf\u5730\u6279\u91cf\u66f4\u65b0\u70b9\u4fe1\u606f\u3002\u4f46\u662f\uff0c\u76ee\u524d\u5f88\u5c11\u6709\u5de5\u4f5c\u80fd\u591f\u6709\u6548\u8fbe\u6210\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u9009\u62e9\u4e24\u79cd\u88ab\u8ba4\u4e3a\u4f18\u5316\u4e86\u4f4e\u5ef6\u8fdf\u66f4\u65b0\u7684\u7a7a\u95f4\u7d22\u5f15\u7c7b\u578b\uff1aOrth-tree\u548cR-tree/BVH\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u6570\u636e\u7ed3\u6784\uff1aP-Orth\u6811\uff08\u4e00\u79cd\u5e76\u884cOrth-tree\uff09\u548cSPaC\u6811\u65cf\uff08\u4e00\u79cd\u5e76\u884cR-tree/BVH\uff09\u3002", "result": "P-Orth\u6811\u548cSPaC\u6811\u65cf\u5728\u6279\u91cf\u66f4\u65b0\u65b9\u9762\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u5e76\u884ckd-trees\u548cOrth-trees\uff0c\u540c\u65f6\u4e0e\u5bf9\u5e94\u7684Orth-tree\u548cR-tree\u76f8\u6bd4\uff0c\u4fdd\u7559\u4e86\u66f4\u597d\u6216\u76f8\u5f53\u7684\u67e5\u8be2\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u5404\u79cd\u5e76\u884c\u7a7a\u95f4\u7d22\u5f15\u7684\u6027\u80fd\uff0c\u5e76\u5728\u8bba\u6587\u672b\u5c3e\u5206\u4eab\u4e86\u53d1\u73b0\u3002"}}
{"id": "2601.05955", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.05955", "abs": "https://arxiv.org/abs/2601.05955", "authors": ["Yuliang Chen", "Xi Lin", "Jun Wu", "Xiangrui Cai", "Qiaolun Zhang", "Xichun Fan", "Jiapeng Xu", "Xiu Su"], "title": "Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization", "comment": null, "summary": "Federated Domain Generalization (FDG) aims to collaboratively train a global model across distributed clients that can generalize well on unseen domains. However, existing FDG methods typically struggle with cross-client data heterogeneity and incur significant communication and computation overhead. To address these challenges, this paper presents a new FDG framework, dubbed FaST-PT, which facilitates local feature augmentation and efficient unseen domain adaptation in a distributed manner. First, we propose a lightweight Multi-Modal Style Transfer (MST) method to transform image embedding under text supervision, which could expand the training data distribution and mitigate domain shift. We then design a dual-prompt module that decomposes the prompt into global and domain prompts. Specifically, global prompts capture general knowledge from augmented embedding across clients, while domain prompts capture domain-specific knowledge from local data. Besides, Domain-aware Prompt Generation (DPG) is introduced to adaptively generate suitable prompts for each sample, which facilitates unseen domain adaptation through knowledge fusion. Extensive experiments on four cross-domain benchmark datasets, e.g., PACS and DomainNet, demonstrate the superior performance of FaST-PT over SOTA FDG methods such as FedDG-GA and DiPrompt. Ablation studies further validate the effectiveness and efficiency of FaST-PT.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u9886\u57df\u6cdb\u5316\u6846\u67b6FaST-PT\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u98ce\u683c\u8f6c\u6362\u548c\u53cc\u63d0\u793a\u6a21\u5757\u8bbe\u8ba1\u6765\u89e3\u51b3\u8de8\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u8d28\u6027\u548c\u8ba1\u7b97\u901a\u4fe1\u5f00\u9500\u5927\u7684\u95ee\u9898\u3002\u5728PACS\u548cDomainNet\u7b49\u56db\u4e2a\u8de8\u57df\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u7684SOTA FDG\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u9886\u57df\u6cdb\u5316(FDG)\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8de8\u5ba2\u6237\u7aef\u7684\u6570\u636e\u5f02\u8d28\u6027\uff0c\u5e76\u4e14\u4f1a\u5e26\u6765\u663e\u8457\u7684\u901a\u4fe1\u4e0e\u8ba1\u7b97\u5f00\u9500\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684FDG\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b0\u6846\u67b6\u540d\u4e3aFaST-PT\uff0c\u5b83\u5305\u62ec\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u98ce\u683c\u8f6c\u6362(MST)\u65b9\u6cd5\u7528\u4e8e\u56fe\u50cf\u5d4c\u5165\u53d8\u6362\u4ee5\u6269\u5c55\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5e76\u7f13\u89e3\u9886\u57df\u8fc1\u79fb\uff1b\u4ee5\u53ca\u4e00\u4e2a\u53cc\u63d0\u793a\u6a21\u5757\uff0c\u5c06\u63d0\u793a\u5206\u89e3\u4e3a\u5168\u5c40\u63d0\u793a\u548c\u9886\u57df\u63d0\u793a\uff0c\u5176\u4e2d\u5168\u5c40\u63d0\u793a\u4ece\u589e\u5f3a\u540e\u7684\u5d4c\u5165\u4e2d\u6355\u83b7\u901a\u7528\u77e5\u8bc6\uff0c\u800c\u9886\u57df\u63d0\u793a\u5219\u4ece\u672c\u5730\u6570\u636e\u4e2d\u6355\u83b7\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u9886\u57df\u611f\u77e5\u63d0\u793a\u751f\u6210(DPG)\uff0c\u4ee5\u81ea\u9002\u5e94\u5730\u4e3a\u6bcf\u4e2a\u6837\u672c\u751f\u6210\u5408\u9002\u7684\u63d0\u793a\uff0c\u4fc3\u8fdb\u672a\u89c1\u9886\u57df\u7684\u9002\u5e94\u6027\u3002", "result": "\u5728PACS\u3001DomainNet\u7b49\u56db\u4e2a\u8de8\u57df\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eFaST-PT\u7684\u8868\u73b0\u4f18\u4e8eFedDG-GA\u548cDiPrompt\u7b49\u5f53\u524d\u6700\u5148\u8fdb\u7684FDG\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86FaST-PT\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684FaST-PT\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709FDG\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u8de8\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u8d28\u6027\u548c\u9ad8\u5f00\u9500\u95ee\u9898\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u6cdb\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.05463", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05463", "abs": "https://arxiv.org/abs/2601.05463", "authors": ["Chao Wei", "Xinyi Peng", "Yawen Yan", "Mao Luo", "Ting Cai"], "title": "Rethinking Basis Path Testing: Mixed Integer Programming Approach for Test Path Set Generation", "comment": null, "summary": "Basis path testing is a cornerstone of structural testing, yet traditional automated methods, relying on greedy graph-traversal algorithms (e.g., DFS/BFS), often generate sub-optimal paths. This structural inferiority is not a trivial issue; it directly impedes downstream testing activities by complicating automated test data generation and increasing the cognitive load for human engineers. This paper reframes basis path generation from a procedural search task into a declarative optimization problem. We introduce a Mixed Integer Programming (MIP) framework designed to produce a complete basis path set that is globally optimal in its structural simplicity. Our framework includes two complementary strategies: a Holistic MIP model that guarantees a theoretically optimal path set, and a scalable Incremental MIP strategy for large, complex topologies. The incremental approach features a multi-objective function that prioritizes path simplicity and incorporates a novelty penalty to maximize the successful generation of linearly independent paths. Empirical evaluations on both real-code and large-scale synthetic Control Flow Graphs demonstrate that our Incremental MIP strategy achieves a 100\\% success rate in generating complete basis sets, while remaining computationally efficient. Our work provides a foundational method for generating a high-quality structural \"scaffold\" that can enhance the efficiency and effectiveness of subsequent test generation efforts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u6846\u67b6\u6765\u751f\u6210\u5168\u5c40\u6700\u4f18\u7684\u57fa\u7840\u8def\u5f84\u96c6\uff0c\u901a\u8fc7\u4e24\u79cd\u7b56\u7565\uff1a\u6574\u4f53MIP\u6a21\u578b\u548c\u53ef\u6269\u5c55\u7684\u589e\u91cfMIP\u7b56\u7565\uff0c\u540e\u8005\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86100%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u57fa\u7840\u8def\u5f84\u6d4b\u8bd5\u662f\u7ed3\u6784\u5316\u6d4b\u8bd5\u7684\u6838\u5fc3\uff0c\u4f46\u4f20\u7edf\u7684\u81ea\u52a8\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8d2a\u5a6a\u56fe\u904d\u5386\u7b97\u6cd5\uff08\u5982DFS/BFS\uff09\uff0c\u901a\u5e38\u4f1a\u751f\u6210\u6b21\u4f18\u8def\u5f84\u3002\u8fd9\u79cd\u7ed3\u6784\u6027\u7f3a\u9677\u76f4\u63a5\u5f71\u54cd\u4e86\u4e0b\u6e38\u6d4b\u8bd5\u6d3b\u52a8\uff0c\u589e\u52a0\u4e86\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6570\u636e\u7684\u590d\u6742\u6027\u548c\u5de5\u7a0b\u5e08\u7684\u8ba4\u77e5\u8d1f\u62c5\u3002", "method": "\u4f5c\u8005\u5c06\u57fa\u7840\u8def\u5f84\u751f\u6210\u4ece\u4e00\u4e2a\u8fc7\u7a0b\u6027\u641c\u7d22\u4efb\u52a1\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u58f0\u660e\u5f0f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65e8\u5728\u4ea7\u751f\u7ed3\u6784\u4e0a\u6700\u7b80\u5316\u7684\u5b8c\u6574\u57fa\u7840\u8def\u5f84\u96c6\u7684MIP\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e24\u79cd\u4e92\u8865\u7b56\u7565\uff1a\u4e00\u79cd\u786e\u4fdd\u7406\u8bba\u6700\u4f18\u8def\u5f84\u96c6\u7684\u6574\u4f53MIP\u6a21\u578b\uff0c\u4ee5\u53ca\u9488\u5bf9\u5927\u578b\u590d\u6742\u62d3\u6251\u7ed3\u6784\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u589e\u91cfMIP\u7b56\u7565\u3002\u589e\u91cf\u65b9\u6cd5\u91c7\u7528\u4e00\u4e2a\u591a\u76ee\u6807\u51fd\u6570\uff0c\u4f18\u5148\u8003\u8651\u8def\u5f84\u7b80\u6d01\u6027\uff0c\u5e76\u52a0\u5165\u65b0\u9896\u6027\u60e9\u7f5a\u4ee5\u6700\u5927\u5316\u7ebf\u6027\u72ec\u7acb\u8def\u5f84\u7684\u751f\u6210\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4ee3\u7801\u548c\u5927\u89c4\u6a21\u5408\u6210\u63a7\u5236\u6d41\u56fe\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u589e\u91cfMIP\u7b56\u7565\u5728\u751f\u6210\u5b8c\u6574\u7684\u57fa\u8def\u5f84\u96c6\u65b9\u9762\u8fbe\u5230\u4e86100%\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u7840\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u7ed3\u6784\u201c\u652f\u67b6\u201d\uff0c\u8fd9\u53ef\u4ee5\u63d0\u9ad8\u540e\u7eed\u6d4b\u8bd5\u751f\u6210\u52aa\u529b\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2601.05254", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05254", "abs": "https://arxiv.org/abs/2601.05254", "authors": ["Wenbiao Tao", "Yunshi Lan", "Weining Qian"], "title": "TagRAG: Tag-guided Hierarchical Knowledge Graph Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances language models by retrieving external knowledge to support informed and grounded responses. However, traditional RAG methods rely on fragment-level retrieval, limiting their ability to address query-focused summarization queries. GraphRAG introduces a graph-based paradigm for global knowledge reasoning, yet suffers from inefficiencies in information extraction, costly resource consumption, and poor adaptability to incremental updates. To overcome these limitations, we propose TagRAG, a tag-guided hierarchical knowledge graph RAG framework designed for efficient global reasoning and scalable graph maintenance. TagRAG introduces two key components: (1) Tag Knowledge Graph Construction, which extracts object tags and their relationships from documents and organizes them into hierarchical domain tag chains for structured knowledge representation, and (2) Tag-Guided Retrieval-Augmented Generation, which retrieves domain-centric tag chains to localize and synthesize relevant knowledge during inference. This design significantly adapts to smaller language models, improves retrieval granularity, and supports efficient knowledge increment. Extensive experiments on UltraDomain datasets spanning Agriculture, Computer Science, Law, and cross-domain settings demonstrate that TagRAG achieves an average win rate of 95.41\\% against baselines while maintaining about 14.6x construction and 1.9x retrieval efficiency compared with GraphRAG.", "AI": {"tldr": "\u63d0\u51fa\u4e86TagRAG\uff0c\u4e00\u79cd\u6807\u7b7e\u5f15\u5bfc\u7684\u5c42\u6b21\u77e5\u8bc6\u56fe\u8c31RAG\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u5728\u67e5\u8be2\u805a\u7126\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u7684RAG\u65b9\u6cd5\u4f9d\u8d56\u7247\u6bb5\u7ea7\u68c0\u7d22\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5904\u7406\u67e5\u8be2\u805a\u7126\u6458\u8981\u8bf7\u6c42\u7684\u80fd\u529b\uff1b\u800cGraphRAG\u867d\u7136\u5f15\u5165\u4e86\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u5168\u5c40\u77e5\u8bc6\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u4fe1\u606f\u63d0\u53d6\u6548\u7387\u4f4e\u4e0b\u3001\u8d44\u6e90\u6d88\u8017\u5927\u4ee5\u53ca\u5bf9\u589e\u91cf\u66f4\u65b0\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "TagRAG\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff1a(1) \u6807\u7b7e\u77e5\u8bc6\u56fe\u6784\u5efa\uff0c\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u5bf9\u8c61\u6807\u7b7e\u53ca\u5176\u5173\u7cfb\uff0c\u5e76\u5c06\u5176\u7ec4\u7ec7\u6210\u5c42\u6b21\u5316\u7684\u9886\u57df\u6807\u7b7e\u94fe\u4ee5\u5b9e\u73b0\u7ed3\u6784\u5316\u77e5\u8bc6\u8868\u793a\uff1b(2) \u6807\u7b7e\u5f15\u5bfc\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u901a\u8fc7\u68c0\u7d22\u9886\u57df\u4e2d\u5fc3\u7684\u6807\u7b7e\u94fe\u6765\u5b9a\u4f4d\u5e76\u5408\u6210\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5728\u6db5\u76d6\u519c\u4e1a\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u6cd5\u5f8b\u7b49\u591a\u4e2a\u9886\u57df\u7684UltraDomain\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0cTagRAG\u8fbe\u5230\u4e86\u5e73\u574795.41%\u7684\u80dc\u7387\uff0c\u540c\u65f6\u5728\u6784\u5efa\u548c\u68c0\u7d22\u6548\u7387\u65b9\u9762\u5206\u522b\u6bd4GraphRAG\u63d0\u9ad8\u4e86\u7ea614.6\u500d\u548c1.9\u500d\u3002", "conclusion": "TagRAG\u663e\u8457\u6539\u5584\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5bf9\u4e8e\u8f83\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u652f\u6301\uff0c\u63d0\u5347\u4e86\u68c0\u7d22\u7c92\u5ea6\uff0c\u5e76\u4e14\u652f\u6301\u9ad8\u6548\u7684\u77e5\u8bc6\u589e\u91cf\u66f4\u65b0\u3002"}}
{"id": "2601.05371", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05371", "abs": "https://arxiv.org/abs/2601.05371", "authors": ["Md Shafiqul Islam", "Shakti Prasad Padhy", "Douglas Allaire", "Raymundo Arr\u00f3yave"], "title": "The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection", "comment": null, "summary": "Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6838\u95f4\u51e0\u4f55\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u671f\u6563\u5ea6\u8ddd\u79bb\u63a2\u7d22\u6838\u7a7a\u95f4\uff0c\u4f7f\u7528\u591a\u7ef4\u7f29\u653e\uff08MDS\uff09\u5c06\u79bb\u6563\u6838\u5e93\u6620\u5c04\u5230\u8fde\u7eed\u6b27\u51e0\u91cc\u5f97\u6d41\u5f62\u4e0a\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u6838\u9009\u62e9\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u8868\u73b0\u4e25\u91cd\u4f9d\u8d56\u4e8e\u534f\u65b9\u5dee\u6838\u7684\u9009\u62e9\uff0c\u800c\u9009\u62e9\u5408\u9002\u7684\u6838\u662f\u63d0\u9ad8\u6a21\u578b\u8d28\u91cf\u7684\u5173\u952e\uff0c\u4f46\u4e5f\u662f\u6982\u7387\u5efa\u6a21\u4e2d\u6700\u5177\u6709\u6311\u6218\u6027\u548c\u8ba1\u7b97\u6210\u672c\u7684\u90e8\u5206\u4e4b\u4e00\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6838\u4e4b\u95f4\u51e0\u4f55\u5f62\u72b6\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u5229\u7528GP\u5148\u9a8c\u4e4b\u95f4\u7684\u9884\u671f\u6563\u5ea6\u8ddd\u79bb\u6765\u6709\u6548\u5730\u63a2\u7d22\u6838\u7a7a\u95f4\u3002\u91c7\u7528\u591a\u7ef4\u5c3a\u5ea6\u5206\u6790(MDS)\u5d4c\u5165\u6280\u672f\uff0c\u5c06\u8fd9\u4e2a\u8ddd\u79bb\u77e9\u9635\u8f6c\u5316\u4e3a\u4e00\u4e2a\u8fde\u7eed\u7684\u6b27\u51e0\u91cc\u5f97\u6d41\u5f62\uff0c\u4f7f\u5f97\u539f\u672c\u79bb\u6563\u7684\u6838\u5e93\u53ef\u4ee5\u88ab\u6620\u5c04\u5230\u8fd9\u6837\u4e00\u4e2a\u8fde\u7eed\u7684\u7a7a\u95f4\u4e2d\uff0c\u8fdb\u800c\u652f\u6301\u5e73\u6ed1\u7684\u8d1d\u53f6\u65af\u4f18\u5316(BO)\u3002", "result": "\u901a\u8fc7\u5408\u6210\u57fa\u51c6\u3001\u771f\u5b9e\u4e16\u754c\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4ee5\u53ca\u589e\u6750\u5236\u9020\u6848\u4f8b\u7814\u7a76\u9884\u6d4b\u7194\u6c60\u51e0\u4f55\u5f62\u72b6\u7684\u5e94\u7528\u5b9e\u4f8b\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5f15\u5bfc\u7684\u641c\u7d22\u3002", "conclusion": "\u8fd9\u4e00\u6846\u67b6\u4e3a\u6838\u641c\u7d22\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u6982\u7387\u51e0\u4f55\u5b66\u65b9\u6cd5\uff0c\u5e76\u76f4\u63a5\u5173\u8054\u5230\u9ad8\u65af\u8fc7\u7a0b\u5efa\u6a21\u548c\u6df1\u5ea6\u6838\u5b66\u4e60\u9886\u57df\u3002"}}
{"id": "2601.05467", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05467", "abs": "https://arxiv.org/abs/2601.05467", "authors": ["Swapnil Shinde", "Sahil Wadhwa", "Andy Luo", "Emily Chen"], "title": "STELP: Secure Transpilation and Execution of LLM-Generated Programs", "comment": null, "summary": "Rapid evolution of Large Language Models (LLMs) has achieved major advances in reasoning, planning, and function-calling capabilities. Multi-agentic collaborative frameworks using such LLMs place them at the center of solving software development-related tasks such as code generation. However, direct use of LLM generated code in production software development systems is problematic. The code could be unstable or erroneous and contain vulnerabilities such as data poisoning, malicious attacks, and hallucinations that could lead to widespread system malfunctions. This prohibits the adoption of LLM generated code in production AI systems where human code reviews and traditional secure testing tools are impractical or untrustworthy. In this paper, we discuss safety and reliability problems with the execution of LLM generated code and propose a Secure Transpiler and Executor of LLM-Generated Program (STELP), capable of executing LLM-generated code in a controlled and safe manner. STELP secures autonomous production AI systems involving code generation, filling the critical void left by the impracticality or limitations of traditional secure testing methodologies and human oversight. This includes applications such as headless code generation-execution and LLMs that produce executable code snippets as an action plan to be executed in real time. We contribute a human-validated dataset of insecure code snippets and benchmark our approach on publicly available datasets for correctness, safety, and latency. Our results demonstrate that our approach outperforms an existing method by a significant margin, particularly in its ability to safely execute risky code snippets. Warning: This paper contains malicious code snippets that should be run with caution.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSTELP\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u80fd\u591f\u4ee5\u53d7\u63a7\u4e14\u5b89\u5168\u7684\u65b9\u5f0f\u6267\u884c\u7531LLM\u751f\u6210\u7684\u4ee3\u7801\u3002\u901a\u8fc7\u4eba\u7c7b\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u548c\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e\u6b64\u65b9\u6cd5\u5728\u5b89\u5168\u6267\u884c\u98ce\u9669\u4ee3\u7801\u7247\u6bb5\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5feb\u901f\u53d1\u5c55\uff0c\u5728\u63a8\u7406\u3001\u89c4\u5212\u53ca\u51fd\u6570\u8c03\u7528\u80fd\u529b\u4e0a\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u6b65\u3002\u7136\u800c\uff0c\u76f4\u63a5\u5c06\u8fd9\u4e9b\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u5e94\u7528\u4e8e\u751f\u4ea7\u8f6f\u4ef6\u5f00\u53d1\u7cfb\u7edf\u4e2d\u5b58\u5728\u8bf8\u591a\u95ee\u9898\uff0c\u5982\u4ee3\u7801\u4e0d\u7a33\u5b9a\u6216\u9519\u8bef\u3001\u5305\u542b\u6570\u636e\u6c61\u67d3\u3001\u6076\u610f\u653b\u51fb\u7b49\u6f0f\u6d1e\uff0c\u8fd9\u963b\u788d\u4e86\u8fd9\u7c7b\u4ee3\u7801\u5728\u751f\u4ea7AI\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\u4f20\u7edf\u5b89\u5168\u6d4b\u8bd5\u5de5\u5177\u4e0e\u4eba\u5de5\u5ba1\u67e5\u5728\u6b64\u60c5\u5883\u4e0b\u65e2\u4e0d\u5b9e\u7528\u4e5f\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSTELP\uff08Secure Transpiler and Executor of LLM-Generated Program\uff09\u7684\u7cfb\u7edf\uff0c\u65e8\u5728\u4ee5\u53ef\u63a7\u4e14\u5b89\u5168\u7684\u65b9\u5f0f\u6267\u884c\u7531LLM\u751f\u6210\u7684\u4ee3\u7801\u3002\u6b64\u5916\uff0c\u8fd8\u8d21\u732e\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u7684\u4e0d\u5b89\u5168\u4ee3\u7801\u7247\u6bb5\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u516c\u5171\u53ef\u7528\u6570\u636e\u96c6\u5bf9\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u548c\u5ef6\u8fdf\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684STELP\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u6267\u884c\u98ce\u9669\u4ee3\u7801\u7247\u6bb5\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\u3002", "conclusion": "STELP\u4e3a\u89e3\u51b3\u4f7f\u7528LLM\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u65f6\u9047\u5230\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u9014\u5f84\uff0c\u9002\u7528\u4e8e\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u5373\u53ef\u81ea\u52a8\u4ea7\u751f\u5e76\u7acb\u5373\u6267\u884c\u4ee3\u7801\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.05255", "categories": ["cs.IR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05255", "abs": "https://arxiv.org/abs/2601.05255", "authors": ["Sai Khadloya", "Kush Juvekar", "Arghya Bhattacharya", "Utkarsh Saxena"], "title": "CourtNav: Voice-Guided, Anchor-Accurate Navigation of Long Legal Documents in Courtrooms", "comment": null, "summary": "Judicial work depends on close reading of long records, charge sheets, pleadings, annexures, orders, often spanning hundreds of pages. With limited staff support, exhaustive reading during hearings is impractical. We present CourtNav, a voice-guided, anchor-first navigator for legal PDFs that maps a judge's spoken command (e.g., \"go to paragraph 23\", \"highlight the contradiction in the cross-examination\") directly to a highlighted paragraph in seconds. CourtNav transcribes the command, classifies intent with a grammar-first(Exact regex matching), LLM-backed router classifying the queries using few shot examples, retrieves over a layout-aware hybrid index, and auto-scrolls the viewer to the cited span while highlighting it and close alternates. By design, the interface shows only grounded passages, never free text, keeping evidence verifiable and auditable. This need is acute in India, where judgments and cross-examinations are notoriously long.In a pilot on representative charge sheets, pleadings, and orders, median time-to-relevance drops from 3-5 minutes (manual navigation) to 10-15 seconds; with quick visual verification included, 30-45 seconds. Under fixed time budgets, this navigation-first design increases the breadth of the record actually consulted while preserving control and transparency.", "AI": {"tldr": "CourtNav\u662f\u4e00\u4e2a\u8bed\u97f3\u5f15\u5bfc\u7684\u6cd5\u5f8bPDF\u5bfc\u822a\u5668\uff0c\u901a\u8fc7\u6cd5\u5b98\u7684\u8bed\u97f3\u547d\u4ee4\u5feb\u901f\u5b9a\u4f4d\u5e76\u9ad8\u4eae\u663e\u793a\u76f8\u5173\u6bb5\u843d\uff0c\u5927\u5927\u51cf\u5c11\u4e86\u67e5\u627e\u65f6\u95f4\u3002", "motivation": "\u53f8\u6cd5\u5de5\u4f5c\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u5927\u91cf\u7684\u6587\u6863\uff0c\u4f46\u5b9e\u9645\u64cd\u4f5c\u4e2d\u7531\u4e8e\u4eba\u529b\u6709\u9650\uff0c\u8be6\u5c3d\u9605\u8bfb\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\u3002\u7279\u522b\u662f\u5728\u5370\u5ea6\uff0c\u5224\u51b3\u4e66\u548c\u4ea4\u53c9\u5ba1\u95ee\u8bb0\u5f55\u975e\u5e38\u957f\u3002", "method": "CourtNav\u4f7f\u7528\u8bed\u97f3\u8f6c\u5f55\u3001\u610f\u56fe\u5206\u7c7b\uff08\u57fa\u4e8e\u8bed\u6cd5\u4f18\u5148\u548c\u5c11\u91cf\u793a\u4f8b\u652f\u6301\u7684LLM\uff09\u3001\u5e03\u5c40\u611f\u77e5\u6df7\u5408\u7d22\u5f15\u68c0\u7d22\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u4ece\u8bed\u97f3\u547d\u4ee4\u5230\u6587\u6863\u5185\u7279\u5b9a\u6bb5\u843d\u7684\u5feb\u901f\u5b9a\u4f4d\u4e0e\u9ad8\u4eae\u3002", "result": "\u5728\u4ee3\u8868\u6027\u7684\u8d77\u8bc9\u4e66\u3001\u8bc9\u72b6\u548c\u547d\u4ee4\u6587\u4ef6\u4e0a\u7684\u8bd5\u70b9\u8868\u660e\uff0c\u4f7f\u7528CourtNav\u540e\uff0c\u627e\u5230\u76f8\u5173\u4fe1\u606f\u7684\u65f6\u95f4\u4ece\u624b\u52a8\u5bfc\u822a\u65f6\u76843-5\u5206\u949f\u51cf\u5c11\u5230\u4e8610-15\u79d2\uff1b\u5982\u679c\u5305\u62ec\u5feb\u901f\u89c6\u89c9\u9a8c\u8bc1\uff0c\u5219\u4e3a30-45\u79d2\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u4ee5\u5bfc\u822a\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\uff0cCourtNav\u80fd\u591f\u5728\u4fdd\u6301\u63a7\u5236\u6027\u548c\u900f\u660e\u5ea6\u7684\u540c\u65f6\u589e\u52a0\u54a8\u8be2\u8bb0\u5f55\u7684\u5b9e\u9645\u8303\u56f4\u3002"}}
{"id": "2601.05579", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05579", "abs": "https://arxiv.org/abs/2601.05579", "authors": ["Xudong Xie", "Yuwei Zhang", "Wensheng Dou", "Yu Gao", "Ziyu Cui", "Jiansen Song", "Rui Yang", "Jun Wei"], "title": "RISE: Rule-Driven SQL Dialect Translation via Query Reduction", "comment": "Accepted by ICSE 2026", "summary": "Translating SQL dialects across different relational database management systems (RDBMSs) is crucial for migrating RDBMS-based applications to the cloud. Traditional SQL dialect translation tools rely on manually-crafted rules, necessitating significant manual effort to support new RDBMSs and dialects. Although large language models (LLMs) can assist in translating SQL dialects, they often struggle with lengthy and complex SQL queries.\n  In this paper, we propose RISE, a novel LLM-based SQL dialect translation approach that can accurately handle lengthy and complex SQL queries. Given a complex source query $Q_c$ that contains a SQL dialect $d$, we first employ a dialect-aware query reduction technique to derive a simplified query $Q_{s}$ by removing $d$-irrelevant SQL elements from $Q_c$. Subsequently, we utilize LLMs to translate $Q_{s}$ into $Q_{s^{'}}$, and automatically extract the translation rule $r_d$ for dialect $d$ based on the relationship between $Q_{s}$ and $Q_{s^{'}}$. By applying $r_d$ to $Q_c$, we can effectively translate the dialect $d$ within $Q_c$, thereby bypassing the complexity of the source query $Q_c$. We evaluate RISE on two real-world benchmarks, i.e., TPC-DS and SQLProcBench, comparing its performance against both the traditional rule-based tools and the LLM-based approaches with respect to translation accuracy. RISE achieves accuracies of 97.98% on TPC-DS and 100% on SQLProcBench, outperforming the baselines by an average improvement of 24.62% and 238.41%, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684SQL\u65b9\u8a00\u7ffb\u8bd1\u65b9\u6cd5RISE\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7b80\u5316\u67e5\u8be2\u6765\u63d0\u9ad8\u5bf9\u590d\u6742\u548c\u957fSQL\u67e5\u8be2\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\u3002\u5728TPC-DS\u548cSQLProcBench\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRISE\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5de5\u5177\u548c\u5176\u4ed6\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5c06\u57fa\u4e8eRDBMS\u7684\u5e94\u7528\u8fc1\u79fb\u5230\u4e91\u7aef\u65f6\u9700\u8981\u8de8\u4e0d\u540c\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u8f6c\u6362SQL\u65b9\u8a00\uff0c\u800c\u4f20\u7edf\u7684\u8f6c\u6362\u5de5\u5177\u4f9d\u8d56\u4e8e\u624b\u5de5\u7f16\u5199\u7684\u89c4\u5219\uff0c\u8fd9\u8981\u6c42\u5927\u91cf\u7684\u624b\u52a8\u5de5\u4f5c\u6765\u652f\u6301\u65b0\u7684RDBMS\u548c\u65b9\u8a00\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5e2e\u52a9\u7ffb\u8bd1SQL\u65b9\u8a00\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u96be\u4ee5\u5904\u7406\u957f\u4e14\u590d\u6742\u7684SQL\u67e5\u8be2\u3002", "method": "RISE\u65b9\u6cd5\u9996\u5148\u4f7f\u7528\u4e00\u79cd\u65b9\u8a00\u611f\u77e5\u7684\u67e5\u8be2\u7b80\u5316\u6280\u672f\u4ece\u590d\u6742\u6e90\u67e5\u8be2$Q_c$\u4e2d\u79fb\u9664\u4e0e\u7279\u5b9a\u65b9\u8a00$d$\u65e0\u5173\u7684SQL\u5143\u7d20\u4ee5\u5f97\u5230\u7b80\u5316\u540e\u7684\u67e5\u8be2$Q_s$\uff0c\u7136\u540e\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06$Q_s$\u7ffb\u8bd1\u6210$Q_{s^{'}}$\uff0c\u5e76\u6839\u636e$Q_s$\u548c$Q_{s^{'}}$\u4e4b\u95f4\u7684\u5173\u7cfb\u81ea\u52a8\u63d0\u53d6\u9488\u5bf9\u65b9\u8a00$d$\u7684\u7ffb\u8bd1\u89c4\u5219$r_d$\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5c06$r_d$\u5e94\u7528\u4e8e$Q_c$\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u7ffb\u8bd1\u5176\u4e2d\u7684\u65b9\u8a00$d$\uff0c\u4ece\u800c\u7ed5\u8fc7\u4e86\u6e90\u67e5\u8be2$Q_c$\u7684\u590d\u6742\u6027\u3002", "result": "\u5728TPC-DS\u548cSQLProcBench\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e86RISE\uff0c\u5e76\u5c06\u5176\u6027\u80fd\u4e0e\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5de5\u5177\u4ee5\u53ca\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\uff0cRISE\u5728TPC-DS\u4e0a\u7684\u51c6\u786e\u7387\u4e3a97.98%\uff0c\u5728SQLProcBench\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u5230100%\uff0c\u5206\u522b\u6bd4\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad8\u4e8624.62%\u548c238.41%\u3002", "conclusion": "\u63d0\u51fa\u7684RISE\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u5730\u5904\u7406\u957f\u4e14\u590d\u6742\u7684SQL\u67e5\u8be2\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u8fc1\u79fbRDBMS\u5e94\u7528\u7a0b\u5e8f\u5230\u4e91\u7aef\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05485", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05485", "abs": "https://arxiv.org/abs/2601.05485", "authors": ["Wenhao Zeng", "Yitian Chai", "Hao Zhou", "Fandong Meng", "Jie Zhou", "Xiaodong Gu"], "title": "Readability-Robust Code Summarization via Meta Curriculum Learning", "comment": "Code available at https://github.com/Zengwh02/RoFTCodeSum", "summary": "Code summarization has emerged as a fundamental technique in the field of program comprehension. While code language models have shown significant advancements, the current models and benchmarks are confined to high-readability code, which contains sufficient semantic cues such as function and variable names. In the real world, however, code is often poorly structured or obfuscated, significantly degrading model performance. In this paper, we first empirically evaluate the robustness of state-of-the-art language models on poor-readability code for the task of code summarization, focusing on (1) their effectiveness, (2) the impact of prompt engineering, and (3) the robustness of different variants. Experimental results reveal that state-of-the-art models-including GPT-4o and DeepSeek-V3 experience a substantial performance drop when faced with poorly readable code, and that prompt engineering and reasoning-enhanced models offer limited improvements. Motivated by these findings, we propose RoFTCodeSum, a novel fine-tuning method that enhances the robustness of code summarization against poorly readable code. RoFTCodeSum marries the concepts of curriculum learning and meta-learning: based on the original dataset for fine-tuning, it creates curricular training sets, e.g., obfuscating function names and identifiers from the code, respectively, that have progressive difficulty in code comprehension. In each training step, the approach meta-updates the gradients using these progressively challenging datasets, thereby optimizing both accuracy and readability robustness simultaneously. Experimental results demonstrate that RoFTCodeSum exhibits increased robustness against semantic perturbation while enhancing performance on the original code.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f53\u524d\u4ee3\u7801\u6458\u8981\u6a21\u578b\u5728\u5904\u7406\u53ef\u8bfb\u6027\u5dee\u7684\u4ee3\u7801\u65f6\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5fae\u8c03\u65b9\u6cd5RoFTCodeSum\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u4f4e\u8d28\u91cf\u4ee3\u7801\u7684\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRoFTCodeSum\u4e0d\u4ec5\u80fd\u63d0\u9ad8\u6a21\u578b\u5bf9\u8bed\u4e49\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4e5f\u80fd\u6539\u5584\u5176\u5728\u539f\u59cb\u4ee3\u7801\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u9ad8\u53ef\u8bfb\u6027\u7684\u4ee3\u7801\u8fdb\u884c\u4f18\u5316\uff0c\u4f46\u5728\u9762\u5bf9\u7ed3\u6784\u4e0d\u826f\u6216\u6df7\u6dc6\u8fc7\u7684\u5b9e\u9645\u4ee3\u7801\u65f6\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u4e3a\u4e86\u63d0\u5347\u6a21\u578b\u5728\u5904\u7406\u8fd9\u7c7b\u4ee3\u7801\u65f6\u7684\u9c81\u68d2\u6027\u548c\u6548\u679c\uff0c\u4f5c\u8005\u5c55\u5f00\u4e86\u672c\u9879\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u73b0\u6709\u5148\u8fdb\u6a21\u578b\uff08\u5982GPT-4o\u548cDeepSeek-V3\uff09\u5728\u5904\u7406\u4f4e\u53ef\u8bfb\u6027\u4ee3\u7801\u65f6\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u63d0\u793a\u5de5\u7a0b\u7684\u4f5c\u7528\u53ca\u4e0d\u540c\u53d8\u4f53\u7684\u7a33\u5b9a\u6027\u3002\u57fa\u4e8e\u53d1\u73b0\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u4e0e\u5143\u5b66\u4e60\u6982\u5ff5\u7684\u65b0\u5fae\u8c03\u65b9\u6cd5RoFTCodeSum\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u8bad\u7ec3\u6570\u636e\u96c6\u9010\u6b65\u589e\u52a0\u96be\u5ea6\u6765\u4f18\u5316\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u6700\u65b0\u7684\u6a21\u578b\u5728\u906d\u9047\u4f4e\u53ef\u8bfb\u6027\u4ee3\u7801\u65f6\u8868\u73b0\u4e0d\u4f73\u4e14\u63d0\u793a\u5de5\u7a0b\u5e26\u6765\u7684\u6539\u8fdb\u6709\u9650\uff0c\u4f46\u91c7\u7528RoFTCodeSum\u65b9\u6cd5\u540e\uff0c\u6a21\u578b\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5bf9\u8bed\u4e49\u6270\u52a8\u7684\u62b5\u6297\u80fd\u529b\uff0c\u8fd8\u5728\u5904\u7406\u6b63\u5e38\u4ee3\u7801\u65b9\u9762\u5c55\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "RoFTCodeSum\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u589e\u5f3a\u4ee3\u7801\u6458\u8981\u6a21\u578b\u9c81\u68d2\u6027\u7684\u65b0\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u96be\u4ee5\u7406\u89e3\u7684\u4ee3\u7801\u65f6\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u65b9\u5411\u3002"}}
{"id": "2601.05383", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.05383", "abs": "https://arxiv.org/abs/2601.05383", "authors": ["Prakash Gawas", "Antoine Legrain", "Louis-Martin Rousseau"], "title": "Imitation Learning for Combinatorial Optimisation under Uncertainty", "comment": null, "summary": "Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \\emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.\n  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.\n  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u7ec4\u5408\u4f18\u5316\u4e2d\u6a21\u4eff\u5b66\u4e60\u7684\u4e13\u5bb6\uff0c\u5e76\u57fa\u4e8e\u6b64\u5206\u7c7b\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e7f\u4e49\u7684\u6570\u636e\u96c6\u805a\u5408\u7b97\u6cd5\u3002\u901a\u8fc7\u52a8\u6001\u533b\u751f-\u60a3\u8005\u5206\u914d\u95ee\u9898\u7684\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u4ece\u968f\u673a\u4e13\u5bb6\u90a3\u91cc\u5b66\u4e60\u5230\u7684\u7b56\u7565\u4f18\u4e8e\u786e\u5b9a\u6027\u6216\u5168\u4fe1\u606f\u4e13\u5bb6\uff0c\u800c\u4ea4\u4e92\u5f0f\u5b66\u4e60\u5219\u80fd\u5728\u4f7f\u7528\u66f4\u5c11\u7684\u4e13\u5bb6\u6f14\u793a\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "motivation": "\u6a21\u4eff\u5b66\u4e60\u4e3a\u5927\u89c4\u6a21\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u751f\u6210\u8bad\u7ec3\u793a\u4f8b\u7684'\u4e13\u5bb6'\u89d2\u8272\u7684\u7edf\u4e00\u6846\u67b6\u6765\u63cf\u8ff0\u5176\u5efa\u6a21\u5047\u8bbe\u3001\u8ba1\u7b97\u5c5e\u6027\u53ca\u5bf9\u5b66\u4e60\u8868\u73b0\u7684\u5f71\u54cd\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9488\u5bf9\u4e0d\u786e\u5b9a\u6027\u4e0b\u7ec4\u5408\u4f18\u5316\u4e2d\u6a21\u4eff\u5b66\u4e60\u4e13\u5bb6\u7684\u7cfb\u7edf\u5206\u7c7b\u65b9\u6cd5\uff0c\u6839\u636e\u4ed6\u4eec\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3001\u6700\u4f18\u7a0b\u5ea6\u4ee5\u53ca\u4e0e\u5b66\u4e60\u8005\u7684\u4e92\u52a8\u6a21\u5f0f\u5c06\u4e13\u5bb6\u5206\u4e3a\u4e09\u7c7b\u3002\u57fa\u4e8e\u8fd9\u4e00\u5206\u7c7b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u591a\u4e13\u5bb6\u67e5\u8be2\u3001\u4e13\u5bb6\u805a\u5408\u548c\u7075\u6d3b\u4e92\u52a8\u7b56\u7565\u7684\u5e7f\u4e49\u6570\u636e\u96c6\u805a\u5408(DAgger)\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5bf9\u5177\u6709\u968f\u673a\u5230\u8fbe\u548c\u5bb9\u91cf\u9650\u5236\u7684\u52a8\u6001\u533b\u751f-\u60a3\u8005\u5206\u914d\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u4ece\u968f\u673a\u4e13\u5bb6\u5904\u5b66\u5230\u7684\u7b56\u7565\u59cb\u7ec8\u4f18\u4e8e\u4ece\u786e\u5b9a\u6027\u6216\u5168\u4fe1\u606f\u4e13\u5bb6\u5904\u5b66\u5230\u7684\u7b56\u7565\uff1b\u540c\u65f6\uff0c\u4ea4\u4e92\u5f0f\u5b66\u4e60\u80fd\u591f\u4ee5\u8f83\u5c11\u7684\u4e13\u5bb6\u6f14\u793a\u6b21\u6570\u63d0\u5347\u89e3\u7684\u8d28\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\uff0c\u5229\u7528\u968f\u673a\u4e13\u5bb6\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6a21\u4eff\u5b66\u4e60\u7684\u6548\u679c\uff1b\u5f53\u968f\u673a\u4f18\u5316\u53d8\u5f97\u8ba1\u7b97\u4e0a\u96be\u4ee5\u5904\u7406\u65f6\uff0c\u805a\u5408\u786e\u5b9a\u6027\u4e13\u5bb6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.05258", "categories": ["cs.IR", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05258", "abs": "https://arxiv.org/abs/2601.05258", "authors": ["Kaichun Wang", "Yanguang Chen", "Ting Zhang", "Mengyao Bao", "Keyu Chen", "Xu Hu", "Yongliang Wang", "Jingsheng Yang", "Jinsong Zhang", "Fei Lu"], "title": "From Events to Trending: A Multi-Stage Hotspots Detection Method Based on Generative Query Indexing", "comment": null, "summary": "LLM-based conversational systems have become a popular gateway for information access, yet most existing chatbots struggle to handle news-related trending queries effectively. To improve user experience, an effective trending query detection method is urgently needed to enable differentiated processing of such target traffic. However, current research on trending detection tailored to the dialogue system scenario remains largely unexplored, and methods designed for traditional search engines often underperform in conversational contexts due to radically distinct query distributions and expression patterns. To fill this gap, we propose a multi-stage framework for trending detection, which achieves systematic optimization from both offline generation and online identification perspectives. Specifically, our framework first exploits selected hot events to generate index queries, establishing a key bridge between static events and dynamic user queries. It then employs a retrieval matching mechanism for real-time online detection of trending queries, where we introduce a cascaded recall and ranking architecture to balance detection efficiency and accuracy. Furthermore, to better adapt to the practical application scenario, our framework adopts a single-recall module as a cold-start strategy to collect online data for fine-tuning the reranker. Extensive experiments demonstrate that our framework significantly outperforms baseline methods in both offline evaluations and online A/B tests, and user satisfaction is relatively improved by 27\\% in terms of positive-negative feedback ratio.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5bf9\u8bdd\u7cfb\u7edf\u573a\u666f\u4f18\u5316\u7684\u591a\u9636\u6bb5\u8d8b\u52bf\u67e5\u8be2\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u7d22\u5f15\u67e5\u8be2\u548c\u5728\u7ebf\u68c0\u7d22\u5339\u914d\u673a\u5236\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5e76\u5728\u79bb\u7ebf\u8bc4\u4f30\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u804a\u5929\u673a\u5668\u4eba\u96be\u4ee5\u6709\u6548\u5904\u7406\u4e0e\u65b0\u95fb\u76f8\u5173\u7684\u70ed\u95e8\u67e5\u8be2\uff0c\u800c\u4e3a\u4f20\u7edf\u641c\u7d22\u5f15\u64ce\u8bbe\u8ba1\u7684\u65b9\u6cd5\u5728\u5bf9\u8bdd\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u5bf9\u8bdd\u7cfb\u7edf\u573a\u666f\u7684\u8d8b\u52bf\u67e5\u8be2\u68c0\u6d4b\u65b9\u6cd5\u6765\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u9996\u5148\u5229\u7528\u9009\u5b9a\u7684\u70ed\u70b9\u4e8b\u4ef6\u751f\u6210\u7d22\u5f15\u67e5\u8be2\uff0c\u7136\u540e\u91c7\u7528\u68c0\u7d22\u5339\u914d\u673a\u5236\u5b9e\u73b0\u5b9e\u65f6\u5728\u7ebf\u68c0\u6d4b\u8d8b\u52bf\u67e5\u8be2\u3002\u8be5\u6846\u67b6\u8fd8\u5f15\u5165\u4e86\u7ea7\u8054\u53ec\u56de\u4e0e\u6392\u5e8f\u67b6\u6784\u4ee5\u5e73\u8861\u68c0\u6d4b\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u91c7\u7528\u5355\u4e00\u53ec\u56de\u6a21\u5757\u4f5c\u4e3a\u51b7\u542f\u52a8\u7b56\u7565\u6536\u96c6\u5728\u7ebf\u6570\u636e\u4ee5\u5fae\u8c03\u91cd\u6392\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u79bb\u7ebf\u8bc4\u4f30\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7528\u6237\u6ee1\u610f\u5ea6\uff08\u6b63\u8d1f\u53cd\u9988\u6bd4\u7387\uff09\u76f8\u5bf9\u63d0\u9ad8\u4e8627%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6210\u529f\u5730\u586b\u8865\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u573a\u666f\u4e0b\u8d8b\u52bf\u68c0\u6d4b\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u8bc6\u522b\u548c\u5904\u7406\u70ed\u95e8\u67e5\u8be2\uff0c\u4ece\u800c\u6539\u5584\u4e86\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\u7684\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2601.06001", "categories": ["cs.DB", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.06001", "abs": "https://arxiv.org/abs/2601.06001", "authors": ["Christoph Standke", "Nikolaos Tziavelis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "The Importance of Parameters in Ranking Functions", "comment": "Extended version of ICDT 2026 paper", "summary": "How important is the weight of a given column in determining the ranking of tuples in a table? To address such an explanation question about a ranking function, we investigate the computation of SHAP scores for column weights, adopting a recent framework by Grohe et al.[ICDT'24]. The exact definition of this score depends on three key components: (1) the ranking function in use, (2) an effect function that quantifies the impact of using alternative weights on the ranking, and (3) an underlying weight distribution. We analyze the computational complexity of different instantiations of this framework for a range of fundamental ranking and effect functions, focusing on probabilistically independent finite distributions for individual columns.\n  For the ranking functions, we examine lexicographic orders and score-based orders defined by the summation, minimum, and maximum functions. For the effect functions, we consider global, top-k, and local perspectives: global measures quantify the divergence between the perturbed and original rankings, top-k measures inspect the change in the set of top-k answers, and local measures capture the impact on an individual tuple of interest. Although all cases admit an additive fully polynomial-time randomized approximation scheme (FPRAS), we establish the complexity of exact computation, identifying which cases are solvable in polynomial time and which are #P-hard. We further show that all complexity results, lower bounds and upper bounds, extend to a related task of computing the Shapley value of whole columns (regardless of their weight).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5217\u6743\u91cd\u5728\u51b3\u5b9a\u8868\u4e2d\u5143\u7ec4\u6392\u540d\u65f6\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u8ba1\u7b97SHAP\u5206\u6570\u6765\u91cf\u5316\u4e0d\u540c\u6392\u540d\u51fd\u6570\u548c\u6548\u5e94\u51fd\u6570\u4e0b\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6240\u6709\u60c5\u51b5\u90fd\u5141\u8bb8\u4f7f\u7528\u5b8c\u5168\u591a\u9879\u5f0f\u65f6\u95f4\u968f\u673a\u8fd1\u4f3c\u65b9\u6848\uff08FPRAS\uff09\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97\u7684\u590d\u6742\u6027\u5728\u4e0d\u540c\u60c5\u51b5\u4e0b\u6709\u6240\u4e0d\u540c\uff0c\u6709\u4e9b\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u800c\u6709\u4e9b\u5219\u662f#P-hard\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u590d\u6742\u6027\u7ed3\u679c\u4e5f\u9002\u7528\u4e8e\u8ba1\u7b97\u6574\u4e2a\u5217\u7684Shapley\u503c\u3002", "motivation": "\u4e3a\u4e86\u56de\u7b54\u5173\u4e8e\u6392\u540d\u51fd\u6570\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5217\u6743\u91cd\u5bf9\u5143\u7ec4\u6392\u540d\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u672c\u6587\u91c7\u7528Grohe\u7b49\u4eba[ICDT'24]\u63d0\u51fa\u7684\u6846\u67b6\u6765\u8ba1\u7b97\u5217\u6743\u91cd\u7684SHAP\u5206\u6570\u3002", "method": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u4e8e\u4e0d\u540c\u57fa\u672c\u6392\u540d\u51fd\u6570\uff08\u5b57\u5178\u5e8f\u3001\u57fa\u4e8e\u6c42\u548c/\u6700\u5c0f/\u6700\u5927\u5f97\u5206\u7684\u987a\u5e8f\uff09\u4ee5\u53ca\u4ece\u5168\u5c40\u3001top-k\u548c\u5c40\u90e8\u89c6\u89d2\u8003\u8651\u7684\u6548\u679c\u51fd\u6570\u4e0b\uff0c\u8be5\u6846\u67b6\u5b9e\u4f8b\u5316\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u7279\u522b\u5730\uff0c\u7814\u7a76\u96c6\u4e2d\u5728\u4e2a\u4f53\u5217\u7684\u6982\u7387\u72ec\u7acb\u6709\u9650\u5206\u5e03\u4e0a\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u5bf9\u4e8e\u6240\u6709\u60c5\u5f62\u90fd\u53ef\u4ee5\u4f7f\u7528\u4e00\u79cd\u52a0\u6027\u5b8c\u5168\u591a\u9879\u5f0f\u65f6\u95f4\u968f\u673a\u8fd1\u4f3c\u65b9\u6848(FPRAS)\uff0c\u4f46\u5bf9\u4e8e\u7cbe\u786e\u8ba1\u7b97\u800c\u8a00\uff0c\u67d0\u4e9b\u60c5\u5f62\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u53ef\u89e3\u7684\uff0c\u800c\u53e6\u4e00\u4e9b\u5219\u4e3a#P-hard\u95ee\u9898\u3002\u6b64\u5916\uff0c\u6240\u6709\u590d\u6742\u5ea6\u7ed3\u679c\uff08\u5305\u62ec\u4e0b\u754c\u548c\u4e0a\u754c\uff09\u540c\u6837\u9002\u7528\u4e8e\u8ba1\u7b97\u6574\u5217\uff08\u4e0d\u8003\u8651\u5176\u6743\u91cd\uff09\u7684Shapley\u503c\u7684\u4efb\u52a1\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u4e0d\u540c\u6392\u540d\u4e0e\u6548\u679c\u51fd\u6570\u8bbe\u7f6e\u4e0b\uff0c\u8bc4\u4f30\u5217\u6743\u91cd\u91cd\u8981\u6027\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u5c3d\u7ba1\u6709\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\u53ef\u7528\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97\u7684\u96be\u5ea6\u968f\u5177\u4f53\u60c5\u51b5\u800c\u5f02\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u7ed3\u8bba\u4e5f\u6269\u5c55\u5230\u4e86\u6574\u5217Shapley\u503c\u7684\u8ba1\u7b97\u9886\u57df\u3002"}}
{"id": "2601.05259", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05259", "abs": "https://arxiv.org/abs/2601.05259", "authors": ["Haotao Xie", "Ruilin Chen", "Yicheng Wu", "Zhan Zhao", "Yuanyuan Liu"], "title": "A Technical Report on the Second Place Solution for the CIKM 2025 AnalytiCup Competition", "comment": null, "summary": "In this work, we address the challenge of multilingual category relevance judgment in e-commerce search, where traditional ensemble-based systems improve accuracy but at the cost of heavy training, inference, and maintenance complexity. To overcome this limitation, we propose a simplified yet effective framework that leverages prompt engineering with Chain-of-Thought task decomposition to guide reasoning within a single large language model. Specifically, our approach decomposes the relevance judgment process into four interpretable subtasks: translation, intent understanding, category matching, and relevance judgment -- and fine-tunes a base model (Qwen2.5-14B) using Low-Rank Adaptation (LoRA) for efficient adaptation. This design not only reduces computational and storage overhead but also enhances interpretability by explicitly structuring the model's reasoning path. Experimental results show that our single-model framework achieves competitive accuracy and high inference efficiency, processing 20 samples per second on a single A100 GPU. In the CIKM 2025 AnalytiCup Competition Proposals, our method achieved 0.8902 on the public leaderboard and 0.8889 on the private leaderboard, validating the effectiveness and robustness of the proposed approach. These results highlight that structured prompting combined with lightweight fine-tuning can outperform complex ensemble systems, offering a new paradigm for scalable industrial AI applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u548c\u601d\u7ef4\u94fe\u4efb\u52a1\u5206\u89e3\u7684\u7b80\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7535\u5b50\u5546\u52a1\u641c\u7d22\u4e2d\u7684\u591a\u8bed\u8a00\u7c7b\u522b\u76f8\u5173\u6027\u5224\u65ad\u95ee\u9898\u3002\u901a\u8fc7\u5c06\u76f8\u5173\u6027\u5224\u65ad\u8fc7\u7a0b\u5206\u89e3\u4e3a\u7ffb\u8bd1\u3001\u610f\u56fe\u7406\u89e3\u3001\u7c7b\u522b\u5339\u914d\u548c\u76f8\u5173\u6027\u5224\u65ad\u56db\u4e2a\u53ef\u89e3\u91ca\u5b50\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u5fae\u8c03\u57fa\u7840\u6a21\u578bQwen2.5-14B\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u4e0e\u5b58\u50a8\u5f00\u9500\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u5355\u6a21\u578b\u6846\u67b6\u4e0d\u4ec5\u5728CIKM 2025 AnalytiCup\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u7ee9\uff0c\u800c\u4e14\u5c55\u793a\u4e86\u7ed3\u6784\u5316\u63d0\u793a\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5fae\u8c03\u4f5c\u4e3a\u53ef\u6269\u5c55\u5de5\u4e1aAI\u5e94\u7528\u65b0\u8303\u5f0f\u7684\u6f5c\u529b\u3002", "motivation": "\u9488\u5bf9\u4f20\u7edf\u96c6\u6210\u7cfb\u7edf\u867d\u7136\u80fd\u591f\u63d0\u9ad8\u591a\u8bed\u8a00\u7c7b\u522b\u76f8\u5173\u6027\u5224\u65ad\u51c6\u786e\u6027\u4f46\u540c\u65f6\u5e26\u6765\u8bad\u7ec3\u3001\u63a8\u7406\u53ca\u7ef4\u62a4\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e2\u7b80\u5316\u53c8\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u914d\u5408\u601d\u7ef4\u94fe\u4efb\u52a1\u5206\u89e3\u7b56\u7565\uff0c\u5c06\u6574\u4e2a\u76f8\u5173\u6027\u8bc4\u4f30\u6d41\u7a0b\u62c6\u5206\u4e3a\u7ffb\u8bd1\u3001\u610f\u56fe\u7406\u89e3\u3001\u7c7b\u522b\u5339\u914d\u4ee5\u53ca\u6700\u7ec8\u7684\u76f8\u5173\u6027\u8bc4\u5224\u56db\u4e2a\u6b65\u9aa4\uff0c\u5e76\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\u6280\u672f\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578bQwen2.5-14B\u8fdb\u884c\u9ad8\u6548\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u5355\u4e00\u6a21\u578b\u67b6\u6784\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u590d\u6742\u96c6\u6210\u7cfb\u7edf\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5177\u5907\u66f4\u9ad8\u7684\u63a8\u7406\u901f\u5ea6\uff08\u5355\u4e2aA100 GPU\u4e0a\u6bcf\u79d2\u5904\u740620\u4e2a\u6837\u672c\uff09\u3002\u6b64\u5916\uff0c\u5728CIKM 2025 AnalytiCup\u6bd4\u8d5b\u63d0\u6848\u4e2d\u5206\u522b\u83b7\u5f97\u4e86\u516c\u5171\u6392\u884c\u699c0.8902\u5206\u548c\u79c1\u4eba\u6392\u884c\u699c0.8889\u5206\u7684\u597d\u6210\u7ee9\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u63d0\u793a\u5de5\u7a0b\u8054\u5408\u8f7b\u91cf\u5316\u5fae\u8c03\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u590d\u6742\u7684\u96c6\u6210\u7cfb\u7edf\uff0c\u4e3a\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5de5\u4e1a\u7ea7\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2601.06013", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2601.06013", "abs": "https://arxiv.org/abs/2601.06013", "authors": ["Jiayin Hu", "Nikolaos Tziavelis"], "title": "Database Theory in Action: Direct Access to Query Answers", "comment": null, "summary": "Direct access asks for the retrieval of query answers by their ranked position, given a query and a desired order. While the time complexity of data structures supporting such accesses has been studied in depth, and efficient algorithms for many queries and common orders are known, their practical performance has received little attention. We provide an implementation covering a wide range of queries and orders; it allows us to investigate intriguing practical aspects, including the comparative performance of database systems and the relationship between direct access and its single-access counterpart.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0\u4e86\u4e00\u4e2a\u652f\u6301\u591a\u79cd\u67e5\u8be2\u548c\u6392\u5e8f\u7684\u76f4\u63a5\u8bbf\u95ee\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5b9e\u7528\u6027\u80fd\uff0c\u5305\u62ec\u6570\u636e\u5e93\u7cfb\u7edf\u7684\u6bd4\u8f83\u6027\u80fd\u4ee5\u53ca\u76f4\u63a5\u8bbf\u95ee\u4e0e\u5176\u5355\u6b21\u8bbf\u95ee\u5bf9\u5e94\u9879\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u5c3d\u7ba1\u652f\u6301\u76f4\u63a5\u8bbf\u95ee\u7684\u6570\u636e\u7ed3\u6784\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u5df2\u7ecf\u5f97\u5230\u4e86\u6df1\u5165\u7814\u7a76\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8bb8\u591a\u67e5\u8be2\u548c\u5e38\u89c1\u6392\u5e8f\u5df2\u7ecf\u6709\u4e86\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u4f46\u5176\u5b9e\u7528\u6027\u80fd\u5374\u5f88\u5c11\u53d7\u5230\u5173\u6ce8\u3002", "method": "\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u6db5\u76d6\u5e7f\u6cdb\u67e5\u8be2\u548c\u6392\u5e8f\u7684\u5b9e\u73b0\u6765\u7814\u7a76\u76f4\u63a5\u8bbf\u95ee\u7684\u5b9e\u9645\u8868\u73b0\u65b9\u9762\uff0c\u5305\u62ec\u6570\u636e\u5e93\u7cfb\u7edf\u4e4b\u95f4\u7684\u6027\u80fd\u6bd4\u8f83\u4ee5\u53ca\u76f4\u63a5\u8bbf\u95ee\u4e0e\u5355\u4e00\u8bbf\u95ee\u5f62\u5f0f\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u5b9e\u73b0\u7684\u6570\u636e\u7ed3\u6784\u5728\u5904\u7406\u5404\u79cd\u67e5\u8be2\u548c\u6392\u5e8f\u65f6\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u80fd\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e0d\u540c\u6570\u636e\u5e93\u7cfb\u7edf\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u53ca\u76f4\u63a5\u8bbf\u95ee\u548c\u5355\u6b21\u8bbf\u95ee\u65b9\u5f0f\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5bf9\u76f4\u63a5\u8bbf\u95ee\u6570\u636e\u7ed3\u6784\u5b9e\u9645\u6027\u80fd\u7684\u65b0\u89c1\u89e3\uff0c\u4e5f\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316\u8fd9\u7c7b\u6570\u636e\u7ed3\u6784\u7684\u8bbe\u8ba1\u63d0\u51fa\u4e86\u53ef\u80fd\u7684\u65b9\u5411\u3002"}}
{"id": "2601.05407", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05407", "abs": "https://arxiv.org/abs/2601.05407", "authors": ["Minwoo Cho", "Batuhan Altundas", "Matthew Gombolay"], "title": "Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning", "comment": null, "summary": "Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHINT\u7684\u65b0\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u8bbe\u7f6e\u3002\u901a\u8fc7\u5229\u7528\u5c42\u6b21\u5316RL\u548c\u4f2a\u975e\u7b56\u7565RL\uff0cHINT\u89e3\u51b3\u4e86\u590d\u6742\u9886\u57df\u5185\u5408\u6210\u9ad8\u6548\u6559\u5b66\u7b56\u7565\u7684\u6311\u6218\u3001\u6559\u5e08\u5728\u5904\u7406\u5206\u5e03\u5916\u72b6\u6001\u65f6\u9047\u5230\u7684\u56f0\u96be\u4ee5\u53ca\u5b66\u751f\u4e0e\u6559\u5e08\u89c2\u5bdf\u7a7a\u95f4\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5408\u4f5c\u9886\u57df\u6d4b\u8bd5\u4e2d\uff0cHINT\u76f8\u8f83\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u6210\u529f\u7387\u4e0a\u5b9e\u73b0\u4e8660%\u5230165%\u7684\u63d0\u5347\u3002", "motivation": "\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u4e2d\u901a\u8fc7\u4f7f\u7528\u96c6\u4e2d\u7684\u6559\u5e08\u6765\u52a0\u901f\u5206\u6563\u7684\u5b66\u751f\u7684\u5b66\u4e60\u8fc7\u7a0b\u6709\u7740\u6f5c\u5728\u4ef7\u503c\uff0c\u4f46\u9762\u4e34\u7740\u51e0\u4e2a\u5173\u952e\u74f6\u9888\uff1a\u96be\u4ee5\u5728\u590d\u6742\u9886\u57df\u5408\u6210\u9ad8\u6027\u80fd\u7684\u6559\u5b66\u7b56\u7565\uff1b\u5f53\u6559\u5e08\u9700\u8981\u5728\u5206\u5e03\u5916(OOD)\u72b6\u6001\u4e0b\u8fdb\u884c\u63a8\u7406\u65f6\u5b58\u5728\u96be\u5ea6\uff1b\u4ee5\u53ca\u5206\u6563\u7684\u5b66\u751f\u4e0e\u96c6\u4e2d\u7684\u6559\u5e08\u4e4b\u95f4\u89c2\u5bdf\u7a7a\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86HINT\uff08\u5206\u5c42\u4e92\u52a8\u5f0f\u6559\u5e08\u8f6c\u79fb\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u9488\u5bf9MARL\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u7684\u573a\u666f\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6027\u80fd\u9ad8\u7684\u6559\u5e08\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4f2a\u975e\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u4f7f\u6559\u5e08\u7b56\u7565\u80fd\u591f\u57fa\u4e8e\u6559\u5e08\u548c\u5b66\u751f\u7684\u7ecf\u9a8c\u5171\u540c\u66f4\u65b0\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9OOD\u60c5\u51b5\u7684\u9002\u5e94\u80fd\u529b\u3002\u6b64\u5916\uff0cHINT\u8fd8\u91c7\u7528\u4e86\u57fa\u4e8e\u8868\u73b0\u7684\u8fc7\u6ee4\u673a\u5236\uff0c\u53ea\u4fdd\u7559\u4e0e\u7ed3\u679c\u76f8\u5173\u7684\u6307\u5bfc\u4fe1\u606f\uff0c\u51cf\u5c11\u4e86\u89c2\u5bdf\u7a7a\u95f4\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u5408\u4f5c\u4efb\u52a1\u73af\u5883\uff08\u5982FireCommander\u8d44\u6e90\u5206\u914d\u4efb\u52a1\u548cMARINE\u6218\u672f\u6218\u6597\u4efb\u52a1\uff09\u4e2d\u8bc4\u4f30\u4e86HINT\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHINT\u5728\u8fd9\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6210\u529f\u7387\u65b9\u9762\u53d6\u5f97\u4e8660%\u81f3165%\u7684\u6539\u8fdb\u3002", "conclusion": "HINT\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u51e0\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\u5408\u6210\u9ad8\u6548\u6559\u5b66\u7b56\u7565\u3001\u6539\u5584\u6559\u5e08\u5bf9\u4e8e\u672a\u89c1\u8fc7\u72b6\u6001\u7684\u9002\u5e94\u80fd\u529b\u4ee5\u53ca\u51cf\u5c11\u7531\u4e8e\u89c2\u5bdf\u7a7a\u95f4\u4e0d\u540c\u800c\u5bfc\u81f4\u7684\u4fe1\u606f\u4e22\u5931\u7b49\u95ee\u9898\u3002\u5b83\u4e0d\u4ec5\u8bc1\u660e\u4e86\u81ea\u5df1\u5728\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u800c\u4e14\u4e5f\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.05540", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05540", "abs": "https://arxiv.org/abs/2601.05540", "authors": ["Patrick Loic Foalem", "Leuson Da Silva", "Foutse Khomh", "Ettore Merlo", "Heng Li"], "title": "Empirical Characterization of Logging Smells in Machine Learning Code", "comment": null, "summary": "\\underline{Context:} Logging is a fundamental yet complex practice in software engineering, essential for monitoring, debugging, and auditing software systems. With the increasing integration of machine learning (ML) components into software systems, effective logging has become critical to ensure reproducibility, traceability, and observability throughout model training and deployment. Although various general-purpose and ML-specific logging frameworks exist, little is known about how these tools are actually used in practice or whether ML practitioners adopt consistent and effective logging strategies. To date, no empirical study has systematically characterized recurring bad logging practices--or logging smells--in ML System. \\underline{Goal:} This study aims to empirically identify and characterize logging smells in ML systems, providing an evidence-based understanding of how logging is implemented and challenged in practice. \\underline{Method:} We propose to conduct a large-scale mining of open-source ML repositories hosted on GitHub to catalogue recurring logging smells. Subsequently, a practitioner survey involving ML engineers will be conducted to assess the perceived relevance, severity, and frequency of the identified smells. \\underline{Limitations:} % While The study's limitations include that While our findings may not be generalizable to closed-source industrial projects, we believe our study provides an essential step toward understanding and improving logging practices in ML development.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5927\u89c4\u6a21\u6316\u6398GitHub\u4e0a\u5f00\u6e90\u7684\u673a\u5668\u5b66\u4e60\u4ed3\u5e93\uff0c\u8bc6\u522b\u5e76\u63cf\u8ff0\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u5e38\u89c1\u65e5\u5fd7\u8bb0\u5f55\u95ee\u9898\uff08logging smells\uff09\uff0c\u5e76\u901a\u8fc7\u8c03\u67e5\u95ee\u5377\u7684\u5f62\u5f0f\u8bc4\u4f30\u8fd9\u4e9b\u95ee\u9898\u7684\u76f8\u5173\u6027\u3001\u4e25\u91cd\u6027\u548c\u9891\u7387\u3002\u5c3d\u7ba1\u7814\u7a76\u7ed3\u679c\u53ef\u80fd\u65e0\u6cd5\u63a8\u5e7f\u5230\u95ed\u6e90\u5de5\u4e1a\u9879\u76ee\uff0c\u4f46\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u5e76\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u4e2d\u7684\u65e5\u5fd7\u8bb0\u5f55\u5b9e\u8df5\u63d0\u4f9b\u4e86\u91cd\u8981\u6b65\u9aa4\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u6709\u6548\u7684\u65e5\u5fd7\u8bb0\u5f55\u5bf9\u4e8e\u786e\u4fdd\u6a21\u578b\u8bad\u7ec3\u548c\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u7684\u53ef\u91cd\u590d\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u89c2\u6d4b\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u5b9e\u9645\u64cd\u4f5c\u4e2d\u8fd9\u4e9b\u5de5\u5177\u662f\u5982\u4f55\u88ab\u4f7f\u7528\u7684\uff0c\u6216\u8005\u673a\u5668\u5b66\u4e60\u4ece\u4e1a\u8005\u662f\u5426\u91c7\u7528\u4e86\u7edf\u4e00\u4e14\u6709\u6548\u7684\u65e5\u5fd7\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u6ca1\u6709\u5b9e\u8bc1\u7814\u7a76\u7cfb\u7edf\u5730\u63cf\u8ff0\u4e86\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u53cd\u590d\u51fa\u73b0\u7684\u65e5\u5fd7\u8bb0\u5f55\u4e0d\u4f73\u505a\u6cd5\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u5bf9GitHub\u4e0a\u6258\u7ba1\u7684\u5f00\u6e90\u673a\u5668\u5b66\u4e60\u5e93\u8fdb\u884c\u5927\u89c4\u6a21\u6316\u6398\u4ee5\u7f16\u76ee\u5e38\u89c1\u7684\u65e5\u5fd7\u8bb0\u5f55\u95ee\u9898\uff0c\u5e76\u968f\u540e\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u5f00\u5c55\u4e00\u9879\u4ece\u4e1a\u8005\u8c03\u67e5\uff0c\u4ee5\u8bc4\u4f30\u6240\u8bc6\u522b\u51fa\u7684\u95ee\u9898\u7684\u91cd\u8981\u6027\u3001\u4e25\u91cd\u7a0b\u5ea6\u53ca\u53d1\u751f\u9891\u7387\u3002", "result": "\u7814\u7a76\u9884\u8ba1\u4f1a\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u4e0d\u540c\u7c7b\u578b\u7684\u65e5\u5fd7\u8bb0\u5f55\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u8c03\u67e5\u7ed3\u679c\u7ed9\u51fa\u8fd9\u4e9b\u95ee\u9898\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u7684\u76f8\u5173\u6027\u3001\u4e25\u91cd\u6027\u4ee5\u53ca\u51fa\u73b0\u9891\u7387\u7684\u8bc4\u4f30\u3002", "conclusion": "\u867d\u7136\u8fd9\u9879\u7814\u7a76\u7684\u7ed3\u679c\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u5c01\u95ed\u6e90\u4ee3\u7801\u7684\u5de5\u4e1a\u9879\u76ee\uff0c\u4f46\u5b83\u4e3a\u7406\u89e3\u548c\u6539\u5584\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u4e2d\u7684\u65e5\u5fd7\u8bb0\u5f55\u5b9e\u8df5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u8d77\u70b9\u3002"}}
{"id": "2601.05260", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05260", "abs": "https://arxiv.org/abs/2601.05260", "authors": ["Armin Gerami", "Kazem Faghih", "Ramani Duraiswami"], "title": "Quantifying Document Impact in RAG-LLMs", "comment": null, "summary": "Retrieval Augmented Generation (RAG) enhances Large Language Models (LLMs) by connecting them to external knowledge, improving accuracy and reducing outdated information. However, this introduces challenges such as factual inconsistencies, source conflicts, bias propagation, and security vulnerabilities, which undermine the trustworthiness of RAG systems. A key gap in current RAG evaluation is the lack of a metric to quantify the contribution of individual retrieved documents to the final output. To address this, we introduce the Influence Score (IS), a novel metric based on Partial Information Decomposition that measures the impact of each retrieved document on the generated response. We validate IS through two experiments. First, a poison attack simulation across three datasets demonstrates that IS correctly identifies the malicious document as the most influential in $86\\%$ of cases. Second, an ablation study shows that a response generated using only the top-ranked documents by IS is consistently judged more similar to the original response than one generated from the remaining documents. These results confirm the efficacy of IS in isolating and quantifying document influence, offering a valuable tool for improving the transparency and reliability of RAG systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u5f71\u54cd\u5206\u6570(IS)\uff0c\u7528\u4e8e\u91cf\u5316\u68c0\u7d22\u6587\u6863\u5bf9\u6700\u7ec8\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u7684RAG\u8bc4\u4f30\u7f3a\u4e4f\u8861\u91cf\u5355\u4e2a\u68c0\u7d22\u6587\u6863\u5bf9\u6700\u7ec8\u8f93\u51fa\u8d21\u732e\u7684\u6307\u6807\uff0c\u8fd9\u5bfc\u81f4\u4e86\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u3001\u6765\u6e90\u51b2\u7a81\u3001\u504f\u89c1\u4f20\u64ad\u4ee5\u53ca\u5b89\u5168\u6f0f\u6d1e\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u90e8\u5206\u4fe1\u606f\u5206\u89e3\u63d0\u51fa\u4e86\u5f71\u54cd\u5206\u6570(IS)\u8fd9\u4e00\u65b0\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u6bd2\u5bb3\u653b\u51fb\u6a21\u62df\u5b9e\u9a8c\u4e0e\u6d88\u878d\u7814\u7a76\u4e24\u79cd\u65b9\u5f0f\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u5728\u6bd2\u5bb3\u653b\u51fb\u6a21\u62df\u4e2d\uff0cIS\u80fd\u591f\u572886%\u7684\u60c5\u51b5\u4e0b\u6b63\u786e\u8bc6\u522b\u51fa\u6700\u5177\u5f71\u54cd\u529b\u7684\u6076\u610f\u6587\u6863\uff1b\u800c\u5728\u6d88\u878d\u7814\u7a76\u4e2d\uff0c\u4ec5\u4f7f\u7528IS\u6392\u540d\u9760\u524d\u7684\u6587\u6863\u751f\u6210\u7684\u56de\u7b54\u88ab\u6301\u7eed\u8ba4\u4e3a\u6bd4\u4f7f\u7528\u5269\u4f59\u6587\u6863\u751f\u6210\u7684\u56de\u7b54\u66f4\u63a5\u8fd1\u539f\u59cb\u56de\u7b54\u3002", "conclusion": "\u5f71\u54cd\u5206\u6570(IS)\u6709\u6548\u5730\u9694\u79bb\u5e76\u91cf\u5316\u4e86\u6587\u6863\u7684\u5f71\u54cd\uff0c\u4e3a\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002"}}
{"id": "2601.05270", "categories": ["cs.IR", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.05270", "abs": "https://arxiv.org/abs/2601.05270", "authors": ["Tarun Prajapati"], "title": "LiveVectorLake: A Real-Time Versioned Knowledge Base Architecture for Streaming Vector Updates and Temporal Retrieval", "comment": "7 pages, 1 figure. Preprint; work in progress", "summary": "Modern Retrieval-Augmented Generation (RAG) systems struggle with a fundamental architectural tension: vector indices are optimized for query latency but poorly handle continuous knowledge updates, while data lakes excel at versioning but introduce query latency penalties. We introduce LiveVectorLake, a dual-tier temporal knowledge base architecture that enables real-time semantic search on current knowledge while maintaining complete version history for compliance, auditability, and point-in-time retrieval. The system introduces three core architectural contributions: (1) Content-addressable chunk-level synchronization using SHA-256 hashing for deterministic change detection without external state tracking; (2) Dual-tier storage separating hot-tier vector indices (Milvus with HNSW) from cold-tier columnar versioning (Delta Lake with Parquet), optimizing query latency and storage cost independently; (3) Temporal query routing enabling point-in-time knowledge retrieval via delta-versioning with ACID consistency across tiers. Evaluation on a 100-document corpus versioned across five time points demonstrates: (i) 10-15% re-processing of content during updates compared to 100% for full re-indexing; (ii) sub-100ms retrieval latency on current knowledge; (iii) sub-2s latency for temporal queries across version history; and (iv) storage cost optimization through hot/cold tier separation (only current chunks in expensive vector indices). The approach enables production RAG deployments requiring simultaneous optimization for query performance, update efficiency, and regulatory compliance. Code and resources: [https://github.com/praj-tarun/LiveVectorLake]", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLiveVectorLake\u7684\u53cc\u5c42\u65f6\u95f4\u77e5\u8bc6\u5e93\u67b6\u6784\uff0c\u5b83\u80fd\u591f\u5b9e\u73b0\u5b9e\u65f6\u8bed\u4e49\u641c\u7d22\u7684\u540c\u65f6\u4fdd\u6301\u5b8c\u6574\u7684\u7248\u672c\u5386\u53f2\u8bb0\u5f55\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u5185\u5bb9\u5bfb\u5740\u7684\u5757\u7ea7\u540c\u6b65\u3001\u53cc\u5c42\u5b58\u50a8\u5206\u79bb\u4ee5\u53ca\u65f6\u95f4\u67e5\u8be2\u8def\u7531\u7b49\u6838\u5fc3\u67b6\u6784\u8d21\u732e\uff0c\u4f18\u5316\u4e86\u67e5\u8be2\u5ef6\u8fdf\u548c\u5b58\u50a8\u6210\u672c\uff0c\u5e76\u652f\u6301\u8de8\u5c42\u7ea7\u7684ACID\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5b8c\u5168\u91cd\u65b0\u7d22\u5f15\u76f8\u6bd4\uff0c\u66f4\u65b0\u65f6\u7684\u5185\u5bb9\u518d\u5904\u7406\u51cf\u5c11\u4e8610-15%\uff0c\u5f53\u524d\u77e5\u8bc6\u68c0\u7d22\u5ef6\u8fdf\u4f4e\u4e8e100\u6beb\u79d2\uff0c\u5386\u53f2\u7248\u672c\u7684\u65f6\u95f4\u67e5\u8be2\u5ef6\u8fdf\u63a7\u5236\u57282\u79d2\u5185\u3002", "motivation": "\u73b0\u4ee3\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u9762\u4e34\u7740\u4e00\u4e2a\u57fa\u672c\u67b6\u6784\u4e0a\u7684\u77db\u76fe\uff1a\u5411\u91cf\u7d22\u5f15\u867d\u7136\u5bf9\u67e5\u8be2\u5ef6\u8fdf\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4f46\u5728\u6301\u7eed\u7684\u77e5\u8bc6\u66f4\u65b0\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff1b\u800c\u6570\u636e\u6e56\u867d\u7136\u64c5\u957f\u7248\u672c\u63a7\u5236\uff0c\u4f46\u4f1a\u5f15\u5165\u67e5\u8be2\u5ef6\u8fdf\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86LiveVectorLake\u3002", "method": "LiveVectorLake\u91c7\u7528\u4e86\u4e09\u4e2a\u4e3b\u8981\u7684\u67b6\u6784\u521b\u65b0\uff1a\n1. \u4f7f\u7528SHA-256\u54c8\u5e0c\u8fdb\u884c\u5185\u5bb9\u5bfb\u5740\u7684\u5757\u7ea7\u540c\u6b65\uff0c\u5b9e\u73b0\u65e0\u9700\u5916\u90e8\u72b6\u6001\u8ddf\u8e2a\u7684\u786e\u5b9a\u6027\u53d8\u66f4\u68c0\u6d4b\u3002\n2. \u91c7\u7528\u53cc\u5c42\u5b58\u50a8\u7ed3\u6784\uff0c\u5c06\u70ed\u5c42\u5411\u91cf\u7d22\u5f15\uff08Milvus\u642d\u914dHNSW\u7b97\u6cd5\uff09\u4e0e\u51b7\u5c42\u5217\u5f0f\u7248\u672c\u7ba1\u7406\uff08Delta Lake\u914d\u5408Parquet\u683c\u5f0f\uff09\u5206\u5f00\uff0c\u4ece\u800c\u72ec\u7acb\u4f18\u5316\u67e5\u8be2\u5ef6\u8fdf\u548c\u5b58\u50a8\u6210\u672c\u3002\n3. \u5b9e\u73b0\u4e86\u65f6\u95f4\u67e5\u8be2\u8def\u7531\u529f\u80fd\uff0c\u5141\u8bb8\u901a\u8fc7\u5e26\u6709ACID\u4e00\u81f4\u6027\u7684delta-versioning\u673a\u5236\u6765\u8fdb\u884c\u6307\u5b9a\u65f6\u95f4\u70b9\u7684\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u65f6\u95f4\u70b9\u7248\u672c\u7684100\u6587\u6863\u8bed\u6599\u5e93\u4e0a\uff0cLiveVectorLake\u5c55\u793a\u4e86\u4ee5\u4e0b\u6027\u80fd\u6307\u6807\uff1a(i) \u66f4\u65b0\u671f\u95f4\u4ec5\u9700\u91cd\u5904\u740610-15%\u7684\u5185\u5bb9\uff0c\u8fdc\u4f4e\u4e8e\u5b8c\u5168\u91cd\u65b0\u7d22\u5f15\u6240\u9700\u7684100%\uff1b(ii) \u5bf9\u5f53\u524d\u77e5\u8bc6\u7684\u68c0\u7d22\u5ef6\u8fdf\u4f4e\u4e8e100\u6beb\u79d2\uff1b(iii) \u9488\u5bf9\u6574\u4e2a\u7248\u672c\u5386\u53f2\u7684\u65f6\u95f4\u67e5\u8be2\u5ef6\u8fdf\u4fdd\u6301\u57282\u79d2\u4ee5\u5185\uff1b(iv) \u901a\u8fc7\u5bf9\u70ed/\u51b7\u5c42\u7684\u5206\u79bb\u5b9e\u73b0\u4e86\u5b58\u50a8\u6210\u672c\u7684\u4f18\u5316\uff08\u53ea\u6709\u6700\u65b0\u5757\u4f4d\u4e8e\u6602\u8d35\u7684\u5411\u91cf\u7d22\u5f15\u4e2d\uff09\u3002", "conclusion": "LiveVectorLake\u65b9\u6cd5\u80fd\u591f\u5728\u9700\u8981\u540c\u65f6\u4f18\u5316\u67e5\u8be2\u6027\u80fd\u3001\u66f4\u65b0\u6548\u7387\u548c\u6cd5\u89c4\u9075\u4ece\u6027\u7684\u751f\u4ea7RAG\u90e8\u7f72\u4e2d\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2601.05542", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05542", "abs": "https://arxiv.org/abs/2601.05542", "authors": ["Adam Bodicoat", "Gunel Jahangirova", "Valerio Terragni"], "title": "Understanding LLM-Driven Test Oracle Generation", "comment": "Accepted for presentation at the 2nd ACM/IEEE International Conference on AI-powered Software (AIware 2025)", "summary": "Automated unit test generation aims to improve software quality while reducing the time and effort required for creating tests manually. However, existing techniques primarily generate regression oracles that predicate on the implemented behavior of the class under test. They do not address the oracle problem: the challenge of distinguishing correct from incorrect program behavior. With the rise of Foundation Models (FMs), particularly Large Language Models (LLMs), there is a new opportunity to generate test oracles that reflect intended behavior. This positions LLMs as enablers of Promptware, where software creation and testing are driven by natural-language prompts. This paper presents an empirical study on the effectiveness of LLMs in generating test oracles that expose software failures. We investigate how different prompting strategies and levels of contextual input impact the quality of LLM-generated oracles. Our findings offer insights into the strengths and limitations of LLM-based oracle generation in the FM era, improving our understanding of their capabilities and fostering future research in this area.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u6d4b\u8bd5\u9884\u8a00\u4ee5\u66b4\u9732\u8f6f\u4ef6\u6545\u969c\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u548c\u4e0a\u4e0b\u6587\u8f93\u5165\u6c34\u5e73\u5982\u4f55\u5f71\u54cdLLM\u751f\u6210\u9884\u8a00\u7684\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u6280\u672f\u4e3b\u8981\u4f9d\u8d56\u4e8e\u88ab\u6d4b\u7c7b\u7684\u5b9e\u73b0\u884c\u4e3a\u6765\u751f\u6210\u56de\u5f52\u9884\u8a00\uff0c\u4f46\u5b83\u4eec\u672a\u80fd\u89e3\u51b3\u9884\u8a00\u95ee\u9898\uff1a\u5373\u533a\u5206\u6b63\u786e\u4e0e\u4e0d\u6b63\u786e\u7684\u7a0b\u5e8f\u884c\u4e3a\u3002\u968f\u7740\u57fa\u7840\u6a21\u578b\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u5b58\u5728\u4e00\u4e2a\u65b0\u673a\u9047\u53bb\u751f\u6210\u53cd\u6620\u9884\u671f\u884c\u4e3a\u7684\u6d4b\u8bd5\u9884\u8a00\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u53ca\u4e0a\u4e0b\u6587\u8f93\u5165\u7a0b\u5ea6\u5bf9LLM\u751f\u6210\u9884\u8a00\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5173\u4e8e\u57fa\u4e8eLLM\u9884\u8a00\u751f\u6210\u7684\u4f18\u70b9\u548c\u5c40\u9650\u6027\u7684\u89c1\u89e3\uff0c\u589e\u5f3a\u4e86\u6211\u4eec\u5bf9\u5176\u80fd\u529b\u7684\u7406\u89e3\uff0c\u5e76\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u80fd\u591f\u63ed\u793a\u8f6f\u4ef6\u7f3a\u9677\u7684\u6d4b\u8bd5\u9884\u8a00\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u6f5c\u529b\uff0c\u4f46\u5176\u6548\u679c\u53d7\u5230\u63d0\u793a\u7b56\u7565\u548c\u6240\u63d0\u4f9b\u4e0a\u4e0b\u6587\u4fe1\u606f\u91cf\u7684\u5f71\u54cd\u3002"}}
{"id": "2601.05261", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05261", "abs": "https://arxiv.org/abs/2601.05261", "authors": ["Muhammad Mufti", "Omar Hammad", "Mahfuzur Rahman"], "title": "Improving User Experience with Personalized Review Ranking and Summarization", "comment": null, "summary": "Online consumer reviews play a crucial role in guiding purchase decisions by offering insights into product quality, usability, and performance. However, the increasing volume of user-generated reviews has led to information overload, making it difficult for consumers to identify content that aligns with their specific preferences. Existing review ranking systems typically rely on metrics such as helpfulness votes, star ratings, and recency, but these fail to capture individual user interests and often treat textual sentiment and rating signals separately. This research addresses these limitations by proposing a personalized framework that integrates review ranking and abstractive summarization to enhance decision-making efficiency. The proposed system begins by modeling each user's sentiment through a hybrid analysis of star ratings and review content. Simultaneously, user preferences were derived from historical reviews using sentence embeddings and clustering, forming semantic profiles aligned with thematic and sentiment dimensions. A relevance scoring algorithm matched these profiles with unseen reviews based on sentiment and aspect similarity. Top-matched reviews were then summarized to reflect individual interests. A user study with 70 participants demonstrated that the personalized approach improved satisfaction, perceived relevance, and decision-making confidence, while reducing time spent reading. The results highlight the method's effectiveness in alleviating information overload and delivering content tailored to user-specific preferences, emphasizing its value in enhancing user experience in review-rich decision-making environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bc4\u8bba\u6392\u5e8f\u548c\u62bd\u8c61\u603b\u7ed3\u7684\u4e2a\u6027\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u7528\u6237\u7684\u5386\u53f2\u8bc4\u4ef7\u6765\u5f62\u6210\u60c5\u611f\u548c\u4e2a\u4eba\u504f\u597d\u6a21\u578b\uff0c\u5e76\u636e\u6b64\u5339\u914d\u5e76\u603b\u7ed3\u51fa\u6700\u76f8\u5173\u7684\u8bc4\u8bba\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7528\u6237\u6ee1\u610f\u5ea6\u3001\u76f8\u5173\u6027\u548c\u51b3\u7b56\u4fe1\u5fc3\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9605\u8bfb\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u7528\u6237\u751f\u6210\u8bc4\u8bba\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6d88\u8d39\u8005\u9762\u4e34\u7740\u4fe1\u606f\u8fc7\u8f7d\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u627e\u5230\u7b26\u5408\u4e2a\u4eba\u504f\u597d\u7684\u5185\u5bb9\u3002\u73b0\u6709\u7684\u8bc4\u8bba\u6392\u540d\u7cfb\u7edf\u4e3b\u8981\u4f9d\u636e\u6709\u7528\u6027\u6295\u7968\u3001\u661f\u7ea7\u8bc4\u5206\u7b49\u6307\u6807\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u4e2a\u4f53\u7528\u6237\u7684\u5174\u8da3\uff0c\u4e14\u901a\u5e38\u5c06\u6587\u672c\u60c5\u7eea\u4e0e\u8bc4\u5206\u4fe1\u53f7\u5206\u5f00\u5904\u7406\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e8\u5728\u63d0\u9ad8\u51b3\u7b56\u6548\u7387\u7684\u65b0\u6846\u67b6\u3002", "method": "\u8be5\u7814\u7a76\u9996\u5148\u901a\u8fc7\u7efc\u5408\u5206\u6790\u661f\u7ea7\u8bc4\u5206\u548c\u8bc4\u8bba\u5185\u5bb9\u6765\u5efa\u6a21\u6bcf\u4e2a\u7528\u6237\u7684\u60c5\u611f\u3002\u540c\u65f6\u5229\u7528\u53e5\u5b50\u5d4c\u5165\u548c\u805a\u7c7b\u6280\u672f\u4ece\u5386\u53f2\u8bc4\u8bba\u4e2d\u63d0\u53d6\u7528\u6237\u504f\u597d\uff0c\u6784\u5efa\u4e0e\u4e3b\u9898\u548c\u60c5\u611f\u7ef4\u5ea6\u5bf9\u9f50\u7684\u8bed\u4e49\u6863\u6848\u3002\u7136\u540e\u91c7\u7528\u76f8\u5173\u6027\u8bc4\u5206\u7b97\u6cd5\u6839\u636e\u60c5\u611f\u548c\u65b9\u9762\u76f8\u4f3c\u5ea6\u5c06\u8fd9\u4e9b\u6863\u6848\u4e0e\u672a\u89c1\u8fc7\u7684\u8bc4\u8bba\u8fdb\u884c\u5339\u914d\u3002\u6700\u540e\u5bf9\u6700\u9ad8\u5339\u914d\u5ea6\u7684\u8bc4\u8bba\u8fdb\u884c\u6458\u8981\u5904\u7406\u4ee5\u53cd\u6620\u4e2a\u4eba\u5174\u8da3\u3002", "result": "\u4e00\u9879\u5305\u542b70\u540d\u53c2\u4e0e\u8005\u7684\u7814\u7a76\u663e\u793a\uff0c\u4e2a\u6027\u5316\u7684\u65b9\u6cd5\u5728\u63d0\u5347\u6ee1\u610f\u5ea6\u3001\u611f\u77e5\u76f8\u5173\u6027\u548c\u51b3\u7b56\u81ea\u4fe1\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u4e5f\u51cf\u5c11\u4e86\u7528\u6237\u82b1\u5728\u9605\u8bfb\u4e0a\u7684\u65f6\u95f4\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u8c03\u4e86\u8be5\u65b9\u6cd5\u5728\u7f13\u89e3\u4fe1\u606f\u8fc7\u8f7d\u53ca\u63d0\u4f9b\u5b9a\u5236\u5316\u5185\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5bf9\u4e8e\u6539\u5584\u5bcc\u542b\u8bc4\u8bba\u7684\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u7528\u6237\u4f53\u9a8c\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.05431", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05431", "abs": "https://arxiv.org/abs/2601.05431", "authors": ["Xiaowen He", "Su Jiang", "Louis J. Durlofsky"], "title": "Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion", "comment": null, "summary": "Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields, and fault slip tendency, in CO${_2}$ storage projects. The main computations required by the DSI workflow entail the simulation of O(1000) prior geomodels. The posterior distributions for quantities of interest are then inferred directly from prior simulation results and observed data, without the need to generate posterior geomodels. The model used here involves a synthetic 3D system with two faults. Realizations of heterogeneous permeability and porosity fields are generated using geostatistical software, and uncertain geomechanical and fault parameters are sampled for each realization from prior distributions. Coupled flow-geomechanics simulations for these geomodels are conducted using GEOS. A VAE with stacked convolutional long short-term memory layers is trained, using the prior simulation results, to represent pressure, strain, effective normal stress and shear stress fields in terms of latent variables. The VAE parameterization is used with DSI for posterior predictions, with monitoring wells providing observed pressure and strain data. Posterior results for synthetic true models demonstrate that the DSI-VAE framework gives accurate predictions for pressure, strain, and stress fields and for fault slip tendency. The framework is also shown to reduce uncertainty in key geomechanical and fault parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6570\u636e\u7a7a\u95f4\u53cd\u6f14\uff08DSI\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4bCO2\u50a8\u5b58\u9879\u76ee\u4e2d\u7684\u538b\u529b\u3001\u5e94\u529b\u3001\u5e94\u53d8\u573a\u4ee5\u53ca\u65ad\u5c42\u6ed1\u79fb\u503e\u5411\u3002\u901a\u8fc7\u4f7f\u7528\u5148\u9a8c\u5730\u8d28\u6a21\u578b\u6a21\u62df\u7ed3\u679c\u548c\u89c2\u6d4b\u6570\u636e\u76f4\u63a5\u63a8\u65ad\u611f\u5174\u8da3\u91cf\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u65e0\u9700\u751f\u6210\u540e\u9a8c\u5730\u8d28\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u9884\u6d4b\u538b\u529b\u3001\u5e94\u53d8\u3001\u5e94\u529b\u573a\u53ca\u65ad\u5c42\u6ed1\u79fb\u503e\u5411\uff0c\u5e76\u51cf\u5c11\u5173\u952e\u5730\u8d28\u529b\u5b66\u548c\u65ad\u5c42\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5728\u8bb8\u591a\u5730\u4e0b\u4f5c\u4e1a\u4e2d\uff0c\u51c6\u786e\u8bc4\u4f30\u65ad\u5c42\u6ed1\u52a8\u7684\u53ef\u80fd\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u6d89\u53ca\u65ad\u5c42\u7684\u8026\u5408\u6d41\u52a8-\u5730\u8d28\u529b\u5b66\u95ee\u9898\u4e0a\u5e94\u7528\u4f20\u7edf\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u5386\u53f2\u5339\u914d\u65b9\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u96be\u9898\u3002", "method": "\u672c\u7814\u7a76\u5b9e\u65bd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6570\u636e\u7a7a\u95f4\u53cd\u6f14\uff08DSI\uff09\u6846\u67b6\uff0c\u7528\u6765\u9884\u6d4bCO2\u50a8\u5b58\u9879\u76ee\u4e2d\u7684\u538b\u529b\u3001\u5e94\u529b\u3001\u5e94\u53d8\u573a\u4ee5\u53ca\u65ad\u5c42\u6ed1\u79fb\u503e\u5411\u3002\u9996\u5148\u751f\u6210\u4e86\u5305\u542b\u4e24\u4e2a\u65ad\u5c42\u7684\u5408\u6210\u4e09\u7ef4\u7cfb\u7edf\u4e0b\u7684\u5f02\u8d28\u6e17\u900f\u7387\u548c\u5b54\u9699\u5ea6\u573a\u5b9e\u73b0\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u5b9e\u73b0\u4ece\u5148\u9a8c\u5206\u5e03\u4e2d\u62bd\u6837\u4e0d\u786e\u5b9a\u7684\u5730\u8d28\u529b\u5b66\u548c\u65ad\u5c42\u53c2\u6570\u3002\u63a5\u7740\uff0c\u5229\u7528GEOS\u8fdb\u884c\u4e86\u8fd9\u4e9b\u5730\u8d28\u6a21\u578b\u7684\u8026\u5408\u6d41\u52a8-\u5730\u8d28\u529b\u5b66\u6a21\u62df\u3002\u7136\u540e\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5e26\u6709\u5806\u53e0\u5377\u79ef\u957f\u77ed\u671f\u8bb0\u5fc6\u5c42\u7684VAE\uff0c\u4ee5\u6839\u636e\u6f5c\u5728\u53d8\u91cf\u8868\u793a\u538b\u529b\u3001\u5e94\u53d8\u3001\u6709\u6548\u6b63\u5e94\u529b\u548c\u526a\u5e94\u529b\u573a\u3002\u6700\u540e\uff0c\u7ed3\u5408\u76d1\u6d4b\u4e95\u63d0\u4f9b\u7684\u89c2\u6d4b\u538b\u529b\u548c\u5e94\u53d8\u6570\u636e\uff0c\u5229\u7528VAE\u53c2\u6570\u5316\u4e0eDSI\u8fdb\u884c\u540e\u9a8c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5bf9\u4e8e\u5408\u6210\u7684\u771f\u5b9e\u6a21\u578b\u800c\u8a00\uff0cDSI-VAE\u6846\u67b6\u80fd\u591f\u51c6\u786e\u5730\u9884\u6d4b\u538b\u529b\u3001\u5e94\u53d8\u3001\u5e94\u529b\u573a\u4ee5\u53ca\u65ad\u5c42\u6ed1\u79fb\u503e\u5411\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5173\u952e\u5730\u8d28\u529b\u5b66\u548c\u65ad\u5c42\u53c2\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eVAE\u7684\u6570\u636e\u7a7a\u95f4\u53cd\u6f14\u6846\u67b6\u4e3a\u89e3\u51b3\u590d\u6742\u5730\u8d28\u6761\u4ef6\u4e0b\u7684\u65ad\u5c42\u6ed1\u79fb\u9884\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u53ca\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.05555", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05555", "abs": "https://arxiv.org/abs/2601.05555", "authors": ["Patrick Loic Foalem", "Foutse Khomh", "Leuson Da Silva", "Ettore Merlo"], "title": "An Empirical Study of Policy-as-Code Adoption in Open-Source Software Projects", "comment": null, "summary": "\\textbf{Context:} Policy-as-Code (PaC) has become a foundational approach for embedding governance, compliance, and security requirements directly into software systems. While organizations increasingly adopt PaC tools, the software engineering community lacks an empirical understanding of how these tools are used in real-world development practices.\n  \\textbf{Objective:} This paper aims to bridge this gap by conducting the first large-scale study of PaC usage in open-source software. Our goal is to characterize how PaC tools are adopted, what purposes they serve, and what governance activities they support across diverse software ecosystems.\n  \\textbf{Method:} We analyzed 399 GitHub repositories using nine widely adopted PaC tools. Our mixed-methods approach combines quantitative analysis of tool usage and project characteristics with a qualitative investigation of policy files. We further employ a Large Language Model (LLM)--assisted classification pipeline, refined through expert validation, to derive a taxonomy of PaC usage consisting of 5 categories and 15 sub-categories.\n  \\textbf{Results:} Our study reveals substantial diversity in PaC adoption. PaC tools are frequently used in early-stage projects and are heavily oriented toward governance, configuration control, and documentation. We also observe emerging PaC usage in MLOps pipelines and strong co-usage patterns, such as between OPA and Gatekeeper. Our taxonomy highlights recurring governance intents.\n  \\textbf{Conclusion:} Our findings offer actionable insights for practitioners and tool developers. They highlight concrete usage patterns, emphasize actual PaC usage, and motivate opportunities for improving tool interoperability. This study lays the empirical foundation for future research on PaC practices and their role in ensuring trustworthy, compliant software systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9399\u4e2a\u4f7f\u7528\u4e86\u4e5d\u79cd\u5e7f\u6cdb\u91c7\u7528\u7684\u653f\u7b56\u5373\u4ee3\u7801\uff08PaC\uff09\u5de5\u5177\u7684GitHub\u4ed3\u5e93\u8fdb\u884c\u5206\u6790\uff0c\u7ed3\u5408\u5b9a\u91cf\u548c\u5b9a\u6027\u65b9\u6cd5\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u5206\u7c7b\uff0c\u63ed\u793a\u4e86PaC\u5de5\u5177\u5728\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u7684\u591a\u6837\u6027\u548c\u5177\u4f53\u5e94\u7528\u6a21\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\u4e3a\u5b9e\u8df5\u8005\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5173\u4e8e\u5982\u4f55\u6539\u8fdb\u5de5\u5177\u4e92\u64cd\u4f5c\u6027\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76PaC\u5b9e\u8df5\u53ca\u5176\u5728\u786e\u4fdd\u53ef\u4fe1\u3001\u5408\u89c4\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u7ec4\u7ec7\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u653f\u7b56\u5373\u4ee3\u7801(PaC)\u5de5\u5177\uff0c\u5c06\u6cbb\u7406\u3001\u5408\u89c4\u6027\u548c\u5b89\u5168\u8981\u6c42\u76f4\u63a5\u5d4c\u5165\u5230\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u57fa\u7840\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u5de5\u5177\u5728\u5b9e\u9645\u5f00\u53d1\u5b9e\u8df5\u4e2d\u5982\u4f55\u4f7f\u7528\u7684\u5b9e\u8bc1\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f00\u5c55\u9996\u4e2a\u5927\u89c4\u6a21PaC\u4f7f\u7528\u60c5\u51b5\u7684\u7814\u7a76\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ee5\u4e86\u89e3PaC\u5de5\u5177\u662f\u5982\u4f55\u88ab\u91c7\u7eb3\u7684\u3001\u5b83\u4eec\u670d\u52a1\u4e8e\u4ec0\u4e48\u76ee\u7684\u4ee5\u53ca\u5b83\u4eec\u652f\u6301\u54ea\u4e9b\u6cbb\u7406\u6d3b\u52a8\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5206\u6790\u4e86\u5229\u7528\u4e5d\u79cd\u5e7f\u6cdb\u5e94\u7528\u7684PaC\u5de5\u5177\u7684399\u4e2aGitHub\u4ed3\u5e93\u3002\u4ed6\u4eec\u91c7\u7528\u4e86\u6df7\u5408\u65b9\u6cd5\u8bba\uff0c\u7ed3\u5408\u4e86\u5de5\u5177\u4f7f\u7528\u4e0e\u9879\u76ee\u7279\u5f81\u7684\u5b9a\u91cf\u5206\u6790\u53ca\u653f\u7b56\u6587\u4ef6\u7684\u5b9a\u6027\u8c03\u67e5\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86\u4e00\u79cd\u7ecf\u8fc7\u4e13\u5bb6\u9a8c\u8bc1\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b(LLM)\u8f85\u52a9\u5206\u7c7b\u6d41\u7a0b\uff0c\u4ee5\u6b64\u53d1\u5c55\u51fa\u4e00\u4e2a\u75315\u4e2a\u7c7b\u522b\u548c15\u4e2a\u5b50\u7c7b\u522b\u7ec4\u6210\u7684PaC\u4f7f\u7528\u5206\u7c7b\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728PaC\u91c7\u7eb3\u65b9\u9762\u5b58\u5728\u663e\u8457\u591a\u6837\u6027\u3002PaC\u5de5\u5177\u7ecf\u5e38\u88ab\u7528\u4e8e\u65e9\u671f\u9636\u6bb5\u9879\u76ee\uff0c\u5e76\u4e14\u4e3b\u8981\u5173\u6ce8\u4e8e\u6cbb\u7406\u3001\u914d\u7f6e\u63a7\u5236\u548c\u6587\u6863\u5316\u3002\u540c\u65f6\u89c2\u5bdf\u5230\u4e86\u5728MLOps\u7ba1\u9053\u4e2d\u65b0\u5174\u7684PaC\u4f7f\u7528\u8d8b\u52bf\uff0c\u4ee5\u53ca\u660e\u663e\u7684\u5171\u7528\u6a21\u5f0f\uff0c\u6bd4\u5982OPA\u4e0eGatekeeper\u4e4b\u95f4\u7684\u642d\u914d\u4f7f\u7528\u3002\u6240\u53d1\u5c55\u7684\u5206\u7c7b\u6cd5\u7a81\u51fa\u4e86\u91cd\u590d\u51fa\u73b0\u7684\u6cbb\u7406\u610f\u56fe\u3002", "conclusion": "\u8be5\u7814\u7a76\u7684\u7ed3\u679c\u4e3a\u4ece\u4e1a\u8005\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u5177\u4f53\u7684PaC\u4f7f\u7528\u6a21\u5f0f\uff0c\u5e76\u6fc0\u53d1\u4e86\u63d0\u9ad8\u5de5\u5177\u95f4\u4e92\u64cd\u4f5c\u6027\u7684\u673a\u4f1a\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u672a\u6765\u5173\u4e8ePaC\u5b9e\u8df5\u53ca\u5176\u5728\u786e\u4fdd\u53ef\u4fe1\u3001\u5408\u89c4\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u89d2\u8272\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2601.05262", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05262", "abs": "https://arxiv.org/abs/2601.05262", "authors": ["Xiaocong Yang"], "title": "LLM2IR: simple unsupervised contrastive learning makes long-context LLM great retriever", "comment": "MS Thesis", "summary": "Modern dense information retrieval (IR) models usually rely on costly large-scale pretraining. In this paper, we introduce LLM2IR, an efficient unsupervised contrastive learning framework to convert any decoder-only large language model (LLM) to an information retrieval model. Despite its simplicity, the effectiveness is proven among different LLMs on multiple IR benchmarks including LoCo, LongEmbed and BEIR. We also find that models with a longer context length tend to have a stronger IR capacity by comparing task performances of models in the same model family. Our work not only provides an effective way to build IR models on the state-of-the-art LLMs, but also shed light on the relationship between information retrieval ability and model context length, which helps the design of better information retrievers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLLM2IR\u7684\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u4efb\u4f55\u4ec5\u89e3\u7801\u5668\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u4e86\u6709\u6548\u6027\uff0c\u800c\u4e14\u63ed\u793a\u4e86\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0e\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u73b0\u4ee3\u5bc6\u96c6\u578b\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u6210\u672c\u9ad8\u6602\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u3002\u4e3a\u4e86\u63d0\u4f9b\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6784\u5efa\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u63a2\u7d22\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\u4e0e\u6a21\u578b\u7279\u6027\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u5f15\u5165LLM2IR\u8fd9\u4e00\u9ad8\u6548\u7684\u65e0\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5404\u79cd\u4ec5\u89e3\u7801\u5668\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8f6c\u6362\u4e3a\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u3002", "result": "\u4e0d\u540c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728LoCo\u3001LongEmbed\u548cBEIR\u7b49\u591a\u4e2a\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff1b\u540c\u65f6\u53d1\u73b0\uff0c\u5728\u76f8\u540c\u6a21\u578b\u5bb6\u65cf\u5185\u6bd4\u8f83\u65f6\uff0c\u5177\u6709\u66f4\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u6a21\u578b\u5f80\u5f80\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u4e3a\u5229\u7528\u6700\u5148\u8fdb\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u4fe1\u606f\u68c0\u7d22\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u8fd8\u63ed\u793a\u4e86\u4fe1\u606f\u68c0\u7d22\u80fd\u529b\u548c\u6a21\u578b\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u597d\u7684\u4fe1\u606f\u68c0\u7d22\u5668\u3002"}}
{"id": "2601.05451", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05451", "abs": "https://arxiv.org/abs/2601.05451", "authors": ["Marko Sterbentz", "Kevin Cushing", "Cameron Barrie", "Kristian J. Hammond"], "title": "RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models", "comment": null, "summary": "Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.", "AI": {"tldr": "RingSQL, a hybrid data generation framework, combines query templates with LLM-based paraphrasing to produce high-quality, correct, and linguistically diverse training data for text-to-SQL models, leading to improved accuracy on benchmarks.", "motivation": "The development of text-to-SQL systems faces challenges due to the limited availability of high-quality training data. Traditional methods of creating such data are either costly (manual creation) or have limitations in terms of quality and scalability (template-based or LLM-based approaches).", "method": "RingSQL innovatively merges schema-independent query templates with natural language question paraphrasing using large language models (LLMs), aiming to generate SQL queries that are both correct and exhibit a wide range of linguistic diversity.", "result": "Models trained on data generated by RingSQL show an average improvement in accuracy of +2.3% across six different text-to-SQL benchmarks, compared to those trained on other synthetic data sets.", "conclusion": "RingSQL presents a promising solution to enhance the quality and diversity of training data for text-to-SQL tasks, thereby improving the performance of these systems. The approach is made accessible through public code sharing."}}
{"id": "2601.05617", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05617", "abs": "https://arxiv.org/abs/2601.05617", "authors": ["Omar Abedelkader", "St\u00e9phane Ducasse", "Oleksandr Zaitsev", "Romain Robbes", "Guillermo Polito"], "title": "Package-Aware Approach for Repository-Level Code Completion in Pharo", "comment": null, "summary": "Pharo offers a sophisticated completion engine based on semantic heuristics, which coordinates specific fetchers within a lazy architecture. These heuristics can be recomposed to support various activities (e.g., live programming or history usage navigation). While this system is powerful, it does not account for the repository structure when suggesting global names such as class names, class variables, or global variables. As a result, it does not prioritize classes within the same package or project, treating all global names equally. In this paper, we present a new heuristic that addresses this limitation. Our approach searches variable names in a structured manner: it begins with the package of the requesting class, then expands to other packages within the same repository, and finally considers the global namespace. We describe the logic behind this heuristic and evaluate it against the default semantic heuristic and one that directly queries the global namespace. Preliminary results indicate that the Mean Reciprocal Rank (MRR) improves, confirming that package-awareness completions deliver more accurate and relevant suggestions than the previous flat global approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbPharo\u7684\u4ee3\u7801\u8865\u5168\u5f15\u64ce\u3002\u8be5\u65b9\u6cd5\u4f18\u5148\u8003\u8651\u540c\u4e00\u5305\u6216\u9879\u76ee\u4e2d\u7684\u7c7b\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5efa\u8bae\u7684\u76f8\u5173\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "Pharo\u73b0\u6709\u7684\u4ee3\u7801\u8865\u5168\u7cfb\u7edf\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u5728\u6ca1\u6709\u8003\u8651\u5230\u4ed3\u5e93\u7ed3\u6784\uff0c\u5728\u63a8\u8350\u5168\u5c40\u540d\u79f0\u5982\u7c7b\u540d\u3001\u7c7b\u53d8\u91cf\u6216\u5168\u5c40\u53d8\u91cf\u65f6\u4e0d\u4f18\u5148\u8003\u8651\u540c\u5305\u6216\u540c\u9879\u76ee\u7684\u7c7b\u3002", "method": "\u65b0\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u9996\u5148\u5728\u8bf7\u6c42\u7c7b\u6240\u5728\u7684\u5305\u5185\u641c\u7d22\u53d8\u91cf\u540d\uff0c\u7136\u540e\u6269\u5c55\u5230\u540c\u4e00\u4ed3\u5e93\u5185\u7684\u5176\u4ed6\u5305\uff0c\u6700\u540e\u624d\u8003\u8651\u5168\u5c40\u547d\u540d\u7a7a\u95f4\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528\u8fd9\u79cd\u65b9\u6cd5\u540e\u5e73\u5747\u5012\u6570\u6392\u540d\uff08MRR\uff09\u6709\u6240\u63d0\u9ad8\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u5305\u610f\u8bc6\u7684\u8865\u5168\u6bd4\u4e4b\u524d\u7684\u7eaf\u5168\u5c40\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u76f8\u5173\u7684\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u8fd9\u79cd\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0cPharo\u7684\u4ee3\u7801\u8865\u5168\u529f\u80fd\u5f97\u5230\u4e86\u589e\u5f3a\uff0c\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u8f6f\u4ef6\u9879\u76ee\u7684\u5b9e\u9645\u7ed3\u6784\uff0c\u4ece\u800c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u66f4\u52a0\u6709\u7528\u7684\u4ee3\u7801\u8865\u5168\u5efa\u8bae\u3002"}}
{"id": "2601.05263", "categories": ["cs.IR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.05263", "abs": "https://arxiv.org/abs/2601.05263", "authors": ["Zhen Yi Lau"], "title": "A General Metric-Space Formulation of the Time Warp Edit Distance (TWED)", "comment": "20 pages, 1 algorithm, small technical note on the generalization of the Time Warp Edit Distance (TWED) to arbitrary metric spaces", "summary": "This short technical note presents a formal generalization of the Time Warp Edit Distance (TWED) proposed by Marteau (2009) to arbitrary metric spaces. By viewing both the observation and temporal domains as metric spaces $(X, d)$ and $(T, \u0394)$, we define a Generalized TWED (GTWED) that remains a true metric under mild assumptions. We provide self-contained proofs of its metric properties and show that the classical TWED is recovered as a special case when $X = \\mathbb{R}^d$, $T \\subset \\mathbb{R}$, and $g(x) = x$. This note focuses on the theoretical structure of GTWED and its implications for extending elastic distances beyond time series, which enables the use of TWED-like metrics on sequences over arbitrary domains such as symbolic data, manifolds, or embeddings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5e7f\u4e49\u7684\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb\uff08GTWED\uff09\uff0c\u5b83\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u610f\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5e76\u4e14\u5728\u6e29\u548c\u7684\u5047\u8bbe\u4e0b\u4fdd\u6301\u771f\u6b63\u7684\u5ea6\u91cf\u6027\u8d28\u3002\u901a\u8fc7\u5c06\u89c2\u5bdf\u57df\u548c\u65f6\u95f4\u57df\u89c6\u4e3a\u5ea6\u91cf\u7a7a\u95f4\uff0c\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u4f20\u7edf\u7684TWED\u5230\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u7b26\u53f7\u6570\u636e\u3001\u6d41\u5f62\u6216\u5d4c\u5165\u7b49\u3002", "motivation": "\u4e3a\u4e86\u5c06\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb\uff08TWED\uff09\u7684\u6982\u5ff5\u63a8\u5e7f\u81f3\u4efb\u610f\u5ea6\u91cf\u7a7a\u95f4\uff0c\u4f7f\u5f97\u8fd9\u4e00\u5ea6\u91cf\u5de5\u5177\u4e0d\u4ec5\u9650\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\uff0c\u4e5f\u80fd\u88ab\u7528\u4e8e\u5904\u7406\u5176\u4ed6\u7c7b\u578b\u7684\u6570\u636e\u96c6\uff0c\u6bd4\u5982\u7b26\u53f7\u6570\u636e\u3001\u6d41\u5f62\u6216\u8005\u5d4c\u5165\u5411\u91cf\u7b49\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5b9a\u4e49\u4e24\u4e2a\u5ea6\u91cf\u7a7a\u95f4 $(X, d)$ \u548c $(T, \u0394)$ \u5206\u522b\u4ee3\u8868\u89c2\u5bdf\u57df\u548c\u65f6\u95f4\u57df\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49\u7684\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb\uff08GTWED\uff09\u3002\u8bc1\u660e\u4e86\u5728\u4e00\u4e9b\u6e29\u548c\u6761\u4ef6\u4e0b\uff0cGTWED \u6ee1\u8db3\u5ea6\u91cf\u5c5e\u6027\u3002\u5e76\u4e14\u5c55\u793a\u5f53 $X = \\mathbb{R}^d$\u3001$T \\subset \\mathbb{R}$ \u4ee5\u53ca $g(x) = x$ \u65f6\uff0cGTWED \u80fd\u591f\u9000\u5316\u4e3a\u7ecf\u5178 TWED \u7684\u7279\u4f8b\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 GTWED \u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u786e\u5b9e\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5ea6\u91cf\u65b9\u5f0f\uff0c\u5b83\u80fd\u591f\u4f5c\u4e3a\u4f20\u7edf TWED \u7684\u4e00\u822c\u5316\u5f62\u5f0f\uff0c\u9002\u7528\u4e8e\u66f4\u52a0\u591a\u6837\u5316\u7684\u6570\u636e\u7c7b\u578b\u3002", "conclusion": "\u672c\u6280\u672f\u8bf4\u660e\u4ecb\u7ecd\u4e86\u5e7f\u4e49\u65f6\u95f4\u626d\u66f2\u7f16\u8f91\u8ddd\u79bb\uff08GTWED\uff09\u7684\u6982\u5ff5\u53ca\u5176\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u4e00\u79cd\u901a\u7528\u5ea6\u91cf\u624b\u6bb5\u7684\u6709\u6548\u6027\uff0c\u4ece\u800c\u4e3a\u5f39\u6027\u8ddd\u79bb\u5ea6\u91cf\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u4f7f\u5176\u8d85\u8d8a\u65f6\u95f4\u5e8f\u5217\u9886\u57df\uff0c\u53ef\u5e94\u7528\u4e8e\u66f4\u591a\u7c7b\u578b\u7684\u5e8f\u5217\u6570\u636e\u3002"}}
{"id": "2601.05474", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05474", "abs": "https://arxiv.org/abs/2601.05474", "authors": ["Pingchuan Ma", "Qixin Zhang", "Shuai Wang", "Dacheng Tao"], "title": "Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning", "comment": null, "summary": "Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.\n  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.\n  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u5fae\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5ALVGL\uff0c\u901a\u8fc7\u7a00\u758f\u548c\u4f4e\u79e9\u5206\u89e3\u5b66\u4e60\u6570\u636e\u7684\u7cbe\u5ea6\u77e9\u9635\uff0c\u5e76\u6784\u5efa\u4e00\u4e2a\u8d85\u7ea7\u7ed3\u6784\u6765\u521d\u59cb\u5316\u6807\u51c6\u7684\u53ef\u5fae\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660eALVGL\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u5ea6\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u4f18\u5316\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u53ef\u5fae\u5206\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u6216\u5b58\u5728\u6f5c\u5728\u6df7\u6dc6\u53d8\u91cf\u7684\u6570\u636e\u65f6\u9762\u4e34\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\u3001\u76ee\u6807\u51fd\u6570\u590d\u6742\u4ee5\u53ca\u56fe\u8bba\u7ea6\u675f\u975e\u5e73\u51e1\u7b49\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u59cb\u5173\u6ce8\u5229\u7528\u8d85\u7ea7\u7ed3\u6784\u6765\u6307\u5bfc\u4f18\u5316\u8fc7\u7a0b\uff0c\u4f46\u5982\u4f55\u9ad8\u6548\u5730\u5b66\u4e60\u5230\u5408\u9002\u7684\u8d85\u7ea7\u7ed3\u6784\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86ALVGL\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u91c7\u7528\u7a00\u758f\u6027\u548c\u4f4e\u79e9\u6027\u5206\u89e3\u6765\u5b66\u4e60\u6570\u636e\u7684\u7cbe\u5ea6\u77e9\u9635\uff0c\u5e76\u8bbe\u8ba1\u4e86ADMM\u7a0b\u5e8f\u6765\u4f18\u5316\u8fd9\u79cd\u5206\u89e3\uff0c\u4ee5\u8bc6\u522b\u4e0e\u5e95\u5c42\u56e0\u679c\u7ed3\u6784\u6700\u76f8\u5173\u7684\u7cbe\u5ea6\u77e9\u9635\u7ec4\u4ef6\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u968f\u540e\u88ab\u7ec4\u5408\u8d77\u6765\u6784\u9020\u4e00\u4e2a\u8d85\u7ea7\u7ed3\u6784\uff0c\u8be5\u7ed3\u6784\u662f\u771f\u5b9e\u56e0\u679c\u56fe\u7684\u4e00\u4e2a\u8d85\u96c6\u3002\u8fd9\u4e2a\u8d85\u7ea7\u7ed3\u6784\u7528\u4e8e\u521d\u59cb\u5316\u5177\u6709\u66f4\u96c6\u4e2d\u641c\u7d22\u7a7a\u95f4\u7684\u6807\u51c6\u53ef\u5fae\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u5b9e\u4f8b\u5316\u5c55\u793aALVGL\u7684\u591a\u529f\u80fd\u6027\uff0c\u5305\u62ec\u9ad8\u65af\u548c\u975e\u9ad8\u65af\u8bbe\u7f6e\uff0c\u4ee5\u53ca\u6709\u65e0\u672a\u6d4b\u91cf\u6df7\u6742\u56e0\u7d20\u7684\u60c5\u51b5\u3002\u5728\u7efc\u5408\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cALVGL\u4e0d\u4ec5\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u51c6\u786e\u5ea6\u6c34\u5e73\uff0c\u800c\u4e14\u663e\u8457\u63d0\u9ad8\u4e86\u4f18\u5316\u6548\u7387\u3002", "conclusion": "ALVGL\u4f5c\u4e3a\u53ef\u5fae\u56e0\u679c\u53d1\u73b0\u6d41\u7a0b\u7684\u4e00\u79cd\u65b0\u9896\u4e14\u901a\u7528\u7684\u589e\u5f3a\u624b\u6bb5\uff0c\u901a\u8fc7\u6709\u6548\u5b66\u4e60\u6570\u636e\u7684\u7cbe\u5ea6\u77e9\u9635\u5e76\u6784\u9020\u6709\u52a9\u4e8e\u521d\u59cb\u5316\u540e\u7eed\u56e0\u679c\u53d1\u73b0\u6b65\u9aa4\u7684\u8d85\u7ea7\u7ed3\u6784\uff0c\u8bc1\u660e\u4e86\u5176\u81ea\u8eab\u5728\u63d0\u9ad8\u4e0d\u540c\u573a\u666f\u4e0b\u4f18\u5316\u6548\u7387\u53ca\u51c6\u786e\u6027\u65b9\u9762\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.05622", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05622", "abs": "https://arxiv.org/abs/2601.05622", "authors": ["Chengjie Wang", "Jingzheng Wu", "Hao Lyu", "Xiang Ling", "Tianyue Luo", "Yanjun Wu", "Chen Zhao"], "title": "A Large Scale Empirical Analysis on the Adherence Gap between Standards and Tools in SBOM", "comment": "35 pages, 4 figures, 18 tables. Accepted by TOSEM", "summary": "A Software Bill of Materials (SBOM) is a machine-readable artifact that systematically organizes software information, enhancing supply chain transparency and security. To facilitate the exchange and utilization of SBOMs, organizations such as the Linux Foundation and OWASP have proposed SBOM standards. Following standards, organizations have developed tools for generating and utilizing SBOMs. However, limited research has examined the adherence of these SBOM tools to standard specifications, a gap that could lead to compliance failures and disruptions in SBOM utilization. This paper presents the first large-scale, two-stage empirical analysis of the adherence gap, using our automated evaluation framework, SAP. The evaluation, comprising a baseline evaluation and a one-year longitudinal follow-up, covers 55,444 SBOMs generated by six SBOM tools from 3,287 real-world repositories. Our analysis reveals persistent, fundamental limitations in current SBOM tools: (1) inadequate compliance support with policy requirements; (2) poor tool consistencies, including inter-tool consistency rates as low as 7.84% to 12.77% for package detection across languages, and significant longitudinal inconsistency, where tools show low consistency with their own prior versions; and (3) mediocre to poor accuracy for detailed software information, e.g., accuracy of package licenses below 20%. We analyze the root causes of these gaps and provide practical solutions. All the code, replication docker image, evaluation results are open sourced at [GitHub](https://github.com/dw763j/SAP) and [Zenodo](https://doi.org/10.5281/zenodo.14998624) for further researches.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u4e24\u9636\u6bb5\u5b9e\u8bc1\u5206\u6790\u4e86SBOM\u5de5\u5177\u4e0e\u6807\u51c6\u89c4\u8303\u4e4b\u95f4\u7684\u9075\u5b88\u5dee\u8ddd\uff0c\u63ed\u793a\u4e86\u5f53\u524dSBOM\u5de5\u5177\u5728\u5408\u89c4\u652f\u6301\u3001\u5de5\u5177\u4e00\u81f4\u6027\u53ca\u8f6f\u4ef6\u4fe1\u606f\u51c6\u786e\u6027\u65b9\u9762\u7684\u6839\u672c\u6027\u5c40\u9650\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7ec4\u7ec7\u63d0\u51fa\u4e86SBOM\u6807\u51c6\u5e76\u5f00\u53d1\u4e86\u76f8\u5173\u5de5\u5177\uff0c\u4f46\u5bf9\u4e8e\u8fd9\u4e9b\u5de5\u5177\u662f\u5426\u4e25\u683c\u9075\u5faa\u6807\u51c6\u89c4\u8303\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5408\u89c4\u95ee\u9898\u548cSBOM\u4f7f\u7528\u4e2d\u7684\u4e2d\u65ad\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6SAP\u8fdb\u884c\u57fa\u51c6\u8bc4\u4f30\u548c\u4e3a\u671f\u4e00\u5e74\u7684\u7eb5\u5411\u8ddf\u8e2a\u7814\u7a76\uff0c\u6db5\u76d6\u7531\u516d\u79cdSBOM\u5de5\u5177\u4ece3,287\u4e2a\u771f\u5b9e\u4e16\u754c\u5b58\u50a8\u5e93\u751f\u6210\u768455,444\u4e2aSBOM\u3002", "result": "\u53d1\u73b0\u73b0\u6709SBOM\u5de5\u5177\u5b58\u5728\u5bf9\u653f\u7b56\u8981\u6c42\u7684\u652f\u6301\u4e0d\u8db3\u3001\u5de5\u5177\u95f4\u4e00\u81f4\u6027\u4f4e\uff08\u8de8\u8bed\u8a00\u5305\u68c0\u6d4b\u7684\u4e00\u81f4\u7387\u4ec5\u4e3a7.84%\u81f312.77%\uff09\u4ee5\u53ca\u968f\u65f6\u95f4\u53d8\u5316\u7684\u4e00\u81f4\u6027\u5dee\u7b49\u95ee\u9898\uff1b\u6b64\u5916\uff0c\u5728\u8be6\u7ec6\u8f6f\u4ef6\u4fe1\u606f\u5982\u8bb8\u53ef\u8bc1\u51c6\u786e\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff08\u4f4e\u4e8e20%\uff09\u3002", "conclusion": "\u6307\u51fa\u4e86\u5bfc\u81f4\u8fd9\u4e9b\u95ee\u9898\u7684\u6839\u672c\u539f\u56e0\uff0c\u5e76\u4e3a\u6539\u8fdb\u73b0\u72b6\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002\u6240\u6709\u4ee3\u7801\u3001\u590d\u5236docker\u955c\u50cf\u53ca\u8bc4\u4f30\u7ed3\u679c\u5df2\u5f00\u6e90\u53d1\u5e03\u4e8eGitHub\u548cZenodo\u5e73\u53f0\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.05264", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05264", "abs": "https://arxiv.org/abs/2601.05264", "authors": ["Dean Wampler", "Dave Nielson", "Alireza Seddighi"], "title": "Engineering the RAG Stack: A Comprehensive Review of the Architecture and Trust Frameworks for Retrieval-Augmented Generation Systems", "comment": "86 pages, 2 figures, 37 tables. A comprehensive review of Retrieval-Augmented Generation (RAG) architectures and trust frameworks (2018-2025), encompassing a unified taxonomy, evaluation benchmarks, and trust-safety modeling", "summary": "This article provides a comprehensive systematic literature review of academic studies, industrial applications, and real-world deployments from 2018 to 2025, providing a practical guide and detailed overview of modern Retrieval-Augmented Generation (RAG) architectures. RAG offers a modular approach for integrating external knowledge without increasing the capacity of the model as LLM systems expand. Research and engineering practices have been fragmented as a result of the increasing diversity of RAG methodologies, which encompasses a variety of fusion mechanisms, retrieval strategies, and orchestration approaches. We provide quantitative assessment frameworks, analyze the implications for trust and alignment, and systematically consolidate existing RAG techniques into a unified taxonomy. This document is a practical framework for the deployment of resilient, secure, and domain-adaptable RAG systems, synthesizing insights from academic literature, industry reports, and technical implementation guides. It also functions as a technical reference.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u67b6\u6784\u7684\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6db5\u76d6\u4e86\u4ece2018\u5e74\u81f32025\u5e74\u7684\u5b66\u672f\u7814\u7a76\u3001\u5de5\u4e1a\u5e94\u7528\u53ca\u5b9e\u9645\u90e8\u7f72\u60c5\u51b5\u3002\u6587\u7ae0\u5bf9\u73b0\u6709RAG\u6280\u672f\u8fdb\u884c\u4e86\u5206\u7c7b\u6574\u7406\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9a\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba8\u8bba\u4e86\u4fe1\u4efb\u4e0e\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u65e8\u5728\u4e3a\u6784\u5efa\u9002\u5e94\u6027\u5f3a\u3001\u5b89\u5168\u4e14\u53ef\u5b9a\u5236\u9886\u57df\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u548c\u6280\u672f\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u6269\u5c55\uff0c\u5982\u4f55\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\u7684\u60c5\u51b5\u4e0b\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6210\u4e3a\u4e00\u4e2a\u6311\u6218\u3002\u540c\u65f6\uff0c\u7531\u4e8eRAG\u65b9\u6cd5\u591a\u6837\u6027\u5bfc\u81f4\u7684\u7814\u7a76\u548c\u5de5\u7a0b\u5b9e\u8df5\u788e\u7247\u5316\u73b0\u8c61\u65e5\u76ca\u4e25\u91cd\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u6574\u5408\u73b0\u6709\u7684RAG\u6280\u672f\u5e76\u6307\u5bfc\u5176\u672a\u6765\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u7efc\u5408\u5206\u67902018\u5e74\u81f32025\u5e74\u95f4\u5173\u4e8eRAG\u7684\u5b66\u672f\u8bba\u6587\u3001\u884c\u4e1a\u62a5\u544a\u548c\u6280\u672f\u5b9e\u73b0\u6307\u5357\uff0c\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u5957\u5b9a\u91cf\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5e76\u57fa\u4e8e\u6b64\u5c06\u4e0d\u540cRAG\u6280\u672f\u5f52\u7c7b\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u7c7b\u4f53\u7cfb\u4e2d\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u6280\u672f\u5bf9\u4e8e\u5efa\u7acb\u53ef\u4fe1\u5ea6\u9ad8\u3001\u9886\u57df\u9002\u5e94\u6027\u5f3a\u7684RAG\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002", "result": "\u6210\u529f\u5730\u4e3aRAG\u6280\u672f\u521b\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5206\u7c7b\u5b66\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5b9a\u91cf\u8bc4\u4ef7\u6307\u6807\u6765\u5e2e\u52a9\u7406\u89e3\u5404\u79cdRAG\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1RAG\u89e3\u51b3\u65b9\u6848\u65f6\u8003\u8651\u5b89\u5168\u6027\u548c\u9886\u57df\u9002\u5e94\u6027\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u672c\u6587\u4e0d\u4ec5\u4e3a\u7406\u89e3\u548c\u8bc4\u4f30\u5f53\u524d\u7684RAG\u6280\u672f\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\uff0c\u800c\u4e14\u4e5f\u4e3a\u672a\u6765\u8be5\u9886\u57df\u5185\u65b0\u65b9\u6cd5\u7684\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002\u5b83\u4f5c\u4e3a\u4e00\u4efd\u5b9e\u7528\u6307\u5357\u548c\u6280\u672f\u53c2\u8003\u624b\u518c\uff0c\u652f\u6301\u7740\u66f4\u52a0\u5065\u58ee\u3001\u5b89\u5168\u4ee5\u53ca\u80fd\u591f\u9002\u5e94\u7279\u5b9a\u5e94\u7528\u573a\u666f\u9700\u6c42\u7684RAG\u7cfb\u7edf\u7684\u8bbe\u8ba1\u4e0e\u5b9e\u65bd\u3002"}}
{"id": "2601.05475", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05475", "abs": "https://arxiv.org/abs/2601.05475", "authors": ["Jiefu Ou", "Sapana Chaudhary", "Kaj Bostrom", "Nathaniel Weir", "Shuai Zhang", "Huzefa Rangwala", "George Karypis"], "title": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization", "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMaxCode\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6267\u884c\u53cd\u9988\u57fa\u7840\u4e0a\u7684\u8fed\u4ee3\u6539\u8fdb\u6765\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u73b0\u66f4\u4f18\u7684\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u81ea\u7136\u8bed\u8a00\u6279\u8bc4\u6a21\u578b\u4ee5\u589e\u5f3a\u89c2\u5bdf\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u6765\u6539\u8fdb\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0cMaxCode\u5728\u7edd\u5bf9\u52a0\u901f\u503c\u548c\u76f8\u5bf9\u52a0\u901f\u6392\u540d\u4e0a\u5206\u522b\u63d0\u9ad8\u4e8620.3%\u548c10.1%\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u7f16\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u4f18\u5316\u4ee3\u7801\u65f6\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u4e00\u662f\u7f16\u5199\u9ad8\u6548\u4ee3\u7801\uff08\u5982\u9ad8\u6027\u80fdCUDA\u5185\u6838\u548c\u7ade\u8d5b\u7ea7CPU\u4ee3\u7801\uff09\u9700\u8981\u7cfb\u7edf\u3001\u7b97\u6cd5\u53ca\u7279\u5b9a\u8bed\u8a00\u65b9\u9762\u7684\u4e13\u4e1a\u77e5\u8bc6\uff1b\u4e8c\u662f\u9664\u4e86\u4e8c\u8fdb\u5236\u6b63\u786e\u6027\u5916\uff0c\u8fd8\u9700\u8981\u7406\u89e3\u8bf8\u5982\u65f6\u95f4\u6027\u80fd\u548c\u8bbe\u5907\u5229\u7528\u7387\u7b49\u5ea6\u91cf\u6307\u6807\u3002", "method": "\u63d0\u51fa\u4e86MaxCode\u65b9\u6cd5\uff0c\u5b83\u57fa\u4e8e\u6700\u5927\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7edf\u4e00\u4e86\u73b0\u6709\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u5e76\u4f7f\u89c2\u5bdf\u51fd\u6570\u548c\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\u53d8\u5f97\u6a21\u5757\u5316\u6613\u4e8e\u4fee\u6539\u3002\u4e3a\u4e86\u589e\u52a0\u89c2\u5bdf\u7a7a\u95f4\u7684\u4fe1\u606f\u91cf\uff0c\u96c6\u6210\u4e86\u4e00\u4e2a\u81ea\u7136\u8bed\u8a00\u6279\u8bc4\u6a21\u578b\uff0c\u53ef\u4ee5\u5c06\u539f\u59cb\u6267\u884c\u53cd\u9988\u8f6c\u5316\u4e3a\u5173\u4e8e\u9519\u8bef\u548c\u6027\u80fd\u74f6\u9888\u7684\u8bca\u65ad\u89c1\u89e3\u3002\u6b64\u5916\uff0c\u8fd8\u8bad\u7ec3\u4e86\u4e00\u4e2a\u751f\u6210\u5f0f\u7684\u5269\u4f59\u5956\u52b1\u6a21\u578b\uff0c\u5229\u7528\u56de\u653e\u4e2d\u7684\u52a8\u4f5c\u503c\u5bf9\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\uff0c\u4ee5\u6b64\u6539\u5584\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22\u6548\u7387\u3002", "result": "\u5728KernelBench (CUDA) \u548c PIE (C++) \u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u8f83\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0cMaxCode \u5728\u7edd\u5bf9\u52a0\u901f\u503c\u548c\u76f8\u5bf9\u52a0\u901f\u6392\u540d\u65b9\u9762\u5206\u522b\u5b9e\u73b0\u4e86 20.3% \u548c 10.1% \u7684\u63d0\u5347\u3002", "conclusion": "MaxCode \u65b9\u6cd5\u6210\u529f\u5730\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u4f18\u5316\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u4e00\u4e9b\u96be\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u6279\u8bc4\u6a21\u578b\u548c\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u6027\u80fd\u3002"}}
{"id": "2601.05663", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05663", "abs": "https://arxiv.org/abs/2601.05663", "authors": ["Gianmario Voria", "Moses Openja", "Foutse Khomh", "Gemma Catolino", "Fabio Palomba"], "title": "Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models", "comment": null, "summary": "The advent of transformer-based language models has reshaped how AI systems process and generate text. In software engineering (SE), these models now support diverse activities, accelerating automation and decision-making. Yet, evidence shows that these models can reproduce or amplify social biases, raising fairness concerns. Recent work on neuron editing has shown that internal activations in pre-trained transformers can be traced and modified to alter model behavior. Building on the concept of knowledge neurons, neurons that encode factual information, we hypothesize the existence of biased neurons that capture stereotypical associations within pre-trained transformers. To test this hypothesis, we build a dataset of biased relations, i.e., triplets encoding stereotypes across nine bias types, and adapt neuron attribution strategies to trace and suppress biased neurons in BERT models. We then assess the impact of suppression on SE tasks. Our findings show that biased knowledge is localized within small neuron subsets, and suppressing them substantially reduces bias with minimal performance loss. This demonstrates that bias in transformers can be traced and mitigated at the neuron level, offering an interpretable approach to fairness in SE.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u6f5c\u5728\u7684\u504f\u89c1\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u4e5d\u79cd\u504f\u89c1\u7c7b\u578b\u7684\u6709\u504f\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u5e76\u8c03\u6574\u795e\u7ecf\u5143\u5f52\u5c5e\u7b56\u7565\u6765\u8ffd\u8e2a\u548c\u6291\u5236BERT\u6a21\u578b\u4e2d\u7684\u6709\u504f\u795e\u7ecf\u5143\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6709\u504f\u77e5\u8bc6\u5c40\u9650\u4e8e\u5c11\u91cf\u795e\u7ecf\u5143\u5b50\u96c6\u4e2d\uff0c\u6291\u5236\u8fd9\u4e9b\u795e\u7ecf\u5143\u80fd\u591f\u5728\u6700\u5c0f\u5316\u6027\u80fd\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u5927\u5e45\u51cf\u5c11\u504f\u89c1\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u516c\u5e73\u6027\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u91cd\u5851\u4e86AI\u7cfb\u7edf\u5904\u7406\u548c\u751f\u6210\u6587\u672c\u7684\u65b9\u5f0f\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u8fd9\u4e9b\u6a21\u578b\u652f\u6301\u7740\u5404\u79cd\u6d3b\u52a8\u5e76\u52a0\u901f\u81ea\u52a8\u5316\u4e0e\u51b3\u7b56\u8fc7\u7a0b\u3002\u7136\u800c\uff0c\u8bc1\u636e\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u53ef\u80fd\u4f1a\u590d\u5236\u6216\u653e\u5927\u793e\u4f1a\u504f\u89c1\uff0c\u5f15\u53d1\u516c\u5e73\u6027\u62c5\u5fe7\u3002\u53d7\u8fd1\u671f\u5173\u4e8e\u795e\u7ecf\u5143\u7f16\u8f91\u5de5\u4f5c\u7684\u542f\u53d1\uff0c\u672c\u7814\u7a76\u5047\u8bbe\u5b58\u5728\u6355\u6349\u9884\u8bad\u7ec3Transformer\u5185\u523b\u677f\u5370\u8c61\u5173\u8054\u7684\u6709\u504f\u795e\u7ecf\u5143\u3002", "method": "\u9996\u5148\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u5305\u542b\u4e5d\u79cd\u504f\u89c1\u7c7b\u578b\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7f16\u7801\u523b\u677f\u5370\u8c61\u7684\u4e09\u5143\u7ec4\u3002\u63a5\u7740\uff0c\u8c03\u6574\u795e\u7ecf\u5143\u5f52\u56e0\u7b56\u7565\u4ee5\u8ffd\u8e2a\u5e76\u5728BERT\u6a21\u578b\u4e2d\u6291\u5236\u6709\u504f\u795e\u7ecf\u5143\u3002\u6700\u540e\uff0c\u8bc4\u4f30\u4e86\u6291\u5236\u64cd\u4f5c\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6709\u504f\u77e5\u8bc6\u96c6\u4e2d\u5728\u4e00\u5c0f\u90e8\u5206\u795e\u7ecf\u5143\u5b50\u96c6\u4e2d\uff0c\u800c\u6291\u5236\u8fd9\u4e9b\u7279\u5b9a\u795e\u7ecf\u5143\u80fd\u591f\u663e\u8457\u964d\u4f4e\u504f\u89c1\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u6574\u4f53\u6027\u80fd\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u7279\u5b9a\u795e\u7ecf\u5143\u8fdb\u884c\u5e72\u9884\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u6709\u6548\u51cf\u8f7b\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u504f\u89c1\u95ee\u9898\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5185\u7684\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2601.05265", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05265", "abs": "https://arxiv.org/abs/2601.05265", "authors": ["Mile Stankovic"], "title": "Cross-Document Topic-Aligned Chunking for Retrieval-Augmented Generation", "comment": null, "summary": "Chunking quality determines RAG system performance. Current methods partition documents individually, but complex queries need information scattered across multiple sources: the knowledge fragmentation problem. We introduce Cross-Document Topic-Aligned (CDTA) chunking, which reconstructs knowledge at the corpus level. It first identifies topics across documents, maps segments to each topic, and synthesizes them into unified chunks.\n  On HotpotQA multi-hop reasoning, our method reached 0.93 faithfulness versus 0.83 for contextual retrieval and 0.78 for semantic chunking, a 12% improvement over current industry best practice (p < 0.05). On UAE Legal texts, it reached 0.94 faithfulness with 0.93 citation accuracy. At k = 3, it maintains 0.91 faithfulness while semantic methods drop to 0.68, with a single CDTA chunk containing information requiring multiple traditional fragments.\n  Indexing costs are higher, but synthesis produces information-dense chunks that reduce query-time retrieval needs. For high-query-volume applications with distributed knowledge, cross-document synthesis improves measurably over within-document optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6587\u6863\u4e3b\u9898\u5bf9\u9f50(CDTA)\u5207\u5757\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u77e5\u8bc6\u788e\u7247\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5728HotpotQA\u548cUAE\u6cd5\u5f8b\u6587\u672c\u4e0a\uff0cCDTA\u5728\u5fe0\u5b9e\u5ea6\u548c\u5f15\u7528\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u7d22\u5f15\u6210\u672c\u8f83\u9ad8\uff0c\u4f46\u5bf9\u4e8e\u9ad8\u67e5\u8be2\u91cf\u5e94\u7528\u6765\u8bf4\uff0c\u4fe1\u606f\u5bc6\u96c6\u7684\u5207\u5757\u51cf\u5c11\u4e86\u67e5\u8be2\u65f6\u7684\u68c0\u7d22\u9700\u6c42\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u6cd5\u5355\u72ec\u5206\u5272\u6587\u6863\uff0c\u4f46\u590d\u6742\u7684\u67e5\u8be2\u9700\u8981\u4ece\u591a\u4e2a\u6765\u6e90\u83b7\u53d6\u4fe1\u606f\uff0c\u8fd9\u5bfc\u81f4\u4e86\u77e5\u8bc6\u788e\u7247\u5316\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u8de8\u6587\u6863\u4e3b\u9898\u5bf9\u9f50(CDTA)\u5207\u5757\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u8bc6\u522b\u8de8\u6587\u6863\u7684\u4e3b\u9898\uff0c\u7136\u540e\u5c06\u6bb5\u843d\u6620\u5c04\u5230\u6bcf\u4e2a\u4e3b\u9898\u4e0b\uff0c\u6700\u540e\u5c06\u5b83\u4eec\u7efc\u5408\u6210\u7edf\u4e00\u7684\u5207\u5757\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5728\u8bed\u6599\u5e93\u7ea7\u522b\u4e0a\u91cd\u5efa\u4e86\u77e5\u8bc6\u3002", "result": "\u5728HotpotQA\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u4e0e\u4e0a\u4e0b\u6587\u68c0\u7d22(0.83)\u548c\u8bed\u4e49\u5207\u5757(0.78)\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e860.93\u7684\u5fe0\u5b9e\u5ea6\uff1b\u5728UAE\u6cd5\u5f8b\u6587\u672c\u4e0a\uff0c\u8fbe\u5230\u4e860.94\u7684\u5fe0\u5b9e\u5ea6\u4ee5\u53ca0.93\u7684\u5f15\u7528\u51c6\u786e\u6027\u3002\u5373\u4f7fk=3\u65f6\uff0c\u5176\u5fe0\u5b9e\u5ea6\u4ecd\u4fdd\u6301\u57280.91\uff0c\u800c\u8bed\u4e49\u65b9\u6cd5\u964d\u81f30.68\u3002", "conclusion": "\u867d\u7136CDTA\u65b9\u6cd5\u7684\u7d22\u5f15\u6210\u672c\u66f4\u9ad8\uff0c\u4f46\u5b83\u751f\u6210\u7684\u4fe1\u606f\u5bc6\u96c6\u578b\u5207\u5757\u80fd\u591f\u51cf\u5c11\u67e5\u8be2\u65f6\u95f4\u7684\u68c0\u7d22\u9700\u6c42\uff0c\u5bf9\u4e8e\u5177\u6709\u5206\u5e03\u5f0f\u77e5\u8bc6\u7684\u9ad8\u67e5\u8be2\u91cf\u5e94\u7528\u573a\u666f\u800c\u8a00\uff0c\u8de8\u6587\u6863\u5408\u6210\u76f8\u8f83\u4e8e\u5355\u6587\u6863\u4f18\u5316\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2601.05501", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05501", "abs": "https://arxiv.org/abs/2601.05501", "authors": ["Feihu Jin", "Ying Tan"], "title": "Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection", "comment": "13 pages, 4 figures", "summary": "Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \\textbf{Hi-ZFO} (\\textbf{Hi}erarchical \\textbf{Z}eroth- and \\textbf{F}irst-\\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of \"beneficial stochasticity\" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHi-ZFO\u7684\u6df7\u5408\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u96f6\u9636\u65b9\u6cd5\u7684\u63a2\u7d22\u80fd\u529b\u548c\u4e00\u9636\u65b9\u6cd5\u7684\u7cbe\u786e\u5ea6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5bf9\u6a21\u578b\u8fdb\u884c\u5206\u5c42\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u548c\u66f4\u77ed\u7684\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edf\u7684\u7ec6\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5b58\u5728\u4e00\u4e9b\u95ee\u9898\uff1a\u4e00\u9636\uff08FO\uff09\u4f18\u5316\u901a\u5e38\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u8d8b\u5411\u4e8e\u5c16\u9510\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u6781\u5c0f\u503c\uff1b\u800c\u96f6\u9636\uff08ZO\uff09\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u63a2\u7d22\u884c\u4e3a\uff0c\u4f46\u6536\u655b\u901f\u5ea6\u8f83\u6162\uff0c\u5e76\u4e14\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u7531\u4e8e\u8f93\u51fa\u7a7a\u95f4\u548c\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\uff0c\u5bfc\u81f4\u4f30\u8ba1\u65b9\u5dee\u663e\u8457\u589e\u52a0\uff0c\u4f7f\u5f97ZO\u65b9\u6cd5\u65e2\u5608\u6742\u53c8\u4f4e\u6548\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\u3002", "method": "Hi-ZFO\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u96f6\u9636\u4e0e\u4e00\u9636\u4f18\u5316\u6280\u672f\u7684\u5c42\u6b21\u5316\u6df7\u5408\u4f18\u5316\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5c42\u7684\u91cd\u8981\u6027\u5206\u6790\u6765\u81ea\u9002\u5e94\u5730\u5212\u5206\u6a21\u578b\uff0c\u5bf9\u4e8e\u5173\u952e\u5c42\u4f7f\u7528\u7cbe\u786e\u7684\u4e00\u9636\u66f4\u65b0\uff0c\u800c\u5bf9\u4e8e\u4e0d\u592a\u654f\u611f\u7684\u5c42\u5219\u5229\u7528\u96f6\u9636\u4f18\u5316\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728Hi-ZFO\u4e2d\u5f15\u5165\u96f6\u9636\u4f18\u5316\u4e0d\u4ec5\u4ec5\u662f\u4e3a\u4e86\u8282\u7701\u5185\u5b58\uff0c\u800c\u662f\u4f5c\u4e3a\u4e00\u79cd\u6709\u76ca\u968f\u673a\u6027\u7684\u6765\u6e90\uff0c\u5e2e\u52a9\u6a21\u578b\u9003\u79bb\u7eaf\u4e00\u9636\u4f18\u5316\u5bb9\u6613\u505c\u6ede\u7684\u5730\u65b9\u6027\u6700\u5c0f\u503c\u3002", "result": "\u901a\u8fc7\u5728\u5404\u79cd\u751f\u6210\u3001\u6570\u5b66\u4ee5\u53ca\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u9a8c\u8bc1\uff0cHi-ZFO\u4e0d\u4ec5\u6301\u7eed\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4e5f\u5927\u5e45\u51cf\u5c11\u4e86\u8bad\u7ec3\u6240\u9700\u7684\u65f6\u95f4\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u5c42\u6b21\u5316\u7684\u6df7\u5408\u4f18\u5316\u7b56\u7565\u5bf9\u4e8e\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.05685", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05685", "abs": "https://arxiv.org/abs/2601.05685", "authors": ["Mingfei Cheng", "Lionel Briand", "Yuan Zhou"], "title": "Drivora: A Unified and Extensible Infrastructure for Search-based Autonomous Driving Testing", "comment": null, "summary": "Search-based testing is critical for evaluating the safety and reliability of autonomous driving systems (ADSs). However, existing approaches are often built on heterogeneous frameworks (e.g., distinct scenario spaces, simulators, and ADSs), which require considerable effort to reuse and adapt across different settings. To address these challenges, we present Drivora, a unified and extensible infrastructure for search-based ADS testing built on the widely used CARLA simulator. Drivora introduces a unified scenario definition, OpenScenario, that specifies scenarios using low-level, actionable parameters to ensure compatibility with existing methods while supporting extensibility to new testing designs (e.g., multi-autonomous-vehicle testing). On top of this, Drivora decouples the testing engine, scenario execution, and ADS integration. The testing engine leverages evolutionary computation to explore new scenarios and supports flexible customization of core components. The scenario execution can run arbitrary scenarios using a parallel execution mechanism that maximizes hardware utilization for large-scale batch simulation. For ADS integration, Drivora provides access to 12 ADSs through a unified interface, streamlining configuration and simplifying the incorporation of new ADSs. Our tools are publicly available at https://github.com/MingfeiCheng/Drivora.", "AI": {"tldr": "Drivora, a unified and extensible testing infrastructure for autonomous driving systems (ADSs) built on CARLA, introduces a standardized scenario definition, decouples the testing engine, scenario execution, and ADS integration, and supports 12 ADSs through a unified interface.", "motivation": "\u9274\u4e8e\u73b0\u6709\u57fa\u4e8e\u641c\u7d22\u7684\u6d4b\u8bd5\u65b9\u6cd5\u5728\u4e0d\u540c\u6846\u67b6\uff08\u5982\u4e0d\u540c\u7684\u573a\u666f\u7a7a\u95f4\u3001\u6a21\u62df\u5668\u548c\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff09\u95f4\u91cd\u7528\u4e0e\u9002\u5e94\u65f6\u9700\u8981\u5927\u91cf\u5de5\u4f5c\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u8bbe\u65bd\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Drivora\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684CARLA\u6a21\u62df\u5668\u6784\u5efa\u7684\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684ADS\u6d4b\u8bd5\u57fa\u7840\u8bbe\u65bd\u3002\u5b83\u5f15\u5165\u4e86\u4f7f\u7528\u4f4e\u7ea7\u53ef\u6267\u884c\u53c2\u6570\u6307\u5b9a\u573a\u666f\u7684\u7edf\u4e00\u573a\u666f\u5b9a\u4e49OpenScenario\uff0c\u89e3\u8026\u4e86\u6d4b\u8bd5\u5f15\u64ce\u3001\u573a\u666f\u6267\u884c\u4ee5\u53caADS\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u8fdb\u5316\u8ba1\u7b97\u63a2\u7d22\u65b0\u573a\u666f\u3002", "result": "Drivora\u80fd\u591f\u652f\u6301\u7075\u6d3b\u5b9a\u5236\u6838\u5fc3\u7ec4\u4ef6\uff0c\u5229\u7528\u5e76\u884c\u6267\u884c\u673a\u5236\u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387\u4ee5\u8fdb\u884c\u5927\u89c4\u6a21\u6279\u91cf\u4eff\u771f\uff0c\u5e76\u901a\u8fc7\u7edf\u4e00\u63a5\u53e3\u63d0\u4f9b\u5bf912\u4e2aADS\u7684\u652f\u6301\uff0c\u4ece\u800c\u7b80\u5316\u914d\u7f6e\u548c\u65b0ADS\u7684\u6574\u5408\u3002", "conclusion": "Drivora\u4e3a\u57fa\u4e8e\u641c\u7d22\u7684ADS\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u6613\u4e8e\u6269\u5c55\u7684\u57fa\u7840\u67b6\u6784\uff0c\u4fc3\u8fdb\u4e86\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u91cd\u7528\u6027\u548c\u9002\u5e94\u6027\uff0c\u540c\u65f6\u652f\u6301\u65b0\u7684\u6d4b\u8bd5\u8bbe\u8ba1\u3002"}}
{"id": "2601.05266", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05266", "abs": "https://arxiv.org/abs/2601.05266", "authors": ["Muzakkiruddin Ahmed Mohammed", "John R. Talburt", "Leon Claasssens", "Adriaan Marais"], "title": "Retrieval-Augmented Multi-LLM Ensemble for Industrial Part Specification Extraction", "comment": "The 17th International Conference on Knowledge and Systems Engineering", "summary": "Industrial part specification extraction from unstructured text remains a persistent challenge in manufacturing, procurement, and maintenance, where manual processing is both time-consuming and error-prone. This paper introduces a retrieval-augmented multi-LLM ensemble framework that orchestrates nine state-of-the-art Large Language Models (LLMs) within a structured three-phase pipeline. RAGsemble addresses key limitations of single-model systems by combining the complementary strengths of model families including Gemini (2.0, 2.5, 1.5), OpenAI (GPT-4o, o4-mini), Mistral Large, and Gemma (1B, 4B, 3n-e4b), while grounding outputs in factual data using FAISS-based semantic retrieval. The system architecture consists of three stages: (1) parallel extraction by diverse LLMs, (2) targeted research augmentation leveraging high-performing models, and (3) intelligent synthesis with conflict resolution and confidence-aware scoring. RAG integration provides real-time access to structured part databases, enabling the system to validate, refine, and enrich outputs through similarity-based reference retrieval. Experimental results using real industrial datasets demonstrate significant gains in extraction accuracy, technical completeness, and structured output quality compared to leading single-LLM baselines. Key contributions include a scalable ensemble architecture for industrial domains, seamless RAG integration throughout the pipeline, comprehensive quality assessment mechanisms, and a production-ready solution suitable for deployment in knowledge-intensive manufacturing environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAGsemble\u7684\u591a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u6846\u67b6\uff0c\u65e8\u5728\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u5de5\u4e1a\u90e8\u4ef6\u89c4\u683c\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4e5d\u79cd\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u7ed3\u5408FAISS\u57fa\u4e8e\u8bed\u4e49\u68c0\u7d22\u6765\u63d0\u9ad8\u8f93\u51fa\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u9886\u5148\u7684\u5355\u4e00\u6a21\u578b\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u53d6\u7cbe\u5ea6\u3001\u6280\u672f\u5b8c\u6574\u6027\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u8d28\u91cf\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5de5\u4e1a\u90e8\u4ef6\u89c4\u683c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u7684\u62bd\u53d6\u4ecd\u7136\u662f\u5236\u9020\u3001\u91c7\u8d2d\u548c\u7ef4\u62a4\u9886\u57df\u7684\u4e00\u4e2a\u6301\u7eed\u6311\u6218\uff0c\u624b\u52a8\u5904\u7406\u65e2\u8017\u65f6\u53c8\u5bb9\u6613\u51fa\u9519\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u4ee5\u53ca\u5355\u4e00\u6a21\u578b\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u672c\u7814\u7a76\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e86RAGsemble\u6846\u67b6\uff0c\u5b83\u662f\u4e00\u4e2a\u4e09\u9636\u6bb5\u7ba1\u9053\u7ed3\u6784\uff0c\u96c6\u6210\u4e86Gemini\u3001OpenAI\u3001Mistral Large\u548cGemma\u7b49\u5bb6\u65cf\u7684\u4e5d\u4e2a\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u6b64\u6846\u67b6\u5229\u7528FAISS\u8fdb\u884c\u57fa\u4e8e\u8bed\u4e49\u7684\u68c0\u7d22\u4ee5\u589e\u5f3a\u4e8b\u5b9e\u6570\u636e\u652f\u6301\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u6b65\u9aa4\u6267\u884c\uff1a\uff081\uff09\u7531\u4e0d\u540cLLM\u5e76\u884c\u63d0\u53d6\uff1b\uff082\uff09\u5229\u7528\u9ad8\u6027\u80fd\u6a21\u578b\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u7814\u7a76\u589e\u5f3a\uff1b\uff083\uff09\u667a\u80fd\u5408\u6210\u5177\u6709\u51b2\u7a81\u89e3\u51b3\u548c\u7f6e\u4fe1\u5ea6\u611f\u77e5\u8bc4\u5206\u7684\u7ed3\u679c\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u5de5\u4e1a\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u63d0\u53d6\u51c6\u786e\u6027\u3001\u6280\u672f\u5b8c\u5907\u6027\u548c\u7ed3\u6784\u5316\u8f93\u51fa\u8d28\u91cf\u4e0a\uff0cRAGsemble\u76f8\u5bf9\u4e8e\u9886\u5148\u7684\u5355\u4e00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5de5\u4e1a\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u96c6\u6210\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u6574\u4e2a\u6d41\u7a0b\u4e2d\u65e0\u7f1d\u7684RAG\u96c6\u6210\uff0c\u5efa\u7acb\u4e86\u5168\u9762\u7684\u8d28\u91cf\u8bc4\u4f30\u673a\u5236\uff0c\u5e76\u51c6\u5907\u5c31\u7eea\u53ef\u7528\u4e8e\u77e5\u8bc6\u5bc6\u96c6\u578b\u5236\u9020\u4e1a\u73af\u5883\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05503", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05503", "abs": "https://arxiv.org/abs/2601.05503", "authors": ["Roy Xie", "Deepak Gopinath", "David Qiu", "Dong Lin", "Haitian Sun", "Saloni Potdar", "Bhuwan Dhingra"], "title": "Over-Searching in Search-Augmented Large Language Models", "comment": "Accepted to EACL 2026 Main Conference", "summary": "Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u641c\u7d22\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u641c\u7d22\u95ee\u9898\uff0c\u6307\u51fa\u4e86\u5176\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u2014\u2014Tokens Per Correctness (TPC)\uff0c\u65e8\u5728\u8861\u91cf\u6027\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u53d1\u5e03\u4e86OverSearchQA\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u7684\u641c\u7d22\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u641c\u7d22\u7684\u95ee\u9898\uff0c\u5373\u4e0d\u5fc5\u8981\u5730\u8c03\u7528\u641c\u7d22\u5de5\u5177\uff0c\u4e0d\u4ec5\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u8fd8\u4f1a\u56e0\u5f15\u5165\u65e0\u5173\u4e0a\u4e0b\u6587\u800c\u4ea7\u751f\u9519\u8bef\u4fe1\u606f\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u9700\u8981\u5bf9\u8fc7\u5ea6\u641c\u7d22\u73b0\u8c61\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u5e76\u63a2\u7d22\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u4ece\u67e5\u8be2\u7c7b\u578b\u3001\u6a21\u578b\u7c7b\u522b\u3001\u68c0\u7d22\u6761\u4ef6\u4ee5\u53ca\u591a\u8f6e\u5bf9\u8bdd\u7b49\u591a\u4e2a\u7ef4\u5ea6\u51fa\u53d1\uff0c\u8bc4\u4ef7\u4e86\u641c\u7d22\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8fc7\u5ea6\u641c\u7d22\u7684\u73b0\u8c61\u3002\u5b9a\u4e49\u4e86\u65b0\u5ea6\u91cf\u6807\u51c6Tokens Per Correctness (TPC)\u6765\u91cf\u5316\u641c\u7d22\u64cd\u4f5c\u7684\u6210\u672c\u6548\u76ca\u6bd4\u3002\u540c\u65f6\uff0c\u5728\u67e5\u8be2\u548c\u68c0\u7d22\u4e24\u4e2a\u5c42\u9762\u63a2\u7d22\u4e86\u51cf\u8f7b\u8fc7\u5ea6\u641c\u7d22\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u53ef\u56de\u7b54\u7684\u95ee\u9898\uff0c\u641c\u7d22\u901a\u5e38\u80fd\u63d0\u9ad8\u7b54\u6848\u51c6\u786e\u6027\uff0c\u4f46\u5bf9\u4e8e\u65e0\u6cd5\u56de\u7b54\u7684\u95ee\u9898\uff0c\u5219\u4f1a\u964d\u4f4e\u62d2\u7edd\u4f5c\u7b54\u7684\u80fd\u529b\uff1b\u590d\u6742\u63a8\u7406\u6a21\u578b\u548c\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4e2d\u7684\u8fc7\u5ea6\u641c\u7d22\u60c5\u51b5\u66f4\u4e3a\u4e25\u91cd\uff0c\u4e14\u5bb9\u6613\u53d7\u5230\u566a\u97f3\u68c0\u7d22\u7684\u5f71\u54cd\uff0c\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u8fd9\u79cd\u6548\u5e94\u8fd8\u4f1a\u7d2f\u79ef\uff1b\u8bc1\u636e\u7ec4\u5408\u975e\u5e38\u5173\u952e\uff0c\u8d1f\u9762\u8bc1\u636e\u7684\u5b58\u5728\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u6b63\u786e\u62d2\u7edd\u4f5c\u7b54\u7684\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u641c\u7d22\u589e\u5f3a\u578b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8fc7\u5ea6\u641c\u7d22\u7684\u5177\u4f53\u8868\u73b0\u5f62\u5f0f\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5TPC\u6765\u5e2e\u52a9\u7406\u89e3\u641c\u7d22\u5e26\u6765\u7684\u6027\u80fd\u589e\u76ca\u4e0e\u989d\u5916\u5f00\u9500\u4e4b\u95f4\u7684\u5e73\u8861\u70b9\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u521d\u6b65\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6OverSearchQA\u4ee5\u652f\u6301\u672a\u6765\u7684\u7814\u7a76\u5de5\u4f5c\u3002"}}
{"id": "2601.05703", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05703", "abs": "https://arxiv.org/abs/2601.05703", "authors": ["Wiebe Vandendriessche", "Jordi Thijsman", "Laurens D'hooge", "Bruno Volckaert", "Merlijn Sebrechts"], "title": "AIBoMGen: Generating an AI Bill of Materials for Secure, Transparent, and Compliant Model Training", "comment": "Accepted at ACM/IEEE CAIN 2026", "summary": "The rapid adoption of complex AI systems has outpaced the development of tools to ensure their transparency, security, and regulatory compliance. In this paper, the AI Bill of Materials (AIBOM), an extension of the Software Bill of Materials (SBOM), is introduced as a standardized, verifiable record of trained AI models and their environments. Our proof-of-concept platform, AIBoMGen, automates the generation of signed AIBOMs by capturing datasets, model metadata, and environment details during training. The training platform acts as a neutral, third-party observer and root of trust. It enforces verifiable AIBOM creation for every job. The system uses cryptographic hashing, digital signatures, and in-toto attestations to ensure integrity and protect against threats such as artifact tampering by dishonest model creators. Our evaluation demonstrates that AIBoMGen reliably detects unauthorized modifications to all artifacts and can generate AIBOMs with negligible performance overhead. These results highlight the potential of AIBoMGen as a foundational step toward building secure and transparent AI ecosystems, enabling compliance with regulatory frameworks like the EUs AI Act.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAI Bill of Materials (AIBOM)\u7684\u5de5\u5177\uff0c\u4f5c\u4e3a\u8bad\u7ec3\u8fc7\u7684AI\u6a21\u578b\u53ca\u5176\u73af\u5883\u7684\u6807\u51c6\u5316\u3001\u53ef\u9a8c\u8bc1\u8bb0\u5f55\u3002\u901a\u8fc7\u81ea\u52a8\u5316\u5e73\u53f0AIBoMGen\u751f\u6210\u7b7e\u540d\u7684AIBOMs\uff0c\u8be5\u5e73\u53f0\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6355\u83b7\u6570\u636e\u96c6\u3001\u6a21\u578b\u5143\u6570\u636e\u548c\u73af\u5883\u7ec6\u8282\uff0c\u5e76\u5229\u7528\u52a0\u5bc6\u54c8\u5e0c\u3001\u6570\u5b57\u7b7e\u540d\u7b49\u6280\u672f\u786e\u4fdd\u5b8c\u6574\u6027\uff0c\u9632\u6b62\u4e0d\u8bda\u5b9e\u6a21\u578b\u521b\u5efa\u8005\u7684\u7be1\u6539\u3002\u8bc4\u4f30\u663e\u793aAIBoMGen\u80fd\u591f\u53ef\u9760\u5730\u68c0\u6d4b\u5230\u6240\u6709\u4eba\u5de5\u5236\u54c1\u672a\u7ecf\u6388\u6743\u7684\u4fee\u6539\uff0c\u5e76\u4ee5\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u7684\u6027\u80fd\u5f00\u9500\u751f\u6210AIBOMs\uff0c\u4e3a\u6784\u5efa\u5b89\u5168\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u590d\u6742\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5feb\u901f\u91c7\u7528\uff0c\u5bf9\u4e8e\u786e\u4fdd\u8fd9\u4e9b\u7cfb\u7edf\u900f\u660e\u5ea6\u3001\u5b89\u5168\u6027\u53ca\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u5de5\u5177\u7684\u53d1\u5c55\u76f8\u5bf9\u6ede\u540e\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u63d0\u4f9bAI\u6a21\u578b\u53ca\u5176\u8fd0\u884c\u73af\u5883\u8be6\u7ec6\u4fe1\u606f\u7684\u6807\u51c6\u5316\u8bb0\u5f55\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u4fbf\u4e8e\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u589e\u5f3a\u5b89\u5168\u6027\u5e76\u652f\u6301\u5408\u89c4\u6027\u3002", "method": "\u5f15\u5165\u4e86AI Bill of Materials (AIBOM)\uff0c\u5b83\u662f\u8f6f\u4ef6\u6750\u6599\u6e05\u5355(SBOM)\u7684\u4e00\u79cd\u6269\u5c55\u5f62\u5f0f\uff0c\u7528\u4e8e\u4f5c\u4e3a\u5df2\u8bad\u7ec3AI\u6a21\u578b\u53ca\u5176\u73af\u5883\u7684\u6807\u51c6\u5316\u3001\u53ef\u9a8c\u8bc1\u8bb0\u5f55\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u5e73\u53f0AIBoMGen\uff0c\u8be5\u5e73\u53f0\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u6536\u96c6\u6570\u636e\u96c6\u3001\u6a21\u578b\u5143\u6570\u636e\u4ee5\u53ca\u73af\u5883\u8be6\u60c5\u6765\u751f\u6210\u7b7e\u540d\u7248\u7684AIBOM\u6587\u4ef6\u3002\u6b64\u5916\uff0c\u8be5\u7cfb\u7edf\u8fd8\u91c7\u7528\u4e86\u52a0\u5bc6\u54c8\u5e0c\u7b97\u6cd5\u3001\u6570\u5b57\u7b7e\u540d\u4ee5\u53cain-toto\u8ba4\u8bc1\u673a\u5236\u6765\u4fdd\u969c\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u7684\u5b8c\u6574\u6027\u4e0e\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAIBoMGen\u80fd\u591f\u6709\u6548\u8bc6\u522b\u672a\u7ecf\u8bb8\u53ef\u5bf9\u5404\u79cd\u7ec4\u4ef6\u6240\u505a\u7684\u4efb\u4f55\u6539\u52a8\uff0c\u5e76\u4e14\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u6210\u529f\u751f\u6210AIBOM\u6587\u6863\u3002\u8fd9\u8bc1\u660e\u4e86AIBoMGen\u5728\u4fc3\u8fdb\u66f4\u52a0\u5b89\u5168\u548c\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u751f\u6001\u4f53\u7cfb\u5efa\u8bbe\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "AIBoMGen\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u6784\u5efa\u5b89\u5168\u900f\u660eAI\u751f\u6001\u7cfb\u7edf\u57fa\u7840\u6b65\u9aa4\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u6709\u52a9\u4e8e\u6ee1\u8db3\u5982\u6b27\u76dfAI\u6cd5\u6848\u7b49\u76d1\u7ba1\u6846\u67b6\u7684\u8981\u6c42\u3002"}}
{"id": "2601.05721", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05721", "abs": "https://arxiv.org/abs/2601.05721", "authors": ["Daniel P\u00f6ttgen", "Mersedeh Sadeghi", "Max Unterbusch", "Andreas Vogelsang"], "title": "From Issues to Insights: RAG-based Explanation Generation from Software Engineering Artifacts", "comment": "Accepted at NLBSE 2026, Rio de Janeiro, Brazil", "summary": "The increasing complexity of modern software systems has made understanding their behavior increasingly challenging, driving the need for explainability to improve transparency and user trust. Traditional documentation is often outdated or incomplete, making it difficult to derive accurate, context-specific explanations. Meanwhile, issue-tracking systems capture rich and continuously updated development knowledge, but their potential for explainability remains untapped. With this work, we are the first to apply a Retrieval-Augmented Generation (RAG) approach for generating explanations from issue-tracking data. Our proof-of-concept system is implemented using open-source tools and language models, demonstrating the feasibility of leveraging structured issue data for explanation generation. Evaluating our approach on an exemplary project's set of GitHub issues, we achieve 90% alignment with human-written explanations. Additionally, our system exhibits strong faithfulness and instruction adherence, ensuring reliable and grounded explanations. These findings suggest that RAG-based methods can extend explainability beyond black-box ML models to a broader range of software systems, provided that issue-tracking data is available - making system behavior more accessible and interpretable.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5e94\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\u4ece\u95ee\u9898\u8ddf\u8e2a\u6570\u636e\u4e2d\u751f\u6210\u89e3\u91ca\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4eba\u5de5\u7f16\u5199\u7684\u89e3\u91ca90%\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u63d0\u9ad8\u8f6f\u4ef6\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u7684\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u7406\u89e3\u5176\u884c\u4e3a\u53d8\u5f97\u8d8a\u6765\u8d8a\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u4ee5\u6539\u5584\u900f\u660e\u5ea6\u548c\u7528\u6237\u4fe1\u4efb\u3002\u4f20\u7edf\u6587\u6863\u5f80\u5f80\u8fc7\u65f6\u6216\u4e0d\u5b8c\u6574\uff0c\u96be\u4ee5\u4ece\u4e2d\u83b7\u5f97\u51c6\u786e\u4e14\u5177\u6709\u4e0a\u4e0b\u6587\u7279\u5f02\u6027\u7684\u89e3\u91ca\u3002\u4e0e\u6b64\u540c\u65f6\uff0c\u867d\u7136\u95ee\u9898\u8ddf\u8e2a\u7cfb\u7edf\u80fd\u591f\u6355\u6349\u5230\u4e30\u5bcc\u4e14\u4e0d\u65ad\u66f4\u65b0\u7684\u5f00\u53d1\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4e9b\u77e5\u8bc6\u5728\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u53d1\u6398\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u65b9\u6cd5\u6765\u5229\u7528\u95ee\u9898\u8ddf\u8e2a\u6570\u636e\u81ea\u52a8\u751f\u6210\u89e3\u91ca\u3002\u8be5\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u4f7f\u7528\u5f00\u6e90\u5de5\u5177\u548c\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\uff0c\u65e8\u5728\u5c55\u793a\u5982\u4f55\u6709\u6548\u5229\u7528\u7ed3\u6784\u5316\u7684\u95ee\u9898\u6570\u636e\u751f\u6210\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u5728\u4e00\u4e2a\u793a\u4f8b\u9879\u76ee\u7684GitHub\u95ee\u9898\u96c6\u4e0a\u8bc4\u4f30\u6240\u63d0\u65b9\u6cd5\uff0c\u7814\u7a76\u53d1\u73b0\u751f\u6210\u7684\u89e3\u91ca\u4e0e\u4eba\u5de5\u7f16\u5199\u7684\u89e3\u91ca\u670990%\u7684\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u7cfb\u7edf\u8868\u73b0\u51fa\u5f88\u5f3a\u7684\u771f\u5b9e\u6027\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u4fdd\u8bc1\u4e86\u6240\u63d0\u4f9b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u548c\u57fa\u7840\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eRAG\u7684\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u4ee5\u5728\u9ed1\u76d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e4b\u5916\u6269\u5c55\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u4e14\u5f53\u95ee\u9898\u8ddf\u8e2a\u6570\u636e\u53ef\u7528\u65f6\uff0c\u8fd8\u80fd\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u4f7f\u5f97\u7cfb\u7edf\u884c\u4e3a\u66f4\u52a0\u6613\u4e8e\u7406\u89e3\u548c\u89e3\u8bfb\u3002"}}
{"id": "2601.05268", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05268", "abs": "https://arxiv.org/abs/2601.05268", "authors": ["Rob Koopman"], "title": "Separating Semantic Expansion from Linear Geometry for PubMed-Scale Vector Search", "comment": "4 pages", "summary": "We describe a PubMed scale retrieval framework that separates semantic interpretation from metric geometry. A large language model expands a natural language query into concise biomedical phrases; retrieval then operates in a fixed, mean free, approximately isotropic embedding space. Each document and query vector is formed as a weighted mean of token embeddings, projected onto the complement of nuisance axes and compressed by a Johnson Lindenstrauss transform. No parameters are trained. The system retrieves coherent biomedical clusters across the full MEDLINE corpus (about 40 million records) using exact cosine search on 256 dimensional int8 vectors. Evaluation is purely geometric: head cosine, compactness, centroid closure, and isotropy are compared with random vector baselines. Recall is not defined, since the language-model expansion specifies the effective target set.", "AI": {"tldr": "This paper introduces a PubMed scale retrieval system that uses a large language model to expand natural language queries into biomedical phrases, and then performs retrieval in a fixed, approximately isotropic embedding space without training any parameters. The evaluation is based on geometric properties.", "motivation": "The motivation of this paper is to develop an efficient and scalable retrieval framework for the biomedical literature, which can interpret natural language queries and retrieve relevant information from a vast corpus such as MEDLINE, while separating semantic interpretation from the metric geometry of the document space.", "method": "The method involves using a large language model to expand natural language queries into concise biomedical phrases. The retrieval operates in a pre-defined, mean-free, and nearly isotropic embedding space. Each document and query vector is created by averaging token embeddings, removing nuisance axes, and compressing with a Johnson-Lindenstrauss transform. Retrieval is done using exact cosine search on 256-dimensional int8 vectors across the entire MEDLINE corpus.", "result": "The results show that the system can retrieve coherent biomedical clusters from the full MEDLINE corpus (around 40 million records) using exact cosine search. The evaluation, which focuses on geometric properties like head cosine, compactness, centroid closure, and isotropy, indicates that the proposed method outperforms random vector baselines. Recall is not applicable due to the nature of the language-model expansion.", "conclusion": "The conclusion is that the proposed retrieval framework, which does not require training and separates semantic processing from geometric representation, can effectively handle PubMed scale retrieval tasks, demonstrating its potential for large-scale biomedical information retrieval."}}
{"id": "2601.05772", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05772", "abs": "https://arxiv.org/abs/2601.05772", "authors": ["Qingyuan Li", "Chenchen Yu", "Chuanyi Li", "Xin-Cheng Wen", "Cheryl Lee", "Cuiyun Gao", "Bin Luo"], "title": "StriderSPD: Structure-Guided Joint Representation Learning for Binary Security Patch Detection", "comment": null, "summary": "Vulnerabilities severely threaten software systems, making the timely application of security patches crucial for mitigating attacks. However, software vendors often silently patch vulnerabilities with limited disclosure, where Security Patch Detection (SPD) comes to protect software assets. Recently, most SPD studies have targeted Open-Source Software (OSS), yet a large portion of real-world software is closed-source, where patches are distributed as binaries without accessible source code. The limited binary SPD approaches often lift binaries to abstraction levels, i.e., assembly code or pseudo-code. However, assembly code is register-based instructions conveying limited semantics, while pseudo-code lacks parser-compatible grammar to extract structure, both hindering accurate vulnerability-fix representation learning. In addition, previous studies often obtain training and testing data from the same project for evaluation, which fails to reflect closed-source conditions. To alleviate the above challenges, we propose \\textbf{\\textit{StriderSPD}}, a \\underline{Str}ucture-gu\\underline{ide}d joint \\underline{r}epresentation \\underline{SPD} framework of binary code that integrates a graph branch into a large language model (LLM), leveraging structural information to guide the LLM in identifying security patches. Our novel design of the adapters in the graph branch effectively aligns the representations between assembly code and pseudo-code at the LLM's token level. We further present a two-stage training strategy to address the optimization imbalance caused by the large parameter disparity between StriderSPD's two branches, which enables proper branch fitting. To enable more realistic evaluation, we construct a binary SPD benchmark that is disjoint from prior datasets in both projects and domains and extensively evaluate StriderSPD on this benchmark.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStriderSPD\u7684\u6846\u67b6\uff0c\u5b83\u7ed3\u5408\u4e86\u56fe\u5206\u652f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5229\u7528\u7ed3\u6784\u4fe1\u606f\u6765\u6307\u5bfcLLM\u8bc6\u522b\u5b89\u5168\u8865\u4e01\u3002\u901a\u8fc7\u521b\u65b0\u8bbe\u8ba1\u7684\u9002\u914d\u5668\u5728LLM\u7684\u4ee4\u724c\u7ea7\u522b\u4e0a\u6709\u6548\u5bf9\u9f50\u6c47\u7f16\u4ee3\u7801\u548c\u4f2a\u4ee3\u7801\u4e4b\u95f4\u7684\u8868\u793a\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u89e3\u51b3\u4e86\u7531\u4e24\u4e2a\u5206\u652f\u95f4\u53c2\u6570\u5dee\u5f02\u5927\u5bfc\u81f4\u7684\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u4e0e\u5148\u524d\u6570\u636e\u96c6\u5728\u9879\u76ee\u548c\u9886\u57df\u4e0a\u5747\u4e0d\u91cd\u53e0\u7684\u4e8c\u8fdb\u5236SPD\u57fa\u51c6\u4ee5\u8fdb\u884c\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u4e2d\u6f0f\u6d1e\u7684\u5b58\u5728\u4e25\u91cd\u5a01\u80c1\u7cfb\u7edf\u5b89\u5168\uff0c\u53ca\u65f6\u5e94\u7528\u5b89\u5168\u8865\u4e01\u5bf9\u4e8e\u7f13\u89e3\u653b\u51fb\u81f3\u5173\u91cd\u8981\u3002\u4f46\u8f6f\u4ef6\u4f9b\u5e94\u5546\u901a\u5e38\u4f1a\u9759\u9ed8\u4fee\u8865\u6f0f\u6d1e\u800c\u62ab\u9732\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u95ed\u6e90\u8f6f\u4ef6\u4e2d\uff0c\u8865\u4e01\u4ee5\u4e8c\u8fdb\u5236\u5f62\u5f0f\u5206\u53d1\u800c\u4e0d\u63d0\u4f9b\u6e90\u4ee3\u7801\u8bbf\u95ee\u6743\u9650\u3002\u5f53\u524d\u7684\u4e8c\u8fdb\u5236SPD\u65b9\u6cd5\u5f80\u5f80\u5c06\u4e8c\u8fdb\u5236\u63d0\u5347\u5230\u62bd\u8c61\u5c42\u6b21\u5982\u6c47\u7f16\u6216\u4f2a\u4ee3\u7801\u5c42\u9762\u5904\u7406\uff0c\u8fd9\u9650\u5236\u4e86\u8bed\u4e49\u8868\u8fbe\u5e76\u7f3a\u4e4f\u53ef\u7528\u4e8e\u63d0\u53d6\u7ed3\u6784\u7684\u8bed\u6cd5\u89e3\u6790\u517c\u5bb9\u6027\uff0c\u4ece\u800c\u963b\u788d\u51c6\u786e\u7684\u5b66\u4e60\u6f0f\u6d1e\u4fee\u590d\u8868\u793a\u3002\u6b64\u5916\uff0c\u4ee5\u5f80\u7814\u7a76\u591a\u4ece\u540c\u4e00\u9879\u76ee\u83b7\u53d6\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u6570\u636e\uff0c\u672a\u80fd\u53cd\u6620\u95ed\u6e90\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86StriderSPD\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u56fe\u5206\u652f\u96c6\u6210\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5229\u7528\u7ed3\u6784\u5316\u4fe1\u606f\u5f15\u5bfc\u6a21\u578b\u8bc6\u522b\u5b89\u5168\u8865\u4e01\u3002\u8bbe\u8ba1\u4e86\u65b0\u7684\u9002\u914d\u5668\uff0c\u5728LLM\u7684token\u7ea7\u522b\u4e0a\u6709\u6548\u5730\u5bf9\u9f50\u6c47\u7f16\u4ee3\u7801\u548c\u4f2a\u4ee3\u7801\u4e4b\u95f4\u7684\u8868\u793a\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u89e3\u51b3\u7531\u4e8eStriderSPD\u4e24\u4e2a\u5206\u652f\u4e4b\u95f4\u53c2\u6570\u6570\u91cf\u5de8\u5927\u5dee\u5f02\u5f15\u8d77\u7684\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "StriderSPD\u80fd\u591f\u5728\u65b0\u6784\u5efa\u7684\u3001\u4e0e\u5148\u524d\u6570\u636e\u96c6\u5728\u9879\u76ee\u548c\u9886\u57df\u4e0a\u90fd\u4e0d\u91cd\u53e0\u7684\u4e8c\u8fdb\u5236SPD\u57fa\u51c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5176\u5728\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u68c0\u6d4b\u95ed\u6e90\u8f6f\u4ef6\u4e2d\u5b89\u5168\u8865\u4e01\u7684\u6709\u6548\u6027\u3002", "conclusion": "StriderSPD\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u514b\u670d\u73b0\u6709\u4e8c\u8fdb\u5236SPD\u65b9\u6cd5\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u95ed\u6e90\u8f6f\u4ef6\u65f6\u3002\u901a\u8fc7\u7ed3\u5408\u56fe\u5206\u652f\u4e0eLLM\u4ee5\u53ca\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0cStriderSPD\u80fd\u591f\u66f4\u51c6\u786e\u5730\u5b66\u4e60\u548c\u8bc6\u522b\u5b89\u5168\u8865\u4e01\u3002"}}
{"id": "2601.05269", "categories": ["cs.IR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05269", "abs": "https://arxiv.org/abs/2601.05269", "authors": ["Yoav Evron", "Michal Bar-Asher Siegal", "Michael Fire"], "title": "Studying Illustrations in Manuscripts: An Efficient Deep-Learning Approach", "comment": "14 pages, 5 figures", "summary": "The recent Artificial Intelligence (AI) revolution has opened transformative possibilities for the humanities, particularly in unlocking the visual content embedded in historical manuscripts. While digital archives now offer unprecedented access to these materials, the ability to systematically study illustrations at a large scale remains challenging. Our study presents a fast and scalable AI approach for detecting, extracting, and describing illustrations in digitized manuscripts. Focusing on collections like the Vatican Library, our system enables efficient visual analysis across millions of pages. Our pipeline consists of three stages: (1) a fine-tuned image classification model filters out text-only pages; (2) an efficient object detection model identifies and crops illustrations; and (3) a multimodal image captioning model generates concise, human-readable descriptions. These are stored in a searchable database, allowing scholars to retrieve relevant visual materials through keyword queries. By harnessing the power of recent AI advancements, we enable large-scale visual research that was previously impractical, empowering scholars in historical studies, art history, and cultural heritage to explore visual motifs, artistic styles, and cross-cultural influences with new precision and speed. Applying our pipeline to over three million digitized manuscript pages, we automatically identified and extracted more than 200,000 unique illustrations. This scale of processing in under 0.06 seconds per page, dramatically outperforms traditional segmentation techniques in both efficiency and accessibility for visual scholarship. Our work demonstrates how cutting-edge AI tools can profoundly reshape scholarly workflows and open new avenues for multidisciplinary research in the age of digital manuscripts.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u53ef\u6269\u5c55\u7684AI\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u3001\u63d0\u53d6\u548c\u63cf\u8ff0\u6570\u5b57\u5316\u624b\u7a3f\u4e2d\u7684\u63d2\u56fe\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u5b9e\u73b0\u4e86\u5bf9\u5927\u89c4\u6a21\u624b\u7a3f\u56fe\u50cf\u5185\u5bb9\u7684\u6709\u6548\u5206\u6790\u4e0e\u68c0\u7d22\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u6863\u6848\u4e3a\u5386\u53f2\u6587\u732e\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u8bbf\u95ee\u673a\u4f1a\uff0c\u4f46\u7cfb\u7edf\u6027\u5730\u5927\u89c4\u6a21\u7814\u7a76\u63d2\u56fe\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u4eec\u5e0c\u671b\u901a\u8fc7\u5f00\u53d1\u4e00\u79cd\u65b0\u7684AI\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f7f\u5f97\u5b66\u8005\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u8fdb\u884c\u89c6\u89c9\u6750\u6599\u7684\u7814\u7a76\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u4e09\u9636\u6bb5\u7684\u65b9\u6cd5\uff1a\u9996\u5148\u4f7f\u7528\u5fae\u8c03\u8fc7\u7684\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u8fc7\u6ee4\u6389\u7eaf\u6587\u672c\u9875\u9762\uff1b\u5176\u6b21\u5229\u7528\u9ad8\u6548\u7684\u5bf9\u8c61\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u5e76\u88c1\u526a\u51fa\u63d2\u56fe\uff1b\u6700\u540e\u8fd0\u7528\u591a\u6a21\u6001\u56fe\u50cf\u6807\u6ce8\u6a21\u578b\u751f\u6210\u7b80\u6d01\u7684\u4eba\u7c7b\u53ef\u8bfb\u63cf\u8ff0\u3002\u8fd9\u4e9b\u4fe1\u606f\u88ab\u5b58\u50a8\u5728\u4e00\u4e2a\u53ef\u641c\u7d22\u6570\u636e\u5e93\u4e2d\u3002", "result": "\u5e94\u7528\u6b64\u7ba1\u9053\u5904\u7406\u8d85\u8fc7\u4e09\u767e\u4e07\u9875\u7684\u6570\u5b57\u5316\u624b\u7a3f\u540e\uff0c\u81ea\u52a8\u8bc6\u522b\u5e76\u63d0\u53d6\u4e86\u8d85\u8fc720\u4e07\u5f20\u72ec\u7279\u7684\u63d2\u56fe\u3002\u6bcf\u9875\u5904\u7406\u65f6\u95f4\u5c11\u4e8e0.06\u79d2\uff0c\u8fdc\u8d85\u4f20\u7edf\u5206\u5272\u6280\u672f\u5728\u6548\u7387\u548c\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5c16\u7aefAI\u5de5\u5177\u5982\u4f55\u6df1\u523b\u6539\u53d8\u5b66\u672f\u5de5\u4f5c\u6d41\uff0c\u5e76\u4e3a\u6570\u5b57\u624b\u7a3f\u65f6\u4ee3\u7684\u8de8\u5b66\u79d1\u7814\u7a76\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.05544", "categories": ["cs.LG", "math.OC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.05544", "abs": "https://arxiv.org/abs/2601.05544", "authors": ["Moe Shiina", "Shunnosuke Ikeda", "Yuichi Takano"], "title": "Buffered AUC maximization for scoring systems via mixed-integer optimization", "comment": null, "summary": "A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u7ebf\u6027\u4f18\u5316\uff08MILO\uff09\u7684\u65b9\u6cd5\uff0c\u76f4\u63a5\u6700\u5927\u5316\u7f13\u51b2AUC\uff08bAUC\uff09\uff0c\u7528\u4e8e\u6784\u5efa\u5177\u6709\u9ad8\u53ef\u89e3\u91ca\u6027\u7684\u8bc4\u5206\u7cfb\u7edf\u3002\u901a\u8fc7\u9650\u5236\u8bc4\u5206\u7cfb\u7edf\u4e2d\u7684\u95ee\u9898\u6570\u91cf\u6765\u5b9e\u73b0\u7ec4\u7a00\u758f\u6027\u7ea6\u675f\uff0c\u5e76\u4e14\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728AUC\u503c\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u6b63\u5219\u5316\u548c\u9010\u6b65\u56de\u5f52\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u4e4b\u524d\u7684\u8bb8\u591a\u7814\u7a76\u5df2\u7ecf\u4f7f\u7528\u4e86\u6df7\u5408\u6574\u6570\u4f18\u5316(MIO)\u6280\u672f\u6765\u5f00\u53d1\u7528\u4e8e\u4e8c\u5206\u7c7b\u7684\u8bc4\u5206\u7cfb\u7edf\uff0c\u4f46\u5b83\u4eec\u6ca1\u6709\u4e13\u6ce8\u4e8e\u76f4\u63a5\u6700\u5927\u5316AUC\uff08\u5373\u63a5\u6536\u8005\u64cd\u4f5c\u7279\u5f81\u66f2\u7ebf\u4e0b\u7684\u9762\u79ef\uff09\u3002\u9274\u4e8eAUC\u88ab\u8ba4\u4e3a\u662f\u8bc4\u4ef7\u8bc4\u5206\u7cfb\u7edf\u7684\u4e00\u4e2a\u91cd\u8981\u6307\u6807\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u6709\u6548\u7684MIO\u6846\u67b6\uff0c\u4ee5\u76f4\u63a5\u6700\u5927\u5316\u4f5c\u4e3aAUC\u6700\u7d27\u51f8\u4e0b\u754c\u7684\u7f13\u51b2AUC(bAUC)\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u4f18\u5316(MILO)\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u8003\u8651\u7ec4\u7a00\u758f\u6027\u7ea6\u675f\u4ee5\u9650\u5236\u8bc4\u5206\u7cfb\u7edf\u4e2d\u95ee\u9898\u6570\u91cf\u7684\u540c\u65f6\uff0c\u6700\u5927\u5316bAUC\u3002", "result": "\u5229\u7528\u516c\u5f00\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8fdb\u884c\u7684\u8ba1\u7b97\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u51fa\u7684MILO\u65b9\u6cd5\u80fd\u591f\u6784\u5efa\u51fa\u6bd4\u57fa\u4e8e\u6b63\u5219\u5316\u548c\u9010\u6b65\u56de\u5f52\u7684\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8AUC\u503c\u7684\u8bc4\u5206\u7cfb\u7edf\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4fc3\u8fdb\u4e86\u5f00\u53d1\u9ad8\u5ea6\u53ef\u89e3\u91ca\u5206\u7c7b\u6a21\u578b\u7684MIO\u6280\u672f\u7684\u8fdb\u6b65\u3002"}}
{"id": "2601.05827", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.05827", "abs": "https://arxiv.org/abs/2601.05827", "authors": ["Zewei Lin", "Jiachi Chen", "Jingwen Zhang", "Zexu Wang", "Yuming Feng", "Weizhe Zhang", "Zibin Zheng"], "title": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking", "comment": null, "summary": "Decentralized Finance (DeFi) staking is one of the most prominent applications within the DeFi ecosystem, where DeFi projects enable users to stake tokens on the platform and reward participants with additional tokens. However, logical defects in DeFi staking could enable attackers to claim unwarranted rewards by manipulating reward amounts, repeatedly claiming rewards, or engaging in other malicious actions. To mitigate these threats, we conducted the first study focused on defining and detecting logical defects in DeFi staking. Through the analysis of 64 security incidents and 144 audit reports, we identified six distinct types of logical defects, each accompanied by detailed descriptions and code examples. Building on this empirical research, we developed SSR (Safeguarding Staking Reward), a static analysis tool designed to detect logical defects in DeFi staking contracts. SSR utilizes a large language model (LLM) to extract fundamental information about staking logic and constructs a DeFi staking model. It then identifies logical defects by analyzing the model and the associated semantic features. We constructed a ground truth dataset based on known security incidents and audit reports to evaluate the effectiveness of SSR. The results indicate that SSR achieves an overall precision of 92.31%, a recall of 87.92%, and an F1-score of 88.85%. Additionally, to assess the prevalence of logical defects in real-world smart contracts, we compiled a large-scale dataset of 15,992 DeFi staking contracts. SSR detected that 3,557 (22.24%) of these contracts contained at least one logical defect.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76\u4e86\u53bb\u4e2d\u5fc3\u5316\u91d1\u878d(DeFi)\u8d28\u62bc\u4e2d\u7684\u903b\u8f91\u7f3a\u9677\u95ee\u9898\uff0c\u5b9a\u4e49\u5e76\u68c0\u6d4b\u4e86\u516d\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u903b\u8f91\u7f3a\u9677\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aSSR\u7684\u9759\u6001\u5206\u6790\u5de5\u5177\u6765\u68c0\u6d4bDeFi\u8d28\u62bc\u5408\u7ea6\u4e2d\u7684\u903b\u8f91\u7f3a\u9677\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSSR\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u8868\u73b0\u4f18\u79c0\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5206\u6790\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u8d85\u8fc720%\u7684DeFi\u8d28\u62bc\u5408\u540c\u81f3\u5c11\u5305\u542b\u4e00\u79cd\u903b\u8f91\u7f3a\u9677\u3002", "motivation": "\u9274\u4e8eDeFi\u8d28\u62bc\u4e2d\u5b58\u5728\u7684\u903b\u8f91\u7f3a\u9677\u53ef\u80fd\u8ba9\u653b\u51fb\u8005\u4e0d\u5f53\u83b7\u5229\uff0c\u6bd4\u5982\u901a\u8fc7\u64cd\u7eb5\u5956\u52b1\u91d1\u989d\u6216\u91cd\u590d\u9886\u53d6\u5956\u52b1\u7b49\u65b9\u5f0f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u8fd9\u4e9b\u903b\u8f91\u7f3a\u9677\u5e76\u901a\u8fc7\u5f00\u53d1\u4e13\u95e8\u5de5\u5177\u6765\u5e2e\u52a9\u7f13\u89e3\u6b64\u7c7b\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u5bf964\u8d77\u5b89\u5168\u4e8b\u4ef6\u53ca144\u4efd\u5ba1\u8ba1\u62a5\u544a\u8fdb\u884c\u5206\u6790\uff0c\u786e\u5b9a\u4e86\u516d\u79cd\u4e0d\u540c\u7684\u903b\u8f91\u7f3a\u9677\u7c7b\u578b\uff1b\u57fa\u4e8e\u6b64\u7814\u7a76\u5f00\u53d1\u4e86SSR\u5de5\u5177\uff0c\u8be5\u5de5\u5177\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u53d6\u5173\u4e8e\u8d28\u62bc\u903b\u8f91\u7684\u57fa\u672c\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u4e00\u4e2aDeFi\u8d28\u62bc\u6a21\u578b\u4ee5\u8bc6\u522b\u5176\u4e2d\u5b58\u5728\u7684\u903b\u8f91\u7f3a\u9677\u3002", "result": "SSR\u5de5\u5177\u8fbe\u5230\u4e8692.31%\u7684\u51c6\u786e\u7387\u300187.92%\u7684\u53ec\u56de\u7387\u4ee5\u53ca88.85%\u7684F1\u5206\u6570\u3002\u53e6\u5916\uff0c\u5728\u5bf915,992\u4e2aDeFi\u8d28\u62bc\u5408\u540c\u8fdb\u884c\u5206\u6790\u65f6\uff0c\u53d1\u73b0\u67093,557\u4e2a\uff08\u5360\u603b\u6570\u768422.24%\uff09\u5408\u540c\u81f3\u5c11\u5b58\u5728\u4e00\u79cd\u903b\u8f91\u7f3a\u9677\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0cDeFi\u8d28\u62bc\u9886\u57df\u5185\u5b58\u5728\u7740\u663e\u8457\u6bd4\u4f8b\u7684\u903b\u8f91\u7f3a\u9677\uff0c\u800c\u6240\u63d0\u51fa\u7684SSR\u5de5\u5177\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3a\u63d0\u9ad8DeFi\u5e94\u7528\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2601.05461", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05461", "abs": "https://arxiv.org/abs/2601.05461", "authors": ["Mohammed Ali", "Abdelrahman Abdallah", "Amit Agarwal", "Hitesh Laxmichand Patel", "Adam Jatowt"], "title": "RECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark", "comment": null, "summary": "Existing benchmarks treat multi-turn conversation and reasoning-intensive retrieval separately, yet real-world information seeking requires both. To bridge this gap, we present a benchmark for reasoning-based conversational information retrieval comprising 707 conversations (2,971 turns) across eleven domains. To ensure quality, our Decomposition-and-Verification framework transforms complex queries into fact-grounded multi-turn dialogues through multi-level validation, where atomic facts are verified against sources and explicit retrieval reasoning is generated for each turn. Comprehensive evaluation reveals that combining conversation history with reasoning doubles retrieval performance (Baseline .236 $\\rightarrow$ History+Reasoning .479 nDCG@10), while reasoning-specialized models substantially outperform dense encoders. Despite these gains, further analysis highlights that implicit reasoning remains challenging, particularly when logical connections are not explicitly stated in the text.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a8\u7406\u7684\u5bf9\u8bdd\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\uff0c\u5305\u542b11\u4e2a\u9886\u57df\u4e2d\u7684707\u6b21\u5bf9\u8bdd\uff082,971\u8f6e\uff09\uff0c\u5e76\u901a\u8fc7\u5206\u89e3\u4e0e\u9a8c\u8bc1\u6846\u67b6\u4fdd\u8bc1\u8d28\u91cf\u3002\u7efc\u5408\u8bc4\u4f30\u8868\u660e\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u68c0\u7d22\u6027\u80fd\uff0c\u4f46\u9690\u5f0f\u63a8\u7406\u4ecd\u5177\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u5c06\u591a\u8f6e\u5bf9\u8bdd\u548c\u5bc6\u96c6\u63a8\u7406\u68c0\u7d22\u5206\u5f00\u5904\u7406\uff0c\u7136\u800c\u5b9e\u9645\u7684\u4fe1\u606f\u5bfb\u6c42\u9700\u8981\u4e24\u8005\u517c\u5907\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e8\u5728\u6574\u5408\u8fd9\u4e24\u65b9\u9762\u7684\u65b0\u7684\u57fa\u51c6\u3002", "method": "\u7814\u7a76\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u5206\u89e3\u4e0e\u9a8c\u8bc1\u201d\u7684\u6846\u67b6\u6765\u8f6c\u53d8\u590d\u6742\u67e5\u8be2\u4e3a\u57fa\u4e8e\u4e8b\u5b9e\u7684\u591a\u8f6e\u5bf9\u8bdd\uff0c\u5e76\u901a\u8fc7\u591a\u5c42\u6b21\u9a8c\u8bc1\u786e\u4fdd\u8d28\u91cf\uff0c\u5728\u6bcf\u4e2a\u5bf9\u8bdd\u56de\u5408\u4e2d\u751f\u6210\u663e\u5f0f\u7684\u68c0\u7d22\u63a8\u7406\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0c\u5f53\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u65f6\uff0c\u68c0\u7d22\u6027\u80fd\u7ffb\u500d\uff08\u57fa\u7ebf.236 \u2192 \u5386\u53f2+\u63a8\u7406.479 nDCG@10\uff09\uff0c\u5e76\u4e14\u4e13\u6ce8\u4e8e\u63a8\u7406\u7684\u6a21\u578b\u660e\u663e\u4f18\u4e8e\u5bc6\u96c6\u7f16\u7801\u5668\u3002\u4e0d\u8fc7\uff0c\u5bf9\u4e8e\u6587\u672c\u4e2d\u672a\u660e\u786e\u9648\u8ff0\u903b\u8f91\u8054\u7cfb\u7684\u60c5\u51b5\u4e0b\u7684\u9690\u5f0f\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7ed3\u5408\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4e0e\u660e\u786e\u7684\u63a8\u7406\u8fc7\u7a0b\u53ef\u4ee5\u5927\u5e45\u63d0\u9ad8\u4fe1\u606f\u68c0\u7d22\u7684\u6548\u679c\uff1b\u4f46\u662f\uff0c\u5bf9\u4e8e\u90a3\u4e9b\u6ca1\u6709\u76f4\u63a5\u5728\u6587\u672c\u4e2d\u8868\u8fbe\u51fa\u6765\u7684\u903b\u8f91\u5173\u7cfb\u8fdb\u884c\u63a8\u7406\u4f9d\u7136\u662f\u672a\u6765\u5de5\u4f5c\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2601.05583", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.05583", "abs": "https://arxiv.org/abs/2601.05583", "authors": ["Xue Feng", "Li Wang", "Deanna Needell", "Rongjie Lai"], "title": "Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow", "comment": null, "summary": "The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u65b9\u6cd5\u6765\u5b66\u4e60JKO\u89e3\u7b97\u5b50\uff0c\u65e0\u9700\u6570\u503c\u6c42\u89e3\u4efb\u4f55JKO\u8f68\u8ff9\u3002\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u8f68\u8ff9\u751f\u6210\u548c\u7b97\u5b50\u66f4\u65b0\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u5b66\u4e60JKO\u7b97\u5b50\u53ca\u5176\u5f15\u8d77\u7684\u8f68\u8ff9\uff0c\u5e76\u4e14\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u751f\u6210\u7684\u6570\u636e\u8d8a\u6765\u8d8a\u63a5\u8fd1\u771f\u5b9e\u7684JKO\u8f68\u8ff9\u3002", "motivation": "\u4f20\u7edf\u7684JKO\u65b9\u6848\u867d\u7136\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5b9a\u7684\u53d8\u5206\u6846\u67b6\u7528\u4e8e\u8ba1\u7b97Wasserstein\u68af\u5ea6\u6d41\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u5e38\u5e38\u53d7\u5230\u53cd\u590d\u89e3\u51b3JKO\u5b50\u95ee\u9898\u5e26\u6765\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u76f4\u63a5\u5c06\u8f93\u5165\u5bc6\u5ea6\u6620\u5c04\u5230\u76f8\u5e94JKO\u5b50\u95ee\u9898\u7684\u6700\u5c0f\u503c\u70b9\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86Learn-to-Evolve\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5728\u8f68\u8ff9\u751f\u6210\u548c\u7b97\u5b50\u66f4\u65b0\u4e4b\u95f4\u4ea4\u66ff\u6765\u8fdb\u884c\uff0c\u4ee5\u514b\u670d\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5bf9\u4e8e\u4e0d\u540c\u80fd\u91cf\u5f62\u5f0f\u53ca\u521d\u59cb\u6761\u4ef6\u90fd\u8868\u73b0\u51fa\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4eJKO\u65b9\u6848\u7684\u5e94\u7528\u96be\u5ea6\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.05549", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05549", "abs": "https://arxiv.org/abs/2601.05549", "authors": ["Tuan-Luc Huynh", "Weiqing Wang", "Trung Le", "Thuy-Trang Vu", "Dragan Ga\u0161evi\u0107", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "Efficient Temporal-aware Matryoshka Adaptation for Temporal Information Retrieval", "comment": "18 pages", "summary": "Retrievers are a key bottleneck in Temporal Retrieval-Augmented Generation (RAG) systems: failing to retrieve temporally relevant context can degrade downstream generation, regardless of LLM reasoning. We propose Temporal-aware Matryoshka Representation Learning (TMRL), an efficient method that equips retrievers with temporal-aware Matryoshka embeddings. TMRL leverages the nested structure of Matryoshka embeddings to introduce a temporal subspace, enhancing temporal encoding while preserving general semantic representations. Experiments show that TMRL efficiently adapts diverse text embedding models, achieving competitive temporal retrieval and temporal RAG performance compared to prior Matryoshka-based non-temporal methods and prior temporal methods, while enabling flexible accuracy-efficiency trade-offs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTMRL\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5b50\u7a7a\u95f4\u6765\u63d0\u9ad8\u68c0\u7d22\u5668\u5728\u65f6\u95f4\u76f8\u5173\u4e0a\u4e0b\u6587\u4e2d\u7684\u68c0\u7d22\u80fd\u529b\uff0c\u4ece\u800c\u6539\u5584RAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709RAG\u7cfb\u7edf\u4e2d\u68c0\u7d22\u5668\u65e0\u6cd5\u6709\u6548\u68c0\u7d22\u65f6\u95f4\u76f8\u5173\u4e0a\u4e0b\u6587\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u5f71\u54cd\u4e0b\u6e38\u751f\u6210\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u4e00\u79cd\u53eb\u505aTemporal-aware Matryoshka Representation Learning (TMRL)\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528Matryoshka\u5d4c\u5165\u7684\u5d4c\u5957\u7ed3\u6784\u6765\u6dfb\u52a0\u4e00\u4e2a\u65f6\u95f4\u5b50\u7a7a\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e00\u822c\u7684\u8bed\u4e49\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTMRL\u80fd\u591f\u6709\u6548\u5730\u9002\u5e94\u591a\u79cd\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u65f6\u95f4\u68c0\u7d22\u548c\u65f6\u95f4RAG\u8868\u73b0\u4e0a\u4e0e\u4e4b\u524d\u57fa\u4e8eMatryoshka\u4f46\u4e0d\u8003\u8651\u65f6\u95f4\u7684\u65b9\u6cd5\u4ee5\u53ca\u5148\u524d\u7684\u65f6\u95f4\u611f\u77e5\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u8fd8\u5141\u8bb8\u7075\u6d3b\u8c03\u6574\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "conclusion": "TMRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6539\u8fdb\u68c0\u7d22\u5668\u5904\u7406\u65f6\u95f4\u76f8\u5173\u4fe1\u606f\u80fd\u529b\u7684\u6709\u6548\u624b\u6bb5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6574\u4f53RAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2601.05593", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05593", "abs": "https://arxiv.org/abs/2601.05593", "authors": ["Jingcheng Hu", "Yinmin Zhang", "Shijie Shang", "Xiaobo Yang", "Yue Peng", "Zhewei Huang", "Hebin Zhou", "Xin Wu", "Jie Cheng", "Fanqi Wan", "Xiangwen Kong", "Chengyuan Yao", "Kaiwen Yan", "Ailin Huang", "Hongyu Zhou", "Qi Han", "Zheng Ge", "Daxin Jiang", "Xiangyu Zhang", "Heung-Yeung Shum"], "title": "PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning", "comment": null, "summary": "We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u6846\u67b6Parallel Coordinated Reasoning (PaCoRe)\uff0c\u65e8\u5728\u514b\u670d\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u4e0a\u7684\u9650\u5236\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5e76\u884c\u63a2\u7d22\u4e0e\u6d88\u606f\u4f20\u9012\u67b6\u6784\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u8d85\u51fa\u4e0a\u4e0b\u6587\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u6269\u5c55\u81f3\u6570\u767e\u4e07\u6807\u8bb0\u7684\u6709\u6548\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u7684\u4e00\u4e2a\u6838\u5fc3\u5c40\u9650\u662f\u5b83\u4eec\u96be\u4ee5\u5c06\u6d4b\u8bd5\u65f6\u7684\u8ba1\u7b97\u91cf\u663e\u8457\u6269\u5927\u5230\u56fa\u5b9a\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e4b\u5916\u7684\u987a\u5e8f\u63a8\u7406\u4e4b\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86Parallel Corored Reasoning\uff08PaCoRe\uff09\uff0c\u4e00\u4e2a\u91c7\u7528\u591a\u8f6e\u6b21\u6d88\u606f\u4f20\u9012\u67b6\u6784\u534f\u8c03\u7684\u5927\u89c4\u6a21\u5e76\u884c\u63a2\u7d22\u8bad\u7ec3\u4e0e\u63a8\u7406\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u6bcf\u8f6e\u751f\u6210\u8bb8\u591a\u5e76\u884c\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u5c06\u7ed3\u679c\u538b\u7f29\u6210\u4e0a\u4e0b\u6587\u6709\u9650\u7684\u6d88\u606f\u6765\u6307\u5bfc\u4e0b\u4e00\u8f6e\u76f4\u81f3\u5f97\u5230\u6700\u7ec8\u7b54\u6848\u3002\u6574\u4e2a\u7cfb\u7edf\u901a\u8fc7\u5927\u89c4\u6a21\u57fa\u4e8e\u7ed3\u679c\u7684\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5730\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u7279\u522b\u662f\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1a80\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u5728HMMT 2025\u4e0a\u8fbe\u5230\u4e8694.5%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86GPT-5\u768493.2%\uff0c\u540c\u65f6\u6709\u6548\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u8fbe\u5230\u4e86\u5927\u7ea6\u4e24\u767e\u4e07\u4e2a\u4ee4\u724c\u3002", "conclusion": "PaCoRe\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5229\u7528\u5e76\u884c\u5904\u7406\u548c\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u6210\u529f\u5730\u5c06\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u91cf\u6269\u5c55\u5230\u4e86\u524d\u6240\u672a\u6709\u7684\u6c34\u5e73\uff0c\u4ece\u800c\u5728\u5305\u62ec\u6570\u5b66\u5728\u5185\u7684\u591a\u4e2a\u9886\u57df\u5185\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002\u6b64\u5916\uff0c\u7814\u7a76\u56e2\u961f\u8fd8\u5f00\u6e90\u4e86\u6a21\u578b\u68c0\u67e5\u70b9\u3001\u8bad\u7ec3\u6570\u636e\u4ee5\u53ca\u5b8c\u6574\u7684\u63a8\u7406\u6d41\u7a0b\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2601.05588", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05588", "abs": "https://arxiv.org/abs/2601.05588", "authors": ["Benjamin Rozonoyer", "Chong You", "Michael Boratko", "Himanshu Jain", "Nilesh Gupta", "Srinadh Bhojanapalli", "Andrew McCallum", "Felix Yu"], "title": "Autoregressive Ranking: Bridging the Gap Between Dual and Cross Encoders", "comment": "22 pages, 5 figures", "summary": "Dual and cross encoders have long been mainstays of information retrieval (IR), but are being challenged by the emergent capabilities of LLMs. An LLM-based approach we term pointwise generative ranking - generating tokens the length of a single docID as opposed to a list in order to enable ranking via beam search - combines efficiency and expressivity benefits while leveraging the in-context capabilities of Causal Transformers. Although there is ample evidence to suggest that pretrained LLMs are well-suited for ranking, we find that the vast majority of LLM-based approaches rely on next-token prediction, a loss function which is fundamentally rank-agnostic (and especially so with pointwise supervision). In this paper, we first prove that the expressivity of pointwise generative ranking with multi-token docIDs is superior to that of dual encoders. We then propose SToICaL - a Simple Token-Item Calibrated Loss - which can incorporate rank-aware supervision at both the item and token levels within the pointwise setup. We run a suite of experiments on ranking tasks derived from WordNet (Fellbaum, 1998) and ESCI (Reddy et al., arXiv:2206.06588). Two variants of SToICaL successfully suppress the probability of invalid docID generations and improve on common ranking metrics beyond top-1 retrieval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u70b9\u751f\u6210\u6392\u540d\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u591a\u6807\u8bb0\u6587\u6863ID\u4e0a\u7684\u8868\u8fbe\u80fd\u529b\u4f18\u4e8e\u53cc\u7f16\u7801\u5668\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570SToICaL\uff0c\u8be5\u51fd\u6570\u53ef\u4ee5\u5728\u70b9\u5f0f\u8bbe\u7f6e\u4e2d\u540c\u65f6\u5728\u9879\u76ee\u548c\u6807\u8bb0\u7ea7\u522b\u4e0a\u6574\u5408\u6392\u540d\u611f\u77e5\u76d1\u7763\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSToICaL\u80fd\u591f\u6291\u5236\u65e0\u6548\u6587\u6863ID\u751f\u6210\u7684\u6982\u7387\uff0c\u5e76\u4e14\u5728\u5e38\u89c1\u7684\u6392\u540d\u6307\u6807\u4e0a\u8d85\u8d8a\u4e86\u9876\u7ea7\u68c0\u7d22\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u6709\u5927\u91cf\u8bc1\u636e\u8868\u660e\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u975e\u5e38\u9002\u5408\u6392\u540d\u4efb\u52a1\uff0c\u4f46\u5927\u591a\u6570\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\uff0c\u8fd9\u662f\u4e00\u79cd\u672c\u8d28\u4e0a\u4e0d\u8003\u8651\u6392\u540d\u7684\u635f\u5931\u51fd\u6570\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u70b9\u751f\u6210\u6392\u540d\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u7ed3\u5408\u6548\u7387\u4e0e\u8868\u8fbe\u529b\u7684\u4f18\u52bf\uff0c\u5e76\u5229\u7528\u56e0\u679c\u53d8\u6362\u5668\u7684\u4e0a\u4e0b\u6587\u80fd\u529b\u6765\u5b9e\u73b0\u6392\u540d\u3002", "method": "\u9996\u5148\uff0c\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u5f53\u4f7f\u7528\u591a\u4ee4\u724c\u6587\u6863ID\u65f6\uff0c\u70b9\u751f\u6210\u6392\u540d\u65b9\u6cd5\u6bd4\u5bf9\u5076\u7f16\u7801\u5668\u5177\u6709\u66f4\u9ad8\u7684\u8868\u8fbe\u529b\u3002\u63a5\u7740\uff0c\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b80\u5316\u7684\u4ee4\u724c-\u9879\u76ee\u6821\u51c6\u635f\u5931\u51fd\u6570SToICaL\uff0c\u5b83\u80fd\u591f\u5728\u5355\u4e2a\u9879\u76ee\u7684\u6846\u67b6\u4e0b\u540c\u65f6\u63d0\u4f9b\u9488\u5bf9\u9879\u76ee\u7ea7\u548c\u4ee4\u724c\u7ea7\u7684\u6392\u540d\u654f\u611f\u76d1\u7763\u3002", "result": "\u5b9e\u9a8c\u90e8\u5206\u91c7\u7528\u4e86WordNet\u4ee5\u53caESCI\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002\u7ed3\u679c\u663e\u793a\uff0cSToICaL\u7684\u4e24\u79cd\u53d8\u4f53\u90fd\u80fd\u591f\u6709\u6548\u51cf\u5c11\u9519\u8bef\u6587\u6863ID\u751f\u6210\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u4e14\u76f8\u6bd4\u4f20\u7edf\u7684\u4ec5\u5173\u6ce8\u7b2c\u4e00\u9879\u68c0\u7d22\u6548\u679c\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5728\u591a\u4e2a\u6392\u540d\u5ea6\u91cf\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u7528\u9002\u5f53\u7684\u635f\u5931\u51fd\u6570\u5982SToICaL\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u57fa\u4e8eLLM\u7684\u70b9\u751f\u6210\u6392\u540d\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9700\u8981\u9ad8\u7cbe\u5ea6\u6392\u540d\u7684\u5e94\u7528\u573a\u666f\u4e2d\u3002"}}
{"id": "2601.05597", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05597", "abs": "https://arxiv.org/abs/2601.05597", "authors": ["S\u00edlvia Casacuberta", "Moritz Hardt"], "title": "Good Allocations from Bad Estimates", "comment": null, "summary": "Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $\u03b5> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/\u03b5^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $\u03b5$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/\u03b5)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u81ea\u7136\u5904\u7406\u6548\u5e94\u5206\u5e03\u4e0b\u4ec5\u4f7f\u7528$O(M/\u03b5)$\u6837\u672c\u8fbe\u5230\u4e0eCATE\u76f8\u540c\u7684\u603b\u4f53\u6cbb\u7597\u6548\u679c\u3002\u6b64\u5916\uff0c\u9884\u7b97\u7075\u6d3b\u6027\u8fd8\u53ef\u4ee5\u8fdb\u4e00\u6b65\u51cf\u5c11\u5206\u914d\u6240\u9700\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684CATE\u4f30\u8ba1\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u6709\u6548\u5730\u9488\u5bf9\u5f02\u8d28\u6027\u4eba\u7fa4\u8fdb\u884c\u6cbb\u7597\u76ee\u6807\u5b9a\u4f4d\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684\u6837\u672c\uff08$O(M/\u03b5^2)$\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8f83\u5c11\u7684\u6837\u672c\u6765\u5b9e\u73b0\u8fd1\u4f3c\u6700\u4f18\u7684\u6cbb\u7597\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u603b\u4f53\u6cbb\u7597\u6548\u679c\u3002", "method": "\u5229\u7528\u7c97\u7565\u4f30\u8ba1\u8db3\u4ee5\u652f\u6301\u8fd1\u4e4e\u6700\u4f18\u7684\u6cbb\u7597\u5206\u914d\u8fd9\u4e00\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u4e14\u8003\u8651\u4e86\u9884\u7b97\u7075\u6d3b\u6027\u5bf9\u8fdb\u4e00\u6b65\u51cf\u5c11\u6837\u672c\u590d\u6742\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u5404\u79cd\u771f\u5b9e\u4e16\u754c\u7684RCT\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6240\u6709\u60c5\u51b5\u4e0b\uff0c\u5b83\u90fd\u80fd\u4ee5\u60ca\u4eba\u7684\u5c11\u91cf\u6837\u672c\u627e\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u6cbb\u7597\u5206\u914d\u65b9\u6848\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u548c\u6cbb\u7597\u5206\u914d\u4e4b\u95f4\u7684\u6839\u672c\u533a\u522b\uff1a\u540e\u8005\u9700\u8981\u7684\u6837\u672c\u8981\u5c11\u5f97\u591a\u3002"}}
{"id": "2601.05603", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05603", "abs": "https://arxiv.org/abs/2601.05603", "authors": ["Watheq Mansour", "J. Shane Culpepper", "Joel Mackenzie", "Andrew Yates"], "title": "Revisiting Human-vs-LLM judgments using the TREC Podcast Track", "comment": "The paper has been accepted to appear at ECIR 2026", "summary": "Using large language models (LLMs) to annotate relevance is an increasingly important technique in the information retrieval community. While some studies demonstrate that LLMs can achieve high user agreement with ground truth (human) judgments, other studies have argued for the opposite conclusion. To the best of our knowledge, these studies have primarily focused on classic ad-hoc text search scenarios. In this paper, we conduct an analysis on user agreement between LLM and human experts, and explore the impact disagreement has on system rankings. In contrast to prior studies, we focus on a collection composed of audio files that are transcribed into two-minute segments -- the TREC 2020 and 2021 podcast track. We employ five different LLM models to re-assess all of the query-segment pairs, which were originally annotated by TREC assessors. Furthermore, we re-assess a small subset of pairs where LLM and TREC assessors have the highest disagreement, and found that the human experts tend to agree with LLMs more than with the TREC assessors. Our results reinforce the previous insights of Sormunen in 2002 -- that relying on a single assessor leads to lower user agreement.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u97f3\u9891\u6587\u4ef6\u8f6c\u5f55\u7247\u6bb5\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5206\u6b67\u5bf9\u7cfb\u7edf\u6392\u540d\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5b58\u5728\u8f83\u5927\u5206\u6b67\u7684\u60c5\u51b5\u4e0b\uff0c\u4eba\u7c7b\u4e13\u5bb6\u66f4\u503e\u5411\u4e8e\u540c\u610fLLMs\u7684\u5224\u65ad\uff0c\u800c\u975eTREC\u8bc4\u4f30\u5458\u7684\u539f\u59cb\u6807\u6ce8\u3002", "motivation": "\u9274\u4e8e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u76f8\u5173\u6027\u6807\u6ce8\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u4f46\u4e0d\u540c\u7814\u7a76\u5bf9\u4e8eLLMs\u80fd\u5426\u8fbe\u5230\u4e0e\u771f\u5b9e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\u6027\u7684\u7ed3\u8bba\u5b58\u5728\u4e89\u8bae\u3002\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790LLMs\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5e76\u7279\u522b\u5173\u6ce8\u4e8e\u7531\u97f3\u9891\u6587\u4ef6\u8f6c\u5f55\u800c\u6765\u7684\u6587\u672c\u6570\u636e\u96c6\u4e0a\u8fd9\u4e00\u73b0\u8c61\u7684\u8868\u73b0\u3002", "method": "\u9009\u53d6TREC 2020\u548c2021\u5e74\u64ad\u5ba2\u8ffd\u8e2a\u9879\u76ee\u4e2d\u7684\u97f3\u9891\u6587\u4ef6\u8f6c\u5f55\u4e3a\u4e24\u5206\u949f\u7247\u6bb5\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\uff1b\u5229\u7528\u4e94\u79cd\u4e0d\u540c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u8bc4\u4f30\u6240\u6709\u67e5\u8be2-\u7247\u6bb5\u5bf9\uff1b\u5bf9LLMs\u4e0eTREC\u8bc4\u4f30\u5458\u610f\u89c1\u5206\u6b67\u6700\u5927\u7684\u4e00\u5c0f\u90e8\u5206\u6837\u672c\u8fdb\u884c\u4e86\u518d\u6b21\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u5f53LLMs\u4e0eTREC\u8bc4\u4f30\u5458\u95f4\u5b58\u5728\u663e\u8457\u5206\u6b67\u65f6\uff0c\u4eba\u7c7b\u4e13\u5bb6\u5b9e\u9645\u4e0a\u66f4\u8d5e\u540cLLMs\u7684\u89c2\u70b9\u3002\u8fd9\u652f\u6301\u4e86Sormunen\u4e8e2002\u5e74\u63d0\u51fa\u7684\u89c2\u70b9\u2014\u2014\u4f9d\u8d56\u5355\u4e00\u8bc4\u4f30\u8005\u4f1a\u5bfc\u81f4\u8f83\u4f4e\u7684\u4e00\u81f4\u6027\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5904\u7406\u7279\u5b9a\u7c7b\u578b\u7684\u591a\u5a92\u4f53\u5185\u5bb9\u5982\u97f3\u9891\u8f6c\u5f55\u6587\u672c\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8865\u5145\u6216\u66ff\u4ee3\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u5b83\u4e5f\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u8003\u8651\u591a\u4e2a\u6765\u6e90\u610f\u89c1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.05607", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05607", "abs": "https://arxiv.org/abs/2601.05607", "authors": ["Zijun Min", "Bingshuai Liu", "Ante Wang", "Long Zhang", "Anxiang Zeng", "Haibo Zhang", "Jinsong Su"], "title": "Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising framework for optimizing large language models in reasoning tasks. However, existing RLVR algorithms focus on different granularities, and each has complementary strengths and limitations. Group Relative Policy Optimization (GRPO) updates the policy with token-level importance ratios, which preserves fine-grained credit assignment but often suffers from high variance and instability. In contrast, Group Sequence Policy Optimization (GSPO) applies single sequence-level importance ratios across all tokens in a response that better matches sequence-level rewards, but sacrifices token-wise credit assignment. In this paper, we propose Dynamic Hybrid Policy Optimization (DHPO) to bridge GRPO and GSPO within a single clipped surrogate objective. DHPO combines token-level and sequence-level importance ratios using weighting mechanisms. We explore two variants of the mixing mechanism, including an averaged mixing and an entropy-guided mixing. To further stabilize training, we employ a branch-specific clipping strategy that constrains token-level and sequence-level ratios within separate trust regions before mixing, preventing outliers in either branch from dominating the update. Across seven challenging mathematical reasoning benchmarks, experiments on both dense and MoE models from the Qwen3 series show that DHPO consistently outperforms GRPO and GSPO. We will release our code upon acceptance of this paper.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u52a8\u6001\u6df7\u5408\u7b56\u7565\u4f18\u5316\uff08DHPO\uff09\uff0c\u7ed3\u5408\u4e86GRPO\u548cGSPO\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u52a0\u6743\u673a\u5236\u878d\u5408\u4e86token\u7ea7\u522b\u548c\u5e8f\u5217\u7ea7\u522b\u7684\u91cd\u8981\u6027\u6bd4\u7387\uff0c\u5e76\u91c7\u7528\u5206\u652f\u7279\u5b9a\u7684\u88c1\u526a\u7b56\u7565\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e03\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDHPO\u7684\u8868\u73b0\u4f18\u4e8eGRPO\u548cGSPO\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u7b97\u6cd5\u5728\u4e0d\u540c\u7c92\u5ea6\u4e0a\u5de5\u4f5c\uff0c\u5404\u6709\u4f18\u52bf\u4e0e\u5c40\u9650\u3002GRPO\u867d\u7136\u4fdd\u6301\u4e86\u7ec6\u7c92\u5ea6\u7684\u4fe1\u7528\u5206\u914d\u4f46\u5e38\u9762\u4e34\u9ad8\u65b9\u5dee\u548c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff1b\u800cGSPO\u867d\u66f4\u597d\u5730\u5339\u914d\u5e8f\u5217\u7ea7\u5956\u52b1\uff0c\u5374\u727a\u7272\u4e86token\u7ea7\u522b\u7684\u4fe1\u7528\u5206\u914d\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u4ee5\u7efc\u5408\u4e24\u8005\u4f18\u70b9\u3002", "method": "\u63d0\u51fa\u4e86Dynamic Hybrid Policy Optimization (DHPO)\uff0c\u5b83\u5728\u4e00\u4e2a\u5355\u4e00\u88c1\u526a\u66ff\u4ee3\u76ee\u6807\u5185\u7ed3\u5408\u4e86GRPO\u548cGSPO\u7684\u7279\u70b9\u3002DHPO\u4f7f\u7528\u52a0\u6743\u673a\u5236\u7ed3\u5408\u4e86token\u7ea7\u548c\u5e8f\u5217\u7ea7\u7684\u91cd\u8981\u6027\u6bd4\u7387\uff0c\u5e76\u63a2\u7d22\u4e86\u4e24\u79cd\u6df7\u5408\u673a\u5236\u53d8\u4f53\uff1a\u5e73\u5747\u6df7\u5408\u4e0e\u71b5\u6307\u5bfc\u6df7\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u5206\u652f\u7279\u5f02\u6027\u88c1\u526a\u7b56\u7565\u6765\u8fdb\u4e00\u6b65\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u4e03\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u9488\u5bf9Qwen3\u7cfb\u5217\u4e2d\u7684\u5bc6\u96c6\u578b\u6a21\u578b\u548cMoE\u6a21\u578b\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDHPO\u76f8\u6bd4GRPO\u548cGSPO\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4f18\u52bf\u3002", "conclusion": "DHPO\u901a\u8fc7\u6709\u6548\u6574\u5408GRPO\u4e0eGSPO\u7684\u4f18\u52bf\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u4f18\u5316\u65b9\u5411\u3002"}}
{"id": "2601.05649", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05649", "abs": "https://arxiv.org/abs/2601.05649", "authors": ["Giulio D'Erasmo", "Cesare Campagnano", "Antonio Mallia", "Pierpaolo Brutti", "Nicola Tonellotto", "Fabrizio Silvestri"], "title": "Statistical Foundations of DIME: Risk Estimation for Practical Index Selection", "comment": "Accepted to EACL 2026 (Main Conference)", "summary": "High-dimensional dense embeddings have become central to modern Information Retrieval, but many dimensions are noisy or redundant. Recently proposed DIME (Dimension IMportance Estimation), provides query-dependent scores to identify informative components of embeddings. DIME relies on a costly grid search to select a priori a dimensionality for all the query corpus's embeddings. Our work provides a statistically grounded criterion that directly identifies the optimal set of dimensions for each query at inference time. Experiments confirm achieving parity of effectiveness and reduces embedding size by an average of $\\sim50\\%$ across different models and datasets at inference time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u8ba1\u5b66\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u76f4\u63a5\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u786e\u5b9a\u6700\u4f73\u7ef4\u5ea6\u96c6\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u6548\u679c\u7684\u540c\u65f6\u5e73\u5747\u51cf\u5c11\u7ea650%\u7684\u5d4c\u5165\u5927\u5c0f\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u7ef4\u5bc6\u96c6\u5d4c\u5165\u6280\u672f\u867d\u7136\u5bf9\u4e8e\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b58\u5728\u5f88\u591a\u566a\u58f0\u6216\u5197\u4f59\u7ef4\u5ea6\u3002DIME\uff08Dimension Importance Estimation\uff09\u867d\u80fd\u63d0\u4f9b\u67e5\u8be2\u4f9d\u8d56\u6027\u7684\u8bc4\u5206\u6765\u8bc6\u522b\u5d4c\u5165\u4e2d\u7684\u4fe1\u606f\u6210\u5206\uff0c\u4f46\u5176\u9700\u8981\u901a\u8fc7\u6602\u8d35\u7684\u7f51\u683c\u641c\u7d22\u9884\u5148\u9009\u5b9a\u6240\u6709\u67e5\u8be2\u8bed\u6599\u5e93\u5d4c\u5165\u7684\u7ef4\u5ea6\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7edf\u8ba1\u7684\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u95f4\u76f4\u63a5\u786e\u5b9a\u6bcf\u4e2a\u67e5\u8be2\u7684\u6700\u4f73\u7ef4\u5ea6\u96c6\u5408\uff0c\u65e0\u9700\u4e8b\u5148\u5bf9\u6574\u4e2a\u67e5\u8be2\u8bed\u6599\u5e93\u8fdb\u884c\u7ef4\u5ea6\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u8fbe\u5230\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u6709\u6548\u6027\uff0c\u800c\u4e14\u80fd\u591f\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u5c06\u5d4c\u5165\u5927\u5c0f\u5e73\u5747\u51cf\u5c11\u7ea650%\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u7edf\u8ba1\u5b66\u6807\u51c6\u80fd\u591f\u5728\u4fdd\u8bc1\u68c0\u7d22\u6548\u679c\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u5d4c\u5165\u5411\u91cf\u7684\u7ef4\u5ea6\uff0c\u8fdb\u800c\u63d0\u9ad8\u6548\u7387\u3002"}}
{"id": "2601.05613", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05613", "abs": "https://arxiv.org/abs/2601.05613", "authors": ["Yiming Zhou", "Mingyue Cheng", "Hao Wang", "Enhong Chen"], "title": "PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes", "comment": null, "summary": "Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPiXTime\u7684\u65b0\u578b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u73af\u5883\uff0c\u89e3\u51b3\u4e86\u4e0d\u540c\u8282\u70b9\u95f4\u56e0\u91c7\u6837\u6807\u51c6\u4e0d\u540c\u5bfc\u81f4\u7684\u65f6\u95f4\u7c92\u5ea6\u548c\u53d8\u91cf\u96c6\u5dee\u5f02\u95ee\u9898\u3002\u901a\u8fc7\u4e2a\u6027\u5316Patch Embedding\u4e0e\u5168\u5c40VE\u8868\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u591a\u7c92\u5ea6\u3001\u5f02\u6784\u53d8\u91cf\u96c6\u7684\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9645\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u56e0\u5176\u9ad8\u4ef7\u503c\u800c\u96be\u4ee5\u8de8\u8282\u70b9\u5171\u4eab\uff0c\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u5229\u7528\u5206\u5e03\u5f0f\u65f6\u95f4\u6570\u636e\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u4e0d\u540c\u7684\u91c7\u6837\u6807\u51c6\u9020\u6210\u4e86\u5404\u8282\u70b9\u95f4\u65f6\u95f4\u7c92\u5ea6\u53ca\u53d8\u91cf\u96c6\u5408\u7684\u4e0d\u540c\uff0c\u8fd9\u5bf9\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u6784\u6210\u4e86\u6311\u6218\u3002", "method": "PiXTime\u91c7\u7528\u4e2a\u6027\u5316\u7684Patch Embedding\u6280\u672f\u5c06\u7279\u5b9a\u4e8e\u8282\u70b9\u7684\u65f6\u95f4\u7c92\u5ea6\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u7edf\u4e00\u7ef4\u5ea6\u7684\u4ee4\u724c\u5e8f\u5217\u4f9b\u540e\u7eed\u5171\u4eab\u6a21\u578b\u5904\u7406\uff0c\u5e76\u4f7f\u7528\u5168\u5c40VE\u8868\u6765\u5bf9\u9f50\u8de8\u8282\u70b9\u7684\u53d8\u91cf\u7c7b\u522b\u8bed\u4e49\uff0c\u4ece\u800c\u63d0\u9ad8\u8de8\u8282\u70b9\u53ef\u8f6c\u79fb\u6027\u3002\u6b64\u5916\uff0c\u57fa\u4e8eTransformer\u7684\u5171\u4eab\u6a21\u578b\u80fd\u591f\u6355\u6349\u5177\u6709\u4efb\u610f\u6570\u91cf\u53d8\u91cf\u7684\u8f85\u52a9\u5e8f\u5217\u8868\u793a\uff0c\u5e76\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u76ee\u6807\u5e8f\u5217\u7684\u9884\u6d4b\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPiXTime\u5728\u8054\u90a6\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u516b\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u73b0\u5b9e\u4e16\u754c\u4f20\u7edf\u57fa\u51c6\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u8868\u73b0\u3002", "conclusion": "PiXTime\u4f5c\u4e3a\u4e13\u4e3a\u8054\u90a6\u5b66\u4e60\u8bbe\u8ba1\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u8de8\u8282\u70b9\u5b58\u5728\u591a\u7c92\u5ea6\u548c\u5f02\u6784\u53d8\u91cf\u96c6\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u6027\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u5728\u591a\u79cd\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.05647", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05647", "abs": "https://arxiv.org/abs/2601.05647", "authors": ["Xinyue Wang", "Stephen Wang", "Biwei Huang"], "title": "Transformer Is Inherently a Causal Learner", "comment": null, "summary": "We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\uff0c\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u8bad\u7ec3\u7684transformer\u80fd\u591f\u81ea\u7136\u5730\u5728\u5176\u5b66\u4e60\u5230\u7684\u8868\u793a\u4e2d\u7f16\u7801\u65f6\u95f4\u5ef6\u8fdf\u7684\u56e0\u679c\u7ed3\u6784\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u8fc7\u53bb\u8f93\u5165\u7684\u68af\u5ea6\u654f\u611f\u6027\u53ef\u4ee5\u76f4\u63a5\u6062\u590d\u5e95\u5c42\u7684\u56e0\u679c\u56fe\uff0c\u65e0\u9700\u660e\u786e\u7684\u56e0\u679c\u76ee\u6807\u6216\u7ed3\u6784\u7ea6\u675f\u3002\u8fd9\u4e00\u65b9\u6cd5\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u3001\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u53ca\u975e\u5e73\u7a33\u7cfb\u7edf\u7b49\u590d\u6742\u60c5\u51b5\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5f02\u8d28\u6027\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u6700\u5148\u8fdb\u7684\u53d1\u73b0\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u968f\u7740\u6570\u636e\u91cf\u548c\u5f02\u8d28\u6027\u7684\u589e\u52a0\uff0c\u8be5\u65b9\u6cd5\u663e\u793a\u51fa\u56e0\u679c\u51c6\u786e\u5ea6\u63d0\u9ad8\u7684\u6f5c\u529b\uff0c\u8fd9\u662f\u4f20\u7edf\u65b9\u6cd5\u6240\u7f3a\u4e4f\u7684\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u81ea\u56de\u5f52\u8bad\u7ec3\u7684transformer\u662f\u5426\u80fd\u591f\u5728\u6ca1\u6709\u660e\u786e\u56e0\u679c\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u7136\u5730\u5b66\u4e60\u5e76\u8868\u8fbe\u51fa\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u5bf9\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u8bad\u7ec3\u7528\u4e8e\u9884\u6d4b\u672a\u6765\u503c\u7684transformer\u6a21\u578b\u8f93\u51fa\u76f8\u5bf9\u4e8e\u8fc7\u53bb\u8f93\u5165\u7684\u68af\u5ea6\u654f\u611f\u6027\u8fdb\u884c\u5206\u6790\uff0c\u76f4\u63a5\u6062\u590d\u51fa\u5e95\u5c42\u56e0\u679c\u56fe\u3002\u57fa\u4e8e\u6807\u51c6\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u4e0b\u7684\u7406\u8bba\u8bc1\u660e\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u4f7f\u7528\u805a\u5408\u68af\u5ea6\u5f52\u56e0\u7684\u5b9e\u9645\u63d0\u53d6\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5904\u7406\u975e\u7ebf\u6027\u52a8\u6001\u3001\u957f\u4f9d\u8d56\u5173\u7cfb\u53ca\u975e\u5e73\u7a33\u7cfb\u7edf\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u65f6\uff0c\u672c\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u53d1\u73b0\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5f02\u8d28\u6027\u8f83\u9ad8\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002\u800c\u4e14\uff0c\u968f\u7740\u6570\u636e\u91cf\u4e0e\u5f02\u8d28\u6027\u7684\u589e\u52a0\uff0c\u56e0\u679c\u51c6\u786e\u6027\u4e5f\u5f97\u5230\u4e86\u63d0\u5347\uff0c\u8fd9\u4e00\u70b9\u662f\u4f20\u7edf\u65b9\u6cd5\u4e0d\u5177\u5907\u7684\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u8fd9\u79cd\u7edf\u4e00\u7684\u89c2\u70b9\u4e3a\u672a\u6765\u7684\u8303\u5f0f\u5960\u5b9a\u4e86\u57fa\u7840\uff1a\u4e00\u65b9\u9762\uff0c\u56e0\u679c\u53d1\u73b0\u53ef\u4ee5\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u7684\u89d2\u5ea6\u6765\u5b9e\u73b0\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u57fa\u7840\u6a21\u578b\u4e5f\u53ef\u4ee5\u901a\u8fc7\u56e0\u679c\u89c6\u89d2\u83b7\u5f97\u53ef\u89e3\u91ca\u6027\u548c\u589e\u5f3a\u3002"}}
{"id": "2601.05650", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05650", "abs": "https://arxiv.org/abs/2601.05650", "authors": ["Miguel Matey-Sanz", "Joaqu\u00edn Torres-Sospedra", "Joaqu\u00edn Huerta", "Sergio Trilles"], "title": "From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation", "comment": "20 pages, 9 figures, 6 tables", "summary": "Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5\u6765\u7ed3\u6784\u5316Wi-Fi\u6307\u7eb9\u6570\u636e\u96c6\uff0c\u4ee5\u63d0\u9ad8\u5ba4\u5185\u5b9a\u4f4d\u7cbe\u5ea6\u3002\u901a\u8fc7\u7a7a\u95f4\u6216\u65e0\u7ebf\u7535\u7279\u5f81\u5bf9\u6307\u7eb9\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5efa\u7b51\u6216\u697c\u5c42\u7ea7\u522b\u5e94\u7528\u805a\u7c7b\u3002\u5b9a\u4f4d\u9636\u6bb5\u4f7f\u7528\u6700\u5f3a\u63a5\u5165\u70b9\u7684\u805a\u7c7b\u4f30\u8ba1\u7a0b\u5e8f\u5c06\u672a\u89c1\u7684\u6307\u7eb9\u5206\u914d\u7ed9\u6700\u76f8\u5173\u7684\u805a\u7c7b\u4e2d\u3002\u7136\u540e\u4ec5\u5728\u9009\u5b9a\u7684\u805a\u7c7b\u5185\u6267\u884c\u5b9a\u4f4d\uff0c\u4ece\u800c\u5141\u8bb8\u5b66\u4e60\u6a21\u578b\u64cd\u4f5c\u4e8e\u66f4\u5c0f\u4e14\u66f4\u4e00\u81f4\u7684\u6570\u636e\u5b50\u96c6\u4e0a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u4e86\u5b9a\u4f4d\u8bef\u5dee\uff0c\u7279\u522b\u662f\u5728\u5efa\u7b51\u7269\u7ea7\u522b\u7684\u7b56\u7565\u4e0b\uff0c\u4f46\u4ee3\u4ef7\u662f\u964d\u4f4e\u4e86\u697c\u5c42\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684Wi-Fi\u6307\u7eb9\u5ba4\u5185\u5b9a\u4f4d\u6280\u672f\u6027\u80fd\u53d7\u9650\u4e8e\u6307\u7eb9\u6570\u636e\u96c6\u7684\u5927\u5c0f\u548c\u5f02\u8d28\u6027\u3001\u4fe1\u53f7\u5f3a\u5ea6\u6307\u793a\u5668\u7684\u53ef\u53d8\u6027\u4ee5\u53ca\u5927\u8303\u56f4\u591a\u5c42\u73af\u5883\u4e2d\u7684\u6a21\u7cca\u6027\u3002\u8fd9\u4e9b\u56e0\u7d20\u663e\u8457\u964d\u4f4e\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5f53\u5168\u5c40\u6a21\u578b\u4e0d\u8003\u8651\u7ed3\u6784\u7ea6\u675f\u65f6\u76f4\u63a5\u5e94\u7528\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u65b9\u6cd5\uff0c\u5728\u5b9a\u4f4d\u4e4b\u524d\u5148\u5bf9\u6307\u7eb9\u6570\u636e\u96c6\u8fdb\u884c\u7ed3\u6784\u5316\u5904\u7406\u3002\u6839\u636e\u7a7a\u95f4\u6216\u65e0\u7ebf\u7535\u7279\u6027\u5bf9\u6307\u7eb9\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u53ef\u5728\u5efa\u7b51\u6216\u697c\u5c42\u5c42\u9762\u5b9e\u65bd\u805a\u7c7b\u3002\u5bf9\u4e8e\u65b0\u51fa\u73b0\u7684\u6307\u7eb9\uff0c\u57fa\u4e8e\u6700\u5f3a\u63a5\u5165\u70b9\u7684\u805a\u7c7b\u4f30\u8ba1\u8fc7\u7a0b\u5c06\u5176\u5206\u914d\u7ed9\u6700\u76f8\u5173\u7684\u7c07\u5185\u3002\u968f\u540e\uff0c\u4ec5\u5728\u9009\u5b9a\u7684\u7c07\u5185\u6267\u884c\u5b9a\u4f4d\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u5bf9\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u53ca\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6301\u7eed\u51cf\u5c11\u5b9a\u4f4d\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u91c7\u7528\u5efa\u7b51\u7ea7\u7b56\u7565\u65f6\u6548\u679c\u660e\u663e\uff1b\u4e0d\u8fc7\uff0c\u8fd9\u540c\u65f6\u4e5f\u5bfc\u81f4\u4e86\u697c\u5c42\u8bc6\u522b\u51c6\u786e\u5ea6\u6709\u6240\u4e0b\u964d\u3002", "conclusion": "\u660e\u786e\u5730\u901a\u8fc7\u805a\u7c7b\u6765\u7ed3\u6784\u5316\u6570\u636e\u96c6\u662f\u4e00\u79cd\u6709\u6548\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u3002\u5c3d\u7ba1\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u4f1a\u5f71\u54cd\u697c\u5c42\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u603b\u4f53\u4e0a\u63d0\u9ad8\u4e86\u6574\u4f53\u5b9a\u4f4d\u7cbe\u5ea6\u3002"}}
{"id": "2601.05679", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05679", "abs": "https://arxiv.org/abs/2601.05679", "authors": ["George Ma", "Zhongyuan Liang", "Irene Y. Chen", "Somayeh Sojoudi"], "title": "Do Sparse Autoencoders Identify Reasoning Features in Language Models?", "comment": null, "summary": "We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u901a\u8fc7\u5bf9\u6bd4\u65b9\u6cd5\u8bc6\u522b\u51fa\u7684\u63a8\u7406\u7279\u5f81\u4e3b\u8981\u6355\u6349\u7684\u662f\u63a8\u7406\u7684\u8bed\u8a00\u76f8\u5173\u6027\uff0c\u800c\u975e\u5b9e\u9645\u7684\u63a8\u7406\u8ba1\u7b97\u8fc7\u7a0b\u672c\u8eab\u3002\u8fd9\u4e9b\u7279\u5f81\u5bf9\u8bcd\u6c47\u5c42\u9762\u7684\u5e72\u9884\u975e\u5e38\u654f\u611f\uff0c\u4e14\u64cd\u7eb5\u8fd9\u4e9b\u7279\u5f81\u5bf9\u57fa\u51c6\u6027\u80fd\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\uff08SAEs\uff09\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u662f\u5426\u80fd\u591f\u8bc6\u522b\u51fa\u771f\u6b63\u7684\u63a8\u7406\u7279\u5f81\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u4ee5\u8bc1\u4f2a\u4e3a\u5bfc\u5411\u7684\u65b9\u6cd5\u8bba\uff0c\u7ed3\u5408\u56e0\u679c\u4ee4\u724c\u6ce8\u5165\u5b9e\u9a8c\u548c\u7531LLM\u6307\u5bfc\u7684\u8bc1\u4f2a\u8fc7\u7a0b\u6765\u6d4b\u8bd5\u7279\u5f81\u6fc0\u6d3b\u662f\u53cd\u6620\u4e86\u63a8\u7406\u8fc7\u7a0b\u8fd8\u662f\u4ec5\u4ec5\u662f\u5bf9\u8868\u9762\u8bed\u8a00\u5173\u8054\u6027\u7684\u53cd\u6620\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u572820\u79cd\u4e0d\u540c\u7684\u914d\u7f6e\u4e0b\uff0c\u88ab\u8bc6\u522b\u4e3a\u63a8\u7406\u76f8\u5173\u7684\u7279\u5f81\u5bf9\u4e8e\u8bcd\u6c47\u7ea7\u522b\u7684\u5e72\u9884\u975e\u5e38\u654f\u611f\uff1b\u5e76\u4e14\uff0c\u6ca1\u6709\u4e00\u4e2a\u5206\u6790\u8fc7\u7684\u7279\u5f81\u6ee1\u8db3\u771f\u6b63\u63a8\u7406\u884c\u4e3a\u7684\u6807\u51c6\u3002\u64cd\u63a7\u8fd9\u4e9b\u7279\u5f81\u4ec5\u5bfc\u81f4\u57fa\u51c6\u6027\u80fd\u7684\u5c0f\u5e45\u53d8\u5316\u6216\u8f7b\u5fae\u4e0b\u964d\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u901a\u8fc7\u5bf9\u6bd4\u65b9\u6cd5\u8bc6\u522b\u51fa\u7684\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u7279\u5f81\u4e3b\u8981\u6355\u83b7\u7684\u662f\u4e0e\u63a8\u7406\u76f8\u5173\u7684\u8bed\u8a00\u7279\u6027\uff0c\u800c\u4e0d\u662f\u5e95\u5c42\u7684\u63a8\u7406\u8ba1\u7b97\u3002"}}
{"id": "2601.05680", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05680", "abs": "https://arxiv.org/abs/2601.05680", "authors": ["Yeonsang Shin", "Insoo Kim", "Bongkeun Kim", "Keonwoo Bae", "Bohyung Han"], "title": "AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces", "comment": null, "summary": "Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6AGDC\uff0c\u7528\u4e8e\u540c\u65f6\u5efa\u6a21\u79bb\u6563\u548c\u8fde\u7eed\u503c\u7684\u53d8\u957f\u5e8f\u5217\uff0c\u901a\u8fc7\u7ed3\u5408\u5206\u7c7b\u9884\u6d4b\u4e0e\u57fa\u4e8e\u6269\u6563\u7684\u5efa\u6a21\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u79bb\u6563\u5316\u65b9\u6cd5\u5728\u9ad8\u7cbe\u5ea6\u9886\u57df\u751f\u6210\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u5e8f\u5217\u65f6\u5b58\u5728\u7684\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u79bb\u6563\u5316\u7684\u6a21\u578b\u5728\u751f\u6210\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u5e8f\u5217\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u9ad8\u7cbe\u5ea6\u7684\u9886\u57df\u5982\u534a\u5bfc\u4f53\u7535\u8def\u8bbe\u8ba1\u4e2d\uff0c\u8fd9\u79cd\u5c40\u9650\u53ef\u80fd\u5bfc\u81f4\u529f\u80fd\u6027\u5931\u8d25\u3002", "method": "\u5f00\u53d1\u4e86AGDC\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6765\u8054\u5408\u5904\u7406\u79bb\u6563\u503c\uff08\u901a\u8fc7\u5206\u7c7b\u9884\u6d4b\uff09\u4e0e\u8fde\u7eed\u503c\uff08\u901a\u8fc7\u57fa\u4e8e\u6269\u6563\u7684\u5efa\u6a21\uff09\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86EOS logit\u8c03\u6574\u673a\u5236\u53ca\u957f\u5ea6\u6b63\u5219\u5316\u9879\uff0c\u5e76\u5efa\u7acb\u4e86\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5ContLayNet\u7528\u4e8e\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u534a\u5bfc\u4f53\u5e03\u5c40\u3001\u56fe\u5f62\u5e03\u5c40\u4ee5\u53caSVGs\u7b49\u591a\u6837\u5316\u9886\u57df\u5185\uff0cAGDC\u76f8\u6bd4\u57fa\u4e8e\u79bb\u6563\u5316\u7684\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u66f4\u9ad8\u4fdd\u771f\u5ea6\u7684\u6df7\u5408\u5411\u91cf\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u7684\u53ef\u6269\u5c55\u9ad8\u7cbe\u5ea6\u751f\u6210\u3002", "conclusion": "AGDC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u89e3\u51b3\u9ad8\u7cbe\u5ea6\u8981\u6c42\u4e0b\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u5e8f\u5217\u751f\u6210\u95ee\u9898\u7684\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.05684", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05684", "abs": "https://arxiv.org/abs/2601.05684", "authors": ["Hongyaoxing Gul", "Lijuan Hu", "Shuzi Niu", "Fangfang Liu"], "title": "FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching", "comment": null, "summary": "Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \\underline{F}lexible \\underline{L}ow-\\underline{R}ank \\underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5316\u65b9\u6cd5FLRQ\uff0c\u65e8\u5728\u901a\u8fc7\u5feb\u901f\u8bc6\u522b\u6700\u4f73\u79e9\u5e76\u5c06\u5176\u805a\u5408\u4ee5\u5b9e\u73b0\u6700\u5c0f\u5b58\u50a8\u7ec4\u5408\uff0c\u4ece\u800c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u4e2d\u6709\u6548\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u548c\u52a0\u901f\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u4f4e\u79e9\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u5fae\u8c03\u6765\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u7684\u4e0d\u540c\u6570\u636e\u548c\u5c42\u786e\u5b9a\u6298\u8877\u79e9\uff0c\u5e76\u4e14\u5f53\u524d\u57fa\u4e8eSVD\u7684\u4f4e\u79e9\u8fd1\u4f3c\u589e\u52a0\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5FLRQ\u5305\u62ec\u4e24\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a\u57fa\u4e8eRank1-Sketch\u7684\u7075\u6d3b\u79e9\u9009\u62e9\uff08R1-FLR\uff09\u548c\u526a\u8f91\u4e0b\u7684\u6700\u4f73\u4f4e\u79e9\u903c\u8fd1\uff08BLC\uff09\u3002R1-FLR\u4f7f\u7528\u5e26\u6709\u9ad8\u65af\u6295\u5f71\u7684R1-Sketch\u8fdb\u884c\u5feb\u901f\u4f4e\u79e9\u8fd1\u4f3c\uff0c\u5141\u8bb8\u4e3a\u6bcf\u4e00\u5c42\u63d0\u53d6\u5f02\u5e38\u503c\u611f\u77e5\u7684\u79e9\uff1bBLC\u5219\u901a\u8fc7\u8fed\u4ee3\u6cd5\u5728\u7f29\u653e\u548c\u526a\u8f91\u7b56\u7565\u4e0b\u6700\u5c0f\u5316\u4f4e\u79e9\u91cf\u5316\u8bef\u5dee\u3002", "result": "FLRQ\u5728\u5168\u9762\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6709\u6548\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u5728\u91cf\u5316\u8d28\u91cf\u548c\u7b97\u6cd5\u6548\u7387\u4e24\u65b9\u9762\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "FLRQ\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5feb\u901f\u786e\u5b9a\u6700\u4f73\u79e9\u5e76\u901a\u8fc7\u805a\u96c6\u8fd9\u4e9b\u79e9\u6765\u8fbe\u5230\u6700\u5c0f\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u51c6\u786e\u6027\u548c\u9ad8\u6548\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f4e\u79e9\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u7684\u95ee\u9898\u3002"}}
{"id": "2601.05732", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05732", "abs": "https://arxiv.org/abs/2601.05732", "authors": ["Yongyi Yang", "Jianyang Gao"], "title": "mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations", "comment": null, "summary": "Hyper-Connections (HC) generalizes residual connections by introducing dynamic residual matrices that mix information across multiple residual streams, accelerating convergence in deep neural networks. However, unconstrained residual matrices can compromise training stability. To address this, DeepSeek's Manifold-Constrained Hyper-Connections (mHC) approximately projects these matrices onto the Birkhoff polytope via iterative Sinkhorn--Knopp (SK) normalization. We identify two limitations of this approach: (i) finite SK iterations do not guarantee exact doubly stochasticity, leaving an approximation gap that can accumulate through network depth and undermine stability; (ii) efficient SK implementation requires highly specialized CUDA kernels, raising engineering barriers and reducing portability. Motivated by the Birkhoff--von Neumann theorem, we propose mHC-lite, a simple reparameterization that explicitly constructs doubly stochastic matrices as convex combinations of permutation matrices. This approach guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations. Extensive experiments demonstrate that mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with a naive implementation and eliminating the residual instabilities observed in both HC and mHC. The code is publicly available at https://github.com/FFTYYY/mhc-lite.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5mHC-lite\uff0c\u901a\u8fc7\u5c06\u53cc\u968f\u673a\u77e9\u9635\u663e\u5f0f\u6784\u9020\u4e3a\u7f6e\u6362\u77e9\u9635\u7684\u51f8\u7ec4\u5408\u6765\u89e3\u51b3mHC\u4e2d\u7531\u4e8e\u6709\u9650\u6b21Sinkhorn-Knopp\u8fed\u4ee3\u5bfc\u81f4\u7684\u8fd1\u4f3c\u8bef\u5dee\u4ee5\u53ca\u5b9e\u73b0\u6548\u7387\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660emHC-lite\u5728\u4fdd\u6301\u6216\u8d85\u8d8amHC\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u5e76\u6d88\u9664\u4e86\u6b8b\u5dee\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5mHC\u4f7f\u7528\u6709\u9650\u6b21Sinkhorn-Knopp\u8fed\u4ee3\u6765\u8fd1\u4f3c\u6295\u5f71\u5230Birkhoff\u591a\u9762\u4f53\u4e0a\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u4e25\u683c\u7684\u53cc\u968f\u673a\u6027\uff0c\u5e76\u4e14\u9700\u8981\u4e13\u95e8\u7684CUDA\u5185\u6838\u5b9e\u73b0\uff0c\u589e\u52a0\u4e86\u5de5\u7a0b\u96be\u5ea6\u548c\u79fb\u690d\u6027\u95ee\u9898\u3002", "method": "\u57fa\u4e8eBirkhoff-von Neumann\u5b9a\u7406\uff0c\u63d0\u51famHC-lite\uff0c\u901a\u8fc7\u7f6e\u6362\u77e9\u9635\u7684\u51f8\u7ec4\u5408\u76f4\u63a5\u6784\u5efa\u53cc\u968f\u673a\u77e9\u9635\uff0c\u4ece\u800c\u786e\u4fdd\u4e86\u4e25\u683c\u7684\u53cc\u968f\u673a\u6027\uff0c\u5e76\u4e14\u4ec5\u4f9d\u8d56\u4e8e\u539f\u751f\u77e9\u9635\u64cd\u4f5c\u5373\u53ef\u5b9e\u73b0\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86mHC-lite\u4e0d\u4ec5\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8fc7mHC\u7684\u8868\u73b0\uff0c\u800c\u4e14\u5373\u4f7f\u91c7\u7528\u6734\u7d20\u5b9e\u73b0\u4e5f\u80fd\u591f\u8fbe\u5230\u66f4\u9ad8\u7684\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u5e76\u4e14\u907f\u514d\u4e86HC\u548cmHC\u4e2d\u5b58\u5728\u7684\u6b8b\u5dee\u4e0d\u7a33\u5b9a\u73b0\u8c61\u3002", "conclusion": "mHC-lite\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u6d01\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86mHC\u56e0\u6709\u9650SK\u8fed\u4ee3\u5e26\u6765\u7684\u7a33\u5b9a\u6027\u548c\u5b9e\u73b0\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.05759", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05759", "abs": "https://arxiv.org/abs/2601.05759", "authors": ["Turkan Simge Ispak", "Salih Tileylioglu", "Erdem Akagunduz"], "title": "Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms", "comment": "13 pages, 8 figures, 3 tables", "summary": "Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce \"overgeneralization\", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06P\u6ce2\u5230\u8fbe\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u81ea\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u914d\u7f6e\u53d1\u73b0\u6ce8\u610f\u529b\u673a\u5236\u76f8\u6bd4\u8df3\u8dc3\u8fde\u63a5\u66f4\u80fd\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8fd1\u6e90\u8303\u56f4\u5185\uff0c\u8868\u660e\u4e86\u5728\u81ea\u76d1\u7763P\u6ce2\u68c0\u6d4b\u4e2d\u5168\u5c40\u4e0a\u4e0b\u6587\u4f18\u5148\u4e8e\u50cf\u7d20\u7ea7\u91cd\u5efa\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u51c6\u786e\u7684P\u6ce2\u68c0\u6d4b\u5bf9\u5730\u9707\u9884\u8b66\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f3a\u9707\u8bb0\u5f55\u56e0\u9ad8\u566a\u58f0\u6c34\u5e73\u3001\u6709\u9650\u7684\u6807\u8bb0\u6570\u636e\u548c\u590d\u6742\u7684\u6ce2\u5f62\u7279\u5f81\u800c\u5e26\u6765\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u5c06P\u6ce2\u5230\u8fbe\u68c0\u6d4b\u95ee\u9898\u91cd\u6784\u4e3a\u4e00\u4e2a\u81ea\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u7684\u7f51\u683c\u641c\u7d22\u8bc4\u4f30\u4e86492\u79cd\u4e0d\u540c\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u67b6\u6784\u914d\u7f6e\uff0c\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u67b6\u6784\u5982\u4f55\u5e73\u8861\u91cd\u5efa\u7cbe\u5ea6\u4e0e\u5f02\u5e38\u533a\u5206\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136\u8df3\u8dc3\u8fde\u63a5\u53ef\u4ee5\u6700\u5c0f\u5316\u91cd\u5efa\u8bef\u5dee\uff08\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u7ea6\u4e3a0.0012\uff09\uff0c\u4f46\u5b83\u4f1a\u5bfc\u81f4\u201c\u8fc7\u5ea6\u6cdb\u5316\u201d\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u91cd\u5efa\u566a\u58f0\u5e76\u63a9\u76d6\u68c0\u6d4b\u4fe1\u53f7\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6ce8\u610f\u529b\u673a\u5236\u66f4\u6ce8\u91cd\u5168\u5c40\u80cc\u666f\u800c\u975e\u5c40\u90e8\u7ec6\u8282\uff0c\u4ece\u800c\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u5176\u66f2\u7ebf\u4e0b\u9762\u79ef\u8fbe\u52300.875\u3002\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u57280\u523040\u516c\u91cc\u7684\u8fd1\u6e90\u8303\u56f4\u5185\u7684\u66f2\u7ebf\u4e0b\u9762\u79ef\u8fbe\u5230\u4e860.91\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u81ea\u76d1\u7763P\u6ce2\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u503e\u5411\u4e8e\u5168\u5c40\u4e0a\u4e0b\u6587\u7406\u89e3\u800c\u975e\u8ffd\u6c42\u5b8c\u7f8e\u50cf\u7d20\u7ea7\u91cd\u5efa\u7684\u67b6\u6784\u8bbe\u8ba1\u5bf9\u4e8e\u5b9e\u73b0\u9c81\u68d2\u6027\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.05770", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05770", "abs": "https://arxiv.org/abs/2601.05770", "authors": ["Yifan Zhang", "Wei Bi", "Kechi Zhang", "Dongming Jin", "Jie Fu", "Zhi Jin"], "title": "Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer", "comment": null, "summary": "Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u79bb\u6563Transformer\u7684\u65b0\u67b6\u6784\uff0c\u65e8\u5728\u89e3\u51b3\u4ece\u8fde\u7eed\u8868\u793a\u5230\u79bb\u62bd\u8c61\u903b\u8f91\u8f6c\u6362\u7684\u95ee\u9898\u3002\u901a\u8fc7\u529f\u80fd\u89e3\u8026\u548c\u6e29\u5ea6\u9000\u706b\u91c7\u6837\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4fc3\u8fdb\u4eba\u7c7b\u53ef\u8bfb\u7a0b\u5e8f\u7684\u63d0\u53d6\uff0c\u5e76\u5728\u4fdd\u6301\u4e0e\u57fa\u4e8eRNN\u57fa\u51c6\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u5bf9\u8fde\u7eed\u53d8\u91cf\u57df\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7b97\u6cd5\u63d0\u53d6\u7684\u76ee\u6807\u662f\u4ece\u7279\u5b9a\u7b97\u6cd5\u4efb\u52a1\u8bad\u7ec3\u7684\u6a21\u578b\u4e2d\u76f4\u63a5\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u4f46\u5c06\u8fd9\u79cd\u65b9\u6cd5\u6269\u5c55\u5230Transformer\u65f6\u9047\u5230\u4e86\u8d85\u4f4d\u7f6e\u95ee\u9898\uff0c\u5373\u7ea0\u7f20\u7279\u5f81\u4ee5\u91cd\u53e0\u65b9\u5411\u7f16\u7801\u963b\u788d\u4e86\u7b26\u53f7\u8868\u8fbe\u5f0f\u7684\u63d0\u53d6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aDiscrete Transformer\u7684\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u5bf9\u6570\u503c\u6ce8\u610f\u529b\u673a\u5236\u548c\u6570\u503cMLP\u7684\u529f\u80fd\u8fdb\u884c\u4e25\u683c\u5206\u79bb\uff0c\u5e76\u91c7\u7528\u6e29\u5ea6\u9000\u706b\u91c7\u6837\u7b56\u7565\u6765\u4fc3\u8fdb\u4eba\u7c7b\u53ef\u8bfb\u7a0b\u5e8f\u7684\u63d0\u53d6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cDiscrete Transformer\u4e0d\u4ec5\u8fbe\u5230\u4e86\u4e0e\u57fa\u4e8eRNN\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u800c\u4e14\u5173\u952e\u5730\u5c06\u5176\u53ef\u89e3\u91ca\u6027\u6269\u5c55\u5230\u4e86\u8fde\u7eed\u53d8\u91cf\u9886\u57df\u3002\u6b64\u5916\uff0c\u5bf9\u9000\u706b\u8fc7\u7a0b\u7684\u5206\u6790\u663e\u793a\uff0c\u9ad8\u6548\u7684\u79bb\u6563\u641c\u7d22\u7ecf\u5386\u4e86\u4e00\u4e2a\u4ece\u63a2\u7d22\u5230\u5229\u7528\u7684\u660e\u786e\u9636\u6bb5\u8f6c\u53d8\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5171\u540c\u786e\u7acb\u4e86Discrete Transformer\u4f5c\u4e3a\u65e0\u793a\u4f8b\u7b97\u6cd5\u53d1\u73b0\u7684\u5f3a\u5927\u6846\u67b6\u7684\u5730\u4f4d\uff0c\u4e3a\u63d0\u9ad8Transformer\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u4e00\u6761\u4e25\u8c28\u7684\u8def\u5f84\u3002"}}
{"id": "2601.05792", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.05792", "abs": "https://arxiv.org/abs/2601.05792", "authors": ["Manel Gil-Sorribes", "J\u00falia Vilalta-Mor", "Isaac Filella-Merc\u00e8", "Robert Soliva", "\u00c1lvaro Ciudad", "V\u00edctor Guallar", "Alexis Molina"], "title": "Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning", "comment": "Accepted at the Generative and Experimental Perspectives for Biomolecular Design Workshop at ICLR 2025 and at the Learning Meaningful Representations of Life Workshop at ICLR 2025", "summary": "Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTensor-DTI\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6765\u81ea\u5206\u5b50\u56fe\u3001\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u548c\u7ed3\u5408\u4f4d\u70b9\u9884\u6d4b\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6765\u63d0\u9ad8\u836f\u7269-\u9776\u6807\u76f8\u4e92\u4f5c\u7528\uff08DTI\uff09\u5efa\u6a21\u7684\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5e8f\u5217\u548c\u57fa\u4e8e\u56fe\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u5373\u4f7f\u5728\u8bad\u7ec3\u65f6\u6392\u9664\u4e86CDK2\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u591f\u4ea7\u751f\u5316\u5b66\u4e0a\u5408\u7406\u7684\u547d\u4e2d\u5206\u5e03\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u7d22\u4e86\u5176\u5728\u86cb\u767d\u8d28-RNA\u548c\u80bd-\u86cb\u767d\u76f8\u4e92\u4f5c\u7528\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u8ba1\u7b97\u836f\u7269\u53d1\u73b0\u7684\u836f\u7269-\u9776\u6807\u76f8\u4e92\u4f5c\u7528\uff08DTI\uff09\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u5355\u4e00\u6a21\u6001\u7684\u9884\u5b9a\u4e49\u5206\u5b50\u63cf\u8ff0\u7b26\u6216\u57fa\u4e8e\u5e8f\u5217\u7684\u5d4c\u5165\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u8868\u5f81\u80fd\u529b\u4e0a\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u6311\u6218\u5e76\u63d0\u9ad8DTI\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u3002", "method": "Tensor-DTI\u91c7\u7528\u4e86\u4e00\u79cd\u5b6a\u751f\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u80fd\u591f\u540c\u65f6\u6355\u6349\u5316\u5b66\u4e0e\u7ed3\u6784\u4e0a\u7684\u4ea4\u4e92\u7279\u5f81\uff0c\u5e76\u533a\u5206\u76f8\u4e92\u4f5c\u7528\u5bf9\u4e0e\u975e\u76f8\u4e92\u4f5c\u7528\u5bf9\u3002\u5b83\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b9\u5f0f\uff0c\u5c06\u4ece\u5206\u5b50\u56fe\u3001\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u4ee5\u53ca\u7ed3\u5408\u4f4d\u70b9\u9884\u6d4b\u5f97\u5230\u7684\u4fe1\u606f\u8fdb\u884c\u878d\u5408\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u5b66\u4e60\u80fd\u529b\u3002", "result": "\u5728\u591a\u79cdDTI\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cTensor-DTI\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u57fa\u4e8e\u5e8f\u5217\u548c\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\u3002\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u5316\u5b66\u5e93\u4e2d\u9488\u5bf9CDK2\u8fdb\u884c\u63a8\u7406\u65f6\uff0c\u5373\u4f7f\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u672a\u5305\u542bCDK2\u7684\u60c5\u51b5\u4e0b\uff0cTensor-DTI\u4f9d\u7136\u80fd\u591f\u751f\u6210\u5177\u6709\u5316\u5b66\u5408\u7406\u6027\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u5728\u4e0eGlide\u5bf9\u63a5\u53caBoltz-2\u5171\u6298\u53e0\u5668\u76f8\u6bd4\u7684\u7814\u7a76\u4e2d\uff0cTensor-DTI\u5bf9\u4e8eCDK2\u4ee5\u53ca\u5176\u4ed6\u5bb6\u65cf\u5916\u76ee\u6807\u5c55\u73b0\u4e86\u7ade\u4e89\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u836f\u7269-\u9776\u6807\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e5f\u4e3a\u865a\u62df\u7b5b\u9009\u63d0\u4f9b\u4e86\u66f4\u52a0\u53ef\u89e3\u91ca\u4e14\u53ef\u9760\u6027\u66f4\u9ad8\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8fd8\u6709\u671b\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u751f\u7269\u5206\u5b50\u76f8\u4e92\u4f5c\u7528\u7c7b\u578b\u3002"}}
{"id": "2601.05807", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05807", "abs": "https://arxiv.org/abs/2601.05807", "authors": ["Mohamed Amine Hallam", "Kuo-Kun Tseng"], "title": "Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers", "comment": "10 pages, 5 figures. Code and reproduction materials available on GitHub", "summary": "Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u957f\u5e8f\u5217\u8bbe\u7f6e\u4e2d\uff0c\u4f4d\u7f6e\u7f16\u7801\u4e0etoken\u5d4c\u5165\u878d\u5408\u673a\u5236\u5bf9Transformer\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u9009\u62e9\u5408\u9002\u7684\u878d\u5408\u7b56\u7565\u53ef\u4ee5\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14\u8fd9\u79cd\u597d\u5904\u5bf9\u4e8e\u591a\u79cd\u4f4d\u7f6e\u7f16\u7801\u5bb6\u65cf\u90fd\u662f\u901a\u7528\u7684\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5377\u79ef\u95e8\u63a7\u673a\u5236\uff0c\u4e3a\u957f\u6587\u6863\u7684\u878d\u5408\u5c42\u9762\u5f15\u5165\u5c40\u90e8\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u867d\u7136\u5927\u591a\u6570\u5148\u524d\u7684\u5de5\u4f5c\u90fd\u96c6\u4e2d\u5728\u8bbe\u8ba1\u65b0\u7684\u4f4d\u7f6e\u7f16\u7801\u4e0a\uff0c\u4f46\u5f88\u5c11\u6709\u4eba\u7814\u7a76\u4f4d\u7f6e\u4fe1\u606f\u662f\u5982\u4f55\u4e0etoken\u5d4c\u5165\u76f8\u7ed3\u5408\u7684\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e0d\u540c\u7684\u878d\u5408\u673a\u5236\u662f\u5426\u4f1a\u5f71\u54cd\u6a21\u578b\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u5e8f\u5217\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u53d8\u91cf\u5982\u76f8\u540c\u7684Transformer\u67b6\u6784\u3001\u6570\u636e\u5206\u5272\u548c\u968f\u673a\u79cd\u5b50\uff0c\u6bd4\u8f83\u4e86\u4e09\u79cd\u7ecf\u5178\u7684\u878d\u5408\u7b56\u7565\uff1a\u9010\u5143\u7d20\u76f8\u52a0\u3001\u5e26\u6295\u5f71\u7684\u4e32\u8054\u4ee5\u53ca\u6807\u91cf\u95e8\u63a7\u878d\u5408\u3002\u53e6\u5916\uff0c\u4e3a\u4e86\u9a8c\u8bc1\u8fd9\u4e9b\u589e\u76ca\u662f\u7ed3\u6784\u6027\u800c\u975e\u968f\u673a\u6027\u7684\uff0c\u8fdb\u884c\u4e86\u914d\u5bf9\u79cd\u5b50\u5206\u6790\u548c\u8de8\u6570\u636e\u96c6\u6bd4\u8f83\u3002\u6700\u540e\uff0c\u63a2\u7d22\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5377\u79ef\u95e8\u63a7\u673a\u5236\u4ee5\u5728\u878d\u5408\u7ea7\u522b\u5f15\u5165\u5c40\u90e8\u5f52\u7eb3\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5bf9\u4e8e\u77ed\u6587\u672c\u6765\u8bf4\uff0c\u878d\u5408\u65b9\u5f0f\u7684\u9009\u62e9\u5f71\u54cd\u4e0d\u5927\uff1b\u4f46\u5bf9\u4e8e\u957f\u6587\u6863\uff0c\u5219\u80fd\u591f\u4ea7\u751f\u4e00\u81f4\u6027\u7684\u6027\u80fd\u6539\u8fdb\u3002\u8fdb\u4e00\u6b65\u7684\u5b9e\u9a8c\u6307\u51fa\uff0c\u53ef\u5b66\u4e60\u878d\u5408\u7684\u4f18\u52bf\u8de8\u8d8a\u4e86\u591a\u4e2a\u4f4d\u7f6e\u7f16\u7801\u5bb6\u65cf\u3002", "conclusion": "\u4f4d\u7f6e\u7f16\u7801\u878d\u5408\u662f\u9488\u5bf9\u957f\u5e8f\u5217Transformers\u7684\u4e00\u4e2a\u975e\u5e73\u51e1\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e94\u8be5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u660e\u786e\u7684\u5efa\u6a21\u51b3\u7b56\u800c\u4e0d\u662f\u56fa\u5b9a\u7684\u9ed8\u8ba4\u9009\u9879\u3002"}}
{"id": "2601.05812", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05812", "abs": "https://arxiv.org/abs/2601.05812", "authors": ["Zhanpei Huang", "Taochen chen", "Fangqing Gu", "Yiqun Zhang"], "title": "Detecting Autism Spectrum Disorder with Deep Eye Movement Features", "comment": "Accepted to CIS 2025", "summary": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u81ea\u95ed\u75c7\u8c31\u7cfb\u969c\u788d(ASD)\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u5229\u7528\u773c\u52a8\u6570\u636e\u5e76\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u79bb\u6563\u77ed\u671f\u5e8f\u5217(DSTS)\u5efa\u6a21\u6846\u67b6\u6765\u533a\u5206ASD\u4e0e\u6b63\u5e38\u53d1\u5c55\u4e2a\u4f53\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u590d\u6742\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u9274\u4e8e\u773c\u52a8\u6570\u636e\u4e3a\u68c0\u6d4bASD\u63d0\u4f9b\u4e86\u975e\u4fb5\u5165\u6027\u7684\u624b\u6bb5\uff0c\u5e76\u4e14\u5177\u6709\u77ed\u671f\u65f6\u95f4\u4f9d\u8d56\u6027\u7279\u5f81\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u66f4\u6709\u6548\u7684\u6a21\u578b\u6765\u6355\u6349\u8fd9\u4e9b\u7ec6\u5fae\u7684\u884c\u4e3a\u6807\u8bb0\uff0c\u4ee5\u63d0\u9ad8ASD\u8bca\u65ad\u51c6\u786e\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u79bb\u6563\u77ed\u671f\u5e8f\u5217\uff08DSTS\uff09\u5efa\u6a21\u6846\u67b6\uff0c\u7ed3\u5408\u7c7b\u522b\u611f\u77e5\u8868\u793a\u548c\u4e0d\u5e73\u8861\u611f\u77e5\u673a\u5236\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u6548\u6355\u6349\u590d\u6742\u7684\u773c\u52a8\u6a21\u5f0f\uff0c\u533a\u522b\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u6a21\u578b\u4e2d\u5e38\u7528\u7684\u5806\u53e0\u6ce8\u610f\u529b\u5c42\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u773c\u52a8\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u6d4b\u8bd5\uff0cDSTS\u6846\u67b6\u5728\u8bc6\u522bASD\u76f8\u5173\u6a21\u5f0f\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\u548c\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86DSTS\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u773c\u52a8\u6570\u636e\u4e2d\u7684\u77ed\u671f\u5c40\u90e8\u4f9d\u8d56\u6027\u7279\u5f81\uff0c\u4e3aASD\u8bca\u65ad\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2601.05845", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05845", "abs": "https://arxiv.org/abs/2601.05845", "authors": ["Eric Weine", "Peter Carbonetto", "Rafael A. Irizarry", "Matthew Stephens"], "title": "A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link", "comment": null, "summary": "Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable \"parts-based\" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the \"parts\" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e26\u79fb\u4f4d\u5bf9\u6570\u94fe\u63a5\u51fd\u6570\u7684\u6cca\u677e\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u4ee5\u653e\u5bbd\u73b0\u6709\u65b9\u6cd5\u4e2d\u90e8\u5206\u7ec4\u5408\u4e3a\u52a0\u6027\u7684\u5047\u8bbe\u3002\u65b0\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u8c03\u53c2\u53c2\u6570\u53ef\u4ee5\u5b9e\u73b0\u4ece\u52a0\u6027\u5230\u66f4\u63a5\u8fd1\u4e58\u6027\u7684\u7ec4\u5408\u65b9\u5f0f\u53d8\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u6700\u5927\u4f3c\u7136\u62df\u5408\u7b97\u6cd5\u53ca\u9488\u5bf9\u5927\u89c4\u6a21\u7a00\u758f\u6570\u636e\u96c6\u7684\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6cca\u677e\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u5047\u5b9a\u5728\u5206\u89e3\u8fc7\u7a0b\u4e2d\u201c\u90e8\u5206\u201d\u662f\u4ee5\u52a0\u6027\u65b9\u5f0f\u7ec4\u5408\u7684\uff0c\u8fd9\u4e00\u5047\u8bbe\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u5e76\u4e0d\u81ea\u7136\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6cca\u677eNMF\u65b9\u6cd5\uff0c\u91c7\u7528\u79fb\u4f4d\u5bf9\u6570\u94fe\u63a5\u51fd\u6570\u6765\u653e\u677e\u8fd9\u79cd\u52a0\u6027\u7ec4\u5408\u7684\u9650\u5236\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u52a0\u7075\u6d3b\u7684\u6570\u636e\u89e3\u91ca\u6a21\u578b\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u79fb\u4f4d\u5bf9\u6570\u94fe\u63a5\u51fd\u6570\u7684\u6cca\u677e\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u8c03\u8282\u53c2\u6570\uff0c\u968f\u7740\u53c2\u6570\u7684\u53d8\u5316\uff0c\u6a21\u578b\u4ece\u8ba4\u4e3a\u90e8\u5206\u4ee5\u52a0\u6027\u65b9\u5f0f\u7ed3\u5408\uff08\u5373\u6807\u51c6\u6cca\u677eNMF\uff09\u8f6c\u53d8\u4e3a\u66f4\u503e\u5411\u4e8e\u4e58\u6027\u65b9\u5f0f\u7ed3\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u7ed9\u51fa\u4e86\u9002\u5408\u6b64\u6a21\u578b\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u62df\u5408\u7b97\u6cd5\u4ee5\u53ca\u9488\u5bf9\u5927\u578b\u7a00\u758f\u6570\u636e\u96c6\u8bbe\u8ba1\u7684\u4e00\u79cd\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7528\u4ee5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u793a\u4f8b\u8868\u660e\uff0c\u9009\u62e9\u4e0d\u540c\u7684\u94fe\u63a5\u51fd\u6570\u4f1a\u5bf9\u6cca\u677eNMF\u7684\u7ed3\u679c\u4ea7\u751f\u5b9e\u8d28\u6027\u5f71\u54cd\uff1b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u79fb\u4f4d\u5bf9\u6570\u94fe\u63a5\u51fd\u6570\u76f8\u6bd4\u4f20\u7edf\u7684\u52a0\u6027\u94fe\u63a5\u80fd\u591f\u63d0\u9ad8\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u5e26\u6709\u79fb\u4f4d\u5bf9\u6570\u94fe\u63a5\u51fd\u6570\u7684\u6cca\u677eNMF\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u8d85\u8d8a\u4f20\u7edf\u52a0\u6027\u5047\u8bbe\u7684\u7075\u6d3b\u6027\uff0c\u800c\u4e14\u5728\u7279\u5b9a\u5e94\u7528\u573a\u666f\u4e0b\u8fd8\u80fd\u589e\u5f3a\u5206\u6790\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u7a00\u758f\u6570\u636e\u65f6\uff0c\u6240\u63d0\u4f9b\u7684\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u8fd0\u7b97\u6548\u7387\u3002"}}
{"id": "2601.05870", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05870", "abs": "https://arxiv.org/abs/2601.05870", "authors": ["Huilin Deng", "Hongchen Luo", "Yue Zhu", "Long Li", "Zhuoyue Chen", "Xinghao Zhao", "Ming Li", "Jihai Zhang", "Mengchang Wang", "Yang Cao", "Yu Kang"], "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck", "comment": null, "summary": "Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5IIB-LPO\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5\u72b6\u6001\u89e6\u53d1\u6f5c\u5728\u5206\u652f\u6765\u591a\u6837\u5316\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u4f7f\u7528\u4fe1\u606f\u74f6\u9888\u539f\u5219\u4f5c\u4e3a\u8f68\u8ff9\u8fc7\u6ee4\u5668\u548c\u81ea\u6211\u5956\u52b1\u673a\u5236\uff0c\u4ece\u800c\u6539\u5584\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u5d29\u6e83\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u591a\u6837\u6027\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u65f6\u9047\u5230\u4e86\u63a2\u7d22\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u5373\u968f\u673a\u5c55\u5f00\u7684\u8bed\u4e49\u540c\u8d28\u6027\u5bfc\u81f4\u6a21\u578b\u9677\u5165\u72ed\u7a84\u3001\u8fc7\u5ea6\u4f18\u5316\u7684\u884c\u4e3a\u6a21\u5f0f\u4e2d\u3002\u5c3d\u7ba1\u5f53\u524d\u7684\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u7b56\u7565\u71b5\u9f13\u52b1\u63a2\u7d22\uff0c\u4f46\u5b83\u4eec\u5b58\u5728\u56fa\u6709\u7684\u5c40\u9650\u6027\uff0c\u5982\u5168\u5c40\u71b5\u6b63\u5219\u5316\u5bb9\u6613\u53d7\u5230\u5956\u52b1\u6b3a\u9a97\u7684\u5f71\u54cd\uff0c\u800c\u5c40\u90e8\u4ee4\u724c\u9009\u62e9\u6027\u66f4\u65b0\u96be\u4ee5\u514b\u670d\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5f3a\u5927\u5f52\u7eb3\u504f\u7f6e\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aIIB-LPO\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u63a2\u7d22\u4ece\u5bf9\u4ee4\u724c\u5206\u5e03\u8fdb\u884c\u7edf\u8ba1\u6270\u52a8\u8f6c\u53d8\u4e3a\u63a8\u7406\u8f68\u8ff9\u7684\u62d3\u6251\u5206\u652f\u3002IIB-LPO\u5728\u9ad8\u71b5\u72b6\u6001\u4e0b\u89e6\u53d1\u6f5c\u53d8\u91cf\u5206\u652f\u4ee5\u591a\u6837\u5316\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u4e14\u540c\u65f6\u5229\u7528\u4fe1\u606f\u74f6\u9888\u539f\u5219\u4f5c\u4e3a\u8f68\u8ff9\u7b5b\u9009\u5668\u548c\u81ea\u6211\u5956\u52b1\u673a\u5236\uff0c\u786e\u4fdd\u63a2\u7d22\u8fc7\u7a0b\u65e2\u7b80\u6d01\u53c8\u5177\u6709\u4fe1\u606f\u91cf\u3002", "result": "\u8de8\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cIIB-LPO\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u4e0a\u6bd4\u4ee5\u524d\u7684\u65b9\u6cd5\u9ad8\u51fa\u6700\u591a5.3%\uff0c\u5728\u591a\u6837\u6027\u5ea6\u91cf\u4e0a\u63d0\u9ad8\u4e867.4%\u3002", "conclusion": "IIB-LPO\u4e3a\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u9047\u5230\u7684\u63a2\u7d22\u5d29\u6e83\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u63a8\u7406\u8def\u5f84\u7684\u591a\u6837\u6027\u3002"}}
{"id": "2601.05889", "categories": ["cs.LG", "astro-ph.CO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.05889", "abs": "https://arxiv.org/abs/2601.05889", "authors": ["Doyoung Kim", "Donghee Lee", "Hye-Sung Lee", "Jiheon Lee", "Jaeok Yi"], "title": "GlueNN: gluing patchwise analytic solutions with neural networks", "comment": "7 pages, 3 figures", "summary": "In many problems in physics and engineering, one encounters complicated differential equations with strongly scale-dependent terms for which exact analytical or numerical solutions are not available. A common strategy is to divide the domain into several regions (patches) and simplify the equation in each region. When approximate analytic solutions can be obtained in each patch, they are then matched at the interfaces to construct a global solution. However, this patching procedure can fail to reproduce the correct solution, since the approximate forms may break down near the matching boundaries. In this work, we propose a learning framework in which the integration constants of asymptotic analytic solutions are promoted to scale-dependent functions. By constraining these coefficient functions with the original differential equation over the domain, the network learns a globally valid solution that smoothly interpolates between asymptotic regimes, eliminating the need for arbitrary boundary matching. We demonstrate the effectiveness of this framework in representative problems from chemical kinetics and cosmology, where it accurately reproduces global solutions and outperforms conventional matching procedures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6e10\u8fd1\u89e3\u6790\u89e3\u7684\u79ef\u5206\u5e38\u6570\u63d0\u5347\u4e3a\u5c3a\u5ea6\u4f9d\u8d56\u51fd\u6570\uff0c\u5e76\u5229\u7528\u539f\u59cb\u5fae\u5206\u65b9\u7a0b\u5728\u6574\u4e2a\u57df\u4e0a\u7ea6\u675f\u8fd9\u4e9b\u7cfb\u6570\u51fd\u6570\uff0c\u4ece\u800c\u5b66\u4e60\u5f97\u5230\u4e00\u4e2a\u5168\u5c40\u6709\u6548\u7684\u89e3\u3002\u8be5\u65b9\u6cd5\u5728\u5316\u5b66\u52a8\u529b\u5b66\u548c\u5b87\u5b99\u5b66\u4e2d\u7684\u4ee3\u8868\u6027\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u51c6\u786e\u518d\u73b0\u5168\u5c40\u89e3\uff0c\u5e76\u4f18\u4e8e\u4f20\u7edf\u7684\u8fb9\u754c\u5339\u914d\u7a0b\u5e8f\u3002", "motivation": "\u5bf9\u4e8e\u7269\u7406\u548c\u5de5\u7a0b\u4e2d\u9047\u5230\u7684\u5177\u6709\u5f3a\u70c8\u5c3a\u5ea6\u4f9d\u8d56\u9879\u7684\u590d\u6742\u5fae\u5206\u65b9\u7a0b\uff0c\u5f53\u524d\u901a\u8fc7\u533a\u57df\u5212\u5206\u7b80\u5316\u65b9\u7a0b\u7136\u540e\u5339\u914d\u5c40\u90e8\u89e3\u6765\u6784\u9020\u5168\u5c40\u89e3\u7684\u65b9\u6cd5\u53ef\u80fd\u4f1a\u5931\u8d25\uff0c\u56e0\u4e3a\u8fd1\u4f3c\u5f62\u5f0f\u53ef\u80fd\u5728\u5339\u914d\u8fb9\u754c\u9644\u8fd1\u5931\u6548\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u8fd9\u4e2a\u6846\u67b6\u5185\uff0c\u6e10\u8fd1\u89e3\u6790\u89e3\u7684\u79ef\u5206\u5e38\u6570\u88ab\u89c6\u4f5c\u5c3a\u5ea6\u4f9d\u8d56\u51fd\u6570\uff0c\u5e76\u4e14\u901a\u8fc7\u6574\u4e2a\u57df\u4e0a\u7684\u539f\u59cb\u5fae\u5206\u65b9\u7a0b\u6765\u9650\u5236\u8fd9\u4e9b\u7cfb\u6570\u51fd\u6570\uff0c\u4ee5\u5b66\u4e60\u5230\u4e0d\u9700\u8981\u4efb\u610f\u8fb9\u754c\u5339\u914d\u5c31\u80fd\u5e73\u6ed1\u63d2\u503c\u4e8e\u6e10\u8fd1\u533a\u95f4\u4e4b\u95f4\u7684\u5168\u5c40\u6709\u6548\u89e3\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u5316\u5b66\u52a8\u529b\u5b66\u548c\u5b87\u5b99\u5b66\u4e2d\u7684\u793a\u4f8b\u95ee\u9898\u4e2d\u6210\u529f\u5730\u91cd\u73b0\u4e86\u5168\u5c40\u89e3\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u8d85\u8fc7\u4e86\u4f20\u7edf\u5339\u914d\u7a0b\u5e8f\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u9014\u5f84\u6765\u89e3\u51b3\u5305\u542b\u5f3a\u5c3a\u5ea6\u4f9d\u8d56\u6027\u7684\u590d\u6742\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u8fb9\u754c\u6761\u4ef6\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u66f4\u51c6\u786e\u7684\u5168\u5c40\u89e3\u3002"}}
{"id": "2601.05909", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05909", "abs": "https://arxiv.org/abs/2601.05909", "authors": ["Ayoub Ajarra", "Debabrota Basu"], "title": "Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates", "comment": null, "summary": "As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.\n  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.\n  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4efb\u610f\u66f4\u65b0\u4e0b\u8fdb\u884c\u7fa4\u4f53\u516c\u5e73\u6027\u5ba1\u6838\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u9a8c\u5c5e\u6027\u4f18\u5316\uff08EPO\uff09oracle\u7684PAC\u5ba1\u6838\u901a\u7528\u6846\u67b6\uff0c\u5e76\u4e3a\u7edf\u8ba1\u5e73\u7b49\u6027\u5efa\u7acb\u4e86\u4e0eSP\u7ef4\u5ea6\u76f8\u5173\u7684\u65e0\u5206\u5e03\u5ba1\u6838\u8fb9\u754c\uff0c\u8be5\u6846\u67b6\u8fd8\u80fd\u591f\u81ea\u7136\u5730\u6269\u5c55\u5230\u5176\u4ed6\u5ba1\u6838\u76ee\u6807\u4e0a\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5d4c\u5165\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u4e2d\uff0c\u5bf9\u5b83\u4eec\u8fdb\u884c\u504f\u89c1\u5ba1\u8ba1\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u90e8\u7f72\u4e2d\uff0c\u7531\u4e8e\u6a21\u578b\u6240\u6709\u8005\u53ef\u80fd\u4f1a\u6839\u636e\u73af\u5883\u53d8\u5316\u81ea\u9002\u5e94\u5730\u66f4\u65b0\u5176\u6a21\u578b\uff0c\u8fd9\u4f7f\u5f97\u5ba1\u8ba1\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u3002\u8fd9\u4e9b\u66f4\u65b0\u53ef\u4ee5\u6539\u53d8\u57fa\u7840\u6a21\u578b\u7c7b\u522b\u540c\u65f6\u4fdd\u6301\u67d0\u4e9b\u611f\u5174\u8da3\u7684\u5c5e\u6027\u4e0d\u53d8\uff0c\u8fd9\u5c31\u63d0\u51fa\u4e86\u5728\u8fd9\u79cd\u53d8\u52a8\u4e0b\u4ec0\u4e48\u53ef\u4ee5\u88ab\u53ef\u9760\u5ba1\u8ba1\u7684\u57fa\u672c\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u9a8c\u5c5e\u6027\u4f18\u5316\uff08EPO\uff09oracle\u7684PAC\u5ba1\u6838\u901a\u7528\u6846\u67b6\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u5bf9\u4e8e\u7edf\u8ba1\u5e73\u7b49\u6027\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u7ec4\u5408\u5ea6\u91cf\u2014\u2014SP\u7ef4\u5ea6\uff0c\u6765\u6355\u6349\u53ef\u63a5\u53d7\u7b56\u7565\u66f4\u65b0\u7684\u590d\u6742\u6027\uff0c\u5e76\u636e\u6b64\u5efa\u7acb\u65e0\u5206\u5e03\u5ba1\u6838\u8fb9\u754c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u4f7f\u7528\u6700\u5c11\u6807\u8bb0\u6837\u672c\u7684\u5ba1\u6838\u5c5e\u6027\uff0c\u5982\u7fa4\u4f53\u516c\u5e73\u6027\uff0c\u800c\u4e14\u8fd8\u80fd\u81ea\u7136\u5730\u6269\u5c55\u81f3\u8bf8\u5982\u9884\u6d4b\u8bef\u5dee\u548c\u9c81\u68d2\u98ce\u9669\u7b49\u5176\u4ed6\u5ba1\u6838\u76ee\u6807\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u9762\u5bf9\u6a21\u578b\u53ef\u80fd\u7ecf\u5386\u7684\u6218\u7565\u6027\u66f4\u6539\u65f6\u5982\u4f55\u6709\u6548\u5730\u6267\u884c\u7fa4\u4f53\u516c\u5e73\u6027\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002\u5b83\u4e0d\u4ec5\u6709\u52a9\u4e8e\u7406\u89e3\u5141\u8bb8\u66f4\u65b0\u7684\u4fe1\u606f\u590d\u6742\u6027\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u4ec5\u9700\u5c11\u91cf\u6807\u8bb0\u6837\u672c\u5c31\u80fd\u5b8c\u6210\u7684\u5ba1\u6838\u5c5e\u6027\u3002"}}
{"id": "2601.05929", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05929", "abs": "https://arxiv.org/abs/2601.05929", "authors": ["Sidney Shapiro", "Burhanuddin Panvelwala"], "title": "Prophet as a Repro ducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics", "comment": null, "summary": "Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare Prophet's performance and interpretability with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86Meta\u5f00\u53d1\u7684\u5f00\u6e90\u9884\u6d4b\u6846\u67b6Prophet\u5982\u4f55\u901a\u8fc7\u5176\u53ef\u52a0\u6027\u7ed3\u6784\u3001\u5f00\u6e90\u5b9e\u73b0\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u7a0b\u6765\u4fc3\u8fdb\u900f\u660e\u4e14\u53ef\u590d\u5236\u7684\u9884\u6d4b\u5b9e\u8df5\uff0c\u7279\u522b\u662f\u5728\u5546\u4e1a\u548c\u91d1\u878d\u5206\u6790\u9886\u57df\u3002\u7814\u7a76\u901a\u8fc7\u4e0eARIMA\u548c\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u516c\u5f00\u8d22\u52a1\u548c\u96f6\u552e\u6570\u636e\u96c6\u4e0a\u7684\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u4e86Prophet\u7684\u8868\u73b0\u53ca\u5176\u5728\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u590d\u5236\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u5728\u5546\u4e1a\u548c\u91d1\u878d\u5206\u6790\u9886\u57df\uff0c\u9884\u6d4b\u7ed3\u679c\u5bf9\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u8c03\u6574\u4e14\u96be\u4ee5\u5728\u4e13\u6709\u73af\u5883\u4e2d\u590d\u5236\uff1b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u7075\u6d3b\uff0c\u4f46\u5728\u53ef\u89e3\u91ca\u6027\u3001\u968f\u673a\u8bad\u7ec3\u8fc7\u7a0b\u53ca\u8de8\u73af\u5883\u91cd\u73b0\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u4e2a\u65e2\u80fd\u4fdd\u8bc1\u53ef\u89e3\u91ca\u6027\u53c8\u80fd\u786e\u4fdd\u6807\u51c6\u5316\u5de5\u4f5c\u6d41\u4ee5\u53ca\u6613\u4e8e\u8bbf\u95ee\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3\u9884\u6d4b\u4e2d\u7684\u53ef\u518d\u73b0\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528Meta\u5f00\u53d1\u7684\u5f00\u6e90\u9884\u6d4b\u5de5\u5177Prophet\uff0c\u5e76\u57fa\u4e8e\u516c\u5f00\u53ef\u7528\u7684\u91d1\u878d\u548c\u96f6\u552e\u6570\u636e\u96c6\uff0c\u5c06\u5176\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u4e0e\u591a\u79cdARIMA\u8bbe\u5b9a\uff08\u81ea\u52a8\u9009\u62e9\u3001\u624b\u52a8\u6307\u5b9a\u53ca\u5b63\u8282\u6027\u53d8\u4f53\uff09\u4ee5\u53ca\u968f\u673a\u68ee\u6797\u8fdb\u884c\u6bd4\u8f83\u3002\u6574\u4e2a\u5b9e\u9a8c\u8bbe\u8ba1\u53d7\u5230\u4e25\u683c\u63a7\u5236\u5e76\u88ab\u5b8c\u6574\u8bb0\u5f55\u4e0b\u6765\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cProphet\u901a\u8fc7\u5176\u72ec\u7279\u7684\u52a0\u6cd5\u7ed3\u6784\u3001\u5f00\u6e90\u5b9e\u73b0\u65b9\u5f0f\u53ca\u6807\u51c6\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u826f\u597d\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u9884\u6d4b\u5de5\u4f5c\u7684\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u4f7f\u7528Python\u7684\u5177\u4f53\u793a\u4f8b\u6765\u8bf4\u660eProphet\u5982\u4f55\u7b80\u5316\u9884\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u5e76\u4e0e\u5206\u6790\u7ba1\u9053\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "\u672c\u7814\u7a76\u5c06Prophet\u5b9a\u4f4d\u4e3a\u652f\u6301\u9a8c\u8bc1\u3001\u5ba1\u8ba1\u80fd\u529b\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\u7684\u57fa\u77f3\uff0c\u4e3a\u57fa\u4e8ePython\u7684\u7814\u7a76\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u53c2\u8003\u6846\u67b6\uff0c\u4fc3\u8fdb\u4e86\u53ef\u590d\u5236\u6027\u9884\u6d4b\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.06016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06016", "abs": "https://arxiv.org/abs/2601.06016", "authors": ["\u00de\u00f3r Sverrisson", "Steinn Gu\u00f0mundsson"], "title": "LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection", "comment": null, "summary": "Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u766b\u75eb\u68c0\u6d4b\u5668LookAroundNet\uff0c\u8be5\u68c0\u6d4b\u5668\u5229\u7528\u66f4\u5bbd\u7684\u65f6\u95f4\u7a97\u53e3\u6765\u5efa\u6a21\u766b\u75eb\u6d3b\u52a8\uff0c\u5e76\u7ed3\u5408\u4e86\u611f\u5174\u8da3\u7684\u6bb5\u843d\u524d\u540e\u7684\u8111\u7535\u56fe\u4fe1\u53f7\u3002\u901a\u8fc7\u5728\u591a\u79cd\u4e34\u5e8a\u73af\u5883\u548c\u8bb0\u5f55\u6a21\u5f0f\u4e0b\u5bf9\u591a\u4e2a\u8111\u7535\u56fe\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aLookAroundNet\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9002\u5408\u4e34\u5e8a\u90e8\u7f72\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u7531\u4e8e\u60a3\u8005\u3001\u8bb0\u5f55\u6761\u4ef6\u548c\u4e34\u5e8a\u73af\u5883\u95f4\u766b\u75eb\u52a8\u6001\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u4ece\u8111\u7535\u56fe\uff08EEG\uff09\u81ea\u52a8\u68c0\u6d4b\u766b\u75eb\u4ecd\u7136\u5f88\u56f0\u96be\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u5e76\u63a8\u52a8\u81ea\u52a8\u5316\u766b\u75eb\u68c0\u6d4b\u6a21\u578b\u5411\u4e34\u5e8a\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLookAroundNet\u7684\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u766b\u75eb\u68c0\u6d4b\u5668\uff0c\u5b83\u4f7f\u7528\u8f83\u5bbd\u7684\u65f6\u95f4\u7a97\u53e3\u6765\u5efa\u6a21\u766b\u75eb\u6d3b\u52a8\uff0c\u5e76\u4e14\u6574\u5408\u4e86\u611f\u5174\u8da3\u7247\u6bb5\u524d\u540e\u65f6\u671f\u7684EEG\u4fe1\u53f7\uff0c\u4ee5\u6a21\u4eff\u4e34\u5e8a\u533b\u751f\u5728\u89e3\u8bfbEEG\u8bb0\u5f55\u65f6\u6240\u4f7f\u7528\u7684\u5468\u56f4\u80cc\u666f\u3002", "result": "LookAroundNet\u5728\u8de8\u6570\u636e\u96c6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5bf9\u4e8e\u4e4b\u524d\u672a\u89c1\u8fc7\u7684\u8bb0\u5f55\u6761\u4ef6\u4e5f\u663e\u793a\u51fa\u5f88\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5176\u8fd0\u884c\u6210\u672c\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4e34\u5e8a\u90e8\u7f72\u76f8\u517c\u5bb9\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6269\u5c55\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u3001\u589e\u52a0\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u4ee5\u53ca\u6a21\u578b\u96c6\u6210\u662f\u63d0\u9ad8\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5f15\u5165\u80fd\u591f\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u5206\u5e03\u5e76\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u7684\u65b0\u578b\u766b\u75eb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4e3a\u5c06\u81ea\u52a8\u766b\u75eb\u68c0\u6d4b\u6a21\u578b\u63a8\u5411\u4e34\u5e8a\u5e94\u7528\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
