<div id=toc></div>

# Table of Contents

- [cs.MM](#cs.MM) [Total: 2]
- [cs.IR](#cs.IR) [Total: 5]


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [1] [Step-Aware Residual-Guided Diffusion for EEG Spatial Super-Resolution](https://arxiv.org/abs/2510.19166)
*Hongjun Liu,Leyu Zhou,Zijianghao Yang,Chao Yao*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For real-world BCI applications, lightweight Electroencephalography (EEG)
systems offer the best cost-deployment balance. However, such spatial sparsity
of EEG limits spatial fidelity, hurting learning and introducing bias. EEG
spatial super-resolution methods aim to recover high-density EEG signals from
sparse measurements, yet is often hindered by distribution shift and signal
distortion and thus reducing fidelity and usability for EEG analysis and
visualization. To overcome these challenges, we introduce SRGDiff, a step-aware
residual-guided diffusion model that formulates EEG spatial super-resolution as
dynamic conditional generation. Our key idea is to learn a dynamic residual
condition from the low-density input that predicts the step-wise temporal and
spatial details to add and uses the evolving cue to steer the denoising process
toward high-density reconstructions. At each denoising step, the proposed
residual condition is additively fused with the previous denoiser feature maps,
then a step-dependent affine modulation scales and shifts the activation to
produce the current features. This iterative procedure dynamically extracts
step-wise temporal rhythms and spatial-topographic cues to steer high-density
recovery and maintain a fidelity-consistency balance. We adopt a comprehensive
evaluation protocol spanning signal-, feature-, and downstream-level metrics
across SEED, SEED-IV, and Localize-MI and multiple upsampling scales. SRGDiff
achieves consistent gains of up to 40% over strong baselines, proving its
superiority in the task of EEG spatial super-resolution. Moreover, topographic
visualizations comparison and substantial EEG-FID gains jointly indicate that
our SR EEG mitigates the spatial-spectral shift between low- and high-density
recordings.

</details>


### [2] [CDI-DTI: A Strong Cross-domain Interpretable Drug-Target Interaction Prediction Framework Based on Multi-Strategy Fusion](https://arxiv.org/abs/2510.19520)
*Xiangyu Li,Haojie Yang,Kaimiao Hu,Runzhi Wu,Liangliang Liu,Ran Su*

Main category: cs.MM

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate prediction of drug-target interactions (DTI) is pivotal for drug
discovery, yet existing methods often fail to address challenges like
cross-domain generalization, cold-start prediction, and interpretability. In
this work, we propose CDI-DTI, a novel cross-domain interpretable framework for
DTI prediction, designed to overcome these limitations. By integrating
multi-modal features-textual, structural, and functional-through a
multi-strategy fusion approach, CDI-DTI ensures robust performance across
different domains and in cold-start scenarios. A multi-source cross-attention
mechanism is introduced to align and fuse features early, while a bidirectional
cross-attention layer captures fine-grained intra-modal drug-target
interactions. To enhance model interpretability, we incorporate Gram Loss for
feature alignment and a deep orthogonal fusion module to eliminate redundancy.
Experimental results on several benchmark datasets demonstrate that CDI-DTI
significantly outperforms existing methods, particularly in cross-domain and
cold-start tasks, while maintaining high interpretability for practical
applications in drug-target interaction prediction.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [3] [SBAN: A Framework \& Multi-Dimensional Dataset for Large Language Model Pre-Training and Software Code Mining](https://arxiv.org/abs/2510.18936)
*Hamed Jelodar,Mohammad Meymani,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces SBAN (Source code, Binary, Assembly, and Natural
Language Description), a large-scale, multi-dimensional dataset designed to
advance the pre-training and evaluation of large language models (LLMs) for
software code analysis. SBAN comprises more than 3 million samples, including
2.9 million benign and 672,000 malware respectively, each represented across
four complementary layers: binary code, assembly instructions, natural language
descriptions, and source code. This unique multimodal structure enables
research on cross-representation learning, semantic understanding of software,
and automated malware detection. Beyond security applications, SBAN supports
broader tasks such as code translation, code explanation, and other software
mining tasks involving heterogeneous data. It is particularly suited for
scalable training of deep models, including transformers and other LLM
architectures. By bridging low-level machine representations and high-level
human semantics, SBAN provides a robust foundation for building intelligent
systems that reason about code. We believe that this dataset opens new
opportunities for mining software behavior, improving security analytics, and
enhancing LLM capabilities in pre-training and fine-tuning tasks for software
code mining.

</details>


### [4] [XGen-Q: An Explainable Domain-Adaptive LLM Framework with Retrieval-Augmented Generation for Software Security](https://arxiv.org/abs/2510.19006)
*Hamed Jelodar,Mohammad Meymani,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generative AI and large language models (LLMs) have shown strong capabilities
in code understanding, but their use in cybersecurity, particularly for malware
detection and analysis, remains limited. Existing detection systems often fail
to generalize to obfuscated or previously unseen threats, underscoring the need
for more adaptable and explainable models. To address this challenge, we
introduce XGen-Q, a domain-adapted LLM built on the Qwen-Coder architecture and
pretrained on a large-scale corpus of over one million malware samples,
spanning both source and assembly code. XGen-Q uses a multi-stage prompt
strategy combined with retrieval-augmented generation (RAG) to deliver reliable
malware identification and detailed forensic reporting, even in the presence of
complex code obfuscation. To further enhance generalization, we design a
training pipeline that systematically exposes the model to diverse obfuscation
patterns. Experimental results show that XGen-Q achieves significantly lower
perplexity than competitive baselines and exhibits strong performance on novel
malware samples, demonstrating the promise of LLM-based approaches for
interpretable and robust malware analysis.

</details>


### [5] [C2T-ID: Converting Semantic Codebooks to Textual Document Identifiers for Generative Search](https://arxiv.org/abs/2510.19221)
*Yingchen Zhang,Ruqing Zhang,Jiafeng Guo,Wenjun Peng,Sen Li,Fuyu Lv,Xueqi Cheng*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Designing document identifiers (docids) that carry rich semantic information
while maintaining tractable search spaces is a important challenge in
generative retrieval (GR). Popular codebook methods address this by building a
hierarchical semantic tree and constraining generation to its child nodes, yet
their numeric identifiers cannot leverage the large language model's pretrained
natural language understanding. Conversely, using text as docid provides more
semantic expressivity but inflates the decoding space, making the system
brittle to early-step errors. To resolve this trade-off, we propose C2T-ID: (i)
first construct semantic numerical docid via hierarchical clustering; (ii) then
extract high-frequency metadata keywords and iteratively replace each numeric
label with its cluster's top-K keywords; and (iii) an optional two-level
semantic smoothing step further enhances the fluency of C2T-ID. Experiments on
Natural Questions and Taobao's product search demonstrate that C2T-ID
significantly outperforms atomic, semantic codebook, and pure-text docid
baselines, demonstrating its effectiveness in balancing semantic expressiveness
with search space constraints.

</details>


### [6] [CoRECT: A Framework for Evaluating Embedding Compression Techniques at Scale](https://arxiv.org/abs/2510.19340)
*L. Caspari,M. Dinzinger,K. Gosh Dastidar,C. Fellicious,J. MitroviÄ‡,M. Granitzer*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dense retrieval systems have proven to be effective across various
benchmarks, but require substantial memory to store large search indices.
Recent advances in embedding compression show that index sizes can be greatly
reduced with minimal loss in ranking quality. However, existing studies often
overlook the role of corpus complexity -- a critical factor, as recent work
shows that both corpus size and document length strongly affect dense retrieval
performance. In this paper, we introduce CoRECT (Controlled Retrieval
Evaluation of Compression Techniques), a framework for large-scale evaluation
of embedding compression methods, supported by a newly curated dataset
collection. To demonstrate its utility, we benchmark eight representative types
of compression methods. Notably, we show that non-learned compression achieves
substantial index size reduction, even on up to 100M passages, with
statistically insignificant performance loss. However, selecting the optimal
compression method remains challenging, as performance varies across models.
Such variability highlights the necessity of CoRECT to enable consistent
comparison and informed selection of compression methods. All code, data, and
results are available on GitHub and HuggingFace.

</details>


### [7] [Top-P Masking for Cross Language Information Retrieval](https://arxiv.org/abs/2510.19758)
*Joseph Casale,Andrew Silverschotz,Joseph DeSimone*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Top-K masking schemes have been proposed as a method to promote sparse
representations in Information Retrieval (IR) tasks, as a simple alternative to
Floating Point Operations per Second (FLOPS) regularization. Algorithms such as
Bilingual Lexical and Document Expansion Model (BLADE), adopt this approach as
a post-processing stage. We propose using Top-P Dynamic Masking similar to
Nucleus Sampling in Large Language Models, and demonstrate better performance
than Top-K masking. Specifically, we evaluate our methods in the domain of
Cross Language Information Retrieval (CLIR)

</details>
