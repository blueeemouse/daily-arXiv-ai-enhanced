{"id": "2602.19319", "categories": ["cs.MM", "cs.AI", "cs.CR", "cs.DB", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19319", "abs": "https://arxiv.org/abs/2602.19319", "authors": ["Sujaya Maiyya", "Shantanu Sharma", "Avinash Kumar"], "title": "Health+: Empowering Individuals via Unifying Health Data", "comment": "This paper has been accepted in ACM Multimedia 2025", "summary": "Managing personal health data is a challenge in today's fragmented and institution-centric healthcare ecosystem. Individuals often lack meaningful control over their medical records, which are scattered across incompatible systems and formats. This vision paper presents Health+, a user-centric, multimodal health data management system that empowers individuals (including those with limited technical expertise) to upload, query, and share their data across modalities (e.g., text, images, reports). Rather than aiming for institutional overhaul, Health+ emphasizes individual agency by providing intuitive interfaces and intelligent recommendations for data access and sharing. At the system level, it tackles the complexity of storing, integrating, and securing heterogeneous health records, ensuring both efficiency and privacy. By unifying multimodal data and prioritizing patients, Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem.", "AI": {"tldr": "Health+ \u662f\u4e00\u4e2a\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u591a\u6a21\u5f0f\u5065\u5eb7\u6570\u636e\u7ba1\u7406\u7cfb\u7edf\uff0c\u65e8\u5728\u8ba9\u7528\u6237\u80fd\u591f\u8f7b\u677e\u4e0a\u4f20\u3001\u67e5\u8be2\u548c\u5206\u4eab\u4ed6\u4eec\u7684\u5065\u5eb7\u6570\u636e\uff0c\u540c\u65f6\u786e\u4fdd\u6570\u636e\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u4e14\u4ee5\u673a\u6784\u4e3a\u4e2d\u5fc3\uff0c\u4e2a\u4eba\u96be\u4ee5\u6709\u6548\u63a7\u5236\u81ea\u5df1\u7684\u533b\u7597\u8bb0\u5f55\u3002\u8fd9\u4e9b\u8bb0\u5f55\u5206\u6563\u5728\u4e0d\u517c\u5bb9\u7684\u7cfb\u7edf\u548c\u683c\u5f0f\u4e2d\u3002", "method": "Health+ \u901a\u8fc7\u63d0\u4f9b\u76f4\u89c2\u7684\u754c\u9762\u548c\u667a\u80fd\u63a8\u8350\u6765\u589e\u5f3a\u4e2a\u4eba\u5bf9\u5176\u5065\u5eb7\u4fe1\u606f\u7684\u8bbf\u95ee\u548c\u5206\u4eab\u80fd\u529b\uff0c\u540c\u65f6\u5728\u7cfb\u7edf\u5c42\u9762\u89e3\u51b3\u5b58\u50a8\u3001\u6574\u5408\u53ca\u4fdd\u62a4\u5f02\u6784\u5065\u5eb7\u8bb0\u5f55\u6240\u5e26\u6765\u7684\u590d\u6742\u95ee\u9898\u3002", "result": "Health+ \u80fd\u591f\u7edf\u4e00\u4e0d\u540c\u5f62\u5f0f\u7684\u6570\u636e\uff0c\u5e76\u4f18\u5148\u8003\u8651\u60a3\u8005\u9700\u6c42\uff0c\u4e3a\u5efa\u7acb\u66f4\u52a0\u8fde\u63a5\u7d27\u5bc6\u3001\u6613\u4e8e\u7406\u89e3\u4e14\u7531\u7528\u6237\u63a7\u5236\u7684\u5065\u5eb7\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "Health+ \u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u4e2a\u4eba\uff08\u5305\u62ec\u6280\u672f\u77e5\u8bc6\u6709\u9650\u7684\u4eba\uff09\u80fd\u591f\u66f4\u597d\u5730\u7ba1\u7406\u81ea\u5df1\u7684\u5065\u5eb7\u6570\u636e\uff0c\u4fc3\u8fdb\u4e86\u66f4\u9ad8\u6548\u548c\u4e2a\u4eba\u5316\u7684\u5065\u5eb7\u7ba1\u7406\u65b9\u5f0f\u3002"}}
{"id": "2602.19585", "categories": ["cs.MM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19585", "abs": "https://arxiv.org/abs/2602.19585", "authors": ["Chunlei Meng", "Jiabin Luo", "Zhenglin Yan", "Zhenyu Yu", "Rong Fu", "Zhongxue Gan", "Chun Ouyang"], "title": "Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis", "comment": "This study has been Accepted by CVPR 2026", "summary": "Multimodal Sentiment Analysis (MSA) integrates language, visual, and acoustic modalities to infer human sentiment. Most existing methods either focus on globally shared representations or modality-specific features, while overlooking signals that are shared only by certain modality pairs. This limits the expressiveness and discriminative power of multimodal representations. To address this limitation, we propose a Tri-Subspace Disentanglement (TSD) framework that explicitly factorizes features into three complementary subspaces: a common subspace capturing global consistency, submodally-shared subspaces modeling pairwise cross-modal synergies, and private subspaces preserving modality-specific cues. To keep these subspaces pure and independent, we introduce a decoupling supervisor together with structured regularization losses. We further design a Subspace-Aware Cross-Attention (SACA) fusion module that adaptively models and integrates information from the three subspaces to obtain richer and more robust representations. Experiments on CMU-MOSI and CMU-MOSEI demonstrate that TSD achieves state-of-the-art performance across all key metrics, reaching 0.691 MAE on CMU-MOSI and 54.9% ACC-7 on CMU-MOSEI, and also transfers well to multimodal intent recognition tasks. Ablation studies confirm that tri-subspace disentanglement and SACA jointly enhance the modeling of multi-granular cross-modal sentiment cues.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u5b50\u7a7a\u95f4\u89e3\u7f20(TSD)\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\uff0c\u901a\u8fc7\u5c06\u7279\u5f81\u5206\u89e3\u4e3a\u4e09\u4e2a\u4e92\u8865\u7684\u5b50\u7a7a\u95f4\u6765\u63d0\u9ad8\u8868\u793a\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5b50\u7a7a\u95f4\u611f\u77e5\u4ea4\u53c9\u6ce8\u610f\u529b(SACA)\u878d\u5408\u6a21\u5757\u4ee5\u83b7\u5f97\u66f4\u4e30\u5bcc\u3001\u66f4\u9c81\u68d2\u7684\u8868\u793a\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5173\u952e\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5168\u5c40\u5171\u4eab\u8868\u793a\u6216\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u4e0a\uff0c\u5ffd\u7565\u4e86\u4ec5\u7531\u67d0\u4e9b\u6a21\u6001\u5bf9\u5171\u4eab\u7684\u4fe1\u53f7\uff0c\u9650\u5236\u4e86\u591a\u6a21\u6001\u8868\u793a\u7684\u8868\u73b0\u529b\u548c\u533a\u5206\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u5b50\u7a7a\u95f4\u89e3\u7f20\uff08TSD\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u663e\u5f0f\u5730\u5c06\u7279\u5f81\u5206\u89e3\u6210\u4e09\u4e2a\u4e92\u8865\u5b50\u7a7a\u95f4\uff1a\u6355\u83b7\u5168\u5c40\u4e00\u81f4\u6027\u7684\u516c\u5171\u5b50\u7a7a\u95f4\u3001\u5efa\u6a21\u6210\u5bf9\u8de8\u6a21\u6001\u534f\u540c\u4f5c\u7528\u7684\u5b50\u6a21\u6001\u5171\u4eab\u5b50\u7a7a\u95f4\u4ee5\u53ca\u4fdd\u6301\u6a21\u6001\u7279\u5b9a\u7ebf\u7d22\u7684\u79c1\u6709\u5b50\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u89e3\u8026\u76d1\u7763\u5668\u4e0e\u7ed3\u6784\u5316\u6b63\u5219\u5316\u635f\u5931\u4ee5\u4fdd\u8bc1\u8fd9\u4e9b\u5b50\u7a7a\u95f4\u7684\u7eaf\u51c0\u6027\u548c\u72ec\u7acb\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5b50\u7a7a\u95f4\u611f\u77e5\u4ea4\u53c9\u6ce8\u610f\u529b\uff08SACA\uff09\u878d\u5408\u6a21\u5757\u6765\u81ea\u9002\u5e94\u5730\u5efa\u6a21\u548c\u6574\u5408\u6765\u81ea\u4e09\u4e2a\u5b50\u7a7a\u95f4\u7684\u4fe1\u606f\u3002", "result": "\u5728CMU-MOSI\u548cCMU-MOSEI\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTSD\u5728\u6240\u6709\u5173\u952e\u6307\u6807\u4e0a\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4f8b\u5982\u5728CMU-MOSI\u4e0a\u8fbe\u52300.691 MAE\uff0c\u5728CMU-MOSEI\u4e0a\u8fbe\u523054.9% ACC-7\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u4e5f\u5f88\u597d\u5730\u8fc1\u79fb\u5230\u4e86\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e2d\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u4e09\u5b50\u7a7a\u95f4\u89e3\u7f20\u4e0eSACA\u5171\u540c\u589e\u5f3a\u4e86\u591a\u5c42\u6b21\u8de8\u6a21\u6001\u60c5\u611f\u7ebf\u7d22\u7684\u5efa\u6a21\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51faTSD\u6846\u67b6\u53ca\u5176SACA\u878d\u5408\u6a21\u5757\uff0c\u672c\u7814\u7a76\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5224\u522b\u529b\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002"}}
{"id": "2602.19040", "categories": ["cs.IR", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.19040", "abs": "https://arxiv.org/abs/2602.19040", "authors": ["Jiaxin Wu", "Xiao-Yong Wei", "Qing Li"], "title": "Adaptive Multi-Agent Reasoning for Text-to-Video Retrieval", "comment": null, "summary": "The rise of short-form video platforms and the emergence of multimodal large language models (MLLMs) have amplified the need for scalable, effective, zero-shot text-to-video retrieval systems. While recent advances in large-scale pretraining have improved zero-shot cross-modal alignment, existing methods still struggle with query-dependent temporal reasoning, limiting their effectiveness on complex queries involving temporal, logical, or causal relationships. To address these limitations, we propose an adaptive multi-agent retrieval framework that dynamically orchestrates specialized agents over multiple reasoning iterations based on the demands of each query. The framework includes: (1) a retrieval agent for scalable retrieval over large video corpora, (2) a reasoning agent for zero-shot contextual temporal reasoning, and (3) a query reformulation agent for refining ambiguous queries and recovering performance for those that degrade over iterations. These agents are dynamically coordinated by an orchestration agent, which leverages intermediate feedback and reasoning outcomes to guide execution. We also introduce a novel communication mechanism that incorporates retrieval-performance memory and historical reasoning traces to improve coordination and decision-making. Experiments on three TRECVid benchmarks spanning eight years show that our framework achieves a twofold improvement over CLIP4Clip and significantly outperforms state-of-the-art methods by a large margin.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u96f6\u6837\u672c\u6587\u672c\u5230\u89c6\u9891\u68c0\u7d22\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u65f6\u9047\u5230\u7684\u65f6\u5e8f\u3001\u903b\u8f91\u6216\u56e0\u679c\u5173\u7cfb\u63a8\u7406\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5305\u62ec\u68c0\u7d22\u667a\u80fd\u4f53\u3001\u63a8\u7406\u667a\u80fd\u4f53\u548c\u67e5\u8be2\u91cd\u6784\u667a\u80fd\u4f53\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u534f\u8c03\u667a\u80fd\u4f53\u52a8\u6001\u7ba1\u7406\u8fd9\u4e9b\u667a\u80fd\u4f53\u95f4\u7684\u5408\u4f5c\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u4fe1\u673a\u5236\u6765\u52a0\u5f3a\u534f\u4f5c\u4e0e\u51b3\u7b56\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6b64\u65b9\u6cd5\u76f8\u6bd4CLIP4Clip\u548c\u5176\u4ed6\u6700\u5148\u8fdb\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u6837\u672c\u8de8\u6a21\u6001\u5bf9\u9f50\u6280\u672f\u867d\u7136\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u5728\u5904\u7406\u5305\u542b\u65f6\u95f4\u3001\u903b\u8f91\u6216\u56e0\u679c\u5173\u7cfb\u7b49\u590d\u6742\u67e5\u8be2\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\u6027\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u4f9d\u8d56\u4e8e\u67e5\u8be2\u7684\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u62ec\uff1a1) \u7528\u4e8e\u5927\u89c4\u6a21\u89c6\u9891\u5e93\u68c0\u7d22\u7684\u68c0\u7d22\u667a\u80fd\u4f53\uff1b2) \u8fdb\u884c\u96f6\u6837\u672c\u4e0a\u4e0b\u6587\u65f6\u95f4\u63a8\u7406\u7684\u63a8\u7406\u667a\u80fd\u4f53\uff1b3) \u5bf9\u6a21\u7cca\u67e5\u8be2\u8fdb\u884c\u7ec6\u5316\u5e76\u6062\u590d\u56e0\u8fed\u4ee3\u800c\u6027\u80fd\u4e0b\u964d\u7684\u67e5\u8be2\u91cd\u6784\u667a\u80fd\u4f53\u3002\u6b64\u5916\uff0c\u8fd8\u6709\u4e00\u4e2a\u534f\u8c03\u667a\u80fd\u4f53\u8d1f\u8d23\u6839\u636e\u4e2d\u95f4\u53cd\u9988\u548c\u63a8\u7406\u7ed3\u679c\u52a8\u6001\u5730\u534f\u8c03\u4e0a\u8ff0\u667a\u80fd\u4f53\u7684\u5de5\u4f5c\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u4fe1\u673a\u5236\uff0c\u8be5\u673a\u5236\u5229\u7528\u68c0\u7d22\u6027\u80fd\u8bb0\u5fc6\u548c\u5386\u53f2\u63a8\u7406\u8f68\u8ff9\u6765\u63d0\u9ad8\u534f\u4f5c\u4e0e\u51b3\u7b56\u6548\u7387\u3002", "result": "\u5728\u4e09\u4e2aTRECVid\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u6db5\u76d6\u4e86\u516b\u5e74\u7684\u65f6\u95f4\u8de8\u5ea6\uff0c\u7ed3\u679c\u663e\u793a\u63d0\u51fa\u7684\u6846\u67b6\u6bd4CLIP4Clip\u63d0\u9ad8\u4e86\u4e24\u500d\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u8fdc\u8d85\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u591a\u667a\u80fd\u4f53\u68c0\u7d22\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u590d\u6742\u7684\u67e5\u8be2\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8fdb\u884c\u65f6\u95f4\u3001\u903b\u8f91\u6216\u56e0\u679c\u5173\u7cfb\u63a8\u7406\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u5f15\u5165\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u53ca\u521b\u65b0\u7684\u901a\u4fe1\u673a\u5236\uff0c\u4e0d\u4ec5\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u800c\u4e14\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u73b0\u3002"}}
{"id": "2602.18641", "categories": ["cs.DC", "physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18641", "abs": "https://arxiv.org/abs/2602.18641", "authors": ["Paul Borrill"], "title": "The Category Mistake of Cislunar Time: Why NASA Cannot Synchronize What Doesn't Exist", "comment": "13 pages, no figures", "summary": "In April 2024, the White House directed NASA to establish Coordinated Lunar Time (LTC) by December 2026. The programme assumes that a unified time standard can be constructed by deploying atomic clocks on the lunar surface, computing relativistic corrections, and distributing synchronized time via LunaNet. This paper argues that the entire enterprise rests on a category mistake in the sense introduced by Ryle and developed by Spekkens in quantum foundations: it treats \"synchronized time\" as an ontic entity -- something that exists independently and can be transmitted from authoritative sources to dependent receivers -- when it is in fact an epistemic construct: a model-dependent representation of observer-relative clock relationships. We analyze the cislunar time programme through the lens of Forward-In-Time-Only (FITO) assumptions, Spekkens' Leibnizian operationalism, the Wood-Spekkens fine-tuning argument, and the distinction between ontic and epistemic interpretations that has dissolved long-standing puzzles in quantum mechanics. We show that the same conceptual move that dissolves quantum \"mysteries\" -- recognizing what is epistemic versus what is ontic -- dissolves the apparent coherence of the cislunar time programme and reveals it as an engineering project built on a philosophical confusion. We sketch a transactional alternative grounded in bilateral atomic interactions rather than unidirectional time distribution.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7f8e\u56fd\u767d\u5bab\u6307\u793aNASA\u5efa\u7acb\u7684\u534f\u8c03\u6708\u7403\u65f6\u95f4\uff08LTC\uff09\u8ba1\u5212\uff0c\u6307\u51fa\u8be5\u8ba1\u5212\u57fa\u4e8e\u4e00\u4e2a\u7c7b\u522b\u9519\u8bef\uff1a\u5c06\u201c\u540c\u6b65\u65f6\u95f4\u201d\u89c6\u4e3a\u4e00\u79cd\u672c\u4f53\u5b9e\u4f53\uff0c\u800c\u5b9e\u9645\u4e0a\u5b83\u662f\u4e00\u4e2a\u8ba4\u8bc6\u8bba\u6784\u9020\u3002\u901a\u8fc7\u524d\u5411\u65f6\u95f4\u552f\u4e00\u6027\u5047\u8bbe\u3001Spekkens\u7684\u83b1\u5e03\u5c3c\u8328\u64cd\u4f5c\u4e3b\u4e49\u7b49\u89c6\u89d2\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u8fb9\u539f\u5b50\u4ea4\u4e92\u800c\u975e\u5355\u5411\u65f6\u95f4\u5206\u914d\u7684\u4ea4\u6613\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63ed\u793aNASA\u7684\u534f\u8c03\u6708\u7403\u65f6\u95f4\u8ba1\u5212\u80cc\u540e\u5b58\u5728\u7684\u54f2\u5b66\u6df7\u6dc6\uff0c\u5e76\u63d0\u51fa\u66f4\u5408\u7406\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u54f2\u5b66\u5206\u6790\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u901a\u8fc7\u524d\u5411\u65f6\u95f4\u552f\u4e00\u6027\u5047\u8bbe\u3001Spekkens\u7684\u83b1\u5e03\u5c3c\u8328\u64cd\u4f5c\u4e3b\u4e49\u3001Wood-Spekkens\u7cbe\u7ec6\u8c03\u8282\u8bba\u8bc1\u4ee5\u53ca\u672c\u4f53\u4e0e\u8ba4\u8bc6\u8bba\u89e3\u91ca\u4e4b\u95f4\u7684\u533a\u5206\u6765\u5ba1\u89c6cislunar\u65f6\u95f4\u9879\u76ee\u3002", "result": "\u8868\u660e\u5c06\u91cf\u5b50\u529b\u5b66\u4e2d\u7684\u6982\u5ff5\u8f6c\u53d8\u5e94\u7528\u4e8ecislunar\u65f6\u95f4\u9879\u76ee\uff0c\u53ef\u4ee5\u6f84\u6e05\u9879\u76ee\u4e2d\u5173\u4e8e\u65f6\u95f4\u540c\u6b65\u6027\u7684\u8bef\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u73b0\u6709\u5de5\u7a0b\u8bbe\u8ba1\u4e0a\u7684\u6839\u672c\u6027\u95ee\u9898\u3002", "conclusion": "\u534f\u8c03\u6708\u7403\u65f6\u95f4\u8ba1\u5212\u5efa\u7acb\u5728\u4e00\u4e2a\u54f2\u5b66\u6df7\u6dc6\u4e4b\u4e0a\uff0c\u9700\u8981\u91cd\u65b0\u8003\u8651\u5176\u57fa\u7840\uff1b\u5efa\u8bae\u63a2\u7d22\u4e00\u79cd\u57fa\u4e8e\u53cc\u8fb9\u539f\u5b50\u4ea4\u4e92\u7684\u65b0\u65b9\u6cd5\u4f5c\u4e3a\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18437", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18437", "abs": "https://arxiv.org/abs/2602.18437", "authors": ["Yixing Peng", "Licheng Zhang", "Shancheng Fang", "Yi Liu", "Peijian Gu", "Quan Wang"], "title": "FineRef: Fine-Grained Error Reflection and Correction for Long-Form Generation with Citations", "comment": "9 pages, 4figures, AAAI2026", "summary": "Generating with citations is crucial for trustworthy Large Language Models (LLMs), yet even advanced LLMs often produce mismatched or irrelevant citations. Existing methods over-optimize citation fidelity while overlooking relevance to the user query, which degrades answer quality and robustness in real-world settings with noisy or irrelevant retrieved content. Moreover, the prevailing single-pass paradigm struggles to deliver optimal answers in long-form generation that requiring multiple citations. To address these limitations, we propose FineRef, a framework based on Fine-grained error Reflection, which explicitly teaches the model to self-identify and correct two key citation errors, mismatch and irrelevance, on a per-citation basis. FineRef follows a two-stage training strategy. The first stage instills an \"attempt-reflect-correct\" behavioral pattern via supervised fine-tuning, using fine-grained and controllable reflection data constructed by specialized lightweight models. An online self-reflective bootstrapping strategy is designed to improve generalization by iteratively enriching training data with verified, self-improving examples. To further enhance the self-reflection and correction capability, the second stage applies process-level reinforcement learning with a multi-dimensional reward scheme that promotes reflection accuracy, answer quality, and correction gain. Experiments on the ALCE benchmark demonstrate that FineRef significantly improves both citation performance and answer accuracy. Our 7B model outperforms GPT-4 by up to 18% in Citation F1 and 4% in EM Recall, while also surpassing the state-of-the-art model across key evaluation metrics. FineRef also exhibits strong generalization and robustness in domain transfer settings and noisy retrieval scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFineRef\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u9519\u8bef\u53cd\u601d\u6765\u6559\u5bfc\u6a21\u578b\u81ea\u6211\u8bc6\u522b\u548c\u7ea0\u6b63\u5f15\u7528\u9519\u8bef\uff0c\u5305\u62ec\u4e0d\u5339\u914d\u548c\u4e0d\u76f8\u5173\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u4e86\u76d1\u7763\u5fae\u8c03\u548c\u8fc7\u7a0b\u7ea7\u5f3a\u5316\u5b66\u4e60\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFineRef\u5728\u5f15\u7528\u6027\u80fd\u548c\u7b54\u6848\u51c6\u786e\u6027\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u9886\u57df\u8f6c\u79fb\u548c\u566a\u58f0\u68c0\u7d22\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5e26\u6709\u5f15\u7528\u7684\u5185\u5bb9\u65f6\uff0c\u7ecf\u5e38\u4f1a\u51fa\u73b0\u5f15\u7528\u4e0e\u5185\u5bb9\u4e0d\u5339\u914d\u6216\u4e0d\u76f8\u5173\u7684\u60c5\u51b5\u3002\u5f53\u524d\u7684\u65b9\u6cd5\u8fc7\u4e8e\u4f18\u5316\u5f15\u7528\u7684\u51c6\u786e\u6027\u800c\u5ffd\u89c6\u4e86\u4e0e\u7528\u6237\u67e5\u8be2\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u5bfc\u81f4\u4e86\u7b54\u6848\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u7684\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u5728\u9700\u8981\u591a\u4e2a\u5f15\u7528\u7684\u957f\u6587\u672c\u751f\u6210\u4e2d\uff0c\u5355\u6b21\u5904\u7406\u7684\u65b9\u5f0f\u96be\u4ee5\u63d0\u4f9b\u6700\u4f73\u7b54\u6848\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86FineRef\u6846\u67b6\u3002", "method": "FineRef\u6846\u67b6\u57fa\u4e8e\u7ec6\u7c92\u5ea6\u9519\u8bef\u53cd\u601d\u8bbe\u8ba1\uff0c\u65e8\u5728\u660e\u786e\u5730\u6559\u4f1a\u6a21\u578b\u5982\u4f55\u81ea\u6211\u8bc6\u522b\u5e76\u9010\u4e2a\u7ea0\u6b63\u4e24\u5927\u7c7b\u5f15\u7528\u9519\u8bef\uff1a\u4e0d\u5339\u914d\u548c\u4e0d\u76f8\u5173\u3002\u5b83\u91c7\u7528\u4e86\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5f15\u5165\u201c\u5c1d\u8bd5-\u53cd\u601d-\u7ea0\u6b63\u201d\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u4f7f\u7528\u4e13\u95e8\u8f7b\u91cf\u7ea7\u6a21\u578b\u6784\u5efa\u7684\u7cbe\u7ec6\u53ef\u63a7\u53cd\u601d\u6570\u636e\u8fdb\u884c\uff1b\u540c\u65f6\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5728\u7ebf\u81ea\u53cd\u601d\u5f15\u5bfc\u7b56\u7565\uff0c\u901a\u8fc7\u8fed\u4ee3\u589e\u52a0\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u3001\u81ea\u6211\u6539\u8fdb\u7684\u4f8b\u5b50\u6765\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u4ee5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002\u7b2c\u4e8c\u9636\u6bb5\u5219\u5e94\u7528\u8fc7\u7a0b\u7ea7\u522b\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u914d\u5907\u591a\u7ef4\u5ea6\u5956\u52b1\u65b9\u6848\u4ee5\u4fc3\u8fdb\u53cd\u601d\u51c6\u786e\u6027\u3001\u7b54\u6848\u8d28\u91cf\u4ee5\u53ca\u4fee\u6b63\u589e\u76ca\u3002", "result": "\u5728ALCE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u663e\u793a\uff0cFineRef\u5728\u5f15\u7528\u8868\u73b0\u548c\u7b54\u6848\u51c6\u786e\u7387\u65b9\u9762\u90fd\u6709\u663e\u8457\u6539\u8fdb\u3002\u76f8\u6bd4GPT-4\uff0c7B\u6a21\u578b\u5728Citation F1\u4e0a\u63d0\u9ad8\u4e86\u6700\u591a18%\uff0cEM Recall\u4e0a\u63d0\u9ad8\u4e864%\uff0c\u5e76\u4e14\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0cFineRef\u8fd8\u5728\u9886\u57df\u8f6c\u6362\u8bbe\u7f6e\u53ca\u566a\u97f3\u68c0\u7d22\u60c5\u666f\u4e0b\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u901a\u7528\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0cFineRef\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u5f15\u7528\u95ee\u9898\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5f15\u7528\u7684\u51c6\u786e\u6027\u548c\u7b54\u6848\u7684\u8d28\u91cf\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u4e8e\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u9002\u5e94\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.18492", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18492", "abs": "https://arxiv.org/abs/2602.18492", "authors": ["Muhammad Aziz Ullah", "Abdul Serwadda"], "title": "Vibe Coding on Trial: Operating Characteristics of Unanimous LLM Juries", "comment": "Submitted to IEEE International Conference on Semantic Computing 2026", "summary": "Large Language Models (LLMs) are now good enough at coding that developers can describe intent in plain language and let the tool produce the first code draft, a workflow increasingly built into tools like GitHub Copilot, Cursor, and Replit. What is missing is a reliable way to tell which model written queries are safe to accept without sending everything to a human. We study the application of an LLM jury to run this review step. We first benchmark 15 open models on 82 MySQL text to SQL tasks using an execution grounded protocol to get a clean baseline of which models are strong. From the six best models we build unanimous committees of sizes 1 through 6 that see the prompt, schema, and candidate SQL and accept it only when every member says it is correct. This rule matches safety first deployments where false accepts are more costly than false rejects. We measure true positive rate, false positive rate and Youden J and we also look at committees per generator. Our results show that single model judges are uneven, that small unanimous committees of strong models can cut false accepts while still passing many good queries, and that the exact committee composition matters significantly.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u59d4\u5458\u4f1a\u6765\u5ba1\u67e5\u7531\u5176\u4ed6\u6a21\u578b\u751f\u6210\u7684SQL\u67e5\u8be2\u7684\u5b89\u5168\u6027\u3002\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u786e\u5b9a\u4e86\u6700\u5f3a\u7684\u516d\u4e2a\u6a21\u578b\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u6a21\u578b\u6784\u5efa\u4e86\u4e00\u81f4\u6027\u59d4\u5458\u4f1a\uff0c\u4ee5\u51cf\u5c11\u9519\u8bef\u63a5\u53d7\u7387\u540c\u65f6\u4fdd\u6301\u9ad8\u901a\u8fc7\u7387\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c0f\u89c4\u6a21\u7684\u4e00\u81f4\u6027\u59d4\u5458\u4f1a\u5728\u786e\u4fdd\u5b89\u5168\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u59d4\u5458\u4f1a\u7684\u5177\u4f53\u7ec4\u6210\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u7a0b\u65b9\u9762\u7684\u8868\u73b0\u8d8a\u6765\u8d8a\u51fa\u8272\uff0c\u5f00\u53d1\u8005\u53ef\u4ee5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u9700\u6c42\u5e76\u8ba9\u5de5\u5177\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u521d\u7a3f\u3002\u7136\u800c\uff0c\u7f3a\u4e4f\u4e00\u79cd\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u5224\u65ad\u54ea\u4e9b\u7531\u6a21\u578b\u751f\u6210\u7684\u67e5\u8be2\u53ef\u4ee5\u76f4\u63a5\u63a5\u53d7\u800c\u4e0d\u5fc5\u4eba\u5de5\u68c0\u67e5\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528LLM\u59d4\u5458\u4f1a\u6765\u8fdb\u884c\u8fd9\u4e00\u5ba1\u6838\u6b65\u9aa4\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u7b2c\u4e00\u7684\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u9519\u8bef\u63a5\u53d7\u6bd4\u9519\u8bef\u62d2\u7edd\u66f4\u9700\u907f\u514d\u3002", "method": "\u9996\u5148\u5bf915\u4e2a\u5f00\u6e90\u6a21\u578b\u572882\u9879MySQL\u6587\u672c\u5230SQL\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u57fa\u4e8e\u6267\u884c\u7684\u534f\u8bae\u6765\u83b7\u5f97\u4e00\u4e2a\u6e05\u6670\u7684\u57fa\u7ebf\uff0c\u627e\u51fa\u5176\u4e2d\u6700\u5f3a\u7684\u516d\u4e2a\u6a21\u578b\u3002\u7136\u540e\uff0c\u4ece\u8fd9\u516d\u4e2a\u6a21\u578b\u4e2d\u6784\u5efa\u4e86\u5927\u5c0f\u4e3a1\u81f36\u7684\u4e0d\u540c\u4e00\u81f4\u6027\u59d4\u5458\u4f1a\uff0c\u53ea\u6709\u5f53\u6240\u6709\u6210\u5458\u90fd\u8ba4\u4e3a\u7ed9\u5b9a\u7684SQL\u67e5\u8be2\u6b63\u786e\u65f6\u624d\u4e88\u4ee5\u63a5\u53d7\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5355\u4e00\u6a21\u578b\u4f5c\u4e3a\u88c1\u5224\u7684\u8868\u73b0\u53c2\u5dee\u4e0d\u9f50\uff1b\u800c\u7531\u5f3a\u6a21\u578b\u7ec4\u6210\u7684\u5c0f\u89c4\u6a21\u4e00\u81f4\u6027\u59d4\u5458\u4f1a\u80fd\u591f\u6709\u6548\u964d\u4f4e\u9519\u8bef\u63a5\u53d7\u7387\uff0c\u540c\u65f6\u4ecd\u80fd\u901a\u8fc7\u5927\u91cf\u6709\u6548\u7684\u67e5\u8be2\uff1b\u59d4\u5458\u4f1a\u7684\u5177\u4f53\u6784\u6210\u5bf9\u5176\u6027\u80fd\u6709\u7740\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u7531\u51e0\u4e2a\u5f3a\u5927\u6a21\u578b\u7ec4\u6210\u7684\u4e00\u81f4\u6027\u59d4\u5458\u4f1a\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2dSQL\u67e5\u8be2\u7684\u5b89\u5168\u6027\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u8003\u8651\u59d4\u5458\u4f1a\u6210\u5458\u7684\u9009\u62e9\u3002"}}
{"id": "2602.18534", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.18534", "abs": "https://arxiv.org/abs/2602.18534", "authors": ["Hanliang Zhang", "Arindam Sharma", "Cristina David", "Meng Wang", "Brandon Paulsen", "Daniel Kroening", "Wenjia Ye", "Taro Sekiyama"], "title": "Validated Code Translation for Projects with External Libraries", "comment": null, "summary": "Large Language Models (LLMs) have shown promise for program translation, particularly for migrating systems code to memory-safe languages such as Rust. However, existing approaches struggle when source programs depend on external libraries: LLMs frequently hallucinate non-existent target APIs and fail to generate call-enabling imports; moreover, validating semantic equivalence is challenging when the code manipulates opaque, library-defined types. We present a translation and validation framework for translating Go projects with external dependencies to Rust. Our approach combines (i) a retrieval mechanism that maps Go library APIs to Rust APIs, and (ii) a cross-language validation pipeline that establishes language interoperability in the presence of opaque library types by synthesising adapters exclusively from public library APIs, prior to validating I/O equivalence. We evaluate our system on six real-world Go repositories with non-trivial external dependencies. Our approach significantly increases both the compilation and equivalence success rate (up to 100% in the most dependency-heavy case; approx. 2x on average) by enabling validated translation that manipulate opaque, library-defined types.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u673a\u5236\u548c\u8de8\u8bed\u8a00\u9a8c\u8bc1\u6d41\u7a0b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u5177\u6709\u5916\u90e8\u4f9d\u8d56\u7684Go\u9879\u76ee\u7ffb\u8bd1\u6210Rust\uff0c\u5e76\u4e14\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u7f16\u8bd1\u6210\u529f\u7387\u548c\u7b49\u4ef7\u6027\u9a8c\u8bc1\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4f9d\u8d56\u4e8e\u5916\u90e8\u5e93\u7684\u6e90\u7a0b\u5e8f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f1a\u51fa\u73b0\u6784\u9020\u4e0d\u5b58\u5728\u7684\u76ee\u6807API\u4ee5\u53ca\u65e0\u6cd5\u751f\u6210\u8c03\u7528\u6240\u9700\u7684\u5bfc\u5165\u7b49\u95ee\u9898\uff1b\u6b64\u5916\uff0c\u5728\u4ee3\u7801\u64cd\u4f5c\u4e0d\u900f\u660e\u7684\u3001\u7531\u5e93\u5b9a\u4e49\u7684\u7c7b\u578b\u65f6\uff0c\u9a8c\u8bc1\u8bed\u4e49\u7b49\u4ef7\u6027\u4e5f\u53d8\u5f97\u975e\u5e38\u56f0\u96be\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6709\u5916\u90e8\u4f9d\u8d56\u7684Go\u9879\u76ee\u5411Rust\u8f6c\u6362\u7684\u7ffb\u8bd1\u53ca\u9a8c\u8bc1\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\uff08i\uff09\u4e00\u79cd\u6620\u5c04Go\u5e93API\u5230Rust API\u7684\u68c0\u7d22\u673a\u5236\uff0c\u4ee5\u53ca\uff08ii\uff09\u4e00\u79cd\u8de8\u8bed\u8a00\u9a8c\u8bc1\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u4ec5\u4ece\u516c\u5171\u5e93API\u5408\u6210\u9002\u914d\u5668\u6765\u5efa\u7acb\u5b58\u5728\u4e0d\u900f\u660e\u5e93\u7c7b\u578b\u65f6\u7684\u8bed\u8a00\u4e92\u64cd\u4f5c\u6027\uff0c\u7136\u540e\u9a8c\u8bc1I/O\u7b49\u4ef7\u6027\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5bf9\u516d\u4e2a\u5177\u6709\u975e\u5e73\u51e1\u5916\u90e8\u4f9d\u8d56\u7684\u5b9e\u9645Go\u4ed3\u5e93\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u7f16\u8bd1\u6210\u529f\u548c\u7b49\u4ef7\u6027\u9a8c\u8bc1\u7684\u6210\u529f\u7387\uff0c\u5728\u4f9d\u8d56\u6700\u91cd\u7684\u60c5\u51b5\u4e0b\u53ef\u8fbe100%\uff0c\u5e73\u5747\u7ea6\u4e3a\u539f\u6765\u7684\u4e24\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u7ffb\u8bd1\u4e0e\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u6e90\u4ee3\u7801\u4f9d\u8d56\u5916\u90e8\u5e93\u65f6\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7a0b\u5e8f\u7ffb\u8bd1\u5b58\u5728\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e0d\u900f\u660e\u5e93\u5b9a\u4e49\u7c7b\u578b\u65f6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u540e\u7684\u4ee3\u7801\u8d28\u91cf\u4e0e\u6b63\u786e\u6027\u3002"}}
{"id": "2602.18465", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18465", "abs": "https://arxiv.org/abs/2602.18465", "authors": ["Sanjeev Panta", "Xu Yuan", "Li Chen", "Nian-Feng Tzeng"], "title": "Revisiting the Seasonal Trend Decomposition for Enhanced Time Series Forecasting", "comment": "5 pages, accepted at 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2026)", "summary": "Time series forecasting presents significant challenges in real-world applications across various domains. Building upon the decomposition of the time series, we enhance the architecture of machine learning models for better multivariate time series forecasting. To achieve this, we focus on the trend and seasonal components individually and investigate solutions to predict them with less errors. Recognizing that reversible instance normalization is effective only for the trend component, we take a different approach with the seasonal component by directly applying backbone models without any normalization or scaling procedures. Through these strategies, we successfully reduce error values of the existing state-of-the-art models and finally introduce dual-MLP models as more computationally efficient solutions. Furthermore, our approach consistently yields positive results with around 10% MSE average reduction across four state-of-the-art baselines on the benchmark datasets. We also evaluate our approach on a hydrological dataset extracted from the United States Geological Survey (USGS) river stations, where our models achieve significant improvements while maintaining linear time complexity, demonstrating real-world effectiveness. The source code is available at https://github.com/Sanjeev97/Time-Series-Decomposition", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u89e3\u65f6\u95f4\u5e8f\u5217\u5e76\u5206\u522b\u5904\u7406\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6210\u5206\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u67b6\u6784\uff0c\u4ee5\u63d0\u9ad8\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u7ea610%\u7684MSE\u5e73\u5747\u51cf\u5c11\uff0c\u5e76\u5728\u7f8e\u56fd\u5730\u8d28\u8c03\u67e5\u5c40\u6cb3\u6d41\u7ad9\u70b9\u63d0\u4f9b\u7684\u6c34\u6587\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u8bb8\u591a\u9886\u57df\u90fd\u9762\u4e34\u7740\u91cd\u5927\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u5e0c\u671b\u901a\u8fc7\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u67b6\u6784\u6765\u63d0\u9ad8\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5bf9\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u5206\u89e3\uff0c\u7279\u522b\u5173\u6ce8\u8d8b\u52bf\u4e0e\u5b63\u8282\u6027\u6210\u5206\uff0c\u5e76\u91c7\u7528\u4e0d\u540c\u7684\u7b56\u7565\u6765\u9884\u6d4b\u8fd9\u4e24\u4e2a\u90e8\u5206\uff1a\u5bf9\u4e8e\u8d8b\u52bf\u6210\u5206\u4f7f\u7528\u53ef\u9006\u5b9e\u4f8b\u5f52\u4e00\u5316\u6280\u672f\uff0c\u800c\u5bf9\u4e8e\u5b63\u8282\u6027\u6210\u5206\u5219\u76f4\u63a5\u5e94\u7528\u9aa8\u5e72\u6a21\u578b\u800c\u65e0\u9700\u4efb\u4f55\u5f52\u4e00\u5316\u6216\u7f29\u653e\u8fc7\u7a0b\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7b56\u7565\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u53ccMLP\u6a21\u578b\u4f5c\u4e3a\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u7684\u8bef\u5dee\u503c\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u51cf\u5c11\u4e86\u5927\u7ea610%\u7684MSE\u3002\u6b64\u5916\uff0c\u5f53\u5e94\u7528\u4e8e\u4ece\u7f8e\u56fd\u5730\u8d28\u8c03\u67e5\u5c40\u6cb3\u6d41\u7ad9\u63d0\u53d6\u7684\u771f\u5b9e\u4e16\u754c\u6c34\u6587\u6570\u636e\u65f6\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4fdd\u6301\u4e86\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u8fd8\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5206\u522b\u5bf9\u65f6\u95f4\u5e8f\u5217\u7684\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6210\u5206\u91c7\u53d6\u9488\u5bf9\u6027\u63aa\u65bd\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002\u63d0\u51fa\u7684\u53ccMLP\u6a21\u578b\u4e0d\u4ec5\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u800c\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.18723", "categories": ["cs.DC", "cs.LO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18723", "abs": "https://arxiv.org/abs/2602.18723", "authors": ["Paul Borrill"], "title": "What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature", "comment": "15 pages, no figures", "summary": "The foundational impossibility results of distributed computing -- the Fischer-Lynch-Paterson theorem, the Two Generals Problem, the CAP theorem -- are widely understood as discoveries about the physical limits of coordination. This paper argues that they are nothing of the sort. They are consequences of a category mistake: treating Forward-In-Time-Only (FITO) information flow as a law of nature rather than recognizing it as a design choice inherited from Shannon's channel model and Lamport's happened-before relation. We develop this argument in six steps. First, we introduce the category mistake framework from Ryle through Spekkens' ontic/epistemic distinction in quantum foundations. Second, we identify FITO as the hidden axiom that unifies the classical impossibility results. Third, we apply Spekkens' Leibnizian principle to show that FITO-based models contain surplus ontological structure. Fourth, we develop the counterfactual: what changes when FITO is dropped. Fifth, we demonstrate that the impossibility theorems are theorems about FITO systems, not about physics. Sixth, we sketch the transactional alternative -- bilateral interactions that dissolve the apparent impossibilities by replacing unidirectional message passing with atomic bilateral transactions. The implication is that distributed computing has spent fifty years optimizing within the wrong design space.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u57fa\u7840\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff08\u5982FLP\u5b9a\u7406\u3001\u4e8c\u5c06\u519b\u95ee\u9898\u548cCAP\u5b9a\u7406\uff09\u5e76\u975e\u81ea\u7136\u754c\u56fa\u6709\u7684\u7269\u7406\u9650\u5236\uff0c\u800c\u662f\u7531\u4e8e\u5c06\u4ec5\u5411\u524d\u65f6\u95f4\u6d41\u52a8\u7684\u4fe1\u606f\u6d41\uff08FITO\uff09\u9519\u8bef\u5730\u89c6\u4e3a\u81ea\u7136\u6cd5\u5219\u3002\u6587\u7ae0\u901a\u8fc7\u516d\u4e2a\u6b65\u9aa4\u8bba\u8bc1\u4e86\u8fd9\u4e00\u89c2\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u53cc\u8fb9\u4ea4\u6613\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u6307\u51fa\u5206\u5e03\u5f0f\u8ba1\u7b97\u9886\u57df\u53ef\u80fd\u5728\u8fc7\u53bb\u4e94\u5341\u5e74\u95f4\u4e00\u76f4\u5728\u4e00\u4e2a\u9519\u8bef\u7684\u8bbe\u8ba1\u7a7a\u95f4\u5185\u8fdb\u884c\u4f18\u5316\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u7ecf\u5178\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u662f\u57fa\u4e8e\u5bf9\u4fe1\u606f\u6d41\u65b9\u5411\u6027\u7684\u8bef\u89e3\uff0c\u5373\u5047\u8bbe\u4fe1\u606f\u53ea\u80fd\u5411\u524d\u6d41\u52a8\uff08FITO\uff09\uff0c\u800c\u8fd9\u4e00\u5047\u8bbe\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u8bbe\u8ba1\u9009\u62e9\u800c\u975e\u81ea\u7136\u754c\u7684\u5b9a\u5f8b\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5e76\u4e0d\u53cd\u6620\u7269\u7406\u4e16\u754c\u7684\u771f\u6b63\u9650\u5236\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u8303\u7574\u9519\u8bef\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u8bc6\u522bFITO\u4f5c\u4e3a\u9690\u85cf\u516c\u7406\u7684\u4f5c\u7528\uff0c\u5e94\u7528Leibnizian\u539f\u5219\u5206\u6790FITO\u6a21\u578b\u4e2d\u7684\u591a\u4f59\u672c\u4f53\u7ed3\u6784\uff0c\u63a2\u8ba8\u53bb\u9664FITO\u540e\u4f1a\u53d1\u751f\u4ec0\u4e48\u53d8\u5316\uff0c\u5c55\u793a\u8fd9\u4e9b\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u5b9e\u9645\u4e0a\u662f\u5173\u4e8eFITO\u7cfb\u7edf\u800c\u975e\u7269\u7406\u5b66\u7684\u7ed3\u8bba\uff0c\u6700\u540e\u63d0\u51fa\u57fa\u4e8e\u53cc\u8fb9\u4ea4\u4e92\u4f5c\u7528\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86FLP\u5b9a\u7406\u7b49\u5206\u5e03\u5f0f\u8ba1\u7b97\u9886\u57df\u7684\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\u4f9d\u8d56\u4e8eFITO\u5047\u8bbe\uff1b\u5c55\u793a\u4e86\u5f53\u4e0d\u91c7\u7528FITO\u65f6\uff0c\u539f\u6709\u7684\u4e0d\u53ef\u80fd\u6027\u53ef\u4ee5\u88ab\u89e3\u51b3\uff1b\u63d0\u51fa\u4e86\u4f7f\u7528\u539f\u5b50\u53cc\u8fb9\u4e8b\u52a1\u6765\u4ee3\u66ff\u5355\u5411\u6d88\u606f\u4f20\u9012\u7684\u65b0\u65b9\u6cd5\u8bba\u3002", "conclusion": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u9886\u57df\u957f\u671f\u4ee5\u6765\u53ef\u80fd\u57fa\u4e8e\u4e00\u4e2a\u9519\u8bef\u7684\u524d\u63d0\u8fdb\u884c\u7814\u7a76\u548c\u53d1\u5c55\uff0c\u5373\u4ec5\u5411\u524d\u65f6\u95f4\u6d41\u52a8\u7684\u4fe1\u606f\u6d41\uff08FITO\uff09\u3002\u901a\u8fc7\u6539\u53d8\u8fd9\u4e00\u57fa\u672c\u5047\u8bbe\uff0c\u6709\u53ef\u80fd\u514b\u670d\u4f20\u7edf\u4e0a\u88ab\u8ba4\u4e3a\u4e0d\u53ef\u903e\u8d8a\u7684\u6280\u672f\u969c\u788d\u3002"}}
{"id": "2602.18588", "categories": ["cs.IR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.18588", "abs": "https://arxiv.org/abs/2602.18588", "authors": ["William Gaultier", "Andrea Lodetti", "Ian Coghill", "David Colliaux", "Maximilian Fleck", "Alienor Lahlou"], "title": "Altar: Structuring Sharable Experimental Data from Early Exploration to Publication", "comment": null, "summary": "Managing the data and metadata during the active development phase of an experimental project presents a significant challenge, particularly in collaborative research. This phase is frequently overlooked in Data Management Plans included in project proposals, despite its important role in ensuring reproducibility and preventing the need for retroactive reconstruction at the time of publication. Here we present Altar, a lightweight, domain-agnostic framework for structuring experimental data from the onset of a project without imposing rigid data models. Altar is built around the Sacred experiment-tracking model and captures experimental (meta)data and structures them. Parameters, metadata, curves and small files are stored in a flexible NoSQL database, while large raw data are maintained in dedicated storage and linked through unique identifiers, ensuring efficiency and traceability. This integration is composable with exiting workflows, allowing integration with minimial disruption of work habits. We document different pathways to use Altar based on users skillset (PhD students, Post-docs, Principal Investigators, Laboratory administrators, System administrators). While getting started with Altar does not require a specialized infrastructure, the framework can be easily deployed on a server and made publicly accessible when scaling up or preparing data for publication. By addressing the dynamic phase of research, Altar provides a practical bridge between exploratory experimentation and FAIR-aligned data sharing.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAltar\u7684\u8f7b\u91cf\u7ea7\u3001\u9886\u57df\u65e0\u5173\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u9879\u76ee\u5f00\u59cb\u5c31\u7ed3\u6784\u5316\u5b9e\u9a8c\u6570\u636e\uff0c\u800c\u65e0\u9700\u65bd\u52a0\u4e25\u683c\u7684\u6570\u636e\u6a21\u578b\u3002\u5b83\u57fa\u4e8eSacred\u5b9e\u9a8c\u8ddf\u8e2a\u6a21\u578b\u6784\u5efa\uff0c\u65e8\u5728\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u5e76\u9632\u6b62\u5728\u53d1\u8868\u65f6\u9700\u8981\u8ffd\u6eaf\u91cd\u5efa\u3002", "motivation": "\u5728\u5b9e\u9a8c\u9879\u76ee\u7684\u6d3b\u8dc3\u5f00\u53d1\u9636\u6bb5\uff0c\u5c24\u5176\u662f\u5728\u534f\u4f5c\u7814\u7a76\u4e2d\uff0c\u7ba1\u7406\u548c\u5143\u6570\u636e\u7ba1\u7406\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u5c3d\u7ba1\u5728\u8fd9\u4e2a\u9636\u6bb5\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u548c\u907f\u514d\u5728\u53d1\u8868\u65f6\u8fdb\u884c\u8ffd\u6eaf\u91cd\u5efa\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u8fd9\u4e00\u9636\u6bb5\u7ecf\u5e38\u88ab\u9879\u76ee\u63d0\u6848\u4e2d\u7684\u6570\u636e\u7ba1\u7406\u8ba1\u5212\u6240\u5ffd\u89c6\u3002", "method": "\u63d0\u51fa\u4e86Altar\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e14\u4e0d\u53d7\u9886\u57df\u9650\u5236\u7684\u6846\u67b6\uff0c\u5b83\u56f4\u7ed5\u7740Sacred\u5b9e\u9a8c\u8ffd\u8e2a\u6a21\u578b\u8bbe\u8ba1\uff0c\u7528\u6765\u6355\u6349\u5e76\u7ed3\u6784\u5316\u5b9e\u9a8c\uff08\u5143\uff09\u6570\u636e\u3002\u53c2\u6570\u3001\u5143\u6570\u636e\u3001\u66f2\u7ebf\u548c\u5c0f\u6587\u4ef6\u5b58\u50a8\u5728\u4e00\u4e2a\u7075\u6d3b\u7684NoSQL\u6570\u636e\u5e93\u91cc\uff0c\u800c\u5927\u7684\u539f\u59cb\u6570\u636e\u5219\u4fdd\u5b58\u5728\u4e13\u95e8\u7684\u5b58\u50a8\u7a7a\u95f4\u5e76\u901a\u8fc7\u552f\u4e00\u6807\u8bc6\u7b26\u94fe\u63a5\u8d77\u6765\uff0c\u4ee5\u4fdd\u8bc1\u6548\u7387\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "result": "Altar\u4e3a\u4e0d\u540c\u6280\u80fd\u6c34\u5e73\u7684\u7528\u6237\u63d0\u4f9b\u4e86\u591a\u79cd\u4f7f\u7528\u9014\u5f84\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u73b0\u6709\u5de5\u4f5c\u6d41\u7a0b\u7ed3\u5408\uff0c\u6700\u5c0f\u7a0b\u5ea6\u5730\u5e72\u6270\u5de5\u4f5c\u4e60\u60ef\u3002\u867d\u7136\u5f00\u59cb\u4f7f\u7528Altar\u4e0d\u9700\u8981\u4e13\u95e8\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u8be5\u6846\u67b6\u6613\u4e8e\u90e8\u7f72\u5230\u670d\u52a1\u5668\u4e0a\uff0c\u5e76\u4e14\u5728\u6269\u5c55\u6216\u51c6\u5907\u53d1\u8868\u6570\u636e\u65f6\u53ef\u4ee5\u516c\u5f00\u8bbf\u95ee\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u7814\u7a76\u7684\u52a8\u6001\u9636\u6bb5\u95ee\u9898\uff0cAltar\u4e3a\u63a2\u7d22\u6027\u5b9e\u9a8c\u548c\u7b26\u5408FAIR\u539f\u5219\u7684\u6570\u636e\u5171\u4eab\u4e4b\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6865\u6881\u3002"}}
{"id": "2602.18495", "categories": ["cs.DB", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18495", "abs": "https://arxiv.org/abs/2602.18495", "authors": ["Yanlin Zhang", "Linjie Xu", "Quan Gan", "David Wipf", "Minjie Wang"], "title": "RDBLearn: Simple In-Context Prediction Over Relational Databases", "comment": null, "summary": "Recent advances in tabular in-context learning (ICL) show that a single pretrained model can adapt to new prediction tasks from a small set of labeled examples, avoiding per-task training and heavy tuning. However, many real-world tasks live in relational databases, where predictive signal is spread across multiple linked tables rather than a single flat table. We show that tabular ICL can be extended to relational prediction with a simple recipe: automatically featurize each target row using relational aggregations over its linked records, materialize the resulting augmented table, and run an off-the-shelf tabular foundation model on it. We package this approach in \\textit{RDBLearn} (https://github.com/HKUSHXLab/rdblearn), an easy-to-use toolkit with a scikit-learn-style estimator interface that makes it straightforward to swap different tabular ICL backends; a complementary agent-specific interface is provided as well. Across a broad collection of RelBench and 4DBInfer datasets, RDBLearn is the best-performing foundation model approach we evaluate, at times even outperforming strong supervised baselines trained or fine-tuned on each dataset.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8868\u683c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6269\u5c55\u5230\u5173\u7cfb\u578b\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u7279\u5f81\u5316\u6bcf\u4e2a\u76ee\u6807\u884c\u5e76\u4f7f\u7528\u5173\u7cfb\u805a\u5408\u5176\u94fe\u63a5\u8bb0\u5f55\u6765\u5b9e\u73b0\u3002\u5f00\u53d1\u4e86\u540d\u4e3aRDBLearn\u7684\u5de5\u5177\u5305\uff0c\u5b83\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u6709\u65f6\u751a\u81f3\u4f18\u4e8e\u5f3a\u5927\u7684\u76d1\u7763\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u8868\u683c\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u4e00\u5e73\u9762\u8868\u4e2d\u7684\u5c0f\u6837\u672c\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bb8\u591a\u4efb\u52a1\u7684\u6570\u636e\u5206\u5e03\u5728\u591a\u4e2a\u5173\u8054\u8868\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u8fd9\u79cd\u5173\u7cfb\u578b\u6570\u636e\u5e93\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u7684\u65b9\u6cd5\u662f\u9996\u5148\u5bf9\u6bcf\u4e2a\u76ee\u6807\u884c\u8fdb\u884c\u81ea\u52a8\u7279\u5f81\u5316\uff0c\u5229\u7528\u4e0e\u5176\u76f8\u5173\u8054\u7684\u8bb0\u5f55\u8fdb\u884c\u5173\u7cfb\u805a\u5408\uff0c\u751f\u6210\u4e00\u4e2a\u6269\u589e\u540e\u7684\u8868\u683c\uff1b\u7136\u540e\u4f7f\u7528\u73b0\u6210\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\u5728\u8fd9\u4e2a\u6269\u589e\u540e\u7684\u8868\u683c\u4e0a\u8fd0\u884c\u3002\u8fd9\u4e00\u8fc7\u7a0b\u88ab\u5c01\u88c5\u5728\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\u5305RDBLearn\u4e2d\uff0c\u652f\u6301\u4ee5scikit-learn\u98ce\u683c\u7684\u4f30\u8ba1\u5668\u63a5\u53e3\u8f7b\u677e\u5207\u6362\u4e0d\u540c\u7684\u8868\u683cICL\u540e\u7aef\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728RelBench\u548c4DBInfer\u7b49\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cRDBLearn\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u8bc4\u4f30\u4e2d\u7684\u5176\u4ed6\u57fa\u7840\u6a21\u578b\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u4f18\u4e8e\u90a3\u4e9b\u7ecf\u8fc7\u4e13\u95e8\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u5f3a\u5927\u76d1\u7763\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u5c06\u8868\u683c\u4e0a\u4e0b\u6587\u5b66\u4e60\u6269\u5c55\u5230\u4e86\u5173\u7cfb\u578b\u6570\u636e\u73af\u5883\u4e2d\uff0c\u4e3a\u76f4\u63a5\u4ece\u590d\u6742\u7684\u5173\u7cfb\u6570\u636e\u5e93\u7ed3\u6784\u4e2d\u8fdb\u884c\u9ad8\u6548\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18537", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18537", "abs": "https://arxiv.org/abs/2602.18537", "authors": ["Yiran Wang", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Ulf Nilsson", "D\u00e1niel Varr\u00f3"], "title": "Runtime-Augmented LLMs for Crash Detection and Diagnosis in ML Notebooks", "comment": null, "summary": "Jupyter notebooks are widely used for machine learning (ML) development due to their support for interactive and iterative experimentation. However, ML notebooks are highly prone to bugs, with crashes being among the most disruptive. Despite their practical importance, systematic methods for crash detection and diagnosis in ML notebooks remain largely unexplored. We present CRANE-LLM, a novel approach that augments large language models (LLMs) with structured runtime information extracted from the notebook kernel state to detect and diagnose crashes before executing a target cell. Given previously executed cells and a target cell, CRANE-LLM combines static code context with runtime information, including object types, tensor shapes, and data attributes, to predict whether the target cell will crash (detection) and explain the underlying cause (diagnosis). We evaluate CRANE-LLM on JunoBench, a benchmark of 222 ML notebooks comprising 111 pairs of crashing and corresponding non-crashing notebooks across multiple ML libraries and crash root causes. Across three state-of-the-art LLMs (Gemini, Qwen, and GPT-5), runtime information improves crash detection and diagnosis by 7-10 percentage points in accuracy and 8-11 in F1-score, with larger gains for diagnosis. Improvements vary across ML libraries, crash causes, and LLMs, and depends on the integration of complementary categories of runtime information.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCRANE-LLM\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u8fd0\u884c\u65f6\u4fe1\u606f\uff08\u5982\u5bf9\u8c61\u7c7b\u578b\u3001\u5f20\u91cf\u5f62\u72b6\u548c\u6570\u636e\u5c5e\u6027\uff09\u6765\u9884\u6d4bJupyter\u7b14\u8bb0\u672c\u4e2d\u7684\u76ee\u6807\u5355\u5143\u683c\u662f\u5426\u4f1a\u5d29\u6e83\uff0c\u5e76\u89e3\u91ca\u5176\u6839\u672c\u539f\u56e0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4ec5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u5d29\u6e83\u68c0\u6d4b\u548c\u8bca\u65ad\u51c6\u786e\u6027\u4e0a\u63d0\u9ad8\u4e867\u523010\u4e2a\u767e\u5206\u70b9\uff0c\u5728F1\u5206\u6570\u4e0a\u63d0\u9ad8\u4e868\u523011\u70b9\u3002", "motivation": "\u5c3d\u7ba1Jupyter\u7b14\u8bb0\u672c\u56e0\u5176\u652f\u6301\u4ea4\u4e92\u5f0f\u548c\u8fed\u4ee3\u5b9e\u9a8c\u800c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5f00\u53d1\uff0c\u4f46\u5b83\u4eec\u5f88\u5bb9\u6613\u51fa\u73b0\u9519\u8bef\uff0c\u5176\u4e2d\u5d29\u6e83\u662f\u6700\u5177\u7834\u574f\u6027\u7684\u3002\u9488\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u76ee\u524d\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u5d29\u6e83\u68c0\u6d4b\u548c\u8bca\u65ad\u3002", "method": "CRANE-LLM\u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5b83\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u4ece\u7b14\u8bb0\u672c\u5185\u6838\u72b6\u6001\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u7684\u8fd0\u884c\u65f6\u4fe1\u606f\u6765\u5b9e\u73b0\u3002\u7ed9\u5b9a\u5148\u524d\u6267\u884c\u8fc7\u7684\u5355\u5143\u683c\u548c\u4e00\u4e2a\u76ee\u6807\u5355\u5143\u683c\uff0cCRANE-LLM\u5c06\u9759\u6001\u4ee3\u7801\u5185\u5bb9\u4e0e\u8fd0\u884c\u65f6\u4fe1\u606f\u76f8\u7ed3\u5408\uff0c\u5305\u62ec\u5bf9\u8c61\u7c7b\u578b\u3001\u5f20\u91cf\u5f62\u72b6\u4ee5\u53ca\u6570\u636e\u5c5e\u6027\u7b49\uff0c\u4ee5\u9884\u6d4b\u76ee\u6807\u5355\u5143\u683c\u662f\u5426\u4f1a\u5d29\u6e83\u53ca\u5176\u80cc\u540e\u7684\u539f\u56e0\u3002", "result": "\u5728\u5305\u542b222\u4e2aML\u7b14\u8bb0\u672c\u7684JunoBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCRANE-LLM\u5c55\u793a\u4e86\u5bf9\u4e8eGemini\u3001Qwen\u548cGPT-5\u4e09\u79cd\u6700\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u800c\u8a00\uff0c\u8fd0\u884c\u65f6\u4fe1\u606f\u80fd\u591f\u63d0\u9ad8\u5d29\u6e83\u68c0\u6d4b\u548c\u8bca\u65ad\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e867\u523010\u4e2a\u767e\u5206\u70b9\uff0cF1\u5206\u6570\u589e\u52a0\u4e868\u523011\u70b9\u3002\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u5e93\u3001\u5d29\u6e83\u539f\u56e0\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u89c2\u5bdf\u5230\u4e86\u4e0d\u540c\u7684\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u6574\u5408\u8865\u5145\u7c7b\u522b\u7684\u8fd0\u884c\u65f6\u4fe1\u606f\uff0cCRANE-LLM\u80fd\u591f\u663e\u8457\u6539\u5584\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728Jupyter\u7b14\u8bb0\u672c\u5d29\u6e83\u68c0\u6d4b\u4e0e\u8bca\u65ad\u65b9\u9762\u7684\u8868\u73b0\u3002"}}
{"id": "2602.18755", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.18755", "abs": "https://arxiv.org/abs/2602.18755", "authors": ["Omar Basit", "Yunzhao Liu", "Z. Jonny Kong", "Y. Charlie Hu"], "title": "BiScale: Energy-Efficient Disaggregated LLM Serving via Phase-Aware Placement and DVFS", "comment": null, "summary": "Prefill/decode disaggregation is increasingly adopted in LLM serving to improve the latency-throughput tradeoff and meet strict TTFT and TPOT SLOs. However, LLM inference remains energy-hungry: autoscaling alone is too coarse-grained to track fast workload fluctuations, and applying fine-grained DVFS under disaggregation is complicated by phase-asymmetric dynamics and coupling between provisioning and frequency control.\n  We present BiScale, a two-tier energy optimization framework for disaggregated LLM serving. BiScale jointly optimizes placement and DVFS across prefill and decode using predictive latency and power models. At coarse timescales, BiScale computes phase-aware placement and baseline frequencies that minimize energy while satisfying SLO constraints. At fine timescales, BiScale dynamically adapts GPU frequency per iteration using stage-specific control: model predictive control (MPC) for prefill to account for queue evolution and future TTFT impact, and lightweight slack-aware adaptation for decode to exploit its smoother, memory-bound dynamics. This hierarchical design enables coordinated control across timescales while preserving strict serving SLOs.\n  Evaluation on a 16x H100 cluster serving Llama 3.3 70B with production-style traces shows that BiScale meets TTFT/TPOT SLOs while reducing energy by up to 39% in prefill and 48% in decode relative to DistServe.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBiScale\u7684\u4e24\u5c42\u80fd\u6e90\u4f18\u5316\u6846\u67b6\uff0c\u4e13\u4e3a\u89e3\u805a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u8bbe\u8ba1\u3002\u901a\u8fc7\u5728\u7c97\u7565\u548c\u7cbe\u7ec6\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u5206\u522b\u8fdb\u884c\u653e\u7f6e\u4e0e\u57fa\u7ebf\u9891\u7387\u8ba1\u7b97\u53caGPU\u9891\u7387\u52a8\u6001\u8c03\u6574\uff0cBiScale\u80fd\u591f\u5728\u6ee1\u8db3\u670d\u52a1\u7ea7\u522b\u76ee\u6807\uff08SLO\uff09\u7684\u540c\u65f6\uff0c\u5728\u9884\u586b\u5145\u9636\u6bb5\u51cf\u5c11\u9ad8\u8fbe39%\u3001\u5728\u89e3\u7801\u9636\u6bb5\u51cf\u5c11\u9ad8\u8fbe48%\u7684\u80fd\u91cf\u6d88\u8017\u3002", "motivation": "\u968f\u7740LLM\u670d\u52a1\u4e2d\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u9884\u586b\u5145/\u89e3\u7801\u5206\u79bb\u6765\u6539\u5584\u5ef6\u8fdf-\u541e\u5410\u91cf\u6743\u8861\u5e76\u6ee1\u8db3\u4e25\u683c\u7684TTFT\u548cTPOT SLOs\uff0c\u5982\u4f55\u6709\u6548\u7ba1\u7406\u80fd\u6e90\u6d88\u8017\u6210\u4e3a\u4e86\u4e00\u4e2a\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u81ea\u52a8\u6269\u5c55\u8fc7\u4e8e\u7c97\u7cd9\uff0c\u96be\u4ee5\u8ddf\u8e2a\u5feb\u901f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\uff1b\u800c\u89e3\u805a\u73af\u5883\u4e0b\u7684DVFS\u5e94\u7528\u5219\u56e0\u76f8\u4f4d\u4e0d\u5bf9\u79f0\u52a8\u6001\u4ee5\u53ca\u4f9b\u7ed9\u4e0e\u9891\u7387\u63a7\u5236\u4e4b\u95f4\u7684\u8026\u5408\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u3002", "method": "BiScale\u662f\u4e00\u79cd\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u800c\u8bbe\u8ba1\u7684\u4e24\u5c42\u80fd\u6e90\u4f18\u5316\u6846\u67b6\u3002\u5b83\u7ed3\u5408\u4e86\u9884\u6d4b\u5ef6\u8fdf\u548c\u529f\u8017\u6a21\u578b\u6765\u540c\u65f6\u4f18\u5316\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u7684\u4f4d\u7f6e\u9009\u62e9\u4e0eDVFS\u3002\u5728\u8f83\u7c97\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0a\uff0cBiScale\u6839\u636e\u9636\u6bb5\u610f\u8bc6\u8ba1\u7b97\u51fa\u6700\u4f18\u4f4d\u7f6e\u5b89\u6392\u548c\u57fa\u51c6\u9891\u7387\uff0c\u4ee5\u6700\u5c0f\u5316\u80fd\u8017\u5e76\u7b26\u5408SLO\u7ea6\u675f\u6761\u4ef6\uff1b\u800c\u5728\u66f4\u7ec6\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0a\uff0c\u5219\u901a\u8fc7\u9636\u6bb5\u7279\u5b9a\u63a7\u5236\u624b\u6bb5\u2014\u2014\u5bf9\u4e8e\u9884\u586b\u5145\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u8003\u8651\u961f\u5217\u6f14\u53d8\u5bf9\u672a\u6765TTFT\u7684\u5f71\u54cd\uff0c\u5bf9\u4e8e\u89e3\u7801\u91c7\u7528\u8f7b\u91cf\u7ea7\u677e\u5f1b\u611f\u77e5\u9002\u5e94\u7b56\u7565\u5229\u7528\u5176\u8f83\u4e3a\u5e73\u6ed1\u4e14\u53d7\u5185\u5b58\u9650\u5236\u7684\u52a8\u529b\u5b66\u7279\u6027\u2014\u2014\u6765\u5b9e\u73b0\u6bcf\u8fed\u4ee3\u5468\u671f\u5185\u7684GPU\u9891\u7387\u81ea\u9002\u5e94\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e00\u4e2a\u753116\u4e2aH100 GPU\u7ec4\u6210\u7684\u96c6\u7fa4\u4e0a\u8fd0\u884cLlama 3.3 70B\u6a21\u578b\u65f6\uff0c\u76f8\u8f83\u4e8eDistServe\uff0cBiScale\u4e0d\u4ec5\u80fd\u591f\u6ee1\u8db3TTFT/TPOT SLOs\u8981\u6c42\uff0c\u8fd8\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u91cf\u6d88\u8017\uff1a\u9884\u586b\u5145\u9636\u6bb5\u6700\u591a\u53ef\u8282\u770139%\uff0c\u89e3\u7801\u9636\u6bb5\u6700\u591a\u53ef\u8282\u770148%\u3002", "conclusion": "BiScale\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8de8\u65f6\u95f4\u5c3a\u5ea6\u7684\u534f\u8c03\u63a7\u5236\u5b9e\u73b0\u4e86\u5728\u4fdd\u8bc1\u4e25\u683c\u670d\u52a1\u7ea7\u522b\u76ee\u6807\u7684\u540c\u65f6\u5927\u5e45\u5ea6\u964d\u4f4e\u80fd\u6e90\u6d88\u8017\u7684\u76ee\u6807\u3002"}}
{"id": "2602.18759", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18759", "abs": "https://arxiv.org/abs/2602.18759", "authors": ["Chen Chen", "Haobo Lin", "Yuanbo Xu"], "title": "Towards Reliable Negative Sampling for Recommendation with Implicit Feedback via In-Community Popularity", "comment": "12 pages, 9 figures", "summary": "Learning from implicit feedback is a fundamental problem in modern recommender systems, where only positive interactions are observed and explicit negative signals are unavailable. In such settings, negative sampling plays a critical role in model training by constructing negative items that enable effective preference learning and ranking optimization. However, designing reliable negative sampling strategies remains challenging, as they must simultaneously ensure realness, hardness, and interpretability. To this end, we propose \\textbf{ICPNS (In-Community Popularity Negative Sampling)}, a novel framework that leverages user community structure to identify reliable and informative negative samples. Our approach is grounded in the insight that item exposure is driven by latent user communities. By identifying these communities and utilizing in-community popularity, ICPNS effectively approximates the probability of item exposure. Consequently, items that are popular within a user's community but remain unclicked are identified as more reliable true negatives. Extensive experiments on four benchmark datasets demonstrate that ICPNS yields consistent improvements on graph-based recommenders and competitive performance on MF-based models, outperforming representative negative sampling strategies under a unified evaluation protocol.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6ICPNS\uff08In-Community Popularity Negative Sampling\uff09\uff0c\u5229\u7528\u7528\u6237\u793e\u533a\u7ed3\u6784\u6765\u8bc6\u522b\u53ef\u9760\u7684\u8d1f\u6837\u672c\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u7269\u54c1\u66dd\u5149\u7531\u6f5c\u5728\u7684\u7528\u6237\u793e\u533a\u9a71\u52a8\u7684\u6d1e\u5bdf\uff0c\u901a\u8fc7\u8bc6\u522b\u8fd9\u4e9b\u793e\u533a\u5e76\u5229\u7528\u793e\u533a\u5185\u6d41\u884c\u5ea6\u6709\u6548\u8fd1\u4f3c\u7269\u54c1\u66dd\u5149\u6982\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cICPNS\u5728\u57fa\u4e8e\u56fe\u7684\u63a8\u8350\u7cfb\u7edf\u4e0a\u8868\u73b0\u51fa\u4e86\u6301\u7eed\u6539\u8fdb\uff0c\u5e76\u4e14\u5728MF\uff08\u77e9\u9635\u5206\u89e3\uff09\u6a21\u578b\u4e0a\u4e5f\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u4ece\u9690\u5f0f\u53cd\u9988\u4e2d\u5b66\u4e60\u662f\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u53ea\u80fd\u89c2\u5bdf\u5230\u6b63\u9762\u4ea4\u4e92\u800c\u6ca1\u6709\u660e\u786e\u7684\u8d1f\u9762\u4fe1\u53f7\u3002\u5728\u8fd9\u79cd\u8bbe\u5b9a\u4e0b\uff0c\u8d1f\u91c7\u6837\u5bf9\u4e8e\u901a\u8fc7\u6784\u5efa\u8d1f\u9879\u6765\u5b9e\u73b0\u6709\u6548\u7684\u504f\u597d\u5b66\u4e60\u548c\u6392\u540d\u4f18\u5316\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u7136\u800c\uff0c\u8bbe\u8ba1\u53ef\u9760\u7684\u8d1f\u91c7\u6837\u7b56\u7565\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u5fc5\u987b\u540c\u65f6\u786e\u4fdd\u771f\u5b9e\u6027\u3001\u96be\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86ICPNS\uff08In-Community Popularity Negative Sampling\uff09\u6846\u67b6\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u7528\u6237\u793e\u533a\u7ed3\u6784\u6765\u786e\u5b9a\u53ef\u9760\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u8d1f\u6837\u672c\u3002\u57fa\u4e8e\u7269\u54c1\u66dd\u5149\u662f\u7531\u6f5c\u5728\u7528\u6237\u793e\u533a\u9a71\u52a8\u7684\u89c2\u70b9\uff0c\u901a\u8fc7\u8bc6\u522b\u8fd9\u4e9b\u793e\u533a\u5e76\u4f7f\u7528\u793e\u533a\u5185\u90e8\u7684\u53d7\u6b22\u8fce\u7a0b\u5ea6\uff0cICPNS\u80fd\u591f\u6709\u6548\u5730\u4f30\u8ba1\u51fa\u7269\u54c1\u88ab\u66dd\u5149\u7684\u6982\u7387\u3002\u56e0\u6b64\uff0c\u90a3\u4e9b\u5728\u7528\u6237\u6240\u5c5e\u793e\u533a\u5185\u5f88\u53d7\u6b22\u8fce\u4f46\u7528\u6237\u672a\u70b9\u51fb\u7684\u7269\u54c1\u88ab\u89c6\u4e3a\u66f4\u53ef\u4fe1\u7684\u771f\u5b9e\u8d1f\u6837\u672c\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cICPNS\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u57fa\u4e8e\u56fe\u7684\u63a8\u8350\u5668\u4e0a\u53d6\u5f97\u4e86\u6301\u7eed\u6027\u7684\u6539\u8fdb\uff0c\u5e76\u4e14\u5728\u57fa\u4e8eMF\uff08\u77e9\u9635\u5206\u89e3\uff09\u7684\u6a21\u578b\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86\u4ee3\u8868\u6027\u7684\u8d1f\u91c7\u6837\u7b56\u7565\u3002", "conclusion": "ICPNS\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u8d1f\u91c7\u6837\u95ee\u9898\uff0c\u901a\u8fc7\u8003\u8651\u7528\u6237\u6240\u5c5e\u793e\u533a\u5185\u7684\u6d41\u884c\u5ea6\u6765\u8fdb\u884c\u8d1f\u6837\u672c\u7684\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2602.18473", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18473", "abs": "https://arxiv.org/abs/2602.18473", "authors": ["Guoqi Yu", "Juncheng Wang", "Chen Yang", "Jing Qin", "Angelica I. Aviles-Rivero", "Shujun Wang"], "title": "Decentralized Attention Fails Centralized Signals: Rethinking Transformers for Medical Time Series", "comment": "Accepted by ICLR 2026 (Oral). arXiv admin note: text overlap with arXiv:2405.19363 by other authors", "summary": "Accurate analysis of medical time series (MedTS) data, such as electroencephalography (EEG) and electrocardiography (ECG), plays a pivotal role in healthcare applications, including the diagnosis of brain and heart diseases. MedTS data typically exhibit two critical patterns: temporal dependencies within individual channels and channel dependencies across multiple channels. While recent advances in deep learning have leveraged Transformer-based models to effectively capture temporal dependencies, they often struggle with modeling channel dependencies. This limitation stems from a structural mismatch: MedTS signals are inherently centralized, whereas the Transformer's attention mechanism is decentralized, making it less effective at capturing global synchronization and unified waveform patterns. To address this mismatch, we propose CoTAR (Core Token Aggregation-Redistribution), a centralized MLP-based module designed to replace decentralized attention. Instead of allowing all tokens to interact directly, as in standard attention, CoTAR introduces a global core token that serves as a proxy to facilitate inter-token interactions, thereby enforcing a centralized aggregation and redistribution strategy. This design not only better aligns with the centralized nature of MedTS signals but also reduces computational complexity from quadratic to linear. Experiments on five benchmarks validate the superiority of our method in both effectiveness and efficiency, achieving up to a 12.13% improvement on the APAVA dataset, while using only 33% of the memory and 20% of the inference time compared to the previous state of the art. Code and all training scripts are available at https://github.com/Levi-Ackman/TeCh.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoTAR\u7684\u96c6\u4e2d\u5f0f\u591a\u5c42\u611f\u77e5\u5668\u6a21\u5757\uff0c\u7528\u4e8e\u6539\u8fdb\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff08\u5982EEG\u548cECG\uff09\u7684\u5206\u6790\u3002\u901a\u8fc7\u5f15\u5165\u5168\u5c40\u6838\u5fc3\u4ee4\u724c\u6765\u4fc3\u8fdb\u4ee4\u724c\u95f4\u7684\u4ea4\u4e92\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u66f4\u597d\u5730\u9002\u5e94\u4e86MedTS\u4fe1\u53f7\u7684\u96c6\u4e2d\u7279\u6027\uff0c\u8fd8\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5728\u6548\u7387\u548c\u6548\u679c\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u5904\u7406\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u867d\u7136\u80fd\u591f\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u4f46\u5bf9\u4e8e\u901a\u9053\u95f4\u4f9d\u8d56\u6027\u7684\u5efa\u6a21\u5b58\u5728\u5c40\u9650\u3002\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u672c\u8d28\u4e0a\u662f\u96c6\u4e2d\u7684\uff0c\u800cTransformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u662f\u5206\u6563\u5f0f\u7684\uff0c\u5bfc\u81f4\u5b83\u5728\u6355\u6349\u5168\u5c40\u540c\u6b65\u6027\u548c\u7edf\u4e00\u6ce2\u5f62\u6a21\u5f0f\u65b9\u9762\u4e0d\u591f\u6709\u6548\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u7ed3\u6784\u4e0a\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86CoTAR\uff08Core Token Aggregation-Redistribution\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u5c42\u611f\u77e5\u5668(MLP)\u7684\u96c6\u4e2d\u5f0f\u6a21\u5757\uff0c\u65e8\u5728\u66ff\u4ee3\u4f20\u7edf\u7684\u5206\u6563\u5f0f\u6ce8\u610f\u529b\u673a\u5236\u3002CoTAR\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u5168\u5c40\u6838\u5fc3\u4ee4\u724c\u4f5c\u4e3a\u4e2d\u4ecb\u6765\u4fc3\u8fdb\u4ee4\u724c\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u4ece\u800c\u5f3a\u5236\u6267\u884c\u96c6\u4e2d\u5f0f\u7684\u805a\u5408\u4e0e\u518d\u5206\u914d\u7b56\u7565\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4e0d\u4ec5\u66f4\u7b26\u5408\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u7684\u96c6\u4e2d\u7279\u6027\uff0c\u800c\u4e14\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u7ebf\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002\u7279\u522b\u662f\uff0c\u5728APAVA\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u9ad812.13%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u4ec5\u4f7f\u7528\u4e86\u4e09\u5206\u4e4b\u4e00\u7684\u5185\u5b58\u4ee5\u53ca\u4e94\u5206\u4e4b\u4e00\u7684\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165CoTAR\u6a21\u5757\uff0c\u7814\u7a76\u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u901a\u9053\u95f4\u4f9d\u8d56\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4e5f\u5927\u5e45\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.18929", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18929", "abs": "https://arxiv.org/abs/2602.18929", "authors": ["Fuyuan Lyu", "Chenglin Luo", "Qiyuan Zhang", "Yupeng Hou", "Haolun Wu", "Xing Tang", "Xue Liu", "Jin L. C. Guo", "Xiuqiang He"], "title": "Give Users the Wheel: Towards Promptable Recommendation Paradigm", "comment": null, "summary": "Conventional sequential recommendation models have achieved remarkable success in mining implicit behavioral patterns. However, these architectures remain structurally blind to explicit user intent: they struggle to adapt when a user's immediate goal (e.g., expressed via a natural language prompt) deviates from their historical habits. While Large Language Models (LLMs) offer the semantic reasoning to interpret such intent, existing integration paradigms force a dilemma: LLM-as-a-recommender paradigm sacrifices the efficiency and collaborative precision of ID-based retrieval, while Reranking methods are inherently bottlenecked by the recall capabilities of the underlying model. In this paper, we propose Decoupled Promptable Sequential Recommendation (DPR), a model-agnostic framework that empowers conventional sequential backbones to natively support Promptable Recommendation, the ability to dynamically steer the retrieval process using natural language without abandoning collaborative signals. DPR modulates the latent user representation directly within the retrieval space. To achieve this, we introduce a Fusion module to align the collaborative and semantic signals, a Mixture-of-Experts (MoE) architecture that disentangles the conflicting gradients from positive and negative steering, and a three-stage training strategy that progressively aligns the semantic space of prompts with the collaborative space. Extensive experiments on real-world datasets demonstrate that DPR significantly outperforms state-of-the-art baselines in prompt-guided tasks while maintaining competitive performance in standard sequential recommendation scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u63d0\u793a\u53ef\u8c03\u5e8f\u5217\u63a8\u8350\uff08DPR\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u4f20\u7edf\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u52a8\u6001\u5f15\u5bfc\u68c0\u7d22\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u534f\u540c\u4fe1\u53f7\u3002\u5b9e\u9a8c\u8868\u660eDPR\u5728\u63d0\u793a\u5f15\u5bfc\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6807\u51c6\u5e8f\u5217\u63a8\u8350\u573a\u666f\u4e2d\u4e5f\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u65e0\u6cd5\u9002\u5e94\u7528\u6237\u5373\u65f6\u76ee\u6807\u4e0e\u5386\u53f2\u4e60\u60ef\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u53ef\u4ee5\u63d0\u4f9b\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u6765\u89e3\u91ca\u8fd9\u79cd\u610f\u56fe\uff0c\u4f46\u5176\u96c6\u6210\u65b9\u5f0f\u8981\u4e48\u727a\u7272\u4e86\u57fa\u4e8eID\u68c0\u7d22\u7684\u6548\u7387\u548c\u534f\u4f5c\u7cbe\u5ea6\uff0c\u8981\u4e48\u53d7\u9650\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u53ec\u56de\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Decoupled Promptable Sequential Recommendation (DPR)\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165Fusion\u6a21\u5757\u5bf9\u534f\u4f5c\u548c\u8bed\u4e49\u4fe1\u53f7\u8fdb\u884c\u5bf9\u9f50\u3001\u91c7\u7528Mixture-of-Experts\u67b6\u6784\u5206\u79bb\u6b63\u8d1f\u6307\u5bfc\u7684\u68af\u5ea6\u51b2\u7a81\u4ee5\u53ca\u5b9e\u65bd\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u9010\u6b65\u5bf9\u9f50\u63d0\u793a\u7684\u8bed\u4e49\u7a7a\u95f4\u4e0e\u534f\u4f5c\u7a7a\u95f4\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cDPR\u5728\u63d0\u793a\u5bfc\u5411\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u660e\u663e\u4f18\u4e8e\u6700\u65b0\u7684\u57fa\u51c6\u6a21\u578b\uff0c\u540c\u65f6\u5728\u6807\u51c6\u5e8f\u5217\u63a8\u8350\u573a\u666f\u4e0b\u4e5f\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u6027\u80fd\u3002", "conclusion": "DPR\u6846\u67b6\u6210\u529f\u5730\u4e3a\u4f20\u7edf\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u8d4b\u4e88\u4e86\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u52a8\u6001\u8c03\u6574\u68c0\u7d22\u8fc7\u7a0b\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u534f\u4f5c\u4fe1\u53f7\u7684\u652f\u6301\uff0c\u5728\u591a\u79cd\u63a8\u8350\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.18486", "categories": ["cs.LG", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18486", "abs": "https://arxiv.org/abs/2602.18486", "authors": ["Jean Pinsolle", "Yadang Alexis Rouzoumka", "Chengfang Ren", "Chist\u00e8le Morisseau", "Jean-Philippe Ovarlez"], "title": "Support Vector Data Description for Radar Target Detection", "comment": "5 pages, 2 figures, to appear in Acoustics, Speech and Signal Processing (ICASSP), 2026 IEEE International Conference on, Barcelona, Spain, May 2026", "summary": "Classical radar detection techniques rely on adaptive detectors that estimate the noise covariance matrix from target-free secondary data. While effective in Gaussian environments, these methods degrade in the presence of clutter, which is better modeled by heavy-tailed distributions such as the Complex Elliptically Symmetric (CES) and Compound-Gaussian (CGD) families. Robust covariance estimators like M-estimators or Tyler's estimator address this issue, but still struggle when thermal noise combines with clutter. To overcome these challenges, we investigate the use of Support Vector Data Description (SVDD) and its deep extension, Deep SVDD, for target detection. These one-class learning methods avoid direct noise covariance estimation and are adapted here as CFAR detectors. We propose two novel SVDD-based detection algorithms and demonstrate their effectiveness on simulated radar data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u652f\u6301\u5411\u91cf\u6570\u636e\u63cf\u8ff0(SVDD)\u53ca\u5176\u6df1\u5ea6\u6269\u5c55\u7248\u672cDeep SVDD\u4f5c\u4e3a\u4e00\u7c7b\u5b66\u4e60\u65b9\u6cd5\uff0c\u6765\u89e3\u51b3\u96f7\u8fbe\u68c0\u6d4b\u4e2d\u6742\u6ce2\u548c\u70ed\u566a\u58f0\u7ed3\u5408\u5bfc\u81f4\u7684\u4f20\u7edf\u81ea\u9002\u5e94\u68c0\u6d4b\u5668\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u57fa\u4e8eSVDD\u7684\u68c0\u6d4b\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u96f7\u8fbe\u68c0\u6d4b\u6280\u672f\u5728\u9ad8\u65af\u73af\u5883\u4e0b\u6709\u6548\uff0c\u4f46\u5728\u9047\u5230\u66f4\u9002\u4e8e\u7528\u91cd\u5c3e\u5206\u5e03\u5982\u590d\u6570\u692d\u5706\u5bf9\u79f0\uff08CES\uff09\u6216\u590d\u5408\u9ad8\u65af\uff08CGD\uff09\u7cfb\u5217\u5efa\u6a21\u7684\u6742\u6ce2\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u7a33\u5065\u534f\u65b9\u5dee\u4f30\u8ba1\u5668\u867d\u80fd\u90e8\u5206\u89e3\u51b3\u95ee\u9898\uff0c\u4f46\u5728\u70ed\u566a\u58f0\u4e0e\u6742\u6ce2\u540c\u65f6\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u4ecd\u663e\u4e0d\u8db3\u3002", "method": "\u7814\u7a76\u91c7\u7528\u652f\u6301\u5411\u91cf\u6570\u636e\u63cf\u8ff0\uff08SVDD\uff09\u53ca\u5176\u6df1\u5ea6\u5b66\u4e60\u6269\u5c55\u7248\u672cDeep SVDD\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\uff0c\u8fd9\u4e24\u79cd\u5355\u7c7b\u5b66\u4e60\u65b9\u6cd5\u65e0\u9700\u76f4\u63a5\u4f30\u8ba1\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u5f00\u53d1\u4e86\u4e24\u79cd\u65b0\u7684\u57fa\u4e8eSVDD\u7684\u68c0\u6d4b\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u96f7\u8fbe\u6570\u636e\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u57fa\u4e8eSVDD\u7684\u68c0\u6d4b\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eSVDD\u7684\u65b9\u6cd5\u4e3a\u5904\u7406\u590d\u6742\u73af\u5883\u4e0b\u7684\u96f7\u8fbe\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c24\u5176\u662f\u5f53\u9762\u4e34\u6742\u6ce2\u4e0e\u70ed\u566a\u58f0\u5171\u5b58\u6311\u6218\u65f6\uff0c\u663e\u793a\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.18931", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.18931", "abs": "https://arxiv.org/abs/2602.18931", "authors": ["Noah Martin", "Fahad Dogar"], "title": "WANSpec: Leveraging Global Compute Capacity for LLM Inference", "comment": null, "summary": "Data centers capable of running large language models (LLMs) are spread across the globe. Some have high end GPUs for running the most advanced models (100B+ parameters), and others are only suitable for smaller models (1B parameters). The most capable GPUs are under high demand thanks to the rapidly expanding applications of LLMs. Choosing the right location to run an LLM inference workload can have consequences on the latency of requests due to these high demands. In this work, we explore options to shift some aspects of inference to the under-utilized data centers. We first observe the varying delays affecting inference in AWS services from different regions, demonstrating that load is not spread evenly. We then introduce WANSpec, which offloads part of LLM generation to the under-utilized data centers. In doing so, WANSpec can mitigate capacity issues as well as effectively use on-site compute (ie at universities) to augment cloud providers. This is done with speculative decoding, a widely used technique to speed up auto-regressive decoding, by moving the draft model to the under-utilized compute resources. Our experiments in simulation and cloud deployments show that WANSpec can judiciously employ redundancy to avoid increases in latency while still reducing the forward passes of speculative decoding's draft model in high demand data centers by over 50%.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7WANSpec\u6280\u672f\u5c06\u90e8\u5206\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u4efb\u52a1\u8f6c\u79fb\u5230\u5229\u7528\u7387\u8f83\u4f4e\u7684\u6570\u636e\u4e2d\u5fc3\uff0c\u4ee5\u7f13\u89e3\u9ad8\u9700\u6c42\u6570\u636e\u4e2d\u5fc3\u7684\u5bb9\u91cf\u95ee\u9898\uff0c\u5e76\u6709\u6548\u5229\u7528\u73b0\u573a\u8ba1\u7b97\u8d44\u6e90\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u907f\u514d\u5ef6\u8fdf\u589e\u52a0\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u9ad8\u9700\u6c42\u6570\u636e\u4e2d\u5fc3\u4e2d\u63a8\u6d4b\u89e3\u7801\u8349\u7a3f\u6a21\u578b\u7684\u524d\u5411\u4f20\u9012\u8d85\u8fc750%\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e94\u7528\u5feb\u901f\u589e\u957f\uff0c\u5bfc\u81f4\u9ad8\u6027\u80fdGPU\u9700\u6c42\u6fc0\u589e\uff0c\u9009\u62e9\u5408\u9002\u7684\u8fd0\u884c\u4f4d\u7f6e\u5bf9\u8bf7\u6c42\u5ef6\u8fdf\u6709\u663e\u8457\u5f71\u54cd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u4e0d\u540c\u6570\u636e\u4e2d\u5fc3\u4e4b\u95f4\u7684\u8d1f\u8f7d\u3002", "method": "\u63d0\u51fa\u4e86WANSpec\u6280\u672f\uff0c\u5b83\u901a\u8fc7\u5c06\u90e8\u5206LLM\u751f\u6210\u8fc7\u7a0b\u5378\u8f7d\u5230\u5229\u7528\u7387\u8f83\u4f4e\u7684\u6570\u636e\u4e2d\u5fc3\u6765\u8fdb\u884c\u5de5\u4f5c\u3002\u6b64\u8fc7\u7a0b\u91c7\u7528\u4e86\u63a8\u6d4b\u89e3\u7801\u6280\u672f\uff0c\u8fd9\u662f\u4e00\u79cd\u5e7f\u6cdb\u7528\u4e8e\u52a0\u901f\u81ea\u56de\u5f52\u89e3\u7801\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8349\u7a3f\u6a21\u578b\u79fb\u52a8\u5230\u90a3\u4e9b\u672a\u5145\u5206\u5229\u7528\u7684\u8ba1\u7b97\u8d44\u6e90\u4e0a\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cWANSpec\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u5ef6\u8fdf\u7684\u524d\u63d0\u4e0b\uff0c\u51cf\u5c11\u9ad8\u9700\u6c42\u6570\u636e\u4e2d\u5fc3\u5185\u63a8\u6d4b\u89e3\u7801\u8349\u7a3f\u6a21\u578b\u6240\u9700\u8fdb\u884c\u7684\u524d\u5411\u4f20\u9012\u6b21\u6570\u8d85\u8fc7\u4e00\u534a\u3002", "conclusion": "WANSpec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u51cf\u8f7b\u7e41\u5fd9\u6570\u636e\u4e2d\u5fc3\u7684\u538b\u529b\uff0c\u5e76\u4e14\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u73b0\u6709\u7684\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2602.18548", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18548", "abs": "https://arxiv.org/abs/2602.18548", "authors": ["Qiao Xu", "Yipeng Yu", "Chengxiao Feng", "Xu Liu"], "title": "1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World", "comment": null, "summary": "Design-to-code translates high-fidelity UI designs into executable front-end implementations, but progress remains hard to compare due to inconsistent datasets, toolchains, and evaluation protocols. We introduce 1D-Bench, a benchmark grounded in real e-commerce workflows, where each instance provides a reference rendering and an exported intermediate representation that may contain extraction errors. 1D is short for one day, representing the efficient completion of design-to-code tasks in less than one day. Models take both as input, using the intermediate representation as structural cues while being evaluated against the reference rendering, which tests robustness to intermediate representation defects rather than literal adherence.\n  1D-Bench requires generating an executable React codebase under a fixed toolchain with an explicit component hierarchy, and defines a multi-round setting in which models iteratively apply component-level edits using execution feedback. Experiments on commercial and open-weight multimodal models show that iterative editing generally improves final performance by increasing rendering success and often improving visual similarity. We further conduct a pilot study on post-training with synthetic repair trajectories and reinforcement learning based editing, and observe limited and unstable gains that may stem from sparse terminal rewards and high-variance file-level updates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e861D-Bench\uff0c\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u7535\u5546\u5de5\u4f5c\u6d41\u7a0b\u7684\u8bbe\u8ba1\u8f6c\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u901a\u8fc7\u63d0\u4f9b\u53c2\u8003\u6e32\u67d3\u548c\u53ef\u80fd\u5305\u542b\u63d0\u53d6\u9519\u8bef\u7684\u5bfc\u51fa\u4e2d\u95f4\u8868\u793a\u6765\u6d4b\u8bd5\u6a21\u578b\u5bf9\u4e2d\u95f4\u8868\u793a\u7f3a\u9677\u800c\u975e\u5b57\u9762\u9075\u5faa\u7684\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u8fed\u4ee3\u7f16\u8f91\u901a\u5e38\u80fd\u63d0\u9ad8\u6700\u7ec8\u6027\u80fd\uff0c\u4f46\u5728\u5408\u6210\u4fee\u590d\u8f68\u8ff9\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7f16\u8f91\u540e\u8bad\u7ec3\u4e2d\u89c2\u5bdf\u5230\u7684\u6548\u679c\u6709\u9650\u4e14\u4e0d\u7a33\u5b9a\u3002", "motivation": "\u8bbe\u8ba1\u8f6c\u4ee3\u7801\u6280\u672f\u5c06\u9ad8\u4fdd\u771fUI\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u524d\u7aef\u5b9e\u73b0\uff0c\u4f46\u56e0\u4e3a\u6570\u636e\u96c6\u3001\u5de5\u5177\u94fe\u548c\u8bc4\u4f30\u534f\u8bae\u4e0d\u4e00\u81f4\uff0c\u4f7f\u5f97\u8fdb\u5c55\u96be\u4ee5\u6bd4\u8f83\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u52a0\u7edf\u4e00\u4e14\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u6765\u8861\u91cf\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e861D-Bench\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u7535\u5b50\u5546\u52a1\u5de5\u4f5c\u6d41\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u6bcf\u4e2a\u5b9e\u4f8b\u90fd\u63d0\u4f9b\u4e86\u53c2\u8003\u6e32\u67d3\u56fe\u4ee5\u53ca\u53ef\u80fd\u5b58\u5728\u63d0\u53d6\u9519\u8bef\u7684\u5bfc\u51fa\u4e2d\u95f4\u8868\u793a\u3002\u6a21\u578b\u63a5\u53d7\u4e24\u8005\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u4f9d\u636e\u53c2\u8003\u6e32\u67d3\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ee5\u68c0\u9a8c\u6a21\u578b\u5bf9\u4e8e\u4e2d\u95f4\u8868\u793a\u4e2d\u7684\u7f3a\u9677\u662f\u5426\u5177\u6709\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u901a\u8fc7\u591a\u8f6e\u8fed\u4ee3\u4fee\u6539\u7ec4\u4ef6\u7ea7\u7f16\u8f91\u4ee5\u53ca\u57fa\u4e8e\u5408\u6210\u4fee\u590d\u8def\u5f84\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fed\u4ee3\u7f16\u8f91\u901a\u5e38\u80fd\u591f\u63d0\u9ad8\u6700\u7ec8\u7684\u8868\u73b0\uff0c\u5305\u62ec\u589e\u52a0\u6e32\u67d3\u6210\u529f\u7387\u548c\u6539\u5584\u89c6\u89c9\u76f8\u4f3c\u5ea6\u3002\u7136\u800c\uff0c\u5728\u91c7\u7528\u5408\u6210\u4fee\u590d\u8f68\u8ff9\u53ca\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7f16\u8f91\u7b56\u7565\u8fdb\u884c\u540e\u671f\u8bad\u7ec3\u65f6\uff0c\u89c2\u5bdf\u5230\u4e86\u6709\u9650\u4e14\u4e0d\u7a33\u5b9a\u7684\u6548\u679c\u63d0\u5347\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u7ec8\u7aef\u5956\u52b1\u7a00\u758f\u4ee5\u53ca\u6587\u4ef6\u7ea7\u522b\u66f4\u65b0\u7684\u9ad8\u65b9\u5dee\u6240\u81f4\u3002", "conclusion": "1D-Bench\u4e3a\u8bbe\u8ba1\u8f6c\u4ee3\u7801\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5728\u5b58\u5728\u4e2d\u95f4\u8868\u793a\u7f3a\u9677\u60c5\u51b5\u4e0b\u6a21\u578b\u9c81\u68d2\u6027\u7684\u91cd\u8981\u6027\u3002\u5c3d\u7ba1\u8fed\u4ee3\u7f16\u8f91\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\uff0c\u4f46\u540e\u7eed\u5c1d\u8bd5\u901a\u8fc7\u7279\u5b9a\u6280\u672f\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u8868\u73b0\u7684\u52aa\u529b\u663e\u793a\u51fa\u4e86\u5c40\u9650\u6027\u3002"}}
{"id": "2602.19084", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19084", "abs": "https://arxiv.org/abs/2602.19084", "authors": ["Emir Gencer", "Mohammad Kefah Taha Issa", "Ilyas Turimbetov", "James D. Trotter", "Didem Unat"], "title": "ucTrace: A Multi-Layer Profiling Tool for UCX-driven Communication", "comment": "11 pages, 8 figures. To appear in the 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2026)", "summary": "UCX is a communication framework that enables low-latency, high-bandwidth communication in HPC systems. With its unified API, UCX facilitates efficient data transfers across multi-node CPU-GPU clusters. UCX is widely used as the transport layer for MPI, particularly in GPU-aware implementations. However, existing profiling tools lack fine-grained communication traces at the UCX level, do not capture transport-layer behavior, or are limited to specific MPI implementations.\n  To address these gaps, we introduce ucTrace, a novel profiler that exposes and visualizes UCX-driven communication in HPC environments. ucTrace provides insights into MPI workflows by profiling message passing at the UCX level, linking operations between hosts and devices (e.g., GPUs and NICs) directly to their originating MPI functions. Through interactive visualizations of process- and device-specific interactions, ucTrace helps system administrators, library and application developers optimize performance and debug communication patterns in large-scale workloads. We demonstrate ucTrace's features through a wide range of experiments including MPI point-to-point behavior under different UCX settings, Allreduce comparisons across MPI libraries, communication analysis of a linear solver, NUMA binding effects, and profiling of GROMACS MD simulations with GPU acceleration at scale. ucTrace is publicly available at https://github.com/ParCoreLab/ucTrace.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aucTrace\u7684\u65b0\u5de5\u5177\uff0c\u5b83\u80fd\u591f\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684UCX\u7ea7\u522b\u901a\u4fe1\u8ffd\u8e2a\uff0c\u5e2e\u52a9\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u7cfb\u7edf\u7ba1\u7406\u5458\u548c\u5f00\u53d1\u8005\u4f18\u5316\u6027\u80fd\u5e76\u8c03\u8bd5\u901a\u4fe1\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u6790\u5de5\u5177\u7f3a\u4e4f\u5bf9UCX\u7ea7\u522b\u7684\u7cbe\u7ec6\u901a\u4fe1\u8ffd\u8e2a\uff0c\u65e0\u6cd5\u6355\u6349\u4f20\u8f93\u5c42\u884c\u4e3a\uff0c\u6216\u4ec5\u9650\u4e8e\u7279\u5b9a\u7684MPI\u5b9e\u73b0\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e9b\u7a7a\u767d\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86ucTrace\u3002", "method": "\u901a\u8fc7\u5728UCX\u5c42\u9762\u8fdb\u884c\u6d88\u606f\u4f20\u9012\u5256\u6790\uff0c\u5c06\u4e3b\u673a\u4e0e\u8bbe\u5907\uff08\u5982GPU\u548cNIC\uff09\u4e4b\u95f4\u7684\u64cd\u4f5c\u76f4\u63a5\u4e0e\u5176\u6e90MPI\u51fd\u6570\u5173\u8054\u8d77\u6765\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5c55\u793a\u8fdb\u7a0b\u548c\u8bbe\u5907\u7279\u5b9a\u7684\u4ea4\u4e92\u3002", "result": "ucTrace\u5c55\u793a\u4e86\u5176\u7279\u6027\uff0c\u5305\u62ec\u5728\u4e0d\u540cUCX\u8bbe\u7f6e\u4e0b\u7684MPI\u70b9\u5bf9\u70b9\u884c\u4e3a\u3001\u8de8MPI\u5e93\u7684Allreduce\u6bd4\u8f83\u3001\u7ebf\u6027\u6c42\u89e3\u5668\u7684\u901a\u4fe1\u5206\u6790\u3001NUMA\u7ed1\u5b9a\u6548\u679c\u4ee5\u53ca\u5927\u89c4\u6a21\u5e26GPU\u52a0\u901f\u7684GROMACS\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u7684\u5256\u6790\u3002", "conclusion": "ucTrace\u4e3aHPC\u73af\u5883\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6d1e\u5bdf\u529b\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u6027\u80fd\u53ca\u8c03\u8bd5\u5927\u89c4\u6a21\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u901a\u4fe1\u6a21\u5f0f\u3002"}}
{"id": "2602.19183", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.19183", "abs": "https://arxiv.org/abs/2602.19183", "authors": ["Mohammad Ashhad", "Olga Mashkova", "Ricardo Henao", "Robert Hoehndorf"], "title": "SIDEKICK: A Semantically Integrated Resource for Drug Effects, Indications, and Contraindications", "comment": null, "summary": "Pharmacovigilance and clinical decision support systems utilize structured drug safety data to guide medical practice. However, existing datasets frequently depend on terminologies such as MedDRA, which limits their semantic reasoning capabilities and their interoperability with Semantic Web ontologies and knowledge graphs. To address this gap, we developed SIDEKICK, a knowledge graph that standardizes drug indications, contraindications, and adverse reactions from FDA Structured Product Labels. We developed and used a workflow based on Large Language Model (LLM) extraction and Graph-Retrieval Augmented Generation (Graph RAG) for ontology mapping. We processed over 50,000 drug labels and mapped terms to the Human Phenotype Ontology (HPO), the MONDO Disease Ontology, and RxNorm. Our semantically integrated resource outperforms the SIDER and ONSIDES databases when applied to the task of drug repurposing by side effect similarity. We serialized the dataset as a Resource Description Framework (RDF) graph and employed the Semanticscience Integrated Ontology (SIO) as upper level ontology to further improve interoperability. Consequently, SIDEKICK enables automated safety surveillance and phenotype-based similarity analysis for drug repurposing.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86SIDEKICK\uff0c\u4e00\u4e2a\u57fa\u4e8eFDA\u7ed3\u6784\u5316\u4ea7\u54c1\u6807\u7b7e\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u7528\u4e8e\u6807\u51c6\u5316\u836f\u7269\u7684\u9002\u5e94\u75c7\u3001\u7981\u5fcc\u75c7\u548c\u4e0d\u826f\u53cd\u5e94\u4fe1\u606f\u3002\u901a\u8fc7\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u53d6\u548c\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Graph RAG\uff09\u8fdb\u884c\u672c\u4f53\u6620\u5c04\u7684\u65b9\u6cd5\u5904\u7406\u8d85\u8fc750,000\u79cd\u836f\u7269\u6807\u7b7e\uff0c\u5e76\u5c06\u672f\u8bed\u6620\u5c04\u5230\u4eba\u7c7b\u8868\u578b\u672c\u4f53(HPO)\u3001MONDO\u75be\u75c5\u672c\u4f53\u548cRxNorm\u4e0a\u3002\u8be5\u8d44\u6e90\u5728\u57fa\u4e8e\u526f\u4f5c\u7528\u76f8\u4f3c\u6027\u7684\u836f\u7269\u518d\u5229\u7528\u4efb\u52a1\u4e2d\u4f18\u4e8eSIDER\u548cONSIDES\u6570\u636e\u5e93\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u8fd8\u5c06\u6570\u636e\u96c6\u5e8f\u5217\u5316\u4e3aRDF\u56fe\uff0c\u5e76\u91c7\u7528Semanticscience Integrated Ontology (SIO)\u4f5c\u4e3a\u9876\u5c42\u672c\u4f53\u6765\u63d0\u9ad8\u4e92\u64cd\u4f5c\u6027\uff0c\u4ece\u800c\u652f\u6301\u81ea\u52a8\u5316\u5b89\u5168\u6027\u76d1\u6d4b\u53ca\u57fa\u4e8e\u8868\u578b\u7684\u76f8\u4f3c\u6027\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u7684\u836f\u7269\u5b89\u5168\u6570\u636e\u96c6\u5e38\u4f9d\u8d56\u4e8e\u5982MedDRA\u8fd9\u6837\u7684\u672f\u8bed\u4f53\u7cfb\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u4ee5\u53ca\u4e0e\u8bed\u4e49\u7f51\u672c\u4f53\u548c\u77e5\u8bc6\u56fe\u8c31\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u65e8\u5728\u521b\u5efa\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u8bed\u4e49\u96c6\u6210\u80fd\u529b\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "method": "1. \u4eceFDA\u7ed3\u6784\u5316\u4ea7\u54c1\u6807\u7b7e\u4e2d\u63d0\u53d6\u836f\u7269\u76f8\u5173\u4fe1\u606f\uff1b2. \u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u56fe\u68c0\u7d22\u589e\u5f3a\u751f\u6210(Graph RAG)\u6280\u672f\u6765\u8fdb\u884c\u672c\u4f53\u6620\u5c04\uff1b3. \u5c06\u63d0\u53d6\u7684\u6570\u636e\u6620\u5c04\u81f3HPO\u3001MONDO\u75be\u75c5\u672c\u4f53\u8bba\u53caRxNorm\u7b49\u6807\u51c6\u672f\u8bed\u5e93\uff1b4. \u6570\u636e\u96c6\u88ab\u5e8f\u5217\u5316\u4e3aRDF\u683c\u5f0f\uff0c\u5e76\u91c7\u7528\u4e86Semanticscience Integrated Ontology (SIO)\u4f5c\u4e3a\u9ad8\u5c42\u7ea7\u672c\u4f53\u4ee5\u589e\u5f3a\u4e0d\u540c\u7cfb\u7edf\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\u3002", "result": "SIDEKICK\u4f5c\u4e3a\u4e00\u4e2a\u8bed\u4e49\u6574\u5408\u8d44\u6e90\uff0c\u5728\u6839\u636e\u526f\u4f5c\u7528\u76f8\u4f3c\u5ea6\u8fdb\u884c\u836f\u7269\u91cd\u65b0\u5b9a\u4f4d\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684SIDER\u548cONSIDES\u6570\u636e\u5e93\u3002\u540c\u65f6\uff0c\u5b83\u8fd8\u652f\u6301\u81ea\u52a8\u5316\u5b89\u5168\u76d1\u63a7\u4ee5\u53ca\u57fa\u4e8e\u8868\u578b\u7684\u76f8\u4f3c\u6027\u5206\u6790\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efaSIDEKICK\u77e5\u8bc6\u56fe\u8c31\uff0c\u7814\u7a76\u6210\u529f\u5730\u63d0\u5347\u4e86\u836f\u7269\u5b89\u5168\u6570\u636e\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u548c\u8de8\u5e73\u53f0\u4e92\u64cd\u4f5c\u6027\uff0c\u4e3a\u836f\u7269\u518d\u5229\u7528\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2602.19368", "categories": ["cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19368", "abs": "https://arxiv.org/abs/2602.19368", "authors": ["Hazim AbdElazim", "Shadman Islam", "Mostafa Milani"], "title": "The Human Factor in Data Cleaning: Exploring Preferences and Biases", "comment": "Conference submission, 8 pages", "summary": "Data cleaning is often framed as a technical preprocessing step, yet in practice it relies heavily on human judgment. We report results from a controlled survey study in which participants performed error detection, data repair and imputation, and entity matching tasks on census-inspired scenarios with known semantic validity. We find systematic evidence for several cognitive bias mechanisms in data cleaning. Framing effects arise when surface-level formatting differences (e.g., capitalization or numeric presentation) increase false-positive error flags despite unchanged semantics. Anchoring and adjustment bias appears when expert cues shift participant decisions beyond parity, consistent with salience and availability effects. We also observe the representativeness heuristic: atypical but valid attribute combinations are frequently flagged as erroneous, and in entity matching tasks, surface similarity produces a substantial false-positive rate with high confidence. In data repair, participants show a robust preference for leaving values missing rather than imputing plausible values, consistent with omission bias. In contrast, automation-aligned switching under strong contradiction does not exceed a conservative rare-error tolerance threshold at the population level, indicating that deference to automated recommendations is limited in this setting. Across scenarios, bias patterns persist among technically experienced participants and across diverse workflow practices, suggesting that bias in data cleaning reflects general cognitive tendencies rather than lack of expertise. These findings motivate human-in-the-loop cleaning systems that clearly separate representation from semantics, present expert or algorithmic recommendations non-prescriptively, and support reflective evaluation of atypical but valid cases.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u9879\u63a7\u5236\u8c03\u67e5\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u6570\u636e\u6e05\u7406\u8fc7\u7a0b\u4e2d\u7684\u4eba\u7c7b\u5224\u65ad\u504f\u5dee\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6570\u636e\u6e05\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u6846\u67b6\u6548\u5e94\u3001\u951a\u5b9a\u4e0e\u8c03\u6574\u504f\u5dee\u3001\u4ee3\u8868\u6027\u542f\u53d1\u5f0f\u7b49\u8ba4\u77e5\u504f\u5dee\u673a\u5236\u3002\u6b64\u5916\uff0c\u53c2\u4e0e\u8005\u5728\u4fee\u590d\u6570\u636e\u65f6\u503e\u5411\u4e8e\u4fdd\u6301\u6570\u636e\u7f3a\u5931\u800c\u4e0d\u662f\u586b\u5145\u5408\u7406\u503c\u3002\u8fd9\u4e9b\u504f\u5dee\u6a21\u5f0f\u5728\u6280\u672f\u7ecf\u9a8c\u4e30\u5bcc\u7684\u53c2\u4e0e\u8005\u548c\u6280\u672f\u591a\u6837\u7684\u5de5\u4f5c\u6d41\u7a0b\u5b9e\u8df5\u4e2d\u4f9d\u7136\u5b58\u5728\u3002", "motivation": "\u6570\u636e\u6e05\u7406\u901a\u5e38\u88ab\u89c6\u4e3a\u4e00\u4e2a\u6280\u672f\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u4f46\u5b9e\u9645\u4e0a\u5b83\u4e25\u91cd\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u7684\u5224\u65ad\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e00\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u5728\u504f\u5dee\uff0c\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u57fa\u4e8e\u4eba\u53e3\u666e\u67e5\u60c5\u666f\u7684\u4efb\u52a1\uff0c\u4ee5\u63a2\u7d22\u6570\u636e\u6e05\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u8ba4\u77e5\u504f\u5dee\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u9879\u63a7\u5236\u8c03\u67e5\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u53c2\u4e0e\u8005\u9700\u8981\u5b8c\u6210\u9519\u8bef\u68c0\u6d4b\u3001\u6570\u636e\u4fee\u590d\u548c\u63d2\u8865\u4ee5\u53ca\u5b9e\u4f53\u5339\u914d\u7b49\u4efb\u52a1\u3002\u8fd9\u4e9b\u4efb\u52a1\u7684\u8bbe\u8ba1\u7075\u611f\u6765\u6e90\u4e8e\u5177\u6709\u5df2\u77e5\u8bed\u4e49\u6709\u6548\u6027\u7684\u666e\u67e5\u573a\u666f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86\u6570\u636e\u6e05\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u51e0\u79cd\u7cfb\u7edf\u6027\u7684\u8ba4\u77e5\u504f\u5dee\u673a\u5236\uff0c\u5305\u62ec\uff1a\u7531\u4e8e\u8868\u9762\u683c\u5f0f\u5dee\u5f02\u5bfc\u81f4\u7684\u6846\u67b6\u6548\u5e94\u3001\u4e13\u5bb6\u63d0\u793a\u5f15\u8d77\u7684\u951a\u5b9a\u4e0e\u8c03\u6574\u504f\u5dee\u3001\u5178\u578b\u6027\u4f46\u6709\u6548\u7684\u5c5e\u6027\u7ec4\u5408\u88ab\u9891\u7e41\u6807\u8bb0\u4e3a\u9519\u8bef\u7684\u4ee3\u8868\u6027\u542f\u53d1\u5f0f\u504f\u5dee\u3002\u6b64\u5916\uff0c\u53c2\u4e0e\u8005\u5728\u9762\u5bf9\u6570\u636e\u4fee\u590d\u65f6\u8868\u73b0\u51fa\u5bf9\u4fdd\u6301\u6570\u636e\u7f3a\u5931\u800c\u975e\u8fdb\u884c\u5408\u7406\u63d2\u503c\u7684\u504f\u597d\u3002", "conclusion": "\u6570\u636e\u6e05\u7406\u4e2d\u7684\u504f\u5dee\u53cd\u6620\u4e86\u666e\u904d\u7684\u8ba4\u77e5\u503e\u5411\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u7684\u7ed3\u679c\u3002\u8fd9\u4e9b\u53d1\u73b0\u4fc3\u4f7f\u5f00\u53d1\u66f4\u52a0\u4eba\u6027\u5316\u4e14\u80fd\u660e\u786e\u533a\u5206\u8868\u793a\u4e0e\u8bed\u4e49\u7684\u6570\u636e\u6e05\u7406\u7cfb\u7edf\uff0c\u5e76\u4ee5\u975e\u89c4\u5b9a\u6027\u65b9\u5f0f\u5448\u73b0\u4e13\u5bb6\u6216\u7b97\u6cd5\u5efa\u8bae\uff0c\u540c\u65f6\u652f\u6301\u5bf9\u975e\u5178\u578b\u4f46\u6709\u6548\u6848\u4f8b\u7684\u53cd\u601d\u6027\u8bc4\u4f30\u3002"}}
{"id": "2602.19088", "categories": ["cs.DC", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.19088", "abs": "https://arxiv.org/abs/2602.19088", "authors": ["Ziwei Zhou", "Si Liu", "Zhou Zhou", "Peixin Wang", "MIn Zhang"], "title": "A Formal Framework for Predicting Distributed System Performance under Faults", "comment": "32 pages, 3 figures. Accepted by FM 2026", "summary": "Today's distributed systems operate in complex environments that inevitably involve faults and even adversarial behaviors. Predicting their performance under such environments directly from formal designs remains a longstanding challenge. We present the first formal framework that systematically enables performance prediction of distributed systems across diverse faulty scenarios. Our framework features a fault injector together with a wide range of faults, reusable as a library, and model compositions that integrate the system and the fault injector into a unified model suitable for statistical analysis of performance properties such as throughput and latency. We formalize the framework in Maude and implement it as an automated tool, PERF. Applied to representative distributed systems, PERF accurately predicts system performance under varying fault settings, with estimations from formal designs consistent with evaluations on real deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u9884\u6d4b\u5206\u5e03\u5f0f\u7cfb\u7edf\u5728\u5404\u79cd\u6545\u969c\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7PERF\u5de5\u5177\u5b9e\u73b0\u4e86\u8fd9\u4e00\u6846\u67b6\uff0c\u8be5\u5de5\u5177\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u4e0d\u540c\u6545\u969c\u8bbe\u7f6e\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u8fd0\u884c\u5728\u590d\u6742\u7684\u73af\u5883\u4e2d\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u4f1a\u9047\u5230\u6545\u969c\u751a\u81f3\u5bf9\u6297\u884c\u4e3a\u3002\u4ece\u5f62\u5f0f\u5316\u8bbe\u8ba1\u76f4\u63a5\u9884\u6d4b\u8fd9\u79cd\u73af\u5883\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\u4e00\u76f4\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u6545\u969c\u6ce8\u5165\u5668\u548c\u591a\u79cd\u6545\u969c\u5e93\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u4ee5\u53ca\u5c06\u7cfb\u7edf\u4e0e\u6545\u969c\u6ce8\u5165\u5668\u96c6\u6210\u5230\u4e00\u4e2a\u9002\u5408\u4e8e\u7edf\u8ba1\u5206\u6790\u7edf\u4e00\u6a21\u578b\u4e2d\u7684\u6a21\u578b\u7ec4\u5408\u3002\u6b64\u6846\u67b6\u4f7f\u7528Maude\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\uff0c\u5e76\u5b9e\u73b0\u4e3a\u81ea\u52a8\u5316\u5de5\u5177PERF\u3002", "result": "PERF\u5de5\u5177\u88ab\u5e94\u7528\u4e8e\u4ee3\u8868\u6027\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u80fd\u591f\u7cbe\u786e\u9884\u6d4b\u4e0d\u540c\u6545\u969c\u8bbe\u7f6e\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\uff0c\u5176\u57fa\u4e8e\u5f62\u5f0f\u5316\u8bbe\u8ba1\u7684\u4f30\u8ba1\u4e0e\u5b9e\u9645\u90e8\u7f72\u8bc4\u4f30\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u7684\u5f62\u5f0f\u5316\u6846\u67b6\u548cPERF\u5de5\u5177\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u5206\u5e03\u5f0f\u7cfb\u7edf\u5728\u5b58\u5728\u591a\u6837\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.19339", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19339", "abs": "https://arxiv.org/abs/2602.19339", "authors": ["Anna Volodkevich", "Dmitry Anikin", "Danil Gusak", "Anton Klenitskiy", "Evgeny Frolov", "Alexey Vasilev"], "title": "SplitLight: An Exploratory Toolkit for Recommender Systems Datasets and Splits", "comment": null, "summary": "Offline evaluation of recommender systems is often affected by hidden, under-documented choices in data preparation. Seemingly minor decisions in filtering, handling repeats, cold-start treatment, and splitting strategy design can substantially reorder model rankings and undermine reproducibility and cross-paper comparability.\n  In this paper, we introduce SplitLight, an open-source exploratory toolkit that enables researchers and practitioners designing preprocessing and splitting pipelines or reviewing external artifacts to make these decisions measurable, comparable, and reportable. Given an interaction log and derived split subsets, SplitLight analyzes core and temporal dataset statistics, characterizes repeat consumption patterns and timestamp anomalies, and diagnoses split validity, including temporal leakage, cold-user/item exposure, and distribution shifts. SplitLight further allows side-by-side comparison of alternative splitting strategies through comprehensive aggregated summaries and interactive visualizations. Delivered as both a Python toolkit and an interactive no-code interface, SplitLight produces audit summaries that justify evaluation protocols and support transparent, reliable, and comparable experimentation in recommender systems research and industry.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aSplitLight\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u8bbe\u8ba1\u9884\u5904\u7406\u548c\u5206\u5272\u6d41\u7a0b\uff0c\u5e76\u5ba1\u67e5\u5916\u90e8\u5de5\u4ef6\uff0c\u4ece\u800c\u4f7f\u5f97\u51b3\u7b56\u8fc7\u7a0b\u53ef\u6d4b\u91cf\u3001\u53ef\u6bd4\u8f83\u4e14\u53ef\u62a5\u544a\u3002", "motivation": "\u79bb\u7ebf\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u65f6\uff0c\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u4e2d\u9690\u85cf\u6216\u8bb0\u5f55\u4e0d\u8db3\u7684\u9009\u62e9\u5f80\u5f80\u4f1a\u5f71\u54cd\u7ed3\u679c\u3002\u8fd9\u4e9b\u770b\u4f3c\u5fae\u5c0f\u7684\u51b3\u5b9a\uff0c\u5982\u8fc7\u6ee4\u65b9\u5f0f\u3001\u91cd\u590d\u5904\u7406\u3001\u51b7\u542f\u52a8\u5904\u7406\u53ca\u5206\u5272\u7b56\u7565\u7684\u8bbe\u8ba1\uff0c\u90fd\u53ef\u80fd\u6781\u5927\u5730\u6539\u53d8\u6a21\u578b\u6392\u540d\uff0c\u5e76\u524a\u5f31\u7814\u7a76\u7684\u53ef\u518d\u73b0\u6027\u548c\u8bba\u6587\u95f4\u7684\u53ef\u6bd4\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86SplitLight\u5de5\u5177\u5305\u3002", "method": "SplitLight\u662f\u4e00\u4e2a\u63a2\u7d22\u6027\u5de5\u5177\u5305\uff0c\u7ed9\u5b9a\u4e00\u4e2a\u4ea4\u4e92\u65e5\u5fd7\u548c\u7531\u6b64\u4ea7\u751f\u7684\u5206\u5272\u5b50\u96c6\u540e\uff0c\u8be5\u5de5\u5177\u80fd\u591f\u5206\u6790\u6838\u5fc3\u4e0e\u65f6\u95f4\u5e8f\u5217\u7684\u6570\u636e\u7edf\u8ba1\u4fe1\u606f\uff0c\u63cf\u8ff0\u91cd\u590d\u6d88\u8d39\u6a21\u5f0f\u548c\u65f6\u95f4\u6233\u5f02\u5e38\uff0c\u5e76\u8bca\u65ad\u5206\u5272\u7684\u6709\u6548\u6027\uff08\u5305\u62ec\u65f6\u95f4\u6cc4\u6f0f\u3001\u51b7\u7528\u6237/\u9879\u76ee\u66b4\u9732\u4ee5\u53ca\u5206\u5e03\u53d8\u5316\uff09\u3002\u6b64\u5916\uff0cSplitLight\u8fd8\u652f\u6301\u901a\u8fc7\u7efc\u5408\u6c47\u603b\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u6765\u5e76\u6392\u6bd4\u8f83\u4e0d\u540c\u7684\u5206\u5272\u7b56\u7565\u3002", "result": "SplitLight\u4f5c\u4e3aPython\u5de5\u5177\u5305\u548c\u4ea4\u4e92\u5f0f\u7684\u65e0\u4ee3\u7801\u754c\u9762\u63d0\u4f9b\uff0c\u53ef\u4ee5\u751f\u6210\u5ba1\u8ba1\u6458\u8981\u4ee5\u8bc1\u660e\u8bc4\u4f30\u534f\u8bae\u7684\u5408\u7406\u6027\uff0c\u5e76\u652f\u6301\u5728\u63a8\u8350\u7cfb\u7edf\u7684\u7814\u7a76\u548c\u884c\u4e1a\u4e2d\u8fdb\u884c\u900f\u660e\u3001\u53ef\u9760\u4e14\u53ef\u6bd4\u8f83\u7684\u5b9e\u9a8c\u3002", "conclusion": "SplitLight\u65e8\u5728\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u79bb\u7ebf\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\u6570\u636e\u51c6\u5907\u9636\u6bb5\u51b3\u7b56\u7684\u900f\u660e\u5ea6\u3001\u53ef\u6bd4\u6027\u548c\u62a5\u544a\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u7814\u7a76\u91cd\u73b0\u6027\u548c\u8de8\u8bba\u6587\u5bf9\u6bd4\u3002"}}
{"id": "2602.19440", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.19440", "abs": "https://arxiv.org/abs/2602.19440", "authors": ["Toshihiro Suzuki", "Hiroyuki Yamada"], "title": "Breaking the Barriers of Database-Agnostic Transactions", "comment": "technical report (preprint)", "summary": "Federated transaction management has long been used as a method to virtually integrate multiple databases from a transactional perspective, ensuring consistency across the databases. Modern approaches manage transactions on top of a database abstraction to achieve database agnosticism; however, these approaches face several challenges. First, managing transactions on top of a database abstraction makes performance optimization difficult because the abstraction hides away the details of underlying databases, such as database-specific capabilities. Additionally, it requires that application data and the associated transaction metadata be colocated in the same record to allow for efficient updates, necessitating a schema migration to run federated transactions on top of existing databases. This paper introduces a new concept in such database abstraction called Atomicity Unit (AU) to address these challenges. AU enables federated transaction management to aggressively pushdown database operations by making use of the knowledge about the scope within which they can perform operations atomically, fully harnessing the performance of the databases. Moreover, AU enables efficient separation of transaction metadata from application data, allowing federated transactions to run on existing databases without requiring a schema migration or significant performance degradation. In this paper, we describe AU, how AU addresses the challenges, and its implementation within ScalarDB, an open-sourced database-agnostic federated transaction manager. We also present evaluation results demonstrating that ScalarDB with AU achieves significantly better performance and efficient metadata separation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u5e93\u62bd\u8c61\u6982\u5ff5\u2014\u2014\u539f\u5b50\u6027\u5355\u5143\uff08AU\uff09\uff0c\u4ee5\u89e3\u51b3\u8054\u90a6\u4e8b\u52a1\u7ba1\u7406\u4e2d\u6027\u80fd\u4f18\u5316\u96be\u548c\u9700\u8981\u6a21\u5f0f\u8fc1\u79fb\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5229\u7528AU\uff0c\u53ef\u4ee5\u5145\u5206\u5229\u7528\u6570\u636e\u5e93\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u8fdb\u884c\u6a21\u5f0f\u8fc1\u79fb\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u5143\u6570\u636e\u5206\u79bb\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u4e8b\u52a1\u7ba1\u7406\u65b9\u6cd5\u5728\u6570\u636e\u5e93\u62bd\u8c61\u5c42\u4e0a\u6267\u884c\u65f6\u9762\u4e34\u6027\u80fd\u4f18\u5316\u56f0\u96be\u4ee5\u53ca\u9700\u8981\u5c06\u5e94\u7528\u7a0b\u5e8f\u6570\u636e\u53ca\u5176\u5173\u8054\u7684\u4e8b\u52a1\u5143\u6570\u636e\u5171\u5b58\u4e8e\u540c\u4e00\u8bb0\u5f55\u4e2d\u7684\u95ee\u9898\uff0c\u8fd9\u901a\u5e38\u9700\u8981\u5bf9\u73b0\u6709\u6570\u636e\u5e93\u8fdb\u884c\u6a21\u5f0f\u8fc1\u79fb\u3002", "method": "\u63d0\u51fa\u4e86\u539f\u5b50\u6027\u5355\u5143\uff08AU\uff09\u7684\u6982\u5ff5\uff0c\u5b83\u5141\u8bb8\u8054\u90a6\u4e8b\u52a1\u7ba1\u7406\u66f4\u6709\u6548\u5730\u63a8\u9001\u6570\u636e\u5e93\u64cd\u4f5c\uff0c\u5e76\u4e14\u80fd\u591f\u9ad8\u6548\u5730\u5206\u79bb\u4e8b\u52a1\u5143\u6570\u636e\u4e0e\u5e94\u7528\u7a0b\u5e8f\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528AU\u7684ScalarDB\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u597d\u7684\u6027\u80fd\u548c\u6709\u6548\u7684\u5143\u6570\u636e\u5206\u79bb\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165AU\u8fd9\u4e00\u65b0\u6982\u5ff5\uff0c\u8054\u90a6\u4e8b\u52a1\u7ba1\u7406\u7cfb\u7edf\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u6027\u80fd\u6216\u8981\u6c42\u6a21\u5f0f\u8fc1\u79fb\u7684\u524d\u63d0\u4e0b\uff0c\u66f4\u597d\u5730\u5904\u7406\u8de8\u591a\u4e2a\u6570\u636e\u5e93\u7684\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2602.18579", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18579", "abs": "https://arxiv.org/abs/2602.18579", "authors": ["Jos\u00e9 Aldo Silva da Costa", "Rohit Gheyi", "Jos\u00e9 J\u00fanior Silva da Costa", "M\u00e1rcio Ribeiro", "Rodrigo Bonif\u00e1cio", "Hyggo Almeida", "Ana Carla Bibiano", "Alessandro Garcia"], "title": "Refactoring for Novices in Java: An Eye Tracking Study on the Extract vs. Inline Methods", "comment": null, "summary": "Developers often extract methods to improve readability, understanding, and reuse, while inlining keeps logic in one block. Prior work based on static metrics has not shown clear differences between these practices, and the human side of comprehension and navigation remains underexplored. We investigate Inline Method vs. Extract Method refactorings using a dynamic approach: eye tracking while participants read and solve tasks. We analyze key code areas and compare visual effort and reading behavior (fixation duration and count, regressions, revisits), alongside time and attempts. We ran a controlled experiment with 32 Java novices, followed by short interviews. Each participant solved eight simple tasks across four programs presented in an inlined version and four in an extracted version. We also surveyed 58 additional novices for complementary quantitative and qualitative data. Results show that effects depend on task difficulty. In two tasks, method extraction improved performance and reduced visual effort, with time decreasing by up to 78.8% and regressions by 84.6%. For simpler tasks (e.g., square area), extraction hurt performance: time increased by up to 166.9% and regressions by 200%. Even with meaningful method names, novices often switched back and forth between call sites and extracted methods, increasing navigation and cognitive load. Preferences frequently favored extraction for readability and reuse, but did not always match measured performance. These findings suggest educators should be cautious about premature modularization for novices and highlight eye tracking as a useful complement to static metrics.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u6765\u5206\u6790\u5185\u8054\u65b9\u6cd5\u4e0e\u63d0\u53d6\u65b9\u6cd5\u91cd\u6784\u5bf9Java\u521d\u5b66\u8005\u4ee3\u7801\u7406\u89e3\u53ca\u5bfc\u822a\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e24\u79cd\u91cd\u6784\u65b9\u5f0f\u7684\u6548\u679c\u53d6\u51b3\u4e8e\u4efb\u52a1\u96be\u5ea6\uff1a\u5728\u8f83\u96be\u7684\u4efb\u52a1\u4e2d\uff0c\u65b9\u6cd5\u63d0\u53d6\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\u5e76\u51cf\u5c11\u89c6\u89c9\u52aa\u529b\uff1b\u800c\u5728\u8f83\u7b80\u5355\u7684\u4efb\u52a1\u4e2d\uff0c\u5219\u53ef\u80fd\u589e\u52a0\u65f6\u95f4\u6d88\u8017\u548c\u8ba4\u77e5\u8d1f\u62c5\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u53c2\u4e0e\u8005\u504f\u597d\u4e8e\u4e3a\u53ef\u8bfb\u6027\u548c\u590d\u7528\u6027\u800c\u8fdb\u884c\u7684\u65b9\u6cd5\u63d0\u53d6\uff0c\u4f46\u8fd9\u79cd\u504f\u597d\u5e76\u4e0d\u603b\u662f\u4e0e\u5b9e\u9645\u6d4b\u91cf\u7684\u6027\u80fd\u4e00\u81f4\u3002", "motivation": "\u4ee5\u5f80\u57fa\u4e8e\u9759\u6001\u5ea6\u91cf\u7684\u7814\u7a76\u672a\u80fd\u6e05\u6670\u5730\u5c55\u793a\u5185\u8054\u65b9\u6cd5\u4e0e\u63d0\u53d6\u65b9\u6cd5\u91cd\u6784\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4eba\u7c7b\u7406\u89e3\u548c\u5bfc\u822a\u65b9\u9762\u7684\u63a2\u7d22\u4e0d\u8db3\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5229\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u6df1\u5165\u63a2\u8ba8\u4e24\u79cd\u91cd\u6784\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u7f16\u7a0b\u65b0\u624b\u5904\u7406\u4ee3\u7801\u7684\u65b9\u5f0f\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u52a8\u6001\u7684\u65b9\u6cd5\u2014\u2014\u5373\u4f7f\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u8bb0\u5f55\u53c2\u4e0e\u8005\u5728\u9605\u8bfb\u4ee3\u7801\u548c\u89e3\u51b3\u95ee\u9898\u65f6\u7684\u884c\u4e3a\u3002\u5b9e\u9a8c\u8bbe\u8ba1\u5305\u62ec\u8ba932\u4f4dJava\u65b0\u624b\u89e3\u51b3\u516b\u4e2a\u7b80\u5355\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u5206\u522b\u4ee5\u5185\u8054\u7248\u672c\u548c\u63d0\u53d6\u7248\u672c\u7684\u5f62\u5f0f\u5448\u73b0\u7ed9\u53c2\u4e0e\u8005\u3002\u9664\u4e86\u4e3b\u8981\u5b9e\u9a8c\u5916\uff0c\u8fd8\u5bf9\u53e6\u591658\u4f4d\u65b0\u624b\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u4ee5\u6536\u96c6\u66f4\u591a\u5b9a\u91cf\u548c\u5b9a\u6027\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u590d\u6742\u4e00\u4e9b\u7684\u4efb\u52a1\uff0c\u63d0\u53d6\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u6539\u5584\u8868\u73b0\u5e76\u51cf\u5c11\u6240\u9700\u7684\u89c6\u89c9\u52aa\u529b\uff08\u5982\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe78.8%\uff0c\u56de\u89c6\u6b21\u6570\u51cf\u5c1184.6%\uff09\u3002\u7136\u800c\uff0c\u5728\u5904\u7406\u66f4\u7b80\u5355\u7684\u4efb\u52a1\u65f6\uff0c\u63d0\u53d6\u65b9\u6cd5\u53cd\u800c\u4f1a\u635f\u5bb3\u8868\u73b0\uff08\u5982\u65f6\u95f4\u589e\u52a0\u4e86\u6700\u591a166.9%\uff0c\u56de\u89c6\u6b21\u6570\u589e\u52a0\u4e86200%\uff09\u3002\u5373\u4f7f\u65b9\u6cd5\u540d\u79f0\u5177\u6709\u610f\u4e49\uff0c\u65b0\u624b\u4eec\u4e5f\u5e38\u5e38\u9700\u8981\u5728\u8c03\u7528\u70b9\u4e0e\u88ab\u63d0\u53d6\u7684\u65b9\u6cd5\u4e4b\u95f4\u6765\u56de\u5207\u6362\uff0c\u8fd9\u589e\u52a0\u4e86\u5bfc\u822a\u9700\u6c42\u548c\u8ba4\u77e5\u8d1f\u8377\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u521d\u5b66\u8005\u800c\u8a00\uff0c\u8fc7\u65e9\u5730\u6a21\u5757\u5316\u53ef\u80fd\u4f1a\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u6559\u80b2\u8005\u5e94\u5f53\u8c28\u614e\u5bf9\u5f85\u5411\u65b0\u624b\u4ecb\u7ecd\u6a21\u5757\u5316\u7684\u65f6\u673a\u3002\u540c\u65f6\uff0c\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u773c\u52a8\u8ffd\u8e2a\u4f5c\u4e3a\u8865\u5145\u9759\u6001\u5ea6\u91cf\u7684\u4e00\u79cd\u6709\u7528\u5de5\u5177\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.18518", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18518", "abs": "https://arxiv.org/abs/2602.18518", "authors": ["Attila Dobi", "Aravindh Manickavasagam", "Benjamin Thompson", "Xiaohan Yang", "Faisal Farooq"], "title": "Measuring the Prevalence of Policy Violating Content with ML Assisted Sampling and LLM Labeling", "comment": "8 pages", "summary": "Content safety teams need metrics that reflect what users actually experience, not only what is reported. We study prevalence: the fraction of user views (impressions) that went to content violating a given policy on a given day. Accurate prevalence measurement is challenging because violations are often rare and human labeling is costly, making frequent, platform-representative studies slow. We present a design-based measurement system that (i) draws daily probability samples from the impression stream using ML-assisted weights to concentrate label budget on high-exposure and high-risk content while preserving unbiasedness, (ii) labels sampled items with a multimodal LLM governed by policy prompts and gold-set validation, and (iii) produces design-consistent prevalence estimates with confidence intervals and dashboard drilldowns. A key design goal is one global sample with many pivots: the same daily sample supports prevalence by surface, viewer geography, content age, and other segments through post-stratified estimation. We describe the statistical estimators, variance and confidence interval construction, label-quality monitoring, and an engineering workflow that makes the system configurable across policies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bbe\u8ba1\u7684\u6d4b\u91cf\u7cfb\u7edf\uff0c\u7528\u4e8e\u51c6\u786e\u6d4b\u91cf\u5185\u5bb9\u8fdd\u89c4\u7684\u666e\u904d\u6027\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u7684\u6743\u91cd\u4ece\u5c55\u793a\u6d41\u4e2d\u62bd\u53d6\u6bcf\u65e5\u6982\u7387\u6837\u672c\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6807\u7b7e\u5904\u7406\uff0c\u5e76\u751f\u6210\u65e0\u504f\u4e14\u5177\u6709\u4e00\u81f4\u6027\u7684\u8fdd\u89c4\u5185\u5bb9\u666e\u904d\u6027\u4f30\u8ba1\u503c\u53ca\u7f6e\u4fe1\u533a\u95f4\u3002", "motivation": "\u5185\u5bb9\u5b89\u5168\u56e2\u961f\u9700\u8981\u53cd\u6620\u7528\u6237\u5b9e\u9645\u4f53\u9a8c\u7684\u6307\u6807\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u62a5\u544a\u7684\u6570\u636e\u3002\u7136\u800c\uff0c\u51c6\u786e\u5730\u6d4b\u91cf\u8fdd\u89c4\u5185\u5bb9\u7684\u666e\u904d\u6027\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8fdd\u89c4\u60c5\u51b5\u901a\u5e38\u5f88\u5c11\u89c1\uff0c\u800c\u4e14\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u8fd9\u4f7f\u5f97\u9891\u7e41\u8fdb\u884c\u4ee3\u8868\u6027\u7814\u7a76\u53d8\u5f97\u7f13\u6162\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8bbe\u8ba1\u7684\u6d4b\u91cf\u7cfb\u7edf\uff0c\u5b83\u6bcf\u5929\u4ece\u5c55\u793a\u6d41\u4e2d\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u8f85\u52a9\u7684\u6743\u91cd\u62bd\u53d6\u6982\u7387\u6837\u672c\uff0c\u4ee5\u5c06\u6807\u7b7e\u9884\u7b97\u96c6\u4e2d\u5728\u9ad8\u66dd\u5149\u548c\u9ad8\u98ce\u9669\u7684\u5185\u5bb9\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u65e0\u504f\u6027\uff1b\u4f7f\u7528\u7531\u653f\u7b56\u63d0\u793a\u548c\u9ec4\u91d1\u96c6\u9a8c\u8bc1\u7ba1\u7406\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6765\u6807\u8bb0\u91c7\u6837\u9879\uff1b\u5e76\u751f\u6210\u4e0e\u8bbe\u8ba1\u4e00\u81f4\u7684\u666e\u904d\u6027\u4f30\u8ba1\u503c\uff0c\u5305\u62ec\u7f6e\u4fe1\u533a\u95f4\u548c\u4eea\u8868\u677f\u6df1\u5165\u5206\u6790\u3002", "result": "\u8fd9\u4e2a\u7cfb\u7edf\u80fd\u591f\u652f\u6301\u901a\u8fc7\u540e\u5206\u5c42\u4f30\u8ba1\u7684\u65b9\u5f0f\uff0c\u5bf9\u540c\u4e00\u65e5\u5e38\u6837\u672c\u6309\u754c\u9762\u3001\u89c2\u770b\u8005\u5730\u7406\u4f4d\u7f6e\u3001\u5185\u5bb9\u5e74\u9f84\u7b49\u591a\u4e2a\u7ef4\u5ea6\u63d0\u4f9b\u666e\u904d\u6027\u6570\u636e\u3002\u6b64\u5916\uff0c\u8fd8\u63cf\u8ff0\u4e86\u7edf\u8ba1\u4f30\u8ba1\u91cf\u3001\u65b9\u5dee\u548c\u7f6e\u4fe1\u533a\u95f4\u7684\u6784\u5efa\u65b9\u6cd5\u3001\u6807\u7b7e\u8d28\u91cf\u76d1\u63a7\u4ee5\u53ca\u4f7f\u7cfb\u7edf\u80fd\u591f\u5728\u4e0d\u540c\u653f\u7b56\u4e0b\u914d\u7f6e\u7684\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6d4b\u91cf\u7cfb\u7edf\u65e8\u5728\u5b9e\u73b0\u4e00\u4e2a\u5168\u7403\u6837\u672c\u652f\u6301\u591a\u4e2a\u89c6\u89d2\u5206\u6790\u7684\u76ee\u6807\uff0c\u5373\u540c\u6837\u7684\u65e5\u5e38\u6837\u672c\u53ef\u4ee5\u652f\u6301\u6839\u636e\u4e0d\u540c\u7ef4\u5ea6\uff08\u5982\u754c\u9762\u3001\u89c2\u4f17\u5730\u7406\u4f4d\u7f6e\u3001\u5185\u5bb9\u5e74\u9f84\u7b49\uff09\u901a\u8fc7\u540e\u5206\u5c42\u4f30\u8ba1\u5f97\u51fa\u7684\u666e\u904d\u6027\u6570\u636e\uff0c\u4ece\u800c\u4e3a\u5185\u5bb9\u5b89\u5168\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7387\u548c\u6548\u679c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.19702", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19702", "abs": "https://arxiv.org/abs/2602.19702", "authors": ["Adamya Shyam", "Venkateswara Rao Kagita", "Bharti Rana", "Vikas Kumar"], "title": "DReX: An Explainable Deep Learning-based Multimodal Recommendation Framework", "comment": null, "summary": "Multimodal recommender systems leverage diverse data sources, such as user interactions, content features, and contextual information, to address challenges like cold-start and data sparsity. However, existing methods often suffer from one or more key limitations: processing different modalities in isolation, requiring complete multimodal data for each interaction during training, or independent learning of user and item representations. These factors contribute to increased complexity and potential misalignment between user and item embeddings. To address these challenges, we propose DReX, a unified multimodal recommendation framework that incrementally refines user and item representations by leveraging interaction-level features from multimodal feedback. Our model employs gated recurrent units to selectively integrate these fine-grained features into global representations. This incremental update mechanism provides three key advantages: (1) simultaneous modeling of both nuanced interaction details and broader preference patterns, (2) eliminates the need for separate user and item feature extraction processes, leading to enhanced alignment in their learned representation, and (3) inherent robustness to varying or missing modalities. We evaluate the performance of the proposed approach on three real-world datasets containing reviews and ratings as interaction modalities. By considering review text as a modality, our approach automatically generates interpretable keyword profiles for both users and items, which supplement the recommendation process with interpretable preference indicators. Experiment results demonstrate that our approach outperforms state-of-the-art methods across all evaluated datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6DReX\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4ece\u591a\u6a21\u6001\u53cd\u9988\u4e2d\u5229\u7528\u4ea4\u4e92\u7ea7\u522b\u7684\u7279\u5f81\u9010\u6b65\u5b8c\u5584\u7528\u6237\u548c\u9879\u76ee\u8868\u793a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u8bc4\u4f30\u7684\u6570\u636e\u96c6\u4e0a\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u65b9\u6cd5\u5b58\u5728\u4e00\u4e9b\u5173\u952e\u9650\u5236\uff1a\u5355\u72ec\u5904\u7406\u4e0d\u540c\u7684\u6a21\u6001\u3001\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9700\u8981\u6bcf\u4e2a\u4ea4\u4e92\u90fd\u6709\u5b8c\u6574\u7684\u591a\u6a21\u6001\u6570\u636e\u3001\u6216\u8005\u72ec\u7acb\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u8868\u793a\u3002\u8fd9\u4e9b\u95ee\u9898\u5bfc\u81f4\u4e86\u590d\u6742\u6027\u7684\u589e\u52a0\u4ee5\u53ca\u7528\u6237\u4e0e\u9879\u76ee\u5d4c\u5165\u4e4b\u95f4\u6f5c\u5728\u7684\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51fa\u4e86DReX\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u63a8\u8350\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5229\u7528\u6765\u81ea\u591a\u6a21\u6001\u53cd\u9988\u7684\u4ea4\u4e92\u7ea7\u7279\u5f81\u6765\u9010\u6b65\u6539\u8fdb\u7528\u6237\u548c\u7269\u54c1\u8868\u793a\u3002\u6a21\u578b\u4f7f\u7528\u95e8\u63a7\u5faa\u73af\u5355\u5143\u6709\u9009\u62e9\u5730\u5c06\u8fd9\u4e9b\u7ec6\u7c92\u5ea6\u7279\u5f81\u6574\u5408\u5230\u5168\u5c40\u8868\u793a\u4e2d\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u8003\u8651\u4e86\u5305\u542b\u8bc4\u8bba\u6587\u672c\u4e3a\u4e00\u79cd\u6a21\u6001\u7684\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u5f97\u5230\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6240\u6709\u88ab\u8bc4\u4f30\u7684\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5c06\u8bc4\u8bba\u6587\u672c\u89c6\u4e3a\u4e00\u79cd\u6a21\u6001\uff0c\u8be5\u65b9\u6cd5\u8fd8\u80fd\u81ea\u52a8\u751f\u6210\u7528\u6237\u548c\u9879\u76ee\u7684\u53ef\u89e3\u91ca\u5173\u952e\u8bcd\u914d\u7f6e\u6587\u4ef6\u3002", "conclusion": "DReX\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u514b\u670d\u5f53\u524d\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\uff0c\u5305\u62ec\u80fd\u591f\u540c\u65f6\u5efa\u6a21\u7ec6\u81f4\u7684\u4e92\u52a8\u7ec6\u8282\u548c\u66f4\u5e7f\u6cdb\u7684\u504f\u597d\u6a21\u5f0f\uff0c\u65e0\u9700\u5355\u72ec\u8fdb\u884c\u7528\u6237\u548c\u9879\u76ee\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\uff0c\u5e76\u4e14\u5bf9\u53d8\u5316\u6216\u7f3a\u5931\u7684\u6a21\u6001\u5177\u6709\u5185\u5728\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.19490", "categories": ["cs.DB", "cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19490", "abs": "https://arxiv.org/abs/2602.19490", "authors": ["Yongxin Chen", "Zhiyuan Jiang", "Chao Zhang", "Haoran Xu", "Shenglin Xu", "Jianping Tang", "Zheming Li", "Peidai Xie", "Yongjun Wang"], "title": "FuzzySQL: Uncovering Hidden Vulnerabilities in DBMS Special Features with LLM-Driven Fuzzing", "comment": null, "summary": "Traditional database fuzzing techniques primarily focus on syntactic correctness and general SQL structures, leaving critical yet obscure DBMS features, such as system-level modes (e.g., GTID), programmatic constructs (e.g., PROCEDURE), advanced process commands (e.g., KILL), largely underexplored. Although rarely triggered by typical inputs, these features can lead to severe crashes or security issues when executed under edge-case conditions. In this paper, we present FuzzySQL, a novel LLM-powered adaptive fuzzing framework designed to uncover subtle vulnerabilities in DBMS special features. FuzzySQL combines grammar-guided SQL generation with logic-shifting progressive mutation, a novel technique that explores alternative control paths by negating conditions and restructuring execution logic, synthesizing structurally and semantically diverse test cases. To further ensure deeper execution coverage of the back end, FuzzySQL employs a hybrid error repair pipeline that unifies rule-based patching with LLM-driven semantic repair, enabling automatic correction of syntactic and context-sensitive failures. We evaluate FuzzySQL across multiple DBMSs, including MySQL, MariaDB, SQLite, PostgreSQL and Clickhouse, uncovering 37 vulnerabilities, 7 of which are tied to under-tested DBMS special features. As of this writing, 29 cases have been confirmed with 9 assigned CVE identifiers, 14 already fixed by vendors, and additional vulnerabilities scheduled to be patched in upcoming releases. Our results highlight the limitations of conventional fuzzers in semantic feature coverage and demonstrate the potential of LLM-based fuzzing to discover deeply hidden bugs in complex database systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u9002\u5e94\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6FuzzySQL\uff0c\u65e8\u5728\u53d1\u73b0\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf(DBMS)\u7279\u6b8a\u529f\u80fd\u4e2d\u7684\u5fae\u5999\u6f0f\u6d1e\u3002\u901a\u8fc7\u7ed3\u5408\u8bed\u6cd5\u5f15\u5bfc\u7684SQL\u751f\u6210\u4e0e\u903b\u8f91\u8f6c\u6362\u6e10\u8fdb\u7a81\u53d8\u6280\u672f\uff0c\u5e76\u91c7\u7528\u6df7\u5408\u9519\u8bef\u4fee\u590d\u7ba1\u9053\uff0cFuzzySQL\u80fd\u591f\u521b\u5efa\u7ed3\u6784\u548c\u8bed\u4e49\u4e0a\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u6848\u4f8b\uff0c\u4ece\u800c\u66f4\u6df1\u5165\u5730\u8986\u76d6DBMS\u540e\u7aef\u6267\u884c\u8def\u5f84\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728MySQL\u3001MariaDB\u7b49\u4e94\u79cdDBMS\u4e0a\u53d1\u73b0\u4e8637\u4e2a\u6f0f\u6d1e\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u53d1\u73b0\u590d\u6742\u6570\u636e\u5e93\u7cfb\u7edf\u6df1\u5c42\u9690\u85cf\u9519\u8bef\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u5e93\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u8bed\u6cd5\u6b63\u786e\u6027\u548c\u901a\u7528SQL\u7ed3\u6784\uff0c\u5bf9\u4e8e\u7cfb\u7edf\u7ea7\u6a21\u5f0f\uff08\u5982GTID\uff09\u3001\u7a0b\u5e8f\u5316\u6784\u9020\uff08\u5982PROCEDURE\uff09\u53ca\u9ad8\u7ea7\u8fdb\u7a0b\u547d\u4ee4\uff08\u5982KILL\uff09\u7b49\u8f83\u4e3a\u9690\u853d\u4f46\u91cd\u8981\u7684DBMS\u7279\u6027\u63a2\u7d22\u4e0d\u8db3\u3002\u8fd9\u4e9b\u7279\u6027\u867d\u7136\u4e0d\u5e38\u88ab\u5178\u578b\u8f93\u5165\u89e6\u53d1\uff0c\u4f46\u5728\u7279\u5b9a\u8fb9\u7f18\u6761\u4ef6\u4e0b\u53ef\u80fd\u5f15\u53d1\u4e25\u91cd\u5d29\u6e83\u6216\u5b89\u5168\u95ee\u9898\u3002", "method": "\u63d0\u51faFuzzySQL\uff0c\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u652f\u6301\u7684\u81ea\u9002\u5e94\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\u3002\u5b83\u7ed3\u5408\u4e86\u8bed\u6cd5\u6307\u5bfc\u7684SQL\u751f\u6210\u4e0e\u4e00\u79cd\u540d\u4e3a\u903b\u8f91\u8f6c\u79fb\u6e10\u8fdb\u53d8\u5f02\u7684\u65b0\u6280\u672f\uff0c\u540e\u8005\u901a\u8fc7\u5426\u5b9a\u6761\u4ef6\u548c\u91cd\u6784\u6267\u884c\u903b\u8f91\u6765\u63a2\u7d22\u66ff\u4ee3\u63a7\u5236\u8def\u5f84\uff0c\u540c\u65f6\u91c7\u7528\u89c4\u5219\u57fa\u7840\u4fee\u8865\u4e0eLLM\u9a71\u52a8\u8bed\u4e49\u4fee\u590d\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u9519\u8bef\u4fee\u590d\u6d41\u7a0b\uff0c\u4ee5\u81ea\u52a8\u4fee\u6b63\u8bed\u6cd5\u548c\u4e0a\u4e0b\u6587\u654f\u611f\u6545\u969c\u3002", "result": "\u5728\u5305\u62ecMySQL\u3001MariaDB\u3001SQLite\u3001PostgreSQL\u548cClickhouse\u5728\u5185\u7684\u591a\u4e2aDBMS\u4e0a\u8bc4\u4f30FuzzySQL\uff0c\u5171\u53d1\u73b037\u4e2a\u6f0f\u6d1e\uff0c\u5176\u4e2d7\u4e2a\u4e0e\u6d4b\u8bd5\u4e0d\u8db3\u7684DBMS\u7279\u6b8a\u529f\u80fd\u76f8\u5173\u3002\u622a\u81f3\u64b0\u5199\u65f6\uff0c\u5df2\u670929\u4e2a\u6848\u4f8b\u5f97\u5230\u786e\u8ba4\uff0c\u5206\u914d\u4e869\u4e2aCVE\u6807\u8bc6\u7b26\uff0c14\u4e2a\u5df2\u88ab\u4f9b\u5e94\u5546\u4fee\u590d\uff0c\u66f4\u591a\u6f0f\u6d1e\u8ba1\u5212\u5728\u672a\u6765\u7248\u672c\u4e2d\u4fee\u590d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4f20\u7edf\u6a21\u7cca\u5668\u5728\u8bed\u4e49\u7279\u5f81\u8986\u76d6\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u57fa\u4e8eLLM\u7684\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u5177\u6709\u53d1\u73b0\u590d\u6742\u6570\u636e\u5e93\u7cfb\u7edf\u4e2d\u6df1\u5c42\u6b21\u9690\u85cf\u9519\u8bef\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2602.18519", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.18519", "abs": "https://arxiv.org/abs/2602.18519", "authors": ["Joris Bekkers"], "title": "Wide Open Gazes: Quantifying Visual Exploratory Behavior in Soccer with Pose Enhanced Positional Data", "comment": null, "summary": "Traditional approaches to measuring visual exploratory behavior in soccer rely on counting visual exploratory actions (VEAs) based on rapid head movements exceeding 125\u00b0/s, but this method suffer from player position bias (i.e., a focus on central midfielders), annotation challenges, binary measurement constraints (i.e., a player is scanning, or not), lack the power to predict relevant short-term in-game future success, and are incompatible with fundamental soccer analytics models such as pitch control. This research introduces a novel formulaic continuous stochastic vision layer to quantify players' visual perception from pose-enhanced spatiotemporal tracking. Our probabilistic field-of-view and occlusion models incorporate head and shoulder rotation angles to create speed-dependent vision maps for individual players in a two-dimensional top-down plane. We combine these vision maps with pitch control and pitch value surfaces to analyze the awaiting phase (when a player is awaiting the ball to arrive after a pass for a teammate) and their subsequent on-ball phase. We demonstrate that aggregated visual metrics - such as the percentage of defended area observed while awaiting a pass - are predictive of controlled pitch value gained at the end of dribbling actions using 32 games of synchronized pose-enhanced tracking data and on-ball event data from the 2024 Copa America. This methodology works regardless of player position, eliminates manual annotation requirements, and provides continuous measurements that seamlessly integrate into existing soccer analytics frameworks. To further support the integration with existing soccer analytics frameworks we open-source the tools required to make these calculations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u516c\u5f0f\u5316\u8fde\u7eed\u968f\u673a\u89c6\u89c9\u5c42\uff0c\u901a\u8fc7\u589e\u5f3a\u7684\u59ff\u6001\u65f6\u7a7a\u8ddf\u8e2a\u6765\u91cf\u5316\u8db3\u7403\u8fd0\u52a8\u5458\u7684\u89c6\u89c9\u611f\u77e5\u3002\u5229\u7528\u5934\u90e8\u548c\u80a9\u90e8\u65cb\u8f6c\u89d2\u5ea6\u521b\u5efa\u901f\u5ea6\u4f9d\u8d56\u7684\u89c6\u91ce\u56fe\uff0c\u5e76\u7ed3\u5408\u7403\u573a\u63a7\u5236\u548c\u4ef7\u503c\u9762\u5206\u6790\u7403\u5458\u7b49\u5f85\u63a5\u7403\u53ca\u968f\u540e\u63a7\u7403\u9636\u6bb5\u7684\u884c\u4e3a\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5982\u7b49\u5f85\u4f20\u7403\u65f6\u89c2\u5bdf\u5230\u7684\u9632\u5b88\u533a\u57df\u767e\u5206\u6bd4\u7b49\u805a\u5408\u89c6\u89c9\u6307\u6807\uff0c\u53ef\u4ee5\u9884\u6d4b2024\u5e74\u7f8e\u6d32\u676f32\u573a\u6bd4\u8d5b\u4e2d\u76d8\u5e26\u7ed3\u675f\u65f6\u83b7\u5f97\u7684\u53d7\u63a7\u7403\u573a\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u7684\u8db3\u7403\u89c6\u89c9\u63a2\u7d22\u884c\u4e3a\u6d4b\u91cf\u65b9\u6cd5\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\u3001\u6ce8\u91ca\u96be\u9898\u3001\u4e8c\u5143\u6d4b\u91cf\u9650\u5236\u7b49\u95ee\u9898\uff0c\u5e76\u4e14\u65e0\u6cd5\u5f88\u597d\u5730\u9884\u6d4b\u6bd4\u8d5b\u4e2d\u7684\u77ed\u671f\u6210\u529f\u6216\u4e0e\u57fa\u672c\u8db3\u7403\u5206\u6790\u6a21\u578b\u517c\u5bb9\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8e\u6982\u7387\u7684\u89c6\u573a\u548c\u906e\u6321\u6a21\u578b\uff0c\u7ed3\u5408\u5934\u90e8\u548c\u80a9\u8180\u65cb\u8f6c\u89d2\u5ea6\uff0c\u5728\u4e8c\u7ef4\u4fef\u89c6\u5e73\u9762\u4e0a\u4e3a\u6bcf\u4e2a\u7403\u5458\u521b\u5efa\u901f\u5ea6\u4f9d\u8d56\u6027\u7684\u89c6\u89c9\u5730\u56fe\u3002\u8fd9\u4e9b\u89c6\u89c9\u5730\u56fe\u518d\u4e0e\u7403\u573a\u63a7\u5236\u53ca\u4ef7\u503c\u8868\u9762\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u5206\u6790\u7403\u5458\u7b49\u5f85\u63a5\u7403\u4ee5\u53ca\u5176\u540e\u6301\u7403\u9636\u6bb5\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u50cf\u7b49\u5f85\u4f20\u7403\u671f\u95f4\u89c2\u5bdf\u5230\u7684\u9632\u5b88\u9762\u79ef\u6bd4\u4f8b\u8fd9\u6837\u7684\u7efc\u5408\u89c6\u89c9\u5ea6\u91cf\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5728\u4e00\u7cfb\u5217\u76d8\u5e26\u52a8\u4f5c\u7ed3\u675f\u540e\u6240\u83b7\u5f97\u7684\u63a7\u5236\u4e0b\u7684\u7403\u573a\u4ef7\u503c\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u6240\u6709\u4f4d\u7f6e\u7684\u7403\u5458\uff0c\u65e0\u9700\u624b\u52a8\u6ce8\u89e3\uff0c\u8fd8\u80fd\u63d0\u4f9b\u4e0e\u73b0\u6709\u8db3\u7403\u5206\u6790\u6846\u67b6\u65e0\u7f1d\u96c6\u6210\u7684\u8fde\u7eed\u6027\u6d4b\u91cf\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u4fc3\u8fdb\u4e0e\u73b0\u6709\u8db3\u7403\u5206\u6790\u6846\u67b6\u7684\u6574\u5408\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u6e90\u4e86\u8fdb\u884c\u6b64\u7c7b\u8ba1\u7b97\u6240\u9700\u7684\u5de5\u5177\u3002"}}
{"id": "2602.19231", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19231", "abs": "https://arxiv.org/abs/2602.19231", "authors": ["Georgii Semenov", "Vitaly Aksenov"], "title": "Semantic Conflict Model for Collaborative Data Structures", "comment": "6 pages, 7 figures, submitted to PaPoC 2026", "summary": "Digital collaboration systems support asynchronous work over replicated data, where conflicts arise when concurrent operations cannot be unambiguously integrated into a shared history. While Conflict-Free Replicated Data Types (CRDTs) ensure convergence through built-in conflict resolution, this resolution is typically implicit and opaque to users, whereas existing reconciliation techniques often rely on centralized coordination. This paper introduces a conflict model for collaborative data structures that enables explicit, local-first conflict resolution without central coordination. The model identifies conflicts using semantic dependencies between operations and resolves them by rebasing conflicting operations onto a reconciling operation via a three-way merge over a replicated journal. We demonstrate our approach on collaborative registers, including an explicit formulation of the Last-Writer-Wins Register and a multi-register entity supporting semi-automatic reconciliation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u51b2\u7a81\u6a21\u578b\uff0c\u7528\u4e8e\u652f\u6301\u663e\u5f0f\u3001\u672c\u5730\u4f18\u5148\u7684\u51b2\u7a81\u89e3\u51b3\u65b9\u5f0f\uff0c\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u64cd\u4f5c\u4e4b\u95f4\u7684\u8bed\u4e49\u4f9d\u8d56\u6765\u8bc6\u522b\u51b2\u7a81\uff0c\u5e76\u901a\u8fc7\u590d\u5236\u65e5\u5fd7\u4e0a\u7684\u4e09\u65b9\u5408\u5e76\u5c06\u51b2\u7a81\u7684\u64cd\u4f5c\u91cd\u65b0\u57fa\u4e8e\u4e00\u4e2a\u8c03\u548c\u64cd\u4f5c\u4e0a\u8fdb\u884c\u89e3\u51b3\u3002", "motivation": "\u73b0\u6709\u7684\u51b2\u7a81\u81ea\u7531\u590d\u5236\u6570\u636e\u7c7b\u578b\uff08CRDTs\uff09\u867d\u7136\u786e\u4fdd\u4e86\u901a\u8fc7\u5185\u7f6e\u51b2\u7a81\u89e3\u51b3\u65b9\u6848\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u8fd9\u79cd\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u662f\u9690\u542b\u4e14\u5bf9\u7528\u6237\u4e0d\u900f\u660e\u7684\uff1b\u800c\u73b0\u6709\u7684\u8c03\u89e3\u6280\u672f\u5f80\u5f80\u4f9d\u8d56\u4e8e\u96c6\u4e2d\u5f0f\u534f\u8c03\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u663e\u5f0f\u4e14\u672c\u5730\u4f18\u5148\u51b2\u7a81\u89e3\u51b3\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u907f\u514d\u4e2d\u5fc3\u5316\u63a7\u5236\u7684\u9700\u6c42\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u534f\u4f5c\u6570\u636e\u7ed3\u6784\u7684\u51b2\u7a81\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5229\u7528\u64cd\u4f5c\u95f4\u5b58\u5728\u7684\u8bed\u4e49\u4f9d\u8d56\u5173\u7cfb\u6765\u68c0\u6d4b\u51b2\u7a81\uff0c\u5e76\u91c7\u7528\u4e09\u65b9\u5408\u5e76\u6280\u672f\u5728\u590d\u5236\u7684\u65e5\u5fd7\u57fa\u7840\u4e0a\u5c06\u76f8\u4e92\u51b2\u7a81\u7684\u64cd\u4f5c\u91cd\u57fa\u5230\u4e00\u4e2a\u53ef\u4ee5\u7528\u6765\u8c03\u89e3\u7684\u64cd\u4f5c\u4e0a\u3002", "result": "\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5982\u4f55\u5e94\u7528\u4e8e\u534f\u4f5c\u5bc4\u5b58\u5668\uff0c\u5305\u62ec\u6700\u540e\u5199\u5165\u8005\u83b7\u80dc\u5bc4\u5b58\u5668\u7684\u4e00\u4e2a\u660e\u786e\u5f62\u5f0f\u5316\u5b9a\u4e49\u4ee5\u53ca\u4e00\u4e2a\u652f\u6301\u534a\u81ea\u52a8\u8c03\u89e3\u7684\u591a\u5bc4\u5b58\u5668\u5b9e\u4f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u51b2\u7a81\u6a21\u578b\u4e3a\u6570\u5b57\u534f\u4f5c\u7cfb\u7edf\u4e2d\u7684\u5f02\u6b65\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u9014\u5f84\uff0c\u5141\u8bb8\u4ee5\u66f4\u900f\u660e\u7684\u65b9\u5f0f\u5904\u7406\u51b2\u7a81\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u53bb\u4e2d\u5fc3\u5316\u7684\u7279\u6027\u3002"}}
{"id": "2602.19711", "categories": ["cs.IR", "cs.DL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.19711", "abs": "https://arxiv.org/abs/2602.19711", "authors": ["Krzysztof Kutt", "El\u017cbieta Sroka", "Oleksandra Ishchuk", "Luiz do Valle Miranda"], "title": "A Three-stage Neuro-symbolic Recommendation Pipeline for Cultural Heritage Knowledge Graphs", "comment": "15 pages, 1 figure; submitted to ICCS 2026 conference", "summary": "The growing volume of digital cultural heritage resources highlights the need for advanced recommendation methods capable of interpreting semantic relationships between heterogeneous data entities. This paper presents a complete methodology for implementing a hybrid recommendation pipeline integrating knowledge-graph embeddings, approximate nearest-neighbour search, and SPARQL-driven semantic filtering. The work is evaluated on the JUHMP (Jagiellonian University Heritage Metadata Portal) knowledge graph developed within the CHExRISH project, which at the time of experimentation contained ${\\approx}3.2$M RDF triples describing people, events, objects, and historical relations affiliated with the Jagiellonian University (Krak\u00f3w, PL). We evaluate four embedding families (TransE, ComplEx, ConvE, CompGCN) and perform hyperparameter selection for ComplEx and HNSW. Then, we present and evaluate the final three-stage neuro-symbolic recommender. Despite sparse and heterogeneous metadata, the approach produces useful and explainable recommendations, which were also proven with expert evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u63a8\u8350\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u3001\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u548cSPARQL\u9a71\u52a8\u7684\u8bed\u4e49\u8fc7\u6ee4\u6280\u672f\u3002\u901a\u8fc7\u5bf9JUHMP\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528TransE\u3001ComplEx\u3001ConvE\u548cCompGCN\u56db\u79cd\u5d4c\u5165\u6a21\u578b\uff0c\u5e76\u5bf9ComplEx\u548cHNSW\u8fdb\u884c\u4e86\u8d85\u53c2\u6570\u9009\u62e9\u3002\u6700\u7ec8\u5b9e\u73b0\u4e86\u4e09\u9636\u6bb5\u795e\u7ecf-\u7b26\u53f7\u63a8\u8350\u5668\uff0c\u5728\u7a00\u758f\u4e14\u5f02\u6784\u7684\u5143\u6570\u636e\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4ea7\u751f\u6709\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u8350\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u6587\u5316\u9057\u4ea7\u8d44\u6e90\u6570\u91cf\u7684\u589e\u957f\uff0c\u9700\u8981\u5f00\u53d1\u5148\u8fdb\u7684\u63a8\u8350\u65b9\u6cd5\u6765\u7406\u89e3\u5f02\u6784\u6570\u636e\u5b9e\u4f53\u4e4b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u5b9e\u73b0\u65b9\u6cd5\u8bba\uff0c\u5305\u62ec\u6784\u5efa\u6df7\u5408\u63a8\u8350\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u6574\u5408\u4e86\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u3001\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u53caSPARQL\u9a71\u52a8\u7684\u8bed\u4e49\u7b5b\u9009\u3002\u5728\u7531CHExRISH\u9879\u76ee\u521b\u5efa\u7684JUHMP\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8bc4\u4f30\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u5d4c\u5165\u6a21\u578b\uff08TransE, ComplEx, ConvE, CompGCN\uff09\uff0c\u5e76\u5bf9ComplEx\u548cHNSW\u6267\u884c\u4e86\u8d85\u53c2\u6570\u8c03\u6574\u3002", "result": "\u5c3d\u7ba1\u9762\u4e34\u7a00\u758f\u4e0e\u5f02\u6784\u7684\u5143\u6570\u636e\u6311\u6218\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4ecd\u80fd\u751f\u6210\u6709\u4ef7\u503c\u4e14\u6613\u4e8e\u7406\u89e3\u7684\u63a8\u8350\u5efa\u8bae\u3002\u8fd9\u4e9b\u63a8\u8350\u7684\u6709\u6548\u6027\u4e5f\u5f97\u5230\u4e86\u4e13\u5bb6\u8bc4\u5ba1\u7684\u652f\u6301\u3002", "conclusion": "\u901a\u8fc7\u5c06\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u3001\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u4ee5\u53ca\u57fa\u4e8eSPARQL\u7684\u8bed\u4e49\u8fc7\u6ee4\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u5373\u4f7f\u662f\u5728\u9762\u5bf9\u7a00\u758f\u548c\u591a\u6837\u5316\u7684\u5143\u6570\u636e\u65f6\uff0c\u4e5f\u80fd\u6210\u529f\u5730\u4e3a\u6570\u5b57\u6587\u5316\u9057\u4ea7\u63d0\u4f9b\u6709\u6548\u800c\u900f\u660e\u7684\u63a8\u8350\u670d\u52a1\u3002"}}
{"id": "2602.19786", "categories": ["cs.DB", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19786", "abs": "https://arxiv.org/abs/2602.19786", "authors": ["Miguel Ceriani", "Fiorela Ciroku", "Alessandro Russo", "Massimiliano Schembri", "Fai Fung", "Neha Mittal", "Vito Trianni", "Andrea Giovanni Nuzzolese"], "title": "The Climate Change Knowledge Graph: Supporting Climate Services", "comment": null, "summary": "Climate change impacts a broad spectrum of human resources and activities, necessitating the use of climate models to project long-term effects and inform mitigation and adaptation strategies. These models generate multiple datasets by running simulations across various scenarios and configurations, thereby covering a range of potential future outcomes. Currently, researchers rely on traditional search interfaces and APIs to retrieve such datasets, often piecing together information from metadata and community vocabularies. The Climate Change Knowledge Graph is designed to address these challenges by integrating diverse data sources related to climate simulations into a coherent and interoperable knowledge graph. This innovative resource allows for executing complex queries involving climate models, simulations, variables, spatio-temporal domains, and granularities. Developed with input from domain experts, the knowledge graph and its underlying ontology are published with open access license and provide a comprehensive framework that enhances the exploration of climate data, facilitating more informed decision-making in addressing climate change issues.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u6c14\u5019\u53d8\u5316\u77e5\u8bc6\u56fe\u8c31\uff0c\u5b83\u901a\u8fc7\u6574\u5408\u4e0e\u6c14\u5019\u6a21\u62df\u76f8\u5173\u7684\u591a\u6837\u5316\u6570\u636e\u6e90\uff0c\u5f62\u6210\u4e00\u4e2a\u8fde\u8d2f\u4e14\u53ef\u4e92\u64cd\u4f5c\u7684\u77e5\u8bc6\u56fe\uff0c\u4ee5\u652f\u6301\u590d\u6742\u67e5\u8be2\u548c\u66f4\u660e\u667a\u7684\u51b3\u7b56\u3002", "motivation": "\u9762\u5bf9\u6c14\u5019\u53d8\u5316\u5bf9\u4eba\u7c7b\u8d44\u6e90\u548c\u6d3b\u52a8\u7684\u5e7f\u6cdb\u5f71\u54cd\uff0c\u5f53\u524d\u4f9d\u8d56\u4f20\u7edf\u641c\u7d22\u63a5\u53e3\u548cAPI\u6765\u68c0\u7d22\u6c14\u5019\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u96c6\u5b58\u5728\u5c40\u9650\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63a2\u7d22\u6c14\u5019\u6570\u636e\uff0c\u4ece\u800c\u652f\u6301\u66f4\u660e\u667a\u7684\u51b3\u7b56\u5236\u5b9a\u8fc7\u7a0b\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u6c14\u5019\u53d8\u5316\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u6c14\u5019\u53d8\u5316\u77e5\u8bc6\u56fe\u8c31\u901a\u8fc7\u5c06\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u6c14\u5019\u6a21\u62df\u76f8\u5173\u6570\u636e\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u77e5\u8bc6\u6846\u67b6\u4e2d\uff0c\u5229\u7528\u9886\u57df\u4e13\u5bb6\u7684\u610f\u89c1\u6784\u5efa\u4e86\u4e00\u4e2a\u5f00\u653e\u8bbf\u95ee\u7684\u77e5\u8bc6\u56fe\u8c31\u53ca\u5176\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u65e8\u5728\u589e\u5f3a\u5bf9\u6c14\u5019\u6570\u636e\u7684\u63a2\u7d22\u80fd\u529b\u3002", "result": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u80fd\u591f\u6267\u884c\u6d89\u53ca\u6c14\u5019\u6a21\u578b\u3001\u6a21\u62df\u3001\u53d8\u91cf\u3001\u65f6\u7a7a\u57df\u4ee5\u53ca\u7c92\u5ea6\u7b49\u591a\u65b9\u9762\u7684\u590d\u6742\u67e5\u8be2\uff0c\u4e3a\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u52a0\u5168\u9762\u7684\u4fe1\u606f\u652f\u6301\u3002", "conclusion": "\u6c14\u5019\u53d8\u5316\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u8d44\u6e90\uff0c\u901a\u8fc7\u4fc3\u8fdb\u6c14\u5019\u6570\u636e\u7684\u66f4\u597d\u7406\u89e3\u4e0e\u5229\u7528\uff0c\u5728\u89e3\u51b3\u6c14\u5019\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\u65b9\u9762\u626e\u6f14\u7740\u91cd\u8981\u89d2\u8272\u3002"}}
{"id": "2602.18689", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18689", "abs": "https://arxiv.org/abs/2602.18689", "authors": ["Harrison Green", "Fraser Brown", "Claire Le Goues"], "title": "Automatic, Expressive, and Scalable Fuzzing with Stitching", "comment": null, "summary": "Fuzzing is a powerful technique for finding bugs in software libraries, but scaling it remains difficult. Automated harness generation commits to fixed API sequences at synthesis time, limiting the behaviors each harness can test. Approaches that instead explore new sequences dynamically lack the expressiveness to model real-world usage constraints leading to false positives from straightforward API misuse.\n  We propose stitching, a technique that encodes API usage constraints in pieces that a fuzzer dynamically assembles at runtime. A static type system governs how objects flow between blocks, while a dynamically-checked extrinsic typestate tracks arbitrary metadata across blocks, enabling specifications to express rich semantic constraints such as object state dependencies and cross-function preconditions. This allows a single specification to describe an open-ended space of valid API interactions that the fuzzer explores guided by coverage feedback.\n  We implement stitching in STITCH, using LLMs to automatically configure projects for fuzzing, synthesize a specification, triage crashes, and repair the specification itself. We evaluated STITCH against four state-of-the-art tools on 33 benchmarks, where it achieved the highest code coverage on 21 and found 30 true-positive bugs compared to 10 by all other tools combined, with substantially higher precision (70% vs. 12% for the next-best LLM-based tool). Deployed automatically on 1365 widely used open-source projects, STITCH discovered 131 new bugs across 102 projects, 73 of which have already been patched.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3astitching\u7684\u6280\u672f\uff0c\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u7ec4\u88c5API\u4f7f\u7528\u7ea6\u675f\u7684\u7247\u6bb5\u6765\u63d0\u9ad8fuzzing\u6280\u672f\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002STITCH\u5de5\u5177\u5b9e\u73b0\u4e86\u8fd9\u79cd\u6280\u672f\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6548\u679c\uff0c\u81ea\u52a8\u90e8\u7f72\u540e\u5df2\u5728\u5f00\u6e90\u9879\u76ee\u4e2d\u53d1\u73b0\u4e86\u8bb8\u591a\u65b0\u7684bug\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316harness\u751f\u6210\u65b9\u6cd5\u5728\u5408\u6210\u65f6\u5c31\u56fa\u5b9a\u4e86API\u5e8f\u5217\uff0c\u9650\u5236\u4e86\u6bcf\u4e2aharness\u53ef\u4ee5\u6d4b\u8bd5\u7684\u884c\u4e3a\u8303\u56f4\uff1b\u800c\u80fd\u591f\u52a8\u6001\u63a2\u7d22\u65b0\u5e8f\u5217\u7684\u65b9\u6cd5\u53c8\u7f3a\u4e4f\u8868\u8fbe\u73b0\u5b9e\u4e16\u754c\u4f7f\u7528\u7ea6\u675f\u7684\u80fd\u529b\uff0c\u5bfc\u81f4\u56e0\u7b80\u5355API\u8bef\u7528\u800c\u4ea7\u751f\u5927\u91cf\u5047\u9633\u6027\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u53eb\u505astitching\u7684\u6280\u672f\uff0c\u8be5\u6280\u672f\u5141\u8bb8\u5c06API\u4f7f\u7528\u7ea6\u675f\u7f16\u7801\u6210\u591a\u4e2a\u7247\u6bb5\uff0c\u7136\u540e\u7531fuzzer\u6839\u636e\u8986\u76d6\u7387\u53cd\u9988\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u7ec4\u88c5\u8fd9\u4e9b\u7247\u6bb5\u3002\u540c\u65f6\uff0c\u5229\u7528\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u63a7\u5236\u5bf9\u8c61\u5982\u4f55\u5728\u4e0d\u540c\u5757\u4e4b\u95f4\u6d41\u52a8\uff0c\u4ee5\u53ca\u4e00\u4e2a\u52a8\u6001\u68c0\u67e5\u7684\u5916\u5728\u7c7b\u578b\u72b6\u6001\u6765\u8ffd\u8e2a\u4efb\u610f\u5143\u6570\u636e\uff0c\u4ece\u800c\u652f\u6301\u63cf\u8ff0\u4e30\u5bcc\u7684\u8bed\u4e49\u7ea6\u675f\u5982\u5bf9\u8c61\u72b6\u6001\u4f9d\u8d56\u548c\u8de8\u51fd\u6570\u524d\u7f6e\u6761\u4ef6\u3002", "result": "\u4e0e\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u5de5\u5177\u5bf9\u6bd4\uff0c\u572833\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSTITCH\u572821\u4e2a\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u5e76\u4e14\u53d1\u73b0\u4e8630\u4e2a\u771f\u6b63\u5b58\u5728\u7684bug\uff0c\u76f8\u6bd4\u4e4b\u4e0b\u5176\u4ed6\u6240\u6709\u5de5\u5177\u52a0\u8d77\u6765\u4ec5\u627e\u523010\u4e2a\u3002\u6b64\u5916\uff0cSTITCH\u8fd8\u88ab\u81ea\u52a8\u90e8\u7f72\u5230\u4e861365\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f00\u6e90\u9879\u76ee\u4e0a\uff0c\u6210\u529f\u5730\u5728102\u4e2a\u9879\u76ee\u4e2d\u53d1\u73b0\u4e86131\u4e2a\u65b0\u7684bug\uff0c\u5176\u4e2d73\u4e2a\u5df2\u7ecf\u88ab\u4fee\u590d\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165stitching\u6280\u672f\uff0cSTITCH\u5de5\u5177\u4e0d\u4ec5\u63d0\u9ad8\u4e86fuzzing\u8fc7\u7a0b\u4e2d\u53d1\u73b0\u771f\u5b9ebug\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4e5f\u51cf\u5c11\u4e86\u7531\u4e8eAPI\u8bef\u7528\u9020\u6210\u7684\u5047\u9633\u6027\u95ee\u9898\u3002\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.18521", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18521", "abs": "https://arxiv.org/abs/2602.18521", "authors": ["Xueyi Wang", "Claudine J. C. Lamoth", "Elisabeth Wilhelm"], "title": "AdaptStress: Online Adaptive Learning for Interpretable and Personalized Stress Prediction Using Multivariate and Sparse Physiological Signals", "comment": null, "summary": "Continuous stress forecasting could potentially contribute to lifestyle interventions. This paper presents a novel, explainable, and individualized approach for stress prediction using physiological data from consumer-grade smartwatches. We develop a time series forecasting model that leverages multivariate features, including heart rate variability, activity patterns, and sleep metrics, to predict stress levels across 16 temporal horizons (History window: 3, 5, 7, 9 days; forecasting window: 1, 3, 5, 7 days). Our evaluation involves 16 participants monitored for 10-15 weeks. We evaluate our approach across 16 participants, comparing against state-of-the-art time series models (Informer, TimesNet, PatchTST) and traditional baselines (CNN, LSTM, CNN-LSTM) across multiple temporal horizons. Our model achieved performance with an MSE of 0.053, MAE of 0.190, and RMSE of 0.226 in optimal settings (5-day input, 1-day prediction). A comparison with the baseline models shows that our model outperforms TimesNet, PatchTST, CNN-LSTM, LSTM, and CNN under all conditions, representing improvements of 36.9%, 25.5%, and 21.5% over the best baseline. According to the explanability analysis, sleep metrics are the most dominant and consistent stress predictors (importance: 1.1, consistency: 0.9-1.0), while activity features exhibit high inter-participant variability (0.1-0.2). Most notably, the model captures individual-specific patterns where identical features can have opposing effects across users, validating its personalization capabilities. These findings establish that consumer wearables, combined with adaptive and interpretable deep learning, can deliver relevant stress assessment adapted to individual physiological responses, providing a foundation for scalable, continuous, explainable mental health monitoring in real-world settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u53ef\u89e3\u91ca\u7684\u3001\u4e2a\u6027\u5316\u7684\u538b\u529b\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u6d88\u8d39\u7ea7\u667a\u80fd\u624b\u8868\u7684\u751f\u7406\u6570\u636e\uff08\u5982\u5fc3\u7387\u53d8\u5f02\u6027\u3001\u6d3b\u52a8\u6a21\u5f0f\u548c\u7761\u7720\u6307\u6807\uff09\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002\u901a\u8fc7\u4e0e\u6700\u5148\u8fdb\u7684\u6a21\u578b\u53ca\u4f20\u7edf\u57fa\u7ebf\u6bd4\u8f83\uff0c\u5728\u6700\u4f18\u6761\u4ef6\u4e0b\uff085\u5929\u8f93\u5165\uff0c1\u5929\u9884\u6d4b\uff09\uff0c\u672c\u6a21\u578b\u8868\u73b0\u51fa\u4e86\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4e2a\u4eba\u5316\u6a21\u5f0f\u6355\u6349\u65b9\u9762\u3002", "motivation": "\u8fde\u7eed\u7684\u538b\u529b\u9884\u6d4b\u53ef\u80fd\u6709\u52a9\u4e8e\u751f\u6d3b\u65b9\u5f0f\u5e72\u9884\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u5229\u7528\u6d88\u8d39\u7ea7\u667a\u80fd\u624b\u8868\u6536\u96c6\u7684\u751f\u7406\u6570\u636e\u6765\u8fdb\u884c\u4e2a\u6027\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u538b\u529b\u6c34\u5e73\u9884\u6d4b\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u5229\u7528\u591a\u53d8\u91cf\u7279\u5f81\uff08\u5305\u62ec\u5fc3\u7387\u53d8\u5f02\u6027\u3001\u6d3b\u52a8\u6a21\u5f0f\u548c\u7761\u7720\u6307\u6807\uff09\u6765\u9884\u6d4b\u8de8\u8d8a16\u4e2a\u65f6\u95f4\u8303\u56f4\u7684\u538b\u529b\u6c34\u5e73\u3002\u5bf916\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u4e86\u4e3a\u671f10-15\u5468\u7684\u76d1\u6d4b\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u4e0e\u6700\u5148\u8fdb\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff08Informer, TimesNet, PatchTST\uff09\u4ee5\u53ca\u4f20\u7edf\u57fa\u7ebf\uff08CNN, LSTM, CNN-LSTM\uff09\u8fdb\u884c\u4e86\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u5728\u6700\u4f73\u8bbe\u7f6e\u4e0b\uff085\u5929\u8f93\u5165\uff0c1\u5929\u9884\u6d4b\uff09\uff0c\u8be5\u6a21\u578b\u8fbe\u5230\u4e86MSE\u4e3a0.053\uff0cMAE\u4e3a0.190\uff0cRMSE\u4e3a0.226\u7684\u8868\u73b0\u3002\u76f8\u6bd4\u4e8e\u6700\u597d\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5206\u522b\u63d0\u9ad8\u4e8636.9%\u300125.5%\u548c21.5%\u3002\u89e3\u91ca\u6027\u5206\u6790\u663e\u793a\uff0c\u7761\u7720\u6307\u6807\u662f\u6700\u4e3b\u8981\u4e14\u4e00\u81f4\u7684\u538b\u529b\u9884\u6d4b\u56e0\u7d20\uff0c\u800c\u6d3b\u52a8\u7279\u5f81\u663e\u793a\u51fa\u9ad8\u4e2a\u4f53\u95f4\u5dee\u5f02\u3002", "conclusion": "\u7ed3\u5408\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u6d88\u8d39\u7ea7\u7a7f\u6234\u8bbe\u5907\u53ef\u4ee5\u63d0\u4f9b\u6839\u636e\u4e2a\u4f53\u751f\u7406\u53cd\u5e94\u8c03\u6574\u7684\u76f8\u5173\u538b\u529b\u8bc4\u4f30\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5927\u89c4\u6a21\u3001\u6301\u7eed\u3001\u53ef\u89e3\u91ca\u7684\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.19338", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19338", "abs": "https://arxiv.org/abs/2602.19338", "authors": ["Halit Uyan\u0131k", "Tolga Ovatman"], "title": "Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement", "comment": null, "summary": "The increasing variety of input data and complexity of tasks that are handled by the devices of internet of things (IoT) environments require solutions that consider the limited hardware and computation power of the edge devices. Complex event processing (CEP), can be given as an example, which involves reading and aggregating data from multiple sources to infer triggering of important events. In this study, we balance the execution costs between different paths of the CEP task graph with a constrained programming optimization approach and improve critical path performance. The proposed approach is implemented as a Python library, allowing small-scale IoT devices to adaptively optimize code and I/O assignments and improve overall latency and throughput. The implemented library abstracts away the communication details and allows virtualization of a shared memory between IoT devices. The results show that optimizing critical path performance increases throughput and reduces delay across multiple devices during CEP operations.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ea6\u675f\u7f16\u7a0b\u4f18\u5316\u65b9\u6cd5\u5e73\u8861\u590d\u6742\u4e8b\u4ef6\u5904\u7406(CEP)\u4efb\u52a1\u56fe\u4e2d\u4e0d\u540c\u8def\u5f84\u4e4b\u95f4\u7684\u6267\u884c\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u4e00\u4e2aPython\u5e93\u4ee5\u5e2e\u52a9\u5c0f\u578bIoT\u8bbe\u5907\u81ea\u9002\u5e94\u5730\u4f18\u5316\u4ee3\u7801\u548cI/O\u5206\u914d\uff0c\u4ece\u800c\u63d0\u9ad8\u6574\u4f53\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51(IoT)\u73af\u5883\u4e2d\u8f93\u5165\u6570\u636e\u7684\u591a\u6837\u6027\u548c\u4efb\u52a1\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u9700\u8981\u8003\u8651\u5230\u8fb9\u7f18\u8bbe\u5907\u786c\u4ef6\u53ca\u8ba1\u7b97\u80fd\u529b\u6709\u9650\u7684\u89e3\u51b3\u65b9\u6848\u3002\u590d\u6742\u4e8b\u4ef6\u5904\u7406(CEP)\uff0c\u4f5c\u4e3a\u4e00\u79cd\u5178\u578b\u5e94\u7528\u573a\u666f\uff0c\u6d89\u53ca\u4ece\u591a\u4e2a\u6e90\u8bfb\u53d6\u548c\u805a\u5408\u6570\u636e\u4ee5\u63a8\u65ad\u91cd\u8981\u4e8b\u4ef6\u7684\u53d1\u751f\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u7ea6\u675f\u7f16\u7a0b\u4f18\u5316\u65b9\u6cd5\u6765\u5e73\u8861CEP\u4efb\u52a1\u56fe\u4e2d\u4e0d\u540c\u8def\u5f84\u95f4\u7684\u6267\u884c\u6210\u672c\uff0c\u5e76\u7279\u522b\u5173\u6ce8\u4e8e\u6539\u5584\u5173\u952e\u8def\u5f84\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u88ab\u5c01\u88c5\u6210\u4e00\u4e2aPython\u5e93\uff0c\u5141\u8bb8\u5c0f\u89c4\u6a21IoT\u8bbe\u5907\u52a8\u6001\u8c03\u6574\u4ee3\u7801\u6267\u884c\u4e0e\u8f93\u5165\u8f93\u51fa\u914d\u7f6e\uff0c\u5e76\u901a\u8fc7\u62bd\u8c61\u901a\u4fe1\u7ec6\u8282\u5b9e\u73b0\u8bbe\u5907\u95f4\u5171\u4eab\u5185\u5b58\u7684\u865a\u62df\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u5173\u952e\u8def\u5f84\u6027\u80fd\u8fdb\u884c\u4f18\u5316\uff0c\u53ef\u4ee5\u5728\u591a\u8bbe\u5907\u95f4\u6267\u884cCEP\u64cd\u4f5c\u65f6\u663e\u8457\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u51cf\u5c11\u5ef6\u8fdf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86IoT\u73af\u5883\u4e0b\u590d\u6742\u4e8b\u4ef6\u5904\u7406\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u6311\u6218\uff0c\u4e3a\u63d0\u9ad8IoT\u7cfb\u7edf\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.19728", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.19728", "abs": "https://arxiv.org/abs/2602.19728", "authors": ["Adamya Shyam", "Venkateswara Rao Kagita", "Bharti Rana", "Vikas Kumar"], "title": "GrIT: Group Informed Transformer for Sequential Recommendation", "comment": null, "summary": "Sequential recommender systems aim to predict a user's future interests by extracting temporal patterns from their behavioral history. Existing approaches typically employ transformer-based architectures to process long sequences of user interactions, capturing preference shifts by modeling temporal relationships between items. However, these methods often overlook the influence of group-level features that capture the collective behavior of similar users. We hypothesize that explicitly modeling temporally evolving group features alongside individual user histories can significantly enhance next-item recommendation. Our approach introduces latent group representations, where each user's affiliation to these groups is modeled through learnable, time-varying membership weights. The membership weights at each timestep are computed by modeling shifts in user preferences through their interaction history, where we incorporate both short-term and long-term user preferences. We extract a set of statistical features that capture the dynamics of user behavior and further refine them through a series of transformations to produce the final drift-aware membership weights. A group-based representation is derived by weighting latent group embeddings with the learned membership scores. This representation is integrated with the user's sequential representation within the transformer block to jointly capture personal and group-level temporal dynamics, producing richer embeddings that lead to more accurate, context-aware recommendations. We validate the effectiveness of our approach through extensive experiments on five benchmark datasets, where it consistently outperforms state-of-the-art sequential recommendation methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6f5c\u5728\u7684\u7fa4\u7ec4\u8868\u793a\u6765\u6355\u6349\u7528\u6237\u968f\u65f6\u95f4\u53d8\u5316\u7684\u7fa4\u4f53\u7279\u5f81\u548c\u4e2a\u4eba\u5386\u53f2\uff0c\u4ee5\u63d0\u9ad8\u4e0b\u4e00\u9879\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5bf9\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u65b0\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u5ffd\u7565\u4e86\u7fa4\u4f53\u5c42\u9762\u7279\u5f81\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u7279\u5f81\u53ef\u4ee5\u6355\u6349\u76f8\u4f3c\u7528\u6237\u4e4b\u95f4\u7684\u96c6\u4f53\u884c\u4e3a\u3002\u7814\u7a76\u8005\u5047\u8bbe\uff0c\u660e\u786e\u5730\u5efa\u6a21\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u7fa4\u4f53\u7279\u5f81\u4e0e\u4e2a\u4eba\u7528\u6237\u5386\u53f2\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u663e\u8457\u589e\u5f3a\u4e0b\u4e00\u9879\u63a8\u8350\u7684\u6548\u679c\u3002", "method": "\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u6f5c\u5728\u7684\u7fa4\u7ec4\u8868\u793a\uff0c\u6bcf\u4e2a\u7528\u6237\u7684\u7fa4\u4f53\u5f52\u5c5e\u662f\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u5316\u6210\u5458\u6743\u91cd\u6765\u5efa\u6a21\u7684\u3002\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u9aa4\u8ba1\u7b97\u7684\u6210\u5458\u6743\u91cd\u901a\u8fc7\u5efa\u6a21\u7528\u6237\u504f\u597d\u53d8\u5316\u800c\u5f97\u51fa\uff0c\u540c\u65f6\u8003\u8651\u4e86\u77ed\u671f\u548c\u957f\u671f\u7528\u6237\u504f\u597d\u3002\u4ece\u7528\u6237\u884c\u4e3a\u4e2d\u63d0\u53d6\u4e00\u7ec4\u7edf\u8ba1\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u4e00\u7cfb\u5217\u8f6c\u6362\u8fdb\u4e00\u6b65\u7ec6\u5316\uff0c\u4ea7\u751f\u6700\u7ec8\u7684\u6f02\u79fb\u611f\u77e5\u6210\u5458\u6743\u91cd\u3002\u901a\u8fc7\u5c06\u5b66\u5230\u7684\u6210\u5458\u5206\u6570\u52a0\u6743\u6f5c\u7fa4\u5d4c\u5165\uff0c\u5f97\u5230\u4e00\u4e2a\u57fa\u4e8e\u7fa4\u7ec4\u7684\u8868\u793a\u3002\u8fd9\u4e2a\u8868\u793a\u4e0e\u7528\u6237\u5728Transformer\u5757\u5185\u7684\u5e8f\u5217\u8868\u793a\u76f8\u7ed3\u5408\uff0c\u5171\u540c\u6355\u6349\u4e2a\u4eba\u548c\u7fa4\u4f53\u5c42\u9762\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u4ece\u800c\u751f\u6210\u66f4\u4e30\u5bcc\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u66f4\u5f3a\u7684\u5d4c\u5165\u3002", "result": "\u901a\u8fc7\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u7528\u6237\u4e2a\u4f53\u5386\u53f2\u548c\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u7fa4\u4f53\u7279\u5f81\u7684\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u6539\u5584\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2602.19811", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2602.19811", "abs": "https://arxiv.org/abs/2602.19811", "authors": ["Laurent Bindschaedler"], "title": "Semantic Caching for OLAP via LLM-Based Query Canonicalization (Extended Version)", "comment": "12 pages, 2 figures, 5 tables. Extended version of the short paper published at DOLAP 2026 (co-located with EDBT/ICDT 2026)", "summary": "Analytical workloads exhibit substantial semantic repetition, yet most production caches key entries by SQL surface form (text or AST), fragmenting reuse across BI tools, notebooks, and NL interfaces. We introduce a safety-first middleware cache for dashboard-style OLAP over star schemas that canonicalizes both SQL and NL into a unified key space -- the OLAP Intent Signature -- capturing measures, grouping levels, filters, and time windows. Reuse requires exact intent matches under strict schema validation and confidence-gated NL acceptance; two correctness-preserving derivations (roll-up, filter-down) extend coverage without approximate matching. Across TPC-DS, SSB, and NYC TLC (1,395 queries), we achieve 82% hit rate versus 28% (text) and 56% (AST) with zero false hits; derivations double hit rate on hierarchical queries.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u661f\u578b\u6a21\u5f0fOLAP\u7684\u4e2d\u95f4\u4ef6\u7f13\u5b58\uff0c\u901a\u8fc7\u5c06SQL\u548c\u81ea\u7136\u8bed\u8a00(NL)\u67e5\u8be2\u7edf\u4e00\u8f6c\u6362\u4e3a\u4e00\u79cd\u79f0\u4e3aOLAP\u610f\u56fe\u7b7e\u540d\u7684\u5f62\u5f0f\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u590d\u7528\u7387\u3002\u5728\u4e25\u683c\u7684\u6a21\u5f0f\u9a8c\u8bc1\u4e0b\uff0c\u53ea\u6709\u5b8c\u5168\u5339\u914d\u7684\u610f\u56fe\u624d\u80fd\u88ab\u91cd\u7528\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u4e24\u79cd\u4fdd\u6301\u6b63\u786e\u6027\u7684\u6d3e\u751f\u65b9\u6cd5\uff08\u6c47\u603b\u3001\u8fc7\u6ee4\uff09\u6765\u6269\u5c55\u8986\u76d6\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6bd4\u57fa\u4e8e\u6587\u672c\u6216\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u7684\u7f13\u5b58\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u547d\u4e2d\u7387\uff0c\u540c\u65f6\u907f\u514d\u4e86\u9519\u8bef\u547d\u4e2d\u3002", "motivation": "\u5206\u6790\u5de5\u4f5c\u8d1f\u8f7d\u8868\u73b0\u51fa\u663e\u8457\u7684\u8bed\u4e49\u91cd\u590d\u6027\uff0c\u4f46\u5927\u591a\u6570\u751f\u4ea7\u7f13\u5b58\u7cfb\u7edf\u6839\u636eSQL\u8868\u9762\u5f62\u5f0f\uff08\u6587\u672c\u6216AST\uff09\u8fdb\u884c\u952e\u5165\uff0c\u8fd9\u5bfc\u81f4\u8de8BI\u5de5\u5177\u3001\u7b14\u8bb0\u672c\u548c\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u590d\u7528\u788e\u7247\u5316\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f13\u5b58\u673a\u5236\uff0c\u65e8\u5728\u63d0\u5347\u67e5\u8be2\u590d\u7528\u6548\u7387\u7684\u540c\u65f6\u4fdd\u8bc1\u7ed3\u679c\u7684\u51c6\u786e\u6027\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b89\u5168\u4f18\u5148\u7684\u4e2d\u95f4\u4ef6\u7f13\u5b58\u65b9\u6848\uff0c\u4e13\u4e3a\u661f\u578b\u6a21\u5f0f\u4e0a\u7684OLAP\u8bbe\u8ba1\u3002\u8be5\u65b9\u6848\u5c06SQL\u53ca\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6807\u51c6\u5316\u81f3\u7edf\u4e00\u7684\u952e\u7a7a\u95f4\u2014\u2014\u5373\u6240\u8c13\u7684\u201cOLAP\u610f\u56fe\u7b7e\u540d\u201d\uff0c\u5b83\u6355\u6349\u5ea6\u91cf\u3001\u5206\u7ec4\u7ea7\u522b\u3001\u8fc7\u6ee4\u5668\u4ee5\u53ca\u65f6\u95f4\u7a97\u53e3\u7b49\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cd\u4fdd\u6301\u6b63\u786e\u6027\u7684\u884d\u751f\u6280\u672f\uff08\u5411\u4e0a\u6c47\u603b\u3001\u5411\u4e0b\u8fc7\u6ee4\uff09\uff0c\u4ee5\u8fdb\u4e00\u6b65\u6269\u5927\u8986\u76d6\u8303\u56f4\u800c\u4e0d\u4f9d\u8d56\u8fd1\u4f3c\u5339\u914d\u3002", "result": "\u901a\u8fc7\u5bf9TPC-DS, SSB, \u548c NYC TLC\u4e09\u4e2a\u6570\u636e\u96c6\u51711,395\u4e2a\u67e5\u8be2\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e8682%\u7684\u547d\u4e2d\u7387\uff0c\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u57fa\u4e8e\u6587\u672c\u7684\u7f13\u5b58\u65b9\u6cd5\u4ec5\u4e3a28%\uff0c\u800c\u57fa\u4e8eAST\u7684\u65b9\u6cd5\u5219\u4e3a56%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u6ca1\u6709\u51fa\u73b0\u4efb\u4f55\u9519\u8bef\u547d\u4e2d\u60c5\u51b5\u3002\u5bf9\u4e8e\u5c42\u6b21\u7ed3\u6784\u67e5\u8be2\uff0c\u5229\u7528\u63d0\u51fa\u7684\u884d\u751f\u6280\u672f\u80fd\u591f\u4f7f\u547d\u4e2d\u7387\u7ffb\u500d\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u5f15\u5165\u7edf\u4e00\u7684OLAP\u610f\u56fe\u7b7e\u540d\u4f5c\u4e3a\u7f13\u5b58\u952e\u503c\uff0c\u53ef\u4ee5\u5927\u5e45\u5ea6\u63d0\u9ad8\u5206\u6790\u67e5\u8be2\u7684\u7f13\u5b58\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002\u5373\u4f7f\u662f\u5728\u975e\u5e38\u4e25\u683c\u7684\u6761\u4ef6\u4e0b\u4e5f\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u5e76\u91cd\u7528\u76f8\u540c\u610f\u56fe\u7684\u4e0d\u540c\u8868\u8fbe\u5f62\u5f0f\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2602.18768", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18768", "abs": "https://arxiv.org/abs/2602.18768", "authors": ["Jakub Zelek", "Jakub Ruszil", "Adam Roman", "Artur Pola\u0144ski"], "title": "Efficient Dynamic Test Case Generation for Path-Based Coverage Criteria", "comment": null, "summary": "We present a novel approach to test-case generation that satisfies four white-box, path-based coverage criteria: Prime Path, Simple Cycle, Simple Path, and Edge-Acyclic Path. Our method builds on a modified version of Johnson algorithm and enables test cases to be generated incrementally and on demand, rather than requiring the entire test suite to be computed upfront. This streaming capability represents a substantial advancement over existing approaches, as it allows testers to begin executing and refining tests immediately, thereby significantly improving the efficiency of test design. Our solution is inherently memory efficient, as it does not store all discovered coverage items; instead, it retains only the minimal set of paths required to generate subsequent coverage items on the fly. As a result, the approach scales to arbitrarily large graphs. In addition, the algorithm gives testers explicit control over the size of the generated test suite by allowing them to restrict the number of cycles permitted in a test path. The approach is grounded in new theoretical insights, most notably a novel characterization of prime paths in terms of the strongly connected components of control-flow graphs. We complement these theoretical contributions with a practical implementation and a comprehensive empirical evaluation. The results demonstrate that our method not only outperforms existing techniques in terms of execution time and memory consumption, but also provides testers with a more flexible and efficient tool for achieving high coverage while substantially reducing test design overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u6ee1\u8db3\u56db\u79cd\u57fa\u4e8e\u8def\u5f84\u7684\u767d\u76d2\u8986\u76d6\u6807\u51c6\uff0c\u5e76\u4e14\u53ef\u4ee5\u6309\u9700\u589e\u91cf\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u800c\u4e0d\u9700\u8981\u9884\u5148\u8ba1\u7b97\u6574\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u6267\u884c\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u8fd8\u4e3a\u6d4b\u8bd5\u4eba\u5458\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u5de5\u5177\u6765\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u5e76\u663e\u8457\u51cf\u5c11\u6d4b\u8bd5\u8bbe\u8ba1\u5f00\u9500\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u591f\u6ee1\u8db3\u7279\u5b9a\u7684\u8def\u5f84\u8986\u76d6\u6807\u51c6\uff08Prime Path, Simple Cycle, Simple Path, Edge-Acyclic Path\uff09\uff0c\u540c\u65f6\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\u8981\u6c42\u4e00\u6b21\u6027\u751f\u6210\u5168\u90e8\u6d4b\u8bd5\u6848\u4f8b\u7684\u4e0d\u8db3\uff0c\u4ee5\u63d0\u9ad8\u6d4b\u8bd5\u8bbe\u8ba1\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "method": "\u8be5\u7814\u7a76\u57fa\u4e8eJohnson\u7b97\u6cd5\u7684\u4e00\u4e2a\u4fee\u6539\u7248\u672c\uff0c\u5141\u8bb8\u6d4b\u8bd5\u7528\u4f8b\u6839\u636e\u9700\u8981\u9010\u6b65\u751f\u6210\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u4ec5\u4fdd\u7559\u751f\u6210\u540e\u7eed\u8986\u76d6\u9879\u6240\u9700\u7684\u6700\u5c0f\u8def\u5f84\u96c6\u6765\u8282\u7701\u5185\u5b58\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u5927\u7684\u56fe\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5141\u8bb8\u6d4b\u8bd5\u8005\u63a7\u5236\u751f\u6210\u6d4b\u8bd5\u5957\u4ef6\u7684\u5927\u5c0f\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6267\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u4ee5\u53ca\u63d0\u4f9b\u7ed9\u6d4b\u8bd5\u8005\u7684\u7075\u6d3b\u6027\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e0a\u90fd\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u8f6f\u4ef6\u6d4b\u8bd5\u9886\u57df\u5e26\u6765\u4e86\u5b9e\u8d28\u6027\u7684\u8fdb\u6b65\u3002"}}
{"id": "2602.18523", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18523", "abs": "https://arxiv.org/abs/2602.18523", "authors": ["Yongzhong Xu"], "title": "The Geometry of Multi-Task Grokking: Transverse Instability, Superposition, and Weight Decay Phase Structure", "comment": "36 pages, 31 figures, 15 tables", "summary": "Grokking -- the abrupt transition from memorization to generalization long after near-zero training loss -- has been studied mainly in single-task settings. We extend geometric analysis to multi-task modular arithmetic, training shared-trunk Transformers on dual-task (mod-add + mod-mul) and tri-task (mod-add + mod-mul + mod-sq) objectives across a systematic weight decay sweep. Five consistent phenomena emerge. (1) Staggered grokking order: multiplication generalizes first, followed by squaring, then addition, with consistent delays across seeds. (2) Universal integrability: optimization trajectories remain confined to an empirically invariant low-dimensional execution manifold; commutator defects orthogonal to this manifold reliably precede generalization. (3) Weight decay phase structure: grokking timescale, curvature depth, reconstruction threshold, and defect lead covary systematically with weight decay, revealing distinct dynamical regimes and a sharp no-decay failure mode. (4) Holographic incompressibility: final solutions occupy only 4--8 principal trajectory directions yet are distributed across full-rank weights and destroyed by minimal perturbations; SVD truncation, magnitude pruning, and uniform scaling all fail to preserve performance. (5) Transverse fragility and redundancy: removing less than 10% of orthogonal gradient components eliminates grokking, yet dual-task models exhibit partial recovery under extreme deletion, suggesting redundant center manifolds enabled by overparameterization. Together, these results support a dynamical picture in which multi-task grokking constructs a compact superposition subspace in parameter space, with weight decay acting as compression pressure and excess parameters supplying geometric redundancy in optimization pathways.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e0b\u7684Grokking\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7b97\u672f\u4efb\u52a1\u95f4\u7406\u89e3\u987a\u5e8f\u7684\u5dee\u5f02\u3001\u4f18\u5316\u8f68\u8ff9\u7684\u4f4e\u7ef4\u7279\u6027\u3001\u6743\u91cd\u8870\u51cf\u5bf9\u5b66\u4e60\u52a8\u6001\u7684\u5f71\u54cd\u3001\u6700\u7ec8\u89e3\u7684\u538b\u7f29\u6297\u6027\u548c\u53c2\u6570\u5197\u4f59\u6027\u5bf9\u6a21\u578b\u6062\u590d\u80fd\u529b\u7684\u4f5c\u7528\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u591a\u4efb\u52a1\u6a21\u5757\u5316\u7b97\u672f\u80cc\u666f\u4e0bGrokking\u73b0\u8c61\u7684\u672c\u8d28\uff0c\u7279\u522b\u662f\u5171\u4eab\u67b6\u6784\u53d8\u6362\u5668\u5728\u5904\u7406\u52a0\u6cd5\u3001\u4e58\u6cd5\u548c\u5e73\u65b9\u7b49\u591a\u91cd\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u7684\u5b66\u4e60\u884c\u4e3a\u7279\u5f81\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5730\u6539\u53d8\u6743\u91cd\u8870\u51cf\u503c\uff0c\u5728\u53cc\u4efb\u52a1\uff08\u6a21\u52a0+\u6a21\u4e58\uff09\u548c\u4e09\u4efb\u52a1\uff08\u6a21\u52a0+\u6a21\u4e58+\u6a21\u5e73\u65b9\uff09\u76ee\u6807\u4e0a\u8bad\u7ec3\u5171\u4eab\u67b6\u6784\u53d8\u6362\u5668\uff0c\u5e76\u89c2\u5bdf\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u591a\u79cd\u73b0\u8c61\u3002", "result": "\u53d1\u73b0\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a1) \u4e0d\u540c\u7b97\u672f\u4efb\u52a1\u95f4\u5b58\u5728\u56fa\u5b9a\u7684\u7406\u89e3\u5148\u540e\u987a\u5e8f\uff1b2) \u4f18\u5316\u8def\u5f84\u4fdd\u6301\u5728\u4e00\u4e2a\u7ecf\u9a8c\u4e0a\u4e0d\u53d8\u7684\u4f4e\u7ef4\u6267\u884c\u6d41\u5f62\u5185\uff1b3) \u6743\u91cd\u8870\u51cf\u5bf9\u5b66\u4e60\u65f6\u95f4\u5c3a\u5ea6\u53ca\u7f3a\u9677\u51fa\u73b0\u65f6\u673a\u6709\u663e\u8457\u5f71\u54cd\uff1b4) \u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u867d\u7136\u53ea\u5360\u636e\u5c11\u6570\u4e3b\u6210\u5206\u65b9\u5411\u4f46\u5206\u5e03\u4e8e\u5168\u79e9\u6743\u91cd\u4e2d\u4e14\u5bf9\u5c0f\u6270\u52a8\u654f\u611f\uff1b5) \u53c2\u6570\u5197\u4f59\u6027\u6709\u52a9\u4e8e\u6a21\u578b\u90e8\u5206\u6062\u590d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u591a\u4efb\u52a1Grokking\u5728\u53c2\u6570\u7a7a\u95f4\u4e2d\u6784\u5efa\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u53e0\u52a0\u5b50\u7a7a\u95f4\uff0c\u5176\u4e2d\u6743\u91cd\u8870\u51cf\u626e\u6f14\u7740\u538b\u7f29\u538b\u529b\u7684\u89d2\u8272\uff0c\u800c\u591a\u4f59\u7684\u53c2\u6570\u5219\u63d0\u4f9b\u4e86\u4f18\u5316\u8def\u5f84\u4e0a\u7684\u51e0\u4f55\u5197\u4f59\u3002"}}
{"id": "2602.20001", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20001", "abs": "https://arxiv.org/abs/2602.20001", "authors": ["Xianquan Wang", "Zhaocheng Du", "Jieming Zhu", "Qinglin Jia", "Zhenhua Dong", "Kai Zhang"], "title": "FairFS: Addressing Deep Feature Selection Biases for Recommender System", "comment": "Accepted by The Web Conference 2026", "summary": "Large-scale online marketplaces and recommender systems serve as critical technological support for e-commerce development. In industrial recommender systems, features play vital roles as they carry information for downstream models. Accurate feature importance estimation is critical because it helps identify the most useful feature subsets from thousands of feature candidates for online services. Such selection enables improved online performance while reducing computational cost. To address feature selection problems in deep learning, trainable gate-based and sensitivity-based methods have been proposed and proven effective in industrial practice. However, through the analysis of real-world cases, we identified three bias issues that cause feature importance estimation to rely on partial model layers, samples, or gradients, ultimately leading to inaccurate importance estimation. We refer to these as layer bias, baseline bias, and approximation bias. To mitigate these issues, we propose FairFS, a fair and accurate feature selection algorithm. FairFS regularizes feature importance estimated across all nonlinear transformation layers to address layer bias. It also introduces a smooth baseline feature close to the classifier decision boundary and adopts an aggregated approximation method to alleviate baseline and approximation biases. Extensive experiments demonstrate that FairFS effectively mitigates these biases and achieves state-of-the-art feature selection performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFairFS\u7684\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7531\u4e8e\u5c42\u504f\u7f6e\u3001\u57fa\u7ebf\u504f\u7f6e\u548c\u8fd1\u4f3c\u504f\u7f6e\u5bfc\u81f4\u7684\u7279\u5f81\u91cd\u8981\u6027\u4f30\u8ba1\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5728\u6240\u6709\u975e\u7ebf\u6027\u53d8\u6362\u5c42\u4e0a\u89c4\u8303\u5316\u7279\u5f81\u91cd\u8981\u6027\u3001\u5f15\u5165\u63a5\u8fd1\u5206\u7c7b\u5668\u51b3\u7b56\u8fb9\u754c\u7684\u5e73\u6ed1\u57fa\u7ebf\u7279\u5f81\u4ee5\u53ca\u91c7\u7528\u805a\u5408\u8fd1\u4f3c\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e9b\u504f\u7f6e\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u504f\u7f6e\u5e76\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7279\u5f81\u9009\u62e9\u6027\u80fd\u3002", "motivation": "\u5728\u5de5\u4e1a\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u7279\u5f81\u7684\u91cd\u8981\u6027\u8bc4\u4f30\u5bf9\u4e8e\u63d0\u9ad8\u5728\u7ebf\u670d\u52a1\u8868\u73b0\u540c\u65f6\u964d\u4f4e\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u53ef\u8bad\u7ec3\u95e8\u63a7\u548c\u654f\u611f\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5b58\u5728\u5c42\u504f\u7f6e\u3001\u57fa\u7ebf\u504f\u7f6e\u53ca\u8fd1\u4f3c\u504f\u7f6e\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\u4e0d\u591f\u51c6\u786e\u3002", "method": "\u63d0\u51fa\u4e86FairFS\u7b97\u6cd5\uff0c\u901a\u8fc7\u8de8\u6240\u6709\u975e\u7ebf\u6027\u8f6c\u6362\u5c42\u5bf9\u7279\u5f81\u91cd\u8981\u6027\u8fdb\u884c\u6b63\u5219\u5316\u5904\u7406\u4ee5\u89e3\u51b3\u5c42\u504f\u7f6e\uff1b\u5f15\u5165\u9760\u8fd1\u5206\u7c7b\u5668\u51b3\u7b56\u8fb9\u754c\u7684\u5e73\u6ed1\u57fa\u7ebf\u7279\u5f81\uff1b\u91c7\u7528\u4e00\u79cd\u805a\u5408\u8fd1\u4f3c\u65b9\u6cd5\u6765\u51cf\u8f7b\u57fa\u7ebf\u504f\u7f6e\u548c\u8fd1\u4f3c\u504f\u7f6e\u7684\u5f71\u54cd\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86FairFS\u80fd\u591f\u6709\u6548\u5730\u7f13\u89e3\u4e0a\u8ff0\u63d0\u5230\u7684\u5404\u79cd\u504f\u7f6e\uff0c\u5e76\u4e14\u5728\u7279\u5f81\u9009\u62e9\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u8868\u73b0\u3002", "conclusion": "FairFS\u63d0\u4f9b\u4e86\u4e00\u79cd\u516c\u5e73\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u51e0\u79cd\u504f\u7f6e\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7279\u5f81\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2602.18800", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18800", "abs": "https://arxiv.org/abs/2602.18800", "authors": ["Debalina Ghosh Paul", "Hong Zhu", "Ian Bayley"], "title": "Operational Robustness of LLMs on Code Generation", "comment": null, "summary": "It is now common practice in software development for large language models (LLMs) to be used to generate program code. It is desirable to evaluate the robustness of LLMs for this usage. This paper is concerned in particular with how sensitive LLMs are to variations in descriptions of the coding tasks. However, existing techniques for evaluating this robustness are unsuitable for code generation because the input data space of natural language descriptions is discrete. To address this problem, we propose a robustness evaluation method called scenario domain analysis, which aims to find the expected minimal change in the natural language descriptions of coding tasks that would cause the LLMs to produce incorrect outputs. We have formally proved the theoretical properties of the method and also conducted extensive experiments to evaluate the robustness of four state-of-the-art art LLMs: Gemini-pro, Codex, Llamma2 and Falcon 7B, and have found that we are able to rank these with confidence from best to worst. Moreover, we have also studied how robustness varies in different scenarios, including the variations with the topic of the coding task and with the complexity of its sample solution, and found that robustness is lower for more complex tasks and also lower for more advanced topics, such as multi-threading and data structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u65b9\u6cd5\u2014\u2014\u573a\u666f\u57df\u5206\u6790\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u4ee3\u7801\u65f6\u5bf9\u4efb\u52a1\u63cf\u8ff0\u53d8\u5316\u7684\u654f\u611f\u5ea6\u3002\u901a\u8fc7\u5b9e\u9a8c\uff0c\u5bf9\u56db\u79cd\u6700\u5148\u8fdb\u7684LLMs\uff08Gemini-pro, Codex, Llamma2 \u548c Falcon 7B\uff09\u8fdb\u884c\u4e86\u6392\u540d\uff0c\u5e76\u53d1\u73b0\u590d\u6742\u6027\u548c\u9ad8\u7ea7\u4e3b\u9898\u7684\u4efb\u52a1\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u5e94\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u7a0b\u5e8f\u4ee3\u7801\uff0c\u6709\u5fc5\u8981\u5bf9\u5176\u5728\u6b64\u7c7b\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u7f16\u7801\u4efb\u52a1\u63cf\u8ff0\u53d8\u5316\u7684\u654f\u611f\u7a0b\u5ea6\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u6280\u672f\u5e76\u4e0d\u9002\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u573a\u666f\uff0c\u56e0\u4e3a\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u6570\u636e\u7a7a\u95f4\u662f\u79bb\u6563\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3a\u201c\u573a\u666f\u57df\u5206\u6790\u201d\u7684\u9c81\u68d2\u6027\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u65e8\u5728\u5bfb\u627e\u5bfc\u81f4LLMs\u4ea7\u751f\u9519\u8bef\u8f93\u51fa\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4e2d\u9884\u671f\u6700\u5c0f\u7684\u53d8\u5316\u91cf\u3002\u7814\u7a76\u8005\u8fd8\u5bf9\u8be5\u65b9\u6cd5\u7684\u7406\u8bba\u6027\u8d28\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u6765\u8bc4\u4f30\u56db\u6b3e\u6700\u5148\u8fdbLLM\u7684\u9c81\u68d2\u6027\u8868\u73b0\u3002", "result": "\u6210\u529f\u5730\u6839\u636e\u9c81\u68d2\u6027\u4ece\u597d\u5230\u5dee\u5bf9\u56db\u4e2a\u9876\u5c16LLM\u8fdb\u884c\u4e86\u6392\u5e8f\uff1b\u540c\u65f6\u89c2\u5bdf\u5230\uff0c\u5728\u9762\u5bf9\u66f4\u590d\u6742\u7684\u4efb\u52a1\u6216\u6d89\u53ca\u66f4\u9ad8\u7ea7\u7684\u4e3b\u9898\uff08\u5982\u591a\u7ebf\u7a0b\u548c\u6570\u636e\u7ed3\u6784\uff09\u65f6\uff0c\u8fd9\u4e9b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8f83\u5dee\u3002", "conclusion": "\u573a\u666f\u57df\u5206\u6790\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u63ed\u793a\u4e86\u4e0d\u540c\u6761\u4ef6\u4e0bLLMs\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u5dee\u5f02\uff0c\u4e3a\u7406\u89e3\u53ca\u6539\u8fdbLLMs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.18528", "categories": ["cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.18528", "abs": "https://arxiv.org/abs/2602.18528", "authors": ["Sarthak Kumar Maharana", "Akshay Mehra", "Bhavya Ramakrishna", "Yunhui Guo", "Guan-Ming Su"], "title": "Audio-Visual Continual Test-Time Adaptation without Forgetting", "comment": null, "summary": "Audio-visual continual test-time adaptation involves continually adapting a source audio-visual model at test-time, to unlabeled non-stationary domains, where either or both modalities can be distributionally shifted, which hampers online cross-modal learning and eventually leads to poor accuracy. While previous works have tackled this problem, we find that SOTA methods suffer from catastrophic forgetting, where the model's performance drops well below the source model due to continual parameter updates at test-time. In this work, we first show that adapting only the modality fusion layer to a target domain not only improves performance on that domain but can also enhance performance on subsequent domains. Based on this strong cross-task transferability of the fusion layer's parameters, we propose a method, $\\texttt{AV-CTTA}$, that improves test-time performance of the models without access to any source data. Our approach works by using a selective parameter retrieval mechanism that dynamically retrieves the best fusion layer parameters from a buffer using only a small batch of test data. These parameters are then integrated into the model, adapted to the current test distribution, and saved back for future use. Extensive experiments on benchmark datasets involving unimodal and bimodal corruptions show our proposed $\\texttt{AV-CTTA}$ significantly outperforms existing methods while minimizing catastrophic forgetting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAV-CTTA\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u81ea\u9002\u5e94\u8c03\u6574\u6a21\u6001\u878d\u5408\u5c42\u6765\u6539\u5584\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5229\u7528\u4e00\u4e2a\u9009\u62e9\u6027\u53c2\u6570\u68c0\u7d22\u673a\u5236\u52a8\u6001\u5730\u4ece\u7f13\u5b58\u4e2d\u83b7\u53d6\u6700\u4f73\u7684\u878d\u5408\u5c42\u53c2\u6570\uff0c\u4ece\u800c\u5728\u4e0d\u9700\u8981\u6e90\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u975e\u5e73\u7a33\u57df\u7684\u9002\u5e94\u80fd\u529b\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4e86\u707e\u96be\u6027\u9057\u5fd8\u3002", "motivation": "\u5148\u524d\u89e3\u51b3\u97f3\u9891-\u89c6\u89c9\u8fde\u7eed\u6d4b\u8bd5\u65f6\u9002\u5e94\u95ee\u9898\u7684\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5373\u7531\u4e8e\u5728\u6d4b\u8bd5\u65f6\u6301\u7eed\u66f4\u65b0\u53c2\u6570\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u65e8\u5728\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u80fd\u591f\u63d0\u9ad8\u6a21\u578b\u5728\u76ee\u6807\u57df\u4e0a\u7684\u8868\u73b0\uff0c\u8fd8\u80fd\u589e\u5f3a\u5176\u5728\u540e\u7eed\u57df\u4e2d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5c55\u793a\u4e86\u53ea\u9488\u5bf9\u6a21\u6001\u878d\u5408\u5c42\u8fdb\u884c\u76ee\u6807\u57df\u9002\u5e94\u4e0d\u4ec5\u80fd\u591f\u63d0\u5347\u8be5\u57df\u4e0b\u7684\u6027\u80fd\uff0c\u8fd8\u80fd\u591f\u589e\u5f3a\u540e\u7eed\u57df\u4e2d\u7684\u6027\u80fd\u3002\u57fa\u4e8e\u6b64\u53d1\u73b0\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86AV-CTTA\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u4e00\u4e2a\u9009\u62e9\u6027\u7684\u53c2\u6570\u68c0\u7d22\u673a\u5236\uff0c\u6839\u636e\u4e00\u5c0f\u6279\u6d4b\u8bd5\u6570\u636e\u52a8\u6001\u5730\u4ece\u7f13\u51b2\u533a\u4e2d\u68c0\u7d22\u6700\u4f18\u7684\u878d\u5408\u5c42\u53c2\u6570\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u53c2\u6570\u6574\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u4f7f\u5176\u9002\u5e94\u5f53\u524d\u7684\u6d4b\u8bd5\u5206\u5e03\uff0c\u5e76\u4fdd\u5b58\u4ee5\u4f9b\u5c06\u6765\u4f7f\u7528\u3002", "result": "\u5728\u5305\u542b\u5355\u6a21\u6001\u548c\u53cc\u6a21\u6001\u635f\u574f\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684AV-CTTA\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u6709\u6548\u51cf\u5c11\u4e86\u707e\u96be\u6027\u9057\u5fd8\u73b0\u8c61\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u6a21\u6001\u878d\u5408\u5c42\u8fdb\u884c\u5355\u72ec\u8c03\u6574\u4ee5\u53ca\u91c7\u7528\u9009\u62e9\u6027\u53c2\u6570\u68c0\u7d22\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u6d4b\u8bd5\u57df\u4e0a\u7684\u9002\u5e94\u6027\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\u3002"}}
{"id": "2602.19683", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19683", "abs": "https://arxiv.org/abs/2602.19683", "authors": ["Henrik M\u00f6llmann", "Dirk Pfl\u00fcger", "Alexander Strack"], "title": "GPU-Resident Gaussian Process Regression Leveraging Asynchronous Tasks with HPX", "comment": "13 pages, 7 figures, Workshop on Asynchronous Many-Task Systems and Applications 2026", "summary": "Gaussian processes (GPs) are a widely used regression tool, but the cubic complexity of exact solvers limits their scalability. To address this challenge, we extend the GPRat library by incorporating a fully GPU-resident GP prediction pipeline. GPRat is an HPX-based library that combines task-based parallelism with an intuitive Python API.\n  We implement tiled algorithms for the GP prediction using optimized CUDA libraries, thereby exploiting massive parallelism for linear algebra operations. We evaluate the optimal number of CUDA streams and compare the performance of our GPU implementation to the existing CPU-based implementation. Our results show the GPU implementation provides speedups for datasets larger than 128 training samples. We observe speedups of up to 4.3 for the Cholesky decomposition itself and 4.6 for the GP prediction. Furthermore, combining HPX with multiple CUDA streams allows GPRat to match, and for large datasets, surpass cuSOLVER's performance by up to 11 percent.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86GPRat\u5e93\uff0c\u901a\u8fc7\u5f15\u5165\u5b8c\u5168\u57fa\u4e8eGPU\u7684\u9ad8\u65af\u8fc7\u7a0b\u9884\u6d4b\u7ba1\u9053\u6765\u89e3\u51b3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002\u5229\u7528\u4f18\u5316\u540e\u7684CUDA\u5e93\u5b9e\u73b0\u4e86\u5206\u5757\u7b97\u6cd5\uff0c\u5bf9\u4e8e\u5927\u4e8e128\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u6570\u636e\u96c6\uff0cGPU\u5b9e\u73b0\u63d0\u4f9b\u4e86\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u662f\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u56de\u5f52\u5de5\u5177\uff0c\u4f46\u7cbe\u786e\u6c42\u89e3\u5668\u7684\u7acb\u65b9\u590d\u6742\u5ea6\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u5b8c\u5168\u57fa\u4e8eGPU\u7684GP\u9884\u6d4b\u6d41\u7a0b\u6765\u63d0\u9ad8\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u7684\u6548\u7387\u3002", "method": "\u4f5c\u8005\u4eec\u901a\u8fc7\u4f7f\u7528\u4f18\u5316\u8fc7\u7684CUDA\u5e93\u5b9e\u73b0\u4e86\u9488\u5bf9GP\u9884\u6d4b\u7684\u5206\u5757\u7b97\u6cd5\uff0c\u4ece\u800c\u5145\u5206\u5229\u7528\u4e86\u7ebf\u6027\u4ee3\u6570\u8fd0\u7b97\u4e2d\u7684\u5927\u89c4\u6a21\u5e76\u884c\u6027\u3002\u540c\u65f6\uff0c\u4ed6\u4eec\u8fd8\u8bc4\u4f30\u4e86\u6700\u4f73CUDA\u6d41\u7684\u6570\u91cf\uff0c\u5e76\u5c06GPU\u5b9e\u73b0\u4e0e\u73b0\u6709\u7684\u57fa\u4e8eCPU\u7684\u5b9e\u73b0\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u8d85\u8fc7128\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u6570\u636e\u96c6\uff0cGPU\u5b9e\u73b0\u80fd\u591f\u63d0\u4f9b\u52a0\u901f\u6548\u679c\uff1bCholesky\u5206\u89e3\u672c\u8eab\u6700\u9ad8\u53ef\u8fbe4.3\u500d\u52a0\u901f\uff0c\u800cGP\u9884\u6d4b\u5219\u80fd\u8fbe\u52304.6\u500d\u52a0\u901f\u3002\u6b64\u5916\uff0c\u7ed3\u5408HPX\u4e0e\u591a\u4e2aCUDA\u6d41\u4f7f\u5f97GPRat\u5728\u5927\u5c3a\u5bf8\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u751a\u81f3\u8d85\u8fc7\u4e86cuSOLVER\u8fbe11%\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eGPU\u7684\u9884\u6d4b\u7ba1\u9053\u4ee5\u53ca\u5229\u7528\u4f18\u5316\u7684CUDA\u5e93\uff0c\u672c\u7814\u7a76\u6210\u529f\u5730\u63d0\u9ad8\u4e86GPRat\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u6837\u672c\u6570\u91cf\u8f83\u591a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u4f18\u52bf\u3002"}}
{"id": "2602.20093", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2602.20093", "abs": "https://arxiv.org/abs/2602.20093", "authors": ["Kun Yang", "Yuxuan Zhu", "Yazhe Chen", "Siyao Zheng", "Bangyang Hong", "Kangle Wu", "Yabo Ni", "Anxiang Zeng", "Cong Fu", "Hui Li"], "title": "ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation", "comment": "15 pages, 7 figures", "summary": "Sequential recommendation increasingly employs latent multi-step reasoning to enhance test-time computation. Despite empirical gains, existing approaches largely drive intermediate reasoning states via target-dominant objectives without imposing explicit feasibility constraints. This results in latent drift, where reasoning trajectories deviate into implausible regions. We argue that effective recommendation reasoning should instead be viewed as navigation on a collaborative manifold rather than free-form latent refinement. To this end, we propose ManCAR (Manifold-Constrained Adaptive Reasoning), a principled framework that grounds reasoning within the topology of a global interaction graph. ManCAR constructs a local intent prior from the collaborative neighborhood of a user's recent actions, represented as a distribution over the item simplex. During training, the model progressively aligns its latent predictive distribution with this prior, forcing the reasoning trajectory to remain within the valid manifold. At test time, reasoning proceeds adaptively until the predictive distribution stabilizes, avoiding over-refinement. We provide a variational interpretation of ManCAR to theoretically validate its drift-prevention and adaptive test-time stopping mechanisms. Experiments on seven benchmarks demonstrate that ManCAR consistently outperforms state-of-the-art baselines, achieving up to a 46.88% relative improvement w.r.t. NDCG@10. Our code is available at https://github.com/FuCongResearchSquad/ManCAR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aManCAR\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5728\u5168\u5c40\u4ea4\u4e92\u56fe\u7684\u62d3\u6251\u7ed3\u6784\u4e2d\u7ea6\u675f\u63a8\u7406\u8fc7\u7a0b\u6765\u89e3\u51b3\u6f5c\u53d8\u91cf\u6f02\u79fb\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u987a\u5e8f\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u663e\u793aManCAR\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u987a\u5e8f\u63a8\u8350\u7cfb\u7edf\u5728\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u51fa\u73b0\u6f5c\u53d8\u91cf\u6f02\u79fb\u73b0\u8c61\uff0c\u5bfc\u81f4\u63a8\u8350\u7ed3\u679c\u4e0d\u5408\u7406\u3002\u7814\u7a76\u8005\u8ba4\u4e3a\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u63a8\u7406\u5e94\u8be5\u88ab\u89c6\u4e3a\u5728\u534f\u4f5c\u6d41\u5f62\u4e0a\u7684\u5bfc\u822a\uff0c\u800c\u975e\u81ea\u7531\u5f62\u5f0f\u7684\u6f5c\u5728\u6539\u8fdb\u3002", "method": "ManCAR\uff08Manifold-Constrained Adaptive Reasoning\uff09\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7528\u6237\u6700\u8fd1\u884c\u4e3a\u5408\u4f5c\u90bb\u57df\u7684\u5c40\u90e8\u610f\u56fe\u5148\u9a8c\uff0c\u5e76\u4ee5\u9879\u76ee\u5355\u7eaf\u5f62\u4e0a\u7684\u5206\u5e03\u8868\u793a\u3002\u8bad\u7ec3\u65f6\uff0c\u6a21\u578b\u9010\u6b65\u5c06\u5176\u6f5c\u5728\u9884\u6d4b\u5206\u5e03\u4e0e\u8fd9\u4e2a\u5148\u9a8c\u5bf9\u9f50\uff0c\u786e\u4fdd\u63a8\u7406\u8f68\u8ff9\u4fdd\u6301\u5728\u6709\u6548\u7684\u6d41\u5f62\u5185\u3002\u6d4b\u8bd5\u65f6\uff0c\u63a8\u7406\u8fc7\u7a0b\u81ea\u9002\u5e94\u8fdb\u884c\u76f4\u5230\u9884\u6d4b\u5206\u5e03\u7a33\u5b9a\u4e0b\u6765\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aManCAR\u76f8\u5bf9\u4e8e\u6700\u65b0\u57fa\u7ebf\u65b9\u6cd5\u5728NDCG@10\u6307\u6807\u4e0a\u6700\u9ad8\u53ef\u5b9e\u73b046.88%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "ManCAR\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u907f\u514d\u6f5c\u53d8\u91cf\u6f02\u79fb\u5e76\u63d0\u9ad8\u4e86\u987a\u5e8f\u63a8\u8350\u7cfb\u7edf\u7684\u63a8\u8350\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86ManCAR\u53d8\u5206\u89e3\u91ca\uff0c\u7406\u8bba\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9632\u6b62\u6f02\u79fb\u548c\u81ea\u9002\u5e94\u6d4b\u8bd5\u505c\u6b62\u673a\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.19742", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.19742", "abs": "https://arxiv.org/abs/2602.19742", "authors": ["Yulun Huang", "Zhiyu Wang", "Rajkumar Buyya"], "title": "A Risk-Aware UAV-Edge Service Framework for Wildfire Monitoring and Emergency Response", "comment": null, "summary": "Wildfire monitoring demands timely data collection and processing for early detection and rapid response. UAV-assisted edge computing is a promising approach, but jointly minimizing end-to-end service response time while satisfying energy, revisit time, and capacity constraints remains challenging. We propose an integrated framework that co-optimizes UAV route planning, fleet sizing, and edge service provisioning for wildfire monitoring. The framework combines fire-history-weighted clustering to prioritize high-risk areas, Quality of Service (QoS)-aware edge assignment balancing proximity and computational load, 2-opt route optimization with adaptive fleet sizing, and a dynamic emergency rerouting mechanism. The key insight is that these subproblems are interdependent: clustering decisions simultaneously shape patrol efficiency and edge workloads, while capacity constraints feed back into feasible configurations. Experiments show that the proposed framework reduces average response time by 70.6--84.2%, energy consumption by 73.8--88.4%, and fleet size by 26.7--42.1% compared to GA, PSO, and greedy baselines. The emergency mechanism responds within 233 seconds, well under the 300-second deadline, with negligible impact on normal operations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u65e0\u4eba\u673a\u8def\u7ebf\u89c4\u5212\u3001\u673a\u961f\u89c4\u6a21\u548c\u8fb9\u7f18\u670d\u52a1\u63d0\u4f9b\uff0c\u4ee5\u5b9e\u73b0\u91ce\u706b\u76d1\u6d4b\u3002\u901a\u8fc7\u7ed3\u5408\u5386\u53f2\u706b\u707e\u52a0\u6743\u805a\u7c7b\u3001QoS\u611f\u77e5\u7684\u8fb9\u7f18\u5206\u914d\u30012-opt\u8def\u7ebf\u4f18\u5316\u4ee5\u53ca\u52a8\u6001\u7d27\u6025\u91cd\u8def\u7531\u673a\u5236\uff0c\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u54cd\u5e94\u65f6\u95f4\u3001\u80fd\u8017\u548c\u6240\u9700\u673a\u961f\u89c4\u6a21\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u4e0d\u660e\u663e\u5f71\u54cd\u5e38\u89c4\u64cd\u4f5c\u7684\u60c5\u51b5\u4e0b\u8fc5\u901f\u5e94\u5bf9\u7d27\u6025\u60c5\u51b5\u3002", "motivation": "\u9488\u5bf9\u91ce\u706b\u76d1\u6d4b\u4e2d\u53ca\u65f6\u6570\u636e\u6536\u96c6\u4e0e\u5904\u7406\u7684\u9700\u6c42\uff0c\u4ee5\u53ca\u73b0\u6709UAV\u8f85\u52a9\u8fb9\u7f18\u8ba1\u7b97\u65b9\u6cd5\u5728\u6ee1\u8db3\u80fd\u6e90\u3001\u91cd\u8bbf\u65f6\u95f4\u548c\u5bb9\u91cf\u9650\u5236\u6761\u4ef6\u4e0b\u540c\u65f6\u6700\u5c0f\u5316\u7aef\u5230\u7aef\u670d\u52a1\u54cd\u5e94\u65f6\u95f4\u65b9\u9762\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5171\u540c\u4f18\u5316\u4e86UAV\u8def\u5f84\u89c4\u5212\u3001\u8230\u961f\u89c4\u6a21\u53ca\u8fb9\u7f18\u670d\u52a1\u63d0\u4f9b\u3002\u6b64\u6846\u67b6\u7ed3\u5408\u4e86\u57fa\u4e8e\u706b\u707e\u5386\u53f2\u6743\u91cd\u7684\u805a\u7c7b\u6765\u4f18\u5148\u8003\u8651\u9ad8\u98ce\u9669\u533a\u57df\u3001QoS\u611f\u77e5\u7684\u8fb9\u7f18\u5206\u914d\u4ee5\u5e73\u8861\u63a5\u8fd1\u5ea6\u548c\u8ba1\u7b97\u8d1f\u8f7d\u3001\u91c7\u75282-opt\u8def\u7ebf\u4f18\u5316\u5e76\u5177\u6709\u81ea\u9002\u5e94\u8230\u961f\u89c4\u6a21\u8c03\u6574\u80fd\u529b\uff0c\u8fd8\u5305\u62ec\u4e00\u79cd\u52a8\u6001\u7d27\u6025\u91cd\u65b0\u8def\u7531\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eGA, PSO\u548c\u8d2a\u5a6a\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u964d\u4f4e\u4e8670.6-84.2%\uff0c\u80fd\u91cf\u6d88\u8017\u964d\u4f4e\u4e8673.8-88.4%\uff0c\u8230\u961f\u89c4\u6a21\u51cf\u5c11\u4e8626.7-42.1%\u3002\u7d27\u6025\u673a\u5236\u80fd\u5728233\u79d2\u5185\u4f5c\u51fa\u53cd\u5e94\uff0c\u8fdc\u4f4e\u4e8e300\u79d2\u7684\u622a\u6b62\u671f\u9650\uff0c\u5bf9\u6b63\u5e38\u8fd0\u4f5c\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u96c6\u6210\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u91ce\u706b\u76d1\u6d4b\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5305\u62ec\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\u3001\u51cf\u5c11\u80fd\u91cf\u6d88\u8017\u548c\u4f18\u5316\u8230\u961f\u89c4\u6a21\u7b49\uff0c\u4e3a\u672a\u6765\u707e\u5bb3\u7ba1\u7406\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002"}}
{"id": "2602.18613", "categories": ["cs.LG", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18613", "abs": "https://arxiv.org/abs/2602.18613", "authors": ["Baris Arat", "Emre Sefer"], "title": "Diagnosing LLM Reranker Behavior Under Fixed Evidence Pools", "comment": null, "summary": "Standard reranking evaluations study how a reranker orders candidates returned by an upstream retriever. This setup couples ranking behavior with retrieval quality, so differences in output cannot be attributed to the ranking policy alone. We introduce a controlled diagnostic that isolates reranking by using Multi-News clusters as fixed evidence pools. We limit each pool to exactly eight documents and pass identical inputs to all rankers. Within this setup, BM25 and MMR serve as interpretable reference points for lexical matching and diversity optimization. Across 345 clusters, we find that redundancy patterns vary by model: one LLM implicitly diversifies at larger selection budgets, while another increases redundancy. In contrast, LLMs underperform on lexical coverage at small selection budgets. As a result, LLM rankings diverge substantially from both baselines rather than consistently approximating either strategy. By eliminating retrieval variance, we can attribute these differences directly to the ranking policy. This diagnostic is model-agnostic and applicable to any ranker, including open source systems and proprietary APIs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a7\u5236\u8bca\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528Multi-News\u96c6\u7fa4\u4f5c\u4e3a\u56fa\u5b9a\u7684\u8bc1\u636e\u6c60\u6765\u9694\u79bb\u91cd\u6392\u5e8f\u8fc7\u7a0b\uff0c\u4ece\u800c\u72ec\u7acb\u4e8e\u68c0\u7d22\u8d28\u91cf\u7814\u7a76\u4e0d\u540c\u6a21\u578b\u7684\u6392\u5e8f\u884c\u4e3a\u3002", "motivation": "\u4f20\u7edf\u7684\u91cd\u6392\u5e8f\u8bc4\u4f30\u65b9\u6cd5\u5c06\u6392\u5e8f\u884c\u4e3a\u4e0e\u68c0\u7d22\u8d28\u91cf\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u4f7f\u5f97\u8f93\u51fa\u5dee\u5f02\u4e0d\u80fd\u5355\u72ec\u5f52\u56e0\u4e8e\u6392\u5e8f\u7b56\u7565\u3002\u4e3a\u4e86\u80fd\u591f\u72ec\u7acb\u5730\u7814\u7a76\u6392\u5e8f\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bca\u65ad\u65b9\u6cd5\u6765\u9694\u79bb\u91cd\u6392\u5e8f\u8fc7\u7a0b\u3002", "method": "\u4f5c\u8005\u4eec\u91c7\u7528Multi-News\u96c6\u7fa4\u4f5c\u4e3a\u56fa\u5b9a\u8bc1\u636e\u6c60\uff0c\u5e76\u9650\u5236\u6bcf\u4e2a\u6c60\u4e2d\u6070\u597d\u6709\u516b\u4e2a\u6587\u6863\uff0c\u5411\u6240\u6709\u6392\u5e8f\u5668\u4f20\u9012\u5b8c\u5168\u76f8\u540c\u7684\u8f93\u5165\u3002\u5728\u8be5\u8bbe\u7f6e\u4e0b\uff0cBM25\u548cMMR\u88ab\u7528\u4f5c\u8bcd\u6c47\u5339\u914d\u548c\u591a\u6837\u6027\u4f18\u5316\u7684\u53ef\u89e3\u91ca\u53c2\u8003\u70b9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728345\u4e2a\u96c6\u7fa4\u4e0a\uff0c\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5197\u4f59\u6a21\u5f0f\uff1a\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f83\u5927\u7684\u9009\u62e9\u9884\u7b97\u4e0b\u9690\u5f0f\u5730\u589e\u52a0\u4e86\u591a\u6837\u6027\uff0c\u800c\u53e6\u4e00\u4e2a\u5219\u589e\u52a0\u4e86\u5197\u4f59\u6027\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5f53\u9009\u62e9\u9884\u7b97\u8f83\u5c0f\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u6c47\u8986\u76d6\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6392\u540d\u4e0e\u4e24\u79cd\u57fa\u51c6\u7b56\u7565\u90fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u901a\u8fc7\u6d88\u9664\u68c0\u7d22\u53d8\u91cf\uff0c\u53ef\u4ee5\u76f4\u63a5\u5c06\u8fd9\u4e9b\u5dee\u5f02\u5f52\u56e0\u4e8e\u6392\u5e8f\u7b56\u7565\u672c\u8eab\u3002\u63d0\u51fa\u7684\u8fd9\u79cd\u8bca\u65ad\u65b9\u6cd5\u662f\u6a21\u578b\u65e0\u5173\u7684\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6392\u5e8f\u5668\uff0c\u5305\u62ec\u5f00\u6e90\u7cfb\u7edf\u548c\u4e13\u6709API\u3002"}}
{"id": "2602.18928", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18928", "abs": "https://arxiv.org/abs/2602.18928", "authors": ["Yang Chen", "Shuyang Liu", "Reyhaneh Jabbarvand"], "title": "Narrowing the Complexity Gap in the Evaluation of Large Language Models", "comment": null, "summary": "Evaluating Large Language Models (LLMs) with respect to real-world code complexity is essential. Otherwise, there is a risk of overestimating LLMs' programming abilities based on simplistic benchmarks, only to be disappointed when using them in real-world settings. Recently, researchers explored the construction of more realistic benchmarks by mining or augmenting open-source repositories. Such solutions are usually task-specific. Data quality control from real-world projects can also be time-consuming and error-prone. More importantly, evaluating LLMs on fixed benchmark problems is subject to data contamination and overfitting. We propose GeneBench, an automated technique to add real-world complexities to any programming benchmark. GeneBench leverages a multi-objective optimization to increase the complexity of programming problems while maintaining the readability of code similar to real-world programs. Transforming four widely-used programming benchmarks using GeneBench and evaluating 13 LLMs (including two reasoning LLMs) on them shows a notable performance drop across all programming tasks (14.9%-60.5%, avg=35.2%), demonstrating LLMs' struggle under real-world complexities. The struggle persists even when LLMs are few-shot prompted or fine-tuned with examples from different versions of GeneBench, demonstrating the challenging nature of the problems. Finally, we show that the performance of the studied LLMs in bug repair is similar under GeneBench and SWE-Bench. This, along with the consistent reproduction of performance drop of all studied LLMs across four tasks under different versions of GeneBench, makes the technique suitable to evaluate LLMs without costly construction of real-world benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6280\u672fGeneBench\uff0c\u7528\u4e8e\u7ed9\u4efb\u4f55\u7f16\u7a0b\u57fa\u51c6\u6dfb\u52a0\u73b0\u5b9e\u4e16\u754c\u7684\u590d\u6742\u6027\u3002\u901a\u8fc7\u8f6c\u6362\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u7f16\u7a0b\u57fa\u51c6\u5e76\u8bc4\u4f3013\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ec\u4e24\u4e2a\u63a8\u7406\u578b\uff09\u5728\u8fd9\u4e9b\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6240\u6709\u7f16\u7a0b\u4efb\u52a1\u7684\u6027\u80fd\u90fd\u6709\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u4e86LLMs\u5728\u9762\u5bf9\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u65f6\u9047\u5230\u7684\u6311\u6218\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9e\u9645\u4ee3\u7801\u590d\u6742\u6027\u65b9\u9762\u7684\u8868\u73b0\u81f3\u5173\u91cd\u8981\u3002\u5426\u5219\uff0c\u4ec5\u57fa\u4e8e\u7b80\u5355\u7684\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u4f1a\u9ad8\u4f30LLMs\u7684\u7f16\u7a0b\u80fd\u529b\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bfc\u81f4\u5931\u671b\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u662f\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\uff0c\u5e76\u4e14\u4ece\u771f\u5b9e\u9879\u76ee\u63a7\u5236\u6570\u636e\u8d28\u91cf\u53ef\u80fd\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u4f7f\u7528\u56fa\u5b9a\u57fa\u51c6\u95ee\u9898\u8bc4\u4f30LLMs\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u8fc7\u62df\u5408\u7684\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86GeneBench\uff0c\u4e00\u79cd\u5229\u7528\u591a\u76ee\u6807\u4f18\u5316\u6765\u589e\u52a0\u7f16\u7a0b\u95ee\u9898\u590d\u6742\u5ea6\u7684\u6280\u672f\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u4e0e\u73b0\u5b9e\u4e16\u754c\u7a0b\u5e8f\u76f8\u4f3c\u3002\u5bf9\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u7f16\u7a0b\u57fa\u51c6\u8fdb\u884c\u4e86\u8f6c\u6362\uff0c\u5e76\u7528GeneBench\u5bf913\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ec2\u4e2a\u63a8\u7406\u4e13\u7528\u6a21\u578b\uff09\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u6240\u6709\u7f16\u7a0b\u4efb\u52a1\u7684\u6027\u80fd\u90fd\u51fa\u73b0\u4e86\u663e\u8457\u4e0b\u964d\uff08\u8303\u56f4\u4e3a14.9%-60.5%\uff0c\u5e73\u5747\u503c=35.2%\uff09\uff0c\u8fd9\u663e\u793a\u4e86LLMs\u5728\u5904\u7406\u5177\u6709\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u7684\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u56f0\u96be\u3002\u5373\u4f7f\u662f\u5728\u5c11\u91cf\u63d0\u793a\u6216\u5fae\u8c03\u540e\uff0c\u8fd9\u79cd\u6311\u6218\u4f9d\u7136\u5b58\u5728\u3002\u6b64\u5916\uff0c\u5728\u9519\u8bef\u4fee\u590d\u65b9\u9762\uff0c\u7814\u7a76\u4e2d\u7684LLMs\u5728GeneBench\u548cSWE-Bench\u4e0b\u7684\u8868\u73b0\u76f8\u4f3c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cGeneBench\u80fd\u591f\u6709\u6548\u63ed\u793aLLMs\u5728\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u7f16\u7a0b\u590d\u6742\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u800c\u65e0\u9700\u6784\u5efa\u6210\u672c\u9ad8\u6602\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u3002\u8be5\u6280\u672f\u5bf9\u4e8e\u8bc4\u4ef7LLMs\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.18786", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.18786", "abs": "https://arxiv.org/abs/2602.18786", "authors": ["Xikai Yang", "Sebastian Sun", "Yilin Li", "Yue Xing", "Ming Wang", "Yang Wang"], "title": "CaliCausalRank: Calibrated Multi-Objective Ad Ranking with Robust Counterfactual Utility Optimization", "comment": null, "summary": "Ad ranking systems must simultaneously optimize multiple objectives including click-through rate (CTR), conversion rate (CVR), revenue, and user experience metrics. However, production systems face critical challenges: score scale inconsistency across traffic segments undermines threshold transferability, and position bias in click logs causes offline-online metric discrepancies. We propose CaliCausalRank, a unified framework that integrates training-time scale calibration, constraint-based multi-objective optimization, and robust counterfactual utility estimation. Our approach treats score calibration as a first-class training objective rather than post-hoc processing, employs Lagrangian relaxation for constraint satisfaction, and utilizes variance-reduced counterfactual estimators for reliable offline evaluation. Experiments on the Criteo and Avazu datasets demonstrate that CaliCausalRank achieves 1.1% relative AUC improvement, 31.6% calibration error reduction, and 3.2% utility gain compared to the best baseline (PairRank) while maintaining consistent performance across different traffic segments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCaliCausalRank\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5e7f\u544a\u6392\u540d\u7cfb\u7edf\u4e2d\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8bad\u7ec3\u65f6\u7684\u8bc4\u5206\u6821\u51c6\u3001\u57fa\u4e8e\u7ea6\u675f\u7684\u591a\u76ee\u6807\u4f18\u5316\u53ca\u9c81\u68d2\u53cd\u4e8b\u5b9e\u6548\u7528\u4f30\u8ba1\u7b49\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5728\u4e0d\u540c\u6d41\u91cf\u6bb5\u7684\u4e00\u81f4\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5e7f\u544a\u6392\u540d\u7cfb\u7edf\u5728\u540c\u65f6\u4f18\u5316\u70b9\u51fb\u7387(CTR)\u3001\u8f6c\u5316\u7387(CVR)\u3001\u6536\u5165\u548c\u7528\u6237\u4f53\u9a8c\u6307\u6807\u7b49\u591a\u4e2a\u76ee\u6807\u65f6\u9047\u5230\u4e86\u6311\u6218\uff0c\u6bd4\u5982\u8de8\u6d41\u91cf\u6bb5\u7684\u8bc4\u5206\u5c3a\u5ea6\u4e0d\u4e00\u81f4\u4ee5\u53ca\u70b9\u51fb\u65e5\u5fd7\u4e2d\u7684\u4f4d\u7f6e\u504f\u89c1\u5bfc\u81f4\u7684\u79bb\u7ebf-\u5728\u7ebf\u5ea6\u91cf\u5dee\u5f02\u3002", "method": "CaliCausalRank\u6846\u67b6\u5c06\u8bc4\u5206\u6821\u51c6\u89c6\u4e3a\u9996\u8981\u8bad\u7ec3\u76ee\u6807\u4e4b\u4e00\uff0c\u91c7\u7528\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u6cd5\u6765\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\uff0c\u5e76\u5229\u7528\u65b9\u5dee\u51cf\u5c11\u7684\u53cd\u4e8b\u5b9e\u4f30\u8ba1\u5668\u6765\u8fdb\u884c\u53ef\u9760\u7684\u79bb\u7ebf\u8bc4\u4f30\u3002", "result": "\u5728Criteo\u548cAvazu\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6700\u4f73\u57fa\u7ebf(PairRank)\u76f8\u6bd4\uff0cCaliCausalRank\u5b9e\u73b0\u4e861.1%\u7684\u76f8\u5bf9AUC\u63d0\u5347\u300131.6%\u7684\u6821\u51c6\u8bef\u5dee\u964d\u4f4e\u4ee5\u53ca3.2%\u7684\u6548\u7528\u589e\u957f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0d\u540c\u6d41\u91cf\u6bb5\u95f4\u7684\u4e00\u81f4\u6027\u8868\u73b0\u3002", "conclusion": "CaliCausalRank\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u5e7f\u544a\u6392\u540d\u7cfb\u7edf\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u96be\u9898\uff0c\u5305\u62ec\u8bc4\u5206\u5c3a\u5ea6\u4e0d\u4e00\u81f4\u6027\u548c\u4f4d\u7f6e\u504f\u5dee\u7b49\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2602.19098", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19098", "abs": "https://arxiv.org/abs/2602.19098", "authors": ["Negar Hashemi", "Amjed Tahir", "August Shi", "Shawn Rasheed", "Rachel Blagojevic"], "title": "A Systematic Evaluation of Environmental Flakiness in JavaScript Tests", "comment": "Accepted at ICST 2026", "summary": "Test flakiness is a significant issue in industry, affecting test efficiency and product quality. While extensive research has examined the impact of flaky tests, many root causes remain unexplored, particularly in the context of dynamic languages such as JavaScript. In this paper, we conduct a systematic evaluation of the impact of environmental factors on test flakiness in JavaScript. We first executed test suites across multiple environmental configurations to determine whether changes in the environment could lead to flaky behavior. We selected three environmental factors to manipulate: the operating system, the Node.js version, and the browser. We identified a total of 65 environmental flaky projects, with 28 related to operating system issues, five to Node.js version compatibility, 16 to a combination of operating system and Node.js issues, and 17 related to browser compatibility. To address environmental flakiness, we developed a lightweight mitigation approach, js-env-sanitizer, that can sanitize environmental-related flaky tests by skipping and reporting them (rather than failing), allowing CI builds to continue/succeed without rerunning entire test suites. The tool achieves high accuracy with minimal performance or configuration overhead, and currently supports three popular JavaScript testing frameworks (Jest, Mocha, and Vitest)", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u73af\u5883\u56e0\u7d20\uff08\u64cd\u4f5c\u7cfb\u7edf\u3001Node.js\u7248\u672c\u548c\u6d4f\u89c8\u5668\uff09\u5bf9JavaScript\u6d4b\u8bd5\u6ce2\u52a8\u6027\u7684\u5f71\u54cd\uff0c\u786e\u5b9a\u4e8665\u4e2a\u53d7\u73af\u5883\u5f71\u54cd\u7684\u6ce2\u52a8\u9879\u76ee\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848js-env-sanitizer\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u6d4b\u8bd5\u6ce2\u52a8\u6027\u662f\u5de5\u4e1a\u754c\u7684\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\uff0c\u5b83\u5f71\u54cd\u6d4b\u8bd5\u6548\u7387\u548c\u4ea7\u54c1\u8d28\u91cf\u3002\u5c3d\u7ba1\u5df2\u6709\u5927\u91cf\u7814\u7a76\u63a2\u8ba8\u4e86\u6ce2\u52a8\u6d4b\u8bd5\u7684\u5f71\u54cd\uff0c\u4f46\u8bb8\u591a\u6839\u672c\u539f\u56e0\u5c1a\u672a\u88ab\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u50cfJavaScript\u8fd9\u6837\u7684\u52a8\u6001\u8bed\u8a00\u4e2d\u3002", "method": "\u9996\u5148\u5728\u591a\u79cd\u73af\u5883\u914d\u7f6e\u4e0b\u6267\u884c\u6d4b\u8bd5\u5957\u4ef6\uff0c\u4ee5\u786e\u5b9a\u73af\u5883\u53d8\u5316\u662f\u5426\u4f1a\u5bfc\u81f4\u6ce2\u52a8\u884c\u4e3a\u3002\u9009\u53d6\u4e86\u4e09\u4e2a\u73af\u5883\u56e0\u7d20\u8fdb\u884c\u64cd\u4f5c\uff1a\u64cd\u4f5c\u7cfb\u7edf\u3001Node.js\u7248\u672c\u548c\u6d4f\u89c8\u5668\u3002\u57fa\u4e8e\u6b64\u5206\u6790\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3ajs-env-sanitizer\u7684\u5de5\u5177\uff0c\u80fd\u591f\u901a\u8fc7\u8df3\u8fc7\u5e76\u62a5\u544a\u4e0e\u73af\u5883\u76f8\u5173\u7684\u6ce2\u52a8\u6d4b\u8bd5\uff08\u800c\u4e0d\u662f\u8ba9\u5b83\u4eec\u5931\u8d25\uff09\uff0c\u4ece\u800c\u5141\u8bb8CI\u6784\u5efa\u7ee7\u7eed/\u6210\u529f\u800c\u65e0\u9700\u91cd\u65b0\u8fd0\u884c\u6574\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u603b\u5171\u8bc6\u522b\u51fa65\u4e2a\u56e0\u73af\u5883\u56e0\u7d20\u5bfc\u81f4\u6ce2\u52a8\u6027\u7684\u9879\u76ee\uff0c\u5176\u4e2d28\u4e2a\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\uff0c5\u4e2a\u4e0eNode.js\u7248\u672c\u517c\u5bb9\u6027\u6709\u5173\uff0c16\u4e2a\u540c\u65f6\u6d89\u53ca\u64cd\u4f5c\u7cfb\u7edf\u548cNode.js\u95ee\u9898\uff0c\u8fd8\u670917\u4e2a\u4e0e\u6d4f\u89c8\u5668\u517c\u5bb9\u6027\u6709\u5173\u3002\u63d0\u51fa\u7684js-env-sanitizer\u5de5\u5177\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\uff0c\u4e14\u6027\u80fd\u6216\u914d\u7f6e\u5f00\u9500\u6781\u5c0f\uff0c\u5f53\u524d\u652f\u6301\u4e09\u79cd\u6d41\u884c\u7684JavaScript\u6d4b\u8bd5\u6846\u67b6\uff08Jest\u3001Mocha\u548cVitest\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u73af\u5883\u56e0\u7d20\u663e\u8457\u5f71\u54cdJavaScript\u9879\u76ee\u7684\u6d4b\u8bd5\u6ce2\u52a8\u6027\u3002\u4e3a\u6b64\uff0cjs-env-sanitizer\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u624b\u6bb5\u6765\u51cf\u8f7b\u8fd9\u7c7b\u95ee\u9898\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u4e2d\u7684\u6d4b\u8bd5\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.18581", "categories": ["cs.LG", "cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18581", "abs": "https://arxiv.org/abs/2602.18581", "authors": ["Sheng Ran"], "title": "Learning Beyond Optimization: Stress-Gated Dynamical Regime Regulation in Autonomous Systems", "comment": null, "summary": "Despite their apparent diversity, modern machine learning methods can be reduced to a remarkably simple core principle: learning is achieved by continuously optimizing parameters to minimize or maximize a scalar objective function. This paradigm has been extraordinarily successful for well-defined tasks where goals are fixed and evaluation criteria are explicit. However, if artificial systems are to move toward true autonomy-operating over long horizons and across evolving contexts-objectives may become ill-defined, shifting, or entirely absent. In such settings, a fundamental question emerges: in the absence of an explicit objective function, how can a system determine whether its ongoing internal dynamics are productive or pathological? And how should it regulate structural change without external supervision? In this work, we propose a dynamical framework for learning without an explicit objective. Instead of minimizing external error signals, the system evaluates the intrinsic health of its own internal dynamics and regulates structural plasticity accordingly. We introduce a two-timescale architecture that separates fast state evolution from slow structural adaptation, coupled through an internally generated stress variable that accumulates evidence of persistent dynamical dysfunction. Structural modification is then triggered not continuously, but as a state-dependent event. Through a minimal toy model, we demonstrate that this stress-regulated mechanism produces temporally segmented, self-organized learning episodes without reliance on externally defined goals. Our results suggest a possible route toward autonomous learning systems capable of self-assessment and internally regulated structural reorganization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u660e\u786e\u76ee\u6807\u51fd\u6570\u7684\u5b66\u4e60\u52a8\u6001\u6846\u67b6\uff0c\u7cfb\u7edf\u901a\u8fc7\u8bc4\u4f30\u81ea\u8eab\u5185\u90e8\u52a8\u6001\u7684\u5185\u5728\u5065\u5eb7\u72b6\u51b5\u6765\u8c03\u8282\u7ed3\u6784\u53ef\u5851\u6027\u3002\u5f15\u5165\u4e86\u53cc\u65f6\u95f4\u5c3a\u5ea6\u67b6\u6784\uff0c\u5c06\u5feb\u901f\u72b6\u6001\u6f14\u5316\u4e0e\u6162\u901f\u7ed3\u6784\u9002\u5e94\u533a\u5206\u5f00\u6765\uff0c\u5e76\u901a\u8fc7\u5185\u90e8\u751f\u6210\u7684\u538b\u529b\u53d8\u91cf\u89e6\u53d1\u72b6\u6001\u4f9d\u8d56\u6027\u7684\u7ed3\u6784\u4fee\u6539\u4e8b\u4ef6\uff0c\u4ece\u800c\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u5b9a\u4e49\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u81ea\u6211\u7ec4\u7ec7\u7684\u5b66\u4e60\u9636\u6bb5\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5411\u771f\u6b63\u7684\u81ea\u4e3b\u6027\u8fc8\u8fdb\uff0c\u5728\u957f\u65f6\u95f4\u8de8\u5ea6\u548c\u4e0d\u65ad\u53d8\u5316\u7684\u60c5\u5883\u4e0b\u8fd0\u4f5c\u65f6\uff0c\u76ee\u6807\u53ef\u80fd\u4f1a\u53d8\u5f97\u6a21\u7cca\u3001\u53d8\u5316\u6216\u5b8c\u5168\u7f3a\u5931\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u5728\u6ca1\u6709\u660e\u786e\u76ee\u6807\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u7cfb\u7edf\u5982\u4f55\u5224\u65ad\u5176\u6b63\u5728\u8fdb\u884c\u7684\u5185\u90e8\u52a8\u6001\u662f\u6709\u6548\u7684\u8fd8\u662f\u75c5\u6001\u7684\uff1f\u4ee5\u53ca\u5b83\u5e94\u8be5\u5982\u4f55\u5728\u7f3a\u4e4f\u5916\u90e8\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u8c03\u8282\u7ed3\u6784\u53d8\u5316\uff1f", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u76ee\u6807\u51fd\u6570\u3002\u7cfb\u7edf\u4e0d\u662f\u6700\u5c0f\u5316\u5916\u90e8\u9519\u8bef\u4fe1\u53f7\uff0c\u800c\u662f\u8bc4\u4f30\u81ea\u5df1\u5185\u90e8\u52a8\u6001\u7684\u5185\u5728\u5065\u5eb7\u72b6\u51b5\uff0c\u5e76\u636e\u6b64\u8c03\u6574\u7ed3\u6784\u53ef\u5851\u6027\u3002\u4e3a\u6b64\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u53cc\u65f6\u95f4\u5c3a\u5ea6\u67b6\u6784\uff0c\u5176\u4e2d\u5feb\u901f\u72b6\u6001\u6f14\u53d8\u4e0e\u7f13\u6162\u7684\u7ed3\u6784\u6027\u9002\u5e94\u8fc7\u7a0b\u76f8\u5206\u79bb\uff0c\u5e76\u4e14\u8fd9\u4e24\u4e2a\u8fc7\u7a0b\u901a\u8fc7\u4e00\u4e2a\u5185\u90e8\u4ea7\u751f\u7684\u538b\u529b\u53d8\u91cf\u8054\u7cfb\u8d77\u6765\uff0c\u8be5\u53d8\u91cf\u7d2f\u79ef\u4e86\u6301\u7eed\u52a8\u529b\u5b66\u529f\u80fd\u969c\u788d\u7684\u8bc1\u636e\u3002\u7ed3\u6784\u6539\u53d8\u4e0d\u518d\u662f\u8fde\u7eed\u53d1\u751f\u7684\uff0c\u800c\u662f\u4f5c\u4e3a\u4e00\u4e2a\u72b6\u6001\u4f9d\u8d56\u4e8b\u4ef6\u88ab\u89e6\u53d1\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u6781\u7b80\u73a9\u5177\u6a21\u578b\u8bc1\u660e\uff0c\u8fd9\u79cd\u7531\u538b\u529b\u8c03\u8282\u7684\u673a\u5236\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u4e8e\u5916\u90e8\u5b9a\u4e49\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u5206\u6bb5\u7684\u3001\u81ea\u7ec4\u7ec7\u7684\u5b66\u4e60\u9636\u6bb5\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u57fa\u4e8e\u538b\u529b\u8c03\u8282\u673a\u5236\u7684\u65b9\u6cd5\u53ef\u4ee5\u4e3a\u5f00\u53d1\u80fd\u591f\u81ea\u6211\u8bc4\u4f30\u5e76\u8fdb\u884c\u5185\u90e8\u8c03\u8282\u7ed3\u6784\u91cd\u7ec4\u7684\u81ea\u4e3b\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e00\u79cd\u53ef\u80fd\u8def\u5f84\u3002"}}
{"id": "2602.20097", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.20097", "abs": "https://arxiv.org/abs/2602.20097", "authors": ["Pu Jiao", "Sheng Di", "Jiannan Tian", "Mingze Xia", "Xuan Wu", "Yang Zhang", "Xin Liang", "Franck Cappello"], "title": "Mitigating Artifacts in Pre-quantization Based Scientific Data Compressors with Quantization-aware Interpolation", "comment": null, "summary": "Error-bounded lossy compression has been regarded as a promising way to address the ever-increasing amount of scientific data in today's high-performance computing systems. Pre-quantization, a critical technique to remove sequential dependency and enable high parallelism, is widely used to design and develop high-throughput error-controlled data compressors. Despite the extremely high throughput of pre-quantization based compressors, they generally suffer from low data quality with medium or large user-specified error bounds. In this paper, we investigate the artifacts generated by pre-quantization based compressors and propose a novel algorithm to mitigate them. Our contributions are fourfold: (1) We carefully characterize the artifacts in pre-quantization based compressors to understand the correlation between the quantization index and compression error; (2) We propose a novel quantization-aware interpolation algorithm to improve the decompressed data; (3) We parallelize our algorithm in both shared-memory and distributed-memory environments to obtain high performance; (4) We evaluate our algorithm and validate it with two leading pre-quantization based compressors using five real-world datasets. Experiments demonstrate that our artifact mitigation algorithm can effectively improve the quality of decompressed data produced by pre-quantization based compressors while maintaining their high compression throughput.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u9884\u91cf\u5316\u7684\u538b\u7f29\u5668\u4ea7\u751f\u7684\u4f2a\u5f71\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u6765\u51cf\u8f7b\u8fd9\u4e9b\u4f2a\u5f71\uff0c\u4ece\u800c\u63d0\u9ad8\u89e3\u538b\u7f29\u6570\u636e\u7684\u8d28\u91cf\u540c\u65f6\u4fdd\u6301\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u57fa\u4e8e\u9884\u91cf\u5316\u7684\u538b\u7f29\u5668\u867d\u7136\u80fd\u5b9e\u73b0\u6781\u9ad8\u541e\u5410\u91cf\uff0c\u4f46\u5728\u4e2d\u7b49\u6216\u8f83\u5927\u7528\u6237\u6307\u5b9a\u8bef\u5dee\u754c\u9650\u4e0b\u901a\u5e38\u4f1a\u9047\u5230\u6570\u636e\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u7814\u7a76\u4e86\u7531\u8fd9\u79cd\u538b\u7f29\u65b9\u5f0f\u5bfc\u81f4\u7684\u4f2a\u5f71\u5e76\u5bfb\u6c42\u6539\u5584\u65b9\u6cd5\u3002", "method": "1. \u8be6\u7ec6\u63cf\u8ff0\u4e86\u57fa\u4e8e\u9884\u91cf\u5316\u538b\u7f29\u5668\u4e2d\u7684\u4f2a\u5f71\u7279\u5f81\uff0c\u4ee5\u7406\u89e3\u91cf\u5316\u7d22\u5f15\u4e0e\u538b\u7f29\u9519\u8bef\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\n2. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u91cf\u5316\u611f\u77e5\u63d2\u503c\u7b97\u6cd5\u6765\u6539\u8fdb\u89e3\u538b\u7f29\u540e\u7684\u6570\u636e\u8d28\u91cf\u3002\n3. \u5728\u5171\u4eab\u5185\u5b58\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u73af\u5883\u4e2d\u5bf9\u63d0\u51fa\u7684\u7b97\u6cd5\u8fdb\u884c\u4e86\u5e76\u884c\u5316\u5904\u7406\uff0c\u4ee5\u83b7\u5f97\u9ad8\u6027\u80fd\u8868\u73b0\u3002\n4. \u5229\u7528\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u5bf9\u7b97\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4e24\u79cd\u9886\u5148\u7684\u57fa\u4e8e\u9884\u91cf\u5316\u7684\u538b\u7f29\u5668\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f2a\u5f71\u7f13\u89e3\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5730\u63d0\u9ad8\u57fa\u4e8e\u9884\u91cf\u5316\u538b\u7f29\u5668\u751f\u6210\u7684\u89e3\u538b\u7f29\u6570\u636e\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u7ef4\u6301\u5176\u8f83\u9ad8\u7684\u538b\u7f29\u541e\u5410\u91cf\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u51cf\u5c11\u57fa\u4e8e\u9884\u91cf\u5316\u538b\u7f29\u6280\u672f\u6240\u4ea7\u751f\u7684\u8d1f\u9762\u5f71\u54cd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5728\u4e0d\u5f71\u54cd\u538b\u7f29\u901f\u5ea6\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u4e86\u6570\u636e\u8d28\u91cf\u3002"}}
{"id": "2602.19987", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.19987", "abs": "https://arxiv.org/abs/2602.19987", "authors": ["Ha-Anh Hoang Nguyen", "Tri-Duc Phan Le", "Duc-Hoang Pham", "Huy-Son Nguyen", "Cam-Van Thi Nguyen", "Duc-Trong Le", "Hoang-Quynh Le"], "title": "Counterfactual Understanding via Retrieval-aware Multimodal Modeling for Time-to-Event Survival Prediction", "comment": null, "summary": "This paper tackles the problem of time-to-event counterfactual survival prediction, aiming to optimize individualized survival outcomes in the presence of heterogeneity and censored data. We propose CURE, a framework that advances counterfactual survival modeling via comprehensive multimodal embedding and latent subgroup retrieval. CURE integrates clinical, paraclinical, demographic, and multi-omics information, which are aligned and fused through cross-attention mechanisms. Complex multi-omics signals can be adaptively refined using a mixture-of-experts architecture, emphasizing the most informative omics components. Building upon this representation, CURE implicitly retrieves patient-specific latent subgroups that capture both baseline survival dynamics and treatment-dependent variations. Experimental results on METABRIC and TCGA-LUAD datasets demonstrate that proposed CURE model consistently outperforms strong baselines in survival analysis, evaluated using the Time-dependent Concordance Index ($C^{td}$) and Integrated Brier Score (IBS). These findings highlight the potential of CURE to enhance multimodal understanding and serve as a foundation for future treatment recommendation models. All code and related resources are publicly available to facilitate the reproducibility https://github.com/L2R-UET/CURE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCURE\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u65f6\u95f4\u5230\u4e8b\u4ef6\u53cd\u4e8b\u5b9e\u751f\u5b58\u9884\u6d4b\u95ee\u9898\u3002\u901a\u8fc7\u7efc\u5408\u591a\u6a21\u6001\u5d4c\u5165\u548c\u6f5c\u5728\u5b50\u7fa4\u68c0\u7d22\uff0cCURE\u80fd\u591f\u96c6\u6210\u4e34\u5e8a\u3001\u526f\u4e34\u5e8a\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u53ca\u591a\u7ec4\u5b66\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u5bf9\u9f50\u4e0e\u878d\u5408\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCURE\u6a21\u578b\u5728METABRIC\u548cTCGA-LUAD\u6570\u636e\u96c6\u4e0a\u7684\u751f\u5b58\u5206\u6790\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u9762\u5bf9\u5b58\u5728\u5f02\u8d28\u6027\u548c\u5220\u5931\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u4e2a\u4f53\u5316\u751f\u5b58\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u73b0\u6709\u7684\u751f\u5b58\u5206\u6790\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86CURE\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5168\u9762\u7684\u591a\u6a21\u6001\u5d4c\u5165\u548c\u6f5c\u5728\u5b50\u7fa4\u68c0\u7d22\u6765\u63a8\u8fdb\u53cd\u4e8b\u5b9e\u751f\u5b58\u5efa\u6a21\u3002CURE\u6574\u5408\u4e86\u591a\u79cd\u7c7b\u578b\u7684\u4fe1\u606f\uff0c\u5e76\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u4e86\u5bf9\u9f50\u4e0e\u878d\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86\u4e00\u4e2a\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u6765\u9002\u5e94\u6027\u5730\u7cbe\u70bc\u590d\u6742\u7684\u591a\u7ec4\u5b66\u4fe1\u53f7\u3002", "result": "\u5728METABRIC\u548cTCGA-LUAD\u6570\u636e\u96c6\u4e0a\uff0cCURE\u6a21\u578b\u5728\u751f\u5b58\u5206\u6790\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u8fd9\u901a\u8fc7\u65f6\u95f4\u4f9d\u8d56\u4e00\u81f4\u6027\u6307\u6570\uff08$C^{td}$\uff09\u548c\u7efc\u5408\u5e03\u91cc\u5c14\u5206\u6570\uff08IBS\uff09\u8fdb\u884c\u8bc4\u4f30\u5f97\u4ee5\u8bc1\u660e\u3002", "conclusion": "CURE\u5c55\u793a\u4e86\u5176\u5728\u589e\u5f3a\u591a\u6a21\u6001\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u53ef\u4f5c\u4e3a\u672a\u6765\u6cbb\u7597\u63a8\u8350\u6a21\u578b\u7684\u57fa\u7840\u3002\u6240\u6709\u4ee3\u7801\u53ca\u76f8\u5173\u8d44\u6e90\u5747\u5df2\u516c\u5f00\uff0c\u4ee5\u4fc3\u8fdb\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2602.19218", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.19218", "abs": "https://arxiv.org/abs/2602.19218", "authors": ["Zeyu Zhang", "Guohao Li", "Zhenchang Xing", "Alexandros Apostolopoulos", "Yu Lin Lee", "Liang Zheng"], "title": "Gecko: A Simulation Environment with Stateful Feedback for Refining Agent Tool Calls", "comment": null, "summary": "The ability to use tools is fundamental for large language model (LLM) agents. Given a task, existing systems use LLMs to plan and generate tool calls, which are executed by real-world tools to complete the task. However, tool calls are prone to errors because they are derived merely from LLM intrinsic capabilities. What is more, while it is useful to let LLMs iteratively refine the tool-call sequence using execution results from real tools, this process can be expensive and lead to unsafe results. To improve LLM tool calls and address issues caused by using real tools for refinement, we introduce Gecko, a comprehensive environment that simulates tool responses using a combination of rules and LLMs. Specifically, Gecko checks the validity of tool calls including input arguments and tool names, synthesizes reasonable responses that adhere to the output schema, and assesses whether all task objectives have been achieved. These three types of feedback provided by Gecko allow LLMs to refine their tool calls, forming a simple yet effective test-time scaling method named GATS. On BFCLv3 and $\u03c4^2$-bench, GATS consistently improves the tool calling performance of various LLMs including GPT-4o, GPT-5, and Gemini-3.0-pro. We further discuss working mechanisms of our method and share future possibilities.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86Gecko\uff0c\u4e00\u4e2a\u7efc\u5408\u73af\u5883\uff0c\u7528\u4e8e\u6a21\u62df\u5de5\u5177\u54cd\u5e94\uff0c\u4ee5\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5de5\u5177\u8c03\u7528\uff0c\u5e76\u89e3\u51b3\u4f7f\u7528\u771f\u5b9e\u5de5\u5177\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u65f6\u51fa\u73b0\u7684\u95ee\u9898\u3002\u901a\u8fc7\u63d0\u4f9b\u4e09\u79cd\u7c7b\u578b\u7684\u53cd\u9988\uff0cGecko\u5141\u8bb8LLMs\u4f18\u5316\u5176\u5de5\u5177\u8c03\u7528\uff0c\u8fdb\u800c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGATS\u7684\u6709\u6548\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u57fa\u51c6\u4e0aGATS\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2aLLM\u7248\u672c\u7684\u5de5\u5177\u8c03\u7528\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7cfb\u7edf\u4f9d\u8d56\u4e8eLLMs\u6765\u8ba1\u5212\u548c\u751f\u6210\u5de5\u5177\u8c03\u7528\u4ee5\u5b8c\u6210\u4efb\u52a1\uff0c\u4f46\u8fd9\u4e9b\u8c03\u7528\u5bb9\u6613\u51fa\u9519\u4e14\u4ec5\u57fa\u4e8eLLM\u81ea\u8eab\u80fd\u529b\u3002\u867d\u7136\u8ba9LLMs\u6839\u636e\u5b9e\u9645\u5de5\u5177\u6267\u884c\u7ed3\u679c\u8fed\u4ee3\u5730\u5b8c\u5584\u5de5\u5177\u8c03\u7528\u5e8f\u5217\u662f\u6709\u5e2e\u52a9\u7684\uff0c\u4f46\u8fd9\u8fc7\u7a0b\u53ef\u80fd\u6210\u672c\u9ad8\u6602\u5e76\u5bfc\u81f4\u4e0d\u5b89\u5168\u7684\u7ed3\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8LLM\u5de5\u5177\u8c03\u7528\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u771f\u5b9e\u5de5\u5177\u4f9d\u8d56\u6240\u5e26\u6765\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86Gecko\uff0c\u8fd9\u662f\u4e00\u4e2a\u7ed3\u5408\u89c4\u5219\u4e0eLLMs\u6765\u6a21\u62df\u5de5\u5177\u54cd\u5e94\u7684\u73af\u5883\u3002Gecko\u80fd\u591f\u68c0\u67e5\u5de5\u5177\u8c03\u7528\u7684\u6709\u6548\u6027\u3001\u5408\u6210\u7b26\u5408\u8f93\u51fa\u6a21\u5f0f\u7684\u5408\u7406\u54cd\u5e94\uff0c\u5e76\u8bc4\u4f30\u662f\u5426\u6240\u6709\u4efb\u52a1\u76ee\u6807\u90fd\u5df2\u8fbe\u6210\u3002\u57fa\u4e8eGecko\u63d0\u4f9b\u7684\u8fd9\u4e09\u7c7b\u53cd\u9988\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u65b9\u6cd5GATS\uff0c\u7528\u4e8e\u5e2e\u52a9LLMs\u4f18\u5316\u5b83\u4eec\u7684\u5de5\u5177\u8c03\u7528\u3002", "result": "\u5728BFCLv3\u548c$\u03c4^2$-bench\u4e24\u4e2a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGATS\u6301\u7eed\u63d0\u9ad8\u4e86\u5305\u62ecGPT-4o, GPT-5\u4ee5\u53caGemini-3.0-pro\u5728\u5185\u7684\u591a\u79cdLLM\u7684\u5de5\u5177\u8c03\u7528\u8868\u73b0\u3002", "conclusion": "Gecko\u53ca\u5176\u76f8\u5173\u65b9\u6cd5GATS\u4e3a\u6539\u5584LLM\u7684\u5de5\u5177\u8c03\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\uff0c\u4e0d\u4ec5\u51cf\u5c11\u4e86\u5bf9\u771f\u5b9e\u5de5\u5177\u76f4\u63a5\u4f7f\u7528\u7684\u4f9d\u8d56\uff0c\u800c\u4e14\u901a\u8fc7\u63d0\u4f9b\u8be6\u7ec6\u7684\u53cd\u9988\u4fe1\u606f\u4fc3\u8fdb\u4e86LLM\u5de5\u5177\u8c03\u7528\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u63d0\u5347\u3002\u6b64\u5916\uff0c\u8be5\u5de5\u4f5c\u8fd8\u8ba8\u8bba\u4e86\u65b9\u6cd5\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2602.18584", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.18584", "abs": "https://arxiv.org/abs/2602.18584", "authors": ["Guanghui Min", "Tianhao Huang", "Ke Wan", "Chen Chen"], "title": "GIST: Targeted Data Selection for Instruction Tuning via Coupled Optimization Geometry", "comment": "27 pages, 8 figures, 11 tables", "summary": "Targeted data selection has emerged as a crucial paradigm for efficient instruction tuning, aiming to identify a small yet influential subset of training examples for a specific target task. In practice, influence is often measured through the effect of an example on parameter updates. To make selection scalable, many approaches leverage optimizer statistics (e.g., Adam states) as an axis-aligned surrogate for update geometry (i.e., diagonal precondition), implicitly treating parameters as coordinate-wise independent. We show that this assumption breaks down in parameter-efficient fine-tuning (PEFT) methods such as LoRA. In this setting, the induced optimization geometry exhibits strong cross-parameter coupling with non-trivial off-diagonal interactions, while the task-relevant update directions are confined to a low-dimensional subspace. Motivated by this mismatch, we propose GIST (Gradient Isometric Subspace Transformation), a simple yet principled alternative that replaces axis-aligned scaling with robust subspace alignment. GIST recovers a task-specific subspace from validation gradients via spectral filtering (SVD), projects training gradients into this coupled subspace, and scores examples by their alignment with target directions.Extensive experiments have demonstrated that GIST matches or outperforms the state-of-the-art baseline with only 0.29% of the storage and 25% of the computational time under the same selection budget.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGIST\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u573a\u666f\u4e2d\u9009\u62e9\u6709\u5f71\u54cd\u529b\u7684\u6570\u636e\u5b50\u96c6\u3002GIST\u901a\u8fc7\u4ece\u9a8c\u8bc1\u68af\u5ea6\u6062\u590d\u4efb\u52a1\u7279\u5b9a\u5b50\u7a7a\u95f4\uff0c\u5e76\u5c06\u8bad\u7ec3\u68af\u5ea6\u6295\u5f71\u5230\u8be5\u5b50\u7a7a\u95f4\u6765\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u6570\u636e\u9009\u62e9\uff0c\u4ece\u800c\u5728\u76f8\u540c\u7684\u9884\u7b97\u4e0b\u4ee5\u6781\u4f4e\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\u5339\u914d\u6216\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u53c2\u6570\u4e4b\u95f4\u662f\u5750\u6807\u72ec\u7acb\u7684\uff0c\u8fd9\u79cd\u5047\u8bbe\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08\u5982LoRA\uff09\u4e2d\u4e0d\u6210\u7acb\uff0c\u56e0\u4e3a\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4f18\u5316\u51e0\u4f55\u8868\u73b0\u51fa\u5f3a\u53c2\u6570\u8026\u5408\u4ee5\u53ca\u975e\u5bf9\u89d2\u7ebf\u4ea4\u4e92\u4f5c\u7528\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86GIST\u65b9\u6cd5\u3002", "method": "GIST\u91c7\u7528\u68af\u5ea6\u7b49\u8ddd\u5b50\u7a7a\u95f4\u53d8\u6362\u6280\u672f\uff0c\u9996\u5148\u901a\u8fc7\u5947\u5f02\u503c\u5206\u89e3(SVD)\u4ece\u9a8c\u8bc1\u68af\u5ea6\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7684\u5b50\u7a7a\u95f4\uff1b\u7136\u540e\u5c06\u8bad\u7ec3\u68af\u5ea6\u6620\u5c04\u5230\u8fd9\u4e2a\u5b50\u7a7a\u95f4\u5185\uff1b\u6700\u540e\u4f9d\u636e\u6837\u672c\u4e0e\u76ee\u6807\u65b9\u5411\u7684\u4e00\u81f4\u6027\u5bf9\u5176\u8fdb\u884c\u8bc4\u5206\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u76f8\u540c\u7684\u9009\u62e9\u9884\u7b97\u6761\u4ef6\u4e0b\uff0cGIST\u4e0d\u4ec5\u80fd\u591f\u8fbe\u5230\u6216\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6c34\u5e73\uff0c\u800c\u4e14\u53ea\u9700\u8981\u540e\u80050.29%\u7684\u5b58\u50a8\u7a7a\u95f4\u548c25%\u7684\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "GIST\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u539f\u5219\u6027\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u9c81\u68d2\u5b50\u7a7a\u95f4\u5bf9\u9f50\u4ee3\u66ff\u8f74\u5411\u7f29\u653e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u8de8\u53c2\u6570\u8026\u5408\u95ee\u9898\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u6240\u9700\u7684\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.19276", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19276", "abs": "https://arxiv.org/abs/2602.19276", "authors": ["Jingyu Xiao", "Jiantong Qin", "Shuoqi Li", "Man Ho Lam", "Yuxuan Wan", "Jen-tse Huang", "Yintong Huo", "Michael R. Lyu"], "title": "ComUICoder: Component-based Reusable UI Code Generation for Complex Websites via Semantic Segmentation and Element-wise Feedback", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated strong performance on the UI-to-code task, which aims to generate UI code from design mock-ups. However, when applied to long and complex websites, they often struggle with fragmented segmentation, redundant code generation for repetitive components, and frequent UI inconsistencies. To systematically investigate and address these challenges, we introduce ComUIBench, a new multi-page complex webpage benchmark with component annotations, designed to evaluate MLLMs' ability to generate reusable UI code in realistic website scenarios. Building upon this benchmark, we propose ComUICoder, a component-based UI code generation framework that emphasizes semantic-aware segmentation, code reuse, and fine-grained refinement. Specifically, ComUICoder incorporates (1) Hybrid Semantic-aware Block Segmentation for accurate UI semantic coherent block detection, (2) Visual-aware Graph-based Block Merge to consolidate structurally similar components within and across webpages for reusable implementation, and (3) Priority-based Element-wise Feedback to refine generated code and reduce element-level inconsistencies. Extensive experiments demonstrate that ComUICoder significantly improves overall generation quality and code reusability on complex multipage websites. Our datasets and code are publicly available at https://github.com/WebPAI/ComUICoder.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u9875\u9762\u590d\u6742\u7f51\u9875\u57fa\u51c6ComUIBench\uff0c\u4ee5\u53ca\u4e00\u79cd\u57fa\u4e8e\u7ec4\u4ef6\u7684UI\u4ee3\u7801\u751f\u6210\u6846\u67b6ComUICoder\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709MLLMs\u5728\u5904\u7406\u957f\u4e14\u590d\u6742\u7684\u7f51\u7ad9\u65f6\u9047\u5230\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u6df7\u5408\u8bed\u4e49\u611f\u77e5\u5757\u5206\u5272\u3001\u89c6\u89c9\u611f\u77e5\u56fe\u57fa\u5757\u5408\u5e76\u548c\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u5143\u7d20\u53cd\u9988\u673a\u5236\uff0cComUICoder\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u591a\u9875\u9762\u7f51\u7ad9\u7684\u6574\u4f53\u751f\u6210\u8d28\u91cf\u548c\u4ee3\u7801\u590d\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u867d\u7136\u5728UI-to-code\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u957f\u4e14\u590d\u6742\u7684\u7f51\u7ad9\u65f6\uff0c\u5b58\u5728\u7247\u6bb5\u5316\u5206\u5272\u3001\u91cd\u590d\u7ec4\u4ef6\u5197\u4f59\u4ee3\u7801\u751f\u6210\u53ca\u9891\u7e41\u51fa\u73b0\u7684UI\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u3002\u4e3a\u4e86\u7cfb\u7edf\u5730\u7814\u7a76\u5e76\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u5f15\u5165\u4e86ComUIBench\uff0c\u4e00\u4e2a\u5e26\u6709\u7ec4\u4ef6\u6ce8\u91ca\u7684\u65b0\u591a\u9875\u590d\u6742\u7f51\u9875\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30MLLMs\u5728\u5b9e\u9645\u7f51\u7ad9\u573a\u666f\u4e2d\u751f\u6210\u53ef\u590d\u7528UI\u4ee3\u7801\u7684\u80fd\u529b\u3002\n2. \u63d0\u51fa\u4e86ComUICoder\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5f3a\u8c03\u8bed\u4e49\u611f\u77e5\u5206\u5272\u3001\u4ee3\u7801\u91cd\u7528\u548c\u7ec6\u7c92\u5ea6\u4f18\u5316\u3002\u5177\u4f53\u5305\u62ec\uff1a\n   - \u6df7\u5408\u8bed\u4e49\u611f\u77e5\u5757\u5206\u5272\n   - \u89c6\u89c9\u611f\u77e5\u56fe\u57fa\u5757\u5408\u5e76\n   - \u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u5143\u7d20\u7ea7\u53cd\u9988", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cComUICoder\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5bf9\u590d\u6742\u591a\u9875\u9762\u7f51\u7ad9\u7684\u6574\u4f53\u751f\u6210\u8d28\u91cf\u4e0e\u4ee3\u7801\u53ef\u590d\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684ComUIBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cComUICoder\u6846\u67b6\uff0c\u672c\u6587\u4e3a\u6539\u5584MLLMs\u5728\u5904\u7406\u590d\u6742\u591a\u9875\u9762\u7f51\u7ad9\u65f6\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u589e\u5f3a\u4ee3\u7801\u7684\u4e00\u81f4\u6027\u548c\u53ef\u590d\u7528\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2602.19294", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19294", "abs": "https://arxiv.org/abs/2602.19294", "authors": ["Bet\u00fcl Karag\u00f6z", "Filippo Ricca", "Matteo Biagiola", "Andrea Stocco"], "title": "Towards Automated Page Object Generation for Web Testing using Large Language Models", "comment": "In proceedings of the 19th IEEE International Conference on Software Testing, Verification and Validation 2026 (ICST '26)", "summary": "Page Objects (POs) are a widely adopted design pattern for improving the maintainability and scalability of automated end-to-end web tests. However, creating and maintaining POs is still largely a manual, labor-intensive activity, while automated solutions have seen limited practical adoption. In this context, the potential of Large Language Models (LLMs) for these tasks has remained largely unexplored. This paper presents an empirical study on the feasibility of using LLMs, specifically GPT-4o and DeepSeek Coder, to automatically generate POs for web testing. We evaluate the generated artifacts on an existing benchmark of five web applications for which manually written POs are available (the ground truth), focusing on accuracy (i.e., the proportion of ground truth elements correctly identified) and element recognition rate (i.e., the proportion of ground truth elements correctly identified or marked for modification). Our results show that LLMs can generate syntactically correct and functionally useful POs with accuracy values ranging from 32.6% to 54.0% and element recognition rate exceeding 70% in most cases. Our study contributes the first systematic evaluation of LLMs strengths and open challenges for automated PO generation, and provides directions for further research on integrating LLMs into practical testing workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u7279\u522b\u662fGPT-4o\u548cDeepSeek Coder\u81ea\u52a8\u751f\u6210\u7f51\u9875\u6d4b\u8bd5\u7684\u9875\u9762\u5bf9\u8c61\uff08POs\uff09\u7684\u53ef\u80fd\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u4ee532.6%\u523054.0%\u7684\u51c6\u786e\u7387\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u4e14\u529f\u80fd\u4e0a\u6709\u7528\u7684POs\uff0c\u5e76\u4e14\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5143\u7d20\u8bc6\u522b\u7387\u8d85\u8fc770%\u3002", "motivation": "\u5c3d\u7ba1\u9875\u9762\u5bf9\u8c61(POs)\u662f\u63d0\u9ad8\u81ea\u52a8\u5316\u7aef\u5bf9\u7aef\u7f51\u9875\u6d4b\u8bd5\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u5e7f\u6cdb\u91c7\u7528\u7684\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u4f46\u521b\u5efa\u548c\u7ef4\u62a4POs\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u4f9d\u9760\u4eba\u5de5\u3001\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u8fc7\u7a0b\u3002\u800c\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u5b9e\u9645\u5e94\u7528\u6709\u9650\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u8fd9\u65b9\u9762\u7684\u6f5c\u529b\u8fd8\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u4e00\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u7279\u5b9a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578bGPT-4o\u548cDeepSeek Coder\u81ea\u52a8\u751f\u6210\u7528\u4e8e\u7f51\u9875\u6d4b\u8bd5\u7684POs\u7684\u80fd\u529b\u3002\u57fa\u4e8e\u4e94\u4e2a\u5df2\u6709\u624b\u52a8\u7f16\u5199POs\u4f5c\u4e3a\u57fa\u51c6\u7684\u771f\u5b9e\u7f51\u9875\u5e94\u7528\u7a0b\u5e8f\u6765\u8bc4\u4ef7\u751f\u6210\u7269\u7684\u8d28\u91cf\uff0c\u91cd\u70b9\u5173\u6ce8\u51c6\u786e\u6027\uff08\u5373\u6b63\u786e\u8bc6\u522b\u7684\u57fa\u51c6\u5143\u7d20\u7684\u6bd4\u4f8b\uff09\u548c\u5143\u7d20\u8bc6\u522b\u7387\uff08\u5373\u6b63\u786e\u8bc6\u522b\u6216\u6807\u8bb0\u4fee\u6539\u7684\u57fa\u51c6\u5143\u7d20\u6bd4\u4f8b\uff09\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u4e14\u529f\u80fd\u4e0a\u6709\u7528\u7684POs\uff0c\u5176\u51c6\u786e\u6027\u503c\u8303\u56f4\u4ece32.6%\u523054.0%\uff0c\u5e76\u4e14\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5143\u7d20\u8bc6\u522b\u7387\u8d85\u8fc770%\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u751f\u6210\u7f51\u9875\u6d4b\u8bd5\u7528\u9875\u9762\u5bf9\u8c61\u7684\u6f5c\u529b\uff0c\u4f46\u4e5f\u6307\u51fa\u4e86\u5f53\u524d\u5b58\u5728\u7684\u6311\u6218\u3002\u5b83\u4e3a\u672a\u6765\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u8fdb\u5b9e\u9645\u6d4b\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.19383", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19383", "abs": "https://arxiv.org/abs/2602.19383", "authors": ["Jens Dietrich", "Behnaz Hassanshahi"], "title": "On the Variability of Source Code in Maven Package Rebuilds", "comment": null, "summary": "Rebuilding packages from open source is a common practice to improve the security of software supply chains, and is now done at an industrial scale. The basic principle is to acquire the source code used to build a package published in a repository such as Maven Central (for Java), rebuild the package independently with hardened security, and publish it in some alternative repository. In this paper we test the assumption that the same source code is being used by those alternative builds. To study this, we compare the sources released with packages on Maven Central, with the sources associated with independently built packages from Google's Assured Open Source and Oracle's Build-from-Source projects. We study non-equivalent sources for alternative builds of 28 popular packages with 85 releases. We investigate the causes of non-equivalence, and find that the main cause is build extensions that generate code at build time, which are difficult to reproduce. We suggest strategies to address this issue.", "AI": {"tldr": "\u672c\u6587\u6d4b\u8bd5\u4e86\u5f00\u6e90\u8f6f\u4ef6\u5305\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u662f\u5426\u4f7f\u7528\u76f8\u540c\u7684\u6e90\u4ee3\u7801\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e3b\u8981\u7531\u4e8e\u6784\u5efa\u6269\u5c55\u5728\u6784\u5efa\u65f6\u751f\u6210\u4ee3\u7801\u96be\u4ee5\u91cd\u73b0\uff0c\u5bfc\u81f4\u66ff\u4ee3\u6784\u5efa\u7684\u6e90\u4ee3\u7801\u4e0d\u7b49\u6548\uff0c\u5e76\u63d0\u51fa\u4e86\u5e94\u5bf9\u7b56\u7565\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u5b89\u5168\u6027\uff0c\u4e1a\u754c\u666e\u904d\u91c7\u7528\u4ece\u6e90\u4ee3\u7801\u91cd\u65b0\u6784\u5efa\u5f00\u6e90\u8f6f\u4ef6\u5305\u7684\u505a\u6cd5\u3002\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e9b\u72ec\u7acb\u6784\u5efa\u662f\u5426\u771f\u7684\u57fa\u4e8e\u76f8\u540c\u7684\u6e90\u4ee3\u7801\u8fdb\u884c\u3002", "method": "\u6bd4\u8f83Maven Central\u4e0a\u53d1\u5e03\u7684\u8f6f\u4ef6\u5305\u968f\u9644\u7684\u6e90\u4ee3\u7801\u4e0eGoogle\u7684Assured Open Source\u548cOracle\u7684Build-from-Source\u9879\u76ee\u63d0\u4f9b\u7684\u72ec\u7acb\u6784\u5efa\u5173\u8054\u7684\u6e90\u4ee3\u7801\uff0c\u5206\u6790\u975e\u7b49\u6548\u6e90\u4ee3\u7801\u7684\u539f\u56e0\u3002", "result": "\u5bf9\u4e8e28\u4e2a\u6d41\u884c\u8f6f\u4ef6\u5305\u768485\u4e2a\u7248\u672c\u7684\u66ff\u4ee3\u6784\u5efa\u4e2d\u53d1\u73b0\u4e86\u6e90\u4ee3\u7801\u4e0d\u7b49\u6548\u7684\u60c5\u51b5\uff0c\u4e3b\u8981\u539f\u56e0\u5728\u4e8e\u6784\u5efa\u65f6\u751f\u6210\u4ee3\u7801\u7684\u6784\u5efa\u6269\u5c55\u96be\u4ee5\u590d\u5236\u3002", "conclusion": "\u867d\u7136\u5f00\u6e90\u8f6f\u4ef6\u5305\u7684\u91cd\u5efa\u6709\u52a9\u4e8e\u63d0\u5347\u5b89\u5168\u6027\uff0c\u4f46\u5b9e\u73b0\u5b8c\u5168\u4e00\u81f4\u6027\u7684\u6311\u6218\u4f9d\u7136\u5b58\u5728\uff0c\u7279\u522b\u662f\u5f53\u6d89\u53ca\u5230\u6784\u5efa\u671f\u95f4\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u7684\u6280\u672f\u65f6\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e9b\u7f13\u89e3\u8be5\u95ee\u9898\u7684\u7b56\u7565\u3002"}}
{"id": "2602.18639", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18639", "abs": "https://arxiv.org/abs/2602.18639", "authors": ["Leonardo F. Toso", "Davit Shadunts", "Yunyang Lu", "Nihal Sharma", "Donglin Zhan", "Nam H. Nguyen", "James Anderson"], "title": "Learning Invariant Visual Representations for Planning with Joint-Embedding Predictive World Models", "comment": null, "summary": "World models learned from high-dimensional visual observations allow agents to make decisions and plan directly in latent space, avoiding pixel-level reconstruction. However, recent latent predictive architectures (JEPAs), including the DINO world model (DINO-WM), display a degradation in test time robustness due to their sensitivity to \"slow features\". These include visual variations such as background changes and distractors that are irrelevant to the task being solved. We address this limitation by augmenting the predictive objective with a bisimulation encoder that enforces control-relevant state equivalence, mapping states with similar transition dynamics to nearby latent states while limiting contributions from slow features. We evaluate our model on a simple navigation task under different test-time background changes and visual distractors. Across all benchmarks, our model consistently improves robustness to slow features while operating in a reduced latent space, up to 10x smaller than that of DINO-WM. Moreover, our model is agnostic to the choice of pretrained visual encoder and maintains robustness when paired with DINOv2, SimDINOv2, and iBOT features.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u52a0\u4e00\u4e2a\u53cc\u6a21\u62df\u7f16\u7801\u5668\u6765\u6539\u8fdb\u6700\u8fd1\u7684\u6f5c\u5728\u9884\u6d4b\u67b6\u6784\uff08JEPAs\uff09\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u6162\u7279\u5f81\uff08\u5982\u80cc\u666f\u53d8\u5316\u548c\u89c6\u89c9\u5e72\u6270\uff09\u7684\u9c81\u68d2\u6027\u3002\u8be5\u6a21\u578b\u5728\u5bfc\u822a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u6bd4DINO\u4e16\u754c\u6a21\u578b\u5c0f\u5f97\u591a\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fd0\u884c\u3002\u6b64\u5916\uff0c\u5b83\u5bf9\u4e8e\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u7684\u9009\u62e9\u662f\u4e0d\u53ef\u77e5\u7684\uff0c\u4e0eDINOv2\u3001SimDINOv2\u548ciBOT\u7279\u5f81\u642d\u914d\u65f6\u4ecd\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u9ad8\u7ef4\u89c6\u89c9\u89c2\u5bdf\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\uff08\u5982DINO-WM\uff09\u5728\u6d4b\u8bd5\u65f6\u7531\u4e8e\u5bf9\u2018\u6162\u7279\u5f81\u2019\u654f\u611f\u800c\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0b\u964d\u3002\u8fd9\u4e9b\u6162\u7279\u5f81\u5305\u62ec\u80cc\u666f\u53d8\u5316\u548c\u4e0e\u89e3\u51b3\u4efb\u52a1\u65e0\u5173\u7684\u89c6\u89c9\u5e72\u6270\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u8fd9\u7c7b\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f5c\u8005\u7684\u65b9\u6cd5\u662f\u5728\u9884\u6d4b\u76ee\u6807\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u53cc\u6a21\u62df\u7f16\u7801\u5668\uff0c\u8be5\u7f16\u7801\u5668\u5b9e\u65bd\u4e86\u63a7\u5236\u76f8\u5173\u7684\u72b6\u6001\u7b49\u4ef7\u6027\uff0c\u5c06\u5177\u6709\u76f8\u4f3c\u8f6c\u79fb\u52a8\u6001\u7684\u72b6\u6001\u6620\u5c04\u5230\u9644\u8fd1\u7684\u6f5c\u5728\u72b6\u6001\uff0c\u540c\u65f6\u9650\u5236\u6765\u81ea\u6162\u7279\u5f81\u7684\u8d21\u732e\u3002\u8fd9\u6837\u8bbe\u8ba1\u7684\u76ee\u7684\u662f\u4e3a\u4e86\u8ba9\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u5ffd\u7565\u90a3\u4e9b\u4e0d\u91cd\u8981\u7684\u89c6\u89c9\u53d8\u5316\uff0c\u4e13\u6ce8\u4e8e\u771f\u6b63\u5f71\u54cd\u4efb\u52a1\u6267\u884c\u7684\u56e0\u7d20\u3002", "result": "\u901a\u8fc7\u5bf9\u4e0d\u540c\u6d4b\u8bd5\u65f6\u95f4\u80cc\u666f\u53d8\u5316\u53ca\u89c6\u89c9\u5e72\u6270\u4e0b\u7684\u7b80\u5355\u5bfc\u822a\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u5730\u63d0\u9ad8\u4e86\u5bf9\u6162\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5de5\u4f5c\u5728\u4e00\u4e2a\u663e\u8457\u51cf\u5c0f\u7684\u6f5c\u5728\u7a7a\u95f4\u5185\uff0c\u8fd9\u4e2a\u7a7a\u95f4\u6700\u591a\u53ef\u4ee5\u6bd4DINO-WM\u5c0f10\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u51fa\u4e00\u79cd\u66f4\u9c81\u68d2\u4e8e\u6162\u7279\u5f81\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5176\u4e0d\u4ec5\u51cf\u5c11\u4e86\u6240\u9700\u7684\u6f5c\u5728\u7a7a\u95f4\u5927\u5c0f\uff0c\u800c\u4e14\u8fd8\u80fd\u7075\u6d3b\u5730\u4e0e\u591a\u79cd\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u4e00\u8d77\u4f7f\u7528\u800c\u4e0d\u635f\u5931\u6027\u80fd\u3002"}}
{"id": "2602.18645", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18645", "abs": "https://arxiv.org/abs/2602.18645", "authors": ["Shvat Messica", "Jiawen Zhang", "Kevin Li", "Theodoros Tsiligkaridis", "Marinka Zitnik"], "title": "Adaptive Time Series Reasoning via Segment Selection", "comment": null, "summary": "Time series reasoning tasks often start with a natural language question and require targeted analysis of a time series. Evidence may span the full series or appear in a few short intervals, so the model must decide what to inspect. Most existing approaches encode the entire time series into a fixed representation before inference, regardless of whether or not the entire sequence is relevant. We introduce ARTIST, which formulates time-series reasoning as a sequential decision problem. ARTIST interleaves reasoning with adaptive temporal segment selection. It adopts a controller-reasoner architecture and uses reinforcement learning to train the controller role to select informative segments and the reasoner role to generate segment-conditioned reasoning traces and final answers. During inference, the model actively acquires task-relevant information instead of relying on a static summary of the full sequence. We use a novel hierarchical policy optimization approach for post-training that allows the model to excel in both segment selection and question-answering behavior. We evaluate ARTIST on six time-series reasoning benchmarks and compare it with large language models, vision-language models, and prior time-series reasoning systems. ARTIST improves average accuracy by 6.46 absolute percentage points over the strongest baseline. The largest gains appear on rare event localization and multi-segment reasoning tasks. Supervised fine-tuning improves performance, and reinforcement learning provides additional gains by optimizing question-adaptive segment selection. These results show that selective data use drives effective time-series reasoning.", "AI": {"tldr": "ARTIST, a model that uses reinforcement learning for adaptive temporal segment selection and reasoning over time series data, outperforms existing methods on several benchmarks, especially in rare event localization and multi-segment reasoning tasks.", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u65b9\u6cd5\u901a\u5e38\u5728\u63a8\u65ad\u524d\u5c06\u6574\u4e2a\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u4e3a\u56fa\u5b9a\u8868\u793a\uff0c\u800c\u4e0d\u8bba\u6574\u4e2a\u5e8f\u5217\u662f\u5426\u90fd\u4e0e\u95ee\u9898\u76f8\u5173\u3002\u8fd9\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u6839\u636e\u95ee\u9898\u9009\u62e9\u6027\u5730\u68c0\u67e5\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u76f8\u5173\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aARTIST\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u89c6\u4e3a\u4e00\u4e2a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\u3002\u5b83\u91c7\u7528\u4e86\u63a7\u5236\u5668-\u63a8\u7406\u5668\u67b6\u6784\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u8bad\u7ec3\u63a7\u5236\u5668\u89d2\u8272\u4ee5\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u7684\u7247\u6bb5\uff0c\u4ee5\u53ca\u8bad\u7ec3\u63a8\u7406\u5668\u89d2\u8272\u751f\u6210\u57fa\u4e8e\u7247\u6bb5\u6761\u4ef6\u7684\u63a8\u7406\u8f68\u8ff9\u548c\u6700\u7ec8\u7b54\u6848\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5c42\u6b21\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u6765\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4f7f\u6a21\u578b\u5728\u7247\u6bb5\u9009\u62e9\u548c\u95ee\u7b54\u884c\u4e3a\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "result": "ARTIST\u5728\u516d\u4e2a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4ee5\u53ca\u5148\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7cfb\u7edf\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\uff0cARTIST\u6bd4\u6700\u5f3a\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad8\u4e866.46\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u6027\uff0c\u5728\u7f55\u89c1\u4e8b\u4ef6\u5b9a\u4f4d\u548c\u591a\u7247\u6bb5\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5927\u7684\u8fdb\u6b65\u3002\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u4f18\u5316\u9762\u5411\u95ee\u9898\u7684\u7247\u6bb5\u9009\u62e9\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u6548\u679c\u3002", "conclusion": "\u9009\u62e9\u6027\u6570\u636e\u5229\u7528\u5bf9\u4e8e\u6709\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002ARTIST\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u65f6\u95f4\u5e8f\u5217\u7247\u6bb5\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.19446", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19446", "abs": "https://arxiv.org/abs/2602.19446", "authors": ["Masudul Hasan Masud Bhuiyan", "Manish Kumar Bala Kumar", "Cristian-Alexandru Staicu"], "title": "\"Write in English, Nobody Understands Your Language Here\": A Study of Non-English Trends in Open-Source Repositories", "comment": null, "summary": "The open-source software (OSS) community has historically been dominated by English as the primary language for code, documentation, and developer interactions. However, with growing global participation and better support for non-Latin scripts through standards like Unicode, OSS is gradually becoming more multilingual. This study investigates the extent to which OSS is becoming more multilingual, analyzing 9.14 billion GitHub issues, pull requests, and discussions, and 62,500 repositories across five programming languages and 30 natural languages, covering the period from 2015 to 2025. We examine six research questions to track changes in language use across communication, code, and documentation. We find that multilingual participation has steadily increased, especially in Korean, Chinese, and Russian. This growth appears not only in issues and discussions but also in code comments, string literals, and documentation files. While this shift reflects greater inclusivity and language diversity in OSS, it also creates language tension. The ability to express oneself in a native language can clash with shared norms around English use, especially in collaborative settings. Non-English or multilingual projects tend to receive less visibility and participation, suggesting that language remains both a resource and a barrier, shaping who gets heard, who contributes, and how open collaboration unfolds.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u4ece2015\u5e74\u52302025\u5e74\u95f4GitHub\u4e0a\u768491.4\u4ebf\u4e2a\u95ee\u9898\u3001\u62c9\u53d6\u8bf7\u6c42\u548c\u8ba8\u8bba\uff0c\u4ee5\u53ca\u8de8\u8d8a\u4e94\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c30\u79cd\u81ea\u7136\u8bed\u8a00\u768462,500\u4e2a\u5b58\u50a8\u5e93\uff0c\u63a2\u8ba8\u5f00\u6e90\u8f6f\u4ef6\uff08OSS\uff09\u4e2d\u591a\u8bed\u8a00\u4f7f\u7528\u7a0b\u5ea6\u7684\u589e\u957f\u3002\u53d1\u73b0\u97e9\u8bed\u3001\u4e2d\u6587\u548c\u4fc4\u8bed\u7b49\u8bed\u8a00\u7684\u53c2\u4e0e\u5ea6\u7a33\u6b65\u589e\u957f\uff0c\u4e0d\u4ec5\u4f53\u73b0\u5728\u4ea4\u6d41\u4e2d\uff0c\u5728\u4ee3\u7801\u6ce8\u91ca\u3001\u5b57\u7b26\u4e32\u6587\u5b57\u548c\u6587\u6863\u6587\u4ef6\u4e2d\u4e5f\u6709\u6240\u4f53\u73b0\u3002\u5c3d\u7ba1\u8fd9\u79cd\u53d8\u5316\u53cd\u6620\u4e86OSS\u4e2d\u7684\u5305\u5bb9\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u589e\u5f3a\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u8bed\u8a00\u7d27\u5f20\uff0c\u5e76\u4e14\u975e\u82f1\u8bed\u6216\u591a\u79cd\u8bed\u8a00\u9879\u76ee\u5f80\u5f80\u83b7\u5f97\u8f83\u5c11\u7684\u5173\u6ce8\u548c\u53c2\u4e0e\u3002", "motivation": "\u968f\u7740\u5168\u7403\u53c2\u4e0e\u5ea6\u7684\u589e\u52a0\u4ee5\u53caUnicode\u7b49\u6807\u51c6\u5bf9\u975e\u62c9\u4e01\u6587\u811a\u672c\u652f\u6301\u7684\u6539\u5584\uff0c\u5f00\u6e90\u8f6f\u4ef6\u793e\u533a\u6b63\u9010\u6e10\u53d8\u5f97\u66f4\u52a0\u591a\u8bed\u8a00\u5316\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u591a\u8bed\u8a00\u4f7f\u7528\u7684\u589e\u957f\u7a0b\u5ea6\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5bf92015\u5e74\u81f32025\u5e74\u95f4GitHub\u4e0a91.4\u4ebf\u4e2a\u95ee\u9898\u3001\u62c9\u53d6\u8bf7\u6c42\u548c\u8ba8\u8bba\u53ca62,500\u4e2a\u4ed3\u5e93\u8fdb\u884c\u5206\u6790\uff0c\u6db5\u76d6\u4e94\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u4e09\u5341\u79cd\u81ea\u7136\u8bed\u8a00\uff0c\u56f4\u7ed5\u6c9f\u901a\u3001\u4ee3\u7801\u548c\u6587\u6863\u4e2d\u7684\u8bed\u8a00\u4f7f\u7528\u53d8\u5316\u63d0\u51fa\u516d\u4e2a\u7814\u7a76\u95ee\u9898\u6765\u8ffd\u8e2a\u53d8\u5316\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7279\u522b\u662f\u97e9\u8bed\u3001\u4e2d\u6587\u548c\u4fc4\u8bed\u5728\u5185\u7684\u591a\u8bed\u8a00\u53c2\u4e0e\u5ea6\u5728\u6301\u7eed\u589e\u957f\uff0c\u8fd9\u4e0d\u4ec5\u8868\u73b0\u5728\u95ee\u9898\u548c\u8ba8\u8bba\u4e2d\uff0c\u8fd8\u4f53\u73b0\u5728\u4ee3\u7801\u6ce8\u91ca\u3001\u5b57\u7b26\u4e32\u6587\u672c\u548c\u6587\u6863\u6587\u4ef6\u91cc\u3002\u867d\u7136\u8fd9\u79cd\u8f6c\u53d8\u53cd\u6620\u4e86\u5f00\u6e90\u8f6f\u4ef6\u9886\u57df\u66f4\u5927\u7684\u5305\u5bb9\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\uff0c\u4f46\u540c\u65f6\u4e5f\u9020\u6210\u4e86\u8bed\u8a00\u95f4\u7684\u5f20\u529b\u3002\u975e\u82f1\u8bed\u6216\u591a\u79cd\u8bed\u8a00\u9879\u76ee\u503e\u5411\u4e8e\u83b7\u5f97\u8f83\u4f4e\u7684\u5173\u6ce8\u5ea6\u4e0e\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u5f00\u6e90\u8f6f\u4ef6\u6b63\u5728\u53d8\u5f97\u66f4\u52a0\u591a\u8bed\u8a00\u5316\uff0c\u5c24\u5176\u662f\u5728\u97e9\u8bed\u3001\u4e2d\u6587\u548c\u4fc4\u8bed\u65b9\u9762\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u8d8b\u52bf\u4e5f\u5bfc\u81f4\u4e86\u8bed\u8a00\u7d27\u5f20\u611f\uff0c\u5e76\u4e14\u975e\u82f1\u8bed\u6216\u591a\u8bed\u8a00\u9879\u76ee\u901a\u5e38\u4f1a\u6536\u5230\u8f83\u5c11\u7684\u5173\u6ce8\u548c\u8d21\u732e\u3002\u8fd9\u610f\u5473\u7740\u8bed\u8a00\u65e2\u662f\u4e00\u79cd\u8d44\u6e90\u4e5f\u662f\u4e00\u79cd\u969c\u788d\uff0c\u5f71\u54cd\u7740\u8c01\u7684\u58f0\u97f3\u88ab\u542c\u5230\u3001\u8c01\u4f5c\u51fa\u8d21\u732e\u4ee5\u53ca\u5f00\u653e\u534f\u4f5c\u5982\u4f55\u5c55\u5f00\u3002"}}
{"id": "2602.18647", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.18647", "abs": "https://arxiv.org/abs/2602.18647", "authors": ["Gabriel Raya", "Bac Nguyen", "Georgios Batzolis", "Yuhta Takida", "Dejan Stancevic", "Naoki Murata", "Chieh-Hsin Lai", "Yuki Mitsufuji", "Luca Ambrogioni"], "title": "Information-Guided Noise Allocation for Efficient Diffusion Training", "comment": null, "summary": "Training diffusion models typically relies on manually tuned noise schedules, which can waste computation on weakly informative noise regions and limit transfer across datasets, resolutions, and representations. We revisit noise schedule allocation through an information-theoretic lens and propose the conditional entropy rate of the forward process as a theoretically grounded, data-dependent diagnostic for identifying suboptimal noise-level allocation in existing schedules. Based on these insight, we introduce InfoNoise, a principled data-adaptive training noise schedule that replaces heuristic schedule design with an information-guided noise sampling distribution derived from entropy-reduction rates estimated from denoising losses already computed during training. Across natural-image benchmarks, InfoNoise matches or surpasses tuned EDM-style schedules, in some cases with a substantial training speedup (about $1.4\\times$ on CIFAR-10). On discrete datasets, where standard image-tuned schedules exhibit significant mismatch, it reaches superior quality in up to $3\\times$ fewer training steps. Overall, InfoNoise makes noise scheduling data-adaptive, reducing the need for per-dataset schedule design as diffusion models expand across domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6570\u636e\u81ea\u9002\u5e94\u8bad\u7ec3\u566a\u58f0\u8c03\u5ea6\u65b9\u6cd5InfoNoise\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f30\u8ba1\u53bb\u566a\u635f\u5931\u4e2d\u7684\u71b5\u51cf\u5c11\u7387\u6765\u6307\u5bfc\u566a\u58f0\u91c7\u6837\u5206\u5e03\uff0c\u4ece\u800c\u6539\u8fdb\u4e86\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u7684\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u4f9d\u8d56\u4e8e\u624b\u52a8\u8c03\u6574\u7684\u566a\u58f0\u8ba1\u5212\uff0c\u8fd9\u53ef\u80fd\u4f1a\u5728\u4fe1\u606f\u91cf\u8f83\u4f4e\u7684\u566a\u58f0\u533a\u57df\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u4e14\u9650\u5236\u4e86\u8de8\u6570\u636e\u96c6\u3001\u5206\u8fa8\u7387\u548c\u8868\u793a\u6cd5\u7684\u8fc1\u79fb\u6027\u3002", "method": "\u4f5c\u8005\u4ece\u4fe1\u606f\u8bba\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u4e86\u566a\u58f0\u8ba1\u5212\u5206\u914d\uff0c\u5e76\u63d0\u51fa\u4e86\u524d\u5411\u8fc7\u7a0b\u6761\u4ef6\u71b5\u7387\u4f5c\u4e3a\u8bca\u65ad\u73b0\u6709\u8ba1\u5212\u4e2d\u6b21\u4f18\u566a\u58f0\u7ea7\u522b\u5206\u914d\u7684\u7406\u8bba\u57fa\u7840\u548c\u6570\u636e\u4f9d\u8d56\u6027\u6307\u6807\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u4ed6\u4eec\u5f15\u5165\u4e86InfoNoise\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u539f\u5219\u7684\u6570\u636e\u81ea\u9002\u5e94\u8bad\u7ec3\u566a\u58f0\u8ba1\u5212\uff0c\u5b83\u7528\u4ece\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5df2\u8ba1\u7b97\u7684\u53bb\u566a\u635f\u5931\u4f30\u7b97\u51fa\u7684\u71b5\u51cf\u5c11\u7387\u5f97\u51fa\u7684\u4fe1\u606f\u5f15\u5bfc\u566a\u58f0\u91c7\u6837\u5206\u5e03\u6765\u53d6\u4ee3\u542f\u53d1\u5f0f\u8ba1\u5212\u8bbe\u8ba1\u3002", "result": "\u5728\u81ea\u7136\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cInfoNoise\u4e0e\u7ecf\u8fc7\u8c03\u4f18\u7684EDM\u98ce\u683c\u8ba1\u5212\u76f8\u5339\u914d\u6216\u8d85\u8d8a\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff08\u5982CIFAR-10\uff09\u8bad\u7ec3\u901f\u5ea6\u663e\u8457\u52a0\u5feb\uff08\u7ea61.4\u500d\uff09\u3002\u5bf9\u4e8e\u6807\u51c6\u56fe\u50cf\u8c03\u8c10\u8ba1\u5212\u8868\u73b0\u51fa\u660e\u663e\u4e0d\u5339\u914d\u7684\u79bb\u6563\u6570\u636e\u96c6\uff0c\u5b83\u53ef\u4ee5\u5728\u5c11\u81f33\u500d\u7684\u8bad\u7ec3\u6b65\u9aa4\u5185\u8fbe\u5230\u66f4\u4f18\u7684\u8d28\u91cf\u3002", "conclusion": "\u603b\u4f53\u800c\u8a00\uff0cInfoNoise\u4f7f\u566a\u58f0\u8c03\u5ea6\u53d8\u5f97\u6570\u636e\u81ea\u9002\u5e94\uff0c\u51cf\u5c11\u4e86\u968f\u7740\u6269\u6563\u6a21\u578b\u6269\u5c55\u5230\u4e0d\u540c\u9886\u57df\u65f6\u5bf9\u6bcf\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8ba1\u5212\u8bbe\u8ba1\u7684\u9700\u6c42\u3002"}}
{"id": "2602.19614", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19614", "abs": "https://arxiv.org/abs/2602.19614", "authors": ["Chih-Hong Cheng", "Brian Hsuan-Cheng Liao", "Adam Molin", "Hasan Esen"], "title": "Workflow-Level Design Principles for Trustworthy GenAI in Automotive System Engineering", "comment": null, "summary": "The adoption of large language models in safety-critical system engineering is constrained by trustworthiness, traceability, and alignment with established verification practices. We propose workflow-level design principles for trustworthy GenAI integration and demonstrate them in an end-to-end automotive pipeline, from requirement delta identification to SysML v2 architecture update and re-testing. First, we show that monolithic (\"big-bang\") prompting misses critical changes in large specifications, while section-wise decomposition with diversity sampling and lightweight NLP sanity checks improves completeness and correctness. Then, we propagate requirement deltas into SysML v2 models and validate updates via compilation and static analysis. Additionally, we ensure traceable regression testing by generating test cases through explicit mappings from specification variables to architectural ports and states, providing practical safeguards for GenAI used in safety-critical automotive engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b89\u5168\u5173\u952e\u7684\u6c7d\u8f66\u5de5\u7a0b\u4e2d\u96c6\u6210\u53ef\u4fe1\u751f\u6210\u5f0fAI\u7684\u5de5\u4f5c\u6d41\u7ea7\u8bbe\u8ba1\u539f\u5219\uff0c\u901a\u8fc7\u4ece\u9700\u6c42\u5dee\u5f02\u8bc6\u522b\u5230SysML v2\u67b6\u6784\u66f4\u65b0\u53ca\u91cd\u65b0\u6d4b\u8bd5\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u8fdb\u884c\u4e86\u6f14\u793a\u3002\u91c7\u7528\u5206\u6bb5\u5904\u7406\u4e0e\u591a\u6837\u6027\u91c7\u6837\u7b49\u6280\u672f\u6539\u8fdb\u4e86\u5bf9\u5927\u578b\u89c4\u8303\u53d8\u66f4\u7684\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u751f\u6210\u5177\u4f53\u7684\u6d4b\u8bd5\u6848\u4f8b\u6765\u786e\u4fdd\u53ef\u8ffd\u6eaf\u7684\u56de\u5f52\u6d4b\u8bd5\uff0c\u4e3a\u5728\u5b89\u5168\u6027\u8981\u6c42\u9ad8\u7684\u573a\u666f\u4e0b\u4f7f\u7528\u751f\u6210\u5f0fAI\u63d0\u4f9b\u4e86\u5b9e\u7528\u4fdd\u969c\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u5de5\u7a0b\u9886\u57df\u5e94\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u65f6\u9762\u4e34\u4fe1\u4efb\u5ea6\u3001\u53ef\u8ffd\u6eaf\u6027\u4ee5\u53ca\u4e0e\u73b0\u6709\u9a8c\u8bc1\u5b9e\u8df5\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u969c\u788d\uff0c\u4f5c\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u589e\u5f3a\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u96c6\u6210\u53ef\u4fe1\u5ea6\u7684\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u7814\u7a76\u8005\u4eec\u9996\u5148\u5c55\u793a\u4e86\u4f20\u7edf\u7684\u6574\u4f53\u5f0f\u63d0\u793a\u65b9\u6cd5\u5728\u5904\u7406\u5927\u7bc7\u5e45\u89c4\u8303\u6587\u6863\u65f6\u5bb9\u6613\u9057\u6f0f\u91cd\u8981\u53d8\u66f4\u7684\u95ee\u9898\uff1b\u968f\u540e\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ae0\u8282\u5206\u89e3\u7ed3\u5408\u591a\u6837\u6027\u62bd\u6837\u548c\u8f7b\u91cf\u7ea7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u68c0\u67e5\u7684\u65b0\u7b56\u7565\u4ee5\u63d0\u9ad8\u4fe1\u606f\u5b8c\u6574\u6027\u548c\u6b63\u786e\u7387\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u5c06\u9700\u6c42\u53d8\u66f4\u53cd\u6620\u5230SysML v2\u6a21\u578b\u4e2d\u5e76\u901a\u8fc7\u7f16\u8bd1\u548c\u9759\u6001\u5206\u6790\u8fdb\u884c\u9a8c\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5efa\u7acb\u4ece\u89c4\u8303\u53d8\u91cf\u5230\u67b6\u6784\u7aef\u53e3\u548c\u72b6\u6001\u4e4b\u95f4\u660e\u786e\u6620\u5c04\u5173\u7cfb\u7684\u65b9\u5f0f\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4ece\u800c\u652f\u6301\u53ef\u8ffd\u8e2a\u7684\u56de\u5f52\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u4e00\u6b21\u6027\u63d0\u793a\u65b9\u5f0f\uff0c\u6240\u63d0\u51fa\u7684\u5206\u6bb5\u5904\u7406\u52a0\u591a\u6837\u672c\u9009\u53d6\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u4e8e\u590d\u6742\u89c4\u8303\u6587\u4ef6\u4e2d\u7ec6\u5fae\u4f46\u5173\u952e\u53d8\u5316\u7684\u6355\u6349\u80fd\u529b\u3002\u540c\u65f6\uff0c\u5728SysML v2\u6a21\u578b\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u624b\u6bb5\u6709\u6548\u4fdd\u8bc1\u4e86\u66f4\u6539\u540e\u7684\u7cfb\u7edf\u67b6\u6784\u8d28\u91cf\u3002\u6700\u540e\uff0c\u901a\u8fc7\u76f4\u63a5\u5173\u8054\u89c4\u8303\u5143\u7d20\u4e0e\u6d4b\u8bd5\u811a\u672c\u6765\u5b9e\u73b0\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u673a\u5236\uff0c\u4e0d\u4ec5\u7b80\u5316\u4e86\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u4e5f\u4e3a\u540e\u7eed\u7ef4\u62a4\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9075\u5faa\u7279\u5b9a\u7684\u8bbe\u8ba1\u539f\u5219\u5e76\u5728\u6574\u4e2a\u5f00\u53d1\u5468\u671f\u5185\u5b9e\u65bd\u9002\u5f53\u7684\u63a7\u5236\u63aa\u65bd\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u751f\u6210\u5f0fAI\u6280\u672f\u5e94\u7528\u4e8e\u5b89\u5168\u5173\u952e\u578b\u6c7d\u8f66\u5de5\u7a0b\u9879\u76ee\u4e2d\u3002\u8fd9\u4e0d\u4ec5\u6709\u52a9\u4e8e\u63d0\u9ad8\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u5f00\u53d1\u6548\u7387\uff0c\u540c\u65f6\u4e5f\u4e3a\u786e\u4fdd\u6700\u7ec8\u4ea7\u54c1\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.19628", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.19628", "abs": "https://arxiv.org/abs/2602.19628", "authors": ["Pasan Peiris", "Matthias Galster", "Antonija Mitrovic", "Sanna Malinen", "Raul Vincent Lumapas", "Jay Holland"], "title": "Towards Understanding Views on Combining Videos and Gamification in Software Engineering Training", "comment": "2 pages, ICSE-Companion '26", "summary": "Watching training videos passively leads to superficial learning. Adding gamification can increase engagement. We study how software engineering students and industry practitioners view gamifying video-based training. We conducted a survey with students and professionals. Students and professionals share similar perceptions toward video-based training in general and support combining gamification and video-based training. Our findings can inform the design of gamified training solutions for software engineers.", "AI": {"tldr": "\u7814\u7a76\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u5b66\u751f\u548c\u884c\u4e1a\u4ece\u4e1a\u8005\u5bf9\u4e8e\u5c06\u6e38\u620f\u5316\u5143\u7d20\u52a0\u5165\u5230\u57fa\u4e8e\u89c6\u9891\u7684\u57f9\u8bad\u4e2d\u7684\u770b\u6cd5\uff0c\u53d1\u73b0\u4e24\u8005\u5bf9\u6b64\u90fd\u6301\u652f\u6301\u6001\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u901a\u8fc7\u89c2\u770b\u57f9\u8bad\u89c6\u9891\u5b66\u4e60\u7684\u6548\u679c\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u6dfb\u52a0\u6e38\u620f\u5316\u5143\u7d20\u6765\u589e\u52a0\u53c2\u4e0e\u5ea6\uff0c\u5e76\u63a2\u7d22\u8f6f\u4ef6\u5de5\u7a0b\u5b66\u751f\u548c\u884c\u4e1a\u4ece\u4e1a\u8005\u5bf9\u6b64\u7684\u770b\u6cd5\u3002", "method": "\u901a\u8fc7\u5411\u5b66\u751f\u548c\u4e13\u4e1a\u4eba\u58eb\u53d1\u653e\u8c03\u67e5\u95ee\u5377\u7684\u65b9\u5f0f\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b66\u751f\u548c\u4e13\u4e1a\u4eba\u58eb\u5bf9\u57fa\u4e8e\u89c6\u9891\u7684\u57f9\u8bad\u603b\u4f53\u4e0a\u6301\u6709\u76f8\u4f3c\u7684\u770b\u6cd5\uff0c\u5e76\u4e14\u652f\u6301\u5c06\u6e38\u620f\u5316\u4e0e\u57fa\u4e8e\u89c6\u9891\u7684\u57f9\u8bad\u76f8\u7ed3\u5408\u3002", "conclusion": "\u672c\u7814\u7a76\u7684\u7ed3\u679c\u53ef\u4ee5\u4e3a\u8bbe\u8ba1\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u6e38\u620f\u5316\u57f9\u8bad\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2602.18658", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18658", "abs": "https://arxiv.org/abs/2602.18658", "authors": ["Yinan Zou", "Md Kamran Chowdhury Shisher", "Christopher G. Brinton", "Vishrant Tripathi"], "title": "Communication-Efficient Personalized Adaptation via Federated-Local Model Merging", "comment": null, "summary": "Parameter-efficient fine-tuning methods, such as LoRA, offer a practical way to adapt large vision and language models to client tasks. However, this becomes particularly challenging under task-level heterogeneity in federated deployments. In this regime, personalization requires balancing general knowledge with personalized knowledge, yet existing approaches largely rely on heuristic mixing rules and lack theoretical justification. Moreover, prior model merging approaches are also computation and communication intensive, making the process inefficient in federated settings. In this work, we propose Potara, a principled framework for federated personalization that constructs a personalized model for each client by merging two complementary models: (i) a federated model capturing general knowledge, and (ii) a local model capturing personalized knowledge. Through the construct of linear mode connectivity, we show that the expected task loss admits a variance trace upper bound, whose minimization yields closed-form optimal mixing weights that guarantee a tighter bound for the merged model than for either the federated or local model alone. Experiments on vision and language benchmarks show that Potara consistently improves personalization while reducing communication, leading to a strong performance-communication trade-off.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPotara\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8054\u90a6\u4e2a\u6027\u5316\u8bbe\u7f6e\u4e2d\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u7684\u5e94\u7528\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5408\u5e76\u4e00\u4e2a\u8054\u90a6\u6a21\u578b\uff08\u6355\u6349\u901a\u7528\u77e5\u8bc6\uff09\u548c\u4e00\u4e2a\u672c\u5730\u6a21\u578b\uff08\u6355\u6349\u4e2a\u6027\u5316\u77e5\u8bc6\uff09\u6765\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6784\u5efa\u4e2a\u6027\u5316\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660ePotara\u5728\u63d0\u9ad8\u4e2a\u6027\u5316\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u901a\u4fe1\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5728\u9762\u5bf9\u8054\u90a6\u90e8\u7f72\u4e0b\u7684\u4efb\u52a1\u7ea7\u5f02\u8d28\u6027\u65f6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u5e73\u8861\u901a\u7528\u4e0e\u4e2a\u6027\u5316\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u73b0\u6709\u65b9\u6cd5\u591a\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\uff0c\u540c\u65f6\u5148\u524d\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u5927\u3002", "method": "Potara\u6846\u67b6\u5229\u7528\u7ebf\u6027\u6a21\u5f0f\u8fde\u901a\u6027\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86\u9884\u671f\u4efb\u52a1\u635f\u5931\u6709\u4e00\u4e2a\u65b9\u5dee\u8ff9\u4e0a\u754c\uff0c\u6700\u5c0f\u5316\u6b64\u4e0a\u754c\u53ef\u5f97\u95ed\u5f62\u5f0f\u6700\u4f18\u6df7\u5408\u6743\u91cd\uff0c\u4ece\u800c\u786e\u4fdd\u5408\u5e76\u540e\u7684\u6a21\u578b\u6bd4\u5355\u72ec\u4f7f\u7528\u8054\u90a6\u6216\u672c\u5730\u6a21\u578b\u6709\u66f4\u7d27\u7684\u754c\u9650\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPotara\u4e0d\u4ec5\u6301\u7eed\u6539\u5584\u4e86\u4e2a\u6027\u5316\u8868\u73b0\uff0c\u540c\u65f6\u4e5f\u51cf\u5c11\u4e86\u6240\u9700\u7684\u901a\u4fe1\u91cf\uff0c\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u6027\u80fd-\u901a\u4fe1\u6743\u8861\u3002", "conclusion": "Potara\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u9762\u5411\u4e2a\u6027\u5316\u9700\u6c42\u7684\u4efb\u52a1\u7ea7\u5f02\u6784\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u5408\u5e76\u8fc7\u7a0b\u4e2d\u7684\u6743\u91cd\u5206\u914d\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u9002\u5e94\u80fd\u529b\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2602.19718", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19718", "abs": "https://arxiv.org/abs/2602.19718", "authors": ["Mateen A. Abbasi", "Tommi J. Mikkonen", "Petri J. Ihantola", "Muhammad Waseem", "Pekka Abrahamsson", "Niko K. M\u00e4kitalo"], "title": "Carbon-Aware Governance Gates: An Architecture for Sustainable GenAI Development", "comment": "5 pages, 1 figure. Preprint version under review", "summary": "The rapid adoption of Generative AI (GenAI) in the software development life cycle (SDLC) increases computational demand, which can raise the carbon footprint of development activities. At the same time, organizations are increasingly embedding governance mechanisms into GenAI-assisted development to support trust, transparency, and accountability. However, these governance mechanisms introduce additional computational workloads, including repeated inference, regeneration cycles, and expanded validation pipelines, increasing energy use and the carbon footprint of GenAI-assisted development. This paper proposes Carbon-Aware Governance Gates (CAGG), an architectural extension that embeds carbon budgets, energy provenance, and sustainability-aware validation orchestration into human-AI governance layers. CAGG comprises three components: (i) an Energy and Carbon Provenance Ledger, (ii) a Carbon Budget Manager, and (iii) a Green Validation Orchestrator, operationalized through governance policies and reusable design patterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u78b3\u610f\u8bc6\u6cbb\u7406\u95e8(CAGG)\u7684\u67b6\u6784\u6269\u5c55\uff0c\u65e8\u5728\u5c06\u78b3\u9884\u7b97\u3001\u80fd\u6e90\u6765\u6e90\u548c\u53ef\u6301\u7eed\u6027\u9a8c\u8bc1\u7f16\u6392\u6574\u5408\u5230\u4eba\u673a\u6cbb\u7406\u5c42\u4e2d\uff0c\u4ee5\u89e3\u51b3\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u5468\u671f\u4e2d\u589e\u52a0\u7684\u8ba1\u7b97\u9700\u6c42\u5bfc\u81f4\u7684\u78b3\u8db3\u8ff9\u95ee\u9898\u3002CAGG\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u80fd\u91cf\u4e0e\u78b3\u6765\u6e90\u8d26\u672c\u3001\u78b3\u9884\u7b97\u7ba1\u7406\u5668\u4ee5\u53ca\u7eff\u8272\u9a8c\u8bc1\u534f\u8c03\u5668\uff0c\u5e76\u901a\u8fc7\u6cbb\u7406\u653f\u7b56\u548c\u53ef\u91cd\u7528\u8bbe\u8ba1\u6a21\u5f0f\u5b9e\u73b0\u8fd0\u4f5c\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\uff08SDLC\uff09\u4e2d\u7684\u5feb\u901f\u91c7\u7528\uff0c\u5bf9\u4e8e\u8ba1\u7b97\u80fd\u529b\u7684\u9700\u6c42\u4e5f\u968f\u4e4b\u589e\u957f\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5f00\u53d1\u6d3b\u52a8\u7684\u78b3\u6392\u653e\u91cf\u4e0a\u5347\u3002\u540c\u65f6\uff0c\u7ec4\u7ec7\u6b63\u5728\u5c06\u6cbb\u7406\u673a\u5236\u5d4c\u5165\u5230\u57fa\u4e8eGenAI\u7684\u652f\u6301\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u4fc3\u8fdb\u4fe1\u4efb\u3001\u900f\u660e\u5ea6\u548c\u8d23\u4efb\u6027\u3002\u4f46\u662f\uff0c\u8fd9\u4e9b\u6cbb\u7406\u673a\u5236\u5f15\u5165\u4e86\u989d\u5916\u7684\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5305\u62ec\u91cd\u590d\u63a8\u7406\u3001\u518d\u751f\u5faa\u73af\u4ee5\u53ca\u6269\u5927\u7684\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u589e\u52a0\u4e86\u80fd\u6e90\u4f7f\u7528\u53ca\u78b3\u8db3\u8ff9\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u78b3\u610f\u8bc6\u6cbb\u7406\u95e8\uff08Carbon-Aware Governance Gates, CAGG\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u67b6\u6784\u4e0a\u7684\u6269\u5c55\uff0c\u5b83\u5c06\u78b3\u9884\u7b97\u3001\u80fd\u6e90\u6765\u6e90\u8ddf\u8e2a\u4ee5\u53ca\u53ef\u6301\u7eed\u6027\u5bfc\u5411\u7684\u9a8c\u8bc1\u7f16\u6392\u96c6\u6210\u5230\u4e86\u4eba\u7c7b-\u4eba\u5de5\u667a\u80fd\u4ea4\u4e92\u7684\u6cbb\u7406\u5c42\u7ea7\u4e4b\u4e2d\u3002CAGG\u7531\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\u7ec4\u6210\uff1a(i) \u80fd\u6e90\u4e0e\u78b3\u6765\u6e90\u8bb0\u5f55\u8d26\u672c\uff1b(ii) \u78b3\u9884\u7b97\u7ba1\u7406\u8005\uff1b\u4ee5\u53ca(iii) \u7eff\u8272\u9a8c\u8bc1\u8c03\u5ea6\u8005\u3002\u8fd9\u4e9b\u7ec4\u6210\u90e8\u5206\u901a\u8fc7\u6cbb\u7406\u7b56\u7565\u548c\u53ef\u590d\u7528\u7684\u8bbe\u8ba1\u6a21\u5f0f\u6765\u5b9e\u73b0\u5176\u529f\u80fd\u3002", "result": "\u867d\u7136\u6458\u8981\u4e2d\u6ca1\u6709\u76f4\u63a5\u63d0\u5230\u5177\u4f53\u7684\u7ed3\u679c\u6570\u636e\u6216\u5b9e\u9a8c\u53d1\u73b0\uff0c\u4f46\u53ef\u4ee5\u63a8\u6d4b\u51faCAGG\u7684\u5b9e\u65bd\u6709\u671b\u51cf\u5c11GenAI\u8f85\u52a9\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u78b3\u8db3\u8ff9\uff0c\u540c\u65f6\u4fdd\u6301\u5fc5\u8981\u7684\u6cbb\u7406\u6807\u51c6\u3002\u901a\u8fc7\u6709\u6548\u7ba1\u7406\u78b3\u9884\u7b97\u548c\u4f18\u5316\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u8be5\u65b9\u6cd5\u53ef\u80fd\u6709\u52a9\u4e8e\u964d\u4f4e\u6574\u4f53\u80fd\u6e90\u6d88\u8017\u5e76\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u7684\u73af\u5883\u53cb\u597d\u6027\u3002", "conclusion": "\u78b3\u610f\u8bc6\u6cbb\u7406\u95e8(CAGG)\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u901a\u8fc7\u6574\u5408\u78b3\u9884\u7b97\u63a7\u5236\u3001\u80fd\u6e90\u4f7f\u7528\u8ffd\u8e2a\u4ee5\u53ca\u73af\u4fdd\u578b\u9a8c\u8bc1\u6d41\u7a0b\u7b49\u624b\u6bb5\uff0c\u6765\u5e94\u5bf9GenAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u6240\u5e26\u6765\u7684\u78b3\u6392\u653e\u6311\u6218\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u5e2e\u52a9\u7ec4\u7ec7\u7ef4\u6301\u5176\u5bf9\u4e8eGenAI\u5e94\u7528\u7684\u4fe1\u4efb\u3001\u900f\u660e\u5ea6\u548c\u8d23\u4efb\u611f\uff0c\u540c\u65f6\u4e5f\u4fc3\u8fdb\u4e86\u66f4\u52a0\u53ef\u6301\u7eed\u7684\u53d1\u5c55\u5b9e\u8df5\u3002"}}
{"id": "2602.18662", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18662", "abs": "https://arxiv.org/abs/2602.18662", "authors": ["Nikolaos Kougioulis", "Nikolaos Gkorgkolis", "MingXue Wang", "Bora Caglayan", "Dario Simionato", "Andrea Tonon", "Ioannis Tsamardinos"], "title": "Large Causal Models for Temporal Causal Discovery", "comment": "32 pages (16 main text, 16 Appendix), 11 Figures", "summary": "Causal discovery for both cross-sectional and temporal data has traditionally followed a dataset-specific paradigm, where a new model is fitted for each individual dataset. Such an approach limits the potential of multi-dataset pretraining. The concept of large causal models (LCMs) envisions a class of pre-trained neural architectures specifically designed for temporal causal discovery. Prior approaches are constrained to small variable counts, degrade with larger inputs, and rely heavily on synthetic data, limiting generalization. We propose a principled framework for LCMs, combining diverse synthetic generators with realistic time-series datasets, allowing learning at scale. Extensive experiments on synthetic, semi-synthetic and realistic benchmarks show that LCMs scale effectively to higher variable counts and deeper architectures while maintaining strong performance. Trained models achieve competitive or superior accuracy compared to classical and neural baselines, particularly in out-of-distribution settings, while enabling fast, single-pass inference. Results demonstrate LCMs as a promising foundation-model paradigm for temporal causal discovery. Experiments and model weights are available at https://github.com/kougioulis/LCM-paper/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5927\u578b\u56e0\u679c\u6a21\u578b\uff08LCM\uff09\u7684\u539f\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u591a\u6837\u7684\u5408\u6210\u751f\u6210\u5668\u548c\u73b0\u5b9e\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u80fd\u591f\u5728\u66f4\u5927\u89c4\u6a21\u4e0a\u8fdb\u884c\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLCMs\u80fd\u591f\u6709\u6548\u5730\u6269\u5c55\u5230\u66f4\u9ad8\u7684\u53d8\u91cf\u6570\u548c\u66f4\u6df1\u7684\u67b6\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u9488\u5bf9\u6a2a\u622a\u9762\u548c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u901a\u5e38\u9075\u5faa\u7279\u5b9a\u6570\u636e\u96c6\u7684\u8303\u5f0f\uff0c\u4e3a\u6bcf\u4e2a\u5355\u72ec\u7684\u6570\u636e\u96c6\u62df\u5408\u65b0\u6a21\u578b\u3002\u8fd9\u79cd\u65b9\u6cd5\u9650\u5236\u4e86\u591a\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u578b\u56e0\u679c\u6a21\u578b\uff08LCMs\uff09\u7684\u539f\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u6837\u5316\u7684\u5408\u6210\u751f\u6210\u5668\u4e0e\u5b9e\u9645\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u3001\u534a\u5408\u6210\u53ca\u771f\u5b9e\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLCMs\u80fd\u591f\u6709\u6548\u6269\u5c55\u81f3\u66f4\u9ad8\u53d8\u91cf\u8ba1\u6570\u548c\u66f4\u6df1\u5c42\u67b6\u6784\u7684\u540c\u65f6\u4fdd\u6301\u51fa\u8272\u8868\u73b0\u3002\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u76f8\u6bd4\u7ecf\u5178\u548c\u795e\u7ecf\u57fa\u7ebf\uff0c\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u597d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u5feb\u901f\u5355\u6b21\u63a8\u7406\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660e\uff0cLCMs\u4f5c\u4e3a\u65f6\u95f4\u56e0\u679c\u53d1\u73b0\u7684\u57fa\u7840\u6a21\u578b\u8303\u4f8b\u662f\u5f88\u6709\u524d\u9014\u7684\u3002"}}
{"id": "2602.18679", "categories": ["cs.LG", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18679", "abs": "https://arxiv.org/abs/2602.18679", "authors": ["Anthony Bao", "Jeffrey Lai", "William Gilpin"], "title": "Transformers for dynamical systems learn transfer operators in-context", "comment": "6 pages, 3 figures", "summary": "Large-scale foundation models for scientific machine learning adapt to physical settings unseen during training, such as zero-shot transfer between turbulent scales. This phenomenon, in-context learning, challenges conventional understanding of learning and adaptation in physical systems. Here, we study in-context learning of dynamical systems in a minimal setting: we train a small two-layer, single-head transformer to forecast one dynamical system, and then evaluate its ability to forecast a different dynamical system without retraining. We discover an early tradeoff in training between in-distribution and out-of-distribution performance, which manifests as a secondary double descent phenomenon. We discover that attention-based models apply a transfer-operator forecasting strategy in-context. They (1) lift low-dimensional time series using delay embedding, to detect the system's higher-dimensional dynamical manifold, and (2) identify and forecast long-lived invariant sets that characterize the global flow on this manifold. Our results clarify the mechanism enabling large pretrained models to forecast unseen physical systems at test without retraining, and they illustrate the unique ability of attention-based models to leverage global attractor information in service of short-term forecasts.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u7b56\u7565\u6765\u9884\u6d4b\u672a\u89c1\u8fc7\u7684\u52a8\u529b\u7cfb\u7edf\u3002\u8fd9\u79cd\u7b56\u7565\u5305\u62ec\u4f7f\u7528\u5ef6\u8fdf\u5d4c\u5165\u63d0\u5347\u4f4e\u7ef4\u65f6\u95f4\u5e8f\u5217\u4ee5\u68c0\u6d4b\u7cfb\u7edf\u7684\u9ad8\u7ef4\u52a8\u529b\u5b66\u6d41\u5f62\uff0c\u5e76\u8bc6\u522b\u548c\u9884\u6d4b\u8868\u5f81\u8be5\u6d41\u5f62\u4e0a\u5168\u5c40\u6d41\u52a8\u7684\u957f\u671f\u4e0d\u53d8\u96c6\u3002", "motivation": "\u63a2\u7d22\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u5c0f\u89c4\u6a21\u7684\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u9002\u5e94\u5e76\u9884\u6d4b\u4e0d\u540c\u7684\u52a8\u529b\u7cfb\u7edf\uff0c\u4ee5\u53ca\u8fd9\u4e00\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u7684\u6027\u80fd\u6743\u8861\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u4e2a\u5c0f\u578b\u4e24\u5c42\u3001\u5355\u5934\u53d8\u538b\u5668\u8fdb\u884c\u5355\u4e00\u52a8\u529b\u7cfb\u7edf\u7684\u9884\u6d4b\u8bad\u7ec3\uff0c\u7136\u540e\u8bc4\u4f30\u5176\u5bf9\u4e0d\u540c\u52a8\u529b\u7cfb\u7edf\u8fdb\u884c\u9884\u6d4b\u7684\u80fd\u529b\u800c\u65e0\u9700\u8fdb\u4e00\u6b65\u8bad\u7ec3\u3002", "result": "\u89c2\u5bdf\u5230\u4e86\u5728\u5206\u5e03\u5185\u4e0e\u5206\u5e03\u5916\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u65e9\u671f\u6743\u8861\u7684\u73b0\u8c61\uff0c\u8868\u73b0\u4e3a\u4e8c\u6b21\u4e0b\u964d\u73b0\u8c61\uff1b\u63ed\u793a\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\u80fd\u591f\u5229\u7528\u5168\u5c40\u5438\u5f15\u5b50\u4fe1\u606f\u6765\u63d0\u9ad8\u77ed\u671f\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u4e86\u9884\u8bad\u7ec3\u7684\u5927\u6a21\u578b\u53ef\u4ee5\u5728\u672a\u7ecf\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u9884\u6d4b\u672a\u89c1\u7269\u7406\u7cfb\u7edf\u80cc\u540e\u7684\u673a\u5236\uff0c\u5e76\u5c55\u793a\u4e86\u6ce8\u610f\u529b\u673a\u5236\u6a21\u578b\u5229\u7528\u5168\u5c40\u5438\u5f15\u5b50\u4fe1\u606f\u670d\u52a1\u4e8e\u77ed\u671f\u9884\u6d4b\u7684\u72ec\u7279\u80fd\u529b\u3002"}}
{"id": "2602.18694", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18694", "abs": "https://arxiv.org/abs/2602.18694", "authors": ["Baiting Luo", "Yunuo Zhang", "Nathaniel S. Keplinger", "Samir Gupta", "Abhishek Dubey", "Ayan Mukhopadhyay"], "title": "In-Context Planning with Latent Temporal Abstractions", "comment": null, "summary": "Planning-based reinforcement learning for continuous control is bottlenecked by two practical issues: planning at primitive time scales leads to prohibitive branching and long horizons, while real environments are frequently partially observable and exhibit regime shifts that invalidate stationary, fully observed dynamics assumptions. We introduce I-TAP (In-Context Latent Temporal-Abstraction Planner), an offline RL framework that unifies in-context adaptation with online planning in a learned discrete temporal-abstraction space. From offline trajectories, I-TAP learns an observation-conditioned residual-quantization VAE that compresses each observation-macro-action segment into a coarse-to-fine stack of discrete residual tokens, and a temporal Transformer that autoregressively predicts these token stacks from a short recent history. The resulting sequence model acts simultaneously as a context-conditioned prior over abstract actions and a latent dynamics model. At test time, I-TAP performs Monte Carlo Tree Search directly in token space, using short histories for implicit adaptation without gradient update, and decodes selected token stacks into executable actions. Across deterministic MuJoCo, stochastic MuJoCo with per-episode latent dynamics regimes, and high-dimensional Adroit manipulation, including partially observable variants, I-TAP consistently matches or outperforms strong model-free and model-based offline baselines, demonstrating efficient and robust in-context planning under stochastic dynamics and partial observability.", "AI": {"tldr": "I-TAP\u662f\u4e00\u79cd\u7ed3\u5408\u4e86\u4e0a\u4e0b\u6587\u9002\u5e94\u4e0e\u5728\u7ebf\u89c4\u5212\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u5b66\u4e60\u89c2\u5bdf\u6761\u4ef6\u4e0b\u7684\u6b8b\u5dee\u91cf\u5316VAE\u548c\u65f6\u95f4Transformer\uff0c\u4ee5\u5728\u5b66\u4e60\u5230\u7684\u79bb\u4e49\u65f6\u95f4\u62bd\u8c61\u7a7a\u95f4\u4e2d\u76f4\u63a5\u8fdb\u884c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u3002\u5b83\u5728\u786e\u5b9a\u6027\u3001\u968f\u673a\u6027\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u914d\u5f3a\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u57fa\u4e8e\u89c4\u5212\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u9762\u4e34\u4e24\u4e2a\u5b9e\u9645\u95ee\u9898\uff1a\u5728\u539f\u59cb\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u8fdb\u884c\u89c4\u5212\u4f1a\u5bfc\u81f4\u5206\u652f\u8fc7\u591a\u53ca\u957f\u671f\u9884\u6d4b\u56f0\u96be\uff1b\u800c\u771f\u5b9e\u73af\u5883\u5f80\u5f80\u662f\u90e8\u5206\u53ef\u89c2\u5bdf\u7684\uff0c\u5e76\u4e14\u5b58\u5728\u72b6\u6001\u8f6c\u6362\uff0c\u8fd9\u4f7f\u5f97\u9759\u6001\u3001\u5b8c\u5168\u89c2\u5bdf\u7684\u52a8\u6001\u5047\u8bbe\u5931\u6548\u3002", "method": "I-TAP\u5229\u7528\u4e00\u79cd\u89c2\u5bdf\u6761\u4ef6\u4e0b\u7684\u6b8b\u5dee\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5c06\u6bcf\u4e2a\u89c2\u5bdf-\u5b8f\u52a8\u4f5c\u6bb5\u538b\u7f29\u6210\u4e00\u7cfb\u5217\u7c97\u7ec6\u4e0d\u7b49\u7684\u79bb\u6563\u6b8b\u5dee\u4ee4\u724c\u5806\u6808\uff0c\u5e76\u4f7f\u7528\u65f6\u95f4Transformer\u6839\u636e\u6700\u8fd1\u7684\u5386\u53f2\u6570\u636e\u81ea\u56de\u5f52\u5730\u9884\u6d4b\u8fd9\u4e9b\u4ee4\u724c\u5806\u6808\u3002\u6d4b\u8bd5\u65f6\uff0cI-TAP\u76f4\u63a5\u5728\u4ee4\u724c\u7a7a\u95f4\u6267\u884c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u91c7\u7528\u7b80\u77ed\u5386\u53f2\u9690\u5f0f\u9002\u5e94\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\uff0c\u5e76\u5c06\u9009\u5b9a\u7684\u4ee4\u724c\u5806\u6808\u89e3\u7801\u4e3a\u53ef\u6267\u884c\u52a8\u4f5c\u3002", "result": "\u5728\u5305\u62ec\u786e\u5b9a\u6027\u7684MuJoCo\u3001\u6bcf\u96c6\u5177\u6709\u6f5c\u5728\u52a8\u6001\u673a\u5236\u7684\u968f\u673aMuJoCo\u4ee5\u53ca\u9ad8\u7ef4Adroit\u64cd\u63a7\u4efb\u52a1\uff08\u542b\u90e8\u5206\u53ef\u89c2\u6d4b\u7248\u672c\uff09\u5728\u5185\u7684\u591a\u4e2a\u73af\u5883\u4e2d\uff0cI-TAP\u7684\u8868\u73b0\u4e00\u81f4\u5730\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u5f3a\u5927\u7684\u65e0\u6a21\u578b\u548c\u6709\u6a21\u578b\u79bb\u7ebf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u968f\u673a\u52a8\u6001\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u4e0a\u4e0b\u6587\u89c4\u5212\u80fd\u529b\u3002", "conclusion": "I-TAP\u5c55\u793a\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u57fa\u4e8e\u89c4\u5212\u7684\u5f3a\u5316\u5b66\u4e60\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6574\u5408\u4e0a\u4e0b\u6587\u9002\u5e94\u4e0e\u5728\u7ebf\u89c4\u5212\u4e8e\u5b66\u4e60\u5230\u7684\u65f6\u95f4\u62bd\u8c61\u7a7a\u95f4\u5185\uff0c\u5b9e\u73b0\u4e86\u5373\u4f7f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u53ca\u5b58\u5728\u72b6\u6001\u8f6c\u6362\u7684\u771f\u5b9e\u73af\u5883\u4e0b\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.18695", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18695", "abs": "https://arxiv.org/abs/2602.18695", "authors": ["Dhruvesh Patel", "Benjamin Rozonoyer", "Gaurav Pandey", "Tahira Naseem", "Ram\u00f3n Fernandez Astudillo", "Andrew McCallum"], "title": "Insertion Based Sequence Generation with Learnable Order Dynamics", "comment": "Project Page and Code at: https://dhruveshp.com/projects/lflexmdm", "summary": "In many domains generating variable length sequences through insertions provides greater flexibility over autoregressive models. However, the action space of insertion models is much larger than that of autoregressive models (ARMs) making the learning challenging. To address this, we incorporate trainable order dynamics into the target rates for discrete flow matching, and show that with suitable choices of parameterizations, joint training of the target order dynamics and the generator is tractable without the need for numerical simulation. As the generative insertion model, we use a variable length masked diffusion model, which generates by inserting and filling mask tokens. On graph traversal tasks for which a locally optimal insertion order is known, we explore the choices of parameterization empirically and demonstrate the trade-offs between flexibility, training stability and generation quality. On de novo small molecule generation, we find that the learned order dynamics leads to an increase in the number of valid molecules generated and improved quality, when compared to uniform order dynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u63d2\u5165\u751f\u6210\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u53ef\u8bad\u7ec3\u7684\u987a\u5e8f\u52a8\u6001\u6765\u6539\u5584\u79bb\u6563\u6d41\u5339\u914d\u7684\u76ee\u6807\u7387\uff0c\u5e76\u91c7\u7528\u53ef\u53d8\u957f\u5ea6\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u56fe\u904d\u5386\u4efb\u52a1\u548c\u5c0f\u5206\u5b50\u751f\u6210\u4efb\u52a1\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u3001\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u63d2\u5165\u6a21\u578b\u76f8\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u5728\u5b66\u4e60\u4e0a\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u63d2\u5165\u6a21\u578b\u7684\u52a8\u4f5c\u7a7a\u95f4\u66f4\u5927\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6587\u7ae0\u5f15\u5165\u4e86\u53ef\u8bad\u7ec3\u7684\u987a\u5e8f\u52a8\u6001\u5230\u79bb\u6563\u6d41\u5339\u914d\u4e2d\uff0c\u76ee\u7684\u662f\u8ba9\u8054\u5408\u8bad\u7ec3\u66f4\u52a0\u53ef\u884c\uff0c\u65e0\u9700\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "method": "\u4f7f\u7528\u4e86\u53ef\u53d8\u957f\u5ea6\u63a9\u7801\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u751f\u6210\u6027\u63d2\u5165\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u63d2\u5165\u548c\u586b\u5145\u906e\u7f69\u6807\u8bb0\u6765\u751f\u6210\u5e8f\u5217\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5c06\u53ef\u8bad\u7ec3\u7684\u987a\u5e8f\u52a8\u6001\u7eb3\u5165\u76ee\u6807\u7387\u4e2d\uff0c\u63a2\u7d22\u4e86\u4e0d\u540c\u53c2\u6570\u5316\u9009\u62e9\u5bf9\u7075\u6d3b\u6027\u3001\u8bad\u7ec3\u7a33\u5b9a\u6027\u4ee5\u53ca\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u5728\u56fe\u904d\u5386\u4efb\u52a1\u4e2d\uff0c\u5bf9\u4e8e\u5df2\u77e5\u5c40\u90e8\u6700\u4f18\u63d2\u5165\u987a\u5e8f\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u4e86\u53c2\u6570\u5316\u7684\u5b9e\u8bc1\u9009\u62e9\u5e76\u5c55\u793a\u4e86\u7075\u6d3b\u6027\u3001\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5728\u4ece\u5934\u5f00\u59cb\u7684\u5c0f\u5206\u5b50\u751f\u6210\u65b9\u9762\uff0c\u4e0e\u5747\u5300\u987a\u5e8f\u52a8\u6001\u76f8\u6bd4\uff0c\u5b66\u4e60\u5230\u7684\u987a\u5e8f\u52a8\u6001\u5bfc\u81f4\u751f\u6210\u7684\u6709\u6548\u5206\u5b50\u6570\u91cf\u589e\u52a0\u4e14\u8d28\u91cf\u63d0\u9ad8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7ed3\u5408\u53ef\u8bad\u7ec3\u7684\u987a\u5e8f\u52a8\u6001\u4e0e\u53ef\u53d8\u957f\u5ea6\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u6570\u503c\u6a21\u62df\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u5e8f\u5217\u751f\u6210\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u56fe\u904d\u5386\u548c\u5c0f\u5206\u5b50\u751f\u6210\u7b49\u9886\u57df\u3002"}}
{"id": "2602.18728", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.18728", "abs": "https://arxiv.org/abs/2602.18728", "authors": ["Mingdong Lu", "Zhikui Chen", "Meng Liu", "Shubin Ma", "Liang Zhao"], "title": "Phase-Consistent Magnetic Spectral Learning for Multi-View Clustering", "comment": "Preprint. Under review", "summary": "Unsupervised multi-view clustering (MVC) aims to partition data into meaningful groups by leveraging complementary information from multiple views without labels, yet a central challenge is to obtain a reliable shared structural signal to guide representation learning and cross-view alignment under view discrepancy and noise. Existing approaches often rely on magnitude-only affinities or early pseudo targets, which can be unstable when different views induce relations with comparable strengths but contradictory directional tendencies, thereby distorting the global spectral geometry and degrading clustering. In this paper, we propose \\emph{Phase-Consistent Magnetic Spectral Learning} for MVC: we explicitly model cross-view directional agreement as a phase term and combine it with a nonnegative magnitude backbone to form a complex-valued magnetic affinity, extract a stable shared spectral signal via a Hermitian magnetic Laplacian, and use it as structured self-supervision to guide unsupervised multi-view representation learning and clustering. To obtain robust inputs for spectral extraction at scale, we construct a compact shared structure with anchor-based high-order consensus modeling and apply a lightweight refinement to suppress noisy or inconsistent relations. Extensive experiments on multiple public multi-view benchmarks demonstrate that our method consistently outperforms strong baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u76f8\u4f4d\u4e00\u81f4\u78c1\u8c31\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u89c6\u56fe\u95f4\u7684\u5b9a\u5411\u4e00\u81f4\u6027\uff0c\u5e76\u7ed3\u5408\u975e\u8d1f\u5e45\u5ea6\u9aa8\u67b6\u5f62\u6210\u590d\u6570\u503c\u78c1\u4eb2\u548c\u529b\uff0c\u4ece\u800c\u6307\u5bfc\u65e0\u76d1\u7763\u591a\u89c6\u56fe\u8868\u793a\u5b66\u4e60\u4e0e\u805a\u7c7b\u3002", "motivation": "\u73b0\u6709\u7684\u65e0\u76d1\u7763\u591a\u89c6\u56fe\u805a\u7c7b\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u540c\u89c6\u56fe\u95f4\u5177\u6709\u76f8\u4f3c\u5f3a\u5ea6\u4f46\u65b9\u5411\u6027\u8d8b\u52bf\u77db\u76fe\u7684\u5173\u7cfb\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5168\u5c40\u8c31\u51e0\u4f55\u5931\u771f\u5e76\u964d\u4f4e\u805a\u7c7b\u6548\u679c\u3002", "method": "\u5f15\u5165\u4e86\u76f8\u4f4d\u4e00\u81f4\u78c1\u8c31\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u8de8\u89c6\u56fe\u65b9\u5411\u4e00\u81f4\u6027\u5efa\u6a21\u4e3a\u4e00\u4e2a\u76f8\u4f4d\u9879\uff0c\u5e76\u5c06\u5176\u4e0e\u975e\u8d1f\u5e45\u5ea6\u57fa\u7840\u76f8\u7ed3\u5408\u4ee5\u521b\u5efa\u590d\u6570\u503c\u78c1\u4eb2\u548c\u529b\uff1b\u5229\u7528Hermitian\u78c1\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u63d0\u53d6\u7a33\u5b9a\u7684\u5171\u4eab\u8c31\u4fe1\u53f7\uff0c\u5e76\u4f5c\u4e3a\u7ed3\u6784\u5316\u81ea\u76d1\u7763\u6765\u5f15\u5bfc\u65e0\u76d1\u7763\u7684\u591a\u89c6\u56fe\u8868\u793a\u5b66\u4e60\u4e0e\u805a\u7c7b\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u5728\u5927\u89c4\u6a21\u4e0a\u83b7\u5f97\u9c81\u68d2\u7684\u8c31\u63d0\u53d6\u8f93\u5165\uff0c\u91c7\u7528\u4e86\u57fa\u4e8e\u951a\u70b9\u7684\u9ad8\u9636\u5171\u8bc6\u5efa\u6a21\u6784\u5efa\u7d27\u51d1\u5171\u4eab\u7ed3\u6784\uff0c\u5e76\u5e94\u7528\u8f7b\u91cf\u7ea7\u7ec6\u5316\u6765\u6291\u5236\u566a\u58f0\u6216\u4e0d\u4e00\u81f4\u5173\u7cfb\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u7684\u591a\u89c6\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6301\u7eed\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u76f8\u4f4d\u4e00\u81f4\u78c1\u8c31\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u56e0\u89c6\u56fe\u95f4\u5b58\u5728\u77db\u76fe\u7684\u65b9\u5411\u6027\u8d8b\u52bf\u800c\u5bfc\u81f4\u7684\u65e0\u76d1\u7763\u591a\u89c6\u56fe\u805a\u7c7b\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u8c31\u5b66\u4e60\u7b56\u7565\u63d0\u9ad8\u4e86\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2602.18733", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18733", "abs": "https://arxiv.org/abs/2602.18733", "authors": ["Trishita Tiwari", "Ari Trachtenberg", "G. Edward Suh"], "title": "Prior Aware Memorization: An Efficient Metric for Distinguishing Memorization from Generalization in Large Language Models", "comment": null, "summary": "Training data leakage from Large Language Models (LLMs) raises serious concerns related to privacy, security, and copyright compliance. A central challenge in assessing this risk is distinguishing genuine memorization of training data from the generation of statistically common sequences. Existing approaches to measuring memorization often conflate these phenomena, labeling outputs as memorized even when they arise from generalization over common patterns. Counterfactual Memorization provides a principled solution by comparing models trained with and without a target sequence, but its reliance on retraining multiple baseline models makes it computationally expensive and impractical at scale.\n  This work introduces Prior-Aware Memorization, a theoretically grounded, lightweight and training-free criterion for identifying genuine memorization in LLMs. The key idea is to evaluate whether a candidate suffix is strongly associated with its specific training prefix or whether it appears with high probability across many unrelated prompts due to statistical commonality.\n  We evaluate this metric on text from the training corpora of two pre-trained models, LLaMA and OPT, using both long sequences (to simulate copyright risks) and named entities (to simulate PII leakage). Our results show that between 55% and 90% of sequences previously labeled as memorized are in fact statistically common. Similar findings hold for the SATML training data extraction challenge dataset, where roughly 40% of sequences exhibit common-pattern behavior despite appearing only once in the training data. These results demonstrate that low frequency alone is insufficient evidence of memorization and highlight the importance of accounting for model priors when assessing leakage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3a\u5148\u9a8c\u611f\u77e5\u8bb0\u5fc6\u5316\uff08Prior-Aware Memorization\uff09\uff0c\u7528\u4e8e\u8bc6\u522b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u771f\u6b63\u7684\u6570\u636e\u8bb0\u5fc6\u73b0\u8c61\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u4e14\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\uff0c\u901a\u8fc7\u8bc4\u4f30\u5019\u9009\u540e\u7f00\u4e0e\u5176\u7279\u5b9a\u8bad\u7ec3\u524d\u7f00\u4e4b\u95f4\u662f\u5426\u5b58\u5728\u5f3a\u5173\u8054\u6765\u533a\u5206\u771f\u5b9e\u8bb0\u5fc6\u4e0e\u7edf\u8ba1\u5e38\u89c1\u5e8f\u5217\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5148\u524d\u88ab\u6807\u8bb0\u4e3a\u8bb0\u5fc6\u5316\u7684\u5e8f\u5217\u4e2d\u670955%\u523090%\u5b9e\u9645\u4e0a\u662f\u7edf\u8ba1\u4e0a\u5e38\u89c1\u7684\uff0c\u8fd9\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u6cc4\u9732\u98ce\u9669\u65f6\u8003\u8651\u6a21\u578b\u5148\u9a8c\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u6d4b\u91cf\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u5316\u7684\u65b9\u6cd5\u5f80\u5f80\u6df7\u6dc6\u4e86\u771f\u5b9e\u7684\u6570\u636e\u8bb0\u5fc6\u548c\u751f\u6210\u7edf\u8ba1\u5e38\u89c1\u5e8f\u5217\u7684\u73b0\u8c61\uff0c\u5bfc\u81f4\u5bf9\u8bb0\u5fc6\u5316\u7684\u9519\u8bef\u6807\u7b7e\u3002\u6b64\u5916\uff0c\u53cd\u4e8b\u5b9e\u8bb0\u5fc6\u5316\u867d\u7136\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u4f46\u9700\u8981\u591a\u6b21\u91cd\u8bad\u7ec3\u6a21\u578b\uff0c\u5b9e\u9645\u64cd\u4f5c\u4e2d\u6210\u672c\u9ad8\u6602\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u591f\u51c6\u786e\u533a\u5206\u8fd9\u4e24\u79cd\u60c5\u51b5\u53c8\u4e0d\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u5148\u9a8c\u611f\u77e5\u8bb0\u5fc6\u5316\u6807\u51c6\uff0c\u8fd9\u662f\u4e00\u79cd\u7406\u8bba\u57fa\u7840\u575a\u5b9e\u3001\u8f7b\u91cf\u7ea7\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u771f\u5b9e\u8bb0\u5fc6\u73b0\u8c61\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5224\u65ad\u5019\u9009\u540e\u7f00\u662f\u5426\u4ec5\u4e0e\u7279\u5b9a\u7684\u8bad\u7ec3\u524d\u7f00\u9ad8\u5ea6\u76f8\u5173\u8fd8\u662f\u7531\u4e8e\u7edf\u8ba1\u5171\u6027\u800c\u53ef\u80fd\u51fa\u73b0\u5728\u8bb8\u591a\u4e0d\u76f8\u5173\u7684\u63d0\u793a\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e24\u4e2a\u9884\u8bad\u7ec3\u6a21\u578bLLaMA\u548cOPT\u7684\u8bad\u7ec3\u8bed\u6599\u5e93\u4ee5\u53caSATML\u8bad\u7ec3\u6570\u636e\u63d0\u53d6\u6311\u6218\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u65b0\u65b9\u6cd5\u53d1\u73b0\u4e4b\u524d\u88ab\u8ba4\u4e3a\u662f\u7531\u6a21\u578b\u8bb0\u5fc6\u5f15\u8d77\u7684\u5e8f\u5217\u4e2d\u5f88\u5927\u4e00\u90e8\u5206\u5b9e\u9645\u4e0a\u662f\u7edf\u8ba1\u4e0a\u5e38\u89c1\u7684\u3002\u5bf9\u4e8e\u7248\u6743\u98ce\u9669\u6a21\u62df\u4f7f\u7528\u7684\u957f\u5e8f\u5217\u548cPII\u6cc4\u9732\u6a21\u62df\u4f7f\u7528\u7684\u547d\u540d\u5b9e\u4f53\uff0c\u8fd9\u4e00\u6bd4\u4f8b\u5206\u522b\u4e3a55%\u81f390%\u548c\u5927\u7ea640%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u4f4e\u9891\u6b21\u672c\u8eab\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u8bb0\u5fc6\u5316\u7684\u8bc1\u636e\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u6f5c\u5728\u7684\u6570\u636e\u6cc4\u9732\u98ce\u9669\u65f6\u8003\u8651\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u7684\u91cd\u8981\u6027\u3002\u5148\u9a8c\u611f\u77e5\u8bb0\u5fc6\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u624b\u6bb5\u6765\u66f4\u51c6\u786e\u5730\u8861\u91cf\u771f\u6b63\u7531\u8bb0\u5fc6\u5f15\u8d77\u7684\u6570\u636e\u6cc4\u9732\u95ee\u9898\u3002"}}
{"id": "2602.18739", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18739", "abs": "https://arxiv.org/abs/2602.18739", "authors": ["Zhixiang Guo", "Siyuan Liang", "Andras Balogh", "Noah Lunberry", "Rong-Cheng Tu", "Mark Jelasity", "Dacheng Tao"], "title": "When World Models Dream Wrong: Physical-Conditioned Adversarial Attacks against World Models", "comment": null, "summary": "Generative world models (WMs) are increasingly used to synthesize controllable, sensor-conditioned driving videos, yet their reliance on physical priors exposes novel attack surfaces. In this paper, we present Physical-Conditioned World Model Attack (PhysCond-WMA), the first white-box world model attack that perturbs physical-condition channels, such as HDMap embeddings and 3D-box features, to induce semantic, logic, or decision-level distortion while preserving perceptual fidelity. PhysCond-WMA is optimized in two stages: (1) a quality-preserving guidance stage that constrains reverse-diffusion loss below a calibrated threshold, and (2) a momentum-guided denoising stage that accumulates target-aligned gradients along the denoising trajectory for stable, temporally coherent semantic shifts. Extensive experimental results demonstrate that our approach remains effective while increasing FID by about 9% on average and FVD by about 3.9% on average. Under the targeted attack setting, the attack success rate (ASR) reaches 0.55. Downstream studies further show tangible risk, which using attacked videos for training decreases 3D detection performance by about 4%, and worsens open-loop planning performance by about 20%. These findings has for the first time revealed and quantified security vulnerabilities in generative world models, driving more comprehensive security checkers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7269\u7406\u6761\u4ef6\u4e16\u754c\u6a21\u578b\u653b\u51fb(PhysCond-WMA)\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\u7684\u767d\u76d2\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u52a8\u5982HDMap\u5d4c\u5165\u548c3D-box\u7279\u5f81\u7b49\u7269\u7406\u6761\u4ef6\u901a\u9053\uff0c\u5728\u4fdd\u6301\u611f\u77e5\u771f\u5b9e\u6027\u7684\u540c\u65f6\u8bf1\u5bfc\u8bed\u4e49\u3001\u903b\u8f91\u6216\u51b3\u7b56\u7ea7\u626d\u66f2\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u63ed\u793a\u4e86\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\u5728\u5408\u6210\u53ef\u63a7\u3001\u4f20\u611f\u5668\u6761\u4ef6\u4e0b\u7684\u9a7e\u9a76\u89c6\u9891\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u5b83\u4eec\u5bf9\u7269\u7406\u5148\u9a8c\u7684\u4f9d\u8d56\u6027\u66b4\u9732\u51fa\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5e76\u91cf\u5316\u8fd9\u4e9b\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPhysical-Conditioned World Model Attack (PhysCond-WMA)\u7684\u65b9\u6cd5\uff0c\u5206\u4e24\u4e2a\u9636\u6bb5\u4f18\u5316\uff1a\u8d28\u91cf\u4fdd\u7559\u6307\u5bfc\u9636\u6bb5\u786e\u4fdd\u53cd\u5411\u6269\u6563\u635f\u5931\u4f4e\u4e8e\u6821\u51c6\u9608\u503c\uff1b\u52a8\u91cf\u5bfc\u5411\u53bb\u566a\u9636\u6bb5\u6cbf\u7740\u53bb\u566a\u8f68\u8ff9\u7d2f\u79ef\u4e0e\u76ee\u6807\u4e00\u81f4\u7684\u68af\u5ea6\uff0c\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u8bed\u4e49\u8f6c\u6362\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u672c\u65b9\u6cd5\u5728\u63d0\u9ad8FID\u7ea69%\u53caFVD\u7ea63.9%\u7684\u60c5\u51b5\u4e0b\u4f9d\u7136\u6709\u6548\u3002\u5728\u76ee\u6807\u653b\u51fb\u8bbe\u5b9a\u4e0b\uff0c\u653b\u51fb\u6210\u529f\u7387(ASR)\u8fbe\u52300.55\u3002\u8fdb\u4e00\u6b65\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u88ab\u653b\u51fb\u89c6\u9891\u8fdb\u884c\u8bad\u7ec3\u4f1a\u964d\u4f4e3D\u68c0\u6d4b\u6027\u80fd\u7ea64%\uff0c\u5e76\u5bf9\u5f00\u73af\u89c4\u5212\u6027\u80fd\u4ea7\u751f\u7ea620%\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u9996\u6b21\u63ed\u793a\u5e76\u91cf\u5316\u4e86\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5168\u9762\u7684\u5b89\u5168\u68c0\u67e5\u673a\u5236\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.18795", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18795", "abs": "https://arxiv.org/abs/2602.18795", "authors": ["Zheng Wang", "Nizar Bouguila"], "title": "Vectorized Bayesian Inference for Latent Dirichlet-Tree Allocation", "comment": "Submitted to JMLR, under review", "summary": "Latent Dirichlet Allocation (LDA) is a foundational model for discovering latent thematic structure in discrete data, but its Dirichlet prior cannot represent the rich correlations and hierarchical relationships often present among topics. We introduce the framework of Latent Dirichlet-Tree Allocation (LDTA), a generalization of LDA that replaces the Dirichlet prior with an arbitrary Dirichlet-Tree (DT) distribution. LDTA preserves LDA's generative structure but enables expressive, tree-structured priors over topic proportions. To perform inference, we develop universal mean-field variational inference and Expectation Propagation, providing tractable updates for all DT. We reveal the vectorized nature of the two inference methods through theoretical development, and perform fully vectorized, GPU-accelerated implementations. The resulting framework substantially expands the modeling capacity of LDA while maintaining scalability and computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Latent Dirichlet-Tree Allocation (LDTA)\u6846\u67b6\uff0c\u5b83\u662fLDA\u7684\u6cdb\u5316\u7248\u672c\uff0c\u80fd\u591f\u4f7f\u7528\u4efb\u610fDirichlet-Tree\u5206\u5e03\u66ff\u4ee3\u539f\u6709\u7684Dirichlet\u5148\u9a8c\uff0c\u4ece\u800c\u66f4\u597d\u5730\u8868\u793a\u4e3b\u9898\u4e4b\u95f4\u7684\u4e30\u5bcc\u5173\u8054\u548c\u5c42\u6b21\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u7684LDA\u6a21\u578b\u867d\u7136\u80fd\u591f\u53d1\u73b0\u79bb\u6563\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u4e3b\u9898\u7ed3\u6784\uff0c\u4f46\u5176\u4f7f\u7528\u7684Dirichlet\u5148\u9a8c\u65e0\u6cd5\u5145\u5206\u8868\u8fbe\u4e3b\u9898\u4e4b\u95f4\u590d\u6742\u7684\u5173\u8054\u6027\u548c\u5c42\u6b21\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u5f15\u5165\u4e86LDTA\u6846\u67b6\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u901a\u7528\u7684\u5e73\u5747\u573a\u53d8\u5206\u63a8\u65ad\u548c\u671f\u671b\u4f20\u64ad\u65b9\u6cd5\u6765\u5b9e\u73b0LDTA\u6846\u67b6\u4e0b\u7684\u63a8\u7406\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u9002\u7528\u4e8e\u6240\u6709Dirichlet-Tree\u5206\u5e03\u7684\u6709\u6548\u66f4\u65b0\u89c4\u5219\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u4e24\u79cd\u63a8\u7406\u65b9\u6cd5\u7684\u5411\u91cf\u5316\u7279\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u5b8c\u5168\u5411\u91cf\u5316\u53caGPU\u52a0\u901f\u7684\u7b97\u6cd5\u6267\u884c\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cLDTA\u4e0d\u4ec5\u5927\u5927\u6269\u5c55\u4e86LDA\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "LDTA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u6587\u672c\u4e3b\u9898\u6a21\u578b\uff0c\u901a\u8fc7\u91c7\u7528\u66f4\u52a0\u7075\u6d3b\u7684\u6811\u72b6\u7ed3\u6784\u5148\u9a8c\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u4e3b\u9898\u95f4\u5173\u7cfb\u7684\u6355\u6349\u80fd\u529b\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u529b\u7684\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.18801", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18801", "abs": "https://arxiv.org/abs/2602.18801", "authors": ["Jiayi Li", "Zhaonan Wang", "Flora D. Salim"], "title": "SGNO: Spectral Generator Neural Operators for Stable Long Horizon PDE Rollouts", "comment": null, "summary": "Neural operators provide fast PDE surrogates and often generalize across parameters and resolutions. However, in the short train long test setting, autoregressive rollouts can become unstable. This typically happens for two reasons: one step errors accumulate over time, and high frequency components feed back and grow.\n  We introduce the Spectral Generator Neural Operator (SGNO), a residual time stepper that targets both effects. For the linear part, SGNO uses an exponential time differencing update in Fourier space with a learned diagonal generator. We constrain the real part of this generator to be nonpositive, so iterating the step does not amplify the linear dynamics. For nonlinear dynamics, SGNO adds a gated forcing term with channel mixing within each Fourier mode, which keeps the nonlinear update controlled. To further limit high frequency feedback, SGNO applies spectral truncation and an optional smooth mask on the forcing pathway.\n  We derive a one step amplification bound and a finite horizon rollout error bound. The bound separates generator approximation error from nonlinear mismatch and gives sufficient conditions under which the latent $L^2$ norm does not grow across rollout steps. On APEBench spanning 1D, 2D, and 3D PDE families, SGNO achieves lower long horizon error and longer stable rollout lengths than strong neural operator baselines. Ablations confirm the roles of the generator constraint, gating, and filtering.The code is available at https://github.com/lijy32123-cloud/SGNO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7b97\u5b50SGNO\uff0c\u5b83\u901a\u8fc7\u5728\u5085\u91cc\u53f6\u7a7a\u95f4\u4e2d\u4f7f\u7528\u6307\u6570\u65f6\u95f4\u5dee\u5206\u66f4\u65b0\u548c\u5b66\u4e60\u7684\u5bf9\u89d2\u751f\u6210\u5668\u6765\u89e3\u51b3\u957f\u65f6\u95f4\u9884\u6d4b\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u548c\u9ad8\u9891\u6210\u5206\u53cd\u9988\u589e\u957f\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSGNO\u5728\u957f\u65f6\u9884\u6d4b\u4e0a\u6bd4\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u4f4e\u7684\u8bef\u5dee\u548c\u66f4\u7a33\u5b9a\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u795e\u7ecf\u7b97\u5b50\u80fd\u591f\u5feb\u901f\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDE\uff09\u5e76\u901a\u5e38\u80fd\u5728\u53c2\u6570\u548c\u5206\u8fa8\u7387\u4e4b\u95f4\u6cdb\u5316\u3002\u7136\u800c\uff0c\u5728\u77ed\u8bad\u7ec3\u957f\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u56de\u5f52\u5c55\u5f00\u53ef\u80fd\u4f1a\u53d8\u5f97\u4e0d\u7a33\u5b9a\u3002\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u4e00\u6b65\u8bef\u5dee\u968f\u65f6\u95f4\u7d2f\u79ef\u4ee5\u53ca\u9ad8\u9891\u6210\u5206\u53cd\u9988\u589e\u5f3a\u5bfc\u81f4\u7684\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86Spectral Generator Neural Operator (SGNO)\u3002", "method": "SGNO\u91c7\u7528\u4e00\u79cd\u6b8b\u5dee\u65f6\u95f4\u6b65\u8fdb\u65b9\u6cd5\uff0c\u9488\u5bf9\u4e0a\u8ff0\u4e24\u4e2a\u95ee\u9898\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5bf9\u4e8e\u7ebf\u6027\u90e8\u5206\uff0cSGNO\u5229\u7528\u5085\u91cc\u53f6\u7a7a\u95f4\u4e2d\u7684\u6307\u6570\u65f6\u95f4\u5dee\u5206\u66f4\u65b0\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5b66\u4e60\u5230\u7684\u5bf9\u89d2\u751f\u6210\u5668\uff1b\u901a\u8fc7\u9650\u5236\u8be5\u751f\u6210\u5668\u5b9e\u90e8\u4e3a\u975e\u6b63\u6570\uff0c\u786e\u4fdd\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u653e\u5927\u7ebf\u6027\u52a8\u6001\u3002\u5bf9\u4e8e\u975e\u7ebf\u6027\u52a8\u6001\uff0cSGNO\u589e\u52a0\u4e86\u5e26\u6709\u901a\u9053\u6df7\u5408\u529f\u80fd\u7684\u95e8\u63a7\u5f3a\u8feb\u9879\u4ee5\u63a7\u5236\u975e\u7ebf\u6027\u66f4\u65b0\u3002\u6b64\u5916\uff0c\u8fd8\u5e94\u7528\u4e86\u8c31\u622a\u65ad\u53ca\u53ef\u9009\u5e73\u6ed1\u63a9\u6a21\u4e8e\u5f3a\u8feb\u8def\u5f84\u4e0a\uff0c\u8fdb\u4e00\u6b65\u51cf\u5c11\u9ad8\u9891\u53cd\u9988\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u5206\u6790\u7ed9\u51fa\u4e86\u5355\u6b65\u653e\u5927\u754c\u9650\u4e0e\u6709\u9650\u8303\u56f4\u6eda\u52a8\u8bef\u5dee\u754c\u9650\uff0c\u5c06\u751f\u6210\u5668\u8fd1\u4f3c\u8bef\u5dee\u4ece\u975e\u7ebf\u6027\u4e0d\u5339\u914d\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u5e76\u63d0\u4f9b\u4e86\u4fdd\u8bc1\u6f5c\u53d8\u91cf$L^2$\u8303\u6570\u5728\u6574\u4e2a\u6eda\u52a8\u6b65\u9aa4\u4e2d\u4e0d\u589e\u957f\u7684\u5145\u5206\u6761\u4ef6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8de8\u8d8a1D\u30012D\u548c3D PDE\u5bb6\u65cf\u7684APEBench\u6570\u636e\u96c6\u4e0a\uff0cSGNO\u76f8\u6bd4\u5f3a\u5927\u7684\u795e\u7ecf\u7b97\u5b50\u57fa\u7ebf\u6a21\u578b\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u957f\u671f\u8bef\u5dee\u548c\u66f4\u957f\u7684\u7a33\u5b9a\u6eda\u52a8\u957f\u5ea6\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u751f\u6210\u5668\u7ea6\u675f\u3001\u95e8\u63a7\u673a\u5236\u548c\u8fc7\u6ee4\u7684\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684SGNO\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u795e\u7ecf\u7b97\u5b50\u5728\u957f\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406PDE\u95ee\u9898\u65f6\u5c55\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\u80fd\u3002\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u90e8\u5206\u7684\u66f4\u65b0\u7b56\u7565\uff0cSGNO\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u5ea6\u7684\u540c\u65f6\u5ef6\u957f\u9884\u6d4b\u5e8f\u5217\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.18849", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18849", "abs": "https://arxiv.org/abs/2602.18849", "authors": ["Seyed Morteza Emadi"], "title": "Exact Attention Sensitivity and the Geometry of Transformer Stability", "comment": "18 pages, 6 figures", "summary": "Despite powering modern AI, transformers remain mysteriously brittle to train. We develop a stability theory that explains why pre-LayerNorm works, why DeepNorm uses $N^{-1/4}$ scaling, and why warmup is necessary, all from first principles. Our framework has two pillars: (1) We derive the \\emph{exact} operator norm of the softmax Jacobian, $\\|J_{softmax}(u/\u03c4)\\|_{\\infty\\to 1} = \u03b8(p)/\u03c4$, where the balanced-mass factor $\u03b8(p)\\in[0,1]$ quantifies attention sensitivity. (2) We introduce a block-$\\infty$/RMS geometry aligned with tokenwise computation, yielding Lipschitz bounds independent of sequence length. Using this framework, we prove that pre-LN preserves identity gradient paths while post-LN compounds LayerNorm Jacobians exponentially with depth, and we show that DeepNorm's $N^{-1/4}$ emerges from the quartic structure of attention's four projection matrices. We validate our theory on 774M-parameter models and find that, contrary to the intuition that attention sharpens during training to reduce sensitivity, $\u03b8(p) \\approx 1$ persists throughout. Transformer stability arises entirely from architectural gradient flow, not from attention dynamics. This finding changes how we reason about training: the architecture itself must handle sensitivity, not learned attention patterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48pre-LayerNorm\u6709\u6548\u3001DeepNorm\u4e3a\u4f55\u4f7f\u7528$N^{-1/4}$\u7f29\u653e\u4ee5\u53ca\u9884\u70ed\u7684\u5fc5\u8981\u6027\u3002\u901a\u8fc7\u5f15\u5165\u5757-$\\infty$/RMS\u51e0\u4f55\u5b66\u6765\u5bf9\u9f50\u9010\u6807\u8bb0\u8ba1\u7b97\uff0c\u4ece\u800c\u83b7\u5f97\u4e0e\u5e8f\u5217\u957f\u5ea6\u65e0\u5173\u7684Lipschitz\u754c\u3002\u7814\u7a76\u53d1\u73b0\uff0ctransformer\u7684\u7a33\u5b9a\u6027\u5b8c\u5168\u6765\u6e90\u4e8e\u67b6\u6784\u4e0a\u7684\u68af\u5ea6\u6d41\uff0c\u800c\u975e\u6ce8\u610f\u529b\u52a8\u6001\u53d8\u5316\u3002", "motivation": "\u5c3d\u7ba1transformer\u63a8\u52a8\u4e86\u73b0\u4ee3AI\u7684\u53d1\u5c55\uff0c\u4f46\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u8106\u5f31\u6027\u3002\u4e3a\u4e86\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\u5e76\u63d0\u9ad8\u5176\u7a33\u5b9a\u6027\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u65e8\u5728\u4ece\u57fa\u672c\u539f\u7406\u51fa\u53d1\u89e3\u7b54\u51e0\u4e2a\u5173\u952e\u95ee\u9898\uff1apre-LayerNorm\u4e3a\u4f55\u6709\u6548\u3001DeepNorm\u4f7f\u7528\u7684\u7279\u5b9a\u7f29\u653e\u6bd4\u4f8b\u7684\u539f\u56e0\u53ca\u9884\u70ed\u9636\u6bb5\u7684\u91cd\u8981\u6027\u3002", "method": "\u8be5\u7814\u7a76\u57fa\u4e8e\u4e24\u5927\u652f\u67f1\u6784\u5efa\u4e86\u6846\u67b6\uff1a\u9996\u5148\u7cbe\u786e\u5bfc\u51fa\u4e86softmax Jacobian\u7684\u64cd\u4f5c\u8303\u6570\uff1b\u5176\u6b21\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0etokenwise\u8ba1\u7b97\u76f8\u4e00\u81f4\u7684\u5757-$\\infty$/RMS\u51e0\u4f55\u7ed3\u6784\uff0c\u4ee5\u5f97\u5230\u72ec\u7acb\u4e8e\u5e8f\u5217\u957f\u5ea6\u7684Lipschitz\u754c\u9650\u3002\u5229\u7528\u6b64\u6846\u67b6\u8bc1\u660e\u4e86pre-LN\u4fdd\u6301\u6052\u7b49\u68af\u5ea6\u8def\u5f84\uff0c\u800cpost-LN\u5219\u968f\u7740\u6df1\u5ea6\u589e\u52a0\u6307\u6570\u7ea7\u7d2f\u79efLayerNorm\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5e76\u5c55\u793a\u4e86DeepNorm\u4e2d$N^{-1/4}$\u6bd4\u4f8b\u56e0\u5b50\u7684\u6765\u6e90\u3002", "result": "\u5728774M\u53c2\u6570\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u4e0e\u76f4\u89c9\u76f8\u53cd\uff0c\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d$\u03b8(p) \\approx 1$\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u8868\u660etransformer\u7684\u7a33\u5b9a\u6027\u5b8c\u5168\u6765\u81ea\u67b6\u6784\u4e0a\u7684\u68af\u5ea6\u6d41\u52a8\u7279\u6027\uff0c\u800c\u4e0d\u662f\u5b66\u4e60\u5230\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0ctransformer\u6a21\u578b\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e3b\u8981\u7531\u5176\u67b6\u6784\u51b3\u5b9a\uff0c\u7279\u522b\u662f\u68af\u5ea6\u6d41\u52a8\u65b9\u5f0f\uff0c\u800c\u975e\u6ce8\u610f\u529b\u673a\u5236\u672c\u8eab\u7684\u52a8\u6001\u53d8\u5316\u3002\u8fd9\u610f\u5473\u7740\u672a\u6765\u5728\u8bbe\u8ba1\u548c\u4f18\u5316transformer\u65f6\uff0c\u9700\u8981\u66f4\u52a0\u5173\u6ce8\u67b6\u6784\u5c42\u9762\u5982\u4f55\u5904\u7406\u654f\u611f\u6027\u95ee\u9898\u3002"}}
{"id": "2602.18851", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18851", "abs": "https://arxiv.org/abs/2602.18851", "authors": ["Seyed Morteza Emadi"], "title": "Rank-Aware Spectral Bounds on Attention Logits for Stable Low-Precision Training", "comment": "17 pages, 3 figures", "summary": "Attention scores in transformers are bilinear forms $S_{ij} = x_i^\\top M x_j / \\sqrt{d_h}$ whose maximum magnitude governs overflow risk in low-precision training. We derive a \\emph{rank-aware concentration inequality}: when the interaction matrix $M = W^Q W^{K\\top}$ has rank $r \\ll d$, tail probabilities for $\\max_{i,j}|S_{ij}|$ decay as $\\exp(-d^{2}\u03b1^{2}/(\u03b3r))$ rather than $\\exp(-d\u03b1^{2})$, where $\u03b3> 1$ is a typicality parameter. For transformer attention where $r = d_h$, this yields $8$--$28\\times$ tighter concentration than rank-agnostic bounds in modern architectures. We apply this result to FP8 training, deriving \\emph{geometry-aware scale factors} that provide principled overflow guarantees without observing activations. The method computes per-layer scales from the spectral norm $\\|W^Q W^{K\\top}\\|_2$ via implicit power iteration, includes a grouped query attention formulation that avoids key expansion, and remains compatible with fused attention kernels. Across GPT-2 XL to Llama-2-70B, geometry-aware scaling eliminates overflows in transient scenarios where delayed scaling fails, while achieving comparable downstream MMLU accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79e9\u7684\u6ce8\u610f\u529b\u5206\u6570\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u8be5\u4e0d\u7b49\u5f0f\u5728\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u5bf9\u63a7\u5236\u6ea2\u51fa\u98ce\u9669\u6709\u66f4\u5f3a\u7684\u7ea6\u675f\u529b\u3002\u901a\u8fc7\u8fd9\u4e00\u7ed3\u679c\uff0c\u4f5c\u8005\u4e3aFP8\u8bad\u7ec3\u5bfc\u51fa\u4e86\u51e0\u4f55\u611f\u77e5\u7684\u6bd4\u4f8b\u56e0\u5b50\uff0c\u8fd9\u4e9b\u56e0\u5b50\u53ef\u4ee5\u63d0\u4f9b\u539f\u5219\u6027\u7684\u6ea2\u51fa\u4fdd\u8bc1\u800c\u65e0\u9700\u89c2\u5bdf\u6fc0\u6d3b\u503c\u3002\u8fd9\u79cd\u65b9\u6cd5\u8ba1\u7b97\u6bcf\u5c42\u7684\u6bd4\u4f8b\u56e0\u5b50\uff0c\u5e76\u4e14\u4e0e\u878d\u5408\u6ce8\u610f\u529b\u5185\u6838\u517c\u5bb9\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u51e0\u4f55\u611f\u77e5\u7f29\u653e\u5728\u6d88\u9664\u5ef6\u8fdf\u7f29\u653e\u5931\u8d25\u573a\u666f\u4e2d\u7684\u6ea2\u51fa\u65b9\u9762\u6709\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0b\u6e38\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u53d8\u538b\u5668\u6a21\u578b\u5728\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u65f6\u7531\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u7684\u6700\u5927\u5e45\u5ea6\u6240\u5bfc\u81f4\u7684\u6ea2\u51fa\u98ce\u9669\u95ee\u9898\u3002\u4f20\u7edf\u7684\u65b9\u6cd5\u4f7f\u7528\u79e9\u65e0\u5173\u7684\u8fb9\u754c\u4f30\u8ba1\u6700\u5927\u6ce8\u610f\u529b\u5206\u6570\u7684\u5c3e\u6982\u7387\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u4e8e\u73b0\u4ee3\u67b6\u6784\u6765\u8bf4\u8fc7\u4e8e\u5bbd\u677e\u3002", "method": "\u672c\u6587\u9996\u5148\u63a8\u5bfc\u4e86\u4e00\u4e2a\u79e9\u76f8\u5173\u7684\u6ce8\u610f\u529b\u5206\u6570\u96c6\u4e2d\u4e0d\u7b49\u5f0f\uff0c\u8be5\u4e0d\u7b49\u5f0f\u5c55\u793a\u4e86\u5f53\u4ea4\u4e92\u77e9\u9635$M = W^Q W^{K\\top}$\u5177\u6709\u8f83\u4f4e\u79e9$r \\ll d$\u65f6\uff0c\u6700\u5927\u7edd\u5bf9\u6ce8\u610f\u529b\u5206\u6570\u7684\u5c3e\u6982\u7387\u8870\u51cf\u5f97\u66f4\u5feb\u3002\u63a5\u7740\uff0c\u5229\u7528\u8fd9\u4e2a\u7ed3\u8bba\u4e3aFP8\u8bad\u7ec3\u5f00\u53d1\u4e86\u51e0\u4f55\u611f\u77e5\u6bd4\u4f8b\u56e0\u5b50\uff0c\u5b83\u4eec\u53ef\u4ee5\u901a\u8fc7\u9690\u5f0f\u5e42\u8fed\u4ee3\u4ece\u8c31\u8303\u6570$\\|W^Q W^{K\\top}\\|_2$\u4e2d\u83b7\u5f97\u6bcf\u5c42\u7684\u5c3a\u5ea6\u56e0\u5b50\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b\u516c\u5f0f\u6765\u907f\u514d\u952e\u6269\u5c55\u3002", "result": "\u65b0\u65b9\u6cd5\u5728GPT-2 XL\u5230Llama-2-70B\u7b49\u591a\u79cd\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u51e0\u4f55\u611f\u77e5\u7f29\u653e\u80fd\u591f\u5728\u5ef6\u8fdf\u7f29\u653e\u5931\u8d25\u7684\u77ac\u6001\u573a\u666f\u4e2d\u6d88\u9664\u6ea2\u51fa\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u5ef6\u8fdf\u7f29\u653e\u65b9\u6cd5\u76f8\u5f53\u7684\u4e0b\u6e38MMLU\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u7684\u65b0\u65b9\u6cd5\u2014\u2014\u57fa\u4e8e\u79e9\u7684\u6ce8\u610f\u529b\u5206\u6570\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u548c\u51e0\u4f55\u611f\u77e5\u6bd4\u4f8b\u56e0\u5b50\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6f5c\u5728\u7684\u6ea2\u51fa\u98ce\u9669\u95ee\u9898\uff0c\u540c\u65f6\u7ef4\u6301\u6216\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.18856", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18856", "abs": "https://arxiv.org/abs/2602.18856", "authors": ["Reabetswe M. Nkhumise", "Mohamed S. Talamali", "Aditya Gilra"], "title": "Issues with Measuring Task Complexity via Random Policies in Robotic Tasks", "comment": "16 pages, 9 figures, The 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "Reinforcement learning (RL) has enabled major advances in fields such as robotics and natural language processing. A key challenge in RL is measuring task complexity, which is essential for creating meaningful benchmarks and designing effective curricula. While there are numerous well-established metrics for assessing task complexity in tabular settings, relatively few exist in non-tabular domains. These include (i) Statistical analysis of the performance of random policies via Random Weight Guessing (RWG), and (ii) information-theoretic metrics Policy Information Capacity (PIC) and Policy-Optimal Information Capacity (POIC), which are reliant on RWG. In this paper, we evaluate these methods using progressively difficult robotic manipulation setups, with known relative complexity, with both dense and sparse reward formulations. Our empirical results reveal that measuring complexity is still nuanced. Specifically, under the same reward formulation, PIC suggests that a two-link robotic arm setup is easier than a single-link setup - which contradicts the robotic control and empirical RL perspective whereby the two-link setup is inherently more complex. Likewise, for the same setup, POIC estimates that tasks with sparse rewards are easier than those with dense rewards. Thus, we show that both PIC and POIC contradict typical understanding and empirical results from RL. These findings highlight the need to move beyond RWG-based metrics towards better metrics that can more reliably capture task complexity in non-tabular RL with our task framework as a starting point.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u968f\u673a\u6743\u91cd\u731c\u6d4b\uff08RWG\uff09\u7684\u7b56\u7565\u4fe1\u606f\u5bb9\u91cf\uff08PIC\uff09\u548c\u6700\u4f18\u7b56\u7565\u4fe1\u606f\u5bb9\u91cf\uff08POIC\uff09\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u975e\u8868\u683c\u9886\u57df\u5185\u8861\u91cf\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u4f7f\u7528\u96be\u5ea6\u9012\u589e\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u8bbe\u7f6e\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660ePIC\u548cPOIC\u4e0e\u5178\u578b\u7684\u7406\u89e3\u548c\u7ecf\u9a8c\u7ed3\u679c\u76f8\u77db\u76fe\uff0c\u8fd9\u8868\u660e\u9700\u8981\u5f00\u53d1\u51fa\u6bd4\u57fa\u4e8eRWG\u7684\u65b9\u6cd5\u66f4\u53ef\u9760\u7684\u65b0\u6307\u6807\u6765\u8861\u91cf\u975e\u8868\u683c\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4efb\u52a1\u590d\u6742\u5ea6\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u6d4b\u91cf\u4efb\u52a1\u590d\u6742\u5ea6\u5bf9\u4e8e\u521b\u5efa\u6709\u610f\u4e49\u7684\u57fa\u51c6\u548c\u8bbe\u8ba1\u6709\u6548\u7684\u8bfe\u7a0b\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u975e\u8868\u683c\u9886\u57df\u4e2d\uff0c\u6709\u6548\u8861\u91cf\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u65b9\u6cd5\u76f8\u5bf9\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u73b0\u6709\u7684\u57fa\u4e8e\u968f\u673a\u6743\u91cd\u731c\u6d4b\uff08RWG\uff09\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\u2014\u2014\u7b56\u7565\u4fe1\u606f\u5bb9\u91cf\uff08PIC\uff09\u548c\u6700\u4f18\u7b56\u7565\u4fe1\u606f\u5bb9\u91cf\uff08POIC\uff09\uff0c\u6765\u63a2\u8ba8\u8fd9\u4e9b\u65b9\u6cd5\u662f\u5426\u80fd\u591f\u51c6\u786e\u5730\u53cd\u6620\u5b9e\u9645\u4efb\u52a1\u590d\u6742\u5ea6\u3002", "method": "\u7814\u7a76\u8005\u9009\u53d6\u4e86\u4e00\u7cfb\u5217\u5df2\u77e5\u76f8\u5bf9\u590d\u6742\u5ea6\u9010\u6b65\u589e\u52a0\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u573a\u666f\uff0c\u5e76\u5206\u522b\u91c7\u7528\u5bc6\u96c6\u5956\u52b1\u548c\u7a00\u758f\u5956\u52b1\u4e24\u79cd\u5f62\u5f0f\u5bf9\u4efb\u52a1\u8fdb\u884c\u4e86\u8bbe\u5b9a\u3002\u968f\u540e\uff0c\u5229\u7528PIC\u548cPOIC\u4e24\u79cd\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u4efb\u52a1\u7684\u590d\u6742\u5ea6\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6839\u636ePIC\u5ea6\u91cf\uff0c\u5728\u76f8\u540c\u5956\u52b1\u516c\u5f0f\u4e0b\u4e24\u8fde\u6746\u673a\u68b0\u81c2\u88ab\u8ba4\u4e3a\u6bd4\u5355\u8fde\u6746\u673a\u68b0\u81c2\u7b80\u5355\uff0c\u8fd9\u4e0e\u673a\u5668\u4eba\u63a7\u5236\u53ca\u5f3a\u5316\u5b66\u4e60\u7684\u7ecf\u9a8c\u4e0d\u7b26\uff1b\u800c\u6839\u636ePOIC\u5ea6\u91cf\uff0c\u5bf9\u4e8e\u540c\u4e00\u914d\u7f6e\u800c\u8a00\uff0c\u7a00\u758f\u5956\u52b1\u7684\u4efb\u52a1\u88ab\u8ba4\u4e3a\u6bd4\u5bc6\u96c6\u5956\u52b1\u7684\u4efb\u52a1\u8981\u5bb9\u6613\u3002\u8fd9\u4e9b\u53d1\u73b0\u90fd\u4e0e\u5e38\u89c4\u8ba4\u77e5\u76f8\u53cd\u3002", "conclusion": "\u57fa\u4e8e\u73b0\u6709\u8bc4\u4f30\uff0cPIC\u548cPOIC\u4f5c\u4e3a\u8861\u91cf\u975e\u8868\u683c\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u590d\u6742\u6027\u7684\u6307\u6807\u5b58\u5728\u4e0d\u8db3\u4e4b\u5904\uff0c\u5b83\u4eec\u7ed9\u51fa\u7684\u7ed3\u679c\u5f80\u5f80\u4e0e\u5b9e\u9645\u60c5\u51b5\u76f8\u6096\u3002\u56e0\u6b64\uff0c\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u63a2\u7d22\u548c\u53d1\u5c55\u65b0\u7684\u3001\u66f4\u52a0\u53ef\u9760\u7684\u590d\u6742\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2602.18866", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18866", "abs": "https://arxiv.org/abs/2602.18866", "authors": ["Jian Qian", "Shu Ge"], "title": "Boosting for Vector-Valued Prediction and Conditional Density Estimation", "comment": null, "summary": "Despite the widespread use of boosting in structured prediction, a general theoretical understanding of aggregation beyond scalar losses remains incomplete. We study vector-valued and conditional density prediction under general divergences and identify stability conditions under which aggregation amplifies weak guarantees into strong ones.\n  We formalize this stability property as \\emph{$(\u03b1,\u03b2)$-boostability}. We show that geometric median aggregation achieves $(\u03b1,\u03b2)$-boostability for a broad class of divergences, with tradeoffs that depend on the underlying geometry. For vector-valued prediction and conditional density estimation, we characterize boostability under common divergences ($\\ell_1$, $\\ell_2$, $\\TV$, and $\\Hel$) with geometric median, revealing a sharp distinction between dimension-dependent and dimension-free regimes. We further show that while KL divergence is not directly boostable via geometric median aggregation, it can be handled indirectly through boostability under Hellinger distance.\n  Building on these structural results, we propose a generic boosting framework \\textsc{GeoMedBoost} based on exponential reweighting and geometric-median aggregation. Under a weak learner condition and $(\u03b1,\u03b2)$-boostability, we obtain exponential decay of the empirical divergence exceedance error. Our framework recovers classical algorithms such as \\textsc{MedBoost}, \\textsc{AdaBoost}, and \\textsc{SAMME} as special cases, and provides a unified geometric view of boosting for structured prediction.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4e00\u822c\u6563\u5ea6\u4e0b\u8fdb\u884c\u5411\u91cf\u503c\u548c\u6761\u4ef6\u5bc6\u5ea6\u9884\u6d4b\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6307\u6570\u91cd\u52a0\u6743\u548c\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u7684\u901a\u7528\u63d0\u5347\u6846\u67b6GeoMedBoost\u3002\u8be5\u6846\u67b6\u5728\u5f31\u5b66\u4e60\u5668\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u7ecf\u9a8c\u6563\u5ea6\u8d85\u6807\u8bef\u5dee\u7684\u6307\u6570\u8870\u51cf\uff0c\u540c\u65f6\u7edf\u4e00\u4e86\u51e0\u79cd\u7ecf\u5178\u63d0\u5347\u7b97\u6cd5\u7684\u51e0\u4f55\u89c6\u89d2\u3002", "motivation": "\u5c3d\u7ba1\u63d0\u5347\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u9884\u6d4b\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5bf9\u8d85\u51fa\u6807\u91cf\u635f\u5931\u4e4b\u5916\u7684\u805a\u5408\u7684\u4e00\u822c\u7406\u8bba\u7406\u89e3\u4ecd\u4e0d\u5b8c\u6574\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u5411\u91cf\u503c\u53ca\u6761\u4ef6\u5bc6\u5ea6\u9884\u6d4b\u5728\u66f4\u5e7f\u6cdb\u7684\u6563\u5ea6\u4e0b\u7684\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u805a\u5408\u6765\u589e\u5f3a\u6027\u80fd\u4fdd\u8bc1\u3002", "method": "\u5b9a\u4e49\u4e86(\u03b1,\u03b2)-\u53ef\u63d0\u5347\u6027\u4f5c\u4e3a\u7a33\u5b9a\u6027\u7684\u5f62\u5f0f\u5316\u8868\u8ff0\uff1b\u8bc1\u660e\u4e86\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u5bf9\u4e8e\u4e00\u5927\u7c7b\u6563\u5ea6\u8fbe\u5230\u4e86(\u03b1,\u03b2)-\u53ef\u63d0\u5347\u6027\uff1b\u5206\u6790\u4e86\u5e38\u89c1\u6563\u5ea6\uff08\u5982\u21131, \u21132, TV, \u548cHel\uff09\u4e0b\u5411\u91cf\u503c\u9884\u6d4b\u4e0e\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u7684\u53ef\u63d0\u5347\u6027\uff1b\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6307\u6570\u91cd\u52a0\u6743\u548c\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u7684\u65b0\u63d0\u5347\u6846\u67b6GeoMedBoost\u3002", "result": "\u53d1\u73b0\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u80fd\u591f\u5b9e\u73b0\u591a\u79cd\u6563\u5ea6\u4e0b\u7684(\u03b1,\u03b2)-\u53ef\u63d0\u5347\u6027\uff0c\u63ed\u793a\u4e86\u7ef4\u5ea6\u4f9d\u8d56\u4e0e\u7ef4\u5ea6\u65e0\u5173\u673a\u5236\u4e4b\u95f4\u7684\u660e\u663e\u533a\u522b\uff1b\u867d\u7136KL\u6563\u5ea6\u4e0d\u80fd\u76f4\u63a5\u901a\u8fc7\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u53d8\u5f97\u53ef\u63d0\u5347\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7Hellinger\u8ddd\u79bb\u95f4\u63a5\u5904\u7406\uff1b\u6240\u63d0\u51fa\u7684GeoMedBoost\u6846\u67b6\u5728\u6ee1\u8db3\u5f31\u5b66\u4e60\u8005\u6761\u4ef6\u548c(\u03b1,\u03b2)-\u53ef\u63d0\u5347\u6027\u65f6\uff0c\u80fd\u83b7\u5f97\u7ecf\u9a8c\u6563\u5ea6\u8d85\u6807\u8bef\u5dee\u7684\u6307\u6570\u8870\u51cf\u3002", "conclusion": "\u672c\u6587\u4e3a\u7ed3\u6784\u5316\u9884\u6d4b\u4e2d\u7684\u63d0\u5347\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\uff0c\u4e0d\u4ec5\u7edf\u4e00\u4e86\u51e0\u79cd\u7ecf\u5178\u7b97\u6cd5\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u51e0\u4f55\u4e2d\u4f4d\u6570\u805a\u5408\u6765\u6539\u8fdb\u9884\u6d4b\u6a21\u578b\u7684\u8868\u73b0\u3002"}}
{"id": "2602.18904", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.18904", "abs": "https://arxiv.org/abs/2602.18904", "authors": ["Hao Lu", "Onur C. Koyun", "Yongxin Guo", "Zhengjie Zhu", "Abbas Alili", "Metin Nafi Gurcan"], "title": "PCA-VAE: Differentiable Subspace Quantization without Codebook Collapse", "comment": null, "summary": "Vector-quantized autoencoders deliver high-fidelity latents but suffer inherent flaws: the quantizer is non-differentiable, requires straight-through hacks, and is prone to collapse. We address these issues at the root by replacing VQ with a simple, principled, and fully differentiable alternative: an online PCA bottleneck trained via Oja's rule. The resulting model, PCA-VAE, learns an orthogonal, variance-ordered latent basis without codebooks, commitment losses, or lookup noise. Despite its simplicity, PCA-VAE exceeds VQ-GAN and SimVQ in reconstruction quality on CelebAHQ while using 10-100x fewer latent bits. It also produces naturally interpretable dimensions (e.g., pose, lighting, gender cues) without adversarial regularization or disentanglement objectives. These results suggest that PCA is a viable replacement for VQ: mathematically grounded, stable, bit-efficient, and semantically structured, offering a new direction for generative models beyond vector quantization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684PCA-VAE\u6a21\u578b\uff0c\u5b83\u4f7f\u7528\u5728\u7ebfPCA\u74f6\u9888\u901a\u8fc7Oja\u89c4\u5219\u8bad\u7ec3\uff0c\u4ee5\u89e3\u51b3\u5411\u91cf\u91cf\u5316\u81ea\u7f16\u7801\u5668\uff08VQ-VAE\uff09\u7684\u975e\u5fae\u5206\u6027\u3001\u76f4\u901a\u6280\u5de7\u9700\u6c42\u4ee5\u53ca\u6f5c\u5728\u5d29\u6e83\u95ee\u9898\u3002\u8be5\u6a21\u578b\u5728CelebAHQ\u6570\u636e\u96c6\u4e0a\u7684\u91cd\u5efa\u8d28\u91cf\u4f18\u4e8eVQ-GAN\u548cSimVQ\uff0c\u5e76\u4e14\u4f7f\u7528\u7684\u6f5c\u53d8\u91cf\u4f4d\u6570\u5c1110\u5230100\u500d\u3002\u6b64\u5916\uff0cPCA-VAE\u81ea\u7136\u5730\u751f\u6210\u53ef\u89e3\u91ca\u7684\u7ef4\u5ea6\uff0c\u800c\u65e0\u9700\u5bf9\u6297\u6b63\u5219\u5316\u6216\u89e3\u7f20\u76ee\u6807\u3002", "motivation": "\u73b0\u6709\u7684\u5411\u91cf\u91cf\u5316\u81ea\u7f16\u7801\u5668\u5b58\u5728\u51e0\u4e2a\u5185\u5728\u7f3a\u9677\uff1a\u91cf\u5316\u5668\u4e0d\u53ef\u5fae\u5206\uff0c\u9700\u8981\u76f4\u901a\u6280\u5de7\uff0c\u5e76\u4e14\u5bb9\u6613\u53d1\u751f\u574d\u584c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5728\u7ebfPCA\u74f6\u9888\u7684\u65b0\u65b9\u6cd5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u662f\u5b8c\u5168\u53ef\u5fae\u5206\u7684\u5e76\u4e14\u66f4\u52a0\u7b80\u5355\u5408\u7406\u3002", "method": "\u63d0\u51fa\u4e86PCA-VAE\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u91c7\u7528\u5728\u7ebfPCA\u74f6\u9888\u5e76\u901a\u8fc7Oja\u89c4\u5219\u8fdb\u884c\u8bad\u7ec3\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u4ee3\u7801\u672c\u3001\u627f\u8bfa\u635f\u5931\u6216\u67e5\u627e\u566a\u58f0\uff0c\u5e76\u5b66\u4e60\u4e00\u4e2a\u6b63\u4ea4\u7684\u3001\u6309\u65b9\u5dee\u6392\u5e8f\u7684\u6f5c\u53d8\u91cf\u57fa\u3002", "result": "PCA-VAE\u5728CelebAHQ\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6bd4VQ-GAN\u548cSimVQ\u66f4\u9ad8\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u5c11\u5f97\u591a\u7684\u6f5c\u53d8\u91cf\u4f4d\u6570\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u81ea\u7136\u53ef\u89e3\u91ca\u7684\u7ef4\u5ea6\uff0c\u5982\u59ff\u6001\u3001\u5149\u7167\u548c\u6027\u522b\u7ebf\u7d22\uff0c\u800c\u65e0\u9700\u989d\u5916\u7684\u5bf9\u6297\u6b63\u5219\u5316\u6216\u89e3\u7f20\u76ee\u6807\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cPCA\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u66ff\u4ee3\u5411\u91cf\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u6570\u5b66\u57fa\u7840\u3001\u7a33\u5b9a\u6027\u3001\u6bd4\u7279\u6548\u7387\u9ad8\u4ee5\u53ca\u8bed\u4e49\u7ed3\u6784\u5316\u7684\u4f18\u70b9\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2602.18905", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.18905", "abs": "https://arxiv.org/abs/2602.18905", "authors": ["Yujiao Yang"], "title": "TRUE: A Trustworthy Unified Explanation Framework for Large Language Model Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in complex reasoning tasks, yet their decision-making processes remain difficult to interpret. Existing explanation methods often lack trustworthy structural insight and are limited to single-instance analysis, failing to reveal reasoning stability and systematic failure mechanisms. To address these limitations, we propose the Trustworthy Unified Explanation Framework (TRUE), which integrates executable reasoning verification, feasible-region directed acyclic graph (DAG) modeling, and causal failure mode analysis. At the instance level, we redefine reasoning traces as executable process specifications and introduce blind execution verification to assess operational validity. At the local structural level, we construct feasible-region DAGs via structure-consistent perturbations, enabling explicit characterization of reasoning stability and the executable region in the local input space. At the class level, we introduce a causal failure mode analysis method that identifies recurring structural failure patterns and quantifies their causal influence using Shapley values. Extensive experiments across multiple reasoning benchmarks demonstrate that the proposed framework provides multi-level, verifiable explanations, including executable reasoning structures for individual instances, feasible-region representations for neighboring inputs, and interpretable failure modes with quantified importance at the class level. These results establish a unified and principled paradigm for improving the interpretability and reliability of LLM reasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTRUE\u7684\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u591a\u5c42\u6b21\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u5305\u62ec\u5b9e\u4f8b\u7ea7\u7684\u53ef\u6267\u884c\u9a8c\u8bc1\u3001\u5c40\u90e8\u7ed3\u6784\u7ea7\u7684\u53ef\u884c\u533a\u57dfDAG\u5efa\u6a21\u4ee5\u53ca\u7c7b\u522b\u7ea7\u7684\u56e0\u679c\u5931\u6548\u6a21\u5f0f\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u4fe1\u7684\u7ed3\u6784\u6d1e\u5bdf\u529b\uff0c\u5e76\u4e14\u5c40\u9650\u4e8e\u5355\u4e2a\u5b9e\u4f8b\u5206\u6790\uff0c\u65e0\u6cd5\u63ed\u793a\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u7cfb\u7edf\u6027\u5931\u8d25\u673a\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u7406\u89e3\u5ea6\u3002", "method": "TRUE\u6846\u67b6\u7ed3\u5408\u4e86\u53ef\u6267\u884c\u63a8\u7406\u9a8c\u8bc1\u3001\u57fa\u4e8e\u53ef\u884c\u533a\u57df\u7684\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u5efa\u6a21\u4ee5\u53ca\u56e0\u679c\u5931\u6548\u6a21\u5f0f\u5206\u6790\u3002\u8be5\u6846\u67b6\u5728\u5b9e\u4f8b\u5c42\u9762\u91cd\u65b0\u5b9a\u4e49\u4e86\u63a8\u7406\u8f68\u8ff9\u5e76\u5f15\u5165\u76f2\u6267\u884c\u9a8c\u8bc1\uff1b\u5728\u5c40\u90e8\u7ed3\u6784\u5c42\u9762\u901a\u8fc7\u6784\u5efa\u4e00\u81f4\u6027\u7684\u6270\u52a8\u5f62\u6210\u53ef\u884c\u533a\u57dfDAG\uff1b\u5728\u7c7b\u522b\u5c42\u9762\uff0c\u5219\u91c7\u7528\u56e0\u679c\u5931\u6548\u6a21\u5f0f\u5206\u6790\u6cd5\u8bc6\u522b\u91cd\u590d\u51fa\u73b0\u7684\u7ed3\u6784\u6027\u5931\u8d25\u6a21\u5f0f\u5e76\u901a\u8fc7Shapley\u503c\u91cf\u5316\u5176\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u591a\u5c42\u7ea7\u7684\u3001\u53ef\u9a8c\u8bc1\u7684\u89e3\u91ca\uff0c\u5305\u62ec\u4e2a\u4f53\u5b9e\u4f8b\u7684\u53ef\u6267\u884c\u63a8\u7406\u7ed3\u6784\u3001\u90bb\u8fd1\u8f93\u5165\u7684\u53ef\u884c\u533a\u57df\u8868\u793a\u4ee5\u53ca\u5177\u6709\u91cd\u8981\u6027\u91cf\u5316\u7684\u7c7b\u522b\u7ea7\u522b\u53ef\u89e3\u91ca\u5931\u8d25\u6a21\u5f0f\u3002\u8fd9\u4e9b\u6210\u679c\u4e3a\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u5960\u5b9a\u4e86\u7edf\u4e00\u800c\u539f\u5219\u6027\u7684\u8303\u5f0f\u3002", "conclusion": "TRUE\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u9760\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b\u591a\u5c42\u6b21\u7684\u89e3\u91ca\u65b9\u5f0f\uff0c\u4f7f\u5f97\u5bf9\u4e8e\u6a21\u578b\u5982\u4f55\u505a\u51fa\u7279\u5b9a\u51b3\u7b56\u6709\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3\uff0c\u5e76\u4e14\u80fd\u591f\u66f4\u597d\u5730\u5b9a\u4f4d\u548c\u7406\u89e3\u6a21\u578b\u7684\u7cfb\u7edf\u6027\u9519\u8bef\u3002"}}
{"id": "2602.18907", "categories": ["cs.LG", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.18907", "abs": "https://arxiv.org/abs/2602.18907", "authors": ["Yangchen Zeng"], "title": "DeepInterestGR: Mining Deep Multi-Interest Using Multi-Modal LLMs for Generative Recommendation", "comment": null, "summary": "Recent generative recommendation frameworks have demonstrated remarkable scaling potential by reformulating item prediction as autoregressive Semantic ID (SID) generation. However, existing methods primarily rely on shallow behavioral signals, encoding items solely through surface-level textual features such as titles and descriptions. This reliance results in a critical Shallow Interest problem: the model fails to capture the latent, semantically rich interests underlying user interactions, limiting both personalization depth and recommendation interpretability. DeepInterestGR introduces three key innovations: (1) Multi-LLM Interest Mining (MLIM): We leverage multiple frontier LLMs along with their multi-modal variants to extract deep textual and visual interest representations through Chain-of-Thought prompting. (2) Reward-Labeled Deep Interest (RLDI): We employ a lightweight binary classifier to assign reward labels to mined interests, enabling effective supervision signals for reinforcement learning. (3) Interest-Enhanced Item Discretization (IEID): The curated deep interests are encoded into semantic embeddings and quantized into SID tokens via RQ-VAE. We adopt a two-stage training pipeline: supervised fine-tuning aligns the generative model with deep interest signals and collaborative filtering patterns, followed by reinforcement learning with GRPO optimized by our Interest-Aware Reward. Experiments on three Amazon Review benchmarks demonstrate that DeepInterestGR consistently outperforms state-of-the-art baselines across HR@K and NDCG@K metrics.", "AI": {"tldr": "DeepInterestGR\u63d0\u51fa\u4e86\u4e09\u9879\u521b\u65b0\uff1a\u591aLLM\u5174\u8da3\u6316\u6398\u3001\u5956\u52b1\u6807\u8bb0\u7684\u6df1\u5ea6\u5174\u8da3\u548c\u5174\u8da3\u589e\u5f3a\u7684\u5546\u54c1\u79bb\u6563\u5316\uff0c\u4ee5\u89e3\u51b3\u6d45\u5c42\u5174\u8da3\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728HR@K\u548cNDCG@K\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8868\u9762\u884c\u4e3a\u4fe1\u53f7\uff08\u5982\u6807\u9898\u548c\u63cf\u8ff0\u7b49\u6587\u672c\u7279\u5f81\uff09\u6765\u7f16\u7801\u9879\u76ee\uff0c\u8fd9\u5bfc\u81f4\u4e86\u6d45\u5c42\u5174\u8da3\u95ee\u9898\uff1a\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u7528\u6237\u4e92\u52a8\u80cc\u540e\u7684\u6f5c\u5728\u8bed\u4e49\u4e30\u5bcc\u7684\u5174\u8da3\uff0c\u9650\u5236\u4e86\u4e2a\u6027\u5316\u6df1\u5ea6\u548c\u63a8\u8350\u89e3\u91ca\u6027\u3002", "method": "DeepInterestGR\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff1a(1) \u591aLLM\u5174\u8da3\u6316\u6398(MLIM)\uff0c\u5229\u7528\u591a\u4e2a\u524d\u6cbfLLM\u53ca\u5176\u591a\u6a21\u6001\u53d8\u4f53\u901a\u8fc7\u601d\u7ef4\u94fe\u63d0\u793a\u63d0\u53d6\u6df1\u5c42\u6587\u672c\u548c\u89c6\u89c9\u5174\u8da3\u8868\u793a\uff1b(2) \u5956\u52b1\u6807\u8bb0\u7684\u6df1\u5ea6\u5174\u8da3(RLDI)\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4e8c\u5206\u7c7b\u5668\u4e3a\u6316\u6398\u7684\u5174\u8da3\u5206\u914d\u5956\u52b1\u6807\u7b7e\uff0c\u63d0\u4f9b\u6709\u6548\u7684\u76d1\u7763\u4fe1\u53f7\u7ed9\u5f3a\u5316\u5b66\u4e60\uff1b(3) \u5174\u8da3\u589e\u5f3a\u7684\u5546\u54c1\u79bb\u6563\u5316(IEID)\uff0c\u5c06\u7cbe\u9009\u7684\u6df1\u5ea6\u5174\u8da3\u7f16\u7801\u6210\u8bed\u4e49\u5d4c\u5165\u5e76\u901a\u8fc7RQ-VAE\u91cf\u5316\u4e3aSID\u4ee4\u724c\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff1a\u9996\u5148\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u4f7f\u751f\u6210\u6a21\u578b\u4e0e\u6df1\u5ea6\u5174\u8da3\u4fe1\u53f7\u53ca\u534f\u540c\u8fc7\u6ee4\u6a21\u5f0f\u5bf9\u9f50\uff0c\u7136\u540e\u662f\u57fa\u4e8e\u6211\u4eec\u5174\u8da3\u611f\u77e5\u5956\u52b1\u4f18\u5316\u7684GRPO\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728\u4e09\u4e2aAmazon Review\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cDeepInterestGR\u5728HR@K\u548cNDCG@K\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u3002", "conclusion": "DeepInterestGR\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u673a\u5236\u89e3\u51b3\u4e86\u5f53\u524d\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u6d45\u5c42\u5174\u8da3\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u5c55\u793a\u4e86\u5176\u76f8\u5bf9\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.18910", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18910", "abs": "https://arxiv.org/abs/2602.18910", "authors": ["Alexey Kroshnin", "Alexandra Suvorikova"], "title": "SLDP: Semi-Local Differential Privacy for Density-Adaptive Analytics", "comment": null, "summary": "Density-adaptive domain discretization is essential for high-utility privacy-preserving analytics but remains challenging under Local Differential Privacy (LDP) due to the privacy-budget costs associated with iterative refinement. We propose a novel framework, Semi-Local Differential Privacy (SLDP), that assigns a privacy region to each user based on local density and defines adjacency by the potential movement of a point within its privacy region. We present an interactive $(\\varepsilon, \u03b4)$-SLDP protocol, orchestrated by an honest-but-curious server over a public channel, to estimate these regions privately. Crucially, our framework decouples the privacy cost from the number of refinement iterations, allowing for high-resolution grids without additional privacy budget cost. We experimentally demonstrate the framework's effectiveness on estimation tasks across synthetic and real-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5373\u534a\u5c40\u90e8\u5dee\u5206\u9690\u79c1\uff08SLDP\uff09\uff0c\u8be5\u6846\u67b6\u6839\u636e\u5c40\u90e8\u5bc6\u5ea6\u4e3a\u6bcf\u4e2a\u7528\u6237\u5206\u914d\u4e00\u4e2a\u9690\u79c1\u533a\u57df\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7ec6\u5316\u6765\u4f30\u8ba1\u8fd9\u4e9b\u533a\u57df\u3002\u91cd\u8981\u7684\u662f\uff0c\u6b64\u6846\u67b6\u5c06\u9690\u79c1\u6210\u672c\u4e0e\u7ec6\u5316\u8fed\u4ee3\u6b21\u6570\u89e3\u8026\uff0c\u4ece\u800c\u5141\u8bb8\u5728\u4e0d\u589e\u52a0\u989d\u5916\u9690\u79c1\u9884\u7b97\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u7f51\u683c\u3002", "motivation": "\u5728\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u4e0b\u8fdb\u884c\u5bc6\u5ea6\u81ea\u9002\u5e94\u57df\u79bb\u6563\u5316\u5bf9\u4e8e\u9ad8\u5b9e\u7528\u6027\u9690\u79c1\u4fdd\u62a4\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u4e0e\u8fed\u4ee3\u7ec6\u5316\u76f8\u5173\u7684\u9690\u79c1\u9884\u7b97\u6210\u672c\u800c\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86Semi-Local Differential Privacy (SLDP) \u6846\u67b6\uff0c\u5b83\u57fa\u4e8e\u5c40\u90e8\u5bc6\u5ea6\u7ed9\u6bcf\u4e2a\u7528\u6237\u5206\u914d\u9690\u79c1\u533a\u57df\uff0c\u5e76\u901a\u8fc7\u70b9\u5728\u5176\u9690\u79c1\u533a\u57df\u5185\u53ef\u80fd\u7684\u79fb\u52a8\u6765\u5b9a\u4e49\u90bb\u63a5\u5173\u7cfb\u3002\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684(\u03b5, \u03b4)-SLDP\u534f\u8bae\uff0c\u7531\u4e00\u4e2a\u8bda\u5b9e\u4f46\u597d\u5947\u7684\u670d\u52a1\u7aef\u901a\u8fc7\u516c\u5171\u6e20\u9053\u534f\u8c03\uff0c\u4ee5\u79c1\u5bc6\u65b9\u5f0f\u4f30\u8ba1\u8fd9\u4e9b\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u4f30\u8ba1\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684SLDP\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6570\u636e\u5206\u6790\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5b83\u80fd\u591f\u5728\u4e0d\u6d88\u8017\u66f4\u591a\u9690\u79c1\u9884\u7b97\u7684\u524d\u63d0\u4e0b\u652f\u6301\u591a\u6b21\u8fed\u4ee3\u4f18\u5316\u3002"}}
{"id": "2602.18911", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18911", "abs": "https://arxiv.org/abs/2602.18911", "authors": ["Peter Romero", "Fernando Mart\u00ednez-Plumed", "Zachary R. Tyler", "Matthieu T\u00e9h\u00e9nan", "Sipeng Chen", "\u00c1lvaro David G\u00f3mez Ant\u00f3n", "Luning Sun", "Manuel Cebrian", "Lexin Zhou", "Yael Moros Daval", "Daniel Romero-Alvarado", "F\u00e9lix Mart\u00ed P\u00e9rez", "Kevin Wei", "Jos\u00e9 Hern\u00e1ndez-Orallo"], "title": "From Human-Level AI Tales to AI Leveling Human Scales", "comment": "23 pages, 10 figures. submitted to ICML 2026", "summary": "Comparing AI models to \"human level\" is often misleading when benchmark scores are incommensurate or human baselines are drawn from a narrow population. To address this, we propose a framework that calibrates items against the 'world population' and report performance on a common, human-anchored scale. Concretely, we build on a set of multi-level scales for different capabilities where each level should represent a probability of success of the whole world population on a logarithmic scale with a base $B$. We calibrate each scale for each capability (reasoning, comprehension, knowledge, volume, etc.) by compiling publicly released human test data spanning education and reasoning benchmarks (PISA, TIMSS, ICAR, UKBioBank, and ReliabilityBench). The base $B$ is estimated by extrapolating between samples with two demographic profiles using LLMs, with the hypothesis that they condense rich information about human populations. We evaluate the quality of different mappings using group slicing and post-stratification. The new techniques allow for the recalibration and standardization of scales relative to the whole-world population.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06AI\u6a21\u578b\u4e0e'\u5168\u7403\u4eba\u53e3'\u8fdb\u884c\u6821\u51c6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u591a\u7ea7\u80fd\u529b\u91cf\u8868\u5e76\u4f7f\u7528\u516c\u5f00\u7684\u4eba\u7c7b\u6d4b\u8bd5\u6570\u636e\u6765\u6821\u51c6\u6bcf\u4e2a\u91cf\u8868\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9AI\u6027\u80fd\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u6bd4\u8f83AI\u6a21\u578b\u4e0e'\u4eba\u7c7b\u6c34\u5e73'\u65f6\uff0c\u57fa\u51c6\u5206\u6570\u5f80\u5f80\u65e0\u6cd5\u76f4\u63a5\u6bd4\u8f83\u6216\u4eba\u7c7b\u57fa\u7ebf\u6765\u81ea\u72ed\u9698\u7684\u4eba\u7fa4\u6837\u672c\u3002\u4e3a\u4e86\u66f4\u51c6\u786e\u5730\u8861\u91cfAI\u7684\u8868\u73b0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5168\u7403\u4eba\u53e3\u6821\u51c6\u7684\u65b0\u6846\u67b6\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u4e00\u5957\u9488\u5bf9\u4e0d\u540c\u80fd\u529b\uff08\u5982\u63a8\u7406\u3001\u7406\u89e3\u3001\u77e5\u8bc6\u7b49\uff09\u7684\u591a\u7ea7\u91cf\u8868\uff0c\u5e76\u5229\u7528\u516c\u5f00\u53d1\u5e03\u7684\u6559\u80b2\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\uff08PISA, TIMSS, ICAR, UKBioBank, ReliabilityBench\uff09\u6765\u6821\u51c6\u6bcf\u9879\u80fd\u529b\u7684\u91cf\u8868\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u6765\u4f30\u8ba1\u57fa\u7840\u503cB\uff0c\u5047\u8bbe\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u6d53\u7f29\u5173\u4e8e\u4eba\u7c7b\u7fa4\u4f53\u7684\u4e30\u5bcc\u4fe1\u606f\u3002", "result": "\u65b0\u65b9\u6cd5\u5141\u8bb8\u76f8\u5bf9\u4e8e\u5168\u7403\u4eba\u53e3\u91cd\u65b0\u6821\u51c6\u548c\u6807\u51c6\u5316\u91cf\u8868\uff0c\u63d0\u9ad8\u4e86AI\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u73b0\u5bf9\u6bd4\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6821\u51c6\u6846\u67b6\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u52a0\u516c\u5e73\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u8bc4\u4ef7\u6807\u51c6\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3AI\u76f8\u5bf9\u4e8e\u6574\u4e2a\u4eba\u7c7b\u793e\u4f1a\u7684\u80fd\u529b\u6c34\u5e73\u3002"}}
{"id": "2602.18946", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18946", "abs": "https://arxiv.org/abs/2602.18946", "authors": ["Sacchit Kale", "Piyushi Manupriya", "Pierre Marion", "Francis bach", "Anant Raj"], "title": "Exponential Convergence of (Stochastic) Gradient Descent for Separable Logistic Regression", "comment": null, "summary": "Gradient descent and stochastic gradient descent are central to modern machine learning, yet their behavior under large step sizes remains theoretically unclear. Recent work suggests that acceleration often arises near the edge of stability, where optimization trajectories become unstable and difficult to analyze. Existing results for separable logistic regression achieve faster convergence by explicitly leveraging such unstable regimes through constant or adaptive large step sizes. In this paper, we show that instability is not inherent to acceleration. We prove that gradient descent with a simple, non-adaptive increasing step-size schedule achieves exponential convergence for separable logistic regression under a margin condition, while remaining entirely within a stable optimization regime. The resulting method is anytime and does not require prior knowledge of the optimization horizon or target accuracy. We also establish exponential convergence of stochastic gradient descent using a lightweight adaptive step-size rule that avoids line search and specialized procedures, improving upon existing polynomial-rate guarantees. Together, our results demonstrate that carefully structured step-size growth alone suffices to obtain exponential acceleration for both gradient descent and stochastic gradient descent.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u901a\u8fc7\u4f7f\u7528\u7b80\u5355\u4e14\u975e\u81ea\u9002\u5e94\u7684\u9012\u589e\u6b65\u957f\u8ba1\u5212\uff0c\u68af\u5ea6\u4e0b\u964d\u53ef\u4ee5\u5728\u5b8c\u5168\u7a33\u5b9a\u7684\u4f18\u5316\u72b6\u6001\u4e0b\u5b9e\u73b0\u53ef\u5206\u79bb\u903b\u8f91\u56de\u5f52\u4e0b\u7684\u6307\u6570\u6536\u655b\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u5c55\u793a\u4e86\u4f7f\u7528\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u6b65\u957f\u89c4\u5219\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u80fd\u591f\u83b7\u5f97\u6307\u6570\u52a0\u901f\uff0c\u4ece\u800c\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u591a\u9879\u5f0f\u901f\u7387\u4fdd\u8bc1\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u5728\u63a5\u8fd1\u7a33\u5b9a\u6027\u8fb9\u7f18\u65f6\uff0c\u7ecf\u5e38\u4f1a\u51fa\u73b0\u52a0\u901f\u73b0\u8c61\uff0c\u6b64\u65f6\u4f18\u5316\u8f68\u8ff9\u53d8\u5f97\u4e0d\u7a33\u5b9a\u4e14\u96be\u4ee5\u5206\u6790\u3002\u672c\u6587\u65e8\u5728\u5c55\u793a\u52a0\u901f\u5e76\u4e0d\u4e00\u5b9a\u9700\u8981\u4f9d\u8d56\u4e8e\u4e0d\u7a33\u5b9a\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u5e76\u8bd5\u56fe\u8bc1\u660e\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6b65\u957f\u589e\u957f\u65b9\u6848\uff0c\u5373\u4f7f\u5728\u7a33\u5b9a\u533a\u57df\u5185\u4e5f\u80fd\u4e3a\u68af\u5ea6\u4e0b\u964d\u548c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u83b7\u5f97\u6307\u6570\u52a0\u901f\u6548\u679c\u3002", "method": "\u7814\u7a76\u8005\u91c7\u7528\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u3001\u975e\u81ea\u9002\u5e94\u7684\u6b65\u957f\u9012\u589e\u7b56\u7565\u6765\u8bc1\u660e\u68af\u5ea6\u4e0b\u964d\u6cd5\u80fd\u591f\u5728\u6ee1\u8db3\u4e00\u5b9a\u95f4\u9694\u6761\u4ef6\u4e0b\u5bf9\u53ef\u5206\u79bb\u903b\u8f91\u56de\u5f52\u95ee\u9898\u8fbe\u5230\u6307\u6570\u7ea7\u522b\u7684\u5feb\u901f\u6536\u655b\uff0c\u5e76\u4e14\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u5728\u7a33\u5b9a\u72b6\u6001\u3002\u5bf9\u4e8e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5\u5219\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u9700\u8981\u7ebf\u6027\u641c\u7d22\u6216\u7279\u6b8a\u7a0b\u5e8f\u7684\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94\u6b65\u957f\u89c4\u5219\uff0c\u4e5f\u5b9e\u73b0\u4e86\u6307\u6570\u7ea7\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u975e\u81ea\u9002\u5e94\u9012\u589e\u6b65\u957f\u7684\u65b9\u6cd5\u786e\u5b9e\u80fd\u591f\u8ba9\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u5728\u5904\u7406\u53ef\u5206\u79bb\u903b\u8f91\u56de\u5f52\u4efb\u52a1\u65f6\u8fbe\u5230\u9884\u671f\u7684\u6307\u6570\u7ea7\u52a0\u901f\u6548\u679c\uff1b\u540c\u65f6\uff0c\u5bf9\u4e8e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u800c\u8a00\uff0c\u65b0\u5f15\u5165\u7684\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u673a\u5236\u540c\u6837\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5176\u6536\u655b\u901f\u5ea6\u81f3\u6307\u6570\u7ea7\u522b\u3002", "conclusion": "\u672c\u6587\u7684\u7814\u7a76\u6210\u679c\u8868\u660e\uff0c\u4ec5\u4ec5\u901a\u8fc7\u5bf9\u6b65\u957f\u589e\u957f\u65b9\u5f0f\u8fdb\u884c\u6070\u5f53\u7684\u8bbe\u8ba1\uff0c\u5c31\u8db3\u4ee5\u4f7f\u5f97\u68af\u5ea6\u4e0b\u964d\u548c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u8fd9\u4e24\u79cd\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u9886\u57df\u4e2d\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u5904\u7406\u7279\u5b9a\u7c7b\u578b\u7684\u95ee\u9898\u65f6\uff08\u5982\u7b26\u5408\u4e00\u5b9a\u6761\u4ef6\u7684\u53ef\u5206\u79bb\u903b\u8f91\u56de\u5f52\uff09\uff0c\u65e0\u9700\u8fdb\u5165\u4e0d\u7a33\u5b9a\u533a\u57df\u5c31\u80fd\u5b9e\u73b0\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2602.18948", "categories": ["cs.LG", "cs.NE", "hep-th", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18948", "abs": "https://arxiv.org/abs/2602.18948", "authors": ["J. Fran\u00e7ois", "L. Ravera"], "title": "Toward Manifest Relationality in Transformers via Symmetry Reduction", "comment": "12 pages", "summary": "Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u79f0\u6027\u51cf\u5c11\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u4e0d\u53d8\u7684\u5173\u7cfb\u91cf\u6765\u91cd\u65b0\u8868\u8ff0\u8868\u793a\u3001\u6ce8\u610f\u529b\u673a\u5236\u548c\u4f18\u5316\u52a8\u529b\u5b66\uff0c\u4ece\u800c\u76f4\u63a5\u5728\u5173\u7cfb\u7ed3\u6784\u4e0a\u64cd\u4f5c\uff0c\u4ee5\u51cf\u5c11\u53c2\u6570\u5197\u4f59\u5e76\u63d0\u4f9b\u4e00\u4e2a\u6709\u539f\u5219\u7684\u51e0\u4f55\u6846\u67b6\u6765\u5206\u6790\u4f18\u5316\u3002", "motivation": "\u7531\u4e8eTransformer\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5750\u6807\u4f9d\u8d56\u8868\u793a\u548c\u8fde\u7eed\u5bf9\u79f0\u6027\u5bfc\u81f4\u4e86\u5185\u90e8\u5197\u4f59\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u79f0\u6027\u51cf\u5c11\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u4e0d\u53d8\u7684\u5173\u7cfb\u91cf\u6765\u91cd\u6784\u8868\u793a\u3001\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u53ca\u4f18\u5316\u8fc7\u7a0b\uff0c\u4ece\u800c\u53bb\u9664\u6784\u9020\u4e2d\u7684\u591a\u4f59\u81ea\u7531\u5ea6\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u591f\u76f4\u63a5\u5904\u7406\u5173\u7cfb\u7ed3\u6784\u7684\u67b6\u6784\uff0c\u8fd9\u4e3a\u51cf\u5c11\u53c2\u6570\u5197\u4f59\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4f18\u5316\u8fc7\u7a0b\u7684\u5206\u6790\u4e5f\u6709\u4e86\u66f4\u52a0\u51e0\u4f55\u5316\u7684\u7406\u89e3\u65b9\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u79f0\u6027\u51cf\u5c11\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u964d\u4f4eTransformer\u6a21\u578b\u7684\u53c2\u6570\u5197\u4f59\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u548c\u6539\u8fdb\u6a21\u578b\u7684\u4f18\u5316\u8fc7\u7a0b\u3002"}}
{"id": "2602.18955", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18955", "abs": "https://arxiv.org/abs/2602.18955", "authors": ["Philip Mortimer", "Cristiana Diaconu", "Tommy Rochussen", "Bruno Mlodozeniec", "Richard E. Turner"], "title": "Incremental Transformer Neural Processes", "comment": "Code provided at https://github.com/philipmortimer/incTNP-code", "summary": "Neural Processes (NPs), and specifically Transformer Neural Processes (TNPs), have demonstrated remarkable performance across tasks ranging from spatiotemporal forecasting to tabular data modelling. However, many of these applications are inherently sequential, involving continuous data streams such as real-time sensor readings or database updates. In such settings, models should support cheap, incremental updates rather than recomputing internal representations from scratch for every new observation -- a capability existing TNP variants lack. Drawing inspiration from Large Language Models, we introduce the Incremental TNP (incTNP). By leveraging causal masking, Key-Value (KV) caching, and a data-efficient autoregressive training strategy, incTNP matches the predictive performance of standard TNPs while reducing the computational cost of updates from quadratic to linear time complexity. We empirically evaluate our model on a range of synthetic and real-world tasks, including tabular regression and temperature prediction. Our results show that, surprisingly, incTNP delivers performance comparable to -- or better than -- non-causal TNPs while unlocking orders-of-magnitude speedups for sequential inference. Finally, we assess the consistency of the model's updates -- by adapting a metric of ``implicit Bayesianness\", we show that incTNP retains a prediction rule as implicitly Bayesian as standard non-causal TNPs, demonstrating that incTNP achieves the computational benefits of causal masking without sacrificing the consistency required for streaming inference.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u589e\u91cfTNP\uff08incTNP\uff09\u7684\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u91c7\u7528\u56e0\u679c\u906e\u7f69\u3001\u952e\u503c\u7f13\u5b58\u4ee5\u53ca\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u81ea\u56de\u5f52\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u4e0e\u6807\u51c6TNPs\u76f8\u540c\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u66f4\u65b0\u7684\u8ba1\u7b97\u6210\u672c\u4ece\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u7ebf\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cincTNP\u4e0d\u4ec5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u4f18\u4e8e\u975e\u56e0\u679cTNPs\uff0c\u5e76\u4e14\u5728\u987a\u5e8f\u63a8\u7406\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8c03\u6574\u201c\u9690\u5f0f\u8d1d\u53f6\u65af\u6027\u201d\u6307\u6807\u6765\u8bc4\u4f30\u6a21\u578b\u66f4\u65b0\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0incTNP\u4fdd\u6301\u4e86\u4e0e\u6807\u51c6\u975e\u56e0\u679cTNPs\u4e00\u6837\u9690\u5f0f\u7684\u8d1d\u53f6\u65af\u9884\u6d4b\u89c4\u5219\uff0c\u8bc1\u660e\u4e86\u5b83\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6d41\u5f0f\u63a8\u7406\u6240\u9700\u4e00\u81f4\u6027\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u56e0\u679c\u906e\u7f69\u5e26\u6765\u7684\u8ba1\u7b97\u4f18\u52bf\u3002", "motivation": "\u8bb8\u591a\u5e94\u7528\u672c\u8d28\u4e0a\u662f\u987a\u5e8f\u6027\u7684\uff0c\u6d89\u53ca\u8fde\u7eed\u7684\u6570\u636e\u6d41\u5982\u5b9e\u65f6\u4f20\u611f\u5668\u8bfb\u6570\u6216\u6570\u636e\u5e93\u66f4\u65b0\u3002\u5728\u8fd9\u4e9b\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u5e94\u8be5\u652f\u6301\u5ec9\u4ef7\u7684\u589e\u91cf\u66f4\u65b0\u800c\u975e\u6bcf\u6b21\u65b0\u89c2\u5bdf\u65f6\u90fd\u91cd\u65b0\u8ba1\u7b97\u5185\u90e8\u8868\u793a\u2014\u2014\u8fd9\u662f\u73b0\u6709TNP\u53d8\u4f53\u6240\u7f3a\u4e4f\u7684\u80fd\u529b\u3002", "method": "\u53d7\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86Incremental TNP (incTNP)\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u56e0\u679c\u63a9\u7801\u3001\u952e\u503c(KV)\u7f13\u5b58\u548c\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u7684\u81ea\u56de\u5f52\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u5f97incTNP\u80fd\u591f\u5339\u914d\u6807\u51c6TNPs\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u66f4\u65b0\u7684\u8ba1\u7b97\u6210\u672c\u4ece\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u51cf\u5c11\u81f3\u7ebf\u6027\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5408\u6210\u548c\u5b9e\u9645\u4efb\u52a1\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u5305\u62ec\u8868\u683c\u56de\u5f52\u548c\u6e29\u5ea6\u9884\u6d4b\u7b49\uff0c\u7ed3\u679c\u663e\u793aincTNP\u4e0d\u4ec5\u80fd\u63d0\u4f9b\u4e0e\u975e\u56e0\u679cTNPs\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u8868\u73b0\uff0c\u800c\u4e14\u4e3a\u987a\u5e8f\u63a8\u7406\u5e26\u6765\u4e86\u6570\u91cf\u7ea7\u4e0a\u7684\u52a0\u901f\u3002\u53e6\u5916\uff0c\u901a\u8fc7\u8c03\u6574\u4e00\u79cd\u8861\u91cf\u2018\u9690\u5f0f\u8d1d\u53f6\u65af\u6027\u2019\u7684\u6307\u6807\u6765\u68c0\u9a8c\u6a21\u578b\u66f4\u65b0\u7684\u4e00\u81f4\u6027\uff0c\u7814\u7a76\u8868\u660eincTNP\u7ef4\u6301\u4e86\u4e00\u4e2a\u4e0e\u6807\u51c6\u975e\u56e0\u679cTNPs\u540c\u6837\u9690\u542b\u8d1d\u53f6\u65af\u7279\u6027\u7684\u9884\u6d4b\u89c4\u5219\u3002", "conclusion": "incTNP\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u906e\u7f69\u3001\u952e\u503c\u7f13\u5b58\u53ca\u81ea\u56de\u5f52\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5904\u7406\u8fde\u7eed\u6570\u636e\u6d41\u65f6\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5feb\u901f\u54cd\u5e94\u6700\u65b0\u6570\u636e\u53d8\u5316\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.19020", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.19020", "abs": "https://arxiv.org/abs/2602.19020", "authors": ["Junjie Oscar Yin", "John X. Morris", "Vitaly Shmatikov", "Sewon Min", "Hannaneh Hajishirzi"], "title": "Learning to Detect Language Model Training Data via Active Reconstruction", "comment": null, "summary": "Detecting LLM training data is generally framed as a membership inference attack (MIA) problem. However, conventional MIAs operate passively on fixed model weights, using log-likelihoods or text generations. In this work, we introduce \\textbf{Active Data Reconstruction Attack} (ADRA), a family of MIA that actively induces a model to reconstruct a given text through training. We hypothesize that training data are \\textit{more reconstructible} than non-members, and the difference in their reconstructibility can be exploited for membership inference. Motivated by findings that reinforcement learning (RL) sharpens behaviors already encoded in weights, we leverage on-policy RL to actively elicit data reconstruction by finetuning a policy initialized from the target model. To effectively use RL for MIA, we design reconstruction metrics and contrastive rewards. The resulting algorithms, \\textsc{ADRA} and its adaptive variant \\textsc{ADRA+}, improve both reconstruction and detection given a pool of candidate data. Experiments show that our methods consistently outperform existing MIAs in detecting pre-training, post-training, and distillation data, with an average improvement of 10.7\\% over the previous runner-up. In particular, \\MethodPlus~improves over Min-K\\%++ by 18.8\\% on BookMIA for pre-training detection and by 7.6\\% on AIME for post-training detection.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb(ADRA)\uff0c\u901a\u8fc7\u4e3b\u52a8\u8bf1\u5bfc\u6a21\u578b\u91cd\u5efa\u7ed9\u5b9a\u6587\u672c\u6765\u8fdb\u884c\u3002\u5229\u7528\u5728\u7ebf\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\uff0c\u8bbe\u8ba1\u4e86\u91cd\u5efa\u5ea6\u91cf\u548c\u5bf9\u6bd4\u5956\u52b1\u6765\u63d0\u9ad8\u6570\u636e\u91cd\u5efa\u548c\u68c0\u6d4b\u6548\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u548c\u84b8\u998f\u6570\u636e\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e73\u5747\u63d0\u9ad8\u4e8610.7%\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIA\uff09\u901a\u5e38\u57fa\u4e8e\u56fa\u5b9a\u6a21\u578b\u6743\u91cd\u88ab\u52a8\u5730\u8fdb\u884c\uff0c\u4f7f\u7528\u5bf9\u6570\u4f3c\u7136\u6216\u6587\u672c\u751f\u6210\u7b49\u65b9\u5f0f\u3002\u800c\u8fd9\u9879\u5de5\u4f5c\u5047\u8bbe\u8bad\u7ec3\u6570\u636e\u6bd4\u975e\u6210\u5458\u66f4\u6613\u4e8e\u88ab\u91cd\u5efa\uff0c\u5e76\u8bd5\u56fe\u901a\u8fc7\u4e00\u79cd\u65b0\u578b\u7684\u4e3b\u52a8\u6570\u636e\u91cd\u5efa\u653b\u51fb\uff08ADRA\uff09\u6765\u5229\u7528\u8fd9\u79cd\u5dee\u5f02\u8fdb\u884c\u6210\u5458\u63a8\u65ad\u3002\u53d7\u5230\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u589e\u5f3a\u6743\u91cd\u4e2d\u5df2\u7f16\u7801\u884c\u4e3a\u7684\u7814\u7a76\u53d1\u73b0\u542f\u53d1\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u8fd9\u79cd\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Active Data Reconstruction Attack (ADRA) \u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u5f0f\uff0c\u5b83\u901a\u8fc7\u8bad\u7ec3\u79ef\u6781\u8bf1\u5bfc\u6a21\u578b\u91cd\u5efa\u7279\u5b9a\u6587\u672c\u3002\u4e3a\u6709\u6548\u8fd0\u7528\u5f3a\u5316\u5b66\u4e60\u6267\u884cMIA\u4efb\u52a1\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u91cd\u5efa\u6307\u6807\u548c\u5bf9\u6bd4\u5956\u52b1\u673a\u5236\u3002\u57fa\u4e8e\u8fd9\u4e9b\u8bbe\u8ba1\u7406\u5ff5\uff0c\u5f62\u6210\u4e86ADRA\u53ca\u5176\u81ea\u9002\u5e94\u7248\u672cADRA+\u4e24\u79cd\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u7684MIA\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8bc6\u522b\u9884\u8bad\u7ec3\u3001\u540e\u8bad\u7ec3\u4ee5\u53ca\u84b8\u998f\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u603b\u4f53\u4e0a\u5b9e\u73b0\u4e86\u76f8\u5bf9\u4e8e\u6b21\u4f18\u65b9\u6848\u7ea610.7%\u7684\u6027\u80fd\u63d0\u5347\u3002\u7279\u522b\u662f\uff0c\u5728BookMIA\u6d4b\u8bd5\u4e2d\u7684\u9884\u8bad\u7ec3\u6570\u636e\u68c0\u6d4b\u4e0a\uff0cADRA+\u76f8\u8f83\u4e8eMin-K%++\u63d0\u5347\u4e8618.8%\uff0c\u800c\u5728AIME\u4e0a\u7684\u540e\u8bad\u7ec3\u6570\u636e\u68c0\u6d4b\u4e0a\u5219\u63d0\u9ad8\u4e867.6%\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e3b\u52a8\u5f0f\u7684\u6570\u636e\u91cd\u5efa\u653b\u51fb\uff08ADRA\uff09\uff0c\u7ed3\u5408\u5728\u7ebf\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u53ca\u4e13\u95e8\u8bbe\u8ba1\u7684\u91cd\u5efa\u8bc4\u4ef7\u6807\u51c6\u4e0e\u5956\u60e9\u7cfb\u7edf\uff0c\u7814\u7a76\u8005\u4eec\u6210\u529f\u5f00\u53d1\u51fa\u4e00\u79cd\u80fd\u66f4\u6709\u6548\u5730\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u63a8\u65ad\u5176\u8bad\u7ec3\u6570\u636e\u96c6\u6210\u5458\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.19027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19027", "abs": "https://arxiv.org/abs/2602.19027", "authors": ["Haoyu Yang", "Haoxing Ren"], "title": "Pushing the Limits of Inverse Lithography with Generative Reinforcement Learning", "comment": "7 pages, 4 figures, accepted by the 63th Design Automation Conference", "summary": "Inverse lithography (ILT) is critical for modern semiconductor manufacturing but suffers from highly non-convex objectives that often trap optimization in poor local minima. Generative AI has been explored to warm-start ILT, yet most approaches train deterministic image-to-image translators to mimic sub-optimal datasets, providing limited guidance for escaping non-convex traps during refinement. We reformulate mask synthesis as conditional sampling: a generator learns a distribution over masks conditioned on the design and proposes multiple candidates. The generator is first pretrained with WGAN plus a reconstruction loss, then fine-tuned using Group Relative Policy Optimization (GRPO) with an ILT-guided imitation loss. At inference, we sample a small batch of masks, run fast batched ILT refinement, evaluate lithography metrics (e.g., EPE, process window), and select the best candidate. On \\texttt{LithoBench} dataset, the proposed hybrid framework reduces EPE violations under a 3\\,nm tolerance and roughly doubles throughput versus a strong numerical ILT baseline, while improving final mask quality. We also present over 20\\% EPE improvement on \\texttt{ICCAD13} contest cases with 3$\\times$ speedup over the SOTA numerical ILT solver. By learning to propose ILT-friendly initializations, our approach mitigates non-convexity and advances beyond what traditional solvers or GenAI can achieve.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u751f\u6210\u5f0fAI\u548c\u9006\u5411\u5149\u523b\u6280\u672f\uff08ILT\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u751f\u6210\u5668\u6765\u5b66\u4e60\u7ed9\u5b9a\u8bbe\u8ba1\u6761\u4ef6\u4e0b\u7684\u63a9\u6a21\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u591a\u4e2a\u5019\u9009\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u4f7f\u7528WGAN\u52a0\u4e0a\u91cd\u5efa\u635f\u5931\u9884\u8bad\u7ec3\u751f\u6210\u5668\uff0c\u7136\u540e\u901a\u8fc7\u5e26\u6709ILT\u5f15\u5bfc\u6a21\u4eff\u635f\u5931\u7684\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u8fdb\u884c\u5fae\u8c03\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6b64\u65b9\u6cd5\u5728\u51cf\u5c11EPE\u8fdd\u89c4\u3001\u63d0\u9ad8\u5904\u7406\u901f\u5ea6\u53ca\u6700\u7ec8\u63a9\u6a21\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u9006\u5411\u5149\u523b\u6280\u672f\u5bf9\u4e8e\u73b0\u4ee3\u534a\u5bfc\u4f53\u5236\u9020\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u9ad8\u5ea6\u975e\u51f8\u7684\u76ee\u6807\u51fd\u6570\u7ecf\u5e38\u5bfc\u81f4\u4f18\u5316\u9677\u5165\u5c40\u90e8\u6700\u5c0f\u503c\u3002\u5c3d\u7ba1\u5df2\u7ecf\u6709\u4eba\u5c1d\u8bd5\u7528\u751f\u6210\u5f0fAI\u4e3aILT\u63d0\u4f9b\u521d\u59cb\u4f30\u8ba1\uff0c\u4f46\u5927\u591a\u6570\u65b9\u6cd5\u53ea\u80fd\u6a21\u4eff\u6b21\u4f18\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6709\u6548\u5e2e\u52a9\u4f18\u5316\u8fc7\u7a0b\u907f\u5f00\u975e\u51f8\u9677\u9631\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5c06\u63a9\u6a21\u5408\u6210\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6761\u4ef6\u91c7\u6837\u4efb\u52a1\uff0c\u5176\u4e2d\u751f\u6210\u5668\u5b66\u4e60\u4e86\u57fa\u4e8e\u7279\u5b9a\u8bbe\u8ba1\u6761\u4ef6\u4e0b\u7684\u63a9\u6a21\u5206\u5e03\u5e76\u80fd\u63d0\u51fa\u591a\u4e2a\u5019\u9009\u65b9\u6848\u3002\u9996\u5148\uff0c\u91c7\u7528WGAN\u52a0\u4e0a\u91cd\u5efa\u635f\u5931\u5bf9\u751f\u6210\u5668\u8fdb\u884c\u9884\u8bad\u7ec3\uff1b\u968f\u540e\uff0c\u5229\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u914d\u5408\u4e00\u79cd\u57fa\u4e8eILT\u6307\u5bfc\u7684\u6a21\u4eff\u635f\u5931\u5bf9\u8be5\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u4ece\u751f\u6210\u5668\u4e2d\u62bd\u53d6\u4e00\u5c0f\u6279\u63a9\u6a21\u6837\u672c\uff0c\u7ecf\u8fc7\u5feb\u901f\u6279\u91cfILT\u7ec6\u5316\u540e\uff0c\u6839\u636e\u5149\u523b\u5ea6\u91cf\uff08\u5982EPE\u3001\u5de5\u827a\u7a97\u53e3\u7b49\uff09\u9009\u62e9\u6700\u4f73\u5019\u9009\u8005\u3002", "result": "\u5728LithoBench\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u76f8\u6bd4\u5f3a\u5927\u7684\u6570\u503cILT\u57fa\u7ebf\u51cf\u5c11\u4e863nm\u5bb9\u5dee\u4e0b\u7684EPE\u8fdd\u89c4\u60c5\u51b5\uff0c\u5e76\u4e14\u5927\u7ea6\u63d0\u9ad8\u4e86\u4e24\u500d\u7684\u541e\u5410\u91cf\uff0c\u540c\u65f6\u6539\u5584\u4e86\u6700\u7ec8\u63a9\u6a21\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u5728ICCAD13\u7ade\u8d5b\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc720%\u7684EPE\u6539\u8fdb\u4ee5\u53ca\u76f8\u5bf9\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6570\u503cILT\u6c42\u89e3\u56683\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u63d0\u51fa\u6709\u5229\u4e8eILT\u5904\u7406\u7684\u521d\u59cb\u5316\u65b9\u6848\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u7f13\u89e3\u7531\u975e\u51f8\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u5e76\u8d85\u8d8a\u4f20\u7edf\u6c42\u89e3\u5668\u6216\u5355\u7eaf\u4f9d\u9760\u751f\u6210\u5f0fAI\u6240\u80fd\u8fbe\u5230\u7684\u6548\u679c\u3002"}}
{"id": "2602.19033", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.19033", "abs": "https://arxiv.org/abs/2602.19033", "authors": ["Vibhas Kumar Vats", "David J. Crandall", "Samuel Goree"], "title": "A Markovian View of Iterative-Feedback Loops in Image Generative Models: Neural Resonance and Model Collapse", "comment": "A preprint -- Under review", "summary": "AI training datasets will inevitably contain AI-generated examples, leading to ``feedback'' in which the output of one model impacts the training of another. It is known that such iterative feedback can lead to model collapse, yet the mechanisms underlying this degeneration remain poorly understood. Here we show that a broad class of feedback processes converges to a low-dimensional invariant structure in latent space, a phenomenon we call neural resonance. By modeling iterative feedback as a Markov Chain, we show that two conditions are needed for this resonance to occur: ergodicity of the feedback process and directional contraction of the latent representation. By studying diffusion models on MNIST and ImageNet, as well as CycleGAN and an audio feedback experiment, we map how local and global manifold geometry evolve, and we introduce an eight-pattern taxonomy of collapse behaviors. Neural resonance provides a unified explanation for long-term degenerate behavior in generative models and provides practical diagnostics for identifying, characterizing, and eventually mitigating collapse.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cAI\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u7684AI\u751f\u6210\u6837\u672c\u4f1a\u5bfc\u81f4\u6a21\u578b\u95f4\u53cd\u9988\uff0c\u8fd9\u79cd\u53cd\u9988\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\u3002\u901a\u8fc7\u5c06\u8fed\u4ee3\u53cd\u9988\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u7814\u7a76\u4eba\u5458\u8bc6\u522b\u51fa\u5bfc\u81f4\u795e\u7ecf\u5171\u632f\u73b0\u8c61\u7684\u4e24\u4e2a\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u5b9e\u9a8c\u5c55\u793a\u4e86\u8fd9\u79cd\u73b0\u8c61\uff0c\u63d0\u51fa\u4e86\u516b\u79cd\u5d29\u6e83\u884c\u4e3a\u6a21\u5f0f\u3002\u795e\u7ecf\u5171\u632f\u4e3a\u751f\u6210\u6a21\u578b\u4e2d\u7684\u957f\u671f\u9000\u5316\u884c\u4e3a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89e3\u91ca\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bca\u65ad\u548c\u6700\u7ec8\u7f13\u89e3\u5d29\u6e83\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u7684\u6570\u636e\u4e0d\u53ef\u907f\u514d\u5730\u88ab\u5305\u542b\u8fdb\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\uff0c\u7531\u6b64\u4ea7\u751f\u7684\u6a21\u578b\u95f4\u53cd\u9988\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u751a\u81f3\u5d29\u6e83\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u9000\u5316\u80cc\u540e\u7684\u673a\u5236\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5c06\u8fed\u4ee3\u53cd\u9988\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u5e76\u5728MNIST\u3001ImageNet\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u6269\u6563\u6a21\u578b\uff0c\u5728CycleGAN\u4ee5\u53ca\u97f3\u9891\u53cd\u9988\u5b9e\u9a8c\u4e2d\u89c2\u5bdf\u5c40\u90e8\u4e0e\u5168\u5c40\u6d41\u5f62\u51e0\u4f55\u7684\u53d8\u5316\u60c5\u51b5\uff0c\u4ece\u800c\u5b9a\u4e49\u4e86\u5f15\u53d1\u795e\u7ecf\u5171\u632f\u6240\u9700\u7684\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u5173\u4e8e\u5d29\u6e83\u884c\u4e3a\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u53ea\u8981\u53cd\u9988\u8fc7\u7a0b\u5177\u6709\u904d\u5386\u6027\u4e14\u6f5c\u5728\u8868\u793a\u7ecf\u5386\u65b9\u5411\u6536\u7f29\uff0c\u5219\u5e7f\u6cdb\u7c7b\u522b\u7684\u53cd\u9988\u8fc7\u7a0b\u4f1a\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6536\u655b\u5230\u4f4e\u7ef4\u4e0d\u53d8\u7ed3\u6784\uff0c\u5373\u6240\u8c13\u7684\u795e\u7ecf\u5171\u632f\u3002\u6b64\u5916\uff0c\u8fd8\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\u63d0\u51fa\u4e86\u516b\u79cd\u4e0d\u540c\u7684\u5d29\u6e83\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u795e\u7ecf\u5171\u632f\u73b0\u8c61\u4e3a\u7406\u89e3\u751f\u6210\u6a21\u578b\u4e2d\u7531\u53cd\u9988\u5f15\u8d77\u7684\u957f\u671f\u9000\u5316\u884c\u4e3a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\uff0c\u5e76\u4e14\u4e3a\u8bc6\u522b\u3001\u63cf\u8ff0\u4e43\u81f3\u51cf\u8f7b\u8fd9\u79cd\u5d29\u6e83\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2602.19041", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19041", "abs": "https://arxiv.org/abs/2602.19041", "authors": ["Jiahao Zhang", "Lujing Zhang", "Keltin Grimes", "Zhuohao Yu", "Gokul Swamy", "Zhiwei Steven Wu"], "title": "Back to Blackwell: Closing the Loop on Intransitivity in Multi-Objective Preference Fine-Tuning", "comment": "21 pages, 5 figures", "summary": "A recurring challenge in preference fine-tuning (PFT) is handling $\\textit{intransitive}$ (i.e., cyclic) preferences. Intransitive preferences often stem from either $\\textit{(i)}$ inconsistent rankings along a single objective or $\\textit{(ii)}$ scalarizing multiple objectives into a single metric. Regardless of their source, the downstream implication of intransitive preferences is the same: there is no well-defined optimal policy, breaking a core assumption of the standard PFT pipeline. In response, we propose a novel, game-theoretic solution concept -- the $\\textit{Maximum Entropy Blackwell Winner}$ ($\\textit{MaxEntBW}$) -- that is well-defined under multi-objective intransitive preferences. To enable computing MaxEntBWs at scale, we derive $\\texttt{PROSPER}$: a provably efficient PFT algorithm. Unlike prior self-play techniques, $\\texttt{PROSPER}$ directly handles multiple objectives without requiring scalarization. We then apply $\\texttt{PROSPER}$ to the problem of fine-tuning large language models (LLMs) from multi-objective LLM-as-a-Judge feedback (e.g., rubric-based judges), a setting where both sources of intransitivity arise. We find that $\\texttt{PROSPER}$ outperforms all baselines considered across both instruction following and general chat benchmarks, releasing trained model checkpoints at the 7B and 3B parameter scales.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014\u6700\u5927\u71b5\u5e03\u83b1\u514b\u5a01\u5c14\u8d62\u5bb6\uff08MaxEntBW\uff09\uff0c\u4ee5\u53ca\u4e00\u79cd\u6709\u6548\u7684\u504f\u597d\u5fae\u8c03\u7b97\u6cd5PROSPER\uff0c\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u591a\u76ee\u6807\u4e0d\u4f20\u9012\u6027\u504f\u597d\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u65e0\u9700\u5c06\u591a\u4e2a\u76ee\u6807\u6807\u91cf\u5316\u3002", "motivation": "\u89e3\u51b3\u504f\u597d\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u4e0d\u4f20\u9012\u6027\u504f\u597d\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u53ef\u80fd\u6e90\u81ea\u5355\u4e00\u76ee\u6807\u4e0a\u7684\u4e0d\u4e00\u81f4\u6392\u5e8f\u6216\u591a\u4e2a\u76ee\u6807\u7684\u6807\u91cf\u5316\u3002\u8fd9\u7c7b\u95ee\u9898\u4f1a\u5bfc\u81f4\u6ca1\u6709\u660e\u786e\u7684\u6700\u4f73\u7b56\u7565\uff0c\u7834\u574f\u4e86\u6807\u51c6\u504f\u597d\u5fae\u8c03\u6d41\u7a0b\u7684\u6838\u5fc3\u5047\u8bbe\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u65b0\u89e3\u6982\u5ff5\u2014\u2014\u6700\u5927\u71b5\u5e03\u83b1\u514b\u5a01\u5c14\u8d62\u5bb6(MaxEntBW)\uff0c\u5e76\u5f00\u53d1\u4e86\u540d\u4e3aPROSPER\u7684\u6709\u6548\u504f\u597d\u5fae\u8c03\u7b97\u6cd5\u6765\u652f\u6301\u5927\u89c4\u6a21\u8ba1\u7b97MaxEntBWs\u3002PROSPER\u76f4\u63a5\u5904\u7406\u591a\u4e2a\u76ee\u6807\uff0c\u65e0\u9700\u8fdb\u884c\u6807\u91cf\u5316\u5904\u7406\u3002", "result": "\u5f53\u5e94\u7528\u4e8e\u6839\u636e\u591a\u76ee\u6807LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u53cd\u9988\u6765\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0cPROSPER\u5728\u6307\u4ee4\u9075\u5faa\u548c\u901a\u7528\u804a\u5929\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8d85\u8fc7\u4e86\u6240\u6709\u8003\u8651\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u504f\u597d\u5fae\u8c03\u4e2d\u7684\u4e0d\u4f20\u9012\u6027\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165MaxEntBW\u6982\u5ff5\u53ca\u5176\u5b9e\u73b0\u7b97\u6cd5PROSPER\uff0c\u4e3a\u5904\u7406\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2602.19066", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19066", "abs": "https://arxiv.org/abs/2602.19066", "authors": ["David Li", "Nikita Gushchin", "Dmitry Abulkhanov", "Eric Moulines", "Ivan Oseledets", "Maxim Panov", "Alexander Korotin"], "title": "IDLM: Inverse-distilled Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) have recently achieved strong results in text generation. However, their multi-step sampling leads to slow inference, limiting practical use. To address this, we extend Inverse Distillation, a technique originally developed to accelerate continuous diffusion models, to the discrete setting. Nonetheless, this extension introduces both theoretical and practical challenges. From a theoretical perspective, the inverse distillation objective lacks uniqueness guarantees, which may lead to suboptimal solutions. From a practical standpoint, backpropagation in the discrete space is non-trivial and often unstable. To overcome these challenges, we first provide a theoretical result demonstrating that our inverse formulation admits a unique solution, thereby ensuring valid optimization. We then introduce gradient-stable relaxations to support effective training. As a result, experiments on multiple DLMs show that our method, Inverse-distilled Diffusion Language Models (IDLM), reduces the number of inference steps by 4x-64x, while preserving the teacher model's entropy and generative perplexity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5c06\u9006\u5411\u84b8\u998f\u6280\u672f\u6269\u5c55\u5230\u79bb\u6563\u73af\u5883\u4e2d\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b(DLMs)\u5728\u6587\u672c\u751f\u6210\u4e2d\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002\u5c3d\u7ba1\u9762\u4e34\u7406\u8bba\u548c\u5b9e\u9645\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u8bc1\u660e\u9006\u5411\u516c\u5f0f\u5b58\u5728\u552f\u4e00\u89e3\u5e76\u5f15\u5165\u68af\u5ea6\u7a33\u5b9a\u677e\u5f1b\u6cd5\uff0cIDLM\u65b9\u6cd5\u6210\u529f\u51cf\u5c11\u4e864\u523064\u500d\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6559\u5e08\u6a21\u578b\u7684\u71b5\u548c\u751f\u6210\u56f0\u60d1\u5ea6\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u5728\u6587\u672c\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4f46\u7531\u4e8e\u5176\u591a\u6b65\u91c7\u6837\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u7f13\u6162\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u8bd5\u56fe\u5c06\u539f\u672c\u7528\u4e8e\u52a0\u901f\u8fde\u7eed\u6269\u6563\u6a21\u578b\u7684\u9006\u5411\u84b8\u998f\u6280\u672f\u5e94\u7528\u4e8e\u79bb\u6563\u73af\u5883\u4e0b\u7684DLMs\u3002", "method": "\u7814\u7a76\u9996\u5148\u5bf9\u9006\u5411\u84b8\u998f\u76ee\u6807\u7f3a\u4e4f\u552f\u4e00\u6027\u4fdd\u8bc1\u7684\u95ee\u9898\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5e76\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u9006\u5411\u516c\u5f0f\u786e\u5b9e\u5b58\u5728\u552f\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u9488\u5bf9\u79bb\u6563\u7a7a\u95f4\u4e2d\u7684\u53cd\u5411\u4f20\u64ad\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u68af\u5ea6\u7a33\u5b9a\u7684\u677e\u5f1b\u65b9\u6cd5\u6765\u4fc3\u8fdb\u6709\u6548\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684Inverse-distilled Diffusion Language Models (IDLM)\u65b9\u6cd5\u80fd\u591f\u5c06\u4e0d\u540cDLMs\u7684\u63a8\u7406\u6b65\u9aa4\u51cf\u5c114\u81f364\u500d\uff0c\u540c\u65f6\u7ef4\u6301\u4e0e\u539f\u6559\u5e08\u6a21\u578b\u76f8\u8fd1\u7684\u71b5\u503c\u548c\u751f\u6210\u56f0\u60d1\u5ea6\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u7406\u8bba\u5206\u6790\u548c\u6539\u8fdb\u63aa\u65bd\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5229\u7528\u9006\u5411\u84b8\u998f\u6280\u672f\u6765\u52a0\u901f\u79bb\u6563\u73af\u5883\u4e0b\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.19068", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19068", "abs": "https://arxiv.org/abs/2602.19068", "authors": ["Hui He", "Hezhe Qiao", "Yutong Chen", "Kun Yi", "Guansong Pang"], "title": "TimeRadar: A Domain-Rotatable Foundation Model for Time Series Anomaly Detection", "comment": null, "summary": "Current time series foundation models (TSFMs) primarily focus on learning prevalent and regular patterns within a predefined time or frequency domain to enable supervised downstream tasks (e.g., forecasting). Consequently, they are often ineffective for inherently unsupervised downstream tasks-such as time series anomaly detection (TSAD), which aims to identify rare, irregular patterns. This limitation arises because such abnormal patterns can closely resemble the regular patterns when presented in the same time/frequency domain. To address this issue, we introduce TimeRadar, an innovative TSFM built in a fractional time-frequency domain to support generalist TSAD across diverse unseen datasets. Our key insight is that rotating a time series into a data-dependent fractional time-frequency representation can adaptively differentiate the normal and abnormal signals across different datasets. To this end, a novel component, namely Fractionally modulated Time-Frequency Reconstruction (FTFRecon), is proposed in TimeRadar to leverage a learnable fractional order to rotate the time series to the most pronounced angle between a continuous time and frequency domain for accurate data reconstruction. This provides adaptive data reconstruction in an optimal time-frequency domain for each data input, enabling effective differentiation of the unbounded abnormal patterns from the regular ones across datasets, including unseen datasets. To allow TimeRadar to model local abnormality that is not captured by the global data reconstruction, we further introduce a Contextual Deviation Learning (CDL) component to model the local deviation of the input relative to its contextual time series data in the rotatable domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578bTimeRadar\uff0c\u5b83\u5728\u5206\u6570\u65f6\u95f4-\u9891\u7387\u57df\u5185\u6784\u5efa\uff0c\u65e8\u5728\u901a\u8fc7\u81ea\u9002\u5e94\u533a\u5206\u6b63\u5e38\u548c\u5f02\u5e38\u4fe1\u53f7\u6765\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff08TSAD\uff09\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u4e8e\u5b66\u4e60\u9884\u5b9a\u4e49\u65f6\u95f4\u6216\u9891\u7387\u57df\u5185\u7684\u666e\u904d\u548c\u89c4\u5219\u6a21\u5f0f\u4ee5\u652f\u6301\u76d1\u7763\u4e0b\u6e38\u4efb\u52a1\uff0c\u5982\u9884\u6d4b\u3002\u4f46\u5b83\u4eec\u5bf9\u4e8e\u672c\u8d28\u4e0a\u65e0\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u6bd4\u5982\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff08TSAD\uff09\uff0c\u5f80\u5f80\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u662f\u56e0\u4e3a\u5f02\u5e38\u6a21\u5f0f\u5728\u76f8\u540c\u7684\u65f6\u95f4/\u9891\u7387\u57df\u4e2d\u53ef\u80fd\u4e0e\u5e38\u89c4\u6a21\u5f0f\u975e\u5e38\u76f8\u4f3c\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4eec\u5f15\u5165\u4e86\u540d\u4e3aTimeRadar\u7684\u65b0\u9896TSFM\uff0c\u8be5\u6a21\u578b\u5efa\u7acb\u5728\u4e00\u4e2a\u5206\u6570\u65f6\u95f4-\u9891\u7387\u57df\u4e0a\uff0c\u4ee5\u652f\u6301\u8de8\u4e0d\u540c\u672a\u89c1\u6570\u636e\u96c6\u7684\u4e00\u822c\u6027TSAD\u3002\u5176\u6838\u5fc3\u89c1\u89e3\u662f\u5c06\u65f6\u95f4\u5e8f\u5217\u65cb\u8f6c\u5230\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u5206\u6570\u65f6\u95f4-\u9891\u7387\u8868\u793a\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u6839\u636e\u4e0d\u540c\u6570\u636e\u96c6\u533a\u5206\u6b63\u5e38\u548c\u5f02\u5e38\u4fe1\u53f7\u3002\u4e3a\u6b64\uff0c\u5728TimeRadar\u4e2d\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u7ec4\u4ef6\u2014\u2014\u5206\u6570\u8c03\u5236\u65f6\u9891\u91cd\u5efa(FTFRecon)\uff0c\u5229\u7528\u53ef\u5b66\u4e60\u7684\u5206\u6570\u9636\u6570\u5c06\u65f6\u95f4\u5e8f\u5217\u65cb\u8f6c\u81f3\u8fde\u7eed\u65f6\u95f4\u4e0e\u9891\u7387\u57df\u4e4b\u95f4\u6700\u663e\u8457\u7684\u89d2\u5ea6\uff0c\u4ece\u800c\u5b9e\u73b0\u7cbe\u786e\u7684\u6570\u636e\u91cd\u5efa\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u4f7fTimeRadar\u80fd\u591f\u5efa\u6a21\u5168\u5c40\u6570\u636e\u91cd\u5efa\u672a\u80fd\u6355\u6349\u5230\u7684\u5c40\u90e8\u5f02\u5e38\uff0c\u8fd8\u5f15\u5165\u4e86\u4e0a\u4e0b\u6587\u504f\u5dee\u5b66\u4e60(CDL)\u7ec4\u4ef6\uff0c\u7528\u4e8e\u5efa\u6a21\u8f93\u5165\u76f8\u5bf9\u4e8e\u5176\u4e0a\u4e0b\u6587\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u53ef\u65cb\u8f6c\u57df\u4e2d\u7684\u5c40\u90e8\u504f\u5dee\u3002", "result": "\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0cTimeRadar\u80fd\u591f\u5728\u6700\u4f18\u7684\u65f6\u95f4-\u9891\u7387\u57df\u5185\u4e3a\u6bcf\u4e2a\u6570\u636e\u8f93\u5165\u63d0\u4f9b\u81ea\u9002\u5e94\u7684\u6570\u636e\u91cd\u5efa\uff0c\u6709\u6548\u5730\u533a\u5206\u51fa\u5305\u62ec\u672a\u89c1\u6570\u636e\u96c6\u5728\u5185\u7684\u5404\u79cd\u6570\u636e\u96c6\u4e2d\u65e0\u9650\u5b9a\u8fb9\u754c\u7684\u5f02\u5e38\u6a21\u5f0f\u4e0e\u5e38\u89c4\u6a21\u5f0f\u3002", "conclusion": "\u603b\u4e4b\uff0cTimeRadar\u901a\u8fc7\u521b\u65b0\u5730\u4f7f\u7528\u5206\u6570\u65f6\u95f4-\u9891\u7387\u57df\u53ca\u81ea\u9002\u5e94\u65b9\u6cd5\u589e\u5f3a\u4e86\u5bf9\u5f02\u5e38\u4fe1\u53f7\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.19113", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19113", "abs": "https://arxiv.org/abs/2602.19113", "authors": ["Wei Chen", "Junle Chen", "Yuqian Wu", "Yuxuan Liang", "Xiaofang Zhou"], "title": "Learning from Complexity: Exploring Dynamic Sample Pruning of Spatio-Temporal Training", "comment": null, "summary": "Spatio-temporal forecasting is fundamental to intelligent systems in transportation, climate science, and urban planning. However, training deep learning models on the massive, often redundant, datasets from these domains presents a significant computational bottleneck. Existing solutions typically focus on optimizing model architectures or optimizers, while overlooking the inherent inefficiency of the training data itself. This conventional approach of iterating over the entire static dataset each epoch wastes considerable resources on easy-to-learn or repetitive samples. In this paper, we explore a novel training-efficiency techniques, namely learning from complexity with dynamic sample pruning, ST-Prune, for spatio-temporal forecasting. Through dynamic sample pruning, we aim to intelligently identify the most informative samples based on the model's real-time learning state, thereby accelerating convergence and improving training efficiency. Extensive experiments conducted on real-world spatio-temporal datasets show that ST-Prune significantly accelerates the training speed while maintaining or even improving the model performance, and it also has scalability and universality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6548\u7387\u6280\u672fST-Prune\uff0c\u901a\u8fc7\u52a8\u6001\u6837\u672c\u526a\u679d\u6765\u667a\u80fd\u8bc6\u522b\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6837\u672c\uff0c\u4ece\u800c\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u65f6\u7a7a\u9884\u6d4b\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6216\u751a\u81f3\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u52a0\u5feb\u4e86\u8bad\u7ec3\u901f\u5ea6\uff0c\u5e76\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u666e\u904d\u6027\u3002", "motivation": "\u65f6\u7a7a\u9884\u6d4b\u5bf9\u4e8e\u4ea4\u901a\u3001\u6c14\u5019\u79d1\u5b66\u548c\u57ce\u5e02\u89c4\u5212\u7b49\u9886\u57df\u7684\u667a\u80fd\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u8fd9\u4e9b\u9886\u57df\u7684\u5927\u89c4\u6a21\u4e14\u5e38\u5e38\u5197\u4f59\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u74f6\u9888\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4e13\u6ce8\u4e8e\u4f18\u5316\u6a21\u578b\u67b6\u6784\u6216\u4f18\u5316\u5668\uff0c\u800c\u5ffd\u89c6\u4e86\u8bad\u7ec3\u6570\u636e\u672c\u8eab\u7684\u5185\u5728\u4f4e\u6548\u6027\u3002\u4f20\u7edf\u7684\u6bcf\u6b21\u8fed\u4ee3\u6574\u4e2a\u9759\u6001\u6570\u636e\u96c6\u7684\u65b9\u6cd5\u6d6a\u8d39\u4e86\u5927\u91cf\u7684\u8d44\u6e90\u5728\u6613\u4e8e\u5b66\u4e60\u6216\u91cd\u590d\u7684\u6837\u672c\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aST-Prune\u7684\u65b0\u9896\u8bad\u7ec3\u6548\u7387\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u6837\u672c\u526a\u679d\u6765\u6839\u636e\u6a21\u578b\u5b9e\u65f6\u5b66\u4e60\u72b6\u6001\u667a\u80fd\u5730\u8bc6\u522b\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6837\u672c\uff0c\u4ece\u800c\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u65f6\u7a7a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eST-Prune\u663e\u8457\u52a0\u5feb\u4e86\u8bad\u7ec3\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u751a\u81f3\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4e14\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u666e\u904d\u9002\u7528\u6027\u3002", "conclusion": "ST-Prune\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65f6\u7a7a\u9884\u6d4b\u4e2d\u8bad\u7ec3\u6548\u7387\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6837\u672c\u9009\u62e9\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5176\u5c55\u793a\u51fa\u7684\u53ef\u6269\u5c55\u6027\u548c\u666e\u904d\u6027\u610f\u5473\u7740\u8fd9\u9879\u6280\u672f\u53ef\u4ee5\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u9700\u8981\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u573a\u666f\u3002"}}
{"id": "2602.19126", "categories": ["cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.19126", "abs": "https://arxiv.org/abs/2602.19126", "authors": ["Michele Caprio", "Katerina Papagiannouli", "Siu Lun Chau", "Sayan Mukherjee"], "title": "Robust Predictive Uncertainty and Double Descent in Contaminated Bayesian Random Features", "comment": null, "summary": "We propose a robust Bayesian formulation of random feature (RF) regression that accounts explicitly for prior and likelihood misspecification via Huber-style contamination sets. Starting from the classical equivalence between ridge-regularized RF training and Bayesian inference with Gaussian priors and likelihoods, we replace the single prior and likelihood with $\u03b5$- and $\u03b7$-contaminated credal sets, respectively, and perform inference using pessimistic generalized Bayesian updating. We derive explicit and tractable bounds for the resulting lower and upper posterior predictive densities. These bounds show that, when contamination is moderate, prior and likelihood ambiguity effectively acts as a direct contamination of the posterior predictive distribution, yielding uncertainty envelopes around the classical Gaussian predictive. We introduce an Imprecise Highest Density Region (IHDR) for robust predictive uncertainty quantification and show that it admits an efficient outer approximation via an adjusted Gaussian credible interval. We further obtain predictive variance bounds (under a mild truncation approximation for the upper bound) and prove that they preserve the leading-order proportional-growth asymptotics known for RF models. Together, these results establish a robustness theory for Bayesian random features: predictive uncertainty remains computationally tractable, inherits the classical double-descent phase structure, and is improved by explicit worst-case guarantees under bounded prior and likelihood misspecification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u8d1d\u53f6\u65af\u968f\u673a\u7279\u5f81\u56de\u5f52\u65b9\u6cd5\uff0c\u901a\u8fc7Huber\u98ce\u683c\u7684\u6c61\u67d3\u96c6\u660e\u786e\u8003\u8651\u4e86\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u7684\u9519\u8bef\u6307\u5b9a\u3002\u63a8\u5bfc\u51fa\u4e0a\u4e0b\u540e\u9a8c\u9884\u6d4b\u5bc6\u5ea6\u7684\u663e\u5f0f\u548c\u53ef\u5904\u7406\u8fb9\u754c\uff0c\u5e76\u5f15\u5165\u4e86\u4e0d\u7cbe\u786e\u6700\u9ad8\u5bc6\u5ea6\u533a\u57df\uff08IHDR\uff09\u4ee5\u8fdb\u884c\u7a33\u5065\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u6709\u754c\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u9519\u8bef\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4ecd\u7136\u5177\u6709\u8ba1\u7b97\u4e0a\u7684\u53ef\u5904\u7406\u6027\uff0c\u5e76\u4e14\u4fdd\u7559\u4e86\u7ecf\u5178\u7684\u53cc\u4e0b\u964d\u76f8\u7ed3\u6784\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u53ef\u80fd\u5b58\u5728\u7684\u9519\u8bef\u6307\u5b9a\u95ee\u9898\uff0c\u6587\u7ae0\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u8d1d\u53f6\u65af\u968f\u673a\u7279\u5f81\u56de\u5f52\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u5bf9\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u76f4\u63a5\u5efa\u6a21\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u9760\u3001\u66f4\u5177\u6297\u6270\u52a8\u80fd\u529b\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7b49\u4ef7\u6027\u2014\u2014\u5373\u5e26\u6709\u9ad8\u65af\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u4e0e\u4f7f\u7528\u5cad\u6b63\u5219\u5316\u7684\u968f\u673a\u7279\u5f81\u8bad\u7ec3\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4f5c\u8005\u5c06\u5355\u4e00\u7684\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u66ff\u6362\u4e3a\u03b5-\u548c\u03b7-\u6c61\u67d3\u53ef\u4fe1\u96c6\uff0c\u5e76\u5229\u7528\u60b2\u89c2\u5e7f\u4e49\u8d1d\u53f6\u65af\u66f4\u65b0\u6267\u884c\u63a8\u7406\u3002", "result": "\u5f97\u5230\u7684\u7ed3\u679c\u5305\u62ec\uff1a\u663e\u5f0f\u4e14\u6613\u4e8e\u5904\u7406\u7684\u4e0b\u4e0a\u540e\u9a8c\u9884\u6d4b\u5bc6\u5ea6\u754c\u9650\uff1b\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5916\u8fd1\u4f3c\u65b9\u6cd5\u6765\u4f30\u8ba1\u4e0d\u7cbe\u786e\u6700\u9ad8\u5bc6\u5ea6\u533a\u57df\uff1b\u83b7\u5f97\u4e86\u9884\u6d4b\u65b9\u5dee\u7684\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u754c\u9650\u4fdd\u6301\u4e86\u5df2\u77e5\u7684RF\u6a21\u578b\u6210\u6bd4\u4f8b\u589e\u957f\u6e10\u8fd1\u7279\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u5728\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u5b58\u5728\u4e00\u5b9a\u7a0b\u5ea6\u9519\u914d\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u9c81\u68d2\u8d1d\u53f6\u65af\u65b9\u6cd5\u4ecd\u80fd\u4fdd\u6301\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u5e76\u4e14\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u7ee7\u627f\u4e86\u7ecf\u5178\u7684\u53cc\u4e0b\u964d\u9636\u6bb5\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u63d0\u4f9b\u4e86\u5728\u5148\u9a8c\u548c\u4f3c\u7136\u6027\u9519\u914d\u60c5\u51b5\u4e0b\u7684\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\u3002"}}
{"id": "2602.19130", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19130", "abs": "https://arxiv.org/abs/2602.19130", "authors": ["Frida J\u00f8rgensen", "Nina Weng", "Siavash Bigdeli"], "title": "Detecting labeling bias using influence functions", "comment": null, "summary": "Labeling bias arises during data collection due to resource limitations or unconscious bias, leading to unequal label error rates across subgroups or misrepresentation of subgroup prevalence. Most fairness constraints assume training labels reflect the true distribution, rendering them ineffective when labeling bias is present; leaving a challenging question, that \\textit{how can we detect such labeling bias?} In this work, we investigate whether influence functions can be used to detect labeling bias. Influence functions estimate how much each training sample affects a model's predictions by leveraging the gradient and Hessian of the loss function -- when labeling errors occur, influence functions can identify wrongly labeled samples in the training set, revealing the underlying failure mode. We develop a sample valuation pipeline and test it first on the MNIST dataset, then scaled to the more complex CheXpert medical imaging dataset. To examine label noise, we introduced controlled errors by flipping 20\\% of the labels for one class in the dataset. Using a diagonal Hessian approximation, we demonstrated promising results, successfully detecting nearly 90\\% of mislabeled samples in MNIST. On CheXpert, mislabeled samples consistently exhibit higher influence scores. These results highlight the potential of influence functions for identifying label errors.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5f71\u54cd\u51fd\u6570\u5728\u68c0\u6d4b\u6807\u7b7e\u504f\u5dee\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5728MNIST\u548cCheXpert\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5f71\u54cd\u51fd\u6570\u80fd\u591f\u6709\u6548\u8bc6\u522b\u9519\u8bef\u6807\u8bb0\u6837\u672c\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u8d44\u6e90\u9650\u5236\u6216\u65e0\u610f\u8bc6\u504f\u89c1\uff0c\u5728\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\u4f1a\u51fa\u73b0\u6807\u7b7e\u504f\u5dee\u95ee\u9898\uff0c\u5bfc\u81f4\u5b50\u7fa4\u4f53\u95f4\u6807\u7b7e\u9519\u8bef\u7387\u4e0d\u7b49\u6216\u5b50\u7fa4\u4f53\u4ee3\u8868\u6027\u5931\u771f\u3002\u5927\u591a\u6570\u516c\u5e73\u6027\u7ea6\u675f\u5047\u8bbe\u8bad\u7ec3\u6807\u7b7e\u53cd\u6620\u4e86\u771f\u5b9e\u5206\u5e03\uff0c\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u5b58\u5728\u6807\u7b7e\u504f\u5dee\u65f6\u65e0\u6548\uff1b\u56e0\u6b64\u7559\u4e0b\u4e86\u4e00\u4e2a\u6311\u6218\u6027\u7684\u95ee\u9898\uff1a\u6211\u4eec\u5982\u4f55\u68c0\u6d4b\u8fd9\u79cd\u6807\u7b7e\u504f\u5dee\uff1f", "method": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u6837\u672c\u4ef7\u503c\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5e76\u9996\u5148\u5728MNIST\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7136\u540e\u6269\u5c55\u5230\u4e86\u66f4\u590d\u6742\u7684CheXpert\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u3002\u4e3a\u4e86\u68c0\u9a8c\u6807\u7b7e\u566a\u58f0\uff0c\u4ed6\u4eec\u901a\u8fc7\u7ffb\u8f6c\u6570\u636e\u96c6\u4e2d\u4e00\u4e2a\u7c7b\u522b\u768420%\u6807\u7b7e\u6765\u5f15\u5165\u63a7\u5236\u9519\u8bef\u3002\u4f7f\u7528\u5bf9\u89d2Hessian\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7814\u7a76\u4eba\u5458\u5c1d\u8bd5\u5229\u7528\u5f71\u54cd\u51fd\u6570\u6765\u4f30\u8ba1\u6bcf\u4e2a\u8bad\u7ec3\u6837\u672c\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u5f71\u54cd\u7a0b\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728MNIST\u6570\u636e\u96c6\u4e2d\u6210\u529f\u5730\u68c0\u6d4b\u5230\u4e86\u63a5\u8fd190%\u7684\u8bef\u6807\u6837\u672c\u3002\u800c\u5728CheXpert\u6570\u636e\u96c6\u4e0a\uff0c\u8bef\u6807\u6837\u672c\u59cb\u7ec8\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u5f71\u54cd\u5206\u6570\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u51fa\u4e86\u5f71\u54cd\u51fd\u6570\u5728\u8bc6\u522b\u6807\u7b7e\u9519\u8bef\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5f71\u54cd\u51fd\u6570\u53ef\u4ee5\u4f5c\u4e3a\u68c0\u6d4b\u6807\u7b7e\u504f\u5dee\u7684\u6709\u6548\u5de5\u5177\uff0c\u4e3a\u89e3\u51b3\u56e0\u6807\u7b7e\u9519\u8bef\u800c\u5bfc\u81f4\u7684\u6570\u636e\u504f\u5dee\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.19131", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19131", "abs": "https://arxiv.org/abs/2602.19131", "authors": ["Wei Chen", "Rui Ding", "Bojun Huang", "Yang Zhang", "Qiang Fu", "Yuxuan Liang", "Han Shi", "Dongmei Zhang"], "title": "Test-Time Learning of Causal Structure from Interventional Data", "comment": null, "summary": "Supervised causal learning has shown promise in causal discovery, yet it often struggles with generalization across diverse interventional settings, particularly when intervention targets are unknown. To address this, we propose TICL (Test-time Interventional Causal Learning), a novel method that synergizes Test-Time Training with Joint Causal Inference. Specifically, we design a self-augmentation strategy to generate instance-specific training data at test time, effectively avoiding distribution shifts. Furthermore, by integrating joint causal inference, we developed a PC-inspired two-phase supervised learning scheme, which effectively leverages self-augmented training data while ensuring theoretical identifiability. Extensive experiments on bnlearn benchmarks demonstrate TICL's superiority in multiple aspects of causal discovery and intervention target detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTICL\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6d4b\u8bd5\u65f6\u751f\u6210\u5b9e\u4f8b\u7279\u5b9a\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u8054\u5408\u56e0\u679c\u63a8\u65ad\uff0c\u4ee5\u6539\u5584\u76d1\u7763\u56e0\u679c\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u3002", "motivation": "\u76d1\u7763\u56e0\u679c\u5b66\u4e60\u5728\u56e0\u679c\u53d1\u73b0\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u5e72\u9884\u76ee\u6807\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e0d\u540c\u5e72\u9884\u8bbe\u7f6e\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\u3002", "method": "TICL\uff08\u6d4b\u8bd5\u65f6\u95f4\u5e72\u9884\u56e0\u679c\u5b66\u4e60\uff09\uff0c\u7ed3\u5408\u4e86\u6d4b\u8bd5\u65f6\u95f4\u8bad\u7ec3\u4e0e\u8054\u5408\u56e0\u679c\u63a8\u7406\u3002\u91c7\u7528\u81ea\u589e\u5f3a\u7b56\u7565\u5728\u6d4b\u8bd5\u65f6\u751f\u6210\u5b9e\u4f8b\u7279\u5b9a\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u53d7PC\u542f\u53d1\u7684\u4e24\u9636\u6bb5\u76d1\u7763\u5b66\u4e60\u65b9\u6848\u3002", "result": "\u5728bnlearn\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTICL\u5728\u56e0\u679c\u53d1\u73b0\u548c\u5e72\u9884\u76ee\u6807\u68c0\u6d4b\u7684\u591a\u4e2a\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "TICL\u901a\u8fc7\u907f\u514d\u5206\u5e03\u504f\u79fb\u5e76\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u53ef\u8bc6\u522b\u6027\u7684\u540c\u65f6\u6709\u6548\u5229\u7528\u81ea\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8de8\u4e0d\u540c\u5e72\u9884\u73af\u5883\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2602.19142", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19142", "abs": "https://arxiv.org/abs/2602.19142", "authors": ["Abhinav Moudgil", "Boris Knyazev", "Eugene Belilovsky"], "title": "Celo2: Towards Learned Optimization Free Lunch", "comment": "ICLR 2026", "summary": "Learned optimizers are powerful alternatives to hand-designed update rules like Adam, yet they have seen limited practical adoption since they often fail to meta-generalize beyond their training distribution and incur high meta-training cost. For instance, prior work, VeLO, scaled meta-training to 4,000 TPU months ($\\sim$10$\\times$ GPT-3 compute) to meta-train a general-purpose optimizer but it failed to generalize beyond 600M parameters tasks. In this work, we present a surprising finding: by crafting a simple normalized optimizer architecture and augmenting meta-training, it becomes feasible to meta-train a performant general-purpose learned update rule on a tiny fraction of VeLO compute, 4.5 GPU hours to be precise. Our learned update rule scales stably to a billion-scale pretraining task (GPT-3 XL 1.3B) which is six orders of magnitude larger than its meta-training distribution. Furthermore, it shows strong performance across diverse out-of-distribution tasks and is compatible with modern optimization harness that includes orthogonalization, distinct update rules for input-output and hidden weights, and decoupled weight decay. In all, this work paves the way for practically applicable learnable optimization algorithms, unlocking exploration of richer meta-training and data curation recipes to further improve performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u6807\u51c6\u5316\u4f18\u5316\u5668\u67b6\u6784\u548c\u589e\u5f3a\u5143\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f7f\u5f97\u5728\u6781\u5c0f\u7684\u8ba1\u7b97\u8d44\u6e90\u4e0b\uff084.5 GPU\u5c0f\u65f6\uff09\u5c31\u80fd\u5143\u8bad\u7ec3\u51fa\u4e00\u4e2a\u6027\u80fd\u826f\u597d\u7684\u901a\u7528\u5b66\u4e60\u66f4\u65b0\u89c4\u5219\u3002\u8be5\u66f4\u65b0\u89c4\u5219\u80fd\u591f\u7a33\u5b9a\u5730\u6269\u5c55\u5230\u5341\u4ebf\u89c4\u6a21\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u5206\u5e03\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u517c\u5bb9\u73b0\u4ee3\u4f18\u5316\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u578b\u4f18\u5316\u5668\u7531\u4e8e\u5728\u8d85\u51fa\u5176\u8bad\u7ec3\u5206\u5e03\u65f6\u5f80\u5f80\u65e0\u6cd5\u6cdb\u5316\uff0c\u4e14\u5143\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u3002\u4f8b\u5982\uff0c\u5148\u524d\u7684\u5de5\u4f5cVeLO\u5c3d\u7ba1\u4f7f\u7528\u4e86\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff08\u7ea64000 TPU\u6708\uff09\uff0c\u4f46\u672a\u80fd\u8d85\u8d8a6\u4ebf\u53c2\u6570\u7684\u4efb\u52a1\u8303\u56f4\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u7b80\u5355\u7684\u6807\u51c6\u5316\u4f18\u5316\u5668\u67b6\u6784\u4ee5\u53ca\u52a0\u5f3a\u5143\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u5728\u4e00\u4e2a\u975e\u5e38\u5c0f\u7684\u8ba1\u7b97\u91cf\uff08\u5177\u4f53\u4e3a4.5 GPU\u5c0f\u65f6\uff09\u4e0b\u5b8c\u6210\u9ad8\u6548\u3001\u6cdb\u7528\u7684\u5b66\u4e60\u66f4\u65b0\u89c4\u5219\u7684\u5143\u8bad\u7ec3\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5b66\u4e60\u66f4\u65b0\u89c4\u5219\u4e0d\u4ec5\u80fd\u591f\u7a33\u5b9a\u5e94\u7528\u4e8e\u9ad8\u8fbe\u5341\u4ebf\u53c2\u6570\u89c4\u6a21\u7684\u4efb\u52a1\u4e2d\uff08\u5982GPT-3 XL 1.3B\uff09\uff0c\u800c\u4e14\u5bf9\u4e8e\u591a\u79cd\u4e0d\u540c\u4e8e\u8bad\u7ec3\u65f6\u5206\u5e03\u7684\u4efb\u52a1\u4e5f\u8868\u73b0\u51fa\u4e86\u5f3a\u5927\u7684\u9002\u5e94\u6027\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u4e0e\u5305\u62ec\u6b63\u4ea4\u5316\u3001\u5bf9\u8f93\u5165\u8f93\u51fa\u53ca\u9690\u85cf\u6743\u91cd\u91c7\u7528\u4e0d\u540c\u7684\u66f4\u65b0\u89c4\u5219\u7b49\u5728\u5185\u7684\u73b0\u4ee3\u4f18\u5316\u6280\u672f\u76f8\u517c\u5bb9\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u8ba1\u7b97\u8d44\u6e90\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u7279\u5b9a\u7684\u8bbe\u8ba1\u7b56\u7565\u53ef\u4ee5\u5f00\u53d1\u51fa\u65e2\u9ad8\u6548\u53c8\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u7684\u5b66\u4e60\u578b\u4f18\u5316\u7b97\u6cd5\uff0c\u4e3a\u672a\u6765\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u4e30\u5bcc\u7684\u5143\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u7ba1\u7406\u7b56\u7565\u4ee5\u63d0\u5347\u6027\u80fd\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2602.19143", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19143", "abs": "https://arxiv.org/abs/2602.19143", "authors": ["O\u011fuz Kaan Y\u00fcksel", "Rodrigo Alvarez Lucendo", "Nicolas Flammarion"], "title": "Incremental Learning of Sparse Attention Patterns in Transformers", "comment": "36 pages, 19 figures", "summary": "This paper introduces a high-order Markov chain task to investigate how transformers learn to integrate information from multiple past positions with varying statistical significance. We demonstrate that transformers learn this task incrementally: each stage is defined by the acquisition of specific information through sparse attention patterns. Notably, we identify a shift in learning dynamics from competitive, where heads converge on the most statistically dominant pattern, to cooperative, where heads specialize in distinct patterns. We model these dynamics using simplified differential equations that characterize the trajectory and prove stage-wise convergence results. Our analysis reveals that transformers ascend a complexity ladder by passing through simpler, misspecified hypothesis classes before reaching the full model class. We further show that early stopping acts as an implicit regularizer, biasing the model toward these simpler classes. These results provide a theoretical foundation for the emergence of staged learning and complex behaviors in transformers, offering insights into generalization for natural language processing and algorithmic reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u9ad8\u9636\u9a6c\u5c14\u53ef\u592b\u94fe\u4efb\u52a1\uff0c\u63a2\u8ba8\u4e86transformers\u5982\u4f55\u5b66\u4e60\u6574\u5408\u6765\u81ea\u591a\u4e2a\u8fc7\u53bb\u4f4d\u7f6e\u7684\u4fe1\u606f\u3002\u7814\u7a76\u8868\u660e\uff0ctransformers\u901a\u8fc7\u7a00\u758f\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u9010\u6b65\u5b66\u4f1a\u6b64\u4efb\u52a1\uff0c\u5e76\u4e14\u5b66\u4e60\u52a8\u529b\u5b66\u4ece\u7ade\u4e89\u6027\u8f6c\u5411\u5408\u4f5c\u6027\u3002\u5229\u7528\u7b80\u5316\u7684\u5fae\u5206\u65b9\u7a0b\u5efa\u6a21\u8fd9\u4e9b\u52a8\u6001\u5e76\u8bc1\u660e\u4e86\u9636\u6bb5\u6536\u655b\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u6307\u51fa\u65e9\u671f\u505c\u6b62\u4f5c\u4e3a\u9690\u5f0f\u6b63\u5219\u5316\u5668\u4fc3\u4f7f\u6a21\u578b\u503e\u5411\u4e8e\u66f4\u7b80\u5355\u7684\u5047\u8bbe\u7c7b\u522b\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22transformers\u5982\u4f55\u6839\u636e\u7edf\u8ba1\u663e\u8457\u6027\u7684\u4e0d\u540c\u6765\u6574\u5408\u591a\u6e90\u5386\u53f2\u4fe1\u606f\uff0c\u7279\u522b\u662f\u7406\u89e3\u5176\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u9636\u6bb5\u6027\u4ee5\u53ca\u590d\u6742\u884c\u4e3a\u80cc\u540e\u7684\u673a\u5236\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u9ad8\u9636\u9a6c\u5c14\u53ef\u592b\u94fe\u4efb\u52a1\uff0c\u4f7f\u7528\u7a00\u758f\u6ce8\u610f\u6a21\u5f0f\u5206\u6790transformers\u7684\u5b66\u4e60\u8def\u5f84\uff1b\u8fd0\u7528\u7b80\u5316\u540e\u7684\u5fae\u5206\u65b9\u7a0b\u5bf9\u5b66\u4e60\u52a8\u529b\u5b66\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u9a8c\u8bc1\u6bcf\u4e2a\u9636\u6bb5\u7684\u5b66\u4e60\u6210\u679c\u3002", "result": "\u53d1\u73b0transformers\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u5148\u7ade\u4e89\u540e\u5408\u4f5c\u7684\u7279\u70b9\uff0c\u80fd\u591f\u9010\u6b65\u638c\u63e1\u66f4\u590d\u6742\u7684\u4efb\u52a1\uff1b\u540c\u65f6\uff0c\u65e9\u671f\u505c\u6b62\u6709\u52a9\u4e8e\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u4f7f\u6a21\u578b\u504f\u5411\u4e8e\u8f83\u7b80\u5355\u7684\u5047\u8bbe\u7c7b\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3transformers\u4e2d\u7684\u9636\u6bb5\u6027\u5b66\u4e60\u548c\u590d\u6742\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u53ca\u7b97\u6cd5\u63a8\u7406\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u5e26\u6765\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.19169", "categories": ["cs.LG", "cs.AI", "cs.MS", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.19169", "abs": "https://arxiv.org/abs/2602.19169", "authors": ["Saba Kublashvili"], "title": "Virtual Parameter Sharpening: Dynamic Low-Rank Perturbations for Inference-Time Reasoning Enhancement", "comment": null, "summary": "I introduce Virtual Parameter Sharpening (VPS), an inference-time technique that augments frozen transformer linear layers with dynamic, activation-conditioned low-rank perturbations. Unlike parameter-efficient fine-tuning methods such as LoRA, which learn static low-rank adapters, VPS constructs its perturbation factors on the fly from batch activation statistics and optional gradient signals, enabling test-time adaptation without persistent parameter updates. The perturbation takes the form Delta W = gamma * W^T V U^T W, where selector matrices U and V are constructed via sparse activation-guided selection or Sylvester-coupled regression. We provide a theoretical analysis of the perturbation's spectral properties and describe an adaptive policy system that modulates perturbation magnitude based on activation energy and token-level entropy. This system incorporates multi-objective verification with iterative refinement for tasks with ground-truth supervision. We present the complete algorithmic framework, analyze its mathematical foundations, and discuss the mechanisms by which activation-conditioned computation may enhance reasoning capabilities in large language models. Implementation and experimental code are available at https://github.com/Saba-Kublashvili/vps-virtual-parameter-synthesis .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u865a\u62df\u53c2\u6570\u9510\u5316\uff08VPS\uff09\u7684\u6280\u672f\uff0c\u8be5\u6280\u672f\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u57fa\u4e8e\u6fc0\u6d3b\u6761\u4ef6\u7684\u52a8\u6001\u4f4e\u79e9\u6270\u52a8\u6765\u589e\u5f3a\u51bb\u7ed3\u7684\u53d8\u538b\u5668\u7ebf\u6027\u5c42\u3002\u4e0e\u9759\u6001\u5b66\u4e60\u4f4e\u79e9\u9002\u914d\u5668\u7684\u65b9\u6cd5\u4e0d\u540c\uff0cVPS\u5229\u7528\u6279\u5904\u7406\u6fc0\u6d3b\u7edf\u8ba1\u548c\u53ef\u9009\u68af\u5ea6\u4fe1\u53f7\u5373\u65f6\u6784\u5efa\u5176\u6270\u52a8\u56e0\u7d20\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u9700\u6301\u4e45\u53c2\u6570\u66f4\u65b0\u7684\u6d4b\u8bd5\u65f6\u95f4\u9002\u5e94\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u865a\u62df\u53c2\u6570\u9510\u5316\uff08VPS\uff09\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u8fdb\u884c\u6301\u7eed\u53c2\u6570\u66f4\u65b0\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u6d4b\u8bd5\u65f6\u6839\u636e\u8f93\u5165\u6570\u636e\u52a8\u6001\u8c03\u6574\u6a21\u578b\u6743\u91cd\u3002\u8fd9\u79cd\u65b9\u6cd5\u8bd5\u56fe\u514b\u670d\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5982LoRA\u53ea\u80fd\u5b66\u4e60\u9759\u6001\u4f4e\u79e9\u9002\u914d\u5668\u7684\u5c40\u9650\u6027\u3002", "method": "VPS\u901a\u8fc7\u516c\u5f0fDelta W = gamma * W^T V U^T W\u5f15\u5165\u4e86\u52a8\u6001\u3001\u57fa\u4e8e\u6fc0\u6d3b\u6761\u4ef6\u7684\u4f4e\u79e9\u6270\u52a8\u5230\u51bb\u7ed3\u7684\u53d8\u538b\u5668\u7ebf\u6027\u5c42\u4e2d\u3002\u9009\u62e9\u77e9\u9635U\u548cV\u662f\u901a\u8fc7\u7a00\u758f\u6fc0\u6d3b\u5f15\u5bfc\u7684\u9009\u62e9\u6216Sylvester\u8026\u5408\u56de\u5f52\u6784\u5efa\u7684\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u7b56\u7565\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u53ef\u4ee5\u6839\u636e\u6fc0\u6d3b\u80fd\u91cf\u548c\u4ee4\u724c\u7ea7\u71b5\u8c03\u8282\u6270\u52a8\u5e45\u5ea6\uff0c\u5e76\u7ed3\u5408\u591a\u76ee\u6807\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4f18\u5316\u4ee5\u9002\u5e94\u5177\u6709\u771f\u5b9e\u76d1\u7763\u7684\u4efb\u52a1\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u6270\u52a8\u8c31\u7279\u6027\u7684\u7406\u8bba\u5206\u6790\u4ee5\u53ca\u6570\u5b66\u57fa\u7840\u7684\u8be6\u7ec6\u63a2\u8ba8\uff0c\u5e76\u8ba8\u8bba\u4e86\u57fa\u4e8e\u6fc0\u6d3b\u6761\u4ef6\u8ba1\u7b97\u5982\u4f55\u53ef\u80fd\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VPS\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u63a8\u7406\u65f6\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3a\u51bb\u7ed3\u53d8\u6362\u5668\u7ebf\u6027\u5c42\u7684\u8868\u73b0\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u53c2\u6570\u6548\u7387\u3002\u901a\u8fc7\u52a8\u6001\u5730\u9002\u5e94\u8f93\u5165\u6570\u636e\u7279\u6027\uff0cVPS\u5c55\u793a\u4e86\u5728\u6ca1\u6709\u6c38\u4e45\u6027\u53c2\u6570\u66f4\u6539\u7684\u60c5\u51b5\u4e0b\u6539\u5584\u6a21\u578b\u6027\u80fd\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2602.19207", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19207", "abs": "https://arxiv.org/abs/2602.19207", "authors": ["Afsana Khan", "Marijn ten Thij", "Guangzhi Tang", "Anna Wilbik"], "title": "HybridFL: A Federated Learning Approach for Financial Crime Detection", "comment": null, "summary": "Federated learning (FL) is a privacy-preserving machine learning paradigm that enables multiple parties to collaboratively train models on privately owned data without sharing raw information. While standard FL typically addresses either horizontal or vertical data partitions, many real-world scenarios exhibit a complex hybrid distribution. This paper proposes Hybrid Federated Learning (HybridFL) to address data split both horizontally across disjoint users and vertically across complementary feature sets. We evaluate HybridFL in a financial crime detection context, where a transaction party holds transaction-level attributes and multiple banks maintain private account-level features. By integrating horizontal aggregation and vertical feature fusion, the proposed architecture enables joint learning while strictly preserving data locality. Experiments on AMLSim and SWIFT datasets demonstrate that HybridFL significantly outperforms the transaction-only local model and achieves performance comparable to a centralized benchmark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u8054\u90a6\u5b66\u4e60\uff08HybridFL\uff09\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u6570\u636e\u5728\u7528\u6237\u95f4\u6c34\u5e73\u5206\u5272\u4ee5\u53ca\u7279\u5f81\u96c6\u4e0a\u5782\u76f4\u5206\u5272\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u6a2a\u5411\u805a\u5408\u548c\u7eb5\u5411\u7279\u5f81\u878d\u5408\u6280\u672f\uff0cHybridFL\u80fd\u591f\u5728\u4e25\u683c\u4fdd\u6301\u6570\u636e\u672c\u5730\u5316\u7684\u540c\u65f6\u5b9e\u73b0\u8054\u5408\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\uff0cHybridFL\u5728\u91d1\u878d\u72af\u7f6a\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u4ea4\u6613\u7684\u672c\u5730\u6a21\u578b\uff0c\u5e76\u4e14\u8fbe\u5230\u4e86\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u51c6\u76f8\u5f53\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u901a\u5e38\u53ea\u5904\u7406\u6c34\u5e73\u6216\u5782\u76f4\u7684\u6570\u636e\u5206\u533a\u95ee\u9898\uff0c\u4f46\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u6570\u636e\u5206\u5e03\u66f4\u4e3a\u590d\u6742\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u79cd\u540c\u65f6\u5b58\u5728\u6a2a\u8de8\u4e0d\u540c\u7528\u6237\uff08\u6c34\u5e73\uff09\u548c\u8865\u5145\u7279\u5f81\u96c6\u5408\uff08\u5782\u76f4\uff09\u7684\u6570\u636e\u5206\u5272\u60c5\u51b5\uff0c\u63d0\u51fa\u4e86\u6df7\u5408\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u3002", "method": "HybridFL\u901a\u8fc7\u6574\u5408\u6a2a\u5411\u805a\u5408\u4e0e\u7eb5\u5411\u7279\u5f81\u878d\u5408\u7684\u6280\u672f\u624b\u6bb5\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u80fd\u591f\u9002\u5e94\u590d\u6742\u6570\u636e\u5206\u5e03\u7684\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5141\u8bb8\u5728\u4e0d\u76f4\u63a5\u5171\u4eab\u539f\u59cb\u4fe1\u606f\u7684\u524d\u63d0\u4e0b\uff0c\u591a\u4e2a\u53c2\u4e0e\u8005\u5171\u540c\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u4f7f\u7528AMLSim\u548cSWIFT\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHybridFL\u4e0d\u4ec5\u660e\u663e\u4f18\u4e8e\u5355\u72ec\u5229\u7528\u4ea4\u6613\u6570\u636e\u7684\u672c\u5730\u6a21\u578b\uff0c\u5728\u6027\u80fd\u4e0a\u4e5f\u63a5\u8fd1\u4e8e\u4e2d\u5fc3\u5316\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "HybridFL\u4e3a\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u7684\u6df7\u5408\u6570\u636e\u5206\u5e03\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u5ea6\u9690\u79c1\u4fdd\u62a4\u7684\u5e94\u7528\u573a\u666f\u4e0b\uff0c\u5982\u91d1\u878d\u72af\u7f6a\u68c0\u6d4b\u9886\u57df\u3002"}}
{"id": "2602.19237", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19237", "abs": "https://arxiv.org/abs/2602.19237", "authors": ["Amit Lal"], "title": "Evaluating SAP RPT-1 for Enterprise Business Process Prediction: In-Context Learning vs. Traditional Machine Learning on Structured SAP Data", "comment": "12 pages, 5 figures, 32 references. Reproducible experiments available at Hugging Face Spaces", "summary": "Tabular foundation models aim to make machine learning accessible for enterprise data without task-specific training. This paper presents the first independent evaluation of SAP's Retrieval Pretrained Transformer (RPT-1) from a practitioner perspective. RPT-1 is a compact 64.6 MB model pretrained on 1.34 TB of structured data across 3.1 million tables. We benchmark it against tuned gradient-boosted decision trees (XGBoost, LightGBM, CatBoost) on three SAP business scenarios: demand forecasting across SD/MM/PP modules, predictive data integrity in BC/MM/QM, and financial risk classification in FI/CO/AR. Across five-fold cross-validation on datasets ranging from 2,500 to 3,200 rows, RPT-1 reaches 91-96% of tuned GBDT accuracy without any training examples. The classification gap is modest at 3.6-4.1 percentage points on AUC-ROC, though regression tasks show wider gaps of 8.9-11.1 percentage points on R-squared. An interesting finding is a crossover at roughly 75-100 context rows where RPT-1 actually outperforms XGBoost under limited data. Based on these results, we propose a practical hybrid workflow: use RPT-1 for rapid screening, then train GBDT selectively where prediction accuracy justifies the effort. All experiments are reproducible through publicly available Hugging Face Spaces.", "AI": {"tldr": "\u672c\u6587\u4ece\u5b9e\u8df5\u8005\u7684\u89d2\u5ea6\u9996\u6b21\u72ec\u7acb\u8bc4\u4f30\u4e86SAP\u7684\u68c0\u7d22\u9884\u8bad\u7ec3\u8f6c\u6362\u5668\uff08RPT-1\uff09\uff0c\u4e00\u4e2a\u4ec564.6MB\u5927\u5c0f\u4f46\u57fa\u4e8e\u5927\u91cf\u7ed3\u6784\u5316\u6570\u636e\u9884\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u4e0e\u51e0\u79cd\u8c03\u4f18\u540e\u7684\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u5728SAP\u5546\u4e1a\u573a\u666f\u4e0b\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5728\u65e0\u4efb\u4f55\u7279\u5b9a\u4efb\u52a1\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0cRPT-1\u80fd\u591f\u8fbe\u5230\u63a5\u8fd1\u4e8e\u8fd9\u4e9b\u6a21\u578b\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u91cf\u8f83\u5c11\u65f6\u751a\u81f3\u4f18\u4e8eXGBoost\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u9996\u6b21\u72ec\u7acb\u5730\u4ece\u5b9e\u8df5\u8005\u89c6\u89d2\u8bc4\u4f30SAP\u7684\u68c0\u7d22\u9884\u8bad\u7ec3\u8f6c\u6362\u5668\uff08RPT-1\uff09\u6765\u63a2\u8ba8\u8868\u683c\u57fa\u7840\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u5728\u6ca1\u6709\u7279\u5b9a\u4efb\u52a1\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u4f7f\u673a\u5668\u5b66\u4e60\u5bf9\u4f01\u4e1a\u6570\u636e\u53d8\u5f97\u6613\u4e8e\u8bbf\u95ee\u3002", "method": "\u7814\u7a76\u8005\u5c06RPT-1\u4e0e\u7ecf\u8fc7\u8c03\u6574\u7684\u68af\u5ea6\u589e\u5f3a\u51b3\u7b56\u6811\uff08\u5305\u62ecXGBoost\u3001LightGBM\u548cCatBoost\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u6d4b\u8bd5\u573a\u666f\u8986\u76d6\u4e86SAP\u4e1a\u52a1\u4e2d\u7684\u9700\u6c42\u9884\u6d4b\u3001\u9884\u6d4b\u6027\u6570\u636e\u5b8c\u6574\u6027\u548c\u8d22\u52a1\u98ce\u9669\u5206\u7c7b\u4e09\u4e2a\u9886\u57df\u3002\u91c7\u7528\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u89c4\u6a21\u4ecb\u4e8e2,500\u81f33,200\u884c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6ca1\u6709\u4efb\u4f55\u8bad\u7ec3\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0cRPT-1\u80fd\u8fbe\u5230\u8c03\u4f18\u540eGBDT\u51c6\u786e\u6027\u768491-96%\u3002\u5bf9\u4e8e\u5206\u7c7b\u4efb\u52a1\u800c\u8a00\uff0cAUC-ROC\u4e0a\u7684\u5dee\u8ddd\u76f8\u5bf9\u8f83\u5c0f\uff0c\u4e3a3.6-4.1\u4e2a\u767e\u5206\u70b9\uff1b\u800c\u5bf9\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u5219\u663e\u793a\u51fa\u66f4\u5927\u7684\u5dee\u8ddd\uff0cR-squared\u503c\u76f8\u5dee8.9-11.1\u4e2a\u767e\u5206\u70b9\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u5927\u7ea675-100\u884c\u4e0a\u4e0b\u6587\u6570\u636e\u70b9\u5904\uff0cRPT-1\u5b9e\u9645\u4e0a\u8d85\u8fc7\u4e86XGBoost\u7684\u8868\u73b0\u3002", "conclusion": "\u57fa\u4e8e\u4e0a\u8ff0\u53d1\u73b0\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u6df7\u5408\u5de5\u4f5c\u6d41\u7a0b\uff1a\u9996\u5148\u4f7f\u7528RPT-1\u5feb\u901f\u7b5b\u9009\uff0c\u7136\u540e\u6839\u636e\u9700\u8981\u9009\u62e9\u6027\u5730\u8bad\u7ec3GBDT\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6240\u6709\u5b9e\u9a8c\u5747\u53ef\u901a\u8fc7\u516c\u5f00\u53ef\u7528\u7684Hugging Face Spaces\u91cd\u73b0\u3002"}}
{"id": "2602.19253", "categories": ["cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.19253", "abs": "https://arxiv.org/abs/2602.19253", "authors": ["Qusai Khaled", "Uzay Kaymak", "Laura Genga"], "title": "Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems", "comment": "Accepted at IEEE Conference on Artificial Intelligence 2026 (IEEE CAI 2026)", "summary": "Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aX-ANFIS\u7684\u53cc\u76ee\u6807\u68af\u5ea6\u4f18\u5316\u65b9\u6848\uff0c\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u795e\u7ecf\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ea4\u66ff\u68af\u5ea6\u4f20\u9012\u6765\u89e3\u8026\u6027\u80fd\u76ee\u6807\u548c\u53ef\u89e3\u91ca\u6027\u76ee\u6807\uff0c\u5e76\u5728\u4e5d\u4e2aUCI\u56de\u5f52\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7ea65000\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660eX-ANFIS\u80fd\u591f\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u8fbe\u5230\u76ee\u6807\u533a\u5206\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u901a\u8fc7\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u8fdb\u5316\u591a\u76ee\u6807\u4f18\u5316\uff08MOO\uff09\u6765\u5e73\u8861\u7cbe\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u8981\u4e48\u91c7\u7528\u65e0\u6cd5\u6062\u590d\u975e\u51f8Pareto\u533a\u57df\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u6807\u91cf\u5316\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5373\u540c\u65f6\u63d0\u9ad8\u6a21\u7cca\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86X-ANFIS\uff0c\u8fd9\u662f\u4e00\u79cd\u4ea4\u66ff\u53cc\u76ee\u6807\u68af\u5ea6\u4f18\u5316\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u53ef\u89e3\u91ca\u6027\u7684\u81ea\u9002\u5e94\u795e\u7ecf\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528Cauchy\u96b6\u5c5e\u51fd\u6570\u4ee5\u5b9e\u73b0\u8bed\u4e49\u63a7\u5236\u521d\u59cb\u5316\u4e0b\u7684\u7a33\u5b9a\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u53ef\u89e3\u91ca\u6027\u76ee\u6807\uff0c\u5b83\u901a\u8fc7\u4ea4\u66ff\u68af\u5ea6\u4f20\u9012\u4ece\u6027\u80fd\u76ee\u6807\u4e2d\u5206\u79bb\u51fa\u6765\u3002", "result": "\u7ecf\u8fc7\u5bf9\u4e5d\u4e2aUCI\u56de\u5f52\u6570\u636e\u96c6\u7684\u5927\u7ea65,000\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\uff0cX-ANFIS\u80fd\u591f\u4e00\u81f4\u5730\u8fbe\u5230\u76ee\u6807\u533a\u5206\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u627e\u5230\u4e86\u8d85\u51faMOO Pareto\u524d\u6cbf\u51f8\u5305\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "X-ANFIS\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u81ea\u9002\u5e94\u795e\u7ecf\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u4e0d\u4f1a\u727a\u7272\u592a\u591a\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u53ef\u5fae\u5206\u7684\u53ef\u89e3\u91ca\u6027\u76ee\u6807\u5e76\u91c7\u7528\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d\u7b56\u7565\uff0c\u6210\u529f\u5730\u89e3\u51b3\u4e86\u7cbe\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2602.19261", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.19261", "abs": "https://arxiv.org/abs/2602.19261", "authors": ["Aleksei Liuliakov", "Luca Hermes", "Barbara Hammer"], "title": "DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation", "comment": "Submitted to IJCNN 2026 (IEEE WCCI). 6 pages, 4 figures", "summary": "Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGPO\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u62d3\u6251\u8282\u70b9\u6392\u5e8f\u548c\u4f4d\u7f6e\u7f16\u7801\u6269\u5c55\u4e86\u79bb\u6563\u56fe\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u4ee5\u5904\u7406\u6709\u5411\u65e0\u73af\u56fe\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728NAS-Bench-101\u548cNAS-Bech-201\u4e0a\u53d6\u5f97\u4e86\u4e0e\u57fa\u51c6\u76f8\u5f53\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u80fd\u591f\u5b66\u4e60\u53ef\u8fc1\u79fb\u7684\u7ed3\u6784\u5148\u9a8c\uff0c\u5728\u4ec5\u4f7f\u75287%\u641c\u7d22\u7a7a\u95f4\u9884\u8bad\u7ec3\u540e\uff0c\u751f\u6210\u63a5\u8fd1\u6700\u4f73\u7684\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u6269\u6563\u65b9\u6cd5\u8bbe\u8ba1\u7528\u4e8e\u65e0\u5411\u7ed3\u6784\uff0c\u5ffd\u7565\u4e86\u795e\u7ecf\u67b6\u6784\u4e2d\u8fb9\u7684\u65b9\u5411\u6240\u7f16\u7801\u7684\u529f\u80fd\u8bed\u4e49\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u7b49\u7ec4\u5408\u7ed3\u6784\u751f\u6210\u4efb\u52a1\u65f6\u3002", "method": "\u63d0\u51fa\u4e86Directed Graph Policy Optimization (DGPO)\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u8fc7\u62d3\u6251\u8282\u70b9\u6392\u5e8f\u548c\u4f4d\u7f6e\u7f16\u7801\u5c06\u79bb\u6563\u56fe\u6269\u6563\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6269\u5c55\u5230\u6709\u5411\u65e0\u73af\u56fe\uff08DAGs\uff09\u7684\u65b9\u6cd5\u3002", "result": "DGPO\u5728NAS-Bench-101\u548cNAS-Bench-201\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u4e0e\u6240\u6709\u4e09\u4e2aNAS-Bench-201\u4efb\u52a1\u7684\u57fa\u51c6\u6700\u4f18\u7ed3\u679c\u76f8\u5339\u914d\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u8be5\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u53ef\u8f6c\u79fb\u7684\u7ed3\u6784\u5148\u9a8c\uff0c\u5373\u5728\u53ea\u5bf9\u641c\u7d22\u7a7a\u95f4\u76847%\u8fdb\u884c\u9884\u8bad\u7ec3\u4e4b\u540e\uff0c\u7ecf\u8fc7\u5fae\u8c03\u80fd\u591f\u751f\u6210\u63a5\u8fd1\u4e8e\u5168\u6570\u636e\u6a21\u578b\u8868\u73b0\u7684\u67b6\u6784\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u4e0b\u7684\u79bb\u6563\u6269\u6563\u4e00\u65e6\u6269\u5c55\u4ee5\u5904\u7406\u65b9\u5411\u6027\u95ee\u9898\uff0c\u5c31\u80fd\u4e3a\u6709\u5411\u7ec4\u5408\u7ed3\u6784\u63d0\u4f9b\u4e00\u4e2a\u53ef\u63a7\u7684\u751f\u6210\u6846\u67b6\u3002"}}
{"id": "2602.19271", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19271", "abs": "https://arxiv.org/abs/2602.19271", "authors": ["Junkang Liu", "Fanhua Shang", "Hongying Liu", "Jin Liu", "Weixin An", "Yuanyuan Liu"], "title": "Taming Preconditioner Drift: Unlocking the Potential of Second-Order Optimizers for Federated Learning on Non-IID Data", "comment": null, "summary": "Second-order optimizers can significantly accelerate large-scale training, yet their naive federated variants are often unstable or even diverge on non-IID data.\n  We show that a key culprit is \\emph{preconditioner drift}: client-side second-order training induces heterogeneous \\emph{curvature-defined geometries} (i.e., preconditioner coordinate systems), and server-side model averaging updates computed under incompatible metrics, corrupting the global descent direction.\n  To address this geometric mismatch, we propose \\texttt{FedPAC}, a \\emph{preconditioner alignment and correction} framework for reliable federated second-order optimization.\n  \\texttt{FedPAC} explicitly decouples parameter aggregation from geometry synchronization by:\n  (i) \\textbf{Alignment} (i.e.,aggregating local preconditioners into a global reference and warm-starting clients via global preconditioner); and\n  (ii) \\textbf{Correction} (i.e., steering local preconditioned updates using a global preconditioned direction to suppress long-term drift).\n  We provide drift-coupled non-convex convergence guarantees with linear speedup under partial participation.\n  Empirically, \\texttt{FedPAC} consistently improves stability and accuracy across vision and language tasks, achieving up to $5.8\\%$ absolute accuracy gain on CIFAR-100 with ViTs.\n  Code is available at https://anonymous.4open.science/r/FedPAC-8B24.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u4e8c\u9636\u4f18\u5316\u6846\u67b6FedPAC\uff0c\u901a\u8fc7\u9884\u5904\u7406\u5668\u5bf9\u9f50\u548c\u6821\u6b63\u6765\u89e3\u51b3\u5728\u975eIID\u6570\u636e\u4e0a\u8bad\u7ec3\u65f6\u7684\u51e0\u4f55\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u8054\u90a6\u4e8c\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\u751a\u81f3\u53d1\u6563\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5ba2\u6237\u7aef\u7684\u5c40\u90e8\u8bad\u7ec3\u5bfc\u81f4\u4e86\u4e0d\u540c\u7684\u66f2\u7387\u5b9a\u4e49\u51e0\u4f55\u7ed3\u6784\uff08\u5373\u9884\u5904\u7406\u5750\u6807\u7cfb\uff09\uff0c\u800c\u670d\u52a1\u5668\u7aef\u6a21\u578b\u5e73\u5747\u66f4\u65b0\u4f7f\u7528\u7684\u662f\u8fd9\u4e9b\u4e0d\u517c\u5bb9\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u7834\u574f\u4e86\u5168\u5c40\u4e0b\u964d\u65b9\u5411\u3002", "method": "FedPAC\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a(i) \u5bf9\u9f50\uff1a\u5c06\u672c\u5730\u9884\u5904\u7406\u5668\u805a\u5408\u4e3a\u4e00\u4e2a\u5168\u5c40\u53c2\u8003\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u9884\u5904\u7406\u5668\u70ed\u542f\u52a8\u5ba2\u6237\u7aef\uff1b(ii) \u6821\u6b63\uff1a\u5229\u7528\u5168\u5c40\u9884\u5904\u7406\u65b9\u5411\u5f15\u5bfc\u672c\u5730\u9884\u5904\u7406\u66f4\u65b0\u4ee5\u6291\u5236\u957f\u671f\u6f02\u79fb\u3002", "result": "FedPAC\u80fd\u591f\u5728\u89c6\u89c9\u4e0e\u8bed\u8a00\u4efb\u52a1\u4e2d\u6301\u7eed\u6539\u5584\u7a33\u5b9a\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u4f8b\u5982\uff0c\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\u4f7f\u7528ViTs\u5b9e\u73b0\u4e86\u9ad8\u8fbe5.8%\u7684\u7edd\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5728\u90e8\u5206\u53c2\u4e0e\u6761\u4ef6\u4e0b\u5177\u6709\u7ebf\u6027\u52a0\u901f\u6548\u679c\u7684\u975e\u51f8\u6536\u655b\u4fdd\u8bc1\u3002", "conclusion": "FedPaac\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u7531\u4e8e\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u800c\u5bfc\u81f4\u7684\u4f18\u5316\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.19289", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19289", "abs": "https://arxiv.org/abs/2602.19289", "authors": ["Jiangjie Qiu", "Wentao Li", "Honghao Chen", "Leyi Zhao", "Xiaonan Wang"], "title": "AdsorbFlow: energy-conditioned flow matching enables fast and realistic adsorbate placement", "comment": null, "summary": "Identifying low-energy adsorption geometries on catalytic surfaces is a practical bottleneck for computational heterogeneous catalysis: the difficulty lies not only in the cost of density functional theory (DFT) but in proposing initial placements that relax into the correct energy basins. Conditional denoising diffusion has improved success rates, yet requires $\\sim$100 iterative steps per sample.\n  Here we introduce AdsorbFlow, a deterministic generative model that learns an energy-conditioned vector field on the rigid-body configuration space of adsorbate translation and rotation via conditional flow matching. Energy information enters through classifier-free guidance conditioning -- not energy-gradient guidance -- and sampling reduces to integrating an ODE in as few as 5 steps.\n  On OC20-Dense with full DFT single-point verification, AdsorbFlow with an EquiformerV2 backbone achieves 61.4% SR@10 and 34.1% SR@1 -- surpassing AdsorbDiff (31.8% SR@1, 41.0% SR@10) at every evaluation level and AdsorbML (47.7% SR@10) -- while using 20 times fewer generative steps and achieving the lowest anomaly rate among generative methods (6.8%). On 50 out-of-distribution systems, AdsorbFlow retains 58.0% SR@10 with a MLFF-to-DFT gap of only 4~percentage points. These results establish that deterministic transport is both faster and more accurate than stochastic denoising for adsorbate placement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdsorbFlow\u7684\u786e\u5b9a\u6027\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u50ac\u5316\u8868\u9762\u4e0a\u8bc6\u522b\u4f4e\u80fd\u91cf\u5438\u9644\u51e0\u4f55\u7ed3\u6784\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u6761\u4ef6\u6d41\u5339\u914d\u5b66\u4e60\u5438\u9644\u7269\u5e73\u79fb\u548c\u65cb\u8f6c\u521a\u4f53\u914d\u7f6e\u7a7a\u95f4\u4e2d\u7684\u80fd\u91cf\u6761\u4ef6\u5411\u91cf\u573a\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cAdsorbFlow\u4f7f\u7528\u66f4\u5c11\u7684\u751f\u6210\u6b65\u9aa4\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u8ba1\u7b97\u5f02\u8d28\u50ac\u5316\u4e2d\uff0c\u8bc6\u522b\u50ac\u5316\u8868\u9762\u4e0a\u7684\u4f4e\u80fd\u91cf\u5438\u9644\u51e0\u4f55\u7ed3\u6784\u662f\u4e00\u4e2a\u5b9e\u9645\u74f6\u9888\u95ee\u9898\u3002\u4e0d\u4ec5\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u7684\u6210\u672c\u9ad8\uff0c\u800c\u4e14\u8981\u63d0\u51fa\u80fd\u591f\u677e\u5f1b\u5230\u6b63\u786e\u80fd\u91cf\u76c6\u5730\u7684\u521d\u59cb\u653e\u7f6e\u4e5f\u5f88\u56f0\u96be\u3002\u5c3d\u7ba1\u6761\u4ef6\u53bb\u566a\u6269\u6563\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u4f46\u6bcf\u6837\u672c\u4ecd\u9700\u7ea6100\u6b21\u8fed\u4ee3\u6b65\u9aa4\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f15\u5165\u4e86AdsorbFlow\uff0c\u8fd9\u662f\u4e00\u79cd\u786e\u5b9a\u6027\u7684\u751f\u6210\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u6761\u4ef6\u6d41\u5339\u914d\u5b66\u4e60\u5438\u9644\u7269\u5e73\u79fb\u548c\u65cb\u8f6c\u521a\u4f53\u914d\u7f6e\u7a7a\u95f4\u4e2d\u7684\u80fd\u91cf\u6761\u4ef6\u5411\u91cf\u573a\u3002\u80fd\u91cf\u4fe1\u606f\u662f\u901a\u8fc7\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u6761\u4ef6\u8f93\u5165\u7684\uff0c\u800c\u4e0d\u662f\u901a\u8fc7\u80fd\u91cf\u68af\u5ea6\u5f15\u5bfc\u3002\u91c7\u6837\u8fc7\u7a0b\u7b80\u5316\u4e3a\u6c42\u89e3\u4e00\u4e2aODE\uff0c\u53ea\u9700\u6700\u5c115\u6b65\u5373\u53ef\u5b8c\u6210\u3002", "result": "\u5728OC20-Dense\u6570\u636e\u96c6\u4e0a\u7684\u5168DFT\u5355\u70b9\u9a8c\u8bc1\u8868\u660e\uff0c\u57fa\u4e8eEquiformerV2\u9aa8\u5e72\u7684AdsorbFlow\u8fbe\u5230\u4e8661.4% SR@10\u548c34.1% SR@1\u7684\u6210\u529f\u7387\uff0c\u8d85\u8fc7\u4e86AdsorbDiff (SR@1 31.8%, SR@10 41.0%) \u548c AdsorbML (SR@10 47.7%) \u5728\u6bcf\u4e2a\u8bc4\u4f30\u7ea7\u522b\u4e0a\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0cAdsorbFlow\u4f7f\u7528\u7684\u751f\u6210\u6b65\u9aa4\u51cf\u5c11\u4e8620\u500d\uff0c\u5e76\u4e14\u5728\u6240\u6709\u751f\u6210\u65b9\u6cd5\u4e2d\u5177\u6709\u6700\u4f4e\u7684\u5f02\u5e38\u7387(6.8%)\u3002\u5bf9\u4e8e50\u4e2a\u5206\u5e03\u5916\u7cfb\u7edf\uff0cAdsorbFlow\u4fdd\u6301\u4e8658.0% SR@10 \u7684\u6210\u529f\u7387\uff0cMLFF\u5230DFT\u4e4b\u95f4\u7684\u5dee\u8ddd\u4ec5\u4e3a\u7ea64\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u5438\u9644\u7269\u653e\u7f6e\u800c\u8a00\uff0c\u786e\u5b9a\u6027\u4f20\u8f93\u6bd4\u968f\u673a\u53bb\u566a\u66f4\u5feb\u4e14\u66f4\u51c6\u786e\u3002"}}
{"id": "2602.19327", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19327", "abs": "https://arxiv.org/abs/2602.19327", "authors": ["Svetlana Glazyrina", "Maksim Kryzhanovskiy", "Roman Ischenko"], "title": "Soft Sequence Policy Optimization: Bridging GMPO and SAPO", "comment": null, "summary": "A significant portion of recent research on Large Language Model (LLM) alignment focuses on developing new policy optimization methods based on Group Relative Policy Optimization (GRPO). Two prominent directions have emerged: (i) a shift toward sequence-level importance sampling weights that better align with the sequence-level rewards used in many tasks, and (ii) alternatives to PPO-style clipping that aim to avoid the associated loss of training signal and entropy collapse. Recent work, such as Soft Adaptive Policy Optimization (SAPO), reformulates the Scopic objective within the GRPO framework and achieves both sequence coherence and token adaptivity. Geometric-Mean Policy Optimization (GMPO) leverages token-wise ratio clipping within sequence importance sampling weights. Building on these ideas, this work proposes a new objective that promotes effective policy exploration while maintaining training stability. Specifically, we introduce Soft Sequence Policy Optimization, an off-policy reinforcement learning objective that incorporates soft gating functions over token-level probability ratios within sequence-level importance weights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76ee\u6807\u51fd\u6570\uff0c\u79f0\u4e3a\u8f6f\u5e8f\u5217\u7b56\u7565\u4f18\u5316\uff08Soft Sequence Policy Optimization\uff09\uff0c\u5b83\u7ed3\u5408\u4e86\u5e8f\u5217\u7ea7\u91cd\u8981\u6027\u6743\u91cd\u4e2d\u7684token\u7ea7\u522b\u6982\u7387\u6bd4\u7684\u8f6f\u95e8\u63a7\u51fd\u6570\uff0c\u65e8\u5728\u4fc3\u8fdb\u6709\u6548\u7684\u7b56\u7565\u63a2\u7d22\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u57fa\u4e8e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u5f00\u53d1\u65b0\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e0a\uff0c\u4e3b\u8981\u65b9\u5411\u5305\u62ec\u5411\u66f4\u597d\u5730\u4e0e\u4efb\u52a1\u4e2d\u4f7f\u7528\u7684\u5e8f\u5217\u7ea7\u5956\u52b1\u5bf9\u9f50\u7684\u5e8f\u5217\u7ea7\u91cd\u8981\u6027\u91c7\u6837\u6743\u91cd\u8f6c\u53d8\uff0c\u4ee5\u53ca\u5bfb\u627ePPO\u98ce\u683c\u526a\u5207\u7684\u66ff\u4ee3\u65b9\u6848\u4ee5\u907f\u514d\u76f8\u5173\u7684\u8bad\u7ec3\u4fe1\u53f7\u635f\u5931\u548c\u71b5\u5d29\u6e83\u3002\u672c\u6587\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u76ee\u6807\u51fd\u6570\u6765\u63d0\u9ad8\u7b56\u7565\u63a2\u7d22\u6548\u7387\u5e76\u7ef4\u6301\u8bad\u7ec3\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u8f6f\u5e8f\u5217\u7b56\u7565\u4f18\u5316\uff08SSPO\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u5b83\u901a\u8fc7\u5728\u5e8f\u5217\u7ea7\u91cd\u8981\u6027\u6743\u91cd\u5185\u52a0\u5165token\u7ea7\u522b\u7684\u6982\u7387\u6bd4\u7387\u4e0a\u7684\u8f6f\u95e8\u63a7\u51fd\u6570\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u7b56\u7565\u63a2\u7d22\u3002", "result": "\u867d\u7136\u6458\u8981\u4e2d\u6ca1\u6709\u76f4\u63a5\u63d0\u4f9b\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u53ef\u4ee5\u63a8\u6d4b\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u5728\u4fc3\u8fdb\u7b56\u7565\u63a2\u7d22\u7684\u540c\u65f6\uff0c\u4e5f\u80fd\u591f\u89e3\u51b3\u4e4b\u524d\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u2014\u2014\u8f6f\u5e8f\u5217\u7b56\u7565\u4f18\u5316\uff0c\u65e8\u5728\u901a\u8fc7\u6539\u8fdb\u7684\u91cd\u8981\u6027\u6743\u91cd\u673a\u5236\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7b56\u7565\u63a2\u7d22\u80fd\u529b\uff0c\u5e76\u4e14\u4fdd\u8bc1\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.19345", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19345", "abs": "https://arxiv.org/abs/2602.19345", "authors": ["Egor Denisov", "Svetlana Glazyrina", "Maksim Kryzhanovskiy", "Roman Ischenko"], "title": "Smooth Gate Functions for Soft Advantage Policy Optimization", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has significantly advanced the training of large language models and enhanced their reasoning capabilities, while it remains susceptible to instability due to the use of hard clipping. Soft Adaptive Policy Optimization (SAPO) addresses this limitation by replacing clipping with a smooth sigmoid-based gate function, which leads to more stable updates. We have decided to push this theory further and investigate the impact of different gate functions on both training stability and final model performance. We formalize the key properties that admissible gates should satisfy and identify several families of such functions for empirical evaluation. This paper presents an analysis of our findings based on experiments conducted with the Qwen2.5-7B-Instruct model on mathematical reasoning tasks. These results provide practical guidance for designing smoother and more robust policy optimization objectives for large language model training.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728GRPO\u7684\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u4f7f\u7528\u4e0d\u540c\u95e8\u51fd\u6570\u6765\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u8fd9\u4e9b\u95e8\u51fd\u6570\u5bf9Qwen2.5-7B-Instruct\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u663e\u8457\u63a8\u8fdb\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u5e76\u589e\u5f3a\u4e86\u5176\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u7531\u4e8e\u4f7f\u7528\u786c\u88c1\u526a\u800c\u5bb9\u6613\u51fa\u73b0\u4e0d\u7a33\u5b9a\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u8f6f\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316\uff08SAPO\uff09\u91c7\u7528\u5e73\u6ed1\u7684\u57fa\u4e8eSigmoid\u7684\u95e8\u51fd\u6570\u4ee3\u66ff\u88c1\u526a\uff0c\u4ee5\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u66f4\u65b0\u3002\u7814\u7a76\u8005\u5e0c\u671b\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4e0d\u540c\u95e8\u51fd\u6570\u5bf9\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u672c\u6587\u6b63\u5f0f\u5b9a\u4e49\u4e86\u53ef\u63a5\u53d7\u95e8\u51fd\u6570\u5e94\u6ee1\u8db3\u7684\u5173\u952e\u5c5e\u6027\uff0c\u5e76\u8bc6\u522b\u51fa\u51e0\u4e2a\u8fd9\u6837\u7684\u51fd\u6570\u5bb6\u65cf\u7528\u4e8e\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7814\u7a76\u901a\u8fc7\u5bf9Qwen2.5-7B-Instruct\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u6765\u5206\u6790\u8fd9\u4e9b\u53d1\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u66f4\u5e73\u6ed1\u548c\u66f4\u9c81\u68d2\u7684\u7b56\u7565\u4f18\u5316\u76ee\u6807\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "conclusion": "\u9009\u62e9\u5408\u9002\u7684\u95e8\u51fd\u6570\u53ef\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u7a33\u5b9a\u6027\u53ca\u6700\u7ec8\u6027\u80fd\uff1b\u901a\u8fc7\u660e\u786e\u826f\u597d\u95e8\u51fd\u6570\u9700\u5177\u5907\u7684\u7279\u70b9\uff0c\u5e76\u7ecf\u7531\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u51e0\u7c7b\u51fd\u6570\u7684\u8868\u73b0\uff0c\u8be5\u7814\u7a76\u4e3a\u540e\u7eed\u5de5\u4f5c\u6307\u51fa\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.19355", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19355", "abs": "https://arxiv.org/abs/2602.19355", "authors": ["David Rawlinson", "Gideon Kowadlo"], "title": "Active perception and disentangled representations allow continual, episodic zero and few-shot learning", "comment": "17 pages; 7 figures", "summary": "Generalization is often regarded as an essential property of machine learning systems. However, perhaps not every component of a system needs to generalize. Training models for generalization typically produces entangled representations at the boundaries of entities or classes, which can lead to destructive interference when rapid, high-magnitude updates are required for continual or few-shot learning. Techniques for fast learning with non-interfering representations exist, but they generally fail to generalize. Here, we describe a Complementary Learning System (CLS) in which the fast learner entirely foregoes generalization in exchange for continual zero-shot and few-shot learning. Unlike most CLS approaches, which use episodic memory primarily for replay and consolidation, our fast, disentangled learner operates as a parallel reasoning system. The fast learner can overcome observation variability and uncertainty by leveraging a conventional slow, statistical learner within an active perception system: A contextual bias provided by the fast learner induces the slow learner to encode novel stimuli in familiar, generalized terms, enabling zero-shot and few-shot learning. This architecture demonstrates that fast, context-driven reasoning can coexist with slow, structured generalization, providing a pathway for robust continual learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e92\u8865\u5b66\u4e60\u7cfb\u7edf(Complementary Learning System, CLS)\uff0c\u5176\u4e2d\u5feb\u901f\u5b66\u4e60\u5668\u5b8c\u5168\u653e\u5f03\u6cdb\u5316\u4ee5\u5b9e\u73b0\u6301\u7eed\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u3002\u8fd9\u79cd\u67b6\u6784\u8868\u660e\uff0c\u5feb\u901f\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u63a8\u7406\u53ef\u4ee5\u4e0e\u7f13\u6162\u3001\u7ed3\u6784\u5316\u7684\u6cdb\u5316\u5171\u5b58\uff0c\u4e3a\u7a33\u5065\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u6761\u8def\u5f84\u3002", "motivation": "\u6587\u7ae0\u65e8\u5728\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u6cdb\u5316\u9700\u6c42\u4e0e\u5feb\u901f\u5b66\u4e60\u4e4b\u95f4\u5b58\u5728\u7684\u77db\u76fe\u95ee\u9898\u3002\u4f20\u7edf\u7684\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u503e\u5411\u4e8e\u4ea7\u751f\u5b9e\u4f53\u6216\u7c7b\u522b\u8fb9\u754c\u4e0a\u7684\u7ea0\u7f20\u8868\u793a\uff0c\u8fd9\u5728\u9700\u8981\u8fdb\u884c\u5feb\u901f\u5927\u5e45\u5ea6\u66f4\u65b0\uff08\u5982\u6301\u7eed\u5b66\u4e60\u6216\u5c11\u6837\u672c\u5b66\u4e60\uff09\u65f6\u53ef\u80fd\u5bfc\u81f4\u7834\u574f\u6027\u5e72\u6270\u3002\u867d\u7136\u5b58\u5728\u4e00\u4e9b\u80fd\u591f\u5b9e\u73b0\u975e\u5e72\u6270\u8868\u793a\u7684\u5feb\u901f\u5b66\u4e60\u6280\u672f\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e92\u8865\u5b66\u4e60\u7cfb\u7edf(Complementary Learning System, CLS)\u6846\u67b6\uff0c\u5728\u8be5\u6846\u67b6\u4e0b\uff0c\u5feb\u901f\u5b66\u4e60\u7ec4\u4ef6\u5b8c\u5168\u4e0d\u8ffd\u6c42\u6cdb\u5316\u6027\u80fd\uff0c\u800c\u662f\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u8fde\u7eed\u6027\u7684\u96f6\u6837\u672c\u53ca\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u4efb\u52a1\u3002\u4e0d\u540c\u4e8e\u4ee5\u5f80\u591a\u6570CLS\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u60c5\u666f\u8bb0\u5fc6\u6765\u8fdb\u884c\u91cd\u64ad\u548c\u5de9\u56fa\uff0c\u8fd9\u91cc\u63d0\u51fa\u7684\u5feb\u901f\u89e3\u7f20\u5b66\u4e60\u8005\u4f5c\u4e3a\u4e00\u4e2a\u5e76\u884c\u63a8\u7406\u7cfb\u7edf\u8fd0\u884c\u3002\u901a\u8fc7\u5229\u7528\u4f20\u7edf\u6162\u901f\u7edf\u8ba1\u5b66\u4e60\u8005\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u504f\u5dee\uff0c\u5feb\u901f\u5b66\u4e60\u8005\u4fc3\u4f7f\u6162\u901f\u5b66\u4e60\u8005\u4ee5\u719f\u6089\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u65b0\u523a\u6fc0\uff0c\u4ece\u800c\u652f\u6301\u96f6\u6837\u672c\u548c\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u5373\u5feb\u901f\u3001\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u63a8\u7406\u786e\u5b9e\u53ef\u4ee5\u4e0e\u6162\u901f\u3001\u7ed3\u6784\u5316\u7684\u6cdb\u5316\u5171\u5b58\uff0c\u5e76\u4e14\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u5b9e\u73b0\u66f4\u52a0\u9c81\u68d2\u7684\u8fde\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u901a\u8fc7\u7ed3\u5408\u5feb\u901f\u65e0\u6cdb\u5316\u5b66\u4e60\u4e0e\u6162\u901f\u6cdb\u5316\u5b66\u4e60\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u4fc3\u8fdb\u9c81\u68d2\u7684\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u9ad8\u6548\u7075\u6d3b\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2602.19362", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19362", "abs": "https://arxiv.org/abs/2602.19362", "authors": ["Daniel Ritter", "Owen Oertell", "Bradley Guo", "Jonathan Chang", "Kiant\u00e9 Brantley", "Wen Sun"], "title": "LLMs Can Learn to Reason Via Off-Policy RL", "comment": null, "summary": "Reinforcement learning (RL) approaches for Large Language Models (LLMs) frequently use on-policy algorithms, such as PPO or GRPO. However, policy lag from distributed training architectures and differences between the training and inference policies break this assumption, making the data off-policy by design. To rectify this, prior work has focused on making this off-policy data appear more on-policy, either via importance sampling (IS), or by more closely aligning the training and inference policies by explicitly modifying the inference engine. In this work, we embrace off-policyness and propose a novel off-policy RL algorithm that does not require these modifications: Optimal Advantage-based Policy Optimization with Lagged Inference policy (OAPL). We show that OAPL outperforms GRPO with importance sampling on competition math benchmarks, and can match the performance of a publicly available coding model, DeepCoder, on LiveCodeBench, while using 3x fewer generations during training. We further empirically demonstrate that models trained via OAPL have improved test time scaling under the Pass@k metric. OAPL allows for efficient, effective post-training even with lags of more than 400 gradient steps between the training and inference policies, 100x more off-policy than prior approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5OAPL\uff0c\u8be5\u7b97\u6cd5\u5728\u7ade\u4e89\u6570\u5b66\u57fa\u51c6\u4e0a\u4f18\u4e8e\u4f7f\u7528\u91cd\u8981\u6027\u91c7\u6837\u7684GRPO\uff0c\u5e76\u4e14\u5728LiveCodeBench\u4e0a\u4e0e\u516c\u5f00\u53ef\u7528\u7684\u7f16\u7801\u6a21\u578bDeepCoder\u8868\u73b0\u76f8\u5f53\uff0c\u540c\u65f6\u8bad\u7ec3\u671f\u95f4\u751f\u6210\u6b21\u6570\u51cf\u5c11\u4e863\u500d\u3002\u6b64\u5916\uff0cOAPL\u5141\u8bb8\u5373\u4f7f\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u7b56\u7565\u4e4b\u95f4\u5b58\u5728\u8d85\u8fc7400\u4e2a\u68af\u5ea6\u6b65\u9aa4\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fdb\u884c\u6709\u6548\u7684\u540e\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5728\u7ebf\u7b56\u7565\u7b97\u6cd5\u5982PPO\u6216GRPO\uff0c\u4f46\u5206\u5e03\u5f0f\u8bad\u7ec3\u67b6\u6784\u5bfc\u81f4\u7684\u7b56\u7565\u6ede\u540e\u4ee5\u53ca\u8bad\u7ec3\u4e0e\u63a8\u7406\u7b56\u7565\u95f4\u7684\u5dee\u5f02\u4f7f\u5f97\u6570\u636e\u672c\u8d28\u4e0a\u662f\u79bb\u7b56\u7565\u7684\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5148\u524d\u7684\u5de5\u4f5c\u96c6\u4e2d\u5728\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u6216\u8005\u66f4\u7d27\u5bc6\u5730\u8c03\u6574\u8bad\u7ec3\u548c\u63a8\u7406\u7b56\u7565\u6765\u4f7f\u8fd9\u4e9b\u79bb\u7b56\u7565\u6570\u636e\u770b\u8d77\u6765\u66f4\u50cf\u662f\u5728\u7ebf\u7b56\u7565\u3002\u672c\u6587\u5219\u62e5\u62b1\u79bb\u7b56\u7565\u6027\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u9700\u8981\u8fd9\u4e9b\u4fee\u6539\u7684\u65b0\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOAPL\u7684\u65b0\u79bb\u7b56\u7565RL\u7b97\u6cd5\uff0c\u5b83\u4e0d\u4f9d\u8d56\u4e8e\u5bf9\u63a8\u7406\u5f15\u64ce\u7684\u663e\u5f0f\u4fee\u6539\u6216\u91cd\u8981\u6027\u91c7\u6837\u3002", "result": "OAPL\u5728\u7ade\u4e89\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86\u91c7\u7528\u91cd\u8981\u6027\u91c7\u6837\u7684GRPO\uff0c\u5e76\u4e14\u80fd\u591f\u4ee5DeepCoder\u5728LiveCodeBench\u4e0a\u7684\u6027\u80fd\u76f8\u5339\u914d\uff0c\u540c\u65f6\u4ec5\u9700\u540e\u8005\u4e09\u5206\u4e4b\u4e00\u7684\u8bad\u7ec3\u751f\u6210\u6b21\u6570\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8fd8\u8868\u660e\uff0c\u901a\u8fc7OAPL\u8bad\u7ec3\u7684\u6a21\u578b\u5728Pass@k\u6307\u6807\u4e0b\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u6027\u6709\u6240\u63d0\u9ad8\u3002", "conclusion": "OAPL\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u56fa\u6709\u79bb\u7b56\u7565\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u7b56\u7565\u95f4\u5b58\u5728\u663e\u8457\u5ef6\u8fdf\u65f6\u4ecd\u4fdd\u6301\u9ad8\u6548\u8bad\u7ec3\u3002"}}
{"id": "2602.19393", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19393", "abs": "https://arxiv.org/abs/2602.19393", "authors": ["Taha Bouhsine"], "title": "In Defense of Cosine Similarity: Normalization Eliminates the Gauge Freedom", "comment": null, "summary": "Steck, Ekanadham, and Kallus [arXiv:2403.05440] demonstrate that cosine similarity of learned embeddings from matrix factorization models can be rendered arbitrary by a diagonal ``gauge'' matrix $D$. Their result is correct and important for practitioners who compute cosine similarity on embeddings trained with dot-product objectives. However, we argue that their conclusion, cautioning against cosine similarity in general, conflates the pathology of an incompatible training objective with the geometric validity of cosine distance on the unit sphere. We prove that when embeddings are constrained to the unit sphere $\\mathbb{S}^{d-1}$ (either during or after training with an appropriate objective), the $D$-matrix ambiguity vanishes identically, and cosine distance reduces to exactly half the squared Euclidean distance. This monotonic equivalence implies that cosine-based and Euclidean-based neighbor rankings are identical on normalized embeddings. The ``problem'' with cosine similarity is not cosine similarity, it is the failure to normalize.", "AI": {"tldr": "\u672c\u6587\u6f84\u6e05\u4e86\u5728\u5355\u4f4d\u7403\u9762\u4e0a\u53d7\u7ea6\u675f\u7684\u5d4c\u5165\u4e2d\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u6709\u6548\u6027\uff0c\u6307\u51faSteck\u7b49\u4eba\u7684\u7ed3\u8bba\u4e0d\u5e94\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u53cd\u5bf9\u6240\u6709\u60c5\u51b5\u4e0b\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4f7f\u7528\u3002\u5f53\u5d4c\u5165\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6216\u4e4b\u540e\u88ab\u6b63\u89c4\u5316\u5230\u5355\u4f4d\u7403\u9762\u65f6\uff0c\u7531\u5bf9\u89d2'\u89c4\u8303'\u77e9\u9635D\u5f15\u8d77\u7684\u95ee\u9898\u6d88\u5931\uff0c\u5e76\u4e14\u4f59\u5f26\u8ddd\u79bb\u7b49\u540c\u4e8e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u7684\u4e00\u534a\u5e73\u65b9\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u56de\u5e94Steck\u7b49\u4eba\u5173\u4e8e\u4ece\u77e9\u9635\u5206\u89e3\u6a21\u578b\u5b66\u5230\u7684\u5d4c\u5165\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u53ef\u80fd\u7531\u4e8e\u5bf9\u89d2'\u89c4\u8303'\u77e9\u9635D\u800c\u53d8\u5f97\u4efb\u610f\u7684\u89c2\u70b9\u3002\u867d\u7136\u627f\u8ba4\u539f\u7814\u7a76\u7ed3\u679c\u5bf9\u4e8e\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u5b9e\u8df5\u8005\u662f\u6b63\u786e\u7684\u548c\u91cd\u8981\u7684\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u4e0d\u5e94\u5c06\u8fd9\u4e00\u53d1\u73b0\u63a8\u5e7f\u4e3a\u5bf9\u4f59\u5f26\u76f8\u4f3c\u5ea6\u666e\u904d\u4f7f\u7528\u7684\u8b66\u544a\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u5982\u679c\u5d4c\u5165\u88ab\u9650\u5236\u5728\u5355\u4f4d\u7403\u9762\u4e0a\uff08\u65e0\u8bba\u662f\u8bad\u7ec3\u671f\u95f4\u8fd8\u662f\u4e4b\u540e\u901a\u8fc7\u9002\u5f53\u7684\u76ee\u6807\u51fd\u6570\uff09\uff0c\u5219\u53ef\u4ee5\u6d88\u9664\u7531D-\u77e9\u9635\u5f15\u8d77\u7684\u6b67\u4e49\u3002\u6b64\u5916\uff0c\u5c55\u793a\u4e86\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f59\u5f26\u8ddd\u79bb\u4e0e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u4e4b\u95f4\u5b58\u5728\u5355\u8c03\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6b63\u89c4\u5316\u540e\u7684\u5d4c\u5165\u4e0a\uff0c\u57fa\u4e8e\u4f59\u5f26\u7684\u8ddd\u79bb\u4e0e\u57fa\u4e8e\u6b27\u51e0\u91cc\u5f97\u7684\u8ddd\u79bb\u4e4b\u95f4\u7684\u90bb\u5c45\u6392\u540d\u662f\u5b8c\u5168\u76f8\u540c\u7684\u3002\u8fd9\u8868\u660e\uff0c\u53ea\u8981\u6b63\u786e\u5730\u5e94\u7528\u4e86\u89c4\u8303\u5316\u6b65\u9aa4\uff0c\u90a3\u4e48\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u4e2d\u7684\u6240\u8c13\u95ee\u9898\u5b9e\u9645\u4e0a\u5e76\u4e0d\u5b58\u5728\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u4e86\u5d4c\u5165\u5411\u91cf\u6b63\u89c4\u5316\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u786e\u4fdd\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002\u6587\u7ae0\u8fd8\u6307\u51fa\uff0c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u672c\u8eab\u5e76\u4e0d\u662f\u95ee\u9898\u6240\u5728\uff1b\u771f\u6b63\u7684\u95ee\u9898\u5728\u4e8e\u7f3a\u4e4f\u9002\u5f53\u7684\u89c4\u8303\u5316\u5904\u7406\u3002"}}
{"id": "2602.19419", "categories": ["cs.LG", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2602.19419", "abs": "https://arxiv.org/abs/2602.19419", "authors": ["Pranay Anchuri"], "title": "RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs", "comment": "12 pages, 1 figure, 4 tables, 1 algorithm; submitted to Designing DeFi workshop (https://www.designingdefi.xyz/)", "summary": "Concentrated liquidity provision in decentralized exchanges presents a fundamental Impulse Control problem. Liquidity Providers (LPs) face a non-trivial trade-off between maximizing fee accrual through tight price-range concentration and minimizing the friction costs of rebalancing, including gas fees and swap slippage. Existing methods typically employ heuristic or threshold strategies that fail to account for market dynamics. This paper formulates liquidity management as an optimal control problem and derives the corresponding Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI). We present an approximate solution RAmmStein, a Deep Reinforcement Learning method that incorporates the mean-reversion speed (theta) of an Ornstein-Uhlenbeck process among other features as input to the model. We demonstrate that the agent learns to separate the state space into regions of action and inaction. We evaluate the framework using high-frequency 1Hz Coinbase trade data comprising over 6.8M trades. Experimental results show that RAmmStein achieves a superior net ROI of 0.72% compared to both passive and aggressive strategies. Notably, the agent reduces rebalancing frequency by 67% compared to a greedy rebalancing strategy while maintaining 88% active time. Our results demonstrate that regime-aware laziness can significantly improve capital efficiency by preserving the returns that would otherwise be eroded by the operational costs.", "AI": {"tldr": "\u672c\u6587\u5c06\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\u4e2d\u7684\u6d41\u52a8\u6027\u63d0\u4f9b\u95ee\u9898\u89c6\u4e3a\u4e00\u4e2a\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848RAmmStein\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u8d44\u672c\u6548\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u518d\u5e73\u8861\u9891\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u6d41\u52a8\u6027\u7ba1\u7406\u7b56\u7565\u901a\u5e38\u91c7\u7528\u542f\u53d1\u5f0f\u6216\u9608\u503c\u7b56\u7565\uff0c\u672a\u80fd\u5145\u5206\u8003\u8651\u5e02\u573a\u52a8\u6001\u53d8\u5316\u3002\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u5728\u6700\u5927\u5316\u8d39\u7528\u7d2f\u79ef\u548c\u6700\u5c0f\u5316\u518d\u5e73\u8861\u6469\u64e6\u6210\u672c\uff08\u5982gas\u8d39\u3001\u4ea4\u6613\u6ed1\u70b9\uff09\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u7814\u7a76\u8005\u5c1d\u8bd5\u901a\u8fc7\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u6765\u5bfb\u627e\u6700\u4f18\u89e3\u3002", "method": "\u9996\u5148\uff0c\u5c06\u6d41\u52a8\u6027\u7ba1\u7406\u5efa\u6a21\u4e3a\u4e00\u4e2a\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u63a8\u5bfc\u51fa\u5bf9\u5e94\u7684Hamilton-Jacobi-Bellman\u51c6\u53d8\u5206\u4e0d\u7b49\u5f0f(HJB-QVI)\u3002\u63a5\u7740\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8fd1\u4f3c\u89e3\u6cd5\u2014\u2014RAmmStein\uff0c\u8fd9\u662f\u4e00\u79cd\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u5c06Ornstein-Uhlenbeck\u8fc7\u7a0b\u7684\u5747\u503c\u56de\u5f52\u901f\u5ea6\u4ee5\u53ca\u5176\u4ed6\u7279\u5f81\u4f5c\u4e3a\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cRAmmStein\u76f8\u6bd4\u88ab\u52a8\u548c\u6fc0\u8fdb\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c0\u56de\u62a5\u7387(0.72%)\u3002\u6b64\u5916\uff0c\u4e0e\u8d2a\u5a6a\u518d\u5e73\u8861\u7b56\u7565\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e8667%\u7684\u518d\u5e73\u8861\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4e8688%\u7684\u6709\u6548\u65f6\u95f4\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u91c7\u53d6\u5177\u6709\u5236\u5ea6\u610f\u8bc6\u7684\u61d2\u60f0\u7b56\u7565\uff0c\u53ef\u4ee5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u8d44\u672c\u6548\u7387\uff0c\u4ece\u800c\u4fdd\u7559\u539f\u672c\u53ef\u80fd\u56e0\u64cd\u4f5c\u6210\u672c\u800c\u88ab\u4fb5\u8680\u7684\u6536\u76ca\u3002"}}
{"id": "2602.19444", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19444", "abs": "https://arxiv.org/abs/2602.19444", "authors": ["Qianfeng Yu", "Ningkang Peng", "Yanhui Gu"], "title": "PIS: A Physics-Informed System for Accurate State Partitioning of $A\u03b2_{42}$ Protein Trajectories", "comment": null, "summary": "Understanding the conformational evolution of $\u03b2$-amyloid ($A\u03b2$), particularly the $A\u03b2_{42}$ isoform, is fundamental to elucidating the pathogenic mechanisms underlying Alzheimer's disease. However, existing end-to-end deep learning models often struggle to capture subtle state transitions in protein trajectories due to a lack of explicit physical constraints. In this work, we introduce PIS, a Physics-Informed System designed for robust metastable state partitioning. By integrating pre-computed physical priors, such as the radius of gyration and solvent-accessible surface area, into the extraction of topological features, our model achieves superior performance on the $A\u03b2_{42}$ dataset. Furthermore, PIS provides an interactive platform that features dynamic monitoring of physical characteristics and multi-dimensional result validation. This system offers biological researchers a powerful set of analytical tools with physically grounded interpretability. A demonstration video of PIS is available on https://youtu.be/AJHGzUtRCg0.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aPIS\u7684\u7269\u7406\u4fe1\u606f\u7cfb\u7edf\uff0c\u7528\u4e8e\u7a33\u5065\u7684\u4e9a\u7a33\u6001\u5212\u5206\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u9884\u8ba1\u7b97\u7684\u7269\u7406\u5148\u9a8c\u5982\u56de\u8f6c\u534a\u5f84\u548c\u6eb6\u5242\u53ef\u53ca\u8868\u9762\u79ef\u6765\u6539\u8fdb\u5bf9\u86cb\u767d\u8d28\u8f68\u8ff9\u4e2d\u5fae\u5999\u72b6\u6001\u8f6c\u6362\u7684\u7406\u89e3\u3002\u8be5\u7cfb\u7edf\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5e73\u53f0\uff0c\u53ef\u4ee5\u52a8\u6001\u76d1\u6d4b\u7269\u7406\u7279\u6027\u5e76\u8fdb\u884c\u591a\u7ef4\u7ed3\u679c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6355\u6349\u86cb\u767d\u8d28\u8f68\u8ff9\u4e2d\u7684\u7ec6\u5fae\u72b6\u6001\u8f6c\u53d8\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u660e\u786e\u7684\u7269\u7406\u7ea6\u675f\u3002\u800c\u7406\u89e3\u03b2-\u6dc0\u7c89\u6837\u86cb\u767d\uff08A\u03b2\uff09\uff0c\u7279\u522b\u662fA\u03b242\u5f02\u6784\u4f53\u7684\u6784\u8c61\u6f14\u53d8\u5bf9\u4e8e\u9610\u660e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u53d1\u75c5\u673a\u5236\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86PIS\uff08Physics-Informed System\uff09\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u5c06\u8bf8\u5982\u56de\u8f6c\u534a\u5f84\u548c\u6eb6\u5242\u53ef\u53ca\u8868\u9762\u79ef\u7b49\u9884\u5148\u8ba1\u7b97\u597d\u7684\u7269\u7406\u5148\u9a8c\u878d\u5165\u5230\u62d3\u6251\u7279\u5f81\u63d0\u53d6\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9A\u03b242\u6570\u636e\u96c6\u4e0a\u66f4\u4f18\u7684\u8868\u73b0\u3002", "result": "PIS\u7cfb\u7edf\u4e0d\u4ec5\u5728A\u03b242\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u800c\u4e14\u4e3a\u751f\u7269\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5177\u6709\u7269\u7406\u57fa\u7840\u89e3\u91ca\u6027\u7684\u5f3a\u5927\u5206\u6790\u5de5\u5177\u96c6\u5408\u3002\u6b64\u5916\uff0cPIS\u8fd8\u914d\u5907\u4e86\u4e00\u4e2a\u652f\u6301\u52a8\u6001\u76d1\u63a7\u7269\u7406\u7279\u6027\u548c\u591a\u7ef4\u5ea6\u7ed3\u679c\u9a8c\u8bc1\u7684\u4e92\u52a8\u5e73\u53f0\u3002", "conclusion": "PIS\u4f5c\u4e3a\u4e00\u6b3e\u7ed3\u5408\u4e86\u7269\u7406\u4fe1\u606f\u7684\u7cfb\u7edf\uff0c\u5728\u5904\u7406A\u03b242\u86cb\u767d\u8d28\u6784\u8c61\u53d8\u5316\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u7814\u7a76\u8005\u4eec\u7406\u89e3\u548c\u63a2\u7d22\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u76f8\u5173\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u624b\u6bb5\u3002"}}
{"id": "2602.19455", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19455", "abs": "https://arxiv.org/abs/2602.19455", "authors": ["Zelin He", "Boran Han", "Xiyuan Zhang", "Shuai Zhang", "Haotian Lin", "Qi Zhu", "Haoyang Fang", "Danielle C. Maddix", "Abdul Fatir Ansari", "Akash Chandrayan", "Abhinav Pradhan", "Bernie Wang", "Matthew Reimherr"], "title": "SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning", "comment": "Accepted by the 29th International Conference on Artificial Intelligence and Statistics (AISTATS 2026)", "summary": "Time-series diagnostic reasoning is essential for many applications, yet existing solutions face a persistent gap: general reasoning large language models (GRLMs) possess strong reasoning skills but lack the domain-specific knowledge to understand complex time-series patterns. Conversely, fine-tuned time-series LLMs (TSLMs) understand these patterns but lack the capacity to generalize reasoning for more complicated questions. To bridge this gap, we propose a hybrid knowledge-injection framework that injects TSLM-generated insights directly into GRLM's reasoning trace, thereby achieving strong time-series reasoning with in-domain knowledge. As collecting data for knowledge injection fine-tuning is costly, we further leverage a reinforcement learning-based approach with verifiable rewards (RLVR) to elicit knowledge-rich traces without human supervision, then transfer such an in-domain thinking trace into GRLM for efficient knowledge injection. We further release SenTSR-Bench, a multivariate time-series-based diagnostic reasoning benchmark collected from real-world industrial operations. Across SenTSR-Bench and other public datasets, our method consistently surpasses TSLMs by 9.1%-26.1% and GRLMs by 7.9%-22.4%, delivering robust, context-aware time-series diagnostic insights.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u8bed\u8a00\u6a21\u578b\uff08TSLM\uff09\u751f\u6210\u7684\u89c1\u89e3\u76f4\u63a5\u6ce8\u5165\u5230\u901a\u7528\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff08GRLM\uff09\u4e2d\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u5373\u53ef\u83b7\u53d6\u5bcc\u542b\u77e5\u8bc6\u7684\u601d\u8003\u8f68\u8ff9\uff0c\u4ece\u800c\u5b9e\u73b0\u5f3a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e0e\u9886\u57df\u5185\u77e5\u8bc6\u7ed3\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u8bca\u65ad\u63a8\u7406\u65f6\u5b58\u5728\u4e00\u4e2a\u6301\u7eed\u7684\u95ee\u9898\uff1a\u901a\u7528\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u4f46\u7f3a\u4e4f\u5bf9\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u7684\u7406\u89e3\uff1b\u800c\u7ecf\u8fc7\u5fae\u8c03\u7684\u65f6\u95f4\u5e8f\u5217\u8bed\u8a00\u6a21\u578b\u867d\u7136\u7406\u89e3\u8fd9\u4e9b\u6a21\u5f0f\uff0c\u4f46\u5728\u9762\u5bf9\u66f4\u590d\u6742\u95ee\u9898\u65f6\u7f3a\u4e4f\u6cdb\u5316\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5c06TSLM\u4ea7\u751f\u7684\u6d1e\u5bdf\u76f4\u63a5\u6574\u5408\u5230GRLM\u7684\u63a8\u7406\u8fc7\u7a0b\u4e2d\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u6765\u65e0\u76d1\u7763\u5730\u6fc0\u53d1\u5bcc\u6709\u77e5\u8bc6\u542b\u91cf\u7684\u601d\u7ef4\u8def\u5f84\uff0c\u5e76\u5c06\u5176\u8f6c\u79fb\u5230GRLM\u4e2d\u4ee5\u4fc3\u8fdb\u6709\u6548\u77e5\u8bc6\u6ce8\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728SenTSR-Bench\u53ca\u5176\u4ed6\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4TSLMs\u548cGRLMs\u5206\u522b\u63d0\u9ad8\u4e869.1%-26.1%\u53ca7.9%-22.4%\uff0c\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u60c5\u5883\u611f\u77e5\u7684\u65f6\u95f4\u5e8f\u5217\u8bca\u65ad\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6df7\u5408\u77e5\u8bc6\u6ce8\u5165\u6846\u67b6\u6210\u529f\u5730\u5f25\u8865\u4e86\u901a\u7528\u63a8\u7406\u6a21\u578b\u4e0e\u4e13\u95e8\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u4e8e\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4e5f\u63d0\u5347\u4e86\u5176\u89e3\u51b3\u66f4\u590d\u6742\u95ee\u9898\u65f6\u7684\u6cdb\u5316\u63a8\u7406\u6c34\u5e73\u3002"}}
{"id": "2602.19483", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19483", "abs": "https://arxiv.org/abs/2602.19483", "authors": ["Arjun Chatterjee", "Sayeed Sajjad Razin", "John Wu", "Siddhartha Laghuvarapu", "Jathurshan Pradeepkumar", "Jimeng Sun"], "title": "Making Conformal Predictors Robust in Healthcare Settings: a Case Study on EEG Classification", "comment": "Under Review", "summary": "Quantifying uncertainty in clinical predictions is critical for high-stakes diagnosis tasks. Conformal prediction offers a principled approach by providing prediction sets with theoretical coverage guarantees. However, in practice, patient distribution shifts violate the i.i.d. assumptions underlying standard conformal methods, leading to poor coverage in healthcare settings. In this work, we evaluate several conformal prediction approaches on EEG seizure classification, a task with known distribution shift challenges and label uncertainty. We demonstrate that personalized calibration strategies can improve coverage by over 20 percentage points while maintaining comparable prediction set sizes. Our implementation is available via PyHealth, an open-source healthcare AI framework: https://github.com/sunlabuiuc/PyHealth.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u51e0\u79cd\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u5728EEG\u766b\u75eb\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e2a\u6027\u5316\u6821\u51c6\u7b56\u7565\u53ef\u4ee5\u5c06\u8986\u76d6\u7387\u63d0\u9ad820\u4e2a\u767e\u5206\u70b9\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u9884\u6d4b\u96c6\u5927\u5c0f\u3002", "motivation": "\u4e34\u5e8a\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5bf9\u4e8e\u9ad8\u98ce\u9669\u8bca\u65ad\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u4fdd\u5f62\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u7406\u8bba\u8986\u76d6\u4fdd\u8bc1\u7684\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5728\u5b9e\u8df5\u4e2d\uff0c\u60a3\u8005\u5206\u5e03\u7684\u53d8\u5316\u8fdd\u53cd\u4e86\u6807\u51c6\u4fdd\u5f62\u65b9\u6cd5\u6240\u57fa\u4e8e\u7684\u72ec\u7acb\u540c\u5206\u5e03\u5047\u8bbe\uff0c\u5bfc\u81f4\u5728\u533b\u7597\u73af\u5883\u4e0b\u7684\u8986\u76d6\u7387\u4e0d\u4f73\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5728EEG\u766b\u75eb\u5206\u7c7b\u4efb\u52a1\u4e0a\u8bc4\u4f30\u4e86\u51e0\u79cd\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u8be5\u4efb\u52a1\u5177\u6709\u5df2\u77e5\u7684\u5206\u5e03\u53d8\u5316\u6311\u6218\u548c\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u91c7\u7528\u4e2a\u6027\u5316\u7684\u6821\u51c6\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u76f8\u8fd1\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u540c\u65f6\uff0c\u5c06\u8986\u76d6\u7387\u63d0\u5347\u8d85\u8fc720\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u9488\u5bf9\u5b58\u5728\u5206\u5e03\u504f\u79fb\u53ca\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u7684EEG\u766b\u75eb\u5206\u7c7b\u95ee\u9898\uff0c\u4e2a\u6027\u5316\u6821\u51c6\u7b56\u7565\u80fd\u663e\u8457\u63d0\u9ad8\u4fdd\u5f62\u9884\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.19489", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19489", "abs": "https://arxiv.org/abs/2602.19489", "authors": ["Bryan Guanrong Shan", "Alysa Ziying Tan", "Han Yu"], "title": "Federated Learning Playground", "comment": null, "summary": "We present Federated Learning Playground, an interactive browser-based platform inspired by and extends TensorFlow Playground that teaches core Federated Learning (FL) concepts. Users can experiment with heterogeneous client data distributions, model hyperparameters, and aggregation algorithms directly in the browser without coding or system setup, and observe their effects on client and global models through real-time visualizations, gaining intuition for challenges such as non-IID data, local overfitting, and scalability. The playground serves as an easy to use educational tool, lowering the entry barrier for newcomers to distributed AI while also offering a sandbox for rapidly prototyping and comparing FL methods. By democratizing exploration of FL, it promotes broader understanding and adoption of this important paradigm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aFederated Learning Playground\u7684\u4e92\u52a8\u6d4f\u89c8\u5668\u5e73\u53f0\uff0c\u7528\u4e8e\u6559\u6388\u8054\u90a6\u5b66\u4e60\u7684\u6838\u5fc3\u6982\u5ff5\uff0c\u7528\u6237\u65e0\u9700\u7f16\u7801\u6216\u7cfb\u7edf\u8bbe\u7f6e\u5373\u53ef\u76f4\u63a5\u5728\u6d4f\u89c8\u5668\u4e2d\u5b9e\u9a8c\u4e0d\u540c\u7684\u6570\u636e\u5206\u5e03\u3001\u6a21\u578b\u8d85\u53c2\u6570\u548c\u805a\u5408\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u65f6\u53ef\u89c6\u5316\u4e86\u89e3\u8fd9\u4e9b\u56e0\u7d20\u5bf9\u5ba2\u6237\u7aef\u6a21\u578b\u548c\u5168\u5c40\u6a21\u578b\u7684\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u5206\u5e03\u5f0fAI\u65b0\u624b\u7684\u5b66\u4e60\u95e8\u69db\uff0c\u540c\u65f6\u4e3a\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u6bd4\u8f83\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u6c99\u76d2\u73af\u5883\uff0c\u4ece\u800c\u4fc3\u8fdb\u5bf9\u8fd9\u4e00\u91cd\u8981\u8303\u5f0f\u7684\u66f4\u5e7f\u6cdb\u7406\u89e3\u548c\u91c7\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6d4f\u89c8\u5668\u7684\u4ea4\u4e92\u5f0f\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u5141\u8bb8\u7528\u6237\u76f4\u63a5\u5728\u6d4f\u89c8\u5668\u5185\u64cd\u4f5c\u800c\u65e0\u9700\u7f16\u5199\u4ee3\u7801\u6216\u8fdb\u884c\u7cfb\u7edf\u914d\u7f6e\uff0c\u652f\u6301\u8c03\u6574\u5f02\u6784\u5ba2\u6237\u7aef\u7684\u6570\u636e\u5206\u5e03\u3001\u6a21\u578b\u8d85\u53c2\u6570\u53ca\u805a\u5408\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u65f6\u53ef\u89c6\u5316\u5c55\u73b0\u5176\u5bf9\u5ba2\u6237\u4e0e\u5168\u5c40\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u521b\u5efa\u4e86Federated Learning Playground\uff0c\u4f5c\u4e3a\u6613\u4e8e\u4f7f\u7528\u7684\u6559\u80b2\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7528\u6237\u7406\u89e3\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff08\u5982\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u3001\u5c40\u90e8\u8fc7\u62df\u5408\u53ca\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff09\u3002", "conclusion": "Federated Learning Playground\u4e0d\u4ec5\u964d\u4f4e\u4e86\u8054\u90a6\u5b66\u4e60\u9886\u57df\u7684\u5165\u95e8\u96be\u5ea6\uff0c\u8fd8\u4e3a\u5feb\u901f\u6d4b\u8bd5\u548c\u6bd4\u8f83\u4e0d\u540c\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4fc3\u8fdb\u4e86\u8be5\u6280\u672f\u7684\u7406\u89e3\u4e0e\u5e94\u7528\u3002"}}
{"id": "2602.19498", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19498", "abs": "https://arxiv.org/abs/2602.19498", "authors": ["Navid Akhavan Attar", "Hesam Asadollahzadeh", "Ling Luo", "Uwe Aickelin"], "title": "Softmax is not Enough (for Adaptive Conformal Classification)", "comment": null, "summary": "The merit of Conformal Prediction (CP), as a distribution-free framework for uncertainty quantification, depends on generating prediction sets that are efficient, reflected in small average set sizes, while adaptive, meaning they signal uncertainty by varying in size according to input difficulty. A central limitation for deep conformal classifiers is that the nonconformity scores are derived from softmax outputs, which can be unreliable indicators of how certain the model truly is about a given input, sometimes leading to overconfident misclassifications or undue hesitation. In this work, we argue that this unreliability can be inherited by the prediction sets generated by CP, limiting their capacity for adaptiveness. We propose a new approach that leverages information from the pre-softmax logit space, using the Helmholtz Free Energy as a measure of model uncertainty and sample difficulty. By reweighting nonconformity scores with a monotonic transformation of the energy score of each sample, we improve their sensitivity to input difficulty. Our experiments with four state-of-the-art score functions on multiple datasets and deep architectures show that this energy-based enhancement improves the adaptiveness of the prediction sets, leading to a notable increase in both efficiency and adaptiveness compared to baseline nonconformity scores, without introducing any post-hoc complexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u9884softmax logit\u7a7a\u95f4\u7684\u4fe1\u606f\u5e76\u4f7f\u7528Helmholtz\u81ea\u7531\u80fd\u4f5c\u4e3a\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u548c\u6837\u672c\u96be\u5ea6\u7684\u5ea6\u91cf\uff0c\u91cd\u65b0\u52a0\u6743\u975e\u4e00\u81f4\u6027\u5206\u6570\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u8f93\u5165\u96be\u5ea6\u7684\u654f\u611f\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u96c6\u7684\u9002\u5e94\u6027\uff0c\u5728\u6548\u7387\u548c\u9002\u5e94\u6027\u65b9\u9762\u90fd\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7684\u6df1\u5ea6\u5171\u5f62\u5206\u7c7b\u5668\u4ecesoftmax\u8f93\u51fa\u4e2d\u5bfc\u51fa\u975e\u4e00\u81f4\u6027\u5206\u6570\uff0c\u8fd9\u53ef\u80fd\u6210\u4e3a\u4e0d\u53ef\u9760\u7684\u6307\u6807\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u7684\u8bef\u5206\u7c7b\u6216\u4e0d\u5fc5\u8981\u7684\u72b9\u8c6b\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u4e0d\u53ef\u9760\u6027\u53ef\u80fd\u4f1a\u88abCP\u751f\u6210\u7684\u9884\u6d4b\u96c6\u7ee7\u627f\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u7684\u9002\u5e94\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u5229\u7528\u9884softmax logit\u7a7a\u95f4\u4e2d\u7684\u4fe1\u606f\uff0c\u5e76\u91c7\u7528Helmholtz\u81ea\u7531\u80fd\u4f5c\u4e3a\u8861\u91cf\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u53ca\u6837\u672c\u96be\u5ea6\u7684\u6307\u6807\u3002\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u6837\u672c\u7684\u80fd\u91cf\u5f97\u5206\u8fdb\u884c\u5355\u8c03\u53d8\u6362\u6765\u91cd\u65b0\u52a0\u6743\u975e\u4e00\u81f4\u6027\u5206\u6570\uff0c\u4ee5\u63d0\u9ad8\u5176\u5bf9\u8f93\u5165\u96be\u5ea6\u7684\u654f\u611f\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6df1\u5ea6\u67b6\u6784\u4e0a\u4f7f\u7528\u56db\u79cd\u6700\u5148\u8fdb\u7684\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u57fa\u4e8e\u80fd\u91cf\u7684\u589e\u5f3a\u65b9\u6cd5\u6539\u5584\u4e86\u9884\u6d4b\u96c6\u7684\u9002\u5e94\u6027\uff0c\u4e0e\u57fa\u51c6\u975e\u4e00\u81f4\u6027\u5206\u6570\u76f8\u6bd4\uff0c\u5728\u6548\u7387\u548c\u9002\u5e94\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u80fd\u91cf\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u9884\u6d4b\u96c6\u7684\u9002\u5e94\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u6027\uff0c\u4e3a\u89e3\u51b3\u4f20\u7edf\u6df1\u5ea6\u5171\u5f62\u5206\u7c7b\u5668\u4e2d\u5b58\u5728\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.19510", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19510", "abs": "https://arxiv.org/abs/2602.19510", "authors": ["Rudrajit Das", "Neel Patel", "Meisam Razaviyayn", "Vahab Mirrokni"], "title": "Less is More: Convergence Benefits of Fewer Data Weight Updates over Longer Horizon", "comment": null, "summary": "Data mixing--the strategic reweighting of training domains--is a critical component in training robust machine learning models. This problem is naturally formulated as a bilevel optimization task, where the outer loop optimizes domain weights to minimize validation loss, and the inner loop optimizes model parameters to minimize the weighted training loss. Classical bilevel optimization relies on hypergradients, which theoretically require the inner optimization to reach convergence. However, due to computational constraints, state-of-the-art methods use a finite, often small, number of inner update steps before updating the weights. The theoretical implications of this approximation are not well understood. In this work, we rigorously analyze the convergence behavior of data mixing with a finite number of inner steps $T$. We prove that the \"greedy\" practical approach of using $T=1$ can fail even in a simple quadratic example. Under a fixed parameter update budget $N$ and assuming the per-domain losses are strongly convex, we show that the optimal $T$ scales as $\u0398(\\log N)$ (resp., $\u0398({(N \\log N)}^{1/2})$) for the data mixing problem with access to full (resp., stochastic) gradients. We complement our theoretical results with proof-of-concept experiments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u6df7\u5408\u5728\u8bad\u7ec3\u9c81\u68d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u4efb\u52a1\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u4f5c\u8005\u4eec\u5206\u6790\u4e86\u6709\u9650\u5185\u5c42\u66f4\u65b0\u6b65\u6570T\u4e0b\u7684\u6536\u655b\u884c\u4e3a\uff0c\u5e76\u8bc1\u660e\u4e86\u5b9e\u8df5\u4e2d\u5e38\u7528\u7684T=1\u7684\u8d2a\u5a6a\u65b9\u6cd5\u5728\u7b80\u5355\u4e8c\u6b21\u793a\u4f8b\u4e2d\u53ef\u80fd\u5931\u8d25\u3002\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u53c2\u6570\u66f4\u65b0\u9884\u7b97N\u548c\u6bcf\u57df\u635f\u5931\u5f3a\u51f8\u5047\u8bbe\u4e0b\uff0c\u4f7f\u7528\u5168\u68af\u5ea6\uff08\u6216\u968f\u673a\u68af\u5ea6\uff09\u65f6\u6700\u4f18T\u503c\u5206\u522b\u4ee5\u0398(log N) (\u6216\u0398((N log N)^{1/2}))\u7684\u6bd4\u4f8b\u589e\u957f\u3002", "motivation": "\u6570\u636e\u6df7\u5408\u662f\u8bad\u7ec3\u9c81\u68d2\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u7531\u4e8e\u8ba1\u7b97\u9650\u5236\uff0c\u5728\u66f4\u65b0\u6743\u91cd\u4e4b\u524d\u4ec5\u91c7\u7528\u6709\u9650\u4e14\u901a\u5e38\u8f83\u5c0f\u6570\u91cf\u7684\u5185\u5c42\u66f4\u65b0\u6b65\u9aa4\uff0c\u8fd9\u5bfc\u81f4\u5bf9\u8fd9\u79cd\u8fd1\u4f3c\u7684\u7406\u8bba\u5f71\u54cd\u5c1a\u4e0d\u5b8c\u5168\u7406\u89e3\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u4e25\u683c\u7684\u6570\u5b66\u5206\u6790\u63a2\u8ba8\u4e86\u5728\u4ec5\u6709\u6709\u9650\u6b21\u5185\u5c42\u66f4\u65b0\u6b65\u9aa4T\u60c5\u51b5\u4e0b\u7684\u6570\u636e\u6df7\u5408\u6536\u655b\u884c\u4e3a\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u56fa\u5b9a\u7684\u53c2\u6570\u66f4\u65b0\u9884\u7b97N\u4ee5\u53ca\u5047\u8bbe\u6bcf\u57df\u635f\u5931\u5f3a\u51f8\u6761\u4ef6\u4e0b\uff0c\u786e\u5b9a\u4e86\u6700\u4f18T\u503c\u7684\u589e\u957f\u6bd4\u4f8b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u7528\u7684\u5355\u6b65\u66f4\u65b0\u7b56\u7565\uff08T=1\uff09\u5373\u4f7f\u662f\u5728\u7b80\u5355\u7684\u4e8c\u6b21\u793a\u4f8b\u4e2d\u4e5f\u53ef\u80fd\u5931\u6548\uff1b\u800c\u9488\u5bf9\u5168\u68af\u5ea6\u8bbf\u95ee\u573a\u666f\uff0c\u5f53T\u6309\u0398(log N)\u589e\u957f\u65f6\u6548\u679c\u6700\u4f73\uff1b\u5bf9\u4e8e\u53ea\u80fd\u8bbf\u95ee\u968f\u673a\u68af\u5ea6\u7684\u60c5\u51b5\uff0c\u5219T\u5e94\u6309\u7167\u0398((N log N)^{1/2})\u589e\u957f\u3002", "conclusion": "\u9009\u62e9\u5408\u9002\u7684\u5185\u5c42\u8fed\u4ee3\u6b21\u6570T\u5bf9\u4e8e\u63d0\u9ad8\u6570\u636e\u6df7\u5408\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5f53\u8003\u8651\u6574\u4f53\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u65f6\u3002\u8be5\u5de5\u4f5c\u4e3a\u5982\u4f55\u5728\u7ed9\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u6709\u6548\u8bbe\u7f6eT\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2602.19528", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19528", "abs": "https://arxiv.org/abs/2602.19528", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Beyond Accuracy: A Unified Random Matrix Theory Diagnostic Framework for Crash Classification Models", "comment": null, "summary": "Crash classification models in transportation safety are typically evaluated using accuracy, F1, or AUC, metrics that cannot reveal whether a model is silently overfitting. We introduce a spectral diagnostic framework grounded in Random Matrix Theory (RMT) and Heavy-Tailed Self-Regularization (HTSR) that spans the ML taxonomy: weight matrices for BERT/ALBERT/Qwen2.5, out-of-fold increment matrices for XGBoost/Random Forest, empirical Hessians for Logistic Regression, induced affinity matrices for Decision Trees, and Graph Laplacians for KNN. Evaluating nine model families on two Iowa DOT crash classification tasks (173,512 and 371,062 records respectively), we find that the power-law exponent $\u03b1$ provides a structural quality signal: well-regularized models consistently yield $\u03b1$ within $[2, 4]$ (mean $2.87 \\pm 0.34$), while overfit variants show $\u03b1< 2$ or spectral collapse. We observe a strong rank correlation between $\u03b1$ and expert agreement (Spearman $\u03c1= 0.89$, $p < 0.001$), suggesting spectral quality captures model behaviors aligned with expert reasoning. We propose an $\u03b1$-based early stopping criterion and a spectral model selection protocol, and validate both against cross-validated F1 baselines. Sparse Lanczos approximations make the framework scalable to large datasets.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u77e9\u9635\u7406\u8bba(RMT)\u548c\u91cd\u5c3e\u81ea\u6b63\u5219\u5316(HTSR)\u7684\u9891\u8c31\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ea4\u901a\u4e8b\u6545\u5206\u7c7b\u6a21\u578b\u7684\u8d28\u91cf\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5e42\u5f8b\u6307\u6570\u03b1\u6765\u533a\u5206\u6a21\u578b\u662f\u5426\u8fc7\u62df\u5408\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u826f\u597d\u7684\u6b63\u5219\u5316\u6a21\u578b\u901a\u5e38\u5177\u67092\u52304\u4e4b\u95f4\u7684\u03b1\u503c\uff0c\u800c\u8fc7\u62df\u5408\u6a21\u578b\u5219\u8868\u73b0\u51fa\u03b1<2\u6216\u9891\u8c31\u584c\u9677\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u03b1\u7684\u63d0\u524d\u505c\u6b62\u6807\u51c6\u548c\u6a21\u578b\u9009\u62e9\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u901a\u4e8b\u6545\u5206\u7c7b\u6a21\u578b\u8bc4\u4ef7\u6307\u6807\uff08\u5982\u51c6\u786e\u7387\u3001F1\u5206\u6570\u6216AUC\uff09\u65e0\u6cd5\u63ed\u793a\u6a21\u578b\u662f\u5426\u5b58\u5728\u9759\u9ed8\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u9891\u8c31\u8bca\u65ad\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u6df1\u5c42\u6b21\u7684\u6a21\u578b\u8d28\u91cf\u6d1e\u5bdf\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u968f\u673a\u77e9\u9635\u7406\u8bba(RMT)\u4e0e\u91cd\u5c3e\u81ea\u6b63\u5219\u5316(HTSR)\u7684\u65b9\u6cd5\u6784\u5efa\u4e86\u4e00\u4e2a\u9891\u8c31\u8bca\u65ad\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\u5e7f\u6cdb\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7c7b\u522b\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8eBERT/ALBERT/Qwen2.5\u7b49\u6743\u91cd\u77e9\u9635\u3001XGBoost/\u968f\u673a\u68ee\u6797\u7684\u6298\u5916\u589e\u91cf\u77e9\u9635\u3001\u903b\u8f91\u56de\u5f52\u7684\u7ecf\u9a8c\u6d77\u68ee\u77e9\u9635\u3001\u51b3\u7b56\u6811\u7684\u8bf1\u5bfc\u4eb2\u548c\u529b\u77e9\u9635\u4ee5\u53caKNN\u7684\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u3002\u901a\u8fc7\u5bf9\u7231\u8377\u534e\u5dde\u4ea4\u901a\u90e8\u63d0\u4f9b\u7684\u4e24\u4e2a\u4e8b\u6545\u5206\u7c7b\u4efb\u52a1\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5206\u6790\uff0c\u4f7f\u7528\u4e86\u7a00\u758fLanczos\u8fd1\u4f3c\u65b9\u6cd5\u786e\u4fdd\u4e86\u6846\u67b6\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u826f\u597d\u6b63\u5219\u5316\u7684\u6a21\u578b\u5176\u5e42\u5f8b\u6307\u6570\u03b1\u503c\u7a33\u5b9a\u4f4d\u4e8e2\u81f34\u4e4b\u95f4\uff08\u5e73\u57472.87\u00b10.34\uff09\uff0c\u800c\u8fc7\u62df\u5408\u6a21\u578b\u5219\u663e\u793a\u03b1<2\u6216\u51fa\u73b0\u9891\u8c31\u584c\u7f29\u73b0\u8c61\u3002\u6b64\u5916\uff0c\u5e42\u5f8b\u6307\u6570\u03b1\u4e0e\u4e13\u5bb6\u610f\u89c1\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u76f8\u5173\u6027\uff08Spearman \u03c1= 0.89, p < 0.001\uff09\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u03b1\u4e3a\u57fa\u7840\u7684\u65e9\u671f\u505c\u6b62\u51c6\u5219\u53ca\u9891\u8c31\u6a21\u578b\u9009\u62e9\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u9a8c\u8bc1F1\u5206\u6570\u57fa\u51c6\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u9891\u8c31\u8bca\u65ad\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u533a\u5206\u6b63\u5e38\u4e0e\u8fc7\u62df\u5408\u7684\u4ea4\u901a\u4e8b\u6545\u5206\u7c7b\u6a21\u578b\uff0c\u4e14\u901a\u8fc7\u5e42\u5f8b\u6307\u6570\u03b1\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u4e00\u81f4\u6027\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002\u8fd9\u4e3a\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2602.19531", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19531", "abs": "https://arxiv.org/abs/2602.19531", "authors": ["Dingyi Nie", "Yixing Wu", "C. -C. Jay Kuo"], "title": "A Statistical Approach for Modeling Irregular Multivariate Time Series with Missing Observations", "comment": "Accepted for publication in APSIPA Transactions on Signal and Information Processing", "summary": "Irregular multivariate time series with missing values present significant challenges for predictive modeling in domains such as healthcare. While deep learning approaches often focus on temporal interpolation or complex architectures to handle irregularities, we propose a simpler yet effective alternative: extracting time-agnostic summary statistics to eliminate the temporal axis. Our method computes four key features per variable-mean and standard deviation of observed values, as well as the mean and variability of changes between consecutive observations to create a fixed-dimensional representation. These features are then utilized with standard classifiers, such as logistic regression and XGBoost. Evaluated on four biomedical datasets (PhysioNet Challenge 2012, 2019, PAMAP2, and MIMIC-III), our approach achieves state-of-the-art performance, surpassing recent transformer and graph-based models by 0.5-1.7% in AUROC/AUPRC and 1.1-1.7% in accuracy/F1-score, while reducing computational complexity. Ablation studies demonstrate that feature extraction-not classifier choice-drives performance gains, and our summary statistics outperform raw/imputed input in most benchmarks. In particular, we identify scenarios where missing patterns themselves encode predictive signals, as in sepsis prediction (PhysioNet, 2019), where missing indicators alone can achieve 94.2% AUROC with XGBoost, only 1.6% lower than using original raw data as input. Our results challenge the necessity of complex temporal modeling when task objectives permit time-agnostic representations, providing an efficient and interpretable solution for irregular time series classification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u7b80\u5355\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u4e0e\u65f6\u95f4\u65e0\u5173\u7684\u7edf\u8ba1\u7279\u5f81\u6765\u6d88\u9664\u65f6\u95f4\u8f74\u7684\u5f71\u54cd\u3002\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u8f83\u4f4e\u3002", "motivation": "\u9488\u5bf9\u533b\u7597\u4fdd\u5065\u7b49\u9886\u57df\u4e2d\u5b58\u5728\u7f3a\u5931\u503c\u7684\u4e0d\u89c4\u5219\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7ed9\u9884\u6d4b\u5efa\u6a21\u5e26\u6765\u7684\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u5bfb\u627e\u4e00\u79cd\u6bd4\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u66f4\u7b80\u5355\u4f46\u540c\u6837\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u7684\u65b9\u6cd5\u662f\u4e3a\u6bcf\u4e2a\u53d8\u91cf\u8ba1\u7b97\u56db\u4e2a\u5173\u952e\u7279\u5f81\u2014\u2014\u89c2\u6d4b\u503c\u7684\u5747\u503c\u548c\u6807\u51c6\u5dee\u3001\u4ee5\u53ca\u8fde\u7eed\u89c2\u5bdf\u4e4b\u95f4\u53d8\u5316\u7684\u5747\u503c\u548c\u53ef\u53d8\u6027\uff0c\u4ee5\u6b64\u521b\u5efa\u4e00\u4e2a\u56fa\u5b9a\u7ef4\u5ea6\u7684\u8868\u793a\u3002\u8fd9\u4e9b\u7279\u5f81\u968f\u540e\u88ab\u7528\u4e8e\u6807\u51c6\u5206\u7c7b\u5668\u5982\u903b\u8f91\u56de\u5f52\u548cXGBoost\u4e2d\u3002", "result": "\u5728\u56db\u4e2a\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u8d85\u8d8a\u4e86\u6700\u8fd1\u7684transformer\u548c\u57fa\u4e8e\u56fe\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5728AUROC/AUPRC\u4e0a\u63d0\u9ad8\u4e860.5-1.7%\uff0c\u5728\u51c6\u786e\u7387/F1\u5206\u6570\u4e0a\u63d0\u9ad8\u4e861.1-1.7%\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u590d\u6742\u6027\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u5f52\u529f\u4e8e\u7279\u5f81\u63d0\u53d6\u800c\u975e\u5206\u7c7b\u5668\u7684\u9009\u62e9\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5f53\u4efb\u52a1\u76ee\u6807\u5141\u8bb8\u4f7f\u7528\u4e0e\u65f6\u95f4\u65e0\u5173\u7684\u8868\u793a\u65f6\u91c7\u7528\u590d\u6742\u65f6\u95f4\u5efa\u6a21\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u4e0d\u89c4\u5219\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6848\u3002"}}
{"id": "2602.19552", "categories": ["cs.LG", "cs.CC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.19552", "abs": "https://arxiv.org/abs/2602.19552", "authors": ["Kasper Green Larsen", "Markus Engelund Mathiasen", "Chirag Pabbaraju", "Clement Svendsen"], "title": "The Sample Complexity of Replicable Realizable PAC Learning", "comment": null, "summary": "In this paper, we consider the problem of replicable realizable PAC learning. We construct a particularly hard learning problem and show a sample complexity lower bound with a close to $(\\log|H|)^{3/2}$ dependence on the size of the hypothesis class $H$. Our proof uses several novel techniques and works by defining a particular Cayley graph associated with $H$ and analyzing a suitable random walk on this graph by examining the spectral properties of its adjacency matrix.\n  Furthermore, we show an almost matching upper bound for the lower bound instance, meaning if a stronger lower bound exists, one would have to consider a different instance of the problem.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53ef\u590d\u5236\u7684PAC\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u67d0\u4e00\u7279\u5b9a\u7684\u5b66\u4e60\u96be\u9898\u6784\u5efa\u4e86\u4e00\u4e2a\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u5e76\u4e14\u8fd9\u4e2a\u4e0b\u754c\u51e0\u4e4e\u4e0e\u5047\u8bbe\u7c7bH\u7684\u5927\u5c0f\u5448(\u02dclog|H|)^{3/2}\u7684\u5173\u7cfb\u3002\u540c\u65f6\uff0c\u8fd8\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8be5\u4e0b\u754c\u5b9e\u4f8b\uff0c\u5b58\u5728\u4e00\u4e2a\u51e0\u4e4e\u5339\u914d\u7684\u4e0a\u754c\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u63a2\u7d22PAC\u5b66\u4e60\u4e2d\u7684\u53ef\u590d\u5236\u6027\u95ee\u9898\uff0c\u5e76\u8bd5\u56fe\u901a\u8fc7\u6784\u9020\u7279\u522b\u56f0\u96be\u7684\u5b66\u4e60\u95ee\u9898\u6765\u53d1\u73b0\u6837\u672c\u590d\u6742\u5ea6\u7684\u4e0b\u754c\u3002", "method": "\u7814\u7a76\u8005\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4e0e\u5047\u8bbe\u7c7bH\u76f8\u5173\u7684\u7279\u5b9aCayley\u56fe\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u6b64\u56fe\u4e0a\u7684\u9002\u5f53\u968f\u673a\u6e38\u8d70\u4ee5\u53ca\u8003\u5bdf\u5176\u90bb\u63a5\u77e9\u9635\u7684\u8c31\u6027\u8d28\u6765\u8fdb\u884c\u8bc1\u660e\u3002", "result": "\u5f97\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8e\u6837\u672c\u590d\u6742\u5ea6\u7684\u8fd1\u4f3c\u4e0b\u754c\uff0c\u8be5\u4e0b\u754c\u5927\u7ea6\u662f(log|H|)^{3/2}\uff0c\u5e76\u4e14\u5c55\u793a\u4e86\u4e00\u4e2a\u4e0e\u6b64\u4e0b\u754c\u5b9e\u4f8b\u51e0\u4e4e\u5339\u914d\u7684\u4e0a\u754c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5728\u8003\u8651\u7ed9\u5b9a\u7684\u95ee\u9898\u5b9e\u4f8b\u65f6\uff0c\u5df2\u7ecf\u627e\u5230\u4e86\u51e0\u4e4e\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\u3002\u5982\u679c\u8981\u627e\u5230\u66f4\u5f3a\u7684\u4e0b\u754c\uff0c\u5219\u9700\u8981\u8003\u8651\u4e0d\u540c\u7684\u60c5\u5f62\u3002"}}
{"id": "2602.19582", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19582", "abs": "https://arxiv.org/abs/2602.19582", "authors": ["Shenghong He"], "title": "Advantage-based Temporal Attack in Reinforcement Learning", "comment": null, "summary": "Extensive research demonstrates that Deep Reinforcement Learning (DRL) models are susceptible to adversarially constructed inputs (i.e., adversarial examples), which can mislead the agent to take suboptimal or unsafe actions. Recent methods improve attack effectiveness by leveraging future rewards to guide adversarial perturbation generation over sequential time steps (i.e., reward-based attacks). However, these methods are unable to capture dependencies between different time steps in the perturbation generation process, resulting in a weak temporal correlation between the current perturbation and previous perturbations.In this paper, we propose a novel method called Advantage-based Adversarial Transformer (AAT), which can generate adversarial examples with stronger temporal correlations (i.e., time-correlated adversarial examples) to improve the attack performance. AAT employs a multi-scale causal self-attention (MSCSA) mechanism to dynamically capture dependencies between historical information from different time periods and the current state, thus enhancing the correlation between the current perturbation and the previous perturbation. Moreover, AAT introduces a weighted advantage mechanism, which quantifies the effectiveness of a perturbation in a given state and guides the generation process toward high-performance adversarial examples by sampling high-advantage regions. Extensive experiments demonstrate that the performance of AAT matches or surpasses mainstream adversarial attack baselines on Atari, DeepMind Control Suite and Google football tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u57fa\u4e8e\u4f18\u52bf\u7684\u5bf9\u6297\u6027\u53d8\u6362\u5668(AAT)\uff0c\u901a\u8fc7\u5f15\u5165\u591a\u5c3a\u5ea6\u56e0\u679c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u52a0\u6743\u4f18\u52bf\u673a\u5236\u6765\u751f\u6210\u5177\u6709\u66f4\u5f3a\u65f6\u95f4\u76f8\u5173\u6027\u7684\u5bf9\u6297\u6837\u672c\uff0c\u4ece\u800c\u63d0\u9ad8\u653b\u51fb\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660eAAT\u5728Atari\u3001DeepMind\u63a7\u5236\u5957\u4ef6\u548c\u8c37\u6b4c\u8db3\u7403\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u4e3b\u6d41\u5bf9\u6297\u653b\u51fb\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5956\u52b1\u7684\u653b\u51fb\u65b9\u6cd5\u5728\u751f\u6210\u5bf9\u6297\u6270\u52a8\u65f6\u65e0\u6cd5\u6355\u6349\u4e0d\u540c\u65f6\u95f4\u6b65\u9aa4\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u5f53\u524d\u6270\u52a8\u4e0e\u5148\u524d\u6270\u52a8\u4e4b\u95f4\u7684\u65f6\u95f4\u5173\u8054\u8f83\u5f31\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\uff0c\u7814\u7a76\u8005\u4eec\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u751f\u6210\u66f4\u5177\u6709\u65f6\u95f4\u76f8\u5173\u6027\u7684\u5bf9\u6297\u6837\u672c\u6765\u589e\u5f3a\u653b\u51fb\u6548\u679c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Advantage-based Adversarial Transformer (AAT) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u591a\u5c3a\u5ea6\u56e0\u679c\u81ea\u6ce8\u610f\u529b(MSCSA)\u673a\u5236\u52a8\u6001\u6355\u6349\u4e0d\u540c\u65f6\u671f\u7684\u5386\u53f2\u4fe1\u606f\u4e0e\u5f53\u524d\u72b6\u6001\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u4e86\u52a0\u6743\u4f18\u52bf\u673a\u5236\u6765\u91cf\u5316\u7ed9\u5b9a\u72b6\u6001\u4e0b\u6270\u52a8\u7684\u6709\u6548\u6027\uff0c\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\u671d\u5411\u9ad8\u6548\u76ca\u533a\u57df\u91c7\u6837\u4ee5\u4ea7\u751f\u9ad8\u6548\u5bf9\u6297\u6837\u672c\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cAAT \u5728 Atari \u6e38\u620f\u3001DeepMind \u63a7\u5236\u5957\u4ef6\u4ee5\u53ca Google \u8db3\u7403\u7b49\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u4e86\u4e0e\u4e3b\u6d41\u5bf9\u6297\u653b\u51fb\u57fa\u51c6\u76f8\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528MSCSA\u673a\u5236\u548c\u52a0\u6743\u4f18\u52bf\u673a\u5236\uff0cAAT\u80fd\u591f\u751f\u6210\u5177\u5907\u66f4\u5f3a\u65f6\u95f4\u76f8\u5173\u6027\u7684\u5bf9\u6297\u6837\u672c\uff0c\u4ece\u800c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5bf9\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u653b\u51fb\u6027\u80fd\u3002"}}
{"id": "2602.19610", "categories": ["cs.LG", "stat.CO", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19610", "abs": "https://arxiv.org/abs/2602.19610", "authors": ["Luigi Simeone"], "title": "Variational Inference for Bayesian MIDAS Regression", "comment": "27 pages, 11 figures", "summary": "We develop a Coordinate Ascent Variational Inference (CAVI) algorithm for Bayesian Mixed Data Sampling (MIDAS) regression with linear weight parameteri zations. The model separates impact coe cients from weighting function parameters through a normalization constraint, creating a bilinear structure that renders generic Hamiltonian Monte Carlo samplers unreliable while preserving conditional conju gacy exploitable by CAVI. Each variational update admits a closed-form solution: Gaussian for regression coe cients and weight parameters, Inverse-Gamma for the error variance. The algorithm propagates uncertainty across blocks through second moments, distinguishing it from naive plug-in approximations. In a Monte Carlo study spanning 21 data-generating con gurations with up to 50 predictors, CAVI produces posterior means nearly identical to a block Gibbs sampler benchmark while achieving speedups of 107x to 1,772x (Table 9). Generic automatic di eren tiation VI (ADVI), by contrast, produces bias 714 times larger while being orders of magnitude slower, con rming the value of model-speci c derivations. Weight function parameters maintain excellent calibration (coverage above 92%) across all con gurations. Impact coe cient credible intervals exhibit the underdispersion characteristic of mean- eld approximations, with coverage declining from 89% to 55% as the number of predictors grows a documented trade-o between speed and interval calibration that structured variational methods can address. An empirical application to realized volatility forecasting on S&P 500 daily returns con rms that CAVI and Gibbs sampling yield virtually identical point forecasts, with CAVI completing each monthly estimation in under 10 milliseconds.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u8d1d\u53f6\u65af\u6df7\u5408\u6570\u636e\u91c7\u6837\u56de\u5f52\u7684\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u7ebf\u6027\u6743\u91cd\u53c2\u6570\u5316\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f52\u4e00\u5316\u7ea6\u675f\u5206\u79bb\u5f71\u54cd\u7cfb\u6570\u548c\u6743\u91cd\u51fd\u6570\u53c2\u6570\uff0c\u5f62\u6210\u4e86\u4e00\u4e2a\u53cc\u7ebf\u6027\u7ed3\u6784\uff0c\u4f7f\u5f97\u901a\u7528\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5668\u53d8\u5f97\u4e0d\u53ef\u9760\uff0c\u4f46\u4fdd\u6301\u4e86CAVI\u53ef\u5229\u7528\u7684\u6761\u4ef6\u5171\u8f6d\u6027\u3002\u5728\u5305\u542b\u591a\u8fbe50\u4e2a\u9884\u6d4b\u53d8\u91cf\u768421\u79cd\u6570\u636e\u751f\u6210\u914d\u7f6e\u7684\u8499\u7279\u5361\u6d1b\u7814\u7a76\u4e2d\uff0c\u4e0e\u5757\u5409\u5e03\u65af\u91c7\u6837\u5668\u57fa\u51c6\u76f8\u6bd4\uff0cCAVI\u4ea7\u751f\u7684\u540e\u9a8c\u5747\u503c\u51e0\u4e4e\u76f8\u540c\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86107\u500d\u81f31,772\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0c\u5bf9S&P 500\u65e5\u6536\u76ca\u7387\u7684\u5b9e\u9645\u6ce2\u52a8\u7387\u9884\u6d4b\u5e94\u7528\u8868\u660e\uff0cCAVI\u4e0e\u5409\u5e03\u65af\u62bd\u6837\u4ea7\u751f\u7684\u70b9\u9884\u6d4b\u57fa\u672c\u76f8\u540c\uff0c\u800cCAVI\u6bcf\u6708\u4f30\u8ba1\u5b8c\u6210\u65f6\u95f4\u4e0d\u523010\u6beb\u79d2\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u7ebf\u6027\u6743\u91cd\u53c2\u6570\u5316\u7684\u8d1d\u53f6\u65af\u6df7\u5408\u6570\u636e\u91c7\u6837(MIDAS)\u56de\u5f52\u95ee\u9898\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5f53\u6a21\u578b\u5448\u73b0\u51fa\u53cc\u7ebf\u6027\u7ed3\u6784\u65f6\uff0c\u901a\u7528\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5668\u53d8\u5f97\u4e0d\u518d\u53ef\u9760\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u6761\u4ef6\u5171\u8f6d\u6027\u7684\u540c\u65f6\uff0c\u6709\u6548\u5730\u5bf9\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u4f30\u8ba1\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u8d1d\u53f6\u65afMIDAS\u56de\u5f52\u6a21\u578b\uff08\u5e26\u6709\u7ebf\u6027\u6743\u91cd\u53c2\u6570\u5316\uff09\u7684\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\u3002\u6b64\u65b9\u6cd5\u901a\u8fc7\u5f52\u4e00\u5316\u7ea6\u675f\u5c06\u5f71\u54cd\u7cfb\u6570\u4ece\u6743\u91cd\u51fd\u6570\u53c2\u6570\u4e2d\u5206\u79bb\u51fa\u6765\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u79cd\u867d\u7136\u5bf9\u4e8e\u901a\u7528\u54c8\u5bc6\u987f\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5668\u6765\u8bf4\u4e0d\u53ef\u9760\u4f46\u5374\u4fdd\u7559\u4e86\u53ef\u7528\u4e8eCAVI\u7684\u6761\u4ef6\u5171\u8f6d\u6027\u7684\u53cc\u7ebf\u6027\u7ed3\u6784\u3002\u6bcf\u4e00\u6b65\u53d8\u5206\u66f4\u65b0\u90fd\u5141\u8bb8\u95ed\u5f0f\u89e3\uff1a\u56de\u5f52\u7cfb\u6570\u548c\u6743\u91cd\u53c2\u6570\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u8bef\u5dee\u65b9\u5dee\u4e3a\u9006\u4f3d\u9a6c\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6d89\u53ca\u6700\u591a50\u4e2a\u9884\u6d4b\u53d8\u91cf\u768421\u79cd\u4e0d\u540c\u6570\u636e\u751f\u6210\u914d\u7f6e\u4e0b\uff0c\u6240\u63d0\u51fa\u7684CAVI\u7b97\u6cd5\u4e0e\u4f5c\u4e3a\u57fa\u51c6\u7684\u5757\u5409\u5e03\u65af\u91c7\u6837\u5668\u76f8\u6bd4\uff0c\u80fd\u591f\u4ea7\u751f\u8fd1\u4e4e\u76f8\u540c\u7684\u540e\u9a8c\u5747\u503c\u4f30\u8ba1\uff0c\u540c\u65f6\u901f\u5ea6\u63d0\u5347\u4e86107\u500d\u52301,772\u500d\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u901a\u7528\u81ea\u52a8\u5fae\u5206\u53d8\u5206\u63a8\u65ad(ADVI)\u65b9\u6cd5\u4e0d\u4ec5\u504f\u5dee\u66f4\u5927\uff0c\u800c\u4e14\u8ba1\u7b97\u6548\u7387\u663e\u8457\u8f83\u4f4e\u3002\u6b64\u5916\uff0c\u6743\u91cd\u51fd\u6570\u53c2\u6570\u5728\u6240\u6709\u914d\u7f6e\u4e0b\u90fd\u8868\u73b0\u51fa\u4f18\u79c0\u7684\u6821\u51c6\u5ea6\uff1b\u5c3d\u7ba1\u5f71\u54cd\u7cfb\u6570\u53ef\u4fe1\u533a\u95f4\u7684\u8986\u76d6\u8303\u56f4\u968f\u7740\u9884\u6d4b\u53d8\u91cf\u6570\u91cf\u589e\u52a0\u800c\u6709\u6240\u4e0b\u964d\uff0c\u4f46\u4ecd\u7136\u4f53\u73b0\u4e86\u901f\u5ea6\u4e0e\u533a\u95f4\u6821\u51c6\u4e4b\u95f4\u7684\u4e00\u79cd\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u9488\u5bf9\u8d1d\u53f6\u65afMIDAS\u56de\u5f52\u6a21\u578b\u63d0\u51fa\u7684\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u5927\u5927\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u5b83\u4e0d\u4ec5\u80fd\u591f\u5feb\u901f\u51c6\u786e\u5730\u4f30\u8ba1\u51fa\u6a21\u578b\u53c2\u6570\uff0c\u800c\u4e14\u5728\u5b9e\u9645\u5e94\u7528\u5982S&P 500\u65e5\u6536\u76ca\u6ce2\u52a8\u7387\u9884\u6d4b\u4e0a\u4e5f\u8868\u73b0\u51fa\u4e86\u4f18\u5f02\u6027\u80fd\u3002\u8fd9\u8868\u660e\uff0c\u5bf9\u4e8e\u9700\u8981\u9ad8\u6548\u5904\u7406\u5927\u91cf\u6570\u636e\u5e76\u8981\u6c42\u5b9e\u65f6\u54cd\u5e94\u7684\u5e94\u7528\u573a\u666f\u800c\u8a00\uff0cCAVI\u662f\u4e00\u4e2a\u6781\u5177\u6f5c\u529b\u7684\u9009\u62e9\u3002"}}
{"id": "2602.19619", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19619", "abs": "https://arxiv.org/abs/2602.19619", "authors": ["Luhan Tang", "Longxuan Yu", "Shaorong Zhang", "Greg Ver Steeg"], "title": "Is Your Diffusion Sampler Actually Correct? A Sampler-Centric Evaluation of Discrete Diffusion Language Models", "comment": "28 pages, 9 figures", "summary": "Discrete diffusion language models (dLLMs) provide a fast and flexible alternative to autoregressive models (ARMs) via iterative denoising with parallel updates. However, their evaluation is challenging: existing metrics conflate denoiser approximation error with sampler-induced error from the sampling dynamics, a problem that does not arise for ARMs whose autoregressive sampling exactly reflects the learned probability model. We introduce a sampler-centric oracle framework that replaces learned denoisers with an exact Hidden Markov Model posterior derived from a ground-truth Markov chain, isolating sampler-induced error in a controlled setting. We show that few-step discrete diffusion samplers are not distributionally correct even under an oracle denoiser, with transition-level mismatch that vanishes only as the number of steps approaches the sequence length. Moreover, improvements in negative log-likelihood, generative perplexity, or MAUVE do not imply correct sampling. Code is available at https://luhantang.github.io/dllm_sampler", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u5668\u4e3a\u6838\u5fc3\u7684oracle\u6846\u67b6\uff0c\u7528\u4ee5\u89e3\u51b3\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u8bc4\u4f30\u65f6\u9047\u5230\u7684\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u5b66\u4e60\u5230\u7684\u53bb\u566a\u5668\u66ff\u6362\u4e3a\u4ece\u771f\u5b9e\u9a6c\u5c14\u53ef\u592b\u94fe\u5bfc\u51fa\u7684\u786e\u5207\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u540e\u9a8c\uff0c\u4ece\u800c\u9694\u79bb\u4e86\u7531\u4e8e\u91c7\u6837\u52a8\u6001\u5f15\u8d77\u7684\u8bef\u5dee\u3002\u7814\u7a76\u53d1\u73b0\u5373\u4f7f\u5728oracle\u53bb\u566a\u5668\u4e0b\uff0c\u5c11\u6570\u6b65\u9aa4\u7684\u79bb\u6563\u6269\u6563\u91c7\u6837\u5668\u4e5f\u4e0d\u662f\u5206\u5e03\u6b63\u786e\u7684\uff0c\u5e76\u4e14\u8d1f\u5bf9\u6570\u4f3c\u7136\u3001\u751f\u6210\u56f0\u60d1\u5ea6\u6216MAUVE\u7b49\u6307\u6807\u7684\u6539\u8fdb\u5e76\u4e0d\u610f\u5473\u7740\u6b63\u786e\u7684\u91c7\u6837\u3002", "motivation": "\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u7075\u6d3b\u7684\u65b9\u5f0f\u6765\u66ff\u4ee3\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\uff0c\u4f46\u5b83\u4eec\u7684\u8bc4\u4f30\u9762\u4e34\u6311\u6218\uff1a\u73b0\u6709\u6307\u6807\u6df7\u6dc6\u4e86\u53bb\u566a\u5668\u8fd1\u4f3c\u8bef\u5dee\u4e0e\u7531\u91c7\u6837\u52a8\u6001\u5f15\u8d77\u7684\u8bef\u5dee\u3002\u800c\u8fd9\u4e2a\u95ee\u9898\u5728\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u4e0d\u4f1a\u51fa\u73b0\uff0c\u56e0\u4e3a\u5176\u81ea\u56de\u5f52\u91c7\u6837\u7cbe\u786e\u53cd\u6620\u4e86\u6240\u5b66\u7684\u6982\u7387\u6a21\u578b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u91c7\u6837\u5668\u4e3a\u6838\u5fc3\u7684oracle\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u4ece\u771f\u5b9e\u9a6c\u5c14\u53ef\u592b\u94fe\u5f97\u51fa\u7684\u786e\u5207\u9690\u85cf\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u540e\u9a8c\u6765\u4ee3\u66ff\u5b66\u4e60\u5230\u7684\u53bb\u566a\u5668\uff0c\u4ece\u800c\u80fd\u591f\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u5355\u72ec\u8003\u5bdf\u7531\u91c7\u6837\u8fc7\u7a0b\u5f15\u53d1\u7684\u8bef\u5dee\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728oracle\u53bb\u566a\u5668\u4e0b\uff0c\u53ea\u6709\u5f53\u6b65\u6570\u63a5\u8fd1\u5e8f\u5217\u957f\u5ea6\u65f6\uff0c\u5c11\u6570\u51e0\u6b65\u7684\u79bb\u6563\u6269\u6563\u91c7\u6837\u5668\u624d\u4e0d\u4f1a\u8868\u73b0\u51fa\u8f6c\u6362\u7ea7\u522b\u7684\u4e0d\u5339\u914d\u73b0\u8c61\uff1b\u6b64\u5916\uff0c\u8bf8\u5982\u8d1f\u5bf9\u6570\u4f3c\u7136\u3001\u751f\u6210\u56f0\u60d1\u5ea6\u6216\u8005MAUVE\u7b49\u8bc4\u4ef7\u6807\u51c6\u7684\u6539\u5584\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u91c7\u6837\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u2014\u2014\u5373\u5373\u4f7f\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\uff0c\u5c11\u91cf\u8fed\u4ee3\u6b21\u6570\u4e0b\u7684\u91c7\u6837\u7ed3\u679c\u4e5f\u672a\u5fc5\u80fd\u591f\u51c6\u786e\u53cd\u6620\u76ee\u6807\u5206\u5e03\u3002\u8fd9\u8868\u660e\u5f53\u524d\u5e38\u7528\u7684\u6027\u80fd\u6307\u6807\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5168\u9762\u8861\u91cf\u6b64\u7c7b\u6a21\u578b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.19622", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19622", "abs": "https://arxiv.org/abs/2602.19622", "authors": ["Jingbo Zhou", "Jun Xia", "Siyuan Li", "Yunfan Liu", "Wenjun Wang", "Yufei Huang", "Changxi Chi", "Mutian Hong", "Zhuoli Ouyang", "Shu Wang", "Zhongqi Wang", "Xingyu Wu", "Chang Yu", "Stan Z. Li"], "title": "VecFormer: Towards Efficient and Generalizable Graph Transformer with Graph Token Attention", "comment": null, "summary": "Graph Transformer has demonstrated impressive capabilities in the field of graph representation learning. However, existing approaches face two critical challenges: (1) most models suffer from exponentially increasing computational complexity, making it difficult to scale to large graphs; (2) attention mechanisms based on node-level operations limit the flexibility of the model and result in poor generalization performance in out-of-distribution (OOD) scenarios. To address these issues, we propose \\textbf{VecFormer} (the \\textbf{Vec}tor Quantized Graph Trans\\textbf{former}), an efficient and highly generalizable model for node classification, particularly under OOD settings. VecFormer adopts a two-stage training paradigm. In the first stage, two codebooks are used to reconstruct the node features and the graph structure, aiming to learn the rich semantic \\texttt{Graph Codes}. In the second stage, attention mechanisms are performed at the \\texttt{Graph Token} level based on the transformed cross codebook, reducing computational complexity while enhancing the model's generalization capability. Extensive experiments on datasets of various sizes demonstrate that VecFormer outperforms the existing Graph Transformer in both performance and speed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVecFormer\u7684\u65b0\u6a21\u578b\uff0c\u5b83\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u53d8\u6362\u5668\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u4ee5\u53ca\u6cdb\u5316\u6027\u80fd\u5dee\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cVecFormer\u5728\u6027\u80fd\u548c\u901f\u5ea6\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u7684\u56fe\u53d8\u6362\u5668\u3002", "motivation": "\u76ee\u524d\u7684\u56fe\u53d8\u6362\u5668\u65b9\u6cd5\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u4e00\u662f\u5927\u591a\u6570\u6a21\u578b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5448\u6307\u6570\u589e\u957f\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u578b\u56fe\uff1b\u4e8c\u662f\u57fa\u4e8e\u8282\u70b9\u7ea7\u522b\u64cd\u4f5c\u7684\u6ce8\u610f\u529b\u673a\u5236\u9650\u5236\u4e86\u6a21\u578b\u7075\u6d3b\u6027\uff0c\u5e76\u5bfc\u81f4\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u8f83\u5dee\u3002", "method": "\u63d0\u51fa\u4e86VecFormer\uff08\u5411\u91cf\u91cf\u5316\u56fe\u53d8\u6362\u5668\uff09\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u4e24\u4e2a\u7801\u672c\u6765\u91cd\u5efa\u8282\u70b9\u7279\u5f81\u4e0e\u56fe\u7ed3\u6784\uff0c\u5b66\u4e60\u4e30\u5bcc\u7684\u8bed\u4e49Graph Codes\u3002\u7b2c\u4e8c\u9636\u6bb5\u5219\u57fa\u4e8e\u8f6c\u6362\u540e\u7684\u8de8\u7801\u672c\u5728Graph Token\u5c42\u9762\u6267\u884c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6570\u636e\u96c6\u4e0a\uff0cVecFormer\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u56fe\u53d8\u6362\u5668\u5728\u6027\u80fd\u548c\u5904\u7406\u901f\u5ea6\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "VecFormer\u4e3a\u89e3\u51b3\u56fe\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728OOD\u8bbe\u7f6e\u4e0b\u7684\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2602.19634", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19634", "abs": "https://arxiv.org/abs/2602.19634", "authors": ["Jesse Farebrother", "Matteo Pirotta", "Andrea Tirinzoni", "Marc G. Bellemare", "Alessandro Lazaric", "Ahmed Touati"], "title": "Compositional Planning with Jumpy World Models", "comment": null, "summary": "The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone can solve. Such compositional planning remains elusive as compounding errors in long-horizon predictions make it challenging to estimate the visitation distribution induced by sequencing policies. Motivated by the geometric policy composition framework introduced in arXiv:2206.08736, we address these challenges by learning predictive models of multi-step dynamics -- so-called jumpy world models -- that capture state occupancies induced by pre-trained policies across multiple timescales in an off-policy manner. Building on Temporal Difference Flows (arXiv:2503.09817), we enhance these models with a novel consistency objective that aligns predictions across timescales, improving long-horizon predictive accuracy. We further demonstrate how to combine these generative predictions to estimate the value of executing arbitrary sequences of policies over varying timescales. Empirically, we find that compositional planning with jumpy world models significantly improves zero-shot performance across a wide range of base policies on challenging manipulation and navigation tasks, yielding, on average, a 200% relative improvement over planning with primitive actions on long-horizon tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8df3\u8dc3\u4e16\u754c\u6a21\u578b\u7684\u7ec4\u5408\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u591a\u6b65\u52a8\u6001\u9884\u6d4b\u6a21\u578b\u6765\u63d0\u9ad8\u957f\u65f6\u95f4\u8303\u56f4\u4efb\u52a1\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u5728\u591a\u79cd\u57fa\u7840\u7b56\u7565\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u4f18\u4e8e\u539f\u59cb\u52a8\u4f5c\u89c4\u5212\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7ec4\u5408\u89c4\u5212\u4e2d\u957f\u65f6\u5e8f\u9884\u6d4b\u8bef\u5dee\u7d2f\u79ef\u5bfc\u81f4\u96be\u4ee5\u4f30\u8ba1\u7531\u5e8f\u5217\u5316\u7b56\u7565\u5f15\u8d77\u7684\u8bbf\u95ee\u5206\u5e03\u7684\u95ee\u9898\uff0c\u53d7\u51e0\u4f55\u7b56\u7565\u7ec4\u5408\u6846\u67b6\u542f\u53d1\uff0c\u7814\u7a76\u8005\u4eec\u81f4\u529b\u4e8e\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6355\u6349\u72b6\u6001\u5360\u636e\u60c5\u51b5\u7684\u8df3\u8dc3\u4e16\u754c\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5b66\u4e60\u591a\u6b65\u52a8\u6001\u9884\u6d4b\u6a21\u578b\uff08\u8df3\u8dc3\u4e16\u754c\u6a21\u578b\uff09\uff0c\u8be5\u6a21\u578b\u80fd\u5728\u975e\u7b56\u7565\u65b9\u5f0f\u4e0b\u6355\u6349\u9884\u8bad\u7ec3\u7b56\u7565\u5728\u591a\u4e2a\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u72b6\u6001\u5360\u636e\u60c5\u51b5\uff1b\u5e76\u7ed3\u5408TD\u6d41\u63d0\u51fa\u4e86\u65b0\u7684\u8de8\u65f6\u95f4\u5c3a\u5ea6\u4e00\u81f4\u6027\u76ee\u6807\u51fd\u6570\u4ee5\u63d0\u9ad8\u957f\u65f6\u95f4\u9884\u6d4b\u7cbe\u5ea6\u3002\u6b64\u5916\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u751f\u6210\u6027\u9884\u6d4b\u6765\u8bc4\u4f30\u6267\u884c\u4efb\u610f\u7b56\u7565\u5e8f\u5217\u7684\u4ef7\u503c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u64cd\u4f5c\u548c\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u8df3\u8dc3\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u7ec4\u5408\u89c4\u5212\u76f8\u6bd4\u57fa\u4e8e\u539f\u59cb\u52a8\u4f5c\u7684\u89c4\u5212\u5e73\u5747\u63d0\u9ad8\u4e86200%\u7684\u76f8\u5bf9\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8df3\u8dc3\u4e16\u754c\u6a21\u578b\u548c\u76f8\u5e94\u7684\u7ec4\u5408\u89c4\u5212\u65b9\u6cd5\u4e3a\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u957f\u671f\u51b3\u7b56\u7684\u60c5\u5883\u4e0b\u5c55\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.19641", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19641", "abs": "https://arxiv.org/abs/2602.19641", "authors": ["Marvin Chen", "Manuel Eberhardinger", "Johannes Maucher"], "title": "Evaluating the Impact of Data Anonymization on Image Retrieval", "comment": "Submitted to IEEE Access", "summary": "With the growing importance of privacy regulations such as the General Data Protection Regulation, anonymizing visual data is becoming increasingly relevant across institutions. However, anonymization can negatively affect the performance of Computer Vision systems that rely on visual features, such as Content-Based Image Retrieval (CBIR). Despite this, the impact of anonymization on CBIR has not been systematically studied. This work addresses this gap, motivated by the DOKIQ project, an artificial intelligence-based system for document verification actively used by the State Criminal Police Office Baden-W\u00fcrttemberg. We propose a simple evaluation framework: retrieval results after anonymization should match those obtained before anonymization as closely as possible. To this end, we systematically assess the impact of anonymization using two public datasets and the internal DOKIQ dataset. Our experiments span three anonymization methods, four anonymization degrees, and four training strategies, all based on the state of the art backbone Self-Distillation with No Labels (DINO)v2. Our results reveal a pronounced retrieval bias in favor of models trained on original data, which produce the most similar retrievals after anonymization. The findings of this paper offer practical insights for developing privacy-compliant CBIR systems while preserving performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u533f\u540d\u5316\u5bf9\u57fa\u4e8e\u5185\u5bb9\u7684\u56fe\u50cf\u68c0\u7d22\uff08CBIR\uff09\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\u6765\u6bd4\u8f83\u533f\u540d\u5316\u524d\u540e\u68c0\u7d22\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u6db5\u76d6\u4e86\u4e09\u79cd\u533f\u540d\u5316\u65b9\u6cd5\u3001\u56db\u4e2a\u533f\u540d\u5316\u7a0b\u5ea6\u548c\u56db\u79cd\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u63ed\u793a\u4e86\u4f7f\u7528\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u533f\u540d\u5316\u540e\u4ecd\u80fd\u4ea7\u751f\u6700\u76f8\u4f3c\u7684\u68c0\u7d22\u7ed3\u679c\uff0c\u4e3a\u5f00\u53d1\u65e2\u7b26\u5408\u9690\u79c1\u89c4\u5b9a\u53c8\u80fd\u4fdd\u6301\u6027\u80fd\u7684CBIR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "motivation": "\u968f\u7740GDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u89c6\u89c9\u6570\u636e\u7684\u533f\u540d\u5316\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u5176\u53ef\u80fd\u5bf9\u4f9d\u8d56\u4e8e\u89c6\u89c9\u7279\u5f81\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u7cfb\u7edf\u5982CBIR\u9020\u6210\u8d1f\u9762\u5f71\u54cd\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u533f\u540d\u5316\u5982\u4f55\u5f71\u54cdCBIR\u7684\u7814\u7a76\u8fd8\u4e0d\u5145\u5206\u3002\u53d7DOKIQ\u9879\u76ee\u542f\u53d1\uff0c\u8be5\u9879\u76ee\u662f\u5df4\u767b-\u7b26\u817e\u5821\u5dde\u5211\u4e8b\u8b66\u5bdf\u5c40\u79ef\u6781\u4f7f\u7528\u7684\u4e00\u4e2a\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6587\u4ef6\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5373\u533f\u540d\u5316\u540e\u7684\u68c0\u7d22\u7ed3\u679c\u5e94\u8be5\u5c3d\u53ef\u80fd\u63a5\u8fd1\u533f\u540d\u5316\u524d\u7684\u7ed3\u679c\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u4e24\u79cd\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u53ca\u5185\u90e8DOKIQ\u6570\u636e\u96c6\u4e2d\u533f\u540d\u5316\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u5305\u62ec\u4e86\u4e09\u79cd\u533f\u540d\u5316\u65b9\u6cd5\u3001\u56db\u4e2a\u533f\u540d\u5316\u7a0b\u5ea6\u7ea7\u522b\u3001\u4ee5\u53ca\u57fa\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u81ea\u84b8\u998f\u65e0\u6807\u7b7e\u6280\u672f(DINO)v2\u7684\u56db\u79cd\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u663e\u793a\u51fa\u660e\u663e\u7684\u68c0\u7d22\u504f\u597d\uff0c\u5728\u7ecf\u8fc7\u533f\u540d\u5316\u5904\u7406\u540e\u80fd\u591f\u4ea7\u751f\u6700\u4e3a\u76f8\u4f3c\u7684\u68c0\u7d22\u7ed3\u679c\u3002\u8fd9\u610f\u5473\u7740\u5373\u4f7f\u662f\u5728\u6570\u636e\u88ab\u533f\u540d\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4ecd\u7136\u80fd\u591f\u8f83\u597d\u5730\u7ef4\u6301\u5176\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u7814\u7a76\u53d1\u73b0\u4e3a\u5f00\u53d1\u65e2\u80fd\u9075\u5b88\u9690\u79c1\u5408\u89c4\u8981\u6c42\u53c8\u53ef\u6709\u6548\u4fdd\u6301\u68c0\u7d22\u6027\u80fd\u7684CBIR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u5b9e\u8df5\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.19644", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.19644", "abs": "https://arxiv.org/abs/2602.19644", "authors": ["Pablo Herrero G\u00f3mez", "Antonio Jimeno Morenilla", "David Mu\u00f1oz-Hern\u00e1ndez", "Higinio Mora Mora"], "title": "Spectral Phase Encoding for Quantum Kernel Methods", "comment": null, "summary": "Quantum kernel methods are promising for near-term quantum ma- chine learning, yet their behavior under data corruption remains insuf- ficiently understood. We analyze how quantum feature constructions degrade under controlled additive noise. We introduce Spectral Phase Encoding (SPE), a hybrid construc- tion combining a discrete Fourier transform (DFT) front-end with a diagonal phase-only embedding aligned with the geometry of diagonal quantum maps. Within a unified framework, we compare QK-DFT against alternative quantum variants (QK-PCA, QK-RP) and classi- cal SVM baselines under identical clean-data hyperparameter selection, quantifying robustness via dataset fixed-effects regression with wild cluster bootstrap inference across heterogeneous real-world datasets. Across the quantum family, DFT-based preprocessing yields the smallest degradation rate as noise increases, with statistically sup- ported slope differences relative to PCA and RP. Compared to classical baselines, QK-DFT shows degradation comparable to linear SVM and more stable than RBF SVM under matched tuning. Hardware exper- iments confirm that SPE remains executable and numerically stable for overlap estimation. These results indicate that robustness in quan- tum kernels depends critically on structure-aligned preprocessing and its interaction with diagonal embeddings, supporting a robustness-first perspective for NISQ-era quantum machine learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u91cf\u5b50\u6838\u65b9\u6cd5\u5728\u53d7\u63a7\u52a0\u6027\u566a\u58f0\u4e0b\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7279\u5f81\u6784\u5efa\u65b9\u6cd5SPE\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8eDFT\u7684\u9884\u5904\u7406\u5728\u566a\u58f0\u589e\u52a0\u65f6\u5177\u6709\u6700\u5c0f\u7684\u9000\u5316\u7387\uff0c\u4e14\u4e0e\u7ecf\u5178\u57fa\u7ebf\u76f8\u6bd4\u8868\u73b0\u51fa\u4e86\u53ef\u6bd4\u6216\u66f4\u7a33\u5b9a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u91cf\u5b50\u6838\u65b9\u6cd5\u4f5c\u4e3a\u8fd1\u671f\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4f46\u5176\u5728\u6570\u636e\u635f\u574f\u60c5\u51b5\u4e0b\u7684\u884c\u4e3a\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\u3002", "method": "\u5f15\u5165\u4e86SPE\uff08\u8c31\u76f8\u4f4d\u7f16\u7801\uff09\uff0c\u4e00\u79cd\u7ed3\u5408\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u524d\u7aef\u548c\u5bf9\u89d2\u76f8\u4f4d\u5d4c\u5165\u7684\u65b9\u6cd5\uff1b\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u5bf9\u6bd4\u4e86QK-DFT\u4e0e\u5176\u4ed6\u91cf\u5b50\u53d8\u4f53\u53ca\u7ecf\u5178SVM\u57fa\u7ebf\u5728\u76f8\u540c\u6e05\u6d01\u6570\u636e\u8d85\u53c2\u6570\u9009\u62e9\u4e0b\u7684\u6027\u80fd\uff1b\u91c7\u7528\u56fa\u5b9a\u6548\u5e94\u56de\u5f52\u548c\u91ce\u7fa4\u96c6\u81ea\u52a9\u6cd5\u6765\u91cf\u5316\u8de8\u5f02\u6784\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6240\u6709\u91cf\u5b50\u65b9\u6cd5\u4e2d\uff0c\u57fa\u4e8eDFT\u7684\u9884\u5904\u7406\u968f\u7740\u566a\u58f0\u589e\u52a0\u8868\u73b0\u51fa\u6700\u5c0f\u7684\u9000\u5316\u7387\uff0c\u4e14\u76f8\u5bf9\u4e8ePCA\u548cRP\u6709\u7edf\u8ba1\u5b66\u652f\u6301\u7684\u659c\u7387\u5dee\u5f02\uff1b\u4e0e\u7ecf\u5178\u57fa\u7ebf\u76f8\u6bd4\uff0cQK-DFT\u7684\u9000\u5316\u7a0b\u5ea6\u4e0e\u7ebf\u6027SVM\u76f8\u5f53\uff0c\u4f46\u6bd4RBF SVM\u66f4\u4e3a\u7a33\u5b9a\u3002\u786c\u4ef6\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86SPE\u5728\u91cd\u53e0\u4f30\u8ba1\u4e2d\u7684\u6267\u884c\u6027\u548c\u6570\u503c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u91cf\u5b50\u6838\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u7ed3\u6784\u5bf9\u9f50\u7684\u9884\u5904\u7406\u53ca\u5176\u4e0e\u5bf9\u89d2\u5d4c\u5165\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u8fd9\u4e3aNISQ\u65f6\u4ee3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ee5\u9c81\u68d2\u6027\u4e3a\u5148\u7684\u89c2\u70b9\u3002"}}
{"id": "2602.19654", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19654", "abs": "https://arxiv.org/abs/2602.19654", "authors": ["Rampunit Kumar", "Aditya Maheshwari"], "title": "NEXUS : A compact neural architecture for high-resolution spatiotemporal air quality forecasting in Delhi Nationa Capital Region", "comment": "18 pages", "summary": "Urban air pollution in megacities poses critical public health challenges, particularly in Delhi National Capital Region (NCR) where severe degradation affects millions. We present NEXUS (Neural Extraction and Unified Spatiotemporal) architecture for forecasting carbon monoxide, nitrogen oxide, and sulfur dioxide. Working with four years (2018--2021) of atmospheric data across sixteen spatial grids, NEXUS achieves R$^2$ exceeding 0.94 for CO, 0.91 for NO, and 0.95 for SO$_2$ using merely 18,748 parameters -- substantially fewer than SCINet (35,552), Autoformer (68,704), and FEDformer (298,080). The architecture integrates patch embedding, low-rank projections, and adaptive fusion mechanisms to decode complex atmospheric chemistry patterns. Our investigation uncovers distinct diurnal rhythms and pronounced seasonal variations, with winter months experiencing severe pollution episodes driven by temperature inversions and agricultural biomass burning. Analysis identifies critical meteorological thresholds, quantifies wind field impacts on pollutant dispersion, and maps spatial heterogeneity across the region. Extensive ablation experiments demonstrate each architectural component's role. NEXUS delivers superior predictive performance with remarkable computational efficiency, enabling real-time deployment for air quality monitoring systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNEXUS\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u9884\u6d4b\u5fb7\u91cc\u56fd\u5bb6\u9996\u90fd\u533a\u7684\u4e8c\u6c27\u5316\u78b3\u3001\u6c2e\u6c27\u5316\u7269\u548c\u4e8c\u6c27\u5316\u786b\u3002\u8be5\u67b6\u6784\u4f7f\u7528\u4e86\u56db\u5e74\u7684\u5927\u6c14\u6570\u636e\uff0c\u5728\u53c2\u6570\u91cf\u8fdc\u5c11\u4e8e\u5176\u4ed6\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u9884\u6d4b\uff0c\u5e76\u80fd\u591f\u5b9e\u65f6\u90e8\u7f72\u7528\u4e8e\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u7cfb\u7edf\u3002", "motivation": "\u57ce\u5e02\u7a7a\u6c14\u6c61\u67d3\u5bf9\u516c\u4f17\u5065\u5eb7\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5fb7\u91cc\u56fd\u5bb6\u9996\u90fd\u533a\u8fd9\u6837\u7684\u5927\u90fd\u5e02\u4e2d\u5f71\u54cd\u7740\u6570\u767e\u4e07\u4eba\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86NEXUS\u67b6\u6784\u6765\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u4e3b\u8981\u6c61\u67d3\u7269\u6c34\u5e73\u3002", "method": "NEXUS\u67b6\u6784\u96c6\u6210\u4e86\u5757\u5d4c\u5165\u3001\u4f4e\u79e9\u6295\u5f71\u548c\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\uff0c\u4ee5\u89e3\u7801\u590d\u6742\u7684\u5927\u6c14\u5316\u5b66\u6a21\u5f0f\u3002\u5b83\u57fa\u4e8e2018\u5e74\u81f32021\u5e74\u95f4\u6765\u81ea\u5341\u516d\u4e2a\u7a7a\u95f4\u7f51\u683c\u7684\u6570\u636e\u8fdb\u884c\u5de5\u4f5c\u3002", "result": "NEXUS\u5bf9\u4e8eCO\u3001NO\u548cSO2\u7684R^2\u503c\u5206\u522b\u8d85\u8fc7\u4e860.94\u30010.91\u548c0.95\uff0c\u4e14\u4f7f\u7528\u7684\u53c2\u6570\u6570\u91cf\u663e\u8457\u5c11\u4e8eSCINet\u3001Autoformer\u548cFEDformer\u7b49\u73b0\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u660e\u663e\u7684\u663c\u591c\u8282\u5f8b\u4e0e\u5b63\u8282\u6027\u53d8\u5316\u89c4\u5f8b\u3002", "conclusion": "NEXUS\u4e0d\u4ec5\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u5177\u6709\u5f88\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u5230\u7a7a\u6c14\u8d28\u91cf\u76d1\u63a7\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2602.19661", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19661", "abs": "https://arxiv.org/abs/2602.19661", "authors": ["Kihyuk Yoon", "Lingchao Mao", "Catherine Chong", "Todd J. Schwedt", "Chia-Chun Chiang", "Jing Li"], "title": "PaReGTA: An LLM-based EHR Data Encoding Approach to Capture Temporal Information", "comment": "26 pages, 5 figures, 7 tables", "summary": "Temporal information in structured electronic health records (EHRs) is often lost in sparse one-hot or count-based representations, while sequence models can be costly and data-hungry. We propose PaReGTA, an LLM-based encoding framework that (i) converts longitudinal EHR events into visit-level templated text with explicit temporal cues, (ii) learns domain-adapted visit embeddings via lightweight contrastive fine-tuning of a sentence-embedding model, and (iii) aggregates visit embeddings into a fixed-dimensional patient representation using hybrid temporal pooling that captures both recency and globally informative visits. Because PaReGTA does not require training from scratch but instead utilizes a pre-trained LLM, it can perform well even in data-limited cohorts. Furthermore, PaReGTA is model-agnostic and can benefit from future EHR-specialized sentence-embedding models. For interpretability, we introduce PaReGTA-RSS (Representation Shift Score), which quantifies clinically defined factor importance by recomputing representations after targeted factor removal and projecting representation shifts through a machine learning model. On 39,088 migraine patients from the All of Us Research Program, PaReGTA outperforms sparse baselines for migraine type classification while deep sequential models were unstable in our cohort.", "AI": {"tldr": "\u63d0\u51fa\u4e86PaReGTA\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f16\u7801\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u4e2d\u7684\u65f6\u95f4\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u7eb5\u5411EHR\u4e8b\u4ef6\u8f6c\u6362\u4e3a\u5e26\u6709\u660e\u786e\u65f6\u95f4\u7ebf\u7d22\u7684\u8bbf\u95ee\u7ea7\u522b\u6a21\u677f\u6587\u672c\u3001\u5b66\u4e60\u9886\u57df\u9002\u5e94\u7684\u8bbf\u95ee\u5d4c\u5165\u4ee5\u53ca\u4f7f\u7528\u6df7\u5408\u65f6\u95f4\u6c60\u5316\u6765\u6c47\u603b\u60a3\u8005\u8868\u793a\uff0c\u4ee5\u4fdd\u7559\u548c\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u3002\u6b64\u5916\uff0cPaReGTA\u4e0d\u9700\u8981\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u672a\u6765\u4e13\u95e8\u9488\u5bf9EHR\u7684\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u517c\u5bb9\u3002\u572839,088\u540d\u504f\u5934\u75db\u60a3\u8005\u7684\u6d4b\u8bd5\u4e2d\uff0cPaReGTA\u5728\u504f\u5934\u75db\u7c7b\u578b\u5206\u7c7b\u4e0a\u4f18\u4e8e\u7a00\u758f\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684EHRs\u8868\u793a\u65b9\u6cd5\u8981\u4e48\u4e22\u5931\u4e86\u91cd\u8981\u7684\u65f6\u95f4\u4fe1\u606f\uff08\u5982one-hot\u6216\u8ba1\u6570\u4e3a\u57fa\u7840\u7684\u8868\u793a\uff09\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff08\u5982\u5e8f\u5217\u6a21\u578b\uff09\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u65e2\u80fd\u6709\u6548\u5730\u5229\u7528\u65f6\u95f4\u4fe1\u606f\uff0c\u53c8\u80fd\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\u3002", "method": "PaReGTA\u91c7\u7528\u4ee5\u4e0b\u6b65\u9aa4\uff1a1. \u5c06\u7eb5\u5411EHR\u4e8b\u4ef6\u8f6c\u6362\u4e3a\u542b\u6709\u660e\u786e\u65f6\u95f4\u63d0\u793a\u7684\u8bbf\u95ee\u7ea7\u6a21\u677f\u6587\u672c\uff1b2. \u901a\u8fc7\u5bf9\u9884\u8bad\u7ec3\u7684\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5bf9\u6bd4\u5fae\u8c03\u6765\u5b66\u4e60\u9886\u57df\u81ea\u9002\u5e94\u7684\u8bbf\u95ee\u5d4c\u5165\uff1b3. \u5229\u7528\u7ed3\u5408\u8fd1\u671f\u6027\u548c\u5168\u5c40\u4fe1\u606f\u6027\u7684\u6df7\u5408\u65f6\u95f4\u6c60\u5316\u6280\u672f\u5c06\u8bbf\u95ee\u5d4c\u5165\u805a\u5408\u4e3a\u56fa\u5b9a\u7ef4\u5ea6\u7684\u60a3\u8005\u8868\u793a\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff0c\u8fd8\u5f15\u5165\u4e86PaReGTA-RSS\u6307\u6807\uff0c\u901a\u8fc7\u79fb\u9664\u7279\u5b9a\u4e34\u5e8a\u5b9a\u4e49\u56e0\u7d20\u540e\u91cd\u65b0\u8ba1\u7b97\u8868\u793a\u5e76\u6d4b\u91cf\u53d8\u5316\u6765\u91cf\u5316\u8fd9\u4e9b\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3002", "result": "\u5728\u6765\u81eaAll of Us Research Program\u768439,088\u540d\u504f\u5934\u75db\u60a3\u8005\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u4e8e\u7a00\u758f\u57fa\u7ebf\u65b9\u6cd5\uff0cPaReGTA\u5728\u504f\u5934\u75db\u7c7b\u578b\u7684\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u3002\u540c\u65f6\u6307\u51fa\uff0c\u5728\u5f53\u524d\u6570\u636e\u96c6\u89c4\u6a21\u4e0b\uff0c\u6df1\u5c42\u987a\u5e8f\u6a21\u578b\u7684\u8868\u73b0\u4e0d\u591f\u7a33\u5b9a\u3002", "conclusion": "PaReGTA\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u5229\u7528\u65f6\u95f4\u4fe1\u606f\u7684\u65b0\u9014\u5f84\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u3002\u5b83\u4e0d\u4ec5\u80fd\u591f\u6539\u5584\u533b\u7597\u9884\u6d4b\u4efb\u52a1\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u8fd8\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\uff0c\u80fd\u53d7\u76ca\u4e8e\u672a\u6765\u7684EHR\u4e13\u7528\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2602.19685", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19685", "abs": "https://arxiv.org/abs/2602.19685", "authors": ["Xinyu Yuan", "Xixian Liu", "Ya Shi Zhang", "Zuobai Zhang", "Hongyu Guo", "Jian Tang"], "title": "PerturbDiff: Functional Diffusion for Single-Cell Perturbation Modeling", "comment": null, "summary": "Building Virtual Cells that can accurately simulate cellular responses to perturbations is a long-standing goal in systems biology. A fundamental challenge is that high-throughput single-cell sequencing is destructive: the same cell cannot be observed both before and after a perturbation. Thus, perturbation prediction requires mapping unpaired control and perturbed populations. Existing models address this by learning maps between distributions, but typically assume a single fixed response distribution when conditioned on observed cellular context (e.g., cell type) and the perturbation type. In reality, responses vary systematically due to unobservable latent factors such as microenvironmental fluctuations and complex batch effects, forming a manifold of possible distributions for the same observed conditions. To account for this variability, we introduce PerturbDiff, which shifts modeling from individual cells to entire distributions. By embedding distributions as points in a Hilbert space, we define a diffusion-based generative process operating directly over probability distributions. This allows PerturbDiff to capture population-level response shifts across hidden factors. Benchmarks on established datasets show that PerturbDiff achieves state-of-the-art performance in single-cell response prediction and generalizes substantially better to unseen perturbations. See our project page (https://katarinayuan.github.io/PerturbDiff-ProjectPage/), where code and data will be made publicly available (https://github.com/DeepGraphLearning/PerturbDiff).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPerturbDiff\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u7ec6\u80de\u5206\u5e03\u5d4c\u5165\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e2a\u76f4\u63a5\u4f5c\u7528\u4e8e\u6982\u7387\u5206\u5e03\u7684\u6269\u6563\u751f\u6210\u8fc7\u7a0b\uff0c\u4ece\u800c\u6355\u6349\u9690\u85cf\u56e0\u7d20\u4e0b\u7684\u7fa4\u4f53\u6c34\u5e73\u54cd\u5e94\u53d8\u5316\u3002PerturbDiff\u5728\u5355\u7ec6\u80de\u54cd\u5e94\u9884\u6d4b\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5bf9\u4e8e\u672a\u89c1\u8fc7\u7684\u6270\u52a8\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7531\u4e8e\u9ad8\u901a\u91cf\u5355\u7ec6\u80de\u6d4b\u5e8f\u662f\u7834\u574f\u6027\u7684\uff0c\u540c\u4e00\u6837\u672c\u4e0d\u80fd\u540c\u65f6\u89c2\u5bdf\u5230\u6270\u52a8\u524d\u540e\u7684\u60c5\u51b5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6620\u5c04\u672a\u914d\u5bf9\u7684\u5bf9\u7167\u548c\u6270\u52a8\u7fa4\u4f53\u3002\u73b0\u6709\u7684\u6a21\u578b\u901a\u5e38\u5047\u8bbe\u7ed9\u5b9a\u89c2\u5bdf\u6761\u4ef6\uff08\u5982\u7ec6\u80de\u7c7b\u578b\uff09\u548c\u6270\u52a8\u7c7b\u578b\u65f6\u53ea\u6709\u4e00\u4e2a\u56fa\u5b9a\u7684\u54cd\u5e94\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u4e2d\u54cd\u5e94\u4f1a\u56e0\u4e0d\u53ef\u89c2\u6d4b\u7684\u6f5c\u5728\u56e0\u7d20\u800c\u7cfb\u7edf\u5730\u53d8\u5316\uff0c\u5f62\u6210\u540c\u4e00\u89c2\u5bdf\u6761\u4ef6\u4e0b\u53ef\u80fd\u7684\u5206\u5e03\u6d41\u5f62\u3002", "method": "\u63d0\u51fa\u4e86PerturbDiff\uff0c\u5b83\u5c06\u5efa\u6a21\u4ece\u5355\u4e2a\u7ec6\u80de\u8f6c\u79fb\u5230\u6574\u4e2a\u5206\u5e03\u4e0a\uff0c\u901a\u8fc7\u5c06\u8fd9\u4e9b\u5206\u5e03\u4f5c\u4e3a\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7684\u70b9\u8fdb\u884c\u5d4c\u5165\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2a\u76f4\u63a5\u4f5c\u7528\u4e8e\u6982\u7387\u5206\u5e03\u4e0a\u7684\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u8fc7\u7a0b\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8PerturbDiff\u6355\u6349\u8de8\u9690\u85cf\u56e0\u5b50\u7684\u7fa4\u4f53\u7ea7\u54cd\u5e94\u53d8\u5316\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cPerturbDiff\u5728\u5355\u7ec6\u80de\u54cd\u5e94\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u4e14\u5bf9\u4e8e\u672a\u66fe\u9047\u5230\u8fc7\u7684\u6270\u52a8\u6709\u663e\u8457\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "PerturbDiff\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u7ec6\u80de\u5bf9\u4e0d\u540c\u6270\u52a8\u7684\u54cd\u5e94\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5b58\u5728\u4e0d\u53ef\u89c1\u6216\u590d\u6742\u73af\u5883\u56e0\u7d20\u7684\u60c5\u51b5\u4e0b\u3002\u6b64\u5916\uff0c\u5b83\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2602.19733", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.19733", "abs": "https://arxiv.org/abs/2602.19733", "authors": ["Sheheryar Mehmood", "Florian Knoll", "Peter Ochs"], "title": "Understanding the Curse of Unrolling", "comment": null, "summary": "Algorithm unrolling is ubiquitous in machine learning, particularly in hyperparameter optimization and meta-learning, where Jacobians of solution mappings are computed by differentiating through iterative algorithms. Although unrolling is known to yield asymptotically correct Jacobians under suitable conditions, recent work has shown that the derivative iterates may initially diverge from the true Jacobian, a phenomenon known as the curse of unrolling. In this work, we provide a non-asymptotic analysis that explains the origin of this behavior and identifies the algorithmic factors that govern it. We show that truncating early iterations of the derivative computation mitigates the curse while simultaneously reducing memory requirements. Finally, we demonstrate that warm-starting in bilevel optimization naturally induces an implicit form of truncation, providing a practical remedy. Our theoretical findings are supported by numerical experiments on representative examples.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7b97\u6cd5\u5c55\u5f00\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u9488\u5bf9\u89e3\u6620\u5c04\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u8ba1\u7b97\u65f6\u51fa\u73b0\u7684\"\u5c55\u5f00\u8bc5\u5492\"\u73b0\u8c61\u3002\u901a\u8fc7\u975e\u6e10\u8fd1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8be5\u73b0\u8c61\u7684\u6839\u6e90\uff0c\u5e76\u63d0\u51fa\u622a\u65ad\u65e9\u671f\u8fed\u4ee3\u548c\u4f7f\u7528\u6696\u542f\u52a8\u65b9\u6cd5\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u7b97\u6cd5\u5c55\u5f00\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5728\u8d85\u53c2\u6570\u4f18\u5316\u548c\u5143\u5b66\u4e60\u4e2d\u3002\u5c3d\u7ba1\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\uff0c\u5c55\u5f00\u6cd5\u80fd\u4ea7\u751f\u6e10\u8fd1\u6b63\u786e\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u4f46\u6700\u8fd1\u7684\u7814\u7a76\u6307\u51fa\uff0c\u5728\u8fed\u4ee3\u7b97\u6cd5\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u6c42\u5bfc\u53ef\u80fd\u4f1a\u5bfc\u81f4\u5bfc\u6570\u8fed\u4ee3\u521d\u671f\u4e0e\u771f\u5b9e\u96c5\u53ef\u6bd4\u77e9\u9635\u76f8\u504f\u79bb\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u5c55\u5f00\u8bc5\u5492\u201d\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u7406\u89e3\u6b64\u73b0\u8c61\u80cc\u540e\u7684\u673a\u5236\uff0c\u5e76\u63a2\u7d22\u51cf\u8f7b\u5176\u8d1f\u9762\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u975e\u6e10\u8fd1\u5206\u6790\u65b9\u6cd5\u6765\u89e3\u91ca\u5c55\u5f00\u8bc5\u5492\u73b0\u8c61\u7684\u53d1\u751f\u539f\u56e0\uff0c\u5e76\u786e\u5b9a\u5f71\u54cd\u5176\u884c\u4e3a\u7684\u7b97\u6cd5\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5c55\u793a\u4e86\u901a\u8fc7\u622a\u65ad\u5bfc\u6570\u8ba1\u7b97\u7684\u65e9\u671f\u8fed\u4ee3\u4e0d\u4ec5\u53ef\u4ee5\u51cf\u8f7b\u5c55\u5f00\u8bc5\u5492\uff0c\u8fd8\u80fd\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff1b\u540c\u65f6\u53d1\u73b0\uff0c\u5728\u53cc\u5c42\u4f18\u5316\u4e2d\u4f7f\u7528\u6696\u542f\u52a8\u7b56\u7565\u4f1a\u81ea\u7136\u5730\u5f15\u5165\u4e00\u79cd\u9690\u5f0f\u7684\u622a\u65ad\u5f62\u5f0f\uff0c\u4e3a\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7279\u5b9a\u65b9\u5f0f\u622a\u65ad\u65e9\u671f\u8fed\u4ee3\u8fc7\u7a0b\u786e\u5b9e\u6709\u52a9\u4e8e\u7f13\u89e3\u5c55\u5f00\u8bc5\u5492\u73b0\u8c61\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u6240\u9700\u7684\u5185\u5b58\u8d44\u6e90\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4ee3\u8868\u6027\u793a\u4f8b\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u7406\u8bba\u53d1\u73b0\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u5bf9\u4e8e\u7b97\u6cd5\u5c55\u5f00\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u5c55\u5f00\u8bc5\u5492\u95ee\u9898\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u622a\u65ad\u6280\u672f\u53ca\u6696\u542f\u52a8\u7b56\u7565\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u7f13\u89e3\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u4ec5\u6709\u52a9\u4e8e\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u4e5f\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316\u57fa\u4e8e\u8fed\u4ee3\u7b97\u6cd5\u7684\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.19788", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19788", "abs": "https://arxiv.org/abs/2602.19788", "authors": ["Lotta M\u00e4kinen", "Jorge Lor\u00eda", "Samuel Kaski"], "title": "Bayesian Meta-Learning with Expert Feedback for Task-Shift Adaptation through Causal Embeddings", "comment": "27 pages, 8 figures", "summary": "Meta-learning methods perform well on new within-distribution tasks but often fail when adapting to out-of-distribution target tasks, where transfer from source tasks can induce negative transfer. We propose a causally-aware Bayesian meta-learning method, by conditioning task-specific priors on precomputed latent causal task embeddings, enabling transfer based on mechanistic similarity rather than spurious correlations. Our approach explicitly considers realistic deployment settings where access to target-task data is limited, and adaptation relies on noisy (expert-provided) pairwise judgments of causal similarity between source and target tasks. We provide a theoretical analysis showing that conditioning on causal embeddings controls prior mismatch and mitigates negative transfer under task shift. Empirically, we demonstrate reductions in negative transfer and improved out-of-distribution adaptation in both controlled simulations and a large-scale real-world clinical prediction setting for cross-disease transfer, where causal embeddings align with underlying clinical mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u5173\u7cfb\u7684\u8d1d\u53f6\u65af\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u4efb\u52a1\u95f4\u6f5c\u5728\u7684\u56e0\u679c\u5d4c\u5165\u6765\u63d0\u9ad8\u5bf9\u5206\u5e03\u5916\u4efb\u52a1\u7684\u9002\u5e94\u6027\uff0c\u51cf\u5c11\u8d1f\u8fc1\u79fb\uff0c\u5e76\u5728\u4eff\u771f\u548c\u771f\u5b9e\u4e34\u5e8a\u9884\u6d4b\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u65b0\u7684\u540c\u5206\u5e03\u4efb\u52a1\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9047\u5230\u5206\u5e03\u5916\u7684\u4efb\u52a1\u65f6\u5bb9\u6613\u51fa\u73b0\u8d1f\u8fc1\u79fb\u73b0\u8c61\uff0c\u5373\u4ece\u6e90\u4efb\u52a1\u5b66\u5230\u7684\u77e5\u8bc6\u53cd\u800c\u5bf9\u76ee\u6807\u4efb\u52a1\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u56e0\u679c\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u4fc3\u8fdb\u57fa\u4e8e\u673a\u5236\u76f8\u4f3c\u6027\u7684\u77e5\u8bc6\u8fc1\u79fb\u800c\u975e\u8868\u9762\u76f8\u5173\u6027\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u56e0\u679c\u611f\u77e5\u7684\u8d1d\u53f6\u65af\u5143\u5b66\u4e60\u6280\u672f\uff0c\u5b83\u4f9d\u8d56\u4e8e\u9884\u5148\u8ba1\u7b97\u597d\u7684\u3001\u53cd\u6620\u4e0d\u540c\u4efb\u52a1\u95f4\u56e0\u679c\u5173\u7cfb\u7684\u6f5c\u9690\u5f0f\u8868\u793a\uff08\u5373\u56e0\u679c\u5d4c\u5165\uff09\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u6839\u636e\u4e13\u5bb6\u63d0\u4f9b\u7684\u5173\u4e8e\u6e90\u4efb\u52a1\u4e0e\u76ee\u6807\u4efb\u52a1\u4e4b\u95f4\u56e0\u679c\u76f8\u4f3c\u6027\u7684\u566a\u58f0\u5224\u65ad\u6765\u8fdb\u884c\u6709\u9650\u7684\u6570\u636e\u8bbf\u95ee\u6761\u4ef6\u4e0b\u7684\u6a21\u578b\u8c03\u6574\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u8fd9\u4e9b\u56e0\u679c\u5d4c\u5165\u53ef\u4ee5\u63a7\u5236\u5148\u9a8c\u4e0d\u5339\u914d\u7684\u95ee\u9898\u5e76\u51cf\u8f7b\u4efb\u52a1\u8f6c\u79fb\u8fc7\u7a0b\u4e2d\u7684\u8d1f\u8fc1\u79fb\u6548\u5e94\u3002\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u663e\u793a\uff0c\u5728\u63a7\u5236\u5b9e\u9a8c\u53ca\u5927\u89c4\u6a21\u73b0\u5b9e\u4e16\u754c\u4e34\u5e8a\u75be\u75c5\u8de8\u57df\u9884\u6d4b\u5e94\u7528\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4e\u8d1f\u8fc1\u79fb\u7684\u53d1\u751f\u7387\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u5bf9\u4e8e\u672a\u77e5\u6216\u672a\u89c1\u4efb\u52a1\u7c7b\u578b\u7684\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u56e0\u679c\u610f\u8bc6\u8d1d\u53f6\u65af\u5143\u5b66\u4e60\u6846\u67b6\u6210\u529f\u5730\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u9762\u5bf9\u5206\u5e03\u5916\u4efb\u52a1\u65f6\u6613\u906d\u53d7\u8d1f\u8fc1\u79fb\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u4e3a\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u4e14\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\u80fd\u7684\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.19789", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.19789", "abs": "https://arxiv.org/abs/2602.19789", "authors": ["Sophia N. Wilson", "Gu\u00f0r\u00fan Fj\u00f3la Gu\u00f0mundsd\u00f3ttir", "Andrew Millard", "Raghavendra Selvan", "Sebastian Mair"], "title": "Stop Preaching and Start Practising Data Frugality for Responsible Development of AI", "comment": null, "summary": "This position paper argues that the machine learning community must move from preaching to practising data frugality for responsible artificial intelligence (AI) development. For long, progress has been equated with ever-larger datasets, driving remarkable advances but now yielding increasingly diminishing performance gains alongside rising energy use and carbon emissions. While awareness of data frugal approaches has grown, their adoption has remained rhetorical, and data scaling continues to dominate development practice. We argue that this gap between preach and practice must be closed, as continued data scaling entails substantial and under-accounted environmental impacts. To ground our position, we provide indicative estimates of the energy use and carbon emissions associated with the downstream use of ImageNet-1K. We then present empirical evidence that data frugality is both practical and beneficial, demonstrating that coreset-based subset selection can substantially reduce training energy consumption with little loss in accuracy, while also mitigating dataset bias. Finally, we outline actionable recommendations for moving data frugality from rhetorical preach to concrete practice for responsible development of AI.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u673a\u5668\u5b66\u4e60\u793e\u533a\u9700\u8981\u4ece\u5021\u5bfc\u8f6c\u5411\u5b9e\u8df5\u6570\u636e\u8282\u4fed\uff0c\u4ee5\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u3002\u901a\u8fc7\u4f30\u8ba1ImageNet-1K\u4f7f\u7528\u76f8\u5173\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\uff0c\u5e76\u63d0\u4f9b\u5b9e\u8bc1\u8bc1\u660e\u6570\u636e\u8282\u4fed\u65e2\u5b9e\u7528\u53c8\u6709\u76ca\uff0c\u6700\u540e\u63d0\u51fa\u5177\u4f53\u5efa\u8bae\u6765\u4fc3\u8fdbAI\u7684\u8d1f\u8d23\u4efb\u5f00\u53d1\u3002", "motivation": "\u9762\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u6570\u636e\u96c6\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u9010\u6e10\u51cf\u5c11\u3001\u80fd\u6e90\u4f7f\u7528\u4e0e\u78b3\u6392\u653e\u589e\u52a0\u7684\u95ee\u9898\uff0c\u6587\u7ae0\u65e8\u5728\u5f3a\u8c03\u6570\u636e\u8282\u4fed\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u5c3d\u7ba1\u5bf9\u8fd9\u79cd\u65b9\u6cd5\u7684\u8ba4\u8bc6\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u5176\u5b9e\u9645\u91c7\u7528\u4ecd\u4e0d\u8db3\u3002", "method": "\u6587\u7ae0\u9996\u5148\u4f30\u7b97ImageNet-1K\u4e0b\u6e38\u4f7f\u7528\u7684\u80fd\u8017\u4e0e\u78b3\u6392\u653e\u91cf\uff1b\u63a5\u7740\uff0c\u901a\u8fc7\u5c55\u793a\u57fa\u4e8ecoreset\u7684\u5b50\u96c6\u9009\u62e9\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u65f6\u7684\u80fd\u8017\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u4e14\u51cf\u5c11\u6570\u636e\u96c6\u504f\u89c1\uff0c\u63d0\u4f9b\u4e86\u6570\u636e\u8282\u4fed\u53ef\u884c\u6027\u548c\u76ca\u5904\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528coreset\u4e3a\u57fa\u7840\u7684\u65b9\u6cd5\u9009\u62e9\u6570\u636e\u5b50\u96c6\u53ef\u4ee5\u5927\u5e45\u5ea6\u51cf\u5c11\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u800c\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e5f\u80fd\u591f\u51cf\u8f7b\u6570\u636e\u96c6\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "\u4e3a\u4e86\u63a8\u8fdb\u4eba\u5de5\u667a\u80fd\u8d1f\u8d23\u4efb\u7684\u53d1\u5c55\uff0c\u5fc5\u987b\u7f29\u5c0f\u5728\u63d0\u5021\u4e0e\u5b9e\u8df5\u4e2d\u5173\u4e8e\u6570\u636e\u8282\u7ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u6587\u7ae0\u4e3a\u6b64\u63d0\u51fa\u4e86\u5c06\u6570\u636e\u8282\u7ea6\u4ece\u7406\u8bba\u4e0a\u7684\u8ba8\u8bba\u8f6c\u5316\u4e3a\u5b9e\u9645\u884c\u52a8\u7684\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2602.19790", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19790", "abs": "https://arxiv.org/abs/2602.19790", "authors": ["Fabian Hinder", "Valerie Vaquet", "Johannes Brinkrolf", "Barbara Hammer"], "title": "Drift Localization using Conformal Predictions", "comment": "Paper was accepted at the 34th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning --- ESANN 2026", "summary": "Concept drift -- the change of the distribution over time -- poses significant challenges for learning systems and is of central interest for monitoring. Understanding drift is thus paramount, and drift localization -- determining which samples are affected by the drift -- is essential. While several approaches exist, most rely on local testing schemes, which tend to fail in high-dimensional, low-signal settings. In this work, we consider a fundamentally different approach based on conformal predictions. We discuss and show the shortcomings of common approaches and demonstrate the performance of our approach on state-of-the-art image datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u6982\u5ff5\u6f02\u79fb\u5b9a\u4f4d\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u3001\u4f4e\u4fe1\u53f7\u73af\u5883\u4e2d\u73b0\u6709\u5c40\u90e8\u6d4b\u8bd5\u65b9\u6848\u53ef\u80fd\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u5728\u6700\u5148\u8fdb\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6982\u5ff5\u6f02\u79fb\u5b9a\u4f4d\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u4f4e\u4fe1\u53f7\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u6709\u6548\u5730\u8bc6\u522b\u53d7\u6f02\u79fb\u5f71\u54cd\u7684\u6837\u672c\u3002", "method": "\u91c7\u7528\u4fdd\u5f62\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u4e0e\u4f9d\u8d56\u5c40\u90e8\u6d4b\u8bd5\u7684\u4f20\u7edf\u65b9\u6848\u4e0d\u540c\uff0c\u4e3a\u6982\u5ff5\u6f02\u79fb\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u89c6\u89d2\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6700\u65b0\u7684\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u6982\u5ff5\u6f02\u79fb\u5b9a\u4f4d\u65b0\u65b9\u6cd5\u5728\u9ad8\u7ef4\u4f4e\u4fe1\u53f7\u573a\u666f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u76d1\u6d4b\u548c\u7406\u89e3\u6982\u5ff5\u6f02\u79fb\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.19805", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19805", "abs": "https://arxiv.org/abs/2602.19805", "authors": ["Wall Kim", "Chaeyoung Song", "Hanul Kim"], "title": "Decision MetaMamba: Enhancing Selective SSM in Offline RL with Heterogeneous Sequence Mixing", "comment": null, "summary": "Mamba-based models have drawn much attention in offline RL. However, their selective mechanism often detrimental when key steps in RL sequences are omitted. To address these issues, we propose a simple yet effective structure, called Decision MetaMamba (DMM), which replaces Mamba's token mixer with a dense layer-based sequence mixer and modifies positional structure to preserve local information. By performing sequence mixing that considers all channels simultaneously before Mamba, DMM prevents information loss due to selective scanning and residual gating. Extensive experiments demonstrate that our DMM delivers the state-of-the-art performance across diverse RL tasks. Furthermore, DMM achieves these results with a compact parameter footprint, demonstrating strong potential for real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDecision MetaMamba (DMM)\u7684\u65b0\u7ed3\u6784\uff0c\u901a\u8fc7\u91c7\u7528\u57fa\u4e8e\u5bc6\u96c6\u5c42\u7684\u5e8f\u5217\u6df7\u5408\u5668\u548c\u4fee\u6539\u4f4d\u7f6e\u7ed3\u6784\u6765\u89e3\u51b3Mamba\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660eDMM\u5728\u591a\u79cdRL\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u4e14\u53c2\u6570\u91cf\u5c0f\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "Mamba\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08offline RL\uff09\u4e2d\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u9009\u62e9\u673a\u5236\u7ecf\u5e38\u5bfc\u81f4\u5f53RL\u5e8f\u5217\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\u88ab\u7701\u7565\u65f6\u51fa\u73b0\u4e0d\u5229\u5f71\u54cd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u9632\u6b62\u7531\u4e8e\u9009\u62e9\u6027\u626b\u63cf\u548c\u6b8b\u5dee\u95e8\u63a7\u5f15\u8d77\u7684\u4fe1\u606f\u635f\u5931\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u79f0\u4e3aDecision MetaMamba (DMM)\u7684\u65b0\u67b6\u6784\uff0c\u5b83\u7528\u57fa\u4e8e\u5bc6\u96c6\u5c42\u7684\u5e8f\u5217\u6df7\u5408\u5668\u66ff\u6362\u4e86Mamba\u7684\u4ee4\u724c\u6df7\u5408\u5668\uff0c\u5e76\u4fee\u6539\u4e86\u4f4d\u7f6e\u7ed3\u6784\u4ee5\u4fdd\u6301\u5c40\u90e8\u4fe1\u606f\u3002\u8fd9\u79cd\u8bbe\u8ba1\u5141\u8bb8\u5728\u8fdb\u884cMamba\u64cd\u4f5c\u4e4b\u524d\u8003\u8651\u6240\u6709\u901a\u9053\u7684\u540c\u65f6\u6267\u884c\u5e8f\u5217\u6df7\u5408\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86DMM\u5728\u4e0d\u540c\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0cDMM\u8fd8\u4ee5\u5176\u7d27\u51d1\u7684\u53c2\u6570\u91cf\u5b9e\u73b0\u4e86\u8fd9\u4e9b\u7ed3\u679c\uff0c\u663e\u793a\u51fa\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "conclusion": "Decision MetaMamba (DMM)\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u6539\u8fdb\u65b9\u6cd5\uff0c\u5728\u514b\u670dMamba\u6a21\u578b\u5c40\u9650\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6027\u80fd\u800c\u4e14\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.19893", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.19893", "abs": "https://arxiv.org/abs/2602.19893", "authors": ["Soumen Pachal", "Prashanth L. A.", "Shalabh Bhatnagar", "Avinash Achar"], "title": "Generalized Random Direction Newton Algorithms for Stochastic Optimization", "comment": null, "summary": "We present a family of generalized Hessian estimators of the objective using random direction stochastic approximation (RDSA) by utilizing only noisy function measurements. The form of each estimator and the order of the bias depend on the number of function measurements. In particular, we demonstrate that estimators with more function measurements exhibit lower-order estimation bias. We show the asymptotic unbiasedness of the estimators. We also perform asymptotic and non-asymptotic convergence analyses for stochastic Newton methods that incorporate our generalized Hessian estimators. Finally, we perform numerical experiments to validate our theoretical findings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u65b9\u5411\u968f\u673a\u903c\u8fd1(RDSA)\u7684\u5e7f\u4e49Hessian\u4f30\u8ba1\u5668\u65cf\uff0c\u4ec5\u4f7f\u7528\u566a\u58f0\u51fd\u6570\u6d4b\u91cf\u3002\u968f\u7740\u51fd\u6570\u6d4b\u91cf\u6570\u91cf\u589e\u52a0\uff0c\u4f30\u8ba1\u504f\u5dee\u964d\u4f4e\u3002\u5206\u6790\u4e86\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u65e0\u504f\u6027\u4ee5\u53ca\u7ed3\u5408\u8fd9\u4e9b\u4f30\u8ba1\u5668\u7684\u968f\u673a\u725b\u987f\u65b9\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f00\u53d1\u65b0\u7684Hessian\u77e9\u9635\u4f30\u8ba1\u6280\u672f\u6765\u6539\u5584\u5728\u4ec5\u6709\u566a\u58f0\u51fd\u6570\u503c\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u7b97\u6cd5\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u968f\u673a\u65b9\u5411\u968f\u673a\u903c\u8fd1\u65b9\u6cd5\u6784\u5efa\u4e0d\u540c\u5f62\u5f0f\u7684\u5e7f\u4e49Hessian\u4f30\u8ba1\u5668\uff1b\u5bf9\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u8fdb\u884c\u4e86\u6e10\u8fd1\u4e0e\u975e\u6e10\u8fd1\u6536\u655b\u6027\u5206\u6790\uff1b\u5b9e\u65bd\u4e86\u6570\u503c\u5b9e\u9a8c\u4ee5\u6d4b\u8bd5\u7406\u8bba\u53d1\u73b0\u7684\u6709\u6548\u6027\u3002", "result": "\u5c55\u793a\u4e86\u5177\u6709\u66f4\u591a\u51fd\u6570\u6d4b\u91cf\u503c\u7684\u4f30\u8ba1\u5668\u8868\u73b0\u51fa\u66f4\u4f4e\u9636\u7684\u4f30\u8ba1\u504f\u5dee\uff1b\u8bc1\u660e\u4e86\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u65e0\u504f\u6027\u8d28\uff1b\u63d0\u4f9b\u4e86\u5173\u4e8e\u4f7f\u7528\u6240\u63d0\u8bae\u4f30\u8ba1\u5668\u7684\u968f\u673a\u725b\u987f\u6cd5\u7684\u6536\u655b\u6027\u5206\u6790\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eRDSA\u7684\u5e7f\u4e49Hessian\u4f30\u8ba1\u5668\u80fd\u591f\u6709\u6548\u51cf\u5c11\u4f30\u8ba1\u504f\u5dee\uff0c\u5e76\u4e14\u5f53\u5e94\u7528\u4e8e\u968f\u673a\u725b\u987f\u65b9\u6cd5\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u5904\u7406\u542b\u566a\u76ee\u6807\u51fd\u6570\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2602.19895", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.19895", "abs": "https://arxiv.org/abs/2602.19895", "authors": ["Zhongwei Wan", "Yun Shen", "Zhihao Dou", "Donghao Zhou", "Yu Zhang", "Xin Wang", "Hui Shen", "Jing Xiong", "Chaofan Tao", "Zixuan Zhong", "Peizhou Huang", "Mi Zhang"], "title": "DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning", "comment": null, "summary": "Reinforcement learning with verifiers (RLVR) is a central paradigm for improving large language model (LLM) reasoning, yet existing methods often suffer from limited exploration. Policies tend to collapse onto a few reasoning patterns and prematurely stop deep exploration, while conventional entropy regularization introduces only local stochasticity and fails to induce meaningful path-level diversity, leading to weak and unstable learning signals in group-based policy optimization. We propose DSDR, a Dual-Scale Diversity Regularization reinforcement learning framework that decomposes diversity in LLM reasoning into global and coupling components. Globally, DSDR promotes diversity among correct reasoning trajectories to explore distinct solution modes. Locally, it applies a length-invariant, token-level entropy regularization restricted to correct trajectories, preventing entropy collapse within each mode while preserving correctness. The two scales are coupled through a global-to-local allocation mechanism that emphasizes local regularization for more distinctive correct trajectories. We provide theoretical support showing that DSDR preserves optimal correctness under bounded regularization, sustains informative learning signals in group-based optimization, and yields a principled global-to-local coupling rule. Experiments on multiple reasoning benchmarks demonstrate consistent improvements in accuracy and pass@k, highlighting the importance of dual-scale diversity for deep exploration in RLVR. Code is available at https://github.com/SUSTechBruce/DSDR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDSDR\u7684\u53cc\u5c3a\u5ea6\u591a\u6837\u6027\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5168\u5c40\u548c\u5c40\u90e8\u4e24\u4e2a\u5c42\u9762\u4fc3\u8fdb\u63a8\u7406\u8def\u5f84\u7684\u591a\u6837\u6027\uff0c\u65e2\u4fdd\u8bc1\u4e86\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u6a21\u5f0f\u7684\u63a2\u7d22\uff0c\u4e5f\u9632\u6b62\u4e86\u6bcf\u4e2a\u6a21\u5f0f\u5185\u7684\u71b5\u584c\u9677\u3002\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u5747\u8868\u660e\uff0cDSDR\u80fd\u591f\u4fdd\u6301\u6700\u4f18\u6b63\u786e\u6027\uff0c\u5e76\u5728\u57fa\u4e8e\u7fa4\u4f53\u7684\u4f18\u5316\u4e2d\u63d0\u4f9b\u6709\u6548\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "motivation": "\u73b0\u6709\u7684\u589e\u5f3a\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\uff0c\u5f80\u5f80\u5b58\u5728\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7b56\u7565\u503e\u5411\u4e8e\u6536\u655b\u4e8e\u5c11\u6570\u51e0\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u8fc7\u65e9\u505c\u6b62\u6df1\u5ea6\u63a2\u7d22\u3002\u4f20\u7edf\u71b5\u6b63\u5219\u5316\u4ec5\u5f15\u5165\u5c40\u90e8\u968f\u673a\u6027\uff0c\u65e0\u6cd5\u8bf1\u5bfc\u6709\u610f\u4e49\u7684\u8def\u5f84\u7ea7\u591a\u6837\u6027\uff0c\u8fd9\u4f7f\u5f97\u57fa\u4e8e\u7fa4\u4f53\u7684\u7b56\u7565\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u4fe1\u53f7\u5f31\u4e14\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86DSDR\uff08Dual-Scale Diversity Regularization\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5c06LLM\u63a8\u7406\u4e2d\u7684\u591a\u6837\u6027\u5206\u89e3\u4e3a\u5168\u5c40\u548c\u8026\u5408\u4e24\u90e8\u5206\u3002\u5728\u5168\u7403\u5c42\u9762\u4e0a\uff0cDSDR\u9f13\u52b1\u6b63\u786e\u7684\u63a8\u7406\u8f68\u8ff9\u4e4b\u95f4\u5177\u6709\u591a\u6837\u6027\u4ee5\u63a2\u7d22\u4e0d\u540c\u7684\u89e3\u51b3\u65b9\u6848\uff1b\u5728\u5c40\u90e8\u5c42\u9762\u4e0a\uff0c\u5219\u5bf9\u6b63\u786e\u7684\u8f68\u8ff9\u5e94\u7528\u957f\u5ea6\u4e0d\u53d8\u3001\u8bcd\u5143\u7ea7\u522b\u7684\u71b5\u6b63\u5219\u5316\uff0c\u8fd9\u6837\u65e2\u80fd\u907f\u514d\u6bcf\u4e2a\u6a21\u5f0f\u5185\u53d1\u751f\u71b5\u584c\u9677\u53c8\u4fdd\u6301\u4e86\u6b63\u786e\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e00\u4e2a\u5168\u5c40\u5230\u5c40\u90e8\u7684\u5206\u914d\u673a\u5236\u8fde\u63a5\u8fd9\u4e24\u4e2a\u5c3a\u5ea6\uff0c\u5bf9\u4e8e\u66f4\u72ec\u7279\u7684\u6b63\u786e\u8f68\u8ff9\u52a0\u5f3a\u5c40\u90e8\u6b63\u5219\u5316\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff0c\u5728\u6709\u754c\u6b63\u5219\u5316\u6761\u4ef6\u4e0b\uff0cDSDR\u53ef\u4ee5\u7ef4\u6301\u6700\u4f18\u6b63\u786e\u6027\uff0c\u5e76\u5728\u57fa\u4e8e\u7fa4\u4f53\u7684\u4f18\u5316\u4e2d\u6301\u7eed\u63d0\u4f9b\u4fe1\u606f\u91cf\u4e30\u5bcc\u7684\u5b66\u4e60\u4fe1\u53f7\u3002\u540c\u65f6\uff0c\u7ed9\u51fa\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u5168\u5c40\u81f3\u5c40\u90e8\u8026\u5408\u89c4\u5219\u3002\u5b9e\u9a8c\u65b9\u9762\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cDSDR\u5c55\u793a\u4e86\u5728\u51c6\u786e\u6027\u548cpass@k\u6307\u6807\u4e0a\u7684\u6301\u7eed\u63d0\u5347\uff0c\u5f3a\u8c03\u4e86\u53cc\u5c3a\u5ea6\u591a\u6837\u6027\u5bf9\u4e8eRLVR\u4e2d\u6df1\u5165\u63a2\u7d22\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u2014\u2014DSDR\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u65f6\u9047\u5230\u7684\u63a2\u7d22\u4e0d\u8db3\u95ee\u9898\u3002\u901a\u8fc7\u4fc3\u8fdb\u63a8\u7406\u8def\u5f84\u7684\u53cc\u91cd\u5c3a\u5ea6\u591a\u6837\u6027\uff0cDSDR\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8fd8\u589e\u5f3a\u4e86\u5b66\u4e60\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2602.19912", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19912", "abs": "https://arxiv.org/abs/2602.19912", "authors": ["Ghaith Mqawass", "Tuan Le", "Fabian Theis", "Djork-Arn\u00e9 Clevert"], "title": "De novo molecular structure elucidation from mass spectra via flow matching", "comment": "13-page preprint, 4 figures, 1 table", "summary": "Mass spectrometry is a powerful and widely used tool for identifying molecular structures due to its sensitivity and ability to profile complex samples. However, translating spectra into full molecular structures is a difficult, under-defined inverse problem. Overcoming this problem is crucial for enabling biological insight, discovering new metabolites, and advancing chemical research across multiple fields. To this end, we develop MSFlow, a two-stage encoder-decoder flow-matching generative model that achieves state-of-the-art performance on the structure elucidation task for small molecules. In the first stage, we adopt a formula-restricted transformer model for encoding mass spectra into a continuous and chemically informative embedding space, while in the second stage, we train a decoder flow matching model to reconstruct molecules from latent embeddings of mass spectra. We present ablation studies demonstrating the importance of using information-preserving molecular descriptors for encoding mass spectra and motivate the use of our discrete flow-based decoder. Our rigorous evaluation demonstrates that MSFlow can accurately translate up to 45 percent of molecular mass spectra into their corresponding molecular representations - an improvement of up to fourteen-fold over the current state-of-the-art. A trained version of MSFlow is made publicly available on GitHub for non-commercial users.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMSFlow\u7684\u4e24\u9636\u6bb5\u7f16\u7801-\u89e3\u7801\u6d41\u5339\u914d\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u5c0f\u5206\u5b50\u7684\u8d28\u91cf\u8c31\u4e2d\u63a8\u65ad\u51fa\u5206\u5b50\u7ed3\u6784\u3002\u8be5\u6a21\u578b\u5728\u5c06\u8d28\u91cf\u8c31\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u5206\u5b50\u8868\u793a\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe45%\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5341\u56db\u500d\u3002", "motivation": "\u8d28\u8c31\u6cd5\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u8bc6\u522b\u590d\u6742\u7684\u6837\u54c1\u4e2d\u7684\u5206\u5b50\u7ed3\u6784\uff0c\u4f46\u5c06\u5149\u8c31\u8f6c\u5316\u4e3a\u5b8c\u6574\u7684\u5206\u5b50\u7ed3\u6784\u662f\u4e00\u4e2a\u672a\u5145\u5206\u5b9a\u4e49\u4e14\u56f0\u96be\u7684\u95ee\u9898\u3002\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u5bf9\u4e8e\u751f\u7269\u7814\u7a76\u3001\u53d1\u73b0\u65b0\u7684\u4ee3\u8c22\u7269\u4ee5\u53ca\u63a8\u8fdb\u591a\u4e2a\u9886\u57df\u7684\u5316\u5b66\u7814\u7a76\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86MSFlow\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u7f16\u7801-\u89e3\u7801\u6d41\u5339\u914d\u751f\u6210\u6a21\u578b\u3002\u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u516c\u5f0f\u9650\u5b9a\u7684Transformer\u6a21\u578b\u5c06\u8d28\u91cf\u8c31\u7f16\u7801\u6210\u4e00\u4e2a\u8fde\u7eed\u800c\u5177\u6709\u5316\u5b66\u4fe1\u606f\u7684\u5d4c\u5165\u7a7a\u95f4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5219\u8bad\u7ec3\u4e00\u4e2a\u89e3\u7801\u5668\u6d41\u5339\u914d\u6a21\u578b\uff0c\u4ece\u8d28\u91cf\u8c31\u7684\u6f5c\u5728\u5d4c\u5165\u4e2d\u91cd\u5efa\u5206\u5b50\u3002", "result": "\u901a\u8fc7\u4e25\u683c\u7684\u8bc4\u4f30\u663e\u793a\uff0cMSFlow\u53ef\u4ee5\u51c6\u786e\u5730\u5c06\u9ad8\u8fbe45%\u7684\u5206\u5b50\u8d28\u91cf\u8c31\u8f6c\u6362\u4e3a\u5176\u76f8\u5e94\u7684\u5206\u5b50\u8868\u793a\uff0c\u8fd9\u4e00\u6210\u5c31\u76f8\u8f83\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6c34\u5e73\u63d0\u9ad8\u4e86\u6700\u591a\u8fbe\u5341\u56db\u500d\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u6d88\u878d\u7814\u7a76\u6765\u8bc1\u660e\u4f7f\u7528\u4fe1\u606f\u4fdd\u6301\u7684\u5206\u5b50\u63cf\u8ff0\u7b26\u5bf9\u8d28\u91cf\u8c31\u7f16\u7801\u7684\u91cd\u8981\u6027\uff0c\u5e76\u652f\u6301\u91c7\u7528\u57fa\u4e8e\u79bb\u6563\u6d41\u7684\u89e3\u7801\u5668\u3002", "conclusion": "MSFlow\u663e\u8457\u63d0\u9ad8\u4e86\u4ece\u5c0f\u5206\u5b50\u8d28\u91cf\u8c31\u5230\u5206\u5b50\u7ed3\u6784\u89e3\u6790\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u751f\u7269\u5b66\u89c1\u89e3\u3001\u65b0\u4ee3\u8c22\u7269\u53d1\u73b0\u53ca\u8de8\u9886\u57df\u5316\u5b66\u7814\u7a76\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u652f\u6301\u3002\u6b64\u5916\uff0c\u975e\u5546\u4e1a\u7528\u6237\u53ef\u4ee5\u5728GitHub\u4e0a\u83b7\u5f97\u8bad\u7ec3\u597d\u7684MSFlow\u7248\u672c\u3002"}}
{"id": "2602.19926", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19926", "abs": "https://arxiv.org/abs/2602.19926", "authors": ["Jin Liu", "Yinbin Miao", "Ning Xi", "Junkang Liu"], "title": "Rethinking LoRA for Privacy-Preserving Federated Learning in Large Models", "comment": null, "summary": "Fine-tuning large vision models (LVMs) and large language models (LLMs) under differentially private federated learning (DPFL) is hindered by a fundamental privacy-utility trade-off. Low-Rank Adaptation (LoRA), a promising parameter-efficient fine-tuning (PEFT) method, reduces computational and communication costs by introducing two trainable low-rank matrices while freezing pre-trained weights. However, directly applying LoRA in DPFL settings leads to performance degradation, especially in LVMs. Our analysis reveals three previously underexplored challenges: (1) gradient coupling caused by the simultaneous update of two asymmetric low-rank matrices, (2) compounded noise amplification under differential privacy, and (3) sharpness of the global aggregated model in the parameter space. To address these issues, we propose LA-LoRA (\\textbf{L}ocal \\textbf{A}lternating \\textbf{LoRA}), a novel approach that decouples gradient interactions and aligns update directions across clients to enhance robustness under stringent privacy constraints. Theoretically, LA-LoRA strengthens convergence guarantees in noisy federated environments. Extensive experiments demonstrate that LA-LoRA achieves state-of-the-art (SOTA) performance on Swin Transformer and RoBERTa models, showcasing robustness to DP noise and broad applicability across both LVMs and LLMs. For example, when fine-tuning the Swin-B model on the Tiny-ImageNet dataset under a strict privacy budget ($\u03b5= 1$), LA-LoRA outperforms the best baseline, RoLoRA, by 16.83\\% in test accuracy. Code is provided in \\repolink.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLA-LoRA\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5728\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u8fdb\u884c\u5927\u89c4\u6a21\u89c6\u89c9\u6a21\u578b\u548c\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65f6\u9047\u5230\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002\u901a\u8fc7\u89e3\u8026\u68af\u5ea6\u4ea4\u4e92\u5e76\u4f7f\u5ba2\u6237\u7aef\u4e4b\u95f4\u7684\u66f4\u65b0\u65b9\u5411\u4e00\u81f4\uff0cLA-LoRA\u63d0\u9ad8\u4e86\u5728\u4e25\u683c\u9690\u79c1\u9650\u5236\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728Swin Transformer\u548cRoBERTa\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60(DPFL)\u73af\u5883\u4e0b\u5bf9\u5927\u578b\u89c6\u89c9\u6a21\u578b(LVMs)\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u8fdb\u884c\u5fae\u8c03\u9762\u4e34\u57fa\u672c\u7684\u9690\u79c1-\u6548\u7528\u6743\u8861\u95ee\u9898\u3002\u76f4\u63a5\u5c06\u4f4e\u79e9\u9002\u5e94(LoRA)\u5e94\u7528\u4e8eDPFL\u8bbe\u7f6e\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728LVMs\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86LA-LoRA\uff08\u672c\u5730\u4ea4\u66ffLoRA\uff09\uff0c\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u7531\u4e8e\u4e24\u4e2a\u975e\u5bf9\u79f0\u4f4e\u79e9\u77e9\u9635\u540c\u65f6\u66f4\u65b0\u5bfc\u81f4\u7684\u68af\u5ea6\u8026\u5408\uff1b2) \u5728\u5dee\u5206\u9690\u79c1\u4e0b\u590d\u5408\u566a\u58f0\u653e\u5927\uff1b3) \u53c2\u6570\u7a7a\u95f4\u4e2d\u5168\u5c40\u805a\u5408\u6a21\u578b\u7684\u5c16\u9510\u5ea6\u3002LA-LoRA\u901a\u8fc7\u89e3\u8026\u68af\u5ea6\u4ea4\u4e92\u5e76\u8c03\u6574\u5ba2\u6237\u673a\u95f4\u7684\u66f4\u65b0\u65b9\u5411\u6765\u589e\u5f3a\u5728\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLA-LoRA\u5728Swin Transformer\u548cRoBERTa\u6a21\u578b\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb(SOTA)\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u5bf9\u6297DP\u566a\u58f0\u7684\u5f3a\u5927\u80fd\u529b\u548c\u5bf9LVMs\u53caLLMs\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u3002\u4f8b\u5982\uff0c\u5728Tiny-ImageNet\u6570\u636e\u96c6\u4e0a\u5bf9Swin-B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4e14\u9690\u79c1\u9884\u7b97\u03b5=1\u7684\u60c5\u51b5\u4e0b\uff0cLA-LoRA\u6bd4\u6700\u4f73\u57fa\u7ebfRoLoRA\u9ad8\u51fa16.83%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "conclusion": "LA-LoRA\u4e0d\u4ec5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LoRA\u65b9\u6cd5\u5728\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u800c\u4e14\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2602.19931", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.19931", "abs": "https://arxiv.org/abs/2602.19931", "authors": ["Pin-Han Huang", "Shang-Tse Chen", "Hsuan-Tien Lin"], "title": "Expanding the Role of Diffusion Models for Robust Classifier Training", "comment": null, "summary": "Incorporating diffusion-generated synthetic data into adversarial training (AT) has been shown to substantially improve the training of robust image classifiers. In this work, we extend the role of diffusion models beyond merely generating synthetic data, examining whether their internal representations, which encode meaningful features of the data, can provide additional benefits for robust classifier training. Through systematic experiments, we show that diffusion models offer representations that are both diverse and partially robust, and that explicitly incorporating diffusion representations as an auxiliary learning signal during AT consistently improves robustness across settings. Furthermore, our representation analysis indicates that incorporating diffusion models into AT encourages more disentangled features, while diffusion representations and diffusion-generated synthetic data play complementary roles in shaping representations. Experiments on CIFAR-10, CIFAR-100, and ImageNet validate these findings, demonstrating the effectiveness of jointly leveraging diffusion representations and synthetic data within AT.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u5c06\u6269\u6563\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u4f5c\u4e3a\u5bf9\u6297\u8bad\u7ec3\uff08AT\uff09\u4e2d\u7684\u8f85\u52a9\u5b66\u4e60\u4fe1\u53f7\uff0c\u7ed3\u679c\u8868\u660e\u8fd9\u53ef\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u6269\u6563\u8868\u793a\u4e0e\u5408\u6210\u6570\u636e\u5728\u5851\u9020\u8868\u793a\u4e2d\u8d77\u4e92\u8865\u4f5c\u7528\u3002", "motivation": "\u9664\u4e86\u751f\u6210\u5408\u6210\u6570\u636e\u5916\uff0c\u63a2\u7a76\u6269\u6563\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u662f\u5426\u80fd\u591f\u4e3a\u9c81\u68d2\u5206\u7c7b\u5668\u8bad\u7ec3\u63d0\u4f9b\u66f4\u591a\u76ca\u5904\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u5206\u6790\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u7684\u591a\u6837\u5316\u4e14\u90e8\u5206\u9c81\u68d2\u7684\u8868\u793a\uff0c\u5e76\u5728\u5bf9\u6297\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u660e\u786e\u5730\u5c06\u8fd9\u4e9b\u6269\u6563\u8868\u793a\u4f5c\u4e3a\u8f85\u52a9\u5b66\u4e60\u4fe1\u53f7\u6574\u5408\u8fdb\u53bb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728AT\u4e2d\u52a0\u5165\u6269\u6563\u6a21\u578b\u8868\u793a\u59cb\u7ec8\u80fd\u63d0\u9ad8\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u9c81\u68d2\u6027\uff1b\u540c\u65f6\uff0c\u6269\u6563\u6a21\u578b\u548c\u5408\u6210\u6570\u636e\u5728\u5f62\u6210\u66f4\u89e3\u8026\u7279\u5f81\u65b9\u9762\u53d1\u6325\u7740\u4e92\u8865\u4f5c\u7528\u3002", "conclusion": "\u8054\u5408\u5229\u7528\u6269\u6563\u6a21\u578b\u8868\u793a\u548c\u5408\u6210\u6570\u636e\u5728\u5bf9\u6297\u8bad\u7ec3\u4e2d\u88ab\u8bc1\u660e\u662f\u6709\u6548\u7684\u7b56\u7565\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u56fe\u50cf\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.19945", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.19945", "abs": "https://arxiv.org/abs/2602.19945", "authors": ["Jin Liu", "Yinbin Miao", "Ning Xi", "Junkang Liu"], "title": "DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models", "comment": null, "summary": "Balancing convergence efficiency and robustness under Differential Privacy (DP) is a central challenge in Federated Learning (FL). While AdamW accelerates training and fine-tuning in large-scale models, we find that directly applying it to Differentially Private FL (DPFL) suffers from three major issues: (i) data heterogeneity and privacy noise jointly amplify the variance of second-moment estimator, (ii) DP perturbations bias the second-moment estimator, and (iii) DP amplify AdamW sensitivity to local overfitting, worsening client drift. We propose DP-FedAdamW, the first AdamW-based optimizer for DPFL. It restores AdamW under DP by stabilizing second-moment variance, removing DP-induced bias, and aligning local updates to the global descent to curb client drift. Theoretically, we establish an unbiased second-moment estimator and prove a linearly accelerated convergence rate without any heterogeneity assumption, while providing tighter $(\\varepsilon,\u03b4)$-DP guarantees. Our empirical results demonstrate the effectiveness of DP-FedAdamW across language and vision Transformers and ResNet-18. On Tiny-ImageNet (Swin-Base, $\\varepsilon=1$), DP-FedAdamW outperforms the state-of-the-art (SOTA) by 5.83\\%. The code is available in Appendix.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668DP-FedAdamW\uff0c\u65e8\u5728\u89e3\u51b3\u5728\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60(DPFL)\u4e2d\u76f4\u63a5\u5e94\u7528AdamW\u65f6\u9047\u5230\u7684\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u6570\u636e\u5f02\u8d28\u6027\u548c\u9690\u79c1\u566a\u58f0\u5171\u540c\u653e\u5927\u4e86\u4e8c\u9636\u77e9\u4f30\u8ba1\u5668\u7684\u65b9\u5dee\u3001\u5dee\u5206\u9690\u79c1\u6270\u52a8\u5bfc\u81f4\u7684\u4e8c\u9636\u77e9\u4f30\u8ba1\u504f\u5dee\u4ee5\u53ca\u5bf9\u5c40\u90e8\u8fc7\u62df\u5408\u654f\u611f\u5ea6\u589e\u52a0\u5f15\u53d1\u7684\u5ba2\u6237\u7aef\u6f02\u79fb\u3002\u901a\u8fc7\u7a33\u5b9a\u4e8c\u9636\u77e9\u65b9\u5dee\u3001\u6d88\u9664\u5dee\u5206\u9690\u79c1\u5f15\u8d77\u7684\u504f\u5dee\uff0c\u5e76\u4f7f\u672c\u5730\u66f4\u65b0\u4e0e\u5168\u5c40\u4e0b\u964d\u65b9\u5411\u4e00\u81f4\u6765\u6291\u5236\u5ba2\u6237\u7aef\u6f02\u79fb\uff0c\u4ece\u800c\u6062\u590dDP\u4e0b\u7684AdamW\u8868\u73b0\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u4e00\u4e2a\u65e0\u504f\u7684\u4e8c\u9636\u77e9\u4f30\u8ba1\u5668\uff0c\u5e76\u5728\u7ebf\u6027\u52a0\u901f\u6536\u655b\u7387\u65b9\u9762\u53d6\u5f97\u8fdb\u6b65\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86DP-FedAdamW\u5728\u8bed\u8a00\u548c\u89c6\u89c9Transformer\u53caResNet-18\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\uff0c\u5728\u4fdd\u6301\u5dee\u5206\u9690\u79c1\u7684\u540c\u65f6\u5e73\u8861\u6536\u655b\u6548\u7387\u548c\u9c81\u68d2\u6027\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u867d\u7136AdamW\u80fd\u52a0\u901f\u5927\u89c4\u6a21\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u5fae\u8c03\uff0c\u4f46\u5728\u5dee\u5206\u9690\u79c1\u8054\u90a6\u5b66\u4e60\uff08DPFL\uff09\u73af\u5883\u4e0b\u76f4\u63a5\u4f7f\u7528\u5b83\u5b58\u5728\u82e5\u5e72\u95ee\u9898\uff1a\u6570\u636e\u5f02\u8d28\u6027\u548c\u9690\u79c1\u566a\u58f0\u52a0\u5267\u4e86\u4e8c\u9636\u77e9\u4f30\u8ba1\u5668\u7684\u65b9\u5dee\uff1b\u5dee\u5206\u9690\u79c1\u6270\u52a8\u5f15\u5165\u4e86\u5bf9\u4e8c\u9636\u77e9\u4f30\u8ba1\u7684\u504f\u5dee\uff1b\u5e76\u4e14\u589e\u52a0\u4e86\u5bf9\u4e8e\u5c40\u90e8\u8fc7\u62df\u5408\u7684\u654f\u611f\u5ea6\uff0c\u6076\u5316\u4e86\u5ba2\u6237\u7aef\u6f02\u79fb\u73b0\u8c61\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u540d\u4e3aDP-FedAdamW\u7684\u65b0\u4f18\u5316\u5668\u3002\u8be5\u4f18\u5316\u5668\u901a\u8fc7\u7a33\u5b9a\u4e8c\u9636\u77e9\u4f30\u8ba1\u5668\u7684\u65b9\u5dee\u3001\u53bb\u9664\u7531\u5dee\u5206\u9690\u79c1\u5f15\u5165\u7684\u504f\u5dee\u4ee5\u53ca\u8c03\u6574\u5c40\u90e8\u66f4\u65b0\u4ee5\u5339\u914d\u5168\u5c40\u4e0b\u964d\u65b9\u5411\u6765\u51cf\u5c11\u5ba2\u6237\u7aef\u6f02\u79fb\uff0c\u4ece\u800c\u6539\u5584\u4e86DPFL\u573a\u666f\u4e0bAdamW\u7684\u8868\u73b0\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\uff0cDP-FedAdamW\u80fd\u591f\u5b9e\u73b0\u65e0\u504f\u7684\u4e8c\u9636\u77e9\u4f30\u8ba1\uff0c\u5e76\u4e14\u5728\u6ca1\u6709\u4efb\u4f55\u5f02\u8d28\u6027\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u8bc1\u660e\u4e86\u7ebf\u6027\u52a0\u901f\u7684\u6536\u655b\u901f\u5ea6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u66f4\u4e25\u683c\u7684(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u4e0a\uff0c\u5728Tiny-ImageNet (Swin-Base, \u03b5=1) \u6570\u636e\u96c6\u4e0a\uff0cDP-FedAdamW\u76f8\u6bd4\u5f53\u524d\u6700\u4f18\u6280\u672f\u63d0\u9ad8\u4e865.83%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cDP-FedAdamW\u4f5c\u4e3a\u4e00\u79cd\u57fa\u4e8eAdamW\u7684\u4f18\u5316\u5668\uff0c\u6709\u6548\u89e3\u51b3\u4e86DPFL\u73af\u5883\u4e2d\u5b58\u5728\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\uff0c\u800c\u4e14\u589e\u5f3a\u4e86\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2602.19980", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.19980", "abs": "https://arxiv.org/abs/2602.19980", "authors": ["Itamar Trainin", "Shauli Ravfogel", "Omri Abend", "Amir Feder"], "title": "Discrete Diffusion Models Exploit Asymmetry to Solve Lookahead Planning Tasks", "comment": null, "summary": "While Autoregressive (AR) Transformer-based Generative Language Models are frequently employed for lookahead tasks, recent research suggests a potential discrepancy in their ability to perform planning tasks that require multi-step lookahead. In this work, we investigate the distinct emergent mechanisms that arise when training AR versus Non-Autoregressive (NAR) models, such as Discrete Diffusion Models (dLLMs), on lookahead tasks. By requiring the models to plan ahead to reach the correct conclusion, we analyze how these two paradigms fundamentally differ in their approach to the problem. We identify a critical asymmetry in planning problems: while forward generation requires complex lookahead at branching junctions, reverse generation is often deterministic. This asymmetry creates an opportunity for NAR models. Through mechanistic analysis of training and inference dynamics, we demonstrate that NAR models learn to solve planning tasks by utilizing future tokens to decode backwards, avoiding the need to learn complex traversal mechanisms entirely. Consequently, we report that both AR and NAR models are able to achieve perfect accuracy on the lookahead task. However, NAR models require exponentially fewer training examples and shallower architectures compared to AR models, which often fail to converge without specific curriculum adjustments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff08NAR\uff09\u5728\u5904\u7406\u524d\u77bb\u4efb\u52a1\u65f6\uff0c\u901a\u8fc7\u5229\u7528\u672a\u6765\u6807\u8bb0\u53cd\u5411\u89e3\u7801\u6765\u907f\u514d\u5b66\u4e60\u590d\u6742\u7684\u904d\u5386\u673a\u5236\uff0c\u4ece\u800c\u6bd4\u81ea\u56de\u5f52\u6a21\u578b\uff08AR\uff09\u9700\u8981\u66f4\u5c11\u7684\u8bad\u7ec3\u6837\u672c\u548c\u66f4\u6d45\u5c42\u7684\u67b6\u6784\u5373\u53ef\u8fbe\u5230\u76f8\u540c\u6216\u66f4\u597d\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u8ba8\u81ea\u56de\u5f52(AR)\u4e0e\u975e\u81ea\u56de\u5f52(NAR)\u6a21\u578b\u5728\u5904\u7406\u524d\u77bb\u4efb\u52a1\u65f6\u7684\u4e0d\u540c\u673a\u5236\uff0c\u7279\u522b\u662f\u89e3\u51b3\u89c4\u5212\u95ee\u9898\u7684\u80fd\u529b\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u8981\u6c42\u6a21\u578b\u63d0\u524d\u8ba1\u5212\u4ee5\u5f97\u51fa\u6b63\u786e\u7ed3\u8bba\uff0c\u5206\u6790\u4e86AR\u4e0eNAR\u4e24\u79cd\u8303\u5f0f\u5728\u89e3\u51b3\u95ee\u9898\u4e0a\u7684\u6839\u672c\u533a\u522b\uff0c\u5e76\u901a\u8fc7\u673a\u5236\u5206\u6790\u8bad\u7ec3\u548c\u63a8\u7406\u52a8\u6001\u5c55\u793a\u4e86NAR\u6a21\u578b\u5982\u4f55\u5229\u7528\u672a\u6765\u6807\u8bb0\u8fdb\u884c\u53cd\u5411\u89e3\u7801\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136AR\u548cNAR\u6a21\u578b\u90fd\u80fd\u5728\u524d\u77bb\u4efb\u52a1\u4e0a\u5b9e\u73b0\u5b8c\u7f8e\u51c6\u786e\u5ea6\uff0c\u4f46NAR\u6a21\u578b\u53ea\u9700\u8981\u6307\u6570\u7ea7\u66f4\u5c11\u7684\u8bad\u7ec3\u793a\u4f8b\u4ee5\u53ca\u66f4\u6d45\u7684\u67b6\u6784\uff1b\u76f8\u6bd4\u4e4b\u4e0b\uff0cAR\u6a21\u578b\u5f80\u5f80\u9700\u8981\u7279\u5b9a\u8bfe\u7a0b\u8c03\u6574\u624d\u80fd\u6536\u655b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u5904\u7406\u9700\u8981\u591a\u6b65\u524d\u77bb\u7684\u89c4\u5212\u4efb\u52a1\u65f6\uff0cNAR\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6548\u7387\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u80fd\u591f\u6709\u6548\u5229\u7528\u53cd\u5411\u751f\u6210\u7684\u4f18\u52bf\u6765\u7b80\u5316\u590d\u6742\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2602.19982", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.19982", "abs": "https://arxiv.org/abs/2602.19982", "authors": ["Alaa El Ichi", "Khalide Jbilou"], "title": "A Computationally Efficient Multidimensional Vision Transformer", "comment": null, "summary": "Vision Transformers have achieved state-of-the-art performance in a wide range\n  of computer vision tasks, but their practical deployment is limited by high\n  computational and memory costs. In this paper, we introduce a novel tensor-based\n  framework for Vision Transformers built upon the Tensor Cosine Product\n  (Cproduct). By exploiting multilinear structures inherent in image data and the\n  orthogonality of cosine transforms, the proposed approach enables efficient\n  attention mechanisms and structured feature representations. We develop the\n  theoretical foundations of the tensor cosine product, analyze its algebraic\n  properties, and integrate it into a new Cproduct-based Vision Transformer\n  architecture (TCP-ViT). Numerical experiments on standard classification and\n  segmentation benchmarks demonstrate that the proposed method achieves a uniform\n  1/C parameter reduction (where C is the number of channels) while\n  maintaining competitive accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u4f59\u5f26\u79ef\u7684\u65b0\u578b\u89c6\u89c9\u53d8\u6362\u5668\u6846\u67b6\uff08TCP-ViT\uff09\uff0c\u901a\u8fc7\u5229\u7528\u56fe\u50cf\u6570\u636e\u4e2d\u7684\u591a\u7ebf\u6027\u7ed3\u6784\u548c\u4f59\u5f26\u53d8\u6362\u7684\u6b63\u4ea4\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u7ed3\u6784\u5316\u7684\u7279\u5f81\u8868\u793a\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89c6\u89c9\u53d8\u6362\u5668\u867d\u7136\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f46\u5176\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u7684\u9650\u5236\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u4f59\u5f26\u79ef(Cproduct)\u7684\u65b0\u6846\u67b6\u6765\u6784\u5efa\u89c6\u89c9\u53d8\u6362\u5668\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u5f20\u91cf\u4f59\u5f26\u79ef\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5206\u6790\u4e86\u5b83\u7684\u4ee3\u6570\u6027\u8d28\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u65b0\u7684\u57fa\u4e8eCproduct\u7684\u89c6\u89c9\u53d8\u6362\u5668\u67b6\u6784(TCP-ViT)\u4e2d\u3002", "result": "\u5728\u6807\u51c6\u5206\u7c7b\u548c\u5206\u5272\u57fa\u51c6\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fbe\u5230\u4e86\u4e00\u81f4\u76841/C\u53c2\u6570\u51cf\u5c11\uff08\u5176\u4e2dC\u662f\u901a\u9053\u6570\u91cf\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5f20\u91cf\u4f59\u5f26\u79ef\u7684\u65b0\u6846\u67b6\uff0c\u672c\u6587\u4e3a\u89c6\u89c9\u53d8\u6362\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u7ef4\u6301\u4e86\u6a21\u578b\u7684\u51c6\u786e\u5ea6\u3002"}}
{"id": "2602.20019", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20019", "abs": "https://arxiv.org/abs/2602.20019", "authors": ["Yuxing Tian", "Yiyan Qi", "Fengran Mo", "Weixu Zhang", "Jian Guo", "Jian-Yun Nie"], "title": "Learning Discriminative and Generalizable Anomaly Detector for Dynamic Graph with Limited Supervision", "comment": "21 pages, 7 figures", "summary": "Dynamic graph anomaly detection (DGAD) is critical for many real-world applications but remains challenging due to the scarcity of labeled anomalies. Existing methods are either unsupervised or semi-supervised: unsupervised methods avoid the need for labeled anomalies but often produce ambiguous boundary, whereas semi-supervised methods can overfit to the limited labeled anomalies and generalize poorly to unseen anomalies. To address this gap, we consider a largely underexplored problem in DGAD: learning a discriminative boundary from normal/unlabeled data, while leveraging limited labeled anomalies \\textbf{when available} without sacrificing generalization to unseen anomalies. To this end, we propose an effective, generalizable, and model-agnostic framework with three main components: (i) residual representation encoding that capture deviations between current interactions and their historical context, providing anomaly-relevant signals; (ii) a restriction loss that constrain the normal representations within an interval bounded by two co-centered hyperspheres, ensuring consistent scales while keeping anomalies separable; (iii) a bi-boundary optimization strategy that learns a discriminative and robust boundary using the normal log-likelihood distribution modeled by a normalizing flow. Extensive experiments demonstrate the superiority of our framework across diverse evaluation settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u56fe\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u6b63\u5e38/\u672a\u6807\u8bb0\u7684\u6570\u636e\u4e2d\u5b66\u4e60\u533a\u5206\u8fb9\u754c\uff0c\u5e76\u5728\u6709\u6807\u7b7e\u7684\u5f02\u5e38\u6570\u636e\u53ef\u7528\u65f6\u5229\u7528\u8fd9\u4e9b\u6570\u636e\uff0c\u540c\u65f6\u4e0d\u8fc7\u5ea6\u62df\u5408\uff0c\u4ee5\u4fdd\u6301\u5bf9\u672a\u77e5\u5f02\u5e38\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u6001\u56fe\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u8981\u4e48\u662f\u65e0\u76d1\u7763\u7684\uff0c\u5bfc\u81f4\u8fb9\u754c\u6a21\u7cca\uff1b\u8981\u4e48\u662f\u534a\u76d1\u7763\u7684\uff0c\u5bb9\u6613\u8fc7\u5ea6\u62df\u5408\u6709\u9650\u7684\u6807\u8bb0\u5f02\u5e38\u6570\u636e\uff0c\u4e14\u5bf9\u4e8e\u672a\u89c1\u8fc7\u7684\u5f02\u5e38\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u4e86\u5982\u4f55\u4ece\u6b63\u5e38\u6216\u672a\u6807\u8bb0\u6570\u636e\u4e2d\u5b66\u4e60\u4e00\u4e2a\u5177\u6709\u533a\u5206\u6027\u7684\u8fb9\u754c\uff0c\u540c\u65f6\u5728\u6709\u6807\u8bb0\u7684\u5f02\u5e38\u6570\u636e\u65f6\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\uff0c\u800c\u4e0d\u727a\u7272\u5bf9\u672a\u77e5\u5f02\u5e38\u7684\u6cdb\u5316\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u3001\u53ef\u63a8\u5e7f\u7684\u4e14\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a1\uff09\u6b8b\u5dee\u8868\u793a\u7f16\u7801\uff0c\u7528\u4e8e\u6355\u6349\u5f53\u524d\u4ea4\u4e92\u4e0e\u5176\u5386\u53f2\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u504f\u5dee\uff0c\u63d0\u4f9b\u4e0e\u5f02\u5e38\u76f8\u5173\u7684\u4fe1\u53f7\uff1b2\uff09\u9650\u5236\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u4e24\u4e2a\u5171\u4e2d\u5fc3\u8d85\u7403\u4f53\u9650\u5b9a\u6b63\u5e38\u8868\u793a\u8303\u56f4\uff0c\u786e\u4fdd\u5c3a\u5ea6\u4e00\u81f4\u7684\u540c\u65f6\u4f7f\u5f02\u5e38\u70b9\u5206\u79bb\uff1b3\uff09\u53cc\u8fb9\u754c\u4f18\u5316\u7b56\u7565\uff0c\u4f7f\u7528\u6b63\u5219\u6d41\u5efa\u6a21\u7684\u6b63\u5e38\u4f3c\u7136\u5206\u5e03\u6765\u5b66\u4e60\u4e00\u4e2a\u533a\u5206\u6027\u548c\u9c81\u68d2\u6027\u5f3a\u7684\u8fb9\u754c\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u591a\u6837\u5316\u7684\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u521b\u65b0\u7684\u65b9\u6cd5\u8bba\u6765\u89e3\u51b3\u52a8\u6001\u56fe\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u5bf9\u672a\u77e5\u5f02\u5e38\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.20102", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.20102", "abs": "https://arxiv.org/abs/2602.20102", "authors": ["Thanh Q. Tran", "Arun Verma", "Kiwan Wong", "Bryan Kian Hsiang Low", "Daniela Rus", "Wei Xiao"], "title": "BarrierSteer: LLM Safety via Learning Barrier Steering", "comment": "This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs", "summary": "Despite the state-of-the-art performance of large language models (LLMs) across diverse tasks, their susceptibility to adversarial attacks and unsafe content generation remains a major obstacle to deployment, particularly in high-stakes settings. Addressing this challenge requires safety mechanisms that are both practically effective and supported by rigorous theory. We introduce BarrierSteer, a novel framework that formalizes response safety by embedding learned non-linear safety constraints directly into the model's latent representation space. BarrierSteer employs a steering mechanism based on Control Barrier Functions (CBFs) to efficiently detect and prevent unsafe response trajectories during inference with high precision. By enforcing multiple safety constraints through efficient constraint merging, without modifying the underlying LLM parameters, BarrierSteer preserves the model's original capabilities and performance. We provide theoretical results establishing that applying CBFs in latent space offers a principled and computationally efficient approach to enforcing safety. Our experiments across multiple models and datasets show that BarrierSteer substantially reduces adversarial success rates, decreases unsafe generations, and outperforms existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBarrierSteer\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u5b66\u4e60\u5230\u7684\u975e\u7ebf\u6027\u5b89\u5168\u7ea6\u675f\u76f4\u63a5\u5d4c\u5165\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\u6765\u5f62\u5f0f\u5316\u54cd\u5e94\u5b89\u5168\u6027\u3002\u5b83\u4f7f\u7528\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u7684\u5f15\u5bfc\u673a\u5236\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9ad8\u6548\u4e14\u7cbe\u786e\u5730\u68c0\u6d4b\u548c\u9632\u6b62\u4e0d\u5b89\u5168\u7684\u54cd\u5e94\u8f68\u8ff9\u3002\u5b9e\u9a8c\u8868\u660e\uff0cBarrierSteer\u80fd\u591f\u663e\u8457\u964d\u4f4e\u5bf9\u6297\u653b\u51fb\u6210\u529f\u7387\u3001\u51cf\u5c11\u4e0d\u5b89\u5168\u751f\u6210\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\u5e76\u4ea7\u751f\u4e0d\u5b89\u5168\u5185\u5bb9\u7684\u95ee\u9898\u4ecd\u7136\u662f\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\u3002\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u9700\u8981\u65e2\u5b9e\u7528\u53c8\u5177\u5907\u4e25\u683c\u7406\u8bba\u652f\u6301\u7684\u5b89\u5168\u673a\u5236\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86BarrierSteer\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u5b66\u4e60\u5230\u7684\u975e\u7ebf\u6027\u5b89\u5168\u7ea6\u675f\u76f4\u63a5\u5d4c\u5165\u5230\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u6765\u5f62\u5f0f\u5316\u54cd\u5e94\u7684\u5b89\u5168\u6027\u3002BarrierSteer\u91c7\u7528\u57fa\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u7684\u5bfc\u5411\u673a\u5236\uff0c\u5728\u63a8\u65ad\u65f6\u4ee5\u9ad8\u7cbe\u5ea6\u6709\u6548\u5730\u68c0\u6d4b\u548c\u963b\u6b62\u4e0d\u5b89\u5168\u54cd\u5e94\u8f68\u8ff9\u3002\u901a\u8fc7\u6709\u6548\u5408\u5e76\u591a\u4e2a\u5b89\u5168\u7ea6\u675f\u800c\u4e0d\u6539\u53d8\u5e95\u5c42LLM\u53c2\u6570\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u539f\u6709\u7684\u80fd\u529b\u548c\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBarrierSteer\u5927\u5927\u964d\u4f4e\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4e86\u4e0d\u5b89\u5168\u7684\u5185\u5bb9\u751f\u6210\uff0c\u5e76\u4e14\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u8bc1\u660e\u5728\u6f5c\u5728\u7a7a\u95f4\u5e94\u7528CBFs\u662f\u4e00\u79cd\u6709\u539f\u5219\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u786e\u4fdd\u5b89\u5168\u6027\u7684\u65b9\u6cd5\u3002", "conclusion": "BarrierSteer\u4e3a\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u800c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u5185\u5b9e\u65bd\u975e\u7ebf\u6027\u5b89\u5168\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u5b89\u5168\u54cd\u5e94\u7684\u6709\u6548\u7ba1\u7406\u548c\u63a7\u5236\u3002"}}
{"id": "2602.20111", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2602.20111", "abs": "https://arxiv.org/abs/2602.20111", "authors": ["Ezra Edelman", "Surbhi Goel"], "title": "Reliable Abstention under Adversarial Injections: Tight Lower Bounds and New Upper Bounds", "comment": null, "summary": "We study online learning in the adversarial injection model introduced by [Goel et al. 2017], where a stream of labeled examples is predominantly drawn i.i.d.\\ from an unknown distribution $\\mathcal{D}$, but may be interspersed with adversarially chosen instances without the learner knowing which rounds are adversarial. Crucially, labels are always consistent with a fixed target concept (the clean-label setting). The learner is additionally allowed to abstain from predicting, and the total error counts the mistakes whenever the learner decides to predict and incorrect abstentions when it abstains on i.i.d.\\ rounds. Perhaps surprisingly, prior work shows that oracle access to the underlying distribution yields $O(d^2 \\log T)$ combined error for VC dimension $d$, while distribution-agnostic algorithms achieve only $\\tilde{O}(\\sqrt{T})$ for restricted classes, leaving open whether this gap is fundamental.\n  We resolve this question by proving a matching $\u03a9(\\sqrt{T})$ lower bound for VC dimension $1$, establishing a sharp separation between the two information regimes. On the algorithmic side, we introduce a potential-based framework driven by \\emph{robust witnesses}, small subsets of labeled examples that certify predictions while remaining resilient to adversarial contamination. We instantiate this framework using two combinatorial dimensions: (1) \\emph{inference dimension}, yielding combined error $\\tilde{O}(T^{1-1/k})$ for classes of inference dimension $k$, and (2) \\emph{certificate dimension}, a new relaxation we introduce. As an application, we show that halfspaces in $\\mathbb{R}^2$ have certificate dimension $3$, obtaining the first distribution-agnostic bound of $\\tilde{O}(T^{2/3})$ for this class. This is notable since [Blum et al. 2021] showed halfspaces are not robustly learnable under clean-label attacks without abstention.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u5bf9\u6297\u6ce8\u5165\u6a21\u578b\u4e2d\u7684\u5728\u7ebf\u5b66\u4e60\uff0c\u5176\u4e2d\u6570\u636e\u6d41\u4e3b\u8981\u4ece\u672a\u77e5\u5206\u5e03\u4e2d\u72ec\u7acb\u540c\u5206\u5e03\u62bd\u53d6\uff0c\u4f46\u4e5f\u53ef\u80fd\u6df7\u5165\u5bf9\u624b\u9009\u62e9\u7684\u5b9e\u4f8b\u3002\u672c\u6587\u8bc1\u660e\u4e86\u5bf9\u4e8eVC\u7ef41\u7684\u60c5\u51b5\u5b58\u5728\u03a9(\u221aT)\u7684\u4e0b\u754c\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9c81\u68d2\u89c1\u8bc1\u7684\u6846\u67b6\u6765\u6539\u8fdb\u7b97\u6cd5\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5728\u5bf9\u6297\u6ce8\u5165\u6a21\u578b\u4e2d\uff0c\u5728\u7ebf\u5b66\u4e60\u8005\u5982\u4f55\u5728\u9762\u5bf9\u672a\u77e5\u5206\u5e03\u7684\u6570\u636e\u548c\u6f5c\u5728\u7684\u6076\u610f\u5e72\u6270\u65f6\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6548\u7684\u5b66\u4e60\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u201c\u9c81\u68d2\u89c1\u8bc1\u201d\u7684\u6f5c\u5728\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5c0f\u89c4\u6a21\u6807\u8bb0\u6837\u672c\u96c6\u6765\u9a8c\u8bc1\u9884\u6d4b\u540c\u65f6\u62b5\u6297\u5bf9\u6297\u6027\u6c61\u67d3\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u4e24\u79cd\u7ec4\u5408\u7ef4\u5ea6\u2014\u2014\u63a8\u7406\u7ef4\u5ea6\u548c\u8bc1\u4e66\u7ef4\u5ea6\uff08\u65b0\u63d0\u51fa\u7684\u653e\u677e\u6761\u4ef6\uff09\u2014\u2014\u5b9e\u73b0\u4e86\u8be5\u6846\u67b6\u7684\u5177\u4f53\u5e94\u7528\u3002", "result": "\u8bc1\u660e\u4e86\u5f53VC\u7ef4\u4e3a1\u65f6\uff0c\u5b58\u5728\u03a9(\u221aT)\u7684\u4e0b\u754c\uff0c\u8868\u660e\u4e0d\u540c\u4fe1\u606f\u72b6\u6001\u4e0b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u5e76\u4e14\u5bf9\u4e8e\u5177\u6709\u7279\u5b9a\u63a8\u7406\u7ef4\u5ea6k\u7684\u7c7b\uff0c\u8fbe\u5230\u4e86~O(T^(1-1/k))\u7684\u7efc\u5408\u8bef\u5dee\uff1b\u7279\u522b\u5730\uff0c\u53d1\u73b0\u4e8c\u7ef4\u5b9e\u6570\u7a7a\u95f4\u4e2d\u7684\u534a\u7a7a\u95f4\u5177\u67093\u7684\u8bc1\u4e66\u7ef4\u5ea6\uff0c\u4ece\u800c\u9996\u6b21\u5f97\u5230\u4e86\u8fd9\u7c7b\u95ee\u9898\u7684\u4e00\u4e2a\u4e0e\u5206\u5e03\u65e0\u5173\u7684~O(T^(2/3))\u754c\u3002", "conclusion": "\u672c\u6587\u5de5\u4f5c\u63ed\u793a\u4e86\u5728\u5bf9\u6297\u73af\u5883\u4e2d\uff0c\u62e5\u6709\u5bf9\u5e95\u5c42\u5206\u5e03\u7684\u5148\u9a8c\u77e5\u8bc6\u4e0e\u6ca1\u6709\u8fd9\u79cd\u77e5\u8bc6\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u7684\u5dee\u8ddd\uff0c\u5e76\u4e14\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u4ee5\u6539\u5584\u5728\u7f3a\u4e4f\u5b8c\u6574\u4fe1\u606f\u60c5\u51b5\u4e0b\u7684\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2602.20126", "categories": ["cs.LG", "cs.IT", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20126", "abs": "https://arxiv.org/abs/2602.20126", "authors": ["Yunxiao Zhao", "Changxiao Cai"], "title": "Adaptation to Intrinsic Dependence in Diffusion Language Models", "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) approaches, enabling parallel token generation beyond a rigid left-to-right order. Despite growing empirical success, the theoretical understanding of how unmasking schedules -- which specify the order and size of unmasked tokens during sampling -- affect generation quality remains limited. In this work, we introduce a distribution-agnostic unmasking schedule for DLMs that adapts to the (unknown) dependence structure of the target data distribution, without requiring any prior knowledge or hyperparameter tuning. In contrast to prior deterministic procedures that fix unmasking sizes, our method randomizes the number of tokens revealed at each iteration. We show that, for two specific parameter choices, the sampling convergence guarantees -- measured by Kullback-Leibler (KL) divergence -- scale as $\\widetilde O(\\mathsf{TC}/K)$ and $\\widetilde O(\\mathsf{DTC}/K)$ respectively. Here, $K$ is the number of iterations, and $\\mathsf{TC}$ and $\\mathsf{DTC}$ are the total correlation and dual total correlation of the target distribution, capturing the intrinsic dependence structure underlying the data. Importantly, our guarantees hold in the practically relevant parallel-sampling regime $K<L$ where $L$ is the token sequence length. These results significantly improve upon prior convergence theories and yield substantial sampling acceleration for low-complexity distributions. Overall, our findings unveil the adaptivity of DLMs to intrinsic data structures and shed light on the benefit of randomized unmasking sizes in inference schedule design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u5206\u5e03\u65e0\u5173\u7684\u89e3\u7801\u65f6\u95f4\u8868\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u9002\u5e94\u76ee\u6807\u6570\u636e\u5206\u5e03\uff08\u672a\u77e5\uff09\u7684\u4f9d\u8d56\u7ed3\u6784\uff0c\u800c\u65e0\u9700\u4efb\u4f55\u5148\u9a8c\u77e5\u8bc6\u6216\u8d85\u53c2\u6570\u8c03\u6574\u3002\u901a\u8fc7\u968f\u673a\u5316\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u63ed\u793a\u7684\u6807\u8bb0\u6570\u91cf\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u5bf9\u4e8e\u4e24\u79cd\u7279\u5b9a\u53c2\u6570\u9009\u62e9\uff0c\u91c7\u6837\u6536\u655b\u4fdd\u8bc1\u5206\u522b\u4ee5$\\widetilde O(\\mathsf{TC}/K)$\u548c$\\widetilde O(\\mathsf{DTC}/K)$\u7f29\u653e\uff0c\u5176\u4e2d$K$\u662f\u8fed\u4ee3\u6b21\u6570\uff0c$\\mathsf{TC}$\u548c$\\mathsf{DTC}$\u4ee3\u8868\u4e86\u76ee\u6807\u5206\u5e03\u7684\u603b\u76f8\u5173\u6027\u548c\u53cc\u91cd\u603b\u76f8\u5173\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u5bf9\u5b9e\u9645\u5e76\u884c\u62bd\u6837\u65b9\u6848$K<L$\uff08$L$\u4e3a\u6807\u8bb0\u5e8f\u5217\u957f\u5ea6\uff09\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u5148\u524d\u7684\u6536\u655b\u7406\u8bba\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4f4e\u590d\u6742\u5ea6\u5206\u5e03\u63d0\u4f9b\u4e86\u5b9e\u8d28\u6027\u7684\u62bd\u6837\u52a0\u901f\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u8bed\u8a00\u6a21\u578b(DLMs)\u5728\u5b9e\u8bc1\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5173\u4e8e\u89e3\u7801\u65f6\u95f4\u8868\u2014\u2014\u5373\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\u6307\u5b9a\u88ab\u63ed\u5f00\u7684\u6807\u8bb0\u987a\u5e8f\u548c\u5927\u5c0f\u7684\u65b9\u5f0f\u2014\u2014\u5982\u4f55\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u89e3\u7801\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u4e0d\u4ec5\u80fd\u591f\u9002\u5e94\u6570\u636e\u5185\u5728\u7684\u4f9d\u8d56\u7ed3\u6784\uff0c\u8fd8\u80fd\u907f\u514d\u5bf9\u5148\u9a8c\u77e5\u8bc6\u6216\u8d85\u53c2\u6570\u8c03\u8282\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u4e00\u79cd\u968f\u673a\u5316\u7684\u89e3\u7801\u65f6\u95f4\u8868\uff0c\u5b83\u4e0d\u9884\u5148\u8bbe\u5b9a\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u8981\u63ed\u9732\u7684\u6807\u8bb0\u6570\u91cf\uff0c\u800c\u662f\u6839\u636e\u76ee\u6807\u6570\u636e\u5206\u5e03\u7684\u672a\u77e5\u4f9d\u8d56\u7ed3\u6784\u81ea\u9002\u5e94\u5730\u51b3\u5b9a\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u4efb\u4f55\u5148\u9a8c\u4fe1\u606f\u6216\u989d\u5916\u7684\u8d85\u53c2\u6570\u8c03\u6574\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u968f\u673a\u5316\u89e3\u7801\u65f6\u95f4\u8868\u53ef\u4ee5\u5728\u4e24\u4e2a\u5177\u4f53\u7684\u53c2\u6570\u914d\u7f6e\u4e0b\u63d0\u4f9b\u6539\u8fdb\u7684\u91c7\u6837\u6536\u655b\u4fdd\u969c\u3002\u5bf9\u4e8e\u5177\u6709\u8f83\u4f4e\u590d\u6742\u5ea6\u7684\u6570\u636e\u5206\u5e03\uff0c\u8fd9\u79cd\u65b0\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u52a0\u5feb\u62bd\u6837\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u76f8\u5173\u7684\u5e76\u884c\u62bd\u6837\u60c5\u5f62\u4e0b\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u5373\u5f53\u8fed\u4ee3\u6b21\u6570\u5c11\u4e8e\u6807\u8bb0\u5e8f\u5217\u957f\u5ea6\u65f6\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u5185\u5728\u6570\u636e\u7ed3\u6784\u7684\u9002\u5e94\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u63a8\u7406\u8ba1\u5212\u8bbe\u8ba1\u4e2d\u91c7\u7528\u968f\u673a\u5316\u89e3\u7801\u89c4\u6a21\u7684\u597d\u5904\u3002\u8fd9\u4e3a\u7406\u89e3\u53ca\u4f18\u5316\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2602.20152", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20152", "abs": "https://arxiv.org/abs/2602.20152", "authors": ["Zhenyao Ma", "Yue Liang", "Dongxu Li"], "title": "Behavior Learning (BL): Learning Hierarchical Optimization Structures from Data", "comment": "ICLR 2026", "summary": "Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and identifiable optimization structures from data, ranging from single optimization problems to hierarchical compositions. It unifies predictive performance, intrinsic interpretability, and identifiability, with broad applicability to scientific domains involving optimization. BL parameterizes a compositional utility function built from intrinsically interpretable modular blocks, which induces a data distribution for prediction and generation. Each block represents and can be written in symbolic form as a utility maximization problem (UMP), a foundational paradigm in behavioral science and a universal framework of optimization. BL supports architectures ranging from a single UMP to hierarchical compositions, the latter modeling hierarchical optimization structures. Its smooth and monotone variant (IBL) guarantees identifiability. Theoretically, we establish the universal approximation property of BL, and analyze the M-estimation properties of IBL. Empirically, BL demonstrates strong predictive performance, intrinsic interpretability and scalability to high-dimensional data. Code: https://github.com/MoonYLiang/Behavior-Learning ; install via pip install blnetwork.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u2014\u2014\u884c\u4e3a\u5b66\u4e60\uff08BL\uff09\uff0c\u5b83\u53ef\u4ee5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53ef\u89e3\u91ca\u548c\u53ef\u8bc6\u522b\u7684\u4f18\u5316\u7ed3\u6784\uff0c\u9002\u7528\u4e8e\u4ece\u5355\u4e2a\u4f18\u5316\u95ee\u9898\u5230\u5206\u5c42\u7ec4\u5408\u7684\u5404\u79cd\u60c5\u51b5\u3002BL\u4e0d\u4ec5\u7edf\u4e00\u4e86\u9884\u6d4b\u6027\u80fd\u3001\u5185\u5728\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u8bc6\u522b\u6027\uff0c\u8fd8\u5177\u6709\u5e7f\u6cdb\u7684\u79d1\u5b66\u9886\u57df\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u53d7\u5230\u884c\u4e3a\u79d1\u5b66\u542f\u53d1\uff0c\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u53ef\u89e3\u91ca\u548c\u53ef\u8bc6\u522b\u4f18\u5316\u7ed3\u6784\u7684\u65b0\u9896\u901a\u7528\u673a\u5668\u5b66\u4e60\u6846\u67b6\u3002\u8fd9\u6837\u7684\u6846\u67b6\u53ef\u4ee5\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6d89\u53ca\u4f18\u5316\u7684\u79d1\u5b66\u9886\u57df\u3002", "method": "\u901a\u8fc7\u53c2\u6570\u5316\u7531\u672c\u8d28\u4e0a\u53ef\u89e3\u91ca\u6a21\u5757\u6784\u5efa\u7684\u590d\u5408\u6548\u7528\u51fd\u6570\u6765\u5b9e\u73b0\uff0c\u6bcf\u4e2a\u6a21\u5757\u90fd\u53ef\u4ee5\u88ab\u5199\u6210\u7b26\u53f7\u5f62\u5f0f\u4f5c\u4e3a\u6548\u7528\u6700\u5927\u5316\u95ee\u9898(UMP)\u3002BL\u652f\u6301\u4ece\u5355\u4e00UMP\u5230\u5c42\u6b21\u7ec4\u5408\u7684\u4e0d\u540c\u67b6\u6784\uff0c\u5176\u4e2d\u5e73\u6ed1\u4e14\u5355\u8c03\u7684\u53d8\u4f53(IBL)\u4fdd\u8bc1\u4e86\u53ef\u8bc6\u522b\u6027\u3002", "result": "\u7406\u8bba\u65b9\u9762\uff0c\u786e\u7acb\u4e86BL\u7684\u901a\u7528\u903c\u8fd1\u6027\u8d28\uff0c\u5e76\u5206\u6790\u4e86IBL\u7684M-\u4f30\u8ba1\u7279\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cBL\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u9884\u6d4b\u6027\u80fd\u3001\u5185\u5728\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u5bf9\u9ad8\u7ef4\u6570\u636e\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u884c\u4e3a\u5b66\u4e60(BL)\u4e3a\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u4f18\u5316\u7ed3\u6784\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u800c\u6709\u6548\u7684\u9014\u5f84\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\u4e0e\u5185\u5728\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u79d1\u5b66\u9886\u57df\u4e2d\u7684\u4f18\u5316\u95ee\u9898\u3002"}}
